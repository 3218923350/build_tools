{
  "generated_at": "2025-12-16T07:11:29.392589+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "H1",
      "leaf_cluster_name": "医学影像-分割/检测/诊断生态",
      "domain": "Med Imaging",
      "typical_objects": "DICOM/images",
      "task_chain": "预处理→训练/推理→评测→部署",
      "tool_form": "框架 + 标注/数据 + 部署"
    },
    "unit": {
      "unit_id": "H1-03",
      "unit_name": "Foundation models 与微调",
      "target_scale": "200–450",
      "coverage_tools": "pretraining、PEFT"
    },
    "search": {
      "target_candidates": 450,
      "queries": [
        "[GH] RadImageNet",
        "[GH] Medical-Net",
        "[GH] STU-Net",
        "[GH] SwinUNETR",
        "[GH] MONAI",
        "[GH] SAM-Med2D",
        "[GH] MedCLIP",
        "[GH] BioMedCLIP",
        "[GH] MedSAM",
        "[GH] medical foundation model",
        "[GH] medical image pretraining",
        "[GH] med-sam",
        "[GH] medical vision transformer",
        "[GH] medical self-supervised learning",
        "[GH] medical contrastive learning",
        "[GH] medical peft",
        "[GH] medical lora",
        "[GH] medical clip",
        "[GH] radiology foundation model",
        "[GH] pathology foundation model",
        "[GH] medical masked autoencoder",
        "[GH] segment anything medical",
        "[GH] medical fine-tuning",
        "[WEB] medical imaging foundation models github",
        "[WEB] segment anything model medical adaptation github",
        "[WEB] self-supervised learning medical imaging github",
        "[WEB] parameter efficient fine tuning medical imaging github",
        "[WEB] awesome medical foundation models github",
        "[WEB] medical vision language models github"
      ],
      "total_candidates": 1053,
      "tool_candidates": 490,
      "final_tools": 195
    }
  },
  "tools": [
    {
      "name": "Genetic U-Net",
      "one_line_profile": "Automatically designed deep networks for retinal vessel segmentation using genetic algorithms",
      "detailed_description": "A deep learning framework that utilizes genetic algorithms to automatically design U-Net architectures for medical image segmentation, specifically demonstrated on retinal vessel segmentation tasks.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "architecture_search"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/96jhwei/Genetic-U-Net",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "genetic-algorithm",
        "u-net",
        "retinal-segmentation"
      ],
      "id": 1
    },
    {
      "name": "M3FM",
      "one_line_profile": "Multimodal multidomain multilingual medical foundation model for zero-shot clinical diagnosis",
      "detailed_description": "A comprehensive medical foundation model designed to handle multimodal (images, text), multidomain, and multilingual data for zero-shot clinical diagnosis tasks, published in npj Digital Medicine.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "diagnosis",
        "zero_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AI-in-Health/M3FM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "foundation-model",
        "multimodal",
        "zero-shot"
      ],
      "id": 2
    },
    {
      "name": "3DINO",
      "one_line_profile": "Generalizable 3D framework for self-supervised learning in medical imaging",
      "detailed_description": "A framework and model designed for self-supervised learning on 3D medical images, aiming to improve generalizability and representation learning in medical imaging tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "pretraining",
        "self_supervised_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AICONSlab/3DINO",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "self-supervised-learning",
        "3d-imaging",
        "medical-imaging"
      ],
      "id": 3
    },
    {
      "name": "DINOv2-3D-Med",
      "one_line_profile": "3D implementation of DINOv2 for self-supervised pretraining on volumetric medical images",
      "detailed_description": "A 3D adaptation of the DINOv2 self-supervised learning method, implemented using Lightly, MONAI, and PyTorch Lightning, specifically optimized for volumetric medical image pretraining.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "pretraining",
        "self_supervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AIM-Harvard/DINOv2-3D-Med",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dinov2",
        "3d-medical-imaging",
        "self-supervised"
      ],
      "id": 4
    },
    {
      "name": "AHF-Fusion-U-Net",
      "one_line_profile": "Attention-Guided Hierarchical Fusion U-Net for uncertainty-driven segmentation",
      "detailed_description": "A U-Net variant incorporating attention mechanisms and hierarchical fusion to improve medical image segmentation, with a focus on uncertainty estimation.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "uncertainty_estimation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/AfsanaAhmedMunia/AHF-Fusion-U-Net",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "u-net",
        "attention-mechanism",
        "segmentation"
      ],
      "id": 5
    },
    {
      "name": "SAM-Breast-Tumor-Segmentation",
      "one_line_profile": "Custom application of Segment Anything Model (SAM) for breast tumor segmentation",
      "detailed_description": "A workflow and fine-tuning implementation of the Segment Anything Model (SAM) specifically adapted for segmenting breast tumors in medical imaging.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "fine_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/AliAmini93/SAM-Breast-Tumor-Segmentation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sam",
        "breast-cancer",
        "segmentation"
      ],
      "id": 6
    },
    {
      "name": "DC-UNet",
      "one_line_profile": "Dual-Channel U-Net for medical image segmentation",
      "detailed_description": "A novel U-Net based architecture (DC-UNet) designed to enhance performance in medical image segmentation tasks.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AngeLouCN/DC-UNet",
      "help_website": [],
      "license": null,
      "tags": [
        "u-net",
        "medical-segmentation",
        "deep-learning"
      ],
      "id": 7
    },
    {
      "name": "Min_Max_Similarity",
      "one_line_profile": "Contrastive learning based semi-supervised segmentation network",
      "detailed_description": "A semi-supervised learning framework for medical image segmentation that utilizes contrastive learning and min-max similarity techniques.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "semi_supervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AngeLouCN/Min_Max_Similarity",
      "help_website": [],
      "license": null,
      "tags": [
        "contrastive-learning",
        "semi-supervised",
        "segmentation"
      ],
      "id": 8
    },
    {
      "name": "RadImageNet",
      "one_line_profile": "Pre-trained CNNs trained solely on medical imaging for transfer learning",
      "detailed_description": "A large-scale medical imaging dataset and pre-trained convolutional neural network models designed to serve as a backbone for transfer learning in medical imaging applications.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "pretraining",
        "transfer_learning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/BMEII-AI/RadImageNet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pretrained-models",
        "transfer-learning",
        "radiology"
      ],
      "id": 9
    },
    {
      "name": "3D-TransUNet",
      "one_line_profile": "Vision Transformers for 3D medical image segmentation",
      "detailed_description": "An implementation of TransUNet adapted for 3D medical image segmentation, combining the strengths of Transformers and U-Net architectures.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Beckschen/3D-TransUNet",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "transformer",
        "3d-segmentation",
        "u-net"
      ],
      "id": 10
    },
    {
      "name": "SALT",
      "one_line_profile": "Parameter-Efficient Fine-Tuning via Singular Value Adaptation",
      "detailed_description": "A library for Parameter-Efficient Fine-Tuning (PEFT) using Singular Value Adaptation with Low-Rank Transformation, designed for adapting foundation models.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BioMedIA-MBZUAI/SALT",
      "help_website": [],
      "license": null,
      "tags": [
        "peft",
        "fine-tuning",
        "foundation-model"
      ],
      "id": 11
    },
    {
      "name": "MSU-Net",
      "one_line_profile": "Multi-scale U-Net for 2D medical image segmentation",
      "detailed_description": "A multi-scale U-Net architecture designed for accurate 2D medical image segmentation tasks.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CN-zdy/MSU_Net",
      "help_website": [],
      "license": null,
      "tags": [
        "u-net",
        "multi-scale",
        "segmentation"
      ],
      "id": 12
    },
    {
      "name": "ProtoContra-SFDA",
      "one_line_profile": "Source-Free Domain Adaptation for medical image segmentation",
      "detailed_description": "A framework for Source-Free Domain Adaptation (SFDA) in medical image segmentation using prototype-anchored feature alignment and contrastive learning.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "domain_adaptation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CSCYQJ/MICCAI23-ProtoContra-SFDA",
      "help_website": [],
      "license": null,
      "tags": [
        "domain-adaptation",
        "contrastive-learning",
        "segmentation"
      ],
      "id": 13
    },
    {
      "name": "DyCON",
      "one_line_profile": "Dynamic Uncertainty-aware Consistency and Contrastive Learning for Semi-supervised Segmentation",
      "detailed_description": "A semi-supervised medical image segmentation framework incorporating dynamic uncertainty-aware consistency and contrastive learning.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "semi_supervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CVML-KU/DyCON",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semi-supervised",
        "uncertainty-aware",
        "contrastive-learning"
      ],
      "id": 14
    },
    {
      "name": "OSS-Net",
      "one_line_profile": "Memory efficient high resolution semantic segmentation of 3D medical data",
      "detailed_description": "A memory-efficient neural network architecture designed for high-resolution semantic segmentation of 3D medical imaging data.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChristophReich1996/OSS-Net",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "3d-segmentation",
        "memory-efficient",
        "high-resolution"
      ],
      "id": 15
    },
    {
      "name": "SlicerAutomatedDentalTools",
      "one_line_profile": "3D Slicer extension for automated dental tools",
      "detailed_description": "A 3D Slicer extension that provides automated tools for dental image analysis, including AMASSS, ALI-CBCT, and ALI-IOS.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "visualization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/DCBIA-OrthoLab/SlicerAutomatedDentalTools",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "3d-slicer",
        "dental-imaging",
        "automation"
      ],
      "id": 16
    },
    {
      "name": "HealthGPT",
      "one_line_profile": "Medical Large Vision-Language Model for unifying comprehension and generation",
      "detailed_description": "A large vision-language foundation model tailored for medical applications, capable of unifying comprehension and generation tasks via heterogeneous knowledge adaptation.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "diagnosis",
        "report_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DCDmllm/HealthGPT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "foundation-model",
        "vision-language",
        "medical-llm"
      ],
      "id": 17
    },
    {
      "name": "RRT-MIL",
      "one_line_profile": "Feature Re-Embedding for computational pathology",
      "detailed_description": "A method for feature re-embedding in computational pathology to achieve foundation model-level performance, specifically for Multiple Instance Learning (MIL) tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "pathology_analysis",
        "feature_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DearCaat/RRT-MIL",
      "help_website": [],
      "license": null,
      "tags": [
        "computational-pathology",
        "mil",
        "feature-embedding"
      ],
      "id": 18
    },
    {
      "name": "MedicalMultitaskModeling",
      "one_line_profile": "Framework for training foundational medical imaging models via multi-task learning",
      "detailed_description": "A framework developed by Fraunhofer MEVIS for training foundational medical imaging models using multi-task learning strategies, enabling robust feature extraction across various medical tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "model_training",
        "foundation_model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/FraunhoferMEVIS/MedicalMultitaskModeling",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "multi-task-learning",
        "foundation-models",
        "medical-imaging"
      ],
      "id": 19
    },
    {
      "name": "TotalSegmentator-AIDE",
      "one_line_profile": "TotalSegmentator packaged as a MONAI Application Package (MAP) for deployment",
      "detailed_description": "An AIDE (AI Deployment Engine) application wrapper for TotalSegmentator, following the MONAI Application Package (MAP) standard, facilitating the deployment of whole-body segmentation models in clinical workflows.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "deployment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GSTT-CSC/TotalSegmentator-AIDE",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "monai",
        "totalsegmentator",
        "aide",
        "segmentation"
      ],
      "id": 20
    },
    {
      "name": "FairSeg",
      "one_line_profile": "Large-scale medical image segmentation dataset and fairness learning method",
      "detailed_description": "A repository providing a large-scale medical image segmentation dataset and implementing the Fair Error-Bound Scaling method for Segment Anything Model (SAM) to address fairness in medical AI.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "fairness_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Harvard-Ophthalmology-AI-Lab/FairSeg",
      "help_website": [],
      "license": null,
      "tags": [
        "dataset",
        "fairness",
        "segmentation",
        "sam"
      ],
      "id": 21
    },
    {
      "name": "Hibou",
      "one_line_profile": "Foundational models library for pathology image analysis",
      "detailed_description": "A library providing access to foundational models specifically designed for computational pathology, enabling feature extraction and downstream task adaptation.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "pathology_analysis",
        "feature_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HistAI/hibou",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pathology",
        "foundation-models",
        "histopathology"
      ],
      "id": 22
    },
    {
      "name": "Medical-SAM-Adapter",
      "one_line_profile": "Lightweight adapter to bridge Segment Anything Model (SAM) with medical imaging",
      "detailed_description": "A widely used tool that adapts the Segment Anything Model (SAM) for medical image segmentation using a lightweight adapter mechanism, enabling high-performance segmentation on medical data with minimal fine-tuning.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ImprintLab/Medical-SAM-Adapter",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "sam",
        "adapter",
        "segmentation",
        "peft"
      ],
      "id": 23
    },
    {
      "name": "Medical-SAM2",
      "one_line_profile": "Adaptation of Segment Anything Model 2 (SAM2) for 3D medical images",
      "detailed_description": "An extension of the Segment Anything Model 2 (SAM2) tailored for 3D medical imaging, providing capabilities for volumetric segmentation and adaptation to medical domains.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "3d_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ImprintLab/Medical-SAM2",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sam2",
        "3d-segmentation",
        "medical-imaging"
      ],
      "id": 24
    },
    {
      "name": "VS_Seg",
      "one_line_profile": "Automatic segmentation tool for Vestibular Schwannoma using MONAI",
      "detailed_description": "A specialized tool developed by KCL-BMEIS for the automatic segmentation of Vestibular Schwannoma from MRI scans, built upon the MONAI framework.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "diagnosis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/KCL-BMEIS/VS_Seg",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "monai",
        "vestibular-schwannoma",
        "mri-segmentation"
      ],
      "id": 25
    },
    {
      "name": "Pathology-Foundation-Model-Benchmark",
      "one_line_profile": "Benchmarking suite for pathology foundation models on cell type classification",
      "detailed_description": "A benchmarking tool designed to evaluate the performance of various pathology foundation models specifically on cell type classification tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "benchmarking",
        "classification"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Kainmueller-Lab/Pathology-Foundation-Model-Benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "pathology",
        "foundation-models"
      ],
      "id": 26
    },
    {
      "name": "ITKPOCUS",
      "one_line_profile": "Library for streaming and preprocessing point-of-care ultrasound (POCUS) video",
      "detailed_description": "An open-source library based on ITK for handling, streaming, and preprocessing point-of-care ultrasound (POCUS) video data, facilitating development of ultrasound analysis tools.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "image_processing",
        "ultrasound_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/KitwareMedical/ITKPOCUS",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ultrasound",
        "pocus",
        "itk"
      ],
      "id": 27
    },
    {
      "name": "FedFMS",
      "one_line_profile": "Federated learning framework for fine-tuning SAM on medical images",
      "detailed_description": "A framework for fine-tuning the Segment Anything Model (SAM) within a federated learning paradigm, specifically designed for medical image segmentation tasks to address data privacy and scarcity.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "federated_learning",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LIU-YUXI/FedFMS",
      "help_website": [],
      "license": null,
      "tags": [
        "federated-learning",
        "sam",
        "medical-segmentation"
      ],
      "id": 28
    },
    {
      "name": "PASTA",
      "one_line_profile": "Pan-Tumor Radiology Foundation Model using synthetic data",
      "detailed_description": "A foundation model for pan-tumor radiology that utilizes synthetic training data to provide advanced oncological insights, addressing data scarcity in medical imaging.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "diagnosis",
        "oncology",
        "pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LWHYC/PASTA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "foundation-model",
        "radiology",
        "synthetic-data"
      ],
      "id": 29
    },
    {
      "name": "MEDIAR",
      "one_line_profile": "Data-centric and model-centric framework for microscopy segmentation",
      "detailed_description": "An open-source framework for multi-modality microscopy segmentation that combines data-centric and model-centric approaches, winning the NeurIPS 2022 CellSeg Challenge.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "microscopy"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lee-Gihun/MEDIAR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "microscopy",
        "cell-segmentation",
        "neurips-challenge"
      ],
      "id": 30
    },
    {
      "name": "BiomedCLIP-LoRA",
      "one_line_profile": "Implementation of BiomedCLIP with LoRA fine-tuning",
      "detailed_description": "A PyTorch implementation enabling Low-Rank Adaptation (LoRA) fine-tuning for the BiomedCLIP vision-language model, facilitating efficient adaptation to specific biomedical tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "fine_tuning",
        "vision_language_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LightersWang/BiomedCLIP-LoRA",
      "help_website": [],
      "license": null,
      "tags": [
        "biomedclip",
        "lora",
        "peft"
      ],
      "id": 31
    },
    {
      "name": "UNetTransplant",
      "one_line_profile": "Pre-training strategy for model merging in 3D segmentation",
      "detailed_description": "A framework investigating the role of pre-training for model merging in 3D medical segmentation, providing tools to improve model generalization and performance.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "model_merging",
        "pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LucaLumetti/UNetTransplant",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "3d-segmentation",
        "model-merging",
        "u-net"
      ],
      "id": 32
    },
    {
      "name": "VoCo",
      "one_line_profile": "Volume contrastive learning framework for 3D medical imaging",
      "detailed_description": "A simple-yet-effective volume contrastive learning framework designed for 3D medical image analysis, enabling self-supervised pre-training for downstream segmentation and detection tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "pretraining",
        "contrastive_learning",
        "3d_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Luffy03/VoCo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "contrastive-learning",
        "3d-medical-imaging",
        "self-supervised"
      ],
      "id": 33
    },
    {
      "name": "KEEP",
      "one_line_profile": "Knowledge-enhanced pathology vision-language foundation model",
      "detailed_description": "A foundation model for cancer diagnosis that integrates medical knowledge into a pathology vision-language framework to enhance diagnostic accuracy.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "diagnosis",
        "pathology",
        "vision_language_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MAGIC-AI4Med/KEEP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pathology",
        "foundation-model",
        "cancer-diagnosis"
      ],
      "id": 34
    },
    {
      "name": "PathPT",
      "one_line_profile": "Few-shot prompt-tuning for pathology foundation models",
      "detailed_description": "A tool for boosting pathology foundation models via few-shot prompt-tuning, specifically targeting rare cancer subtyping tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "diagnosis",
        "pathology",
        "prompt_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MAGIC-AI4Med/PathPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-tuning",
        "pathology",
        "few-shot-learning"
      ],
      "id": 35
    },
    {
      "name": "LaMIM",
      "one_line_profile": "Large Medical Image Foundation Model",
      "detailed_description": "A large-scale foundation model designed for general medical image analysis tasks, developed by the MAI Lab at West China Hospital.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "image_analysis",
        "pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MAI-Lab-West-China-Hospital/LaMIM",
      "help_website": [],
      "license": null,
      "tags": [
        "foundation-model",
        "medical-imaging"
      ],
      "id": 36
    },
    {
      "name": "agent-sam",
      "one_line_profile": "Segment Anything Model wrapper for MITK",
      "detailed_description": "A wrapper integrating the Segment Anything Model (SAM) into the Medical Imaging Interaction Toolkit (MITK), enabling interactive segmentation within the MITK environment.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "interactive_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MIC-DKFZ/agent-sam",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "mitk",
        "sam",
        "segmentation"
      ],
      "id": 37
    },
    {
      "name": "Medical Detection Toolkit",
      "one_line_profile": "2D and 3D object detection framework for medical images",
      "detailed_description": "A comprehensive toolkit containing 2D and 3D implementations of prevalent object detectors (Mask R-CNN, Retina Net, Retina U-Net) tailored for medical image analysis.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "detection",
        "segmentation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MIC-DKFZ/medicaldetectiontoolkit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "object-detection",
        "medical-imaging",
        "3d-detection"
      ],
      "id": 38
    },
    {
      "name": "fastMONAI",
      "one_line_profile": "High-level wrapper for MONAI to simplify medical deep learning",
      "detailed_description": "A library that simplifies the use of MONAI for deep learning in medical imaging, providing a fastai-like interface for rapid development and training.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "image_analysis",
        "training_framework"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/MMIV-ML/fastMONAI",
      "help_website": [
        "https://fastmonai.no"
      ],
      "license": "Apache-2.0",
      "tags": [
        "monai",
        "fastai",
        "medical-imaging"
      ],
      "id": 39
    },
    {
      "name": "SynFoC",
      "one_line_profile": "Semi-supervised segmentation using foundation and conventional models",
      "detailed_description": "A framework for mixed-domain semi-supervised medical image segmentation that leverages the mutual aid of foundation models and conventional models.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "semi_supervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MQinghe/SynFoC",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "semi-supervised",
        "foundation-model",
        "segmentation"
      ],
      "id": 40
    },
    {
      "name": "mindGlide",
      "one_line_profile": "Brain segmentation tool using MONAI and Dynamic Unet",
      "detailed_description": "A specific implementation for brain segmentation leveraging MONAI and Dynamic U-Net architectures, designed for high-performance neuroimaging analysis.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "neuroimaging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MS-PINPOINT/mindGlide",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "brain-segmentation",
        "monai",
        "nnunet"
      ],
      "id": 41
    },
    {
      "name": "MediConfusion",
      "one_line_profile": "Benchmark for reliability of multimodal medical foundation models",
      "detailed_description": "A dataset and evaluation toolkit designed to probe the reliability of multimodal medical foundation models, assessing their trustworthiness in clinical scenarios.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking",
        "reliability_analysis"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/MShahabSepehri/MediConfusion",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "foundation-model",
        "reliability"
      ],
      "id": 42
    },
    {
      "name": "Generic U-Net GDC",
      "one_line_profile": "Generic U-Net implementation with Generalized Dice Coefficient",
      "detailed_description": "A generic U-Net based segmentation solver using Generalized Dice Coefficient, designed to work out-of-the-box for multiple organs (liver, spleen) as part of the Medical Segmentation Decathlon.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Maor-Oz/Medical-Segmentation-Decathlon-U-net-CNN-with-Generalized-Dice-Coefficient",
      "help_website": [],
      "license": null,
      "tags": [
        "u-net",
        "segmentation",
        "generalized-dice"
      ],
      "id": 43
    },
    {
      "name": "MedCLIP",
      "one_line_profile": "Medical image captioning using CLIP",
      "detailed_description": "An implementation adapting OpenAI's CLIP model for medical image captioning tasks, enabling vision-language alignment in the medical domain.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "image_captioning",
        "vision_language_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Mauville/MedCLIP",
      "help_website": [],
      "license": null,
      "tags": [
        "clip",
        "image-captioning",
        "medical-imaging"
      ],
      "id": 44
    },
    {
      "name": "UDTransNet",
      "one_line_profile": "U-Net with learnable skip connections for segmentation",
      "detailed_description": "An improved version of UCTransNet featuring learnable skip connections to narrow semantic gaps in medical image segmentation.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/McGregorWwww/UDTransNet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "u-net",
        "transformer",
        "segmentation"
      ],
      "id": 45
    },
    {
      "name": "ProMISe",
      "one_line_profile": "Prompt-driven 3D segmentation using pretrained foundation models",
      "detailed_description": "A framework for 3D medical image segmentation that utilizes pretrained image foundation models driven by prompts to achieve accurate segmentation.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "prompt_learning",
        "foundation_model"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MedICL-VU/ProMISe",
      "help_website": [],
      "license": null,
      "tags": [
        "3d-segmentation",
        "prompt-driven",
        "foundation-model"
      ],
      "id": 46
    },
    {
      "name": "MedSegX",
      "one_line_profile": "Generalist foundation model for open-world medical segmentation",
      "detailed_description": "A generalist foundation model and associated database designed for open-world medical image segmentation, capable of handling diverse modalities and targets.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "foundation_model",
        "open_world_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MedSegX/MedSegX-code",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "foundation-model",
        "generalist-model",
        "segmentation"
      ],
      "id": 47
    },
    {
      "name": "MIU-VL",
      "one_line_profile": "Medical Image Understanding with Pretrained Vision Language Models",
      "detailed_description": "A comprehensive study and framework for applying pretrained vision-language models to medical image understanding tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "image_understanding",
        "vision_language_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MembrAI/MIU-VL",
      "help_website": [],
      "license": null,
      "tags": [
        "vision-language",
        "medical-imaging",
        "pretraining"
      ],
      "id": 48
    },
    {
      "name": "MIU-VL (MembrLab)",
      "one_line_profile": "Medical Image Understanding with Pretrained VLM (Mirror/Lab Repo)",
      "detailed_description": "Repository for the ICLR2023 paper on Medical Image Understanding with Pretrained Vision Language Models (likely the lab version of MembrAI/MIU-VL).",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "image_understanding",
        "vision_language_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MembrLab/MIU-VL",
      "help_website": [],
      "license": null,
      "tags": [
        "vision-language",
        "medical-imaging"
      ],
      "id": 49
    },
    {
      "name": "VNet-Tensorflow",
      "one_line_profile": "Tensorflow implementation of V-Net for 3D segmentation",
      "detailed_description": "A TensorFlow implementation of the V-Net architecture, a popular model for volumetric medical image segmentation.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "3d_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MiguelMonteiro/VNet-Tensorflow",
      "help_website": [],
      "license": null,
      "tags": [
        "v-net",
        "tensorflow",
        "segmentation"
      ],
      "id": 50
    },
    {
      "name": "MedSAM Prompt Automation",
      "one_line_profile": "Automating MedSAM prompts with weak few-shot supervision",
      "detailed_description": "A tool for automating the prompt generation process for MedSAM using weak few-shot supervision, reducing the need for manual interaction.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "prompt_engineering",
        "automation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Minimel/MedSAMWeakFewShotPromptAutomation",
      "help_website": [],
      "license": null,
      "tags": [
        "medsam",
        "prompt-learning",
        "few-shot"
      ],
      "id": 51
    },
    {
      "name": "MONAI Cloud API",
      "one_line_profile": "Cloud API tools for MONAI imaging workflows",
      "detailed_description": "Development tools and notebooks for interacting with the MONAI Cloud API, facilitating remote and scalable medical imaging analysis and training.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "workflow_management",
        "cloud_computing"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/NVIDIA/monai-cloud-api",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "monai",
        "cloud-api",
        "nvidia"
      ],
      "id": 52
    },
    {
      "name": "MobileUNETR",
      "one_line_profile": "Lightweight hybrid Vision Transformer for segmentation",
      "detailed_description": "Implementation of MobileUNETR, a lightweight end-to-end hybrid Vision Transformer designed for efficient medical image segmentation on resource-constrained devices.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "efficient_deep_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OSUPCVLab/MobileUNETR",
      "help_website": [],
      "license": null,
      "tags": [
        "vision-transformer",
        "mobile-ai",
        "segmentation"
      ],
      "id": 53
    },
    {
      "name": "MedViT",
      "one_line_profile": "Robust Vision Transformer for medical image classification",
      "detailed_description": "A robust Vision Transformer (MedViT) architecture optimized for generalized medical image classification tasks, offering high performance and robustness.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "classification",
        "diagnosis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Omid-Nejati/MedViT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vision-transformer",
        "classification",
        "cnn-transformer-hybrid"
      ],
      "id": 54
    },
    {
      "name": "SAM-Med2D",
      "one_line_profile": "Segment Anything Model adapted for 2D medical images",
      "detailed_description": "A comprehensive adaptation of the Segment Anything Model (SAM) for 2D medical imaging, providing robust segmentation capabilities across various medical modalities.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "foundation_model"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/OpenGVLab/SAM-Med2D",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sam",
        "medical-segmentation",
        "foundation-model"
      ],
      "id": 55
    },
    {
      "name": "PLIP",
      "one_line_profile": "Pathology Language and Image Pre-Training foundation model",
      "detailed_description": "A large-scale vision-language foundation model for pathology, fine-tuned from CLIP to extract visual and language features from pathology images and text descriptions.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "pathology",
        "vision_language_modeling",
        "pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PathologyFoundation/plip",
      "help_website": [],
      "license": null,
      "tags": [
        "pathology",
        "clip",
        "foundation-model"
      ],
      "id": 56
    },
    {
      "name": "NexToU",
      "one_line_profile": "Topology-aware U-Net for medical segmentation",
      "detailed_description": "An efficient U-Net variant incorporating topology-aware loss functions or architectural changes to improve structural accuracy in medical image segmentation.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "topology_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PengchengShi1220/NexToU",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "u-net",
        "topology",
        "segmentation"
      ],
      "id": 57
    },
    {
      "name": "MONAI Generative Models",
      "one_line_profile": "Generative AI models for medical imaging within MONAI",
      "detailed_description": "A MONAI extension dedicated to training, evaluating, and deploying generative models (GANs, Diffusion Models) for medical imaging applications.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "image_generation",
        "synthesis",
        "augmentation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Project-MONAI/GenerativeModels",
      "help_website": [
        "https://monai.io/generative-models"
      ],
      "license": "Apache-2.0",
      "tags": [
        "generative-ai",
        "diffusion-models",
        "monai"
      ],
      "id": 58
    },
    {
      "name": "MONAI",
      "one_line_profile": "Comprehensive AI Toolkit for Healthcare Imaging",
      "detailed_description": "A PyTorch-based, open-source framework for deep learning in healthcare imaging, providing domain-optimized foundational capabilities for training and deploying medical AI models.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "image_analysis",
        "training_framework",
        "deployment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Project-MONAI/MONAI",
      "help_website": [
        "https://monai.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "deep-learning",
        "medical-imaging",
        "pytorch"
      ],
      "id": 59
    },
    {
      "name": "MONAI Label",
      "one_line_profile": "Intelligent open-source image labeling and learning tool for medical imaging",
      "detailed_description": "MONAI Label is a server-client system that facilitates the development of AI-assisted annotation applications for medical imaging. It allows researchers and clinicians to collaborate by continuously learning from user interactions and updating models in a loop.",
      "domains": [
        "H1",
        "H1-01"
      ],
      "subtask_category": [
        "annotation",
        "segmentation",
        "active_learning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Project-MONAI/MONAILabel",
      "help_website": [
        "https://monai.io/label.html"
      ],
      "license": "Apache-2.0",
      "tags": [
        "medical-imaging",
        "annotation",
        "active-learning",
        "segmentation"
      ],
      "id": 60
    },
    {
      "name": "SlicerMONAIViz",
      "one_line_profile": "3D Slicer extension for MONAI model visualization",
      "detailed_description": "A 3D Slicer extension that enables users to run and visualize MONAI models directly within the Slicer environment, bridging the gap between deep learning development and clinical visualization tools.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "visualization",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Project-MONAI/SlicerMONAIViz",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "3d-slicer",
        "visualization",
        "medical-imaging",
        "monai"
      ],
      "id": 61
    },
    {
      "name": "MONAI VISTA",
      "one_line_profile": "Versatile foundation model for medical image segmentation and annotation",
      "detailed_description": "VISTA (Versatile Imaging Segmentation and Annotation) is a foundation model designed to handle various medical imaging segmentation tasks. It serves as a pre-trained backbone for developing specialized segmentation tools.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "foundation_model"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Project-MONAI/VISTA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "foundation-model",
        "segmentation",
        "medical-imaging"
      ],
      "id": 62
    },
    {
      "name": "MONAI Deploy App SDK",
      "one_line_profile": "SDK for developing and packaging medical AI applications",
      "detailed_description": "A framework and set of tools designed to help developers design, develop, and verify AI-driven applications in the healthcare imaging domain, producing MONAI Application Packages (MAPs) for clinical deployment.",
      "domains": [
        "H1",
        "H1-05"
      ],
      "subtask_category": [
        "deployment",
        "application_packaging"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Project-MONAI/monai-deploy-app-sdk",
      "help_website": [
        "https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "deployment",
        "sdk",
        "medical-ai",
        "clinical-integration"
      ],
      "id": 63
    },
    {
      "name": "MONAI Deploy Informatics Gateway",
      "one_line_profile": "DICOM integration service for medical AI workflows",
      "detailed_description": "A service that facilitates integration with DICOM compliant systems, enabling ingestion of imaging data, triggering of workflows, and pushing outputs to PACS systems, acting as a bridge between clinical data and AI models.",
      "domains": [
        "H1",
        "H1-05"
      ],
      "subtask_category": [
        "data_ingestion",
        "dicom_handling",
        "workflow_integration"
      ],
      "application_level": "service",
      "primary_language": "C#",
      "repo_url": "https://github.com/Project-MONAI/monai-deploy-informatics-gateway",
      "help_website": [
        "https://docs.monai.io/projects/monai-deploy-informatics-gateway/en/latest/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dicom",
        "pacs",
        "integration",
        "gateway"
      ],
      "id": 64
    },
    {
      "name": "medigan",
      "one_line_profile": "Library of pretrained generative models for medical image synthesis",
      "detailed_description": "A Python library that provides an interface to search, retrieve, and use pre-trained generative models (GANs, Diffusion Models) for synthetic medical image generation and data augmentation.",
      "domains": [
        "H1",
        "H1-04"
      ],
      "subtask_category": [
        "image_synthesis",
        "data_augmentation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/RichardObi/medigan",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "generative-models",
        "gan",
        "synthetic-data",
        "medical-imaging"
      ],
      "id": 65
    },
    {
      "name": "MedCLIP",
      "one_line_profile": "Contrastive language-image pre-training foundation model for medical domains",
      "detailed_description": "A foundation model that aligns medical images and text using contrastive learning. It enables zero-shot classification and efficient transfer learning for various medical imaging tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "representation_learning",
        "zero_shot_classification",
        "foundation_model"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RyanWangZf/MedCLIP",
      "help_website": [],
      "license": null,
      "tags": [
        "clip",
        "contrastive-learning",
        "multimodal",
        "medical-imaging"
      ],
      "id": 66
    },
    {
      "name": "SupWMA",
      "one_line_profile": "Deep learning framework for superficial white matter analysis",
      "detailed_description": "A point-cloud-based deep learning framework for consistent tractography parcellation of superficial white matter across populations and dMRI acquisitions, provided as part of the SlicerDMRI ecosystem.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "tractography",
        "parcellation",
        "white_matter_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SlicerDMRI/SupWMA",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "dmri",
        "tractography",
        "deep-learning",
        "neuroimaging"
      ],
      "id": 67
    },
    {
      "name": "MedicalNet",
      "one_line_profile": "Library of 3D-ResNet pre-trained models for medical image analysis",
      "detailed_description": "A project providing a series of 3D-ResNet models pre-trained on large-scale medical datasets (Med3D), serving as a foundation for transfer learning in various 3D medical imaging tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "transfer_learning",
        "representation_learning",
        "foundation_model"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Tencent/MedicalNet",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "pretrained-models",
        "3d-resnet",
        "transfer-learning",
        "medical-imaging"
      ],
      "id": 68
    },
    {
      "name": "MedQA-ChatGLM",
      "one_line_profile": "Fine-tuning framework for ChatGLM on medical dialogue data",
      "detailed_description": "A comprehensive workflow for fine-tuning ChatGLM models using techniques like LoRA, P-Tuning V2, and Freeze on real-world medical dialogue datasets to create medical QA systems.",
      "domains": [
        "H1-03",
        "Medical NLP"
      ],
      "subtask_category": [
        "fine_tuning",
        "medical_qa"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/WangRongsheng/MedQA-ChatGLM",
      "help_website": [],
      "license": null,
      "tags": [
        "chatglm",
        "lora",
        "medical-qa",
        "fine-tuning"
      ],
      "id": 69
    },
    {
      "name": "Generative MONAI",
      "one_line_profile": "Generative AI extension for the MONAI medical imaging framework",
      "detailed_description": "The official implementation and extension of the MONAI framework for generative models in medical imaging, enabling the training and deployment of diffusion models and other generative architectures.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "image_generation",
        "synthesis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Warvito/generative_monai",
      "help_website": [],
      "license": null,
      "tags": [
        "monai",
        "generative-ai",
        "medical-imaging",
        "diffusion-models"
      ],
      "id": 70
    },
    {
      "name": "PIANO",
      "one_line_profile": "Pathology Image Analysis Orchestrator library",
      "detailed_description": "An easy-to-use PyTorch library for pathology image analysis, facilitating patch generation from whole slide images and feature extraction using pathology foundation models.",
      "domains": [
        "H1",
        "H1-03",
        "Pathology"
      ],
      "subtask_category": [
        "feature_extraction",
        "wsi_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/WonderLandxD/PIANO",
      "help_website": [],
      "license": null,
      "tags": [
        "pathology",
        "wsi",
        "foundation-models",
        "pytorch"
      ],
      "id": 71
    },
    {
      "name": "CFUN",
      "one_line_profile": "Efficient medical image segmentation combining Faster R-CNN and U-net",
      "detailed_description": "A deep learning model implementation that integrates object detection (Faster R-CNN) with segmentation (U-net) to improve efficiency and accuracy in medical image segmentation tasks.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "detection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Wuziyi616/CFUN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "segmentation",
        "u-net",
        "faster-rcnn",
        "medical-imaging"
      ],
      "id": 72
    },
    {
      "name": "SAM4MIS",
      "one_line_profile": "Benchmark and toolbox for Segment Anything Model in medical imaging",
      "detailed_description": "A comprehensive project summarizing and implementing the application of the Segment Anything Model (SAM) for medical image segmentation, serving as a benchmark and resource for adapting SAM to medical domains.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "foundation_model_adaptation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/YichiZhang98/SAM4MIS",
      "help_website": [],
      "license": null,
      "tags": [
        "sam",
        "segment-anything",
        "medical-segmentation",
        "benchmark"
      ],
      "id": 73
    },
    {
      "name": "Qwen3-Medical-SFT",
      "one_line_profile": "Fine-tuning pipeline for Qwen3 on medical datasets",
      "detailed_description": "A workflow for Supervised Fine-Tuning (SFT) of the Qwen3 language model specifically for medical R1 style chat applications, enabling the creation of specialized medical assistants.",
      "domains": [
        "H1-03",
        "Medical NLP"
      ],
      "subtask_category": [
        "fine_tuning",
        "medical_chat"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zeyi-Lin/Qwen3-Medical-SFT",
      "help_website": [],
      "license": null,
      "tags": [
        "qwen3",
        "sft",
        "medical-llm",
        "fine-tuning"
      ],
      "id": 74
    },
    {
      "name": "MedEmbed",
      "one_line_profile": "Collection of fine-tuned medical embedding models",
      "detailed_description": "A library and collection of embedding models that have been fine-tuned specifically for medical and clinical data, facilitating downstream tasks like retrieval and clustering in healthcare.",
      "domains": [
        "H1-03",
        "Medical NLP"
      ],
      "subtask_category": [
        "embedding_generation",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/abhinand5/MedEmbed",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "embeddings",
        "medical-nlp",
        "clinical-data",
        "fine-tuning"
      ],
      "id": 75
    },
    {
      "name": "MMedPO",
      "one_line_profile": "Alignment framework for Medical Vision-Language Models",
      "detailed_description": "Implementation of Clinical-Aware Multimodal Preference Optimization to align medical vision-language models with clinical preferences, improving their reliability and utility.",
      "domains": [
        "H1-03"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aiming-lab/MMedPO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vlm",
        "alignment",
        "preference-optimization",
        "medical-ai"
      ],
      "id": 76
    },
    {
      "name": "SaLIP",
      "one_line_profile": "Test-Time Adaptation for Zero-shot Medical Segmentation",
      "detailed_description": "A framework combining SAM and CLIP for zero-shot medical image segmentation via test-time adaptation, allowing segmentation without task-specific training data.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "zero_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aleemsidra/SaLIP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sam",
        "clip",
        "zero-shot",
        "segmentation"
      ],
      "id": 77
    },
    {
      "name": "MRISkullStripping",
      "one_line_profile": "UNet3D model for MRI skull stripping",
      "detailed_description": "A specialized tool implementing a UNet3D architecture for accurate skull stripping in MRI scans, a critical preprocessing step in neuroimaging workflows.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "preprocessing",
        "skull_stripping"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/amrzhd/MRISkullStripping",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mri",
        "skull-stripping",
        "unet3d",
        "preprocessing"
      ],
      "id": 78
    },
    {
      "name": "FastSAM3D",
      "one_line_profile": "Efficient Segment Anything Model for 3D medical images",
      "detailed_description": "An adaptation of the Segment Anything Model (SAM) optimized for 3D volumetric medical images, providing efficient and accurate segmentation capabilities.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "3d_imaging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/arcadelab/FastSAM3D",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sam",
        "3d-segmentation",
        "medical-imaging",
        "volumetric"
      ],
      "id": 79
    },
    {
      "name": "BAPLe",
      "one_line_profile": "Backdoor attack framework for medical foundation models",
      "detailed_description": "A tool for evaluating the robustness of medical foundation models by simulating backdoor attacks using prompt learning, aiding in the security analysis of medical AI systems.",
      "domains": [
        "H1-03"
      ],
      "subtask_category": [
        "robustness_analysis",
        "adversarial_testing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/asif-hanif/baple",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "security",
        "foundation-models",
        "backdoor-attack",
        "robustness"
      ],
      "id": 80
    },
    {
      "name": "Context_Aware_SSL",
      "one_line_profile": "Graph-based self-supervised learning for medical images",
      "detailed_description": "A framework for self-supervised representation learning on medical images that incorporates context via graph-based methods, useful for pretraining on unlabeled medical data.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "pretraining",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/batmanlab/Context_Aware_SSL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ssl",
        "self-supervised-learning",
        "medical-imaging",
        "graph-neural-networks"
      ],
      "id": 81
    },
    {
      "name": "DeepSeek-R1-Distill-Qwen-32B-Medical-Fine-tune",
      "one_line_profile": "Medical fine-tuning workflow for DeepSeek-R1/Qwen models",
      "detailed_description": "A complete workflow for fine-tuning the DeepSeek-R1-Distill-Qwen-32B model on a large-scale medical dataset (2M records) and deploying the resulting model.",
      "domains": [
        "H1-03",
        "Medical NLP"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_deployment"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/beita6969/DeepSeek-R1-Distill-Qwen-32B-Medical-Fine-tune",
      "help_website": [],
      "license": null,
      "tags": [
        "deepseek",
        "qwen",
        "fine-tuning",
        "medical-llm"
      ],
      "id": 82
    },
    {
      "name": "MedGround-R1",
      "one_line_profile": "Medical image grounding method using spatial-semantic rewarded group relative policy optimization",
      "detailed_description": "Official implementation of the MICCAI'25 paper 'MedGround-R1'. It advances medical image grounding by aligning text reports with specific image regions using a reinforcement learning-based approach.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "medical_image_grounding",
        "vision_language_alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bio-mlhui/MedGround-R1",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-grounding",
        "reinforcement-learning",
        "miccai"
      ],
      "id": 83
    },
    {
      "name": "Counterfactual Contrastive Learning",
      "one_line_profile": "Robust representation learning for medical image classification via counterfactual synthesis",
      "detailed_description": "Code for Medical Image Analysis and MICCAI papers focusing on improving robustness of image classification models using counterfactual contrastive learning and causal image synthesis.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "classification",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/biomedia-mira/counterfactual-contrastive",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "contrastive-learning",
        "causal-inference",
        "robustness"
      ],
      "id": 84
    },
    {
      "name": "MedSAM",
      "one_line_profile": "Foundation model for universal medical image segmentation",
      "detailed_description": "A fine-tuned version of the Segment Anything Model (SAM) specifically adapted for medical images. It enables promptable segmentation across various medical imaging modalities.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "foundation_model_adaptation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/bowang-lab/MedSAM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "segment-anything",
        "medical-segmentation",
        "foundation-model"
      ],
      "id": 85
    },
    {
      "name": "MedSAM2",
      "one_line_profile": "Extension of MedSAM for 3D medical images and videos",
      "detailed_description": "Builds upon MedSAM to support volumetric (3D) medical images and video data, providing a unified segmentation solution for dynamic and volumetric medical data.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "3d_image_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bowang-lab/MedSAM2",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "3d-segmentation",
        "video-segmentation",
        "sam"
      ],
      "id": 86
    },
    {
      "name": "MedSAMSlicer",
      "one_line_profile": "3D Slicer plugin for MedSAM integration",
      "detailed_description": "A plugin for the popular medical image visualization platform 3D Slicer, allowing users to apply MedSAM segmentation directly within the Slicer GUI.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "visualization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bowang-lab/MedSAMSlicer",
      "help_website": [],
      "license": null,
      "tags": [
        "3d-slicer",
        "plugin",
        "interactive-segmentation"
      ],
      "id": 87
    },
    {
      "name": "Synthetic Sleep EEG Generation",
      "one_line_profile": "Latent Diffusion Models for generating synthetic sleep EEG signals",
      "detailed_description": "Implementation of Latent Diffusion Models to generate high-fidelity synthetic sleep EEG signals, useful for data augmentation and privacy-preserving research.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "data_generation",
        "signal_synthesis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bruAristimunha/Synthetic-Sleep-EEG-Signal-Generation-using-Latent-Diffusion-Models",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "eeg",
        "diffusion-models",
        "synthetic-data"
      ],
      "id": 88
    },
    {
      "name": "RadFM",
      "one_line_profile": "Generalist foundation model for radiology leveraging 2D and 3D data",
      "detailed_description": "A multimodal foundation model capable of handling both 2D and 3D radiology data, designed for tasks like report generation and visual question answering in radiology.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "foundation_model_training",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chaoyi-wu/RadFM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "radiology",
        "multimodal",
        "transformer"
      ],
      "id": 89
    },
    {
      "name": "ViT-AE++",
      "one_line_profile": "Improved Vision Transformer Autoencoder for medical image representation",
      "detailed_description": "Code for the ViT-AE++ paper, proposing enhancements to Vision Transformer Autoencoders for self-supervised learning of medical image representations.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "representation_learning",
        "self_supervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chinmay5/vit_ae_plus_plus",
      "help_website": [],
      "license": "CC0-1.0",
      "tags": [
        "autoencoder",
        "vision-transformer",
        "self-supervised"
      ],
      "id": 90
    },
    {
      "name": "MediCLIP",
      "one_line_profile": "Adapting CLIP for few-shot medical image anomaly detection",
      "detailed_description": "Implementation of MediCLIP, a method adapting the CLIP foundation model for the specific task of anomaly detection in medical images with limited data.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "anomaly_detection",
        "few_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cnulab/MediCLIP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "clip",
        "anomaly-detection",
        "few-shot"
      ],
      "id": 91
    },
    {
      "name": "Medico-SAM",
      "one_line_profile": "Adaptation of Segment Anything Model for medical imaging",
      "detailed_description": "A specialized implementation of the Segment Anything Model (SAM) tailored for medical imaging tasks, providing tools for segmentation.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "foundation_model_adaptation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/computational-cell-analytics/medico-sam",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sam",
        "medical-imaging",
        "segmentation"
      ],
      "id": 92
    },
    {
      "name": "PEFT-SAM",
      "one_line_profile": "Parameter Efficient Fine-Tuning for Segment Anything Model",
      "detailed_description": "Provides methods for Parameter Efficient Fine-Tuning (PEFT) of the Segment Anything Model, enabling efficient adaptation to medical datasets.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "fine_tuning",
        "segmentation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/computational-cell-analytics/peft-sam",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "lora",
        "sam"
      ],
      "id": 93
    },
    {
      "name": "ASCENT",
      "one_line_profile": "Cardiac ultrasound segmentation and Color-Doppler dealiasing toolbox",
      "detailed_description": "A toolbox for processing cardiac ultrasound data, specifically focusing on segmentation and dealiasing of Color-Doppler images.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "image_restoration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/creatis-myriad/ASCENT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ultrasound",
        "cardiac",
        "doppler"
      ],
      "id": 94
    },
    {
      "name": "SelfMedMAE",
      "one_line_profile": "Masked Autoencoders for medical image classification and segmentation",
      "detailed_description": "Code for the ISBI 2023 paper implementing self-supervised pre-training using Masked Autoencoders (MAE) for medical imaging tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "pretraining",
        "segmentation",
        "classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cvlab-stonybrook/SelfMedMAE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mae",
        "self-supervised",
        "transformer"
      ],
      "id": 95
    },
    {
      "name": "AAS-DCL_FSS",
      "one_line_profile": "Dual Contrastive Learning for Few-shot Medical Image Segmentation",
      "detailed_description": "Implementation of a dual contrastive learning framework designed for few-shot segmentation of medical images.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "few_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cvszusparkle/AAS-DCL_FSS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "contrastive-learning",
        "few-shot",
        "segmentation"
      ],
      "id": 96
    },
    {
      "name": "C2FViT",
      "one_line_profile": "Affine Medical Image Registration with Coarse-to-Fine Vision Transformer",
      "detailed_description": "Official PyTorch implementation of C2FViT (CVPR 2022), a method for affine medical image registration using a coarse-to-fine Vision Transformer approach.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "registration",
        "image_alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cwmok/C2FViT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "registration",
        "vision-transformer",
        "affine"
      ],
      "id": 97
    },
    {
      "name": "MM-DINOv2",
      "one_line_profile": "Adapting Foundation Models for Multi-Modal Medical Image Analysis",
      "detailed_description": "Code for the MICCAI 2025 paper MM-DINOv2, which adapts the DINOv2 foundation model for multi-modal medical image analysis tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "multimodal_analysis",
        "foundation_model_adaptation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/daniel-scholz/mm-dinov2",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "dinov2",
        "multimodal",
        "miccai"
      ],
      "id": 98
    },
    {
      "name": "SALMON",
      "one_line_profile": "MONAI-based deep learning algorithm for 3D medical image segmentation",
      "detailed_description": "A segmentation software developed by QIMP team-Vienna, built on the MONAI toolbox, supporting single and multi-label segmentation of 3D medical images.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "workflow_automation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/davidiommi/Pytorch--3D-Medical-Images-Segmentation--SALMON",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "monai",
        "3d-segmentation",
        "pytorch"
      ],
      "id": 99
    },
    {
      "name": "Positional Contrastive Learning",
      "one_line_profile": "Positional Contrastive Learning for Volumetric Medical Image Segmentation",
      "detailed_description": "Implementation of a positional contrastive learning method to improve volumetric medical image segmentation performance.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "contrastive_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dewenzeng/positional_cl",
      "help_website": [],
      "license": null,
      "tags": [
        "contrastive-learning",
        "volumetric-segmentation"
      ],
      "id": 100
    },
    {
      "name": "GPT2-BERT Medical QA",
      "one_line_profile": "Medical domain-focused GPT-2 fine-tuning and optimization",
      "detailed_description": "Research repository for fine-tuning and optimizing GPT-2 models specifically for medical question-answering tasks, including lightweighting techniques.",
      "domains": [
        "H1-03"
      ],
      "subtask_category": [
        "question_answering",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dsdanielpark/gpt2-bert-medical-qa-chat",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpt-2",
        "medical-qa",
        "fine-tuning"
      ],
      "id": 101
    },
    {
      "name": "3DUnetCNN",
      "one_line_profile": "PyTorch implementation of 3D U-Net for medical image segmentation",
      "detailed_description": "A widely used PyTorch implementation of the 3D U-Net architecture, designed specifically for volumetric medical image segmentation tasks.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "deep_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ellisdg/3DUnetCNN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "3d-unet",
        "pytorch",
        "segmentation"
      ],
      "id": 102
    },
    {
      "name": "CLIP Image Search",
      "one_line_profile": "Fine-tuning CLIP for medical image search",
      "detailed_description": "Tools for fine-tuning OpenAI's CLIP model on medical datasets to enable effective semantic image search within medical archives.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "image_retrieval",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/elsevierlabs-os/clip-image-search",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "clip",
        "image-search",
        "elsevier"
      ],
      "id": 103
    },
    {
      "name": "SEViT",
      "one_line_profile": "Self-Ensembling Vision Transformer for robust medical image classification",
      "detailed_description": "Source code for the MICCAI 2022 paper presenting SEViT, a method improving the robustness of medical image classification using self-ensembling Vision Transformers.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "classification",
        "robustness"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/faresmalik/SEViT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vision-transformer",
        "ensemble-learning",
        "miccai"
      ],
      "id": 104
    },
    {
      "name": "DiRA",
      "one_line_profile": "Discriminative, Restorative, and Adversarial Learning for medical image analysis",
      "detailed_description": "Official PyTorch implementation of DiRA (CVPR 2022), a self-supervised learning framework for medical image analysis combining discriminative, restorative, and adversarial objectives.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "self_supervised_learning",
        "pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/fhaghighi/DiRA",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "self-supervised",
        "cvpr",
        "medical-imaging"
      ],
      "id": 105
    },
    {
      "name": "MLIP",
      "one_line_profile": "Enhancing medical visual representation with divergence encoder and knowledge-guided contrastive learning",
      "detailed_description": "Code for the CVPR'24 paper MLIP, focusing on improving medical visual representations using a divergence encoder and knowledge-guided contrastive learning.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "representation_learning",
        "contrastive_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gentlefress/MLIP",
      "help_website": [],
      "license": null,
      "tags": [
        "cvpr",
        "medical-representation",
        "contrastive-learning"
      ],
      "id": 106
    },
    {
      "name": "CUFIT",
      "one_line_profile": "Curriculum Fine-tuning of Vision Foundation Model for Medical Image Classification",
      "detailed_description": "Official implementation of the NeurIPS 2024 paper CUFIT, proposing a curriculum fine-tuning strategy for vision foundation models to handle label noise in medical image classification.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "fine_tuning",
        "classification",
        "noise_handling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gist-ailab/CUFIT",
      "help_website": [],
      "license": null,
      "tags": [
        "neurips",
        "fine-tuning",
        "curriculum-learning"
      ],
      "id": 107
    },
    {
      "name": "RECITAL 2020 BERT",
      "one_line_profile": "Strategies for pre-training BERT in the medical domain",
      "detailed_description": "Code for the RECITAL 2020 paper investigating strategies for pre-training or fine-tuning BERT models specifically for the medical domain.",
      "domains": [
        "H1-03"
      ],
      "subtask_category": [
        "pretraining",
        "fine_tuning",
        "nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/helboukkouri/recital_2020",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bert",
        "medical-nlp",
        "pretraining"
      ],
      "id": 108
    },
    {
      "name": "MedFicientSAM",
      "one_line_profile": "Efficient implementation of Segment Anything Model for medical images",
      "detailed_description": "A specialized implementation of the Segment Anything Model (SAM) optimized for efficiency in medical image segmentation tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "model_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hieplpvip/medficientsam",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sam",
        "medical-segmentation",
        "efficient-model"
      ],
      "id": 109
    },
    {
      "name": "SAMed",
      "one_line_profile": "Customized Segment Anything Model for medical image segmentation",
      "detailed_description": "A customized version of the Segment Anything Model (SAM) specifically fine-tuned and adapted for medical image segmentation, applying low-rank adaptation (LoRA) strategies.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hitachinsk/SAMed",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sam",
        "medical-segmentation",
        "lora",
        "fine-tuning"
      ],
      "id": 110
    },
    {
      "name": "U-Net-Fixed-Point-Quantization",
      "one_line_profile": "Fixed-point quantization implementation for U-Net in medical segmentation",
      "detailed_description": "A tool providing code for fixed-point quantization of U-Net architectures, aiming to optimize medical image segmentation models for deployment.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "model_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hossein1387/U-Net-Fixed-Point-Quantization-for-Medical-Image-Segmentation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "quantization",
        "u-net",
        "optimization"
      ],
      "id": 111
    },
    {
      "name": "GFDA-disentangled",
      "one_line_profile": "Semi-supervised domain adaptive medical image segmentation tool",
      "detailed_description": "Implementation of a consistency regularized disentangled contrastive learning framework for semi-supervised domain adaptive medical image segmentation.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "domain_adaptation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/hritam-98/GFDA-disentangled",
      "help_website": [],
      "license": null,
      "tags": [
        "domain-adaptation",
        "contrastive-learning",
        "semi-supervised"
      ],
      "id": 112
    },
    {
      "name": "3D U^2-Net",
      "one_line_profile": "3D Universal U-Net for multi-domain medical image segmentation",
      "detailed_description": "A PyTorch implementation of 3D U^2-Net, designed for multi-domain medical image segmentation tasks.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/huangmozhilv/u2net_torch",
      "help_website": [],
      "license": null,
      "tags": [
        "3d-segmentation",
        "u-net",
        "deep-learning"
      ],
      "id": 113
    },
    {
      "name": "viBioGPT",
      "one_line_profile": "Vietnamese medical LLM for question answering",
      "detailed_description": "A Large Language Model fine-tuned for medical and healthcare question answering specifically in the Vietnamese language.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "question_answering",
        "text_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hungnlp/viBioGPT",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "medical-qa",
        "vietnamese",
        "fine-tuning"
      ],
      "id": 114
    },
    {
      "name": "Doctor-SAM",
      "one_line_profile": "Fine-tuned Segment Anything Model for medical imaging",
      "detailed_description": "A fine-tuned adaptation of the Segment Anything Model (SAM) tailored for medical image segmentation tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/huoxiangzuo/Doctor-SAM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sam",
        "medical-segmentation",
        "fine-tuning"
      ],
      "id": 115
    },
    {
      "name": "Falcon-7B-Medical-QLoRA",
      "one_line_profile": "Medical fine-tuning of Falcon-7B using QLoRA",
      "detailed_description": "A repository providing the workflow and code for fine-tuning the Falcon-7B Large Language Model on mental health conversational datasets using QLoRA.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "fine_tuning",
        "text_generation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/iamarunbrahma/finetuned-qlora-falcon7b-medical",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "qlora",
        "mental-health",
        "fine-tuning"
      ],
      "id": 116
    },
    {
      "name": "ResViT",
      "one_line_profile": "Residual Vision Transformers for medical image synthesis",
      "detailed_description": "Implementation of ResViT, a generative adversarial network using vision transformers for multi-modal medical image synthesis.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "image_synthesis",
        "generative_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/icon-lab/ResViT",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "gan",
        "vision-transformer",
        "image-synthesis"
      ],
      "id": 117
    },
    {
      "name": "PeFoMed",
      "one_line_profile": "Parameter efficient fine-tuning for medical VQA",
      "detailed_description": "A framework for parameter-efficient fine-tuning (PEFT) on multi-modal large language models specifically for medical visual question answering (VQA).",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "visual_question_answering",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jinlHe/PeFoMed",
      "help_website": [],
      "license": null,
      "tags": [
        "peft",
        "vqa",
        "multimodal",
        "llm"
      ],
      "id": 118
    },
    {
      "name": "Self-paced-Contrastive-Learning",
      "one_line_profile": "Self-paced contrastive learning for semi-supervised segmentation",
      "detailed_description": "Implementation of a self-paced contrastive learning method for semi-supervised medical image segmentation.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "contrastive_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jizongFox/Self-paced-Contrastive-Learning",
      "help_website": [],
      "license": null,
      "tags": [
        "semi-supervised",
        "contrastive-learning",
        "segmentation"
      ],
      "id": 119
    },
    {
      "name": "MedShapeNet-Foundation-Model",
      "one_line_profile": "Foundation model for medical point cloud completion",
      "detailed_description": "A learning-based multi-modal foundation model designed for completing medical point cloud data.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "point_cloud_completion",
        "3d_reconstruction"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/jrHoss/MedShapeNet-Foundation-Model",
      "help_website": [],
      "license": null,
      "tags": [
        "point-cloud",
        "foundation-model",
        "shape-completion"
      ],
      "id": 120
    },
    {
      "name": "ViT-V-Net",
      "one_line_profile": "Vision Transformer for 3D medical image registration",
      "detailed_description": "A PyTorch implementation of ViT-V-Net, utilizing Vision Transformers for 3D medical image registration tasks.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "registration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/junyuchen245/ViT-V-Net_for_3D_Image_Registration_Pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "registration",
        "vision-transformer",
        "3d-imaging"
      ],
      "id": 121
    },
    {
      "name": "Midnight",
      "one_line_profile": "Pathology foundation models trained on WSI",
      "detailed_description": "A set of pathology foundation models trained on Whole Slide Images (WSI), designed to work with fewer training samples.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "pathology_analysis",
        "feature_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kaiko-ai/Midnight",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pathology",
        "foundation-model",
        "wsi"
      ],
      "id": 122
    },
    {
      "name": "Large-Scale Pathology FMs",
      "one_line_profile": "Training framework for large-scale pathology foundation models",
      "detailed_description": "Implementation code for training large-scale pathology foundation models, scaling from TCGA to hospital-scale datasets.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "model_training",
        "pathology_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/kaiko-ai/towards_large_pathology_fms",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "pathology",
        "foundation-model",
        "training-framework"
      ],
      "id": 123
    },
    {
      "name": "SSL-MedSeg",
      "one_line_profile": "Self-supervised pretraining for 2D medical image segmentation",
      "detailed_description": "A framework for self-supervised pretraining specifically designed to improve 2D medical image segmentation performance.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kaland313/SSL-MedSeg",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "self-supervised",
        "pretraining",
        "segmentation"
      ],
      "id": 124
    },
    {
      "name": "Domain Specific CL",
      "one_line_profile": "Contrastive learning for medical image segmentation with limited annotations",
      "detailed_description": "Implementation of global and local feature contrastive learning for medical image segmentation, optimized for scenarios with limited annotations.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "contrastive_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/krishnabits001/domain_specific_cl",
      "help_website": [],
      "license": null,
      "tags": [
        "contrastive-learning",
        "segmentation",
        "limited-annotation"
      ],
      "id": 125
    },
    {
      "name": "Medical MAE",
      "one_line_profile": "Masked Autoencoders for thorax disease classification",
      "detailed_description": "Implementation of Masked Autoencoders (MAE) adapted for multi-label thorax disease classification from medical images.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "classification",
        "pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/lambert-x/medical_mae",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mae",
        "classification",
        "thorax-disease"
      ],
      "id": 126
    },
    {
      "name": "SlicerMONAIAuto3DSeg",
      "one_line_profile": "3D Slicer extension for MONAI Auto3DSeg",
      "detailed_description": "An extension for the 3D Slicer platform that integrates MONAI's Auto3DSeg models, enabling automated 3D segmentation workflows within the Slicer GUI.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "workflow_automation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/lassoan/SlicerMONAIAuto3DSeg",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "3d-slicer",
        "monai",
        "segmentation",
        "plugin"
      ],
      "id": 127
    },
    {
      "name": "UNet_scAG",
      "one_line_profile": "U-Net with Spatial-Channel Attention Gate for medical segmentation",
      "detailed_description": "Implementation of an enhanced U-Net architecture incorporating Spatial-Channel Attention Gates for abnormal tissue segmentation in medical imaging.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lbktrinh/UNet_scAG",
      "help_website": [],
      "license": null,
      "tags": [
        "u-net",
        "attention-mechanism",
        "segmentation"
      ],
      "id": 128
    },
    {
      "name": "DINOv2-MedSeg",
      "one_line_profile": "DINOv2-based self-supervised learning for few-shot medical segmentation",
      "detailed_description": "A tool leveraging DINOv2 for self-supervised learning to perform few-shot medical image segmentation.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "few_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/levayz/DINOv2-based-Self-Supervised-Learning",
      "help_website": [],
      "license": null,
      "tags": [
        "dinov2",
        "self-supervised",
        "few-shot",
        "segmentation"
      ],
      "id": 129
    },
    {
      "name": "CONCH",
      "one_line_profile": "Vision-Language Foundation Model for Computational Pathology",
      "detailed_description": "A foundation model for pathology that leverages vision-language pretraining to connect histopathology images with text descriptions, enabling tasks like zero-shot classification and retrieval.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "foundation_model",
        "pathology_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mahmoodlab/CONCH",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "pathology",
        "vision-language",
        "foundation-model"
      ],
      "id": 130
    },
    {
      "name": "Feather",
      "one_line_profile": "Lightweight supervised slide foundation models for pathology",
      "detailed_description": "A framework for creating lightweight, supervised foundation models for whole slide images (WSI) in pathology, designed for efficiency and performance in slide-level tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "foundation_model",
        "slide_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mahmoodlab/MIL-Lab",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "pathology",
        "wsi",
        "foundation-model"
      ],
      "id": 131
    },
    {
      "name": "Patho-Bench",
      "one_line_profile": "Standardized benchmark for computational pathology foundation models",
      "detailed_description": "A comprehensive benchmark suite designed to evaluate the performance of foundation models in computational pathology across various tasks and datasets.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "benchmarking",
        "model_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/mahmoodlab/Patho-Bench",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "benchmark",
        "pathology",
        "evaluation"
      ],
      "id": 132
    },
    {
      "name": "TITAN",
      "one_line_profile": "Multimodal Whole Slide Foundation Model for Pathology",
      "detailed_description": "A multimodal foundation model specifically designed for whole slide images in pathology, integrating diverse data modalities to enhance diagnostic and analytical capabilities.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "foundation_model",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mahmoodlab/TITAN",
      "help_website": [],
      "license": null,
      "tags": [
        "pathology",
        "wsi",
        "multimodal"
      ],
      "id": 133
    },
    {
      "name": "UNI",
      "one_line_profile": "General-purpose Pathology Foundation Model",
      "detailed_description": "A large-scale foundation model for computational pathology, pretrained on massive datasets to provide robust feature representations for downstream pathology tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "foundation_model",
        "feature_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mahmoodlab/UNI",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "pathology",
        "foundation-model",
        "deep-learning"
      ],
      "id": 134
    },
    {
      "name": "MadCLIP",
      "one_line_profile": "Few-shot Medical Anomaly Detection with CLIP",
      "detailed_description": "A tool leveraging CLIP-based models for few-shot anomaly detection in medical imaging, allowing for detection of abnormalities with minimal labeled examples.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "anomaly_detection",
        "few_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mahshid1998/MadCLIP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "clip",
        "anomaly-detection",
        "medical-imaging"
      ],
      "id": 135
    },
    {
      "name": "ModalTune",
      "one_line_profile": "Fine-Tuning Slide-Level Foundation Models with Multi-Modal Information",
      "detailed_description": "A framework for fine-tuning slide-level foundation models in digital pathology by incorporating multi-modal information to improve performance on multi-task learning.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "fine_tuning",
        "pathology_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/martellab-sri/ModalTune",
      "help_website": [],
      "license": null,
      "tags": [
        "fine-tuning",
        "pathology",
        "multimodal"
      ],
      "id": 136
    },
    {
      "name": "V-Net (PyTorch)",
      "one_line_profile": "Volumetric Medical Image Segmentation Network",
      "detailed_description": "A PyTorch implementation of V-Net, a fully convolutional neural network designed for volumetric medical image segmentation.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "volumetric_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mattmacy/vnet.pytorch",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "v-net",
        "segmentation",
        "3d-imaging"
      ],
      "id": 137
    },
    {
      "name": "Foundation-based-reg",
      "one_line_profile": "Evaluation of Vision Foundation Models for Medical Image Registration",
      "detailed_description": "A toolkit for evaluating the capability of general vision foundation models to perform medical image registration tasks out-of-the-box.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "image_registration",
        "model_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mazurowski-lab/Foundation-based-reg",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "registration",
        "foundation-model",
        "evaluation"
      ],
      "id": 138
    },
    {
      "name": "finetune-SAM",
      "one_line_profile": "Fine-tuning Segment Anything Model (SAM) for Medical Images",
      "detailed_description": "A repository providing code and methods to fine-tune the Segment Anything Model (SAM) specifically for customized medical image segmentation tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "fine_tuning",
        "segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mazurowski-lab/finetune-SAM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sam",
        "fine-tuning",
        "segmentation"
      ],
      "id": 139
    },
    {
      "name": "SAM-Medical-Evaluation",
      "one_line_profile": "Experimental Study of SAM for Medical Image Analysis",
      "detailed_description": "Codebase for evaluating the performance of the Segment Anything Model (SAM) across various medical image analysis tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "model_evaluation",
        "segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mazurowski-lab/segment-anything-medical-evaluation",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sam",
        "evaluation",
        "medical-imaging"
      ],
      "id": 140
    },
    {
      "name": "UniMed-CLIP",
      "one_line_profile": "Unified Image-Text Pretraining for Diverse Medical Modalities",
      "detailed_description": "A unified image-text pretraining framework designed to handle diverse medical imaging modalities, enabling cross-modal retrieval and classification.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "pretraining",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mbzuai-oryx/UniMed-CLIP",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "clip",
        "multimodal",
        "pretraining"
      ],
      "id": 141
    },
    {
      "name": "BiomedCLIP Data Pipeline",
      "one_line_profile": "Data processing pipeline for BiomedCLIP",
      "detailed_description": "The official data pipeline used for processing and preparing biomedical data for training and using BiomedCLIP models.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "data_processing",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/microsoft/BiomedCLIP_data_pipeline",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "biomedclip",
        "data-pipeline",
        "preprocessing"
      ],
      "id": 142
    },
    {
      "name": "vox2vec",
      "one_line_profile": "Self-supervised Contrastive Learning for Voxel-level Representations",
      "detailed_description": "A framework for self-supervised contrastive learning that generates voxel-level representations in medical images, useful for downstream segmentation and analysis tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "self_supervised_learning",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mishgon/vox2vec",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ssl",
        "contrastive-learning",
        "voxel-representation"
      ],
      "id": 143
    },
    {
      "name": "Medical Hallucination Evaluation",
      "one_line_profile": "Evaluation of Hallucinations in Medical Foundation Models",
      "detailed_description": "A repository dedicated to analyzing and evaluating the phenomenon of hallucination in foundation models applied to healthcare and medical contexts.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "model_evaluation",
        "safety_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mitmedialab/medical_hallucination",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hallucination",
        "evaluation",
        "foundation-model"
      ],
      "id": 144
    },
    {
      "name": "R2U-Net",
      "one_line_profile": "Recurrent Residual U-Net for Medical Image Segmentation",
      "detailed_description": "A PyTorch implementation of R2U-Net, combining recurrent neural networks and residual connections within a U-Net architecture for medical image segmentation.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "model_implementation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/navamikairanda/R2U-Net",
      "help_website": [],
      "license": null,
      "tags": [
        "u-net",
        "segmentation",
        "pytorch"
      ],
      "id": 145
    },
    {
      "name": "MIU-VL",
      "one_line_profile": "Medical Image Understanding with Vision Language Models",
      "detailed_description": "A comprehensive study and codebase for applying pretrained vision-language models to medical image understanding tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "image_understanding",
        "vision_language"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/openmedlab/MIU-VL",
      "help_website": [],
      "license": null,
      "tags": [
        "vlm",
        "medical-imaging",
        "pretraining"
      ],
      "id": 146
    },
    {
      "name": "MedLSAM",
      "one_line_profile": "Localize and Segment Anything Model for 3D Medical Images",
      "detailed_description": "A model designed to localize and segment anatomical structures in 3D medical images, extending the Segment Anything Model (SAM) capabilities to volumetric data.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "localization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/openmedlab/MedLSAM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sam",
        "3d-segmentation",
        "localization"
      ],
      "id": 147
    },
    {
      "name": "SAM-Med2D",
      "one_line_profile": "Medical Image Segmentation using SAM for 2D Images",
      "detailed_description": "A framework adapting the Segment Anything Model (SAM) for 2D medical image segmentation, bridging the domain gap between natural and medical images.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "domain_adaptation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/openmedlab/SAM-Med2D",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sam",
        "2d-segmentation",
        "medical-imaging"
      ],
      "id": 148
    },
    {
      "name": "SAM-Med3D",
      "one_line_profile": "Efficient 3D Model for Promptable Volumetric Segmentation",
      "detailed_description": "An efficient 3D implementation of the Segment Anything Model (SAM) tailored for promptable volumetric medical image segmentation.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "volumetric_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/openmedlab/SAM-Med3D",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sam",
        "3d-segmentation",
        "promptable-segmentation"
      ],
      "id": 149
    },
    {
      "name": "STU-Net",
      "one_line_profile": "Large-scale Pre-trained Medical Image Segmentation Model",
      "detailed_description": "A large-scale pre-trained model (1.4B parameters) for medical image segmentation, trained on a massive dataset of annotated medical images.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/openmedlab/STU-Net",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "segmentation",
        "large-model",
        "pretraining"
      ],
      "id": 150
    },
    {
      "name": "PLISM Benchmark",
      "one_line_profile": "Robustness Benchmark for Pathology Foundation Models",
      "detailed_description": "A benchmark suite for evaluating the robustness of pathology foundation models against various perturbations and domain shifts.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "benchmarking",
        "robustness_analysis"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/owkin/plism-benchmark",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "pathology",
        "robustness"
      ],
      "id": 151
    },
    {
      "name": "Prov-GigaPath",
      "one_line_profile": "Whole-slide foundation model for digital pathology pre-trained on real-world data",
      "detailed_description": "A foundation model designed for digital pathology, utilizing a whole-slide pre-training approach on large-scale real-world data to enable downstream pathology tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "pathology_analysis",
        "foundation_model_pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/prov-gigapath/prov-gigapath",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "digital-pathology",
        "foundation-model",
        "whole-slide-imaging"
      ],
      "id": 152
    },
    {
      "name": "Curia",
      "one_line_profile": "Foundation model designed for radiology applications",
      "detailed_description": "A foundation model specifically developed for radiology, aiming to enhance various radiological image analysis tasks through large-scale pre-training.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "radiology_analysis",
        "foundation_model"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/raidium-med/curia",
      "help_website": [],
      "license": null,
      "tags": [
        "radiology",
        "foundation-model",
        "medical-imaging"
      ],
      "id": 153
    },
    {
      "name": "MedSegmentAnything_SAM_LungCT",
      "one_line_profile": "Fine-tuning implementation of SAM for lung CT segmentation",
      "detailed_description": "A specialized implementation for fine-tuning the Segment Anything Model (SAM) using bounding box prompts specifically for segmenting lungs in CT scans.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/rekalantar/MedSegmentAnything_SAM_LungCT",
      "help_website": [],
      "license": null,
      "tags": [
        "sam",
        "lung-ct",
        "segmentation",
        "fine-tuning"
      ],
      "id": 154
    },
    {
      "name": "BCDU-Net",
      "one_line_profile": "Bi-directional ConvLSTM U-Net for medical image segmentation",
      "detailed_description": "A deep learning architecture combining U-Net with Bi-directional ConvLSTM to capture temporal or volumetric dependencies for improved medical image segmentation.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "model_architecture"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/rezazad68/BCDU-Net",
      "help_website": [],
      "license": null,
      "tags": [
        "u-net",
        "segmentation",
        "medical-imaging",
        "lstm"
      ],
      "id": 155
    },
    {
      "name": "FRCU-Net",
      "one_line_profile": "Frequency Re-calibration U-Net for medical image segmentation",
      "detailed_description": "A U-Net variant that incorporates frequency re-calibration mechanisms to enhance feature representation for medical image segmentation tasks.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "model_architecture"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/rezazad68/FRCU-Net",
      "help_website": [],
      "license": null,
      "tags": [
        "u-net",
        "segmentation",
        "frequency-calibration"
      ],
      "id": 156
    },
    {
      "name": "MedDINOv3",
      "one_line_profile": "Adaptation of vision foundation models for medical image segmentation",
      "detailed_description": "A framework and methodology for adapting general vision foundation models, specifically DINOv3, to the domain of medical image segmentation.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "domain_adaptation",
        "foundation_model"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ricklisz/MedDINOv3",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dinov3",
        "segmentation",
        "foundation-model"
      ],
      "id": 157
    },
    {
      "name": "RETFound",
      "one_line_profile": "Vision foundation models for medical AI including retinal imaging",
      "detailed_description": "A repository hosting vision foundation models for medical AI, featuring RETFound for retinal images as well as adaptations of DINOv2 and DINOv3 for medical contexts.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "foundation_model",
        "retinal_imaging",
        "diagnosis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/rmaphoh/RETFound",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "retfound",
        "foundation-model",
        "ophthalmology"
      ],
      "id": 158
    },
    {
      "name": "SSL-FL",
      "one_line_profile": "Self-supervised federated learning framework for medical imaging",
      "detailed_description": "A framework implementing self-supervised learning within a federated learning setting specifically tailored for medical imaging analysis.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "federated_learning",
        "self_supervised_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rui-yan/SSL-FL",
      "help_website": [],
      "license": null,
      "tags": [
        "federated-learning",
        "self-supervised-learning",
        "medical-imaging"
      ],
      "id": 159
    },
    {
      "name": "LLM-From-Scratch (Medical)",
      "one_line_profile": "Medical Language Model fine-tuning and alignment pipeline",
      "detailed_description": "A pipeline for creating medical language models through pretraining, instruction tuning, and Direct Preference Optimization (DPO), focusing on enhancing clinical reasoning and instruction following.",
      "domains": [
        "H1-03"
      ],
      "subtask_category": [
        "fine_tuning",
        "text_generation",
        "alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/samadon1/LLM-From-Scratch",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "fine-tuning",
        "dpo",
        "medical-nlp"
      ],
      "id": 160
    },
    {
      "name": "Medical-Domain-Adaptive-Neural-Networks",
      "one_line_profile": "Adaptive adversarial networks for domain-shifted medical image analysis",
      "detailed_description": "A library implementing adaptive adversarial neural networks designed to handle lossy and domain-shifted data in medical image analysis.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "domain_adaptation",
        "image_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shafieelab/Medical-Domain-Adaptive-Neural-Networks",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "domain-adaptation",
        "adversarial-networks",
        "medical-imaging"
      ],
      "id": 161
    },
    {
      "name": "Q-Net",
      "one_line_profile": "Meta-learning method for few-shot medical image segmentation",
      "detailed_description": "Implementation of Q-Net, a meta-learning approach designed for segmenting medical images with limited labeled examples (few-shot learning).",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "few_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/shenqq377/Q-Net",
      "help_website": [],
      "license": null,
      "tags": [
        "meta-learning",
        "few-shot",
        "segmentation"
      ],
      "id": 162
    },
    {
      "name": "MDViT",
      "one_line_profile": "Multi-domain Vision Transformer for small medical image datasets",
      "detailed_description": "A Vision Transformer architecture optimized for multi-domain segmentation tasks on small medical image datasets, incorporating domain-adaptive mechanisms.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "model_architecture"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/siyi-wind/MDViT",
      "help_website": [],
      "license": null,
      "tags": [
        "vision-transformer",
        "segmentation",
        "multi-domain"
      ],
      "id": 163
    },
    {
      "name": "FEMR",
      "one_line_profile": "Framework for self-supervised learning on Electronic Medical Records",
      "detailed_description": "A comprehensive framework providing tooling for large-scale self-supervised learning and analysis using electronic health record (EHR) data.",
      "domains": [
        "H1-03"
      ],
      "subtask_category": [
        "self_supervised_learning",
        "ehr_analysis",
        "data_processing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/som-shahlab/femr",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ehr",
        "self-supervised-learning",
        "healthcare-data"
      ],
      "id": 164
    },
    {
      "name": "HistoTME",
      "one_line_profile": "Characterizing tumor microenvironment using pathology foundation models",
      "detailed_description": "A tool leveraging digital pathology foundation models to analyze and characterize the tumor microenvironment (TME) from histological images.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "pathology_analysis",
        "feature_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/spatkar94/HistoTME",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "digital-pathology",
        "tumor-microenvironment",
        "foundation-model"
      ],
      "id": 165
    },
    {
      "name": "MONET",
      "one_line_profile": "Image-text foundation model grounded in medical literature",
      "detailed_description": "A foundation model that connects medical images with text grounded in medical literature to provide transparent and interpretable medical AI analysis.",
      "domains": [
        "H1-03"
      ],
      "subtask_category": [
        "foundation_model",
        "image_text_alignment",
        "interpretability"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/suinleelab/MONET",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "foundation-model",
        "multimodal",
        "interpretability"
      ],
      "id": 166
    },
    {
      "name": "MedDr",
      "one_line_profile": "Generalist foundation model for diverse medical modalities",
      "detailed_description": "A generalist healthcare foundation model capable of processing and analyzing diverse medical data modalities for various downstream tasks.",
      "domains": [
        "H1-03"
      ],
      "subtask_category": [
        "foundation_model",
        "multimodal_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sunanhe/MedDr",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "foundation-model",
        "multimodal",
        "healthcare"
      ],
      "id": 167
    },
    {
      "name": "SAUNet",
      "one_line_profile": "Shape Attentive U-Net for interpretable medical image segmentation",
      "detailed_description": "An implementation of SAUNet, a U-Net variant that integrates shape-attentive mechanisms to improve interpretability and accuracy in medical image segmentation.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "model_architecture"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sunjesse/shape-attentive-unet",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "u-net",
        "segmentation",
        "attention-mechanism"
      ],
      "id": 168
    },
    {
      "name": "ChiMed-GPT",
      "one_line_profile": "Chinese medical large language model",
      "detailed_description": "A Chinese medical Large Language Model (LLM) developed through continual training, supervised fine-tuning, and RLHF on Chinese medical data.",
      "domains": [
        "H1-03"
      ],
      "subtask_category": [
        "text_generation",
        "medical_nlp",
        "foundation_model"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/synlp/ChiMed-GPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "chinese-medical-nlp",
        "rlhf"
      ],
      "id": 169
    },
    {
      "name": "UGPCL",
      "one_line_profile": "Uncertainty-Guided Pixel Contrastive Learning for segmentation",
      "detailed_description": "A semi-supervised medical image segmentation method utilizing uncertainty-guided pixel contrastive learning to leverage unlabeled data.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "segmentation",
        "semi_supervised_learning",
        "contrastive_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/taovv/UGPCL",
      "help_website": [],
      "license": null,
      "tags": [
        "semi-supervised",
        "contrastive-learning",
        "segmentation"
      ],
      "id": 170
    },
    {
      "name": "LoRKD",
      "one_line_profile": "Low-Rank Knowledge Decomposition for Medical Foundation Models",
      "detailed_description": "A method for compressing medical foundation models using low-rank knowledge decomposition to maintain performance while reducing model size.",
      "domains": [
        "H1-03"
      ],
      "subtask_category": [
        "model_compression",
        "knowledge_distillation",
        "foundation_model"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tdlhl/LoRKD",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "model-compression",
        "foundation-model",
        "knowledge-distillation"
      ],
      "id": 171
    },
    {
      "name": "CCD",
      "one_line_profile": "Constrained Contrastive Distribution Learning for anomaly detection",
      "detailed_description": "An unsupervised anomaly detection and localization method for medical images using constrained contrastive distribution learning.",
      "domains": [
        "H1"
      ],
      "subtask_category": [
        "anomaly_detection",
        "unsupervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tianyu0207/CCD",
      "help_website": [],
      "license": null,
      "tags": [
        "anomaly-detection",
        "contrastive-learning",
        "medical-imaging"
      ],
      "id": 172
    },
    {
      "name": "I-MedSAM",
      "one_line_profile": "Implicit Medical Image Segmentation model based on Segment Anything",
      "detailed_description": "An implementation of Implicit Medical Image Segmentation using the Segment Anything Model (SAM), designed to handle medical image segmentation tasks with implicit prompts.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ucwxb/I-MedSAM",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-imaging",
        "segmentation",
        "sam",
        "foundation-model"
      ],
      "id": 173
    },
    {
      "name": "SlicerUniGradICON",
      "one_line_profile": "3D Slicer extension for the uniGradICON registration model",
      "detailed_description": "A 3D Slicer extension that integrates uniGradICON, a foundation model for medical image registration, allowing users to perform registration tasks directly within the Slicer environment.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "registration",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/uncbiag/SlicerUniGradICON",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "3d-slicer",
        "registration",
        "medical-imaging",
        "plugin"
      ],
      "id": 174
    },
    {
      "name": "uniGradICON",
      "one_line_profile": "Foundation model for medical image registration",
      "detailed_description": "A foundation model designed for medical image registration, capable of handling various modalities and registration tasks with high performance.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "registration",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/uncbiag/uniGradICON",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "registration",
        "foundation-model",
        "medical-imaging",
        "deep-learning"
      ],
      "id": 175
    },
    {
      "name": "SAM-Med2D",
      "one_line_profile": "Adaptation of Segment Anything Model for 2D medical images",
      "detailed_description": "A comprehensive framework bridging the gap between natural image segmentation and medical image segmentation using the Segment Anything Model (SAM) for 2D medical data.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/uni-medical/SAM-Med2D",
      "help_website": [],
      "license": null,
      "tags": [
        "segmentation",
        "sam",
        "2d-medical-imaging",
        "foundation-model"
      ],
      "id": 176
    },
    {
      "name": "SAM-Med3D",
      "one_line_profile": "Efficient general-purpose promptable segmentation model for 3D medical images",
      "detailed_description": "A 3D adaptation of the Segment Anything Model (SAM) designed for volumetric medical image segmentation, supporting prompt-based interaction.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/uni-medical/SAM-Med3D",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "segmentation",
        "3d-medical-imaging",
        "sam",
        "volumetric-analysis"
      ],
      "id": 177
    },
    {
      "name": "STU-Net",
      "one_line_profile": "Large-scale pre-trained medical image segmentation model",
      "detailed_description": "A scalable U-Net based model for medical image segmentation, pre-trained on a massive dataset of over 100k annotations, representing one of the largest models in the field.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/uni-medical/STU-Net",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "segmentation",
        "pre-training",
        "large-model",
        "medical-imaging"
      ],
      "id": 178
    },
    {
      "name": "med-sam-brain",
      "one_line_profile": "SAM adaptation for brain tumor segmentation",
      "detailed_description": "A specialized adaptation of the Segment Anything Model (SAM) for multi-parametric MRI brain tumor segmentation.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/vpulab/med-sam-brain",
      "help_website": [],
      "license": null,
      "tags": [
        "brain-tumor",
        "mri",
        "segmentation",
        "sam"
      ],
      "id": 179
    },
    {
      "name": "SwinPA-Net",
      "one_line_profile": "Swin Transformer-based network for medical image segmentation",
      "detailed_description": "A deep learning model utilizing Swin Transformers and multiscale feature pyramid aggregation for accurate medical image segmentation.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wjiazheng/SwinPA-Net",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "swin-transformer",
        "segmentation",
        "medical-imaging",
        "deep-learning"
      ],
      "id": 180
    },
    {
      "name": "SACB-Net",
      "one_line_profile": "Spatial-awareness convolutions for medical image registration",
      "detailed_description": "A neural network model incorporating spatial-awareness convolutions designed specifically for medical image registration tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "registration",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/x-xc/SACB_Net",
      "help_website": [],
      "license": null,
      "tags": [
        "registration",
        "medical-imaging",
        "convolution",
        "deep-learning"
      ],
      "id": 181
    },
    {
      "name": "LKU-Net",
      "one_line_profile": "Large Kernel U-Net for medical image registration",
      "detailed_description": "An implementation of a U-Net variant utilizing large kernels to challenge Transformers in the task of medical image registration.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "registration",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/xi-jia/LKU-Net",
      "help_website": [],
      "license": null,
      "tags": [
        "registration",
        "unet",
        "medical-imaging",
        "deep-learning"
      ],
      "id": 182
    },
    {
      "name": "TP-Mamba",
      "one_line_profile": "Tri-Plane Mamba for 3D medical image segmentation",
      "detailed_description": "An efficient model adapting the Segment Anything Model (SAM) for 3D medical images using a Tri-Plane Mamba architecture.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/xmed-lab/TP-Mamba",
      "help_website": [],
      "license": null,
      "tags": [
        "mamba",
        "segmentation",
        "3d-medical-imaging",
        "sam"
      ],
      "id": 183
    },
    {
      "name": "LHU-Net",
      "one_line_profile": "Lean Hybrid U-Net for volumetric medical image segmentation",
      "detailed_description": "A cost-efficient and high-performance hybrid U-Net architecture designed for volumetric medical image segmentation.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/xmindflow/LHUNet",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "segmentation",
        "unet",
        "volumetric-analysis",
        "medical-imaging"
      ],
      "id": 184
    },
    {
      "name": "MSA-2Net",
      "one_line_profile": "Multi-scale Adaptive Attention-guided Network for segmentation",
      "detailed_description": "A medical image segmentation network featuring multi-scale adaptive attention mechanisms to improve segmentation accuracy.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/xmindflow/MSA-2Net",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "segmentation",
        "attention-mechanism",
        "medical-imaging",
        "deep-learning"
      ],
      "id": 185
    },
    {
      "name": "SSL-contrastive",
      "one_line_profile": "Self-supervised contrastive learning for 3D segmentation",
      "detailed_description": "A framework leveraging unlabeled data for 3D medical image segmentation through self-supervised contrastive learning techniques.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/xmindflow/SSL-contrastive",
      "help_website": [],
      "license": null,
      "tags": [
        "self-supervised-learning",
        "contrastive-learning",
        "segmentation",
        "3d-medical-imaging"
      ],
      "id": 186
    },
    {
      "name": "DCSAU-Net",
      "one_line_profile": "Compact split-attention U-Net for medical image segmentation",
      "detailed_description": "A deeper and more compact U-Net architecture utilizing split-attention mechanisms for efficient medical image segmentation.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/xq141839/DCSAU-Net",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "segmentation",
        "unet",
        "attention-mechanism",
        "medical-imaging"
      ],
      "id": 187
    },
    {
      "name": "DeSAM",
      "one_line_profile": "Decoupled Segment Anything Model for medical images",
      "detailed_description": "A generalizable medical image segmentation model that decouples the Segment Anything Model (SAM) components for improved performance on medical data.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yifangao112/DeSAM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "segmentation",
        "sam",
        "medical-imaging",
        "generalizability"
      ],
      "id": 188
    },
    {
      "name": "DinoUNet",
      "one_line_profile": "U-Net using DINOv3 features for medical segmentation",
      "detailed_description": "A segmentation model that exploits high-fidelity dense features from foundation models (specifically DINOv3) to enhance U-Net performance in medical imaging.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yifangao112/DinoUNet",
      "help_website": [],
      "license": null,
      "tags": [
        "segmentation",
        "foundation-model",
        "dino",
        "unet"
      ],
      "id": 189
    },
    {
      "name": "Segment-Anything-Model-for-Medical-Images",
      "one_line_profile": "Evaluation and adaptation of SAM for medical images",
      "detailed_description": "Codebase for evaluating and adapting the Segment Anything Model (SAM) specifically for medical image analysis tasks.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yuhoo0302/Segment-Anything-Model-for-Medical-Images",
      "help_website": [],
      "license": null,
      "tags": [
        "segmentation",
        "sam",
        "medical-imaging",
        "evaluation"
      ],
      "id": 190
    },
    {
      "name": "TransSeg",
      "one_line_profile": "Adapting 2D Vision Transformers for 3D medical segmentation",
      "detailed_description": "A method and tool for adapting pre-trained 2D Vision Transformers to 3D medical image segmentation tasks via weight inflation.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yuhui-zh15/TransSeg",
      "help_website": [],
      "license": null,
      "tags": [
        "segmentation",
        "transformer",
        "3d-medical-imaging",
        "transfer-learning"
      ],
      "id": 191
    },
    {
      "name": "EM-Net",
      "one_line_profile": "Efficient Mamba-based network for 3D segmentation",
      "detailed_description": "An efficient channel and frequency learning network utilizing the Mamba architecture for 3D medical image segmentation.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zang0902/EM-Net",
      "help_website": [],
      "license": null,
      "tags": [
        "mamba",
        "segmentation",
        "3d-medical-imaging",
        "deep-learning"
      ],
      "id": 192
    },
    {
      "name": "M3AE",
      "one_line_profile": "Multi-Modal Masked Autoencoders for medical pre-training",
      "detailed_description": "A framework for Multi-Modal Masked Autoencoders designed for medical vision-and-language pre-training, enabling downstream tasks like VQA and retrieval.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "pretraining",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhjohnchan/M3AE",
      "help_website": [],
      "license": null,
      "tags": [
        "pre-training",
        "multimodal",
        "masked-autoencoder",
        "medical-imaging"
      ],
      "id": 193
    },
    {
      "name": "BDG-Net",
      "one_line_profile": "Boundary-Difference-Graph Network for medical segmentation",
      "detailed_description": "Implementation of BDG-Net, a deep learning model focused on boundary awareness for medical image segmentation.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "segmentation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zihuanqiu/BDG-Net",
      "help_website": [],
      "license": null,
      "tags": [
        "segmentation",
        "medical-imaging",
        "deep-learning"
      ],
      "id": 194
    },
    {
      "name": "WCL",
      "one_line_profile": "Weakly Supervised Contrastive Learning for report generation",
      "detailed_description": "A model for generating chest X-ray reports using weakly supervised contrastive learning to align visual and textual features.",
      "domains": [
        "H1",
        "H1-03"
      ],
      "subtask_category": [
        "report_generation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zzxslp/WCL",
      "help_website": [],
      "license": null,
      "tags": [
        "report-generation",
        "contrastive-learning",
        "chest-xray",
        "nlp"
      ],
      "id": 195
    }
  ]
}