{
  "generated_at": "2025-12-16T17:10:00.848286+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "AI5",
      "leaf_cluster_name": "科研代理-工具调用与工作流编排生态",
      "domain": "AI Toolchain",
      "typical_objects": "tools/workflows",
      "task_chain": "规划→调用→追踪→回放→评测→治理",
      "tool_form": "agent框架 + tracing + registry"
    },
    "unit": {
      "unit_id": "AI5-05",
      "unit_name": "RAG与证据链（文献/引用溯源）",
      "target_scale": "250–600",
      "coverage_tools": "retrievers、grounding、PDF parsing"
    },
    "search": {
      "target_candidates": 600,
      "queries": [
        "[GH] Verba",
        "[GH] Marker",
        "[GH] GPT-Researcher",
        "[GH] Haystack",
        "[GH] Nougat",
        "[GH] Unstructured",
        "[GH] Grobid",
        "[GH] LangChain",
        "[GH] LlamaIndex",
        "[GH] PaperQA",
        "[GH] retrieval augmented generation",
        "[GH] RAG pipeline",
        "[GH] citation grounding",
        "[GH] source attribution",
        "[GH] scientific pdf parser",
        "[GH] document layout analysis",
        "[GH] fact checking ai",
        "[GH] hallucination detection",
        "[GH] semantic search engine",
        "[GH] knowledge retrieval",
        "[GH] pdf to markdown",
        "[GH] reference extraction",
        "[GH] context aware generation",
        "[GH] evidence retrieval",
        "[WEB] scientific literature RAG tools github",
        "[WEB] pdf parsing for llm github",
        "[WEB] citation based rag agent github",
        "[WEB] hallucination reduction tools github",
        "[WEB] research paper analysis agent github",
        "[WEB] langchain retrieval citation github"
      ],
      "total_candidates": 1325,
      "tool_candidates": 1055,
      "final_tools": 242
    }
  },
  "tools": [
    {
      "name": "ViDoRAG",
      "one_line_profile": "Visual Document Retrieval-Augmented Generation agent for parsing complex scientific documents",
      "detailed_description": "A visual document retrieval-augmented generation system that employs dynamic iterative reasoning agents to process and retrieve information from visually rich documents (like scientific papers with charts and figures). It addresses the challenge of multimodal information extraction in scientific literature.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "visual_retrieval",
        "multimodal_rag"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Alibaba-NLP/ViDoRAG",
      "help_website": [],
      "license": null,
      "tags": [
        "visual-rag",
        "document-parsing",
        "scientific-literature",
        "agent"
      ],
      "id": 1
    },
    {
      "name": "RAGatouille",
      "one_line_profile": "Library for using ColBERT retrieval models in RAG pipelines",
      "detailed_description": "A library that simplifies the use and training of state-of-the-art late-interaction retrieval methods (ColBERT). It is essential for building high-precision RAG systems for scientific evidence retrieval and citation tracing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "retrieval",
        "evidence_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AnswerDotAI/RAGatouille",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "colbert",
        "retrieval",
        "rag",
        "embedding"
      ],
      "id": 2
    },
    {
      "name": "PapersChat",
      "one_line_profile": "Agentic AI application for chatting with scientific papers and ArXiv/PubMed integration",
      "detailed_description": "An agent-based application designed to facilitate literature review by allowing users to chat with local papers and automatically gather information from ArXiv and PubMed, supporting citation tracing and evidence gathering.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "citation_tracing",
        "evidence_gathering"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/AstraBert/PapersChat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arxiv",
        "pubmed",
        "literature-review",
        "agent"
      ],
      "id": 3
    },
    {
      "name": "RAG_Maestro",
      "one_line_profile": "RAG pipeline for reading, summarizing, and quoting scientific papers",
      "detailed_description": "A chatbot application powered by a RAG pipeline specifically designed to read, summarize, and provide accurate quotes from relevant scientific papers, aiding in evidence-based research queries.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "summarization",
        "evidence_citation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/AymenKallala/RAG_Maestro",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "scientific-papers",
        "summarization",
        "citation"
      ],
      "id": 4
    },
    {
      "name": "KG_RAG",
      "one_line_profile": "Knowledge Graph-based Retrieval-Augmented Generation for biomedical tasks",
      "detailed_description": "A framework empowering Large Language Models with Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG), specifically optimized for knowledge-intensive scientific tasks such as biomedical discovery.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "biomedical_inference",
        "rag"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/BaranziniLab/KG_RAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "rag",
        "biomedical",
        "llm"
      ],
      "id": 5
    },
    {
      "name": "ClaimeAI",
      "one_line_profile": "AI-driven fact-checking and claim verification system",
      "detailed_description": "A system built with LangGraph that dissects text into verifiable claims and cross-references them with real-world evidence via web searches to generate accuracy reports, useful for verifying scientific claims or combating misinformation.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "fact_checking",
        "evidence_verification",
        "claim_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/BharathxD/ClaimeAI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fact-checking",
        "langgraph",
        "evidence-retrieval"
      ],
      "id": 6
    },
    {
      "name": "Verbalized Sampling",
      "one_line_profile": "Training-free prompting strategy to mitigate mode collapse in LLMs",
      "detailed_description": "A model-agnostic framework and CLI/API that implements a verbalized sampling strategy to improve the diversity and quality of LLM responses, useful for synthetic data generation and creative scientific writing.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "model_sampling",
        "synthetic_data_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CHATS-lab/verbalized-sampling",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "sampling",
        "prompt-engineering"
      ],
      "id": 7
    },
    {
      "name": "Uniflow",
      "one_line_profile": "LLM-based unstructured data extraction and cleaning tool",
      "detailed_description": "A tool for extracting, cleaning, and transforming text from unstructured data sources like PDFs, Word documents, and HTML into structured formats, facilitating faster R&D and data processing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "data_extraction",
        "text_cleaning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf-extraction",
        "etl",
        "unstructured-data"
      ],
      "id": 8
    },
    {
      "name": "Text Extract API",
      "one_line_profile": "API for parsing and extracting structured data from documents",
      "detailed_description": "A tool leveraging modern OCRs and LLMs to extract, parse, and anonymize content from documents (PDF, Word, PPTX) into structured JSON or Markdown, suitable for scientific literature processing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "ocr",
        "document_anonymization"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/CatchTheTornado/text-extract-api",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ocr",
        "pdf-parsing",
        "data-extraction"
      ],
      "id": 9
    },
    {
      "name": "Climsight",
      "one_line_profile": "LLM-driven climate information and assessment system",
      "detailed_description": "A climate information system that combines Large Language Models with high-resolution climate model data and scientific literature to generate localized and context-aware climate assessments.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "climate_modeling",
        "literature_review",
        "scientific_assessment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/CliDyn/climsight",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "climate-change",
        "llm",
        "scientific-assessment"
      ],
      "id": 10
    },
    {
      "name": "dsRAG",
      "one_line_profile": "High-performance retrieval engine for unstructured data",
      "detailed_description": "A retrieval engine designed for unstructured data, facilitating efficient indexing and retrieval for RAG applications, applicable to scientific literature and data management.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "retrieval",
        "indexing",
        "unstructured_data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/D-Star-AI/dsRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "retrieval",
        "vector-search"
      ],
      "id": 11
    },
    {
      "name": "DawDreamer",
      "one_line_profile": "Python-based Digital Audio Workstation for audio synthesis and processing",
      "detailed_description": "A library for audio signal processing and synthesis enabling the creation of VST instruments/effects and parameter automation, supporting JAX for differentiable audio research.",
      "domains": [
        "AI4",
        "AI4-01"
      ],
      "subtask_category": [
        "signal_processing",
        "audio_synthesis",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/DBraun/DawDreamer",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "audio-processing",
        "jax",
        "synthesis"
      ],
      "id": 12
    },
    {
      "name": "Rankify",
      "one_line_profile": "Comprehensive toolkit for retrieval and re-ranking benchmarks",
      "detailed_description": "A Python toolkit integrating multiple pre-retrieved benchmark datasets, retrieval techniques, and state-of-the-art re-ranking models to facilitate research and development in RAG and information retrieval.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "retrieval",
        "reranking",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DataScienceUIBK/Rankify",
      "help_website": [],
      "license": null,
      "tags": [
        "retrieval",
        "reranking",
        "rag",
        "benchmark"
      ],
      "id": 13
    },
    {
      "name": "Strwythura",
      "one_line_profile": "Knowledge graph construction and GraphRAG pipeline",
      "detailed_description": "A tool to construct knowledge graphs from unstructured data sources, implementing entity resolution and an enhanced GraphRAG approach for optimizing AI application outcomes in specific domains.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "rag",
        "entity_resolution"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/DerwenAI/strwythura",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "graphrag",
        "unstructured-data"
      ],
      "id": 14
    },
    {
      "name": "Dewy",
      "one_line_profile": "Knowledge extraction and semantic retrieval system",
      "detailed_description": "An opinionated knowledge extraction and semantic retrieval tool designed for Gen AI applications, streamlining the process of managing and retrieving information from documents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "retrieval",
        "document_management"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/DewyKB/dewy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-extraction",
        "retrieval",
        "rag"
      ],
      "id": 15
    },
    {
      "name": "Doctor Dok",
      "one_line_profile": "Medical document parsing and analysis framework",
      "detailed_description": "A framework for parsing health-related PDFs and images into JSON and leveraging LLMs for analysis, serving as a medical data vault and research tool for medical document processing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "medical_data_parsing",
        "clinical_analysis",
        "ocr"
      ],
      "application_level": "workflow",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/Doctor-One/doctor-dok",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-data",
        "pdf-parsing",
        "healthcare"
      ],
      "id": 16
    },
    {
      "name": "open-parse",
      "one_line_profile": "Improved file parsing and chunking library for LLMs",
      "detailed_description": "A library designed to solve the problem of parsing complex documents (like PDFs) into chunks suitable for LLMs, supporting layout analysis and table extraction, which is critical for scientific literature mining.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_processing",
        "pdf_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Filimoa/open-parse",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-parsing",
        "chunking",
        "rag",
        "ocr"
      ],
      "id": 17
    },
    {
      "name": "paper-qa",
      "one_line_profile": "RAG agent for answering questions from scientific documents with citations",
      "detailed_description": "A library that uses LLMs to answer questions from scientific papers (PDFs/text) with high accuracy, providing citations and evidence grounding, specifically designed for literature review and evidence extraction.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "evidence_extraction",
        "citation_tracing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Future-House/paper-qa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "scientific-qa",
        "citations",
        "literature-review"
      ],
      "id": 18
    },
    {
      "name": "simba",
      "one_line_profile": "Portable Knowledge Management System (KMS) for RAG integration",
      "detailed_description": "A tool designed to manage unstructured data and integrate seamlessly with Retrieval-Augmented Generation (RAG) systems, facilitating the organization and retrieval of knowledge for AI agents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_management",
        "retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/GitHamza0206/simba",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "kms",
        "vector-database",
        "knowledge-graph"
      ],
      "id": 19
    },
    {
      "name": "LightRAG",
      "one_line_profile": "Simple and fast retrieval-augmented generation framework",
      "detailed_description": "A library implementing the LightRAG framework for efficient and accurate retrieval-augmented generation, incorporating graph-based indexing and retrieval strategies useful for complex knowledge tasks.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "retrieval",
        "generation",
        "knowledge_graph"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUDS/LightRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "graph-rag",
        "retrieval",
        "llm"
      ],
      "id": 20
    },
    {
      "name": "RAG-Anything",
      "one_line_profile": "All-in-one framework for retrieval-augmented generation",
      "detailed_description": "A comprehensive framework designed to facilitate various RAG tasks, providing a unified interface for different retrieval and generation strategies.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "retrieval",
        "generation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUDS/RAG-Anything",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "framework",
        "llm"
      ],
      "id": 21
    },
    {
      "name": "detectron2-publaynet",
      "one_line_profile": "Trained Detectron2 models for document layout analysis on PubLayNet",
      "detailed_description": "A collection of trained Detectron2 object detection models specifically fine-tuned on the PubLayNet dataset for document layout analysis. It serves as a specialized solver for extracting structural components (text, figures, tables) from scientific documents and PDFs.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "layout_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JPLeoRX/detectron2-publaynet",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "detectron2",
        "publaynet",
        "document-layout-analysis",
        "pdf-parsing"
      ],
      "id": 22
    },
    {
      "name": "research-agents-3.0",
      "one_line_profile": "Multi-agent system for automated research using Autogen and GPTs",
      "detailed_description": "A framework leveraging Autogen and GPTs to build a swarm of AI researchers. It orchestrates multiple agents to perform comprehensive research tasks, simulating a collaborative scientific research workflow.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "agent_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/JayZeeDesign/research-agents-3.0",
      "help_website": [],
      "license": null,
      "tags": [
        "autogen",
        "research-agents",
        "multi-agent",
        "literature-review"
      ],
      "id": 23
    },
    {
      "name": "TopOpt.jl",
      "one_line_profile": "Topology optimization library for Julia",
      "detailed_description": "A Julia package for binary and continuous, single and multi-material, truss and continuum, 2D and 3D topology optimization on unstructured meshes using automatic differentiation. It is a core tool for engineering design and physics-based modeling.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "topology_optimization",
        "simulation"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaTopOpt/TopOpt.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "topology-optimization",
        "julia",
        "finite-element-analysis",
        "automatic-differentiation"
      ],
      "id": 24
    },
    {
      "name": "LettuceDetect",
      "one_line_profile": "Hallucination detection framework for RAG applications",
      "detailed_description": "A framework designed to detect hallucinations in Retrieval-Augmented Generation (RAG) applications. It provides metrics and methods to ensure the factual consistency and reliability of AI-generated scientific or technical content.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KRLabsOrg/LettuceDetect",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "hallucination-detection",
        "ai-safety",
        "evaluation"
      ],
      "id": 25
    },
    {
      "name": "owl-verbalizer",
      "one_line_profile": "Converts OWL ontologies into human-readable text",
      "detailed_description": "A tool that translates Web Ontology Language (OWL) statements into controlled natural language. This is useful in scientific knowledge management for making complex ontologies (common in biology and chemistry) accessible to researchers.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_representation",
        "ontology_verbalization"
      ],
      "application_level": "library",
      "primary_language": "Prolog",
      "repo_url": "https://github.com/Kaljurand/owl-verbalizer",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "owl",
        "ontology",
        "natural-language-generation",
        "knowledge-graph"
      ],
      "id": 26
    },
    {
      "name": "LeanRAG",
      "one_line_profile": "Knowledge-Graph-Based RAG with Semantic Aggregation",
      "detailed_description": "A framework for Retrieval-Augmented Generation that leverages Knowledge Graphs for semantic aggregation and hierarchical retrieval. It enhances the accuracy of RAG systems in complex scientific domains by structuring retrieved evidence.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag",
        "knowledge_graph"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KnowledgeXLab/LeanRAG",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "knowledge-graph",
        "retrieval",
        "semantic-aggregation"
      ],
      "id": 27
    },
    {
      "name": "RAKG",
      "one_line_profile": "Document-level Retrieval Augmented Knowledge Graph Construction",
      "detailed_description": "A tool for constructing Knowledge Graphs using document-level retrieval augmentation. It facilitates the extraction of structured knowledge from unstructured scientific text, supporting evidence chains and literature analysis.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "information_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KnowledgeXLab/RAKG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "rag",
        "information-extraction",
        "nlp"
      ],
      "id": 28
    },
    {
      "name": "HyperGraphRAG",
      "one_line_profile": "RAG via Hypergraph-Structured Knowledge Representation",
      "detailed_description": "An advanced RAG framework that uses hypergraph structures to represent complex relationships in knowledge bases. This approach is particularly useful for scientific reasoning where multi-hop and multi-entity relationships are common.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag",
        "knowledge_representation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/LHRLAB/HyperGraphRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hypergraph",
        "rag",
        "knowledge-graph",
        "reasoning"
      ],
      "id": 29
    },
    {
      "name": "Layout-Parser",
      "one_line_profile": "Unified toolkit for deep learning based document image analysis",
      "detailed_description": "A comprehensive toolkit for document image analysis (DIA) using deep learning. It provides a unified interface for various layout detection models, essential for parsing scientific papers (PDFs) and extracting structured data for RAG systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "layout_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Layout-Parser/layout-parser",
      "help_website": [
        "https://layout-parser.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ocr",
        "document-layout-analysis",
        "pdf-parsing",
        "deep-learning"
      ],
      "id": 30
    },
    {
      "name": "LazyLLM",
      "one_line_profile": "Low-code framework for building multi-agent LLM applications",
      "detailed_description": "A framework designed to simplify the creation of multi-agent LLM applications. It supports workflow orchestration and tool calling, enabling the rapid development of research agents and complex reasoning pipelines.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "agent_orchestration",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/LazyAGI/LazyLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "llm",
        "workflow",
        "low-code"
      ],
      "id": 31
    },
    {
      "name": "local-deep-research",
      "one_line_profile": "Local AI agent for deep research and QA",
      "detailed_description": "An AI research agent capable of performing deep research by searching multiple sources (arXiv, PubMed, web) and local documents. It is designed to run locally, ensuring privacy while aggregating evidence for scientific queries.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "evidence_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LearningCircuit/local-deep-research",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "research-agent",
        "rag",
        "arxiv",
        "pubmed"
      ],
      "id": 32
    },
    {
      "name": "SurfSense",
      "one_line_profile": "Open source research assistant and knowledge aggregation platform",
      "detailed_description": "A platform serving as an alternative to NotebookLM, designed for aggregating and querying knowledge from various sources (search engines, documents). It acts as a research assistant for synthesizing information and managing evidence chains.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "knowledge_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/MODSetter/SurfSense",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "research-assistant",
        "rag",
        "knowledge-base",
        "notebooklm-alternative"
      ],
      "id": 33
    },
    {
      "name": "LangChain-GPT-Researcher",
      "one_line_profile": "GPT-Researcher integration for LangChain agents",
      "detailed_description": "A tool wrapper that integrates GPT-Researcher capabilities into LangChain agents. It enables automated online research and report generation within larger scientific workflow orchestrations.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "automated_research"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Makesh-Srinivasan/LangChain-GPT-Researcher",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "langchain",
        "gpt-researcher",
        "agent-tool",
        "research-automation"
      ],
      "id": 34
    },
    {
      "name": "markpdfdown",
      "one_line_profile": "Visual-based PDF to Markdown converter using LLMs",
      "detailed_description": "A tool that converts PDF documents to Markdown format using Large Language Models with visual recognition capabilities. It is essential for preprocessing scientific literature into machine-readable formats for RAG and analysis.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "format_conversion"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/MarkPDFdown/markpdfdown",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf-to-markdown",
        "ocr",
        "document-parsing",
        "llm"
      ],
      "id": 35
    },
    {
      "name": "AutoRAG",
      "one_line_profile": "Automated framework for evaluating and optimizing RAG pipelines",
      "detailed_description": "AutoRAG is a tool designed to automatically evaluate and optimize Retrieval-Augmented Generation (RAG) pipelines. It helps researchers and developers find the optimal RAG configuration for their specific data and use cases, functioning like AutoML for RAG systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_optimization",
        "evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "automl",
        "optimization",
        "evaluation"
      ],
      "id": 36
    },
    {
      "name": "go-light-rag",
      "one_line_profile": "Go implementation of LightRAG for graph-enhanced retrieval",
      "detailed_description": "A Go library implementing the LightRAG architecture, which combines vector databases with knowledge graph relationships to improve information retrieval in RAG systems. It is suitable for building efficient, context-aware retrieval systems for scientific knowledge bases.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "retrieval",
        "knowledge_graph"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/MegaGrindStone/go-light-rag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "graph-database",
        "go",
        "retrieval"
      ],
      "id": 37
    },
    {
      "name": "arabic-nougat",
      "one_line_profile": "Fine-tuned Nougat model for parsing Arabic scientific documents",
      "detailed_description": "A specialized implementation of the Nougat (Neural Optical Understanding for Academic Documents) model, fine-tuned for processing and extracting text/formulas from Arabic PDF documents, facilitating the digitization of non-English scientific literature.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "ocr"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MohamedAliRashad/arabic-nougat",
      "help_website": [],
      "license": null,
      "tags": [
        "pdf-parsing",
        "ocr",
        "arabic",
        "scientific-literature"
      ],
      "id": 38
    },
    {
      "name": "summarization-eval",
      "one_line_profile": "Toolkit for reference-free summarization evaluation and hallucination detection",
      "detailed_description": "A Python toolkit for evaluating text summarization quality without reference summaries. It includes metrics for detecting hallucinations, which is critical for verifying the factual consistency of AI-generated scientific summaries.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "evaluation",
        "hallucination_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Muhtasham/summarization-eval",
      "help_website": [],
      "license": null,
      "tags": [
        "summarization",
        "evaluation",
        "hallucination",
        "nlp"
      ],
      "id": 39
    },
    {
      "name": "NVIDIA RAG Blueprint",
      "one_line_profile": "Reference workflow for building enterprise-grade RAG pipelines",
      "detailed_description": "A foundational blueprint by NVIDIA for constructing Retrieval-Augmented Generation (RAG) pipelines. It serves as a reference implementation for researchers and developers to build scalable systems for querying scientific knowledge bases using NVIDIA's AI stack.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "workflow_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA-AI-Blueprints/rag",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "nvidia",
        "pipeline",
        "enterprise"
      ],
      "id": 40
    },
    {
      "name": "ChatRTX",
      "one_line_profile": "Local RAG application leveraging TensorRT-LLM on Windows",
      "detailed_description": "A developer reference project enabling local Retrieval-Augmented Generation (RAG) on Windows PCs powered by NVIDIA RTX GPUs. It allows researchers to perform secure, local document analysis and querying without data leaving the device.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "local_inference",
        "document_qa"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/ChatRTX",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "local-llm",
        "tensorrt-llm",
        "privacy"
      ],
      "id": 41
    },
    {
      "name": "context-aware-rag",
      "one_line_profile": "Library for context-aware RAG with Knowledge Graph integration",
      "detailed_description": "A library designed to enhance RAG systems by ingesting and retrieving information from Knowledge Graphs. It improves the contextual accuracy of answers, which is essential for complex scientific question answering.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_graph",
        "retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/context-aware-rag",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "knowledge-graph",
        "context-aware"
      ],
      "id": 42
    },
    {
      "name": "docext",
      "one_line_profile": "Toolkit for OCR-free unstructured document extraction and benchmarking",
      "detailed_description": "An on-premises toolkit for extracting data from unstructured documents (like PDFs) without relying on traditional OCR. It includes markdown conversion and benchmarking capabilities, useful for processing scientific literature.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "data_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NanoNets/docext",
      "help_website": [
        "https://idp-leaderboard.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "pdf-parsing",
        "data-extraction",
        "benchmark"
      ],
      "id": 43
    },
    {
      "name": "NeumAI",
      "one_line_profile": "Framework for managing large-scale vector embedding pipelines",
      "detailed_description": "A framework for creating and synchronizing vector embeddings at scale. It manages the data infrastructure required for RAG systems, ensuring that scientific knowledge bases are kept up-to-date and searchable.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "embedding_management",
        "data_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/NeumTry/NeumAI",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "embeddings",
        "rag",
        "data-sync"
      ],
      "id": 44
    },
    {
      "name": "RAGDrive",
      "one_line_profile": "RAG application integrating local files and web search",
      "detailed_description": "An open-source application leveraging LlamaIndex to provide RAG capabilities across mobile and desktop platforms. It allows users to query their own documents and integrate web search, supporting literature review workflows.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_qa",
        "retrieval"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/NidumAI-Inc/ragdrive",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "llamaindex",
        "cross-platform"
      ],
      "id": 45
    },
    {
      "name": "nougat-latex-ocr",
      "one_line_profile": "Codebase for fine-tuning and evaluating Nougat image-to-LaTeX models",
      "detailed_description": "A toolkit for training, fine-tuning, and evaluating Nougat-based models, which are specialized in converting scientific document images into LaTeX/Markdown. Essential for digitizing mathematical and scientific content.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NormXU/nougat-latex-ocr",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "latex",
        "ocr",
        "nougat",
        "fine-tuning"
      ],
      "id": 46
    },
    {
      "name": "General-Documents-Layout-parser",
      "one_line_profile": "Layout analysis and parsing tool for Chinese and general documents",
      "detailed_description": "A tool for document layout analysis and parsing, capable of handling complex document structures. It supports the extraction of structured information from PDFs and images, which is a preprocessing step for scientific literature mining.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OKC13/General-Documents-Layout-parser",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "layout-analysis",
        "ocr",
        "pdf-parsing"
      ],
      "id": 47
    },
    {
      "name": "UltraRAG",
      "one_line_profile": "Low-code framework for building complex RAG pipelines",
      "detailed_description": "A framework designed to simplify the creation of advanced Retrieval-Augmented Generation (RAG) pipelines. It supports modular components for retrieval, generation, and orchestration, facilitating the development of research agents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "workflow_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenBMB/UltraRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "low-code",
        "pipeline",
        "agent"
      ],
      "id": 48
    },
    {
      "name": "Ask-Anything",
      "one_line_profile": "Multimodal chat platform for video and image understanding",
      "detailed_description": "A platform integrating various Large Multimodal Models (LMMs) like VideoChatGPT and MiniGPT-4. It enables users to query and analyze video and image content via natural language, useful for analyzing visual scientific data.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "multimodal_analysis",
        "visual_qa"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/Ask-Anything",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "video-understanding",
        "multimodal",
        "chatgpt",
        "visual-qa"
      ],
      "id": 49
    },
    {
      "name": "InternGPT",
      "one_line_profile": "Interactive multimodal demo platform for image editing and visual reasoning",
      "detailed_description": "An open-source demo platform (iGPT) that integrates multiple vision and language models (DragGAN, ChatGPT, SAM) for interactive image editing and visual reasoning tasks, serving as a workbench for multimodal AI research.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "image_editing",
        "visual_reasoning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/InternGPT",
      "help_website": [
        "http://igpt.opengvlab.com"
      ],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "interactive",
        "visual-reasoning",
        "demo"
      ],
      "id": 50
    },
    {
      "name": "EasyDetect",
      "one_line_profile": "Framework for detecting hallucinations in LLM outputs",
      "detailed_description": "An easy-to-use framework designed to detect hallucinations in Large Language Models. It provides tools to verify the factual accuracy of generated content, which is crucial for reliable scientific RAG systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "fact_checking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenKG-ORG/EasyDetect",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "llm",
        "evaluation",
        "reliability"
      ],
      "id": 51
    },
    {
      "name": "KAG",
      "one_line_profile": "Knowledge Augmented Generation framework for logical reasoning and retrieval",
      "detailed_description": "KAG (Knowledge Augmented Generation) is a framework that combines OpenSPG engine with LLMs to perform logical form-guided reasoning and retrieval. It addresses limitations of vector-based RAG by leveraging professional domain knowledge bases for factual Q&A.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_graph",
        "reasoning",
        "retrieval"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenSPG/KAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "rag",
        "reasoning",
        "openspg"
      ],
      "id": 52
    },
    {
      "name": "OpenThaiRAG",
      "one_line_profile": "RAG framework optimized for Thai language processing",
      "detailed_description": "An open-source RAG framework specifically designed for the Thai language. It integrates vector databases and Thai-optimized LLMs to provide accurate context-aware responses, supporting regional scientific research and information retrieval.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenThaiGPT/openthairag",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "thai",
        "nlp",
        "retrieval"
      ],
      "id": 53
    },
    {
      "name": "local-rag-llamaindex",
      "one_line_profile": "Local RAG tool for navigating research papers",
      "detailed_description": "A local RAG implementation using LlamaIndex designed to assist researchers in quickly navigating and querying research papers. It runs locally to ensure privacy and ease of use for literature review.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "document_qa"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Otman404/local-rag-llamaindex",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "research-papers",
        "llamaindex",
        "local"
      ],
      "id": 54
    },
    {
      "name": "Oxen",
      "one_line_profile": "Data version control system for machine learning datasets",
      "detailed_description": "A lightning-fast data version control system designed for structured and unstructured machine learning datasets. It enables reproducible research by managing versions of large datasets (images, text, video) used in scientific AI workflows.",
      "domains": [
        "AI5",
        "AI2"
      ],
      "subtask_category": [
        "data_management",
        "version_control"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/Oxen-AI/Oxen",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-version-control",
        "machine-learning",
        "reproducibility"
      ],
      "id": 55
    },
    {
      "name": "semantic-search",
      "one_line_profile": "Semantic search engine for scientific papers",
      "detailed_description": "A simple yet effective semantic search engine tailored for scientific papers. It allows researchers to perform meaning-based searches across literature collections, improving the discovery of relevant scientific evidence.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_search",
        "retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PathwayCommons/semantic-search",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-search",
        "scientific-literature",
        "nlp"
      ],
      "id": 56
    },
    {
      "name": "Merlin",
      "one_line_profile": "3D Vision-Language Model for Computed Tomography (CT) analysis",
      "detailed_description": "A 3D Vision-Language Model (VLM) designed for medical imaging, specifically Computed Tomography (CT). It leverages structured Electronic Health Records (EHR) and unstructured radiology reports for pretraining, enabling grounded analysis of medical scans.",
      "domains": [
        "AI5-05",
        "Medical AI"
      ],
      "subtask_category": [
        "medical_imaging",
        "vlm",
        "grounding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/StanfordMIMI/Merlin",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-imaging",
        "ct-scan",
        "vlm",
        "multimodal"
      ],
      "id": 57
    },
    {
      "name": "EmbedAnything",
      "one_line_profile": "High-performance embedding pipeline for RAG and search",
      "detailed_description": "A modular and memory-safe inference, ingestion, and indexing pipeline built in Rust. It is designed to handle embedding tasks efficiently, serving as a core infrastructure component for Retrieval-Augmented Generation (RAG) and vector search applications.",
      "domains": [
        "AI5-05"
      ],
      "subtask_category": [
        "embedding",
        "indexing",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/StarlightSearch/EmbedAnything",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rust",
        "embedding",
        "rag",
        "vector-search"
      ],
      "id": 58
    },
    {
      "name": "TaskingAI",
      "one_line_profile": "Open source platform for AI-native agent and workflow development",
      "detailed_description": "A platform designed for building AI-native applications, enabling the orchestration of AI agents, tool calling, and RAG workflows. It provides the infrastructure to develop complex scientific agents that can interact with various data sources and models.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "agent_development",
        "rag"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/TaskingAI/TaskingAI",
      "help_website": [
        "https://tasking.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "agent",
        "workflow",
        "llm-ops",
        "rag"
      ],
      "id": 59
    },
    {
      "name": "tonic_validate",
      "one_line_profile": "Evaluation metrics for Retrieval Augmented Generation (RAG) applications",
      "detailed_description": "A library providing metrics and tools to evaluate the quality of responses in RAG applications. It helps in validating the evidence chain and ensuring the accuracy of retrieved information in scientific workflows.",
      "domains": [
        "AI5-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "metrics",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TonicAI/tonic_validate",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "metrics",
        "validation"
      ],
      "id": 60
    },
    {
      "name": "PagePlus",
      "one_line_profile": "PAGE XML processing tool for document layout analysis",
      "detailed_description": "A script/tool for processing PAGE XML files, a standard format for document layout analysis. It supports validation, repair, extension, and modification of text regions, facilitating the extraction of structured data from scientific documents.",
      "domains": [
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "layout_analysis",
        "ocr_postprocessing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/UB-Mannheim/PagePlus",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "page-xml",
        "ocr",
        "layout-analysis",
        "document-processing"
      ],
      "id": 61
    },
    {
      "name": "uxarray",
      "one_line_profile": "Xarray extension for unstructured climate and weather data",
      "detailed_description": "An extension to Xarray designed for the analysis and visualization of unstructured grid data, commonly found in climate and global weather modeling. It enables efficient handling of complex scientific datasets.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "climate_analysis",
        "data_visualization",
        "unstructured_grid"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/UXARRAY/uxarray",
      "help_website": [
        "https://uxarray.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "climate-science",
        "xarray",
        "unstructured-grids",
        "geoscience"
      ],
      "id": 62
    },
    {
      "name": "Unstructured",
      "one_line_profile": "ETL pipeline for processing unstructured documents",
      "detailed_description": "A comprehensive ETL solution for transforming complex unstructured documents (PDFs, HTML, etc.) into clean, structured formats suitable for Large Language Models (LLMs). It is a critical component for RAG pipelines involving scientific literature.",
      "domains": [
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "etl",
        "pdf_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Unstructured-IO/unstructured",
      "help_website": [
        "https://unstructured.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "etl",
        "pdf-parsing",
        "rag",
        "preprocessing"
      ],
      "id": 63
    },
    {
      "name": "SimGRAG",
      "one_line_profile": "Knowledge graph driven RAG leveraging similar subgraphs",
      "detailed_description": "A retrieval-augmented generation (RAG) framework that utilizes similar subgraphs within knowledge graphs to enhance information retrieval and generation quality, specifically designed for complex reasoning tasks.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "graph_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/YZ-Cai/SimGRAG",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "knowledge-graph",
        "subgraph-retrieval"
      ],
      "id": 64
    },
    {
      "name": "TableRAG",
      "one_line_profile": "RAG pipeline optimization for tabular data",
      "detailed_description": "A specialized RAG pipeline designed to improve retrieval and generation performance when dealing with tabular data structures, addressing the challenge of extracting information from tables in scientific documents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "table_extraction",
        "structured_data_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/YuhangWuAI/tablerag",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "rag",
        "tabular-data",
        "data-extraction"
      ],
      "id": 65
    },
    {
      "name": "GEM",
      "one_line_profile": "Online globally consistent dense elevation mapping",
      "detailed_description": "A mapping tool for robotics that generates globally consistent dense elevation maps for unstructured terrain, supporting scientific data generation for autonomous navigation and environmental modeling.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "mapping",
        "spatial_modeling"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ZJU-Robotics-Lab/GEM",
      "help_website": [],
      "license": null,
      "tags": [
        "slam",
        "elevation-mapping",
        "robotics"
      ],
      "id": 66
    },
    {
      "name": "Unstract",
      "one_line_profile": "No-code platform for structuring unstructured documents via LLMs",
      "detailed_description": "A platform to launch APIs and ETL pipelines that convert unstructured documents (like PDFs) into structured data using LLMs, essential for scientific literature parsing and data extraction workflows.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "etl",
        "data_structuring"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zipstack/unstract",
      "help_website": [
        "https://unstract.com"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "etl",
        "llm",
        "document-parsing"
      ],
      "id": 67
    },
    {
      "name": "AutoSurveyGPT",
      "one_line_profile": "Automated literature survey assistant using GPT",
      "detailed_description": "An intelligent research assistant that leverages GPT models to automatically find, analyze, and rank relevant academic papers from Google Scholar, streamlining the literature review process.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "citation_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/a554b554/AutoSurveyGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "literature-survey",
        "gpt",
        "automation"
      ],
      "id": 68
    },
    {
      "name": "Deep Lake",
      "one_line_profile": "Database for AI data (vectors, images, text) optimized for LLMs",
      "detailed_description": "A database designed for AI that stores vectors, images, texts, and videos, enabling efficient querying, versioning, and streaming of data to deep learning frameworks, supporting scientific data management.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_management",
        "vector_storage"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/activeloopai/deeplake",
      "help_website": [
        "https://activeloop.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "data-lake",
        "multimodal"
      ],
      "id": 69
    },
    {
      "name": "CompleteSearch",
      "one_line_profile": "Efficient search engine for semi-structured data",
      "detailed_description": "A high-performance search engine from the University of Freiburg designed for semi-structured data, supporting advanced features like semantic search and faceted search on large datasets.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "information_retrieval",
        "semantic_search"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ad-freiburg/completesearch",
      "help_website": [],
      "license": null,
      "tags": [
        "search-engine",
        "semi-structured-data",
        "indexing"
      ],
      "id": 70
    },
    {
      "name": "VARAG",
      "one_line_profile": "Vision-Augmented Retrieval and Generation engine",
      "detailed_description": "A RAG engine that integrates vision capabilities, allowing for the retrieval and generation of information based on visual inputs, enhancing multimodal scientific data analysis.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "multimodal_retrieval",
        "image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/adithya-s-k/VARAG",
      "help_website": [],
      "license": null,
      "tags": [
        "vision-rag",
        "multimodal",
        "retrieval"
      ],
      "id": 71
    },
    {
      "name": "Marker API",
      "one_line_profile": "High-accuracy PDF to Markdown converter",
      "detailed_description": "A deployable API tool for converting PDF documents into Markdown with high accuracy, facilitating the ingestion of scientific papers into RAG pipelines and text analysis workflows.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "document_conversion"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/adithya-s-k/marker-api",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pdf-to-markdown",
        "ocr",
        "document-processing"
      ],
      "id": 72
    },
    {
      "name": "singleCellHaystack",
      "one_line_profile": "Method for finding differentially active genes in single-cell data",
      "detailed_description": "A bioinformatics tool for identifying genes with non-random spatial distributions or differential activity in single-cell transcriptome data without relying on prior clustering.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "gene_expression_analysis",
        "single_cell_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/alexisvdb/singleCellHaystack",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "bioinformatics",
        "single-cell",
        "transcriptomics"
      ],
      "id": 73
    },
    {
      "name": "CCTag",
      "one_line_profile": "Concentric Circle Tag detection library",
      "detailed_description": "A computer vision library for the detection of CCTag markers, used in photogrammetry and robotics for precise localization and calibration.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "marker_detection",
        "photogrammetry"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/alicevision/CCTag",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "computer-vision",
        "fiducial-markers",
        "calibration"
      ],
      "id": 74
    },
    {
      "name": "Science Parse",
      "one_line_profile": "Parser for converting PDF scientific papers into structured JSON",
      "detailed_description": "A tool developed by AllenAI to parse scientific papers in PDF format and extract structured information such as titles, authors, references, and sections, enabling large-scale literature analysis.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "metadata_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/allenai/science-parse",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf-parsing",
        "scientific-literature",
        "allenai"
      ],
      "id": 75
    },
    {
      "name": "Launch",
      "one_line_profile": "Agent Creation Toolkit with RAG and LLMOps integration",
      "detailed_description": "A development environment and toolkit for rapidly constructing intelligent agents, featuring integrated RAG knowledge base management and LLMOps toolchains for research agent deployment.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "agent_development",
        "workflow_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/alphapro-club/Launch",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "agent-framework",
        "rag",
        "llmops"
      ],
      "id": 76
    },
    {
      "name": "CiteEval",
      "one_line_profile": "Principle-Driven Citation Evaluation for Source Attribution",
      "detailed_description": "An evaluation framework from Amazon Science for assessing the quality and accuracy of citations and source attribution in generated text, critical for verifying evidence chains in RAG systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "citation_evaluation",
        "attribution_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/amazon-science/CiteEval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "citation-analysis",
        "evaluation-metric",
        "rag-evaluation"
      ],
      "id": 77
    },
    {
      "name": "LlamaIndex Omakase RAG",
      "one_line_profile": "Enhanced RAG application construction framework",
      "detailed_description": "A framework built on LlamaIndex and Django to streamline the creation of scalable RAG applications, managing data ingestion and user access for research knowledge bases.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_workflow",
        "knowledge_base_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ammirsm/llamaindex-omakase-rag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "llamaindex",
        "django"
      ],
      "id": 78
    },
    {
      "name": "Mistral-Haystack",
      "one_line_profile": "Integration of Mistral models into Haystack RAG pipelines",
      "detailed_description": "A connector library that enables the use of Mistral AI models within the Haystack framework, facilitating the construction of advanced RAG pipelines for scientific text processing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "model_integration",
        "rag_pipeline"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/anakin87/mistral-haystack",
      "help_website": [],
      "license": null,
      "tags": [
        "haystack",
        "mistral",
        "rag"
      ],
      "id": 79
    },
    {
      "name": "ROSGPT",
      "one_line_profile": "Natural language control for ROS robots via ChatGPT",
      "detailed_description": "A tool bridging ChatGPT and ROS (Robot Operating System) to convert unstructured human language into actionable robotic commands, enabling LLM-driven robot control and interaction.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "robot_control",
        "natural_language_instruction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aniskoubaa/rosgpt",
      "help_website": [],
      "license": null,
      "tags": [
        "ros",
        "robotics",
        "llm-control"
      ],
      "id": 80
    },
    {
      "name": "RAG Web Browser",
      "one_line_profile": "Apify Actor for scraping web content for RAG pipelines",
      "detailed_description": "A specialized web scraping tool designed to feed LLM applications and RAG pipelines with up-to-date text content from the web, supporting data acquisition for scientific monitoring.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "web_scraping",
        "data_acquisition"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/apify/rag-web-browser",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "scraping",
        "rag",
        "data-ingestion"
      ],
      "id": 81
    },
    {
      "name": "RESTai",
      "one_line_profile": "AI-as-a-Service platform for RAG and LLM orchestration",
      "detailed_description": "An open-source platform built on LlamaIndex and LangChain that provides REST APIs for managing RAG pipelines, embeddings, and LLM interactions, suitable for deploying research agents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_platform",
        "model_serving"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/apocas/restai",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "aiaas",
        "llamaindex"
      ],
      "id": 82
    },
    {
      "name": "Argilla",
      "one_line_profile": "Collaboration tool for data labeling and model alignment",
      "detailed_description": "A platform for AI engineers and domain experts to build high-quality datasets for NLP, supporting data labeling, feedback loops, and RLHF workflows essential for scientific model alignment.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "data_labeling",
        "rlhf",
        "dataset_curation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/argilla-io/argilla",
      "help_website": [
        "https://docs.argilla.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-labeling",
        "nlp",
        "rlhf"
      ],
      "id": 83
    },
    {
      "name": "ADK Vertex AI RAG Engine",
      "one_line_profile": "Rapid RAG setup using Google Vertex AI",
      "detailed_description": "A tool for quickly setting up semantic search and RAG agents across documents using Google's ADK and Vertex AI, facilitating the creation of research knowledge assistants.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_setup",
        "semantic_search"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/arjunprabhulal/adk-vertex-ai-rag-engine",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vertex-ai",
        "rag",
        "google-cloud"
      ],
      "id": 84
    },
    {
      "name": "Sycamore",
      "one_line_profile": "LLM-powered search and analytics platform for unstructured data processing",
      "detailed_description": "Sycamore is a framework for building Retrieval Augmented Generation (RAG) applications that specializes in processing complex unstructured data like PDFs and HTML. It provides tools for data cleaning, partitioning, and embedding, making it suitable for scientific literature processing and knowledge extraction.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_processing",
        "pdf_parsing",
        "rag_etl"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aryn-ai/sycamore",
      "help_website": [
        "https://sycamore.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "pdf-parsing",
        "unstructured-data",
        "etl"
      ],
      "id": 85
    },
    {
      "name": "GPT Researcher",
      "one_line_profile": "Autonomous agent for deep research and comprehensive report generation",
      "detailed_description": "GPT Researcher is an autonomous agent designed to conduct deep online research on a given topic. It aggregates information from multiple sources, filters for accuracy, and generates detailed research reports with citations, automating the literature review process.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "citation_tracing",
        "report_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/assafelovic/gpt-researcher",
      "help_website": [
        "https://docs.gptr.dev/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "agent",
        "research-automation",
        "rag",
        "web-scraping"
      ],
      "id": 86
    },
    {
      "name": "Snappy",
      "one_line_profile": "Vision-language model for region-level knowledge retrieval from documents",
      "detailed_description": "Snappy unifies vision-language late interaction with structured OCR to enable precise region-level knowledge retrieval from documents. It is particularly useful for extracting information from complex scientific document layouts.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "ocr",
        "document_retrieval",
        "layout_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/athrael-soju/Snappy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ocr",
        "vision-language",
        "document-understanding"
      ],
      "id": 87
    },
    {
      "name": "SearchTheArxiv",
      "one_line_profile": "Semantic search engine for arXiv machine learning papers",
      "detailed_description": "The codebase powering a semantic search engine specifically for ML papers on arXiv. It enables researchers to find relevant literature using natural language queries, facilitating literature discovery.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_search",
        "semantic_retrieval"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/augustwester/searchthearxiv",
      "help_website": [
        "https://www.searchthearxiv.com"
      ],
      "license": "GPL-3.0",
      "tags": [
        "arxiv",
        "semantic-search",
        "literature-mining"
      ],
      "id": 88
    },
    {
      "name": "GraphRAG-rs",
      "one_line_profile": "High-performance Rust implementation of GraphRAG for knowledge graph construction",
      "detailed_description": "A Rust implementation of GraphRAG that builds knowledge graphs from documents to enable complex reasoning and retrieval. It supports entity extraction and local LLM integration, useful for structuring scientific knowledge.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "rag",
        "entity_extraction"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/automataIA/graphrag-rs",
      "help_website": [],
      "license": null,
      "tags": [
        "graph-rag",
        "rust",
        "knowledge-graph"
      ],
      "id": 89
    },
    {
      "name": "Ragit",
      "one_line_profile": "Git-like pipeline for managing RAG knowledge bases",
      "detailed_description": "Ragit provides a version-controlled, git-like workflow for managing Retrieval-Augmented Generation (RAG) pipelines. It helps researchers manage and iterate on their knowledge bases and retrieval strategies.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_base_management",
        "rag_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Rust",
      "repo_url": "https://github.com/baehyunsol/ragit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "version-control",
        "pipeline"
      ],
      "id": 90
    },
    {
      "name": "VeritasGraph",
      "one_line_profile": "Graph RAG system with verifiable attribution for secure AI",
      "detailed_description": "VeritasGraph is an enterprise-grade Graph RAG system designed for secure, on-premise AI. It focuses on verifiable attribution, ensuring that generated answers can be traced back to specific evidence in the knowledge graph, which is critical for scientific integrity.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag",
        "attribution",
        "knowledge_graph"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/bibinprathap/VeritasGraph",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-rag",
        "attribution",
        "security"
      ],
      "id": 91
    },
    {
      "name": "Megatron-DeepSpeed",
      "one_line_profile": "Large-scale transformer language model training framework",
      "detailed_description": "A deep learning framework for training large-scale transformer language models (like BERT and GPT) using model parallelism. It is a fundamental tool for scientific modeling in NLP and foundation model research.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "model_training",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bigscience-workshop/Megatron-DeepSpeed",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "training",
        "deepspeed",
        "transformer"
      ],
      "id": 92
    },
    {
      "name": "Geovista",
      "one_line_profile": "Cartographic rendering and mesh analytics for earth science",
      "detailed_description": "Geovista is a library for cartographic rendering and mesh analytics, powered by PyVista. It is designed for visualizing and analyzing unstructured grids and meshes commonly found in earth science and oceanography.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "scientific_visualization",
        "geospatial_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bjlittle/geovista",
      "help_website": [
        "https://geovista.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "visualization",
        "earth-science",
        "mesh-analytics"
      ],
      "id": 93
    },
    {
      "name": "BABILong",
      "one_line_profile": "Benchmark for evaluating LLM long-context performance",
      "detailed_description": "BABILong is a benchmark designed to evaluate the performance of Large Language Models (LLMs) on long-context tasks using a needle-in-a-haystack approach. It helps in analyzing model capabilities for processing extensive scientific texts.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/booydar/babilong",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "llm-evaluation",
        "long-context"
      ],
      "id": 94
    },
    {
      "name": "Contextualise",
      "one_line_profile": "Knowledge management tool for organising unstructured information",
      "detailed_description": "Contextualise is a tool for organizing information-heavy projects using Topic Maps. It is suitable for structuring diverse and unstructured data resources, aiding in knowledge management and grounding for research.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_management",
        "data_organization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/brettkromkamp/contextualise",
      "help_website": [
        "https://contextualise.dev/"
      ],
      "license": "MIT",
      "tags": [
        "topic-maps",
        "knowledge-graph",
        "information-organization"
      ],
      "id": 95
    },
    {
      "name": "CDLA",
      "one_line_profile": "Chinese Document Layout Analysis Dataset",
      "detailed_description": "A large-scale dataset for Chinese document layout analysis. It serves as a critical resource for training and evaluating models that parse and structure scientific documents and other literature.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "layout_analysis",
        "dataset"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/buptlihang/CDLA",
      "help_website": [],
      "license": null,
      "tags": [
        "dataset",
        "document-layout",
        "ocr"
      ],
      "id": 96
    },
    {
      "name": "DeerFlow",
      "one_line_profile": "Community-driven Deep Research framework",
      "detailed_description": "DeerFlow is a framework for deep research that combines language models with tools like web search, crawling, and code execution. It is designed to automate complex research tasks and information gathering.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "research_automation",
        "agent_framework",
        "web_crawling"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bytedance/deer-flow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent",
        "deep-research",
        "llm"
      ],
      "id": 97
    },
    {
      "name": "Casibase",
      "one_line_profile": "Open-source AI knowledge base and agent management platform",
      "detailed_description": "Casibase is an enterprise-level AI knowledge base and management platform. It supports RAG, agent-to-agent communication, and integrates with various LLMs, providing a robust infrastructure for managing scientific knowledge and research agents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_base_management",
        "rag_platform",
        "agent_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/casibase/casibase",
      "help_website": [
        "https://casibase.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-base",
        "rag",
        "mcp",
        "agent-platform"
      ],
      "id": 98
    },
    {
      "name": "Langchain-Chatchat",
      "one_line_profile": "Local knowledge-based RAG and Agent application",
      "detailed_description": "A RAG and Agent application based on Langchain and local LLMs (like ChatGLM, Qwen). It enables secure, local processing of knowledge bases, widely used for deploying private research assistants and document analysis systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag",
        "local_deployment",
        "document_qa"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/chatchat-space/Langchain-Chatchat",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "langchain",
        "local-llm",
        "knowledge-base"
      ],
      "id": 99
    },
    {
      "name": "OCRFlux",
      "one_line_profile": "Multimodal toolkit for PDF-to-Markdown conversion and table parsing",
      "detailed_description": "OCRFlux is a toolkit designed to convert PDFs to Markdown, handling complex layouts, tables, and cross-page content. It is essential for preprocessing scientific papers and documents for downstream AI analysis.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "ocr",
        "table_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chatdoc-com/OCRFlux",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ocr",
        "pdf-to-markdown",
        "document-parsing"
      ],
      "id": 100
    },
    {
      "name": "Chonkie",
      "one_line_profile": "Lightweight RAG chunking library for text ingestion",
      "detailed_description": "A lightweight and efficient library designed for RAG pipelines to handle text ingestion and chunking, optimizing the preparation of data for vector retrieval systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "text_chunking",
        "data_ingestion"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chonkie-inc/chonkie",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "chunking",
        "nlp",
        "ingestion"
      ],
      "id": 101
    },
    {
      "name": "Eino",
      "one_line_profile": "CloudWeGo's framework for building LLM and AI agents",
      "detailed_description": "An application development framework in Golang designed for building Large Language Model (LLM) applications and AI agents, providing orchestration capabilities for complex AI workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "workflow_management"
      ],
      "application_level": "framework",
      "primary_language": "Go",
      "repo_url": "https://github.com/cloudwego/eino",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "agent",
        "golang",
        "orchestration"
      ],
      "id": 102
    },
    {
      "name": "CocoIndex",
      "one_line_profile": "Incremental data transformation framework for AI/RAG",
      "detailed_description": "A high-performance data transformation framework designed for AI applications, supporting incremental processing to efficiently manage data pipelines for RAG and vector databases.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_transformation",
        "pipeline_processing"
      ],
      "application_level": "framework",
      "primary_language": "Rust",
      "repo_url": "https://github.com/cocoindex-io/cocoindex",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-processing",
        "rag",
        "incremental-computation"
      ],
      "id": 103
    },
    {
      "name": "Abstracts Search",
      "one_line_profile": "Semantic search engine for academic publications",
      "detailed_description": "A semantic search engine implementation designed to index and retrieve information from a large corpus of academic abstracts (110 million publications), facilitating literature review and discovery.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_retrieval",
        "semantic_search"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/colonelwatch/abstracts-search",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "semantic-search",
        "academic-search",
        "literature-review"
      ],
      "id": 104
    },
    {
      "name": "Grobidmonkey",
      "one_line_profile": "Post-processing utility for GROBID outputs",
      "detailed_description": "A Python package designed to post-process and refine the outputs from GROBID, a machine learning library for extracting information from scholarly documents (PDFs).",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "metadata_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/com3dian/Grobidmonkey",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "grobid",
        "pdf-parsing",
        "scientific-literature"
      ],
      "id": 105
    },
    {
      "name": "Opik",
      "one_line_profile": "Evaluation and monitoring platform for LLM/RAG applications",
      "detailed_description": "A comprehensive platform for debugging, evaluating, and monitoring Large Language Model applications and RAG systems, providing tracing and automated evaluation metrics.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "evaluation",
        "monitoring",
        "rag_debugging"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/comet-ml/opik",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-ops",
        "evaluation",
        "rag",
        "monitoring"
      ],
      "id": 106
    },
    {
      "name": "Open Co-Scientist Agents",
      "one_line_profile": "Implementation of AI Co-Scientist agent architecture",
      "detailed_description": "An open-source implementation of the AI Co-Scientist concept (inspired by Google DeepMind), utilizing LangGraph and GPT Researcher to create agents capable of assisting in scientific research tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "scientific_agent",
        "research_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/conradry/open-coscientist-agents",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent",
        "langgraph",
        "scientific-discovery"
      ],
      "id": 107
    },
    {
      "name": "Coze Loop",
      "one_line_profile": "Lifecycle management and optimization platform for AI agents",
      "detailed_description": "A platform for the full lifecycle management of AI agents, including development, debugging, evaluation, and monitoring, aimed at optimizing agent performance.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_optimization",
        "lifecycle_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/coze-dev/coze-loop",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent-ops",
        "optimization",
        "ai-agent"
      ],
      "id": 108
    },
    {
      "name": "UQLM",
      "one_line_profile": "Uncertainty quantification for LLM hallucination detection",
      "detailed_description": "A Python package for detecting hallucinations in Large Language Models using uncertainty quantification (UQ) methods, enhancing the reliability of LLM outputs in scientific contexts.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "uncertainty_quantification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cvs-health/uqlm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "uncertainty",
        "llm-reliability"
      ],
      "id": 109
    },
    {
      "name": "StageRAG",
      "one_line_profile": "Modular RAG pipeline with multi-stage retrieval",
      "detailed_description": "A blueprint and framework for building production-ready Retrieval-Augmented Generation (RAG) systems, featuring switchable pipelines for speed or precision to minimize hallucinations.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "retrieval_optimization"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/darrencxl0301/StageRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "hallucination-reduction",
        "pipeline"
      ],
      "id": 110
    },
    {
      "name": "Marker",
      "one_line_profile": "High-accuracy PDF to Markdown converter for scientific documents",
      "detailed_description": "A tool powered by deep learning to convert PDF documents (including scientific papers with equations and tables) into Markdown and JSON formats with high accuracy.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "document_conversion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/datalab-to/marker",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pdf-to-markdown",
        "ocr",
        "scientific-document"
      ],
      "id": 111
    },
    {
      "name": "Probable People",
      "one_line_profile": "Parser for unstructured western names",
      "detailed_description": "A Python library for parsing unstructured western name strings into their components, useful for bibliographic analysis and citation processing in scientific literature.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "name_parsing",
        "bibliographic_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/datamade/probablepeople",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "name-parsing",
        "citation-analysis"
      ],
      "id": 112
    },
    {
      "name": "Neural RDF Verbalizer",
      "one_line_profile": "Tool for converting RDF knowledge graphs to text",
      "detailed_description": "A multilingual tool that converts RDF triples (Knowledge Graph data) into natural language text, facilitating the integration of structured knowledge into RAG or evidence chains.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "kg_to_text",
        "verbalization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dbpedia/neural-rdf-verbalizer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rdf",
        "knowledge-graph",
        "nlg"
      ],
      "id": 113
    },
    {
      "name": "Edge SLM",
      "one_line_profile": "On-device RAG pipeline for Small Language Models",
      "detailed_description": "A native implementation of a RAG pipeline optimized for Small Language Models (SLMs) running on resource-constrained edge devices like Android smartphones.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "edge_ai"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/deepsense-ai/edge-slm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "slm",
        "edge-computing",
        "android"
      ],
      "id": 114
    },
    {
      "name": "Hayhooks",
      "one_line_profile": "Deployment tool for Haystack pipelines as REST APIs",
      "detailed_description": "A tool to easily deploy Haystack pipelines as REST APIs and MCP Tools, facilitating the integration of scientific RAG workflows into broader applications.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "pipeline_serving",
        "api_deployment"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepset-ai/hayhooks",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "haystack",
        "deployment",
        "rest-api"
      ],
      "id": 115
    },
    {
      "name": "Haystack",
      "one_line_profile": "Orchestration framework for LLM and RAG applications",
      "detailed_description": "An open-source AI orchestration framework to build customizable, production-ready LLM applications, specializing in RAG, question answering, and semantic search pipelines.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "rag_pipeline"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepset-ai/haystack",
      "help_website": [
        "https://haystack.deepset.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "llm",
        "orchestration",
        "semantic-search"
      ],
      "id": 116
    },
    {
      "name": "Haystack Core Integrations",
      "one_line_profile": "Official integrations for the Haystack framework",
      "detailed_description": "A collection of additional components and document stores that extend the capabilities of the Haystack framework, enabling integration with various vector databases and models.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "integration",
        "component_extension"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepset-ai/haystack-core-integrations",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "haystack",
        "plugins",
        "integrations"
      ],
      "id": 117
    },
    {
      "name": "Haystack Experimental",
      "one_line_profile": "Experimental components for the Haystack NLP framework",
      "detailed_description": "A collection of experimental nodes, pipelines, and features for the Haystack framework, enabling advanced RAG and QA workflows for research agents before they are merged into the core library.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "rag_pipeline"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepset-ai/haystack-experimental",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "nlp",
        "experimental",
        "haystack"
      ],
      "id": 118
    },
    {
      "name": "GPT-4o Research Assistant",
      "one_line_profile": "Automated academic paper research and summarization agent",
      "detailed_description": "A research agent tool that leverages GPT-4o to search ArXiv for academic papers, download them, extract content, and generate summaries, automating the literature review process.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_search",
        "summarization",
        "paper_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/echohive42/GPT-4o-Research-assistant",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arxiv",
        "research-assistant",
        "summarization",
        "agent"
      ],
      "id": 119
    },
    {
      "name": "ScienceBeam Parser",
      "one_line_profile": "PDF to XML conversion tool for scientific publications",
      "detailed_description": "A set of tools designed to convert scientific PDF documents into structured XML formats, facilitating text mining, metadata extraction, and literature analysis workflows.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "document_conversion",
        "metadata_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/elifesciences/sciencebeam-parser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-parsing",
        "xml",
        "scientific-publishing",
        "document-conversion"
      ],
      "id": 120
    },
    {
      "name": "Sphere",
      "one_line_profile": "Web-scale retrieval library for knowledge-intensive NLP",
      "detailed_description": "A retrieval library and dataset designed for knowledge-intensive NLP tasks, enabling efficient search over massive web corpora for grounding, verification, and evidence retrieval in scientific contexts.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "retrieval",
        "grounding",
        "knowledge_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/Sphere",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "retrieval",
        "nlp",
        "knowledge-base",
        "grounding"
      ],
      "id": 121
    },
    {
      "name": "Nougat",
      "one_line_profile": "Neural Optical Understanding for Academic Documents",
      "detailed_description": "A Transformer-based model and tool for converting scientific PDF documents into Markdown, specifically designed to handle complex layouts, formulas, and tables in academic papers.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "ocr",
        "document_understanding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/nougat",
      "help_website": [
        "https://facebookresearch.github.io/nougat/"
      ],
      "license": "MIT",
      "tags": [
        "pdf-to-markdown",
        "ocr",
        "scientific-papers",
        "transformer"
      ],
      "id": 122
    },
    {
      "name": "LangExtract",
      "one_line_profile": "LLM-based structured information extraction with precise source grounding",
      "detailed_description": "A Python library designed to extract structured data from unstructured text using Large Language Models (LLMs). It features a mechanism for precise source grounding, allowing researchers to verify extracted facts against the original text, which is critical for evidence-based scientific literature mining and knowledge graph construction.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "information_extraction",
        "grounding",
        "evidence_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google/langextract",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "information-extraction",
        "grounding",
        "rag"
      ],
      "id": 123
    },
    {
      "name": "Gretel Synthetics",
      "one_line_profile": "Synthetic data generation library for privacy-preserving machine learning",
      "detailed_description": "A library for generating synthetic structured and unstructured data using recurrent neural networks and differential privacy techniques. It enables researchers to create safe, shareable versions of sensitive datasets (e.g., medical records, survey data) for training machine learning models without compromising privacy.",
      "domains": [
        "AI5",
        "Data"
      ],
      "subtask_category": [
        "data_generation",
        "synthetic_data",
        "privacy_preserving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gretelai/gretel-synthetics",
      "help_website": [
        "https://gretel.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "synthetic-data",
        "differential-privacy",
        "nlp",
        "data-generation"
      ],
      "id": 124
    },
    {
      "name": "MCPAdapt",
      "one_line_profile": "Adapter for Model Context Protocol (MCP) tools in agent frameworks",
      "detailed_description": "A library that enables AI agents built with various frameworks (like LangChain or LlamaIndex) to access and invoke tools compatible with the Model Context Protocol (MCP). This facilitates the integration of diverse external tools and data sources into scientific research agent workflows.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "tool_invocation",
        "agent_integration",
        "interoperability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/grll/mcpadapt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "agent",
        "tool-use",
        "llm"
      ],
      "id": 125
    },
    {
      "name": "WARC-GPT",
      "one_line_profile": "RAG pipeline for querying Web Archive (WARC) collections",
      "detailed_description": "An experimental retrieval-augmented generation (RAG) tool developed by Harvard Library Innovation Lab. It is designed to index and query Web Archive (WARC) files, allowing researchers to explore, retrieve, and synthesize information from historical web data with proper source attribution.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag",
        "web_archiving",
        "information_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/harvard-lil/warc-gpt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "warc",
        "web-archives",
        "rag",
        "digital-humanities"
      ],
      "id": 126
    },
    {
      "name": "PDF Document Layout Analysis",
      "one_line_profile": "Service for segmenting and classifying PDF document elements",
      "detailed_description": "A machine learning-powered service that analyzes the layout of PDF documents to identify and classify elements such as text blocks, titles, tables, and images. It provides a structured representation of PDF content, which is essential for downstream tasks like scientific literature mining, citation extraction, and knowledge base construction.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "layout_analysis",
        "document_segmentation"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/huridocs/pdf-document-layout-analysis",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf-parsing",
        "layout-analysis",
        "ocr",
        "document-processing"
      ],
      "id": 127
    },
    {
      "name": "pdf-text-extraction",
      "one_line_profile": "Automated text extraction from PDF files using layout analysis outputs",
      "detailed_description": "A tool designed to extract text from PDF files by leveraging the segmentation and classification capabilities of the pdf-document-layout-analysis service, automating the text extraction process for document processing workflows.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "text_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Makefile",
      "repo_url": "https://github.com/huridocs/pdf-text-extraction",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf-extraction",
        "layout-analysis",
        "document-processing"
      ],
      "id": 128
    },
    {
      "name": "vision-parse",
      "one_line_profile": "PDF to Markdown converter using Vision LLMs",
      "detailed_description": "A tool that leverages Vision Large Language Models to parse PDF documents and convert them into Markdown format, facilitating the ingestion of scientific literature and documents into RAG pipelines.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "document_ingestion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/iamarunbrahma/vision-parse",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-to-markdown",
        "vision-llm",
        "ocr"
      ],
      "id": 129
    },
    {
      "name": "SuperKnowa",
      "one_line_profile": "Enterprise RAG pipeline builder",
      "detailed_description": "A framework for building Enterprise Retrieval Augmented Generation (RAG) pipelines, allowing users to plug in components like retrievers and LLMs to tackle generative AI use cases, suitable for knowledge management and evidence retrieval.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "knowledge_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ibm-self-serve-assets/SuperKnowa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "pipeline",
        "enterprise-ai"
      ],
      "id": 130
    },
    {
      "name": "RAGFlow",
      "one_line_profile": "Retrieval-Augmented Generation engine with agent capabilities",
      "detailed_description": "An open-source RAG engine that combines retrieval-augmented generation with agent capabilities to create a context layer for LLMs, supporting complex document parsing and evidence-based generation workflows.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_engine",
        "document_parsing",
        "agent_workflow"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/infiniflow/ragflow",
      "help_website": [
        "https://ragflow.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "agent",
        "document-processing"
      ],
      "id": 131
    },
    {
      "name": "SAC3",
      "one_line_profile": "Semantic-aware Cross-check Consistency for hallucination detection",
      "detailed_description": "A tool for reliable hallucination detection in black-box language models via Semantic-aware Cross-check Consistency, useful for grounding and verifying generated content in scientific RAG systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "grounding"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/intuit/sac3",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination-detection",
        "consistency-check",
        "llm-reliability"
      ],
      "id": 132
    },
    {
      "name": "Nougat",
      "one_line_profile": "OCR model for transcribing scientific PDFs to Markdown",
      "detailed_description": "An OCR model designed specifically to transcribe scientific PDF documents into Markdown format, handling mathematical formulas and complex layouts typical in academic literature.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "scientific_ocr"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/inuwamobarak/nougat",
      "help_website": [],
      "license": null,
      "tags": [
        "ocr",
        "scientific-pdf",
        "markdown-conversion"
      ],
      "id": 133
    },
    {
      "name": "OntologyRAG",
      "one_line_profile": "Biomedical code mapping with RAG and Ontology Knowledge Graphs",
      "detailed_description": "A Retrieval-Augmented Generation tool leveraging Ontology Knowledge Graphs and In-context-learning for biomedical code mapping, enhancing the accuracy of medical entity retrieval and normalization.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "biomedical_rag",
        "ontology_mapping"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/iqvianlp/ontologyRAG",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "biomedical",
        "ontology",
        "rag"
      ],
      "id": 134
    },
    {
      "name": "layout_analysis",
      "one_line_profile": "Chinese document layout detection using YOLOv8",
      "detailed_description": "A tool for detecting the layout of Chinese document images using YOLOv8, facilitating the structural analysis of documents for downstream tasks like OCR and RAG.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jiangnanboy/layout_analysis",
      "help_website": [],
      "license": null,
      "tags": [
        "layout-analysis",
        "yolov8",
        "document-structure"
      ],
      "id": 135
    },
    {
      "name": "layout_analysis4j",
      "one_line_profile": "Java implementation of document layout detection",
      "detailed_description": "A Java-based implementation for document layout detection using YOLOv8, providing layout analysis capabilities for Java environments in document processing pipelines.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_parsing"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/jiangnanboy/layout_analysis4j",
      "help_website": [],
      "license": null,
      "tags": [
        "java",
        "layout-analysis",
        "document-processing"
      ],
      "id": 136
    },
    {
      "name": "pdf-to-markdown",
      "one_line_profile": "Python tool to convert PDF files to Markdown",
      "detailed_description": "A Python utility to convert PDF documents into Markdown format, enabling the extraction of structured text from scientific papers for use in RAG and text mining applications.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "text_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/johnlinp/pdf-to-markdown",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "pdf-conversion",
        "markdown",
        "text-extraction"
      ],
      "id": 137
    },
    {
      "name": "local-rag",
      "one_line_profile": "Local RAG ingestion and retrieval tool",
      "detailed_description": "A tool for ingesting files for Retrieval Augmented Generation (RAG) using open-source LLMs locally, ensuring data privacy while enabling semantic search and question answering on document sets.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_ingestion",
        "local_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jonfairbanks/local-rag",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "rag",
        "local-llm",
        "privacy"
      ],
      "id": 138
    },
    {
      "name": "magicsearch",
      "one_line_profile": "Hybrid full-text and semantic search engine",
      "detailed_description": "A search engine combining full-text and semantic search capabilities, suitable for building retrieval systems in scientific knowledge bases.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "semantic_search",
        "retrieval"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/joschan21/magicsearch",
      "help_website": [],
      "license": null,
      "tags": [
        "hybrid-search",
        "semantic-search",
        "retrieval"
      ],
      "id": 139
    },
    {
      "name": "TRACE",
      "one_line_profile": "Constructing knowledge-grounded reasoning chains for RAG",
      "detailed_description": "A framework for constructing knowledge-grounded reasoning chains (TRACE) to enhance Retrieval-Augmented Generation, improving the evidence traceability and reasoning capabilities of LLMs.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "evidence_chain",
        "reasoning_grounding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jyfang6/trace",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "reasoning-chain",
        "evidence-grounding"
      ],
      "id": 140
    },
    {
      "name": "FLARE",
      "one_line_profile": "Forward-Looking Active Retrieval-augmented generation",
      "detailed_description": "An implementation of Forward-Looking Active Retrieval-augmented generation (FLARE), a method to actively retrieve information during the generation process to reduce hallucinations and improve factual accuracy.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "active_retrieval",
        "rag_method"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jzbjyb/FLARE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "active-retrieval",
        "rag",
        "generation"
      ],
      "id": 141
    },
    {
      "name": "pdf-to-markdown-js",
      "one_line_profile": "JavaScript PDF to Markdown converter",
      "detailed_description": "A JavaScript-based tool for converting PDF documents to Markdown, facilitating the extraction of text and structure from scientific papers for web-based RAG applications.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "text_extraction"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/jzillmann/pdf-to-markdown",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-conversion",
        "javascript",
        "text-extraction"
      ],
      "id": 142
    },
    {
      "name": "SearchAnything",
      "one_line_profile": "Semantic local search engine powered by AI",
      "detailed_description": "A semantic local search engine that uses AI models to index and retrieve information from local documents, serving as a personal knowledge base retrieval tool.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "semantic_search",
        "local_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kaijiezhu11/SearchAnything",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-search",
        "local-search",
        "ai-search"
      ],
      "id": 143
    },
    {
      "name": "byte-vision",
      "one_line_profile": "Privacy-first document intelligence and RAG platform",
      "detailed_description": "A document intelligence platform that transforms static documents into an interactive, searchable knowledge base using Elasticsearch and RAG capabilities, featuring OCR processing and document parsing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_intelligence",
        "rag_platform"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/kbrisso/byte-vision",
      "help_website": [],
      "license": null,
      "tags": [
        "document-intelligence",
        "rag",
        "ocr"
      ],
      "id": 144
    },
    {
      "name": "GROBID",
      "one_line_profile": "Machine learning software for extracting information from scholarly documents",
      "detailed_description": "GROBID (GeneRation Of BIbliographic Data) is a machine learning library for extracting, parsing, and restructuring raw documents such as PDF into structured XML/TEI encoded documents with a focus on technical and scientific publications.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "information_extraction",
        "metadata_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/kermitt2/grobid",
      "help_website": [
        "https://grobid.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "pdf-parsing",
        "scholarly-articles",
        "tei-xml",
        "citation-extraction"
      ],
      "id": 145
    },
    {
      "name": "grobid-astro",
      "one_line_profile": "GROBID module for extracting astronomical entities from scholarly documents",
      "detailed_description": "A specialized module for GROBID designed to recognize and extract astronomical entities (such as celestial objects, events, and locations) from scientific literature.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "entity_extraction",
        "text_mining"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/kermitt2/grobid-astro",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "astronomy",
        "ner",
        "grobid-module"
      ],
      "id": 146
    },
    {
      "name": "grobid-ner",
      "one_line_profile": "Named-Entity Recogniser for scientific text based on GROBID",
      "detailed_description": "A module for GROBID that performs Named Entity Recognition (NER) on scientific texts, leveraging the structural analysis capabilities of the main GROBID engine.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "entity_extraction",
        "ner"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/kermitt2/grobid-ner",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ner",
        "nlp",
        "scientific-text"
      ],
      "id": 147
    },
    {
      "name": "paperqa-zotero",
      "one_line_profile": "LLM-based question answering tool for Zotero libraries",
      "detailed_description": "A tool that integrates Large Language Models with Zotero to enable question answering and information retrieval directly from a user's scientific document library.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "qa"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lejacobroy/paperqa-zotero",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "zotero",
        "rag",
        "literature-review"
      ],
      "id": 148
    },
    {
      "name": "grobid-quantities",
      "one_line_profile": "GROBID extension for identifying and normalizing physical quantities",
      "detailed_description": "A module for GROBID that extracts physical quantities (measurements, units, values) from scientific text and normalizes them for structured analysis.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "entity_extraction",
        "data_normalization"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/lfoppiano/grobid-quantities",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "physical-quantities",
        "measurement-extraction",
        "grobid-module"
      ],
      "id": 149
    },
    {
      "name": "grobid-superconductors",
      "one_line_profile": "GROBID module for superconductor material and properties extraction",
      "detailed_description": "A specialized GROBID module designed to extract superconductor materials, their classes, and associated properties (like critical temperature) from scientific papers.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "entity_extraction",
        "materials_informatics"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/lfoppiano/grobid-superconductors",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "superconductors",
        "materials-science",
        "text-mining"
      ],
      "id": 150
    },
    {
      "name": "material-parsers",
      "one_line_profile": "Parsers for material names and formula",
      "detailed_description": "A collection of tools and scripts for parsing material names and chemical formulas, initially developed for the Grobid Superconductor project.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_processing",
        "materials_informatics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lfoppiano/material-parsers",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "materials-parsing",
        "chemical-formula"
      ],
      "id": 151
    },
    {
      "name": "structure-vision",
      "one_line_profile": "Viewer for document structures extracted by GROBID",
      "detailed_description": "A visualization tool designed to inspect and verify the structured data (XML/TEI) extracted by GROBID from PDF documents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "visualization",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lfoppiano/structure-vision",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "grobid",
        "document-structure"
      ],
      "id": 152
    },
    {
      "name": "supercon2",
      "one_line_profile": "Curation interface for the SuperCon database",
      "detailed_description": "A web-based platform for curating experimental data for the SuperCon database, featuring an enhanced document viewer and tools for validating automatically extracted data.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_curation",
        "database_management"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/lfoppiano/supercon2",
      "help_website": [],
      "license": null,
      "tags": [
        "curation",
        "superconductors",
        "database"
      ],
      "id": 153
    },
    {
      "name": "Aria (ai-research-assistant)",
      "one_line_profile": "AI Research Assistant powered by LLMs",
      "detailed_description": "Aria is an AI-powered research assistant tool that helps researchers read, summarize, and extract information from scientific papers using Large Language Models.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "summarization"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/lifan0127/ai-research-assistant",
      "help_website": [
        "https://aria.ace.sh/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "research-assistant",
        "literature-review",
        "llm-agent"
      ],
      "id": 154
    },
    {
      "name": "LlamaFarm",
      "one_line_profile": "Orchestration tool to deploy AI models, agents, and RAG pipelines locally or remotely",
      "detailed_description": "A deployment and orchestration framework that simplifies the management of AI models, agents, vector databases, and RAG pipelines, facilitating the setup of local or remote AI research environments.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "deployment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/llama-farm/llamafarm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "agent-deployment",
        "pipeline-orchestration"
      ],
      "id": 155
    },
    {
      "name": "LLMWare",
      "one_line_profile": "Unified framework for building enterprise RAG pipelines with specialized small models",
      "detailed_description": "A framework designed for building retrieval-augmented generation (RAG) pipelines, emphasizing the use of small, specialized models for secure and efficient enterprise-grade knowledge retrieval and processing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "knowledge_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/llmware-ai/llmware",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "small-models",
        "enterprise-search"
      ],
      "id": 156
    },
    {
      "name": "Pix2Text-nougat-texify-GUI",
      "one_line_profile": "GUI tool for offline LaTeX OCR using Pix2Text, Nougat, and Texify models",
      "detailed_description": "A graphical interface for running offline Optical Character Recognition (OCR) specifically optimized for converting images of mathematical formulas and scientific text into LaTeX code using multiple backend models.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "ocr",
        "formula_extraction",
        "pdf_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/longchentian/Pix2Text-nougat-texify-GUI",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "latex-ocr",
        "scientific-document-parsing",
        "gui"
      ],
      "id": 157
    },
    {
      "name": "remarks",
      "one_line_profile": "Extractor for annotations and highlights from PDFs marked with reMarkable tablets",
      "detailed_description": "A tool to extract highlights, scribbles, and annotations from PDF and EPUB documents marked on reMarkable tablets, exporting them to formats like Markdown or PDF, useful for literature review and evidence gathering.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "annotation_extraction",
        "literature_review"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucasrla/remarks",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pdf-annotation",
        "remarkable",
        "knowledge-extraction"
      ],
      "id": 158
    },
    {
      "name": "FaviComp",
      "one_line_profile": "Familiarity-aware evidence compression for Retrieval Augmented Generation",
      "detailed_description": "Implementation of a method for compressing retrieved evidence in RAG systems based on familiarity, optimizing the context window and relevance for language models. Associated with EMNLP 2025 Findings.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "evidence_compression",
        "rag_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/luka-group/FaviComp",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "evidence-compression",
        "nlp"
      ],
      "id": 159
    },
    {
      "name": "MrCoD",
      "one_line_profile": "Multi-hop evidence retrieval for cross-document relation extraction",
      "detailed_description": "A tool for retrieving evidence across multiple documents to support relation extraction tasks, specifically designed to handle multi-hop reasoning scenarios in information extraction.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "evidence_retrieval",
        "relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/luka-group/MrCoD",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multi-hop-retrieval",
        "relation-extraction",
        "evidence-chain"
      ],
      "id": 160
    },
    {
      "name": "FRAG",
      "one_line_profile": "Context-aware generation framework from large unstructured knowledge sources",
      "detailed_description": "A flexible and efficient RAG framework designed to generate responses by leveraging large-scale unstructured knowledge sources with context awareness.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag",
        "knowledge_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lumpenspace/FRAG",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "unstructured-data",
        "generation"
      ],
      "id": 161
    },
    {
      "name": "Open WebUI Pipeline for RAGFlow",
      "one_line_profile": "Integration pipeline connecting Open WebUI with RAGFlow agents",
      "detailed_description": "A middleware tool that enables Open WebUI to utilize RAGFlow's agent capabilities, facilitating the creation of knowledge-base driven intelligent dialogue systems with a graphical interface.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "workflow_integration",
        "agent_interface"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/luyilong2015/open-webui-pipeline-for-ragflow",
      "help_website": [],
      "license": "Unlicense",
      "tags": [
        "ragflow",
        "open-webui",
        "pipeline"
      ],
      "id": 162
    },
    {
      "name": "Wenzhou-Pack-Degradation-Data",
      "one_line_profile": "Dataset for battery pack degradation analysis and prognosis",
      "detailed_description": "A dataset containing randomized battery data for transfer-driven prognosis from battery cells to packs, supporting research in energy storage and degradation modeling.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "dataset",
        "battery_prognostics"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/lvdongzhen/Wenzhou-Pack-Degradation-Data",
      "help_website": [],
      "license": null,
      "tags": [
        "battery-data",
        "degradation",
        "energy-storage"
      ],
      "id": 163
    },
    {
      "name": "Wenzhou-Randomized-Battery-Data",
      "one_line_profile": "Dataset for battery cumulative lifetime prognostics",
      "detailed_description": "A dataset bridging laboratory and real-life scenarios for battery lifetime prediction, supporting data-driven research in electrochemistry and energy systems.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "dataset",
        "battery_lifetime"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/lvdongzhen/Wenzhou-Randomized-Battery-Data",
      "help_website": [],
      "license": null,
      "tags": [
        "battery-data",
        "lifetime-prediction",
        "dataset"
      ],
      "id": 164
    },
    {
      "name": "iFEM",
      "one_line_profile": "MATLAB package for adaptive finite element methods",
      "detailed_description": "A MATLAB software package providing robust and efficient codes for adaptive finite element methods (FEM) on unstructured simplicial grids in 2D and 3D, used for numerical simulations.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "finite_element_method",
        "numerical_simulation"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/lyc102/ifem",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "fem",
        "matlab",
        "pde-solver"
      ],
      "id": 165
    },
    {
      "name": "Reference Feature Extraction",
      "one_line_profile": "Reference implementations of feature extraction algorithms in Matlab/Octave",
      "detailed_description": "A collection of reference implementations for various feature extraction algorithms, useful for signal processing and data analysis tasks.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "feature_extraction",
        "signal_processing"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/m-r-s/reference-feature-extraction",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "feature-extraction",
        "signal-processing",
        "matlab"
      ],
      "id": 166
    },
    {
      "name": "RagRabbit",
      "one_line_profile": "Self-hosted AI search and RAG platform for websites",
      "detailed_description": "An open-source, self-hosted solution for implementing AI-powered search and Retrieval-Augmented Generation (RAG) on websites, facilitating knowledge retrieval.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_platform",
        "semantic_search"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/madarco/ragrabbit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "search-engine",
        "self-hosted"
      ],
      "id": 167
    },
    {
      "name": "HaMI",
      "one_line_profile": "Robust hallucination detection in LLMs via adaptive token selection",
      "detailed_description": "Implementation of a method for detecting hallucinations in Large Language Models using adaptive token selection, enhancing the reliability of generative models in scientific contexts.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mala-lab/HaMI",
      "help_website": [],
      "license": null,
      "tags": [
        "hallucination-detection",
        "llm-evaluation",
        "reliability"
      ],
      "id": 168
    },
    {
      "name": "Direct RAG Learning",
      "one_line_profile": "Direct Retrieval-augmented Optimization for synergizing knowledge selection and LMs",
      "detailed_description": "Code for 'Direct Retrieval-augmented Optimization', a method to jointly optimize knowledge selection and language model generation, improving RAG performance.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_optimization",
        "knowledge_selection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mangopy/direct-rag-learning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "optimization",
        "retrieval"
      ],
      "id": 169
    },
    {
      "name": "TinySearch",
      "one_line_profile": "Semantic search engine using BERT embeddings",
      "detailed_description": "A lightweight semantic search engine implementation leveraging BERT embeddings for retrieving relevant documents based on semantic similarity.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "semantic_search",
        "retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/manishpatel005/tinysearch",
      "help_website": [],
      "license": null,
      "tags": [
        "bert",
        "semantic-search",
        "embeddings"
      ],
      "id": 170
    },
    {
      "name": "OrKa",
      "one_line_profile": "Orchestrator Kit for Agentic Reasoning and transparent traceability",
      "detailed_description": "A modular AI orchestration system that transforms LLMs into composable agents capable of reasoning, fact-checking, and constructing answers with transparent traceability, useful for evidence-based scientific inquiry.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "agent_orchestration",
        "reasoning",
        "traceability"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/marcosomma/orka-reasoning",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "agent",
        "reasoning",
        "traceability"
      ],
      "id": 171
    },
    {
      "name": "RELiC",
      "one_line_profile": "Retrieving Evidence for Literary Claims",
      "detailed_description": "Codebase for retrieving evidence to support claims, specifically designed for literary analysis but applicable to general evidence retrieval tasks in RAG systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "evidence_retrieval",
        "claim_verification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/martiansideofthemoon/relic-retrieval",
      "help_website": [
        "https://relic.cs.umass.edu"
      ],
      "license": "MIT",
      "tags": [
        "retrieval",
        "evidence",
        "nlp"
      ],
      "id": 172
    },
    {
      "name": "PhysioNet ECG Segmentation Data",
      "one_line_profile": "ECG data for deep learning segmentation examples",
      "detailed_description": "A dataset of human electrocardiogram (ECG) data sourced from PhysioNet, prepared for signal processing and deep learning segmentation tasks.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "dataset",
        "ecg_segmentation"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/mathworks/physionet_ECG_segmentation",
      "help_website": [],
      "license": null,
      "tags": [
        "ecg",
        "dataset",
        "signal-processing"
      ],
      "id": 173
    },
    {
      "name": "CoNLI",
      "one_line_profile": "Framework for ungrounded hallucination detection and reduction",
      "detailed_description": "A plug-and-play framework designed to detect and reduce ungrounded hallucinations in language models, improving the factual accuracy of generated content.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "fact_checking"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/CoNLI_hallucination",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "nli",
        "grounding"
      ],
      "id": 174
    },
    {
      "name": "Document Knowledge Mining Solution Accelerator",
      "one_line_profile": "Accelerator for extracting summaries and entities from unstructured documents",
      "detailed_description": "A solution accelerator built on Azure OpenAI and Document Intelligence to process unstructured, multi-modal documents, extracting metadata, entities, and summaries for search and RAG applications.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_mining",
        "information_extraction",
        "rag"
      ],
      "application_level": "workflow",
      "primary_language": "C#",
      "repo_url": "https://github.com/microsoft/Document-Knowledge-Mining-Solution-Accelerator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-mining",
        "document-intelligence",
        "azure"
      ],
      "id": 175
    },
    {
      "name": "HaDes",
      "one_line_profile": "Token-level reference-free hallucination detection",
      "detailed_description": "A tool for detecting hallucinations in generated text at the token level without requiring reference texts, useful for quality control in RAG outputs.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/HaDes",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "token-level-detection",
        "nlp"
      ],
      "id": 176
    },
    {
      "name": "GraphRAG",
      "one_line_profile": "Modular graph-based Retrieval-Augmented Generation system",
      "detailed_description": "A system that enhances RAG by using knowledge graphs to structure and retrieve information, enabling more complex reasoning and better context understanding from unstructured data.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag",
        "knowledge_graph",
        "retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/graphrag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-rag",
        "knowledge-graph",
        "retrieval"
      ],
      "id": 177
    },
    {
      "name": "MarkItDown",
      "one_line_profile": "Tool for converting office documents and files to Markdown",
      "detailed_description": "A utility to convert various file formats (PDF, Word, Excel, etc.) into Markdown, facilitating the ingestion of scientific documents into LLMs and RAG pipelines.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_conversion",
        "data_ingestion"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/markitdown",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "markdown",
        "document-conversion",
        "pdf-parsing"
      ],
      "id": 178
    },
    {
      "name": "Micronaire",
      "one_line_profile": "RAG evaluation pipeline for Semantic Kernel",
      "detailed_description": "An evaluation pipeline designed to assess the performance and quality of RAG systems built with Semantic Kernel, ensuring reliability in retrieval and generation.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "quality_control"
      ],
      "application_level": "tool",
      "primary_language": "C#",
      "repo_url": "https://github.com/microsoft/micronaire",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation",
        "rag",
        "semantic-kernel"
      ],
      "id": 179
    },
    {
      "name": "OpenScraping C#",
      "one_line_profile": "Library to turn unstructured HTML into structured data using XPath",
      "detailed_description": "A library for extracting structured data from unstructured HTML pages using JSON configuration and XPath rules, useful for harvesting scientific data from web sources.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "web_scraping",
        "data_extraction"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/microsoft/openscraping-lib-csharp",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "scraping",
        "html-parsing",
        "data-extraction"
      ],
      "id": 180
    },
    {
      "name": "Table Transformer",
      "one_line_profile": "Deep learning model for extracting tables from unstructured documents",
      "detailed_description": "A deep learning-based tool (TATR) for detecting and extracting tabular data from PDFs and images, essential for parsing scientific papers and reports.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "table_extraction",
        "document_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/table-transformer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "table-extraction",
        "pdf-parsing",
        "deep-learning"
      ],
      "id": 181
    },
    {
      "name": "grobidclient",
      "one_line_profile": "Go client for GROBID scientific document parsing service",
      "detailed_description": "A Go client library for interacting with GROBID, a machine learning library for extracting, parsing, and restructuring raw documents such as PDF publications into structured XML/TEI.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "pdf_extraction"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/miku/grobidclient",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "grobid",
        "pdf-parsing",
        "scientific-literature"
      ],
      "id": 182
    },
    {
      "name": "map2gpt",
      "one_line_profile": "Semantic search engine for textual content from PDFs and Wikipedia",
      "detailed_description": "A search tool leveraging NLP models to provide semantic search capabilities over textual content from sources like PDF files and Wikipedia, facilitating information retrieval.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "semantic_search",
        "pdf_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/milkymap/map2gpt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-search",
        "pdf",
        "nlp"
      ],
      "id": 183
    },
    {
      "name": "RAGTune",
      "one_line_profile": "Tool for tuning and evaluating RAG pipelines",
      "detailed_description": "A library designed to tune and evaluate Retrieval-Augmented Generation (RAG) pipelines, aiming to optimize the performance of retrieval and generation components.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_optimization",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/misbahsy/RAGTune",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "tuning",
        "evaluation"
      ],
      "id": 184
    },
    {
      "name": "llm-scraper",
      "one_line_profile": "Library to convert webpages into structured data using LLMs",
      "detailed_description": "A TypeScript library that leverages Large Language Models to scrape and parse web content into structured formats, useful for data collection in research workflows.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "web_scraping",
        "data_extraction"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/mishushakov/llm-scraper",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scraping",
        "llm",
        "structured-data"
      ],
      "id": 185
    },
    {
      "name": "baguetter",
      "one_line_profile": "Flexible search engine library for benchmarking retrieval methods",
      "detailed_description": "A Python library for implementing, testing, and benchmarking sparse, dense, and hybrid search retrieval methods, designed for efficiency and hackability.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "information_retrieval",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mixedbread-ai/baguetter",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "search-engine",
        "retrieval",
        "benchmarking"
      ],
      "id": 186
    },
    {
      "name": "MLflow",
      "one_line_profile": "Platform for end-to-end machine learning lifecycle management",
      "detailed_description": "An open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry, widely used in scientific ML workflows.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "experiment_tracking",
        "model_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/mlflow/mlflow",
      "help_website": [
        "https://mlflow.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "experiment-tracking",
        "model-registry"
      ],
      "id": 187
    },
    {
      "name": "YOLOv10-Document-Layout-Analysis",
      "one_line_profile": "YOLOv10 model trained for document layout analysis",
      "detailed_description": "A repository providing YOLOv10 models trained on the DocLayNet dataset for analyzing and segmenting document layouts, essential for PDF parsing pipelines.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_layout_analysis",
        "pdf_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/moured/YOLOv10-Document-Layout-Analysis",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "yolov10",
        "document-analysis",
        "doclaynet"
      ],
      "id": 188
    },
    {
      "name": "YOLOv11-Document-Layout-Analysis",
      "one_line_profile": "YOLOv11 model trained for document layout analysis",
      "detailed_description": "A repository providing YOLOv11 models trained on the DocLayNet dataset for analyzing and segmenting document layouts, serving as an upgraded tool for PDF parsing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_layout_analysis",
        "pdf_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/moured/YOLOv11-Document-Layout-Analysis",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "yolov11",
        "document-analysis",
        "doclaynet"
      ],
      "id": 189
    },
    {
      "name": "langchain4j-aideepin-admin",
      "one_line_profile": "Java-based RAG platform with knowledge base and search",
      "detailed_description": "A Java implementation of a Retrieval-Augmented Generation (RAG) system, featuring knowledge base management and search capabilities, suitable for enterprise or research data management.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "knowledge_base"
      ],
      "application_level": "platform",
      "primary_language": "Vue",
      "repo_url": "https://github.com/moyangzhan/langchain4j-aideepin-admin",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "java",
        "knowledge-base"
      ],
      "id": 190
    },
    {
      "name": "pdf2md",
      "one_line_profile": "Tool to convert PDF documents to Markdown",
      "detailed_description": "A browser-based tool and library for converting PDF documents into Markdown format, facilitating the ingestion of scientific literature into text processing pipelines.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "format_conversion"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/mrmps/pdf2md",
      "help_website": [],
      "license": null,
      "tags": [
        "pdf-to-markdown",
        "converter",
        "pdf-parsing"
      ],
      "id": 191
    },
    {
      "name": "CitationExtractor",
      "one_line_profile": "Tool to extract canonical references from text",
      "detailed_description": "A utility for parsing text to identify and extract canonical citation references, supporting bibliometric analysis and evidence tracing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "citation_extraction",
        "reference_parsing"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/mromanello/CitationExtractor",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "citation-extraction",
        "bibliography",
        "text-mining"
      ],
      "id": 192
    },
    {
      "name": "pdf3md",
      "one_line_profile": "Web application for converting PDFs to formatted Markdown",
      "detailed_description": "A modern web application designed to convert PDF documents into clean, formatted Markdown text, useful for extracting content from scientific papers.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "format_conversion"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/murtaza-nasir/pdf3md",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "pdf",
        "markdown",
        "converter"
      ],
      "id": 193
    },
    {
      "name": "ASSESS",
      "one_line_profile": "Automatic Semantic Search Engine for Suitable Standards",
      "detailed_description": "A semantic search engine developed by NASA JPL to identify suitable standards, leveraging semantic retrieval techniques.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "semantic_search",
        "information_retrieval"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/nasa-jpl/ASSESS",
      "help_website": [],
      "license": null,
      "tags": [
        "semantic-search",
        "nasa",
        "standards"
      ],
      "id": 194
    },
    {
      "name": "llm-graph-builder",
      "one_line_profile": "Tool to construct Neo4j graphs from unstructured data using LLMs",
      "detailed_description": "A tool that utilizes Large Language Models to extract entities and relationships from unstructured text and construct knowledge graphs in Neo4j.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "unstructured_data_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/neo4j-labs/llm-graph-builder",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "neo4j",
        "llm"
      ],
      "id": 195
    },
    {
      "name": "pgrag",
      "one_line_profile": "Postgres extension for end-to-end RAG pipelines",
      "detailed_description": "A PostgreSQL extension that enables the creation of end-to-end Retrieval-Augmented Generation (RAG) pipelines directly within the database.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "vector_search"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/neondatabase/pgrag",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "postgres",
        "rag",
        "vector-search"
      ],
      "id": 196
    },
    {
      "name": "rag",
      "one_line_profile": "RAG implementation using txtai for search and LLMs",
      "detailed_description": "A repository providing Retrieval Augmented Generation (RAG) capabilities powered by txtai, allowing for the combination of search and LLMs to extract insights from data.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/neuml/rag",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "txtai",
        "search"
      ],
      "id": 197
    },
    {
      "name": "nixiesearch",
      "one_line_profile": "Hybrid search engine combining text and semantic search",
      "detailed_description": "A hybrid search engine that integrates traditional text search with semantic search capabilities, suitable for building advanced retrieval systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "information_retrieval",
        "search_engine"
      ],
      "application_level": "service",
      "primary_language": "Scala",
      "repo_url": "https://github.com/nixiesearch/nixiesearch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "search-engine",
        "hybrid-search",
        "semantic-search"
      ],
      "id": 198
    },
    {
      "name": "KG2RAG",
      "one_line_profile": "Knowledge Graph-Guided Retrieval Augmented Generation",
      "detailed_description": "Implementation of a Knowledge Graph-Guided RAG framework, enhancing retrieval augmented generation with structured knowledge from graphs.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "knowledge_graph"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nju-websoft/KG2RAG",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "rag",
        "knowledge-graph",
        "retrieval"
      ],
      "id": 199
    },
    {
      "name": "verbaflow",
      "one_line_profile": "Neural Language Model library for Go",
      "detailed_description": "A library implementing neural language models in the Go programming language, enabling NLP inference tasks within Go-based workflows.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "nlp_inference"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/nlpodyssey/verbaflow",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "nlp",
        "go",
        "language-model"
      ],
      "id": 200
    },
    {
      "name": "xapian-haystack",
      "one_line_profile": "Xapian backend for the Haystack search framework",
      "detailed_description": "A backend adapter allowing the use of the Xapian search engine within the Haystack framework, facilitating flexible information retrieval setups.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "search_backend",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/notanumber/xapian-haystack",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "haystack",
        "xapian",
        "search"
      ],
      "id": 201
    },
    {
      "name": "THRED",
      "one_line_profile": "Neural response generation model with context-aware topical attention",
      "detailed_description": "Implementation of a neural response generation model that utilizes context-aware topical attention, serving as a tool for dialogue system research and development.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "dialogue_generation",
        "nlp_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nouhadziri/THRED",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dialogue-generation",
        "nlp",
        "attention-mechanism"
      ],
      "id": 202
    },
    {
      "name": "hallucination_probes",
      "one_line_profile": "Real-time detection of hallucinated entities in long-form generation",
      "detailed_description": "A library for detecting hallucinations in Large Language Model outputs, specifically focusing on entity consistency in long-form text generation. It provides probing mechanisms to evaluate the factual reliability of AI-generated content.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/obalcells/hallucination_probes",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "llm",
        "reliability",
        "nlp"
      ],
      "id": 203
    },
    {
      "name": "arucogen",
      "one_line_profile": "Online generator for ArUco markers used in computer vision",
      "detailed_description": "A tool to generate ArUco markers, which are synthetic square markers composed of a wide black border and an inner binary matrix. These are essential for camera pose estimation, tracking, and calibration in robotics and computer vision research.",
      "domains": [
        "Computer Vision",
        "Robotics"
      ],
      "subtask_category": [
        "data_generation",
        "calibration"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/okalachev/arucogen",
      "help_website": [
        "http://chev.me/arucogen/"
      ],
      "license": "MIT",
      "tags": [
        "aruco",
        "computer-vision",
        "robotics",
        "markers"
      ],
      "id": 204
    },
    {
      "name": "gpt-2-output-dataset",
      "one_line_profile": "Dataset of GPT-2 outputs for detection and bias research",
      "detailed_description": "A dataset containing outputs generated by the GPT-2 model, intended for research into AI text detection, bias analysis, and linguistic properties of generated text. Essential for developing hallucination detection and content provenance tools.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "dataset",
        "bias_analysis",
        "detection_research"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/openai/gpt-2-output-dataset",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dataset",
        "gpt-2",
        "ai-safety",
        "hallucination-research"
      ],
      "id": 205
    },
    {
      "name": "DocLayout-YOLO",
      "one_line_profile": "Document layout analysis tool using YOLO",
      "detailed_description": "A specialized computer vision tool for analyzing the layout of documents (PDFs, papers). It detects and classifies document elements (text blocks, tables, figures), which is a critical preprocessing step for scientific literature mining and RAG systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "layout_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/opendatalab/DocLayout-YOLO",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "pdf-parsing",
        "ocr",
        "layout-analysis",
        "rag"
      ],
      "id": 206
    },
    {
      "name": "MinerU",
      "one_line_profile": "High-quality PDF to Markdown/JSON converter for LLM workflows",
      "detailed_description": "A comprehensive toolchain for extracting content from complex scientific documents (PDFs). It handles formulas, tables, and layout preservation, converting them into LLM-friendly formats (Markdown/JSON) to support RAG and Agentic workflows.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "data_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/opendatalab/MinerU",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "pdf-to-markdown",
        "scientific-literature",
        "etl",
        "rag"
      ],
      "id": 207
    },
    {
      "name": "openmovement",
      "one_line_profile": "Open source hardware and software for movement sensing",
      "detailed_description": "A complete ecosystem (firmware, software, hardware designs) for miniature movement sensors (accelerometers). Used in clinical and behavioral research to collect and analyze physical activity data.",
      "domains": [
        "Biomedical Engineering",
        "Health Science"
      ],
      "subtask_category": [
        "data_acquisition",
        "sensor_processing"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/openmovementproject/openmovement",
      "help_website": [
        "https://openmovement.dev/"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "sensors",
        "wearables",
        "data-collection",
        "firmware"
      ],
      "id": 208
    },
    {
      "name": "open-semantic-search",
      "one_line_profile": "Integrated search engine and text analysis platform for document collections",
      "detailed_description": "An open-source research tool for searching and analyzing large document collections. It integrates ETL, OCR, Named Entity Recognition (NER), and semantic search, making it suitable for managing and exploring scientific literature archives.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "information_retrieval",
        "text_mining"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/opensemanticsearch/open-semantic-search",
      "help_website": [
        "https://www.opensemanticsearch.org/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "semantic-search",
        "etl",
        "ocr",
        "ner"
      ],
      "id": 209
    },
    {
      "name": "crrf-det",
      "one_line_profile": "PDF content and table extraction tool for climate finance data",
      "detailed_description": "A tool developed by OS-Climate for extracting structured data from PDF documents, specifically designed for climate-related financial disclosures. It features visual layout analysis and table extraction.",
      "domains": [
        "Climate Science",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_extraction",
        "data_structuring"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/os-climate/crrf-det",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "climate-data",
        "pdf-extraction",
        "ocr",
        "os-climate"
      ],
      "id": 210
    },
    {
      "name": "openalex-pdf-parser",
      "one_line_profile": "PDF parser for OpenAlex powered by GROBID",
      "detailed_description": "A utility to parse scientific PDFs using GROBID, designed to feed structured data into the OpenAlex dataset. It extracts metadata and full text from research papers.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_parsing",
        "metadata_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ourresearch/openalex-pdf-parser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "openalex",
        "grobid",
        "pdf-parsing",
        "bibliometrics"
      ],
      "id": 211
    },
    {
      "name": "aruco_ros",
      "one_line_profile": "ROS wrappers for ArUco marker detection",
      "detailed_description": "Provides ROS (Robot Operating System) integration for the ArUco augmented reality marker detector library. Essential for robotics research involving visual localization and object tracking.",
      "domains": [
        "Robotics",
        "Computer Vision"
      ],
      "subtask_category": [
        "pose_estimation",
        "tracking"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/pal-robotics/aruco_ros",
      "help_website": [
        "http://wiki.ros.org/aruco_ros"
      ],
      "license": "MIT",
      "tags": [
        "ros",
        "aruco",
        "robotics",
        "localization"
      ],
      "id": 212
    },
    {
      "name": "papercast",
      "one_line_profile": "Pipeline tool for processing and audio-converting technical papers",
      "detailed_description": "A modular pipeline tool for processing scientific documents from sources like arXiv. It uses GROBID for parsing and LangChain for processing, enabling workflows like summarizing papers or converting them to audio podcasts.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_processing",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/papercast-dev/papercast",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arxiv",
        "grobid",
        "paper-processing",
        "accessibility"
      ],
      "id": 213
    },
    {
      "name": "VideoHallucer",
      "one_line_profile": "Benchmark for hallucination detection in large video-language models",
      "detailed_description": "A comprehensive benchmark dataset and evaluation framework designed to detect hallucinations in Large Video-Language Models (LVLMs). It aids in assessing the factual consistency of AI models in multimodal scientific contexts.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "benchmark",
        "hallucination_detection"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/patrick-tssn/VideoHallucer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "video-llm",
        "hallucination",
        "benchmark",
        "multimodal"
      ],
      "id": 214
    },
    {
      "name": "Paper-to-Code",
      "one_line_profile": "Automates conversion of research paper concepts into code",
      "detailed_description": "A tool that leverages LLMs to interpret research papers and generate corresponding implementation code. It serves as a research agent to bridge the gap between theoretical publications and practical experimentation.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "code_generation",
        "literature_implementation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/pedroosodrac/Paper-to-Code",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "research-agent",
        "paper-implementation",
        "llm",
        "automation"
      ],
      "id": 215
    },
    {
      "name": "geodict",
      "one_line_profile": "Library for extracting location information from unstructured text",
      "detailed_description": "A Python library designed to identify and extract geographic location names from text. Useful for geospatial analysis in social sciences, earth sciences, and epidemiology to structure unstructured data.",
      "domains": [
        "Earth Science",
        "Social Science"
      ],
      "subtask_category": [
        "entity_extraction",
        "geocoding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/petewarden/geodict",
      "help_website": [],
      "license": null,
      "tags": [
        "geospatial",
        "nlp",
        "location-extraction"
      ],
      "id": 216
    },
    {
      "name": "Canopy",
      "one_line_profile": "Retrieval Augmented Generation (RAG) framework and context engine",
      "detailed_description": "A framework and context engine powered by Pinecone that handles the complexity of RAG pipelines, including chunking, embedding, and retrieval, enabling the construction of research agents and evidence-based AI applications.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_framework",
        "information_retrieval"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/pinecone-io/canopy",
      "help_website": [
        "https://github.com/pinecone-io/canopy"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "retrieval",
        "pinecone",
        "context-engine"
      ],
      "id": 217
    },
    {
      "name": "Korvus",
      "one_line_profile": "Search SDK unifying RAG pipeline in Postgres",
      "detailed_description": "A search SDK that unifies the entire RAG pipeline (embedding, search, generation) into a single database query within Postgres, facilitating efficient management of scientific knowledge bases.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "vector_search"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/postgresml/korvus",
      "help_website": [
        "https://postgresml.org/docs/korvus"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "postgres",
        "search-sdk",
        "vector-database"
      ],
      "id": 218
    },
    {
      "name": "SelfCheckGPT",
      "one_line_profile": "Hallucination detection for generative LLMs",
      "detailed_description": "A zero-resource black-box tool for detecting hallucinations in Generative Large Language Models, critical for ensuring the factual accuracy and grounding of AI-generated scientific content.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "fact_checking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/potsawee/selfcheckgpt",
      "help_website": [
        "https://pypi.org/project/selfcheckgpt/"
      ],
      "license": "MIT",
      "tags": [
        "hallucination-detection",
        "llm",
        "reliability",
        "grounding"
      ],
      "id": 219
    },
    {
      "name": "YOLO-DocLayNet",
      "one_line_profile": "Document Layout Analysis models trained on DocLayNet",
      "detailed_description": "YOLO models trained on the DocLayNet dataset for performing document layout analysis, enabling the structural parsing of scientific papers and documents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_layout_analysis",
        "pdf_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ppaanngggg/yolo-doclaynet",
      "help_website": [
        "https://github.com/ppaanngggg/yolo-doclaynet"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "document-layout-analysis",
        "yolo",
        "pdf-parsing",
        "doclaynet"
      ],
      "id": 220
    },
    {
      "name": "QMiner",
      "one_line_profile": "Real-time large-scale data analytics platform",
      "detailed_description": "An analytic platform for processing real-time large-scale streams containing structured and unstructured data, suitable for scientific data mining and sensor stream analysis.",
      "domains": [
        "AI5",
        "AI4"
      ],
      "subtask_category": [
        "data_mining",
        "stream_analytics"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/qminer/qminer",
      "help_website": [
        "http://qminer.github.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "data-mining",
        "stream-processing",
        "analytics"
      ],
      "id": 221
    },
    {
      "name": "Eynollah",
      "one_line_profile": "Document Layout Analysis tool",
      "detailed_description": "A tool for document layout analysis that performs segmentation and structure recognition, useful for extracting content from scientific literature and historical documents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_layout_analysis",
        "pdf_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/qurator-spk/eynollah",
      "help_website": [
        "https://pypi.org/project/eynollah/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "document-layout-analysis",
        "ocr",
        "segmentation"
      ],
      "id": 222
    },
    {
      "name": "RAG Citation",
      "one_line_profile": "Citation generation for RAG systems",
      "detailed_description": "A library that enhances Retrieval-Augmented Generation (RAG) by automatically generating relevant citations for AI-generated content, ensuring credibility and evidence tracking in scientific agents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "citation_generation",
        "evidence_grounding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rahulanand1103/rag-citation",
      "help_website": [
        "https://github.com/rahulanand1103/rag-citation"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "citation",
        "evidence",
        "grounding"
      ],
      "id": 223
    },
    {
      "name": "Llama-Researcher",
      "one_line_profile": "Autonomous research assistant for online literature review",
      "detailed_description": "A research assistant agent built with LlamaIndex Workflows that performs online research on a given topic, automating the process of literature discovery and summarization.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "autonomous_agent"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/rsrohan99/Llama-Researcher",
      "help_website": [
        "https://github.com/rsrohan99/Llama-Researcher"
      ],
      "license": null,
      "tags": [
        "research-agent",
        "llamaindex",
        "literature-review"
      ],
      "id": 224
    },
    {
      "name": "LlamaIndexTS",
      "one_line_profile": "Data framework for LLM applications (TypeScript)",
      "detailed_description": "The TypeScript version of LlamaIndex, a data framework for building LLM applications, enabling the ingestion, structuring, and accessing of private or domain-specific data (including scientific texts) for RAG and agents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "rag_framework"
      ],
      "application_level": "framework",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/run-llama/LlamaIndexTS",
      "help_website": [
        "https://ts.llamaindex.ai/"
      ],
      "license": "MIT",
      "tags": [
        "llamaindex",
        "rag",
        "typescript",
        "agent-framework"
      ],
      "id": 225
    },
    {
      "name": "LlamaHub",
      "one_line_profile": "Library of data loaders for LLMs",
      "detailed_description": "A community library of data loaders for LlamaIndex and LangChain, facilitating the ingestion of diverse data formats (including scientific papers, PDFs, databases) into LLM workflows.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_ingestion",
        "connector"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/run-llama/llama-hub",
      "help_website": [
        "https://llamahub.ai/"
      ],
      "license": "MIT",
      "tags": [
        "data-loaders",
        "llamaindex",
        "integration",
        "pdf-loader"
      ],
      "id": 226
    },
    {
      "name": "LlamaIndex",
      "one_line_profile": "Data framework for connecting custom data sources to large language models",
      "detailed_description": "LlamaIndex is a data framework for building LLM-based applications. It provides tools for data ingestion, indexing (including vector stores), and retrieval (RAG), enabling researchers to connect their private scientific data (papers, PDFs, databases) to LLMs for evidence-based query and analysis.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "retrieval_augmented_generation",
        "data_indexing",
        "evidence_retrieval"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/run-llama/llama_index",
      "help_website": [
        "https://docs.llamaindex.ai/"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "llm-agent",
        "data-framework",
        "vector-database",
        "knowledge-retrieval"
      ],
      "id": 227
    },
    {
      "name": "Markdrop",
      "one_line_profile": "PDF to Markdown converter with layout analysis for RAG pipelines",
      "detailed_description": "Markdrop is a Python package designed to convert PDF documents into Markdown format while preserving layout structures such as tables and images. It uses LLM clients to generate descriptive text for extracted visual elements, making it specifically suitable for preprocessing scientific literature for Retrieval-Augmented Generation (RAG) systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "document_layout_analysis",
        "data_preprocessing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shoryasethia/markdrop",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pdf-to-markdown",
        "rag-preprocessing",
        "layout-analysis",
        "table-extraction"
      ],
      "id": 228
    },
    {
      "name": "Code Interpreter API",
      "one_line_profile": "Open source implementation of the ChatGPT Code Interpreter for agentic workflows",
      "detailed_description": "Code Interpreter API provides a sandbox environment for LLMs to execute Python code, enabling agents to perform data analysis, visualization, and complex calculations. It serves as a critical tool-calling component in scientific agent workflows where code execution is required for reasoning and data processing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "code_execution",
        "tool_calling",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shroominic/codeinterpreter-api",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "code-interpreter",
        "agent-tool",
        "sandbox",
        "python-execution"
      ],
      "id": 229
    },
    {
      "name": "STaRK",
      "one_line_profile": "Benchmark for LLM retrieval on textual and relational knowledge bases",
      "detailed_description": "STaRK is a benchmarking framework designed to evaluate the retrieval capabilities of Large Language Models (LLMs) over semi-structured knowledge bases that combine textual and relational data. It provides datasets and evaluation metrics essential for developing robust RAG systems in scientific domains where data is often hybrid.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "benchmarking",
        "retrieval_evaluation",
        "knowledge_base_retrieval"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/snap-stanford/stark",
      "help_website": [
        "https://stark-benchmark.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "benchmark",
        "retrieval",
        "knowledge-base",
        "rag-evaluation"
      ],
      "id": 230
    },
    {
      "name": "SUQL",
      "one_line_profile": "Conversational search framework over structured and unstructured data",
      "detailed_description": "SUQL (Structured and Unstructured Query Language) is a framework that extends SQL to support conversational search over hybrid data sources. It enables LLMs to query databases that contain both structured fields and unstructured text, facilitating complex evidence retrieval and grounding in scientific databases.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "retrieval",
        "query_language",
        "hybrid_search"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanford-oval/suql",
      "help_website": [
        "https://suql.stanford.edu/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "conversational-search",
        "hybrid-retrieval",
        "sql-extension",
        "rag"
      ],
      "id": 231
    },
    {
      "name": "GraphGPT",
      "one_line_profile": "Tool for extrapolating knowledge graphs from unstructured text using LLMs",
      "detailed_description": "A library that leverages GPT-3 to convert unstructured text into structured knowledge graphs, facilitating evidence chain construction and relationship extraction from scientific literature.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "graph_construction"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/varunshenoy/GraphGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "nlp",
        "unstructured-text"
      ],
      "id": 232
    },
    {
      "name": "Verba",
      "one_line_profile": "Retrieval Augmented Generation (RAG) chatbot platform powered by Weaviate",
      "detailed_description": "An open-source RAG application designed to ingest data (including documents) and perform semantic search and question answering, serving as a platform for literature review and knowledge retrieval.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_system",
        "semantic_search"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/weaviate/Verba",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "rag",
        "chatbot",
        "weaviate",
        "knowledge-retrieval"
      ],
      "id": 233
    },
    {
      "name": "Knowledge Table",
      "one_line_profile": "Tool for extracting structured data from unstructured documents",
      "detailed_description": "A package designed to simplify the extraction and exploration of structured data from unstructured documents (like PDFs), aiding in the creation of evidence chains and knowledge bases.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_extraction",
        "document_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/whyhow-ai/knowledge-table",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "unstructured-data",
        "extraction",
        "rag"
      ],
      "id": 234
    },
    {
      "name": "E2M",
      "one_line_profile": "Universal file converter to Markdown for LLM ingestion",
      "detailed_description": "A tool that converts various file types (doc, docx, epub, html, pdf, etc.) into Markdown, specifically designed to prepare data for RAG systems and LLM processing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "format_conversion"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/wisupai/e2m",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "markdown",
        "converter",
        "rag-preparation",
        "pdf-parsing"
      ],
      "id": 235
    },
    {
      "name": "ThinkRAG",
      "one_line_profile": "Local RAG system for knowledge base QA",
      "detailed_description": "A Retrieval-Augmented Generation system designed to run locally, enabling researchers to build and query local knowledge bases from their documents securely.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_system",
        "knowledge_base"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wzdavid/ThinkRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "local-rag",
        "llm",
        "knowledge-base"
      ],
      "id": 236
    },
    {
      "name": "gpt_pdf_md",
      "one_line_profile": "PDF to Markdown converter using GPT-4V",
      "detailed_description": "A tool that leverages GPT-4V vision capabilities to convert PDF documents into Markdown, including image extraction, suitable for parsing complex scientific papers.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "document_conversion"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/yachty66/gpt_pdf_md",
      "help_website": [],
      "license": null,
      "tags": [
        "pdf-to-markdown",
        "gpt-4v",
        "ocr"
      ],
      "id": 237
    },
    {
      "name": "LEANN",
      "one_line_profile": "Efficient and private RAG application for personal devices",
      "detailed_description": "A RAG application optimized for storage savings and privacy, allowing researchers to run fast and accurate retrieval on their personal document collections.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_system",
        "personal_knowledge_base"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yichuan-w/LEANN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "privacy",
        "local-llm"
      ],
      "id": 238
    },
    {
      "name": "llm-based-ocr",
      "one_line_profile": "High-accuracy PDF-to-Markdown OCR API using LLMs",
      "detailed_description": "An OCR tool that uses Large Language Models with vision capabilities to extract text and layout from PDFs, converting them to Markdown for downstream analysis.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "ocr_parsing",
        "document_digitization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yigitkonur/llm-based-ocr",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ocr",
        "pdf",
        "llm-vision"
      ],
      "id": 239
    },
    {
      "name": "Extractous",
      "one_line_profile": "Fast unstructured data extraction library",
      "detailed_description": "A high-performance library written in Rust for extracting text and metadata from unstructured data sources, supporting data ingestion pipelines for scientific RAG.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_extraction",
        "text_processing"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/yobix-ai/extractous",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rust",
        "extraction",
        "unstructured-data"
      ],
      "id": 240
    },
    {
      "name": "Faster-Nougat",
      "one_line_profile": "Optimized local implementation of the Nougat PDF parser",
      "detailed_description": "An efficient implementation of the Nougat model, specifically designed for parsing academic PDFs (including formulas and tables) into Markdown locally.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "scientific_document_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhuzilin/faster-nougat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nougat",
        "pdf-parser",
        "academic-papers"
      ],
      "id": 241
    },
    {
      "name": "EasyDetect",
      "one_line_profile": "Hallucination detection framework for Large Language Models",
      "detailed_description": "A framework designed to detect hallucinations in LLM outputs, essential for verifying the factuality and reliability of evidence chains in scientific RAG systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "factuality_check"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/EasyDetect",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "llm-evaluation",
        "factuality"
      ],
      "id": 242
    }
  ]
}