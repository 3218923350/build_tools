{
  "generated_at": "2025-12-17T03:17:55.767686+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "AI6",
      "leaf_cluster_name": "可复现运行时与加速生态（容器/HPC）",
      "domain": "Infra/HPC",
      "typical_objects": "jobs/artifacts",
      "task_chain": "环境→调度→缓存→追踪→加速",
      "tool_form": "容器/调度 + 追踪/成本"
    },
    "unit": {
      "unit_id": "AI6-02",
      "unit_name": "任务调度与作业管理（HPC）",
      "target_scale": "150–350",
      "coverage_tools": "schedulers、job runners"
    },
    "search": {
      "target_candidates": 350,
      "queries": [
        "[GH] Kueue",
        "[GH] Flux Framework",
        "[GH] Submitit",
        "[GH] Dask",
        "[GH] Ray",
        "[GH] Volcano",
        "[GH] HTCondor",
        "[GH] PBS Pro",
        "[GH] Slurm",
        "[GH] hpc job scheduler",
        "[GH] workload manager",
        "[GH] batch system",
        "[GH] cluster resource manager",
        "[GH] distributed task queue",
        "[GH] job submission tool",
        "[GH] slurm wrapper",
        "[GH] gpu scheduling",
        "[GH] parallel job runner",
        "[GH] meta-scheduler",
        "[GH] task orchestration",
        "[GH] kubernetes batch",
        "[GH] mpi launcher",
        "[WEB] open source hpc workload manager github",
        "[WEB] distributed job scheduler for ai github",
        "[WEB] slurm submission tools python github",
        "[WEB] kubernetes batch scheduling framework github",
        "[WEB] high performance computing task runner github"
      ],
      "total_candidates": 1226,
      "tool_candidates": 734,
      "final_tools": 247
    }
  },
  "tools": [
    {
      "name": "DAGEE",
      "one_line_profile": "Directed Acyclic Graph Execution Engine for concurrent task scheduling on CPUs/GPUs",
      "detailed_description": "A C++ library developed by AMD Research that enables programmers to express computation and data movement as task graphs, scheduled concurrently and asynchronously on heterogeneous architectures (CPUs and GPUs).",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "task_execution",
        "runtime_optimization"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/AMDResearch/DAGEE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hpc",
        "task-graph",
        "gpu-scheduling",
        "amd"
      ],
      "id": 1
    },
    {
      "name": "lidar_IMU_calib",
      "one_line_profile": "Targetless Calibration of LiDAR-IMU System Based on Continuous-time Batch Estimation",
      "detailed_description": "A tool for calibrating LiDAR and IMU systems using continuous-time batch estimation, essential for sensor fusion in robotics and autonomous data collection systems.",
      "domains": [
        "AI6",
        "Robotics"
      ],
      "subtask_category": [
        "calibration",
        "sensor_fusion"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/APRIL-ZJU/lidar_IMU_calib",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "calibration",
        "lidar",
        "imu",
        "sensor-fusion"
      ],
      "id": 2
    },
    {
      "name": "gpushare-scheduler-extender",
      "one_line_profile": "GPU Sharing Scheduler for Kubernetes Cluster",
      "detailed_description": "A Kubernetes scheduler extender that enables fine-grained GPU sharing among pods, allowing multiple tasks to share a single GPU resource, optimizing utilization for AI/HPC workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "resource_scheduling",
        "gpu_sharing"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/AliyunContainerService/gpushare-scheduler-extender",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "gpu-scheduling",
        "hpc",
        "resource-management"
      ],
      "id": 3
    },
    {
      "name": "aicsimageio",
      "one_line_profile": "Image Reading, Metadata Conversion, and Image Writing for Microscopy Images",
      "detailed_description": "A Python library developed by the Allen Institute for Cell Science for reading, writing, and converting microscopy image data and metadata, supporting various scientific file formats.",
      "domains": [
        "AI6",
        "Bioinformatics"
      ],
      "subtask_category": [
        "image_io",
        "data_conversion"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AllenCellModeling/aicsimageio",
      "help_website": [
        "https://allencellmodeling.github.io/aicsimageio/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "microscopy",
        "bioimage",
        "image-io",
        "metadata"
      ],
      "id": 4
    },
    {
      "name": "daskqueue",
      "one_line_profile": "Distributed persistent Task Queue running on Dask",
      "detailed_description": "A distributed task queue built on top of Dask, providing a persistent queue mechanism for scheduling and executing tasks in scientific computing workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "task_scheduling",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AmineDiro/daskqueue",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dask",
        "task-queue",
        "distributed-computing",
        "python"
      ],
      "id": 5
    },
    {
      "name": "batch-shipyard",
      "one_line_profile": "Simplify HPC and Batch workloads on Azure",
      "detailed_description": "A tool to provision and execute batch-style and HPC workloads on Azure Batch using Docker containers, simplifying the deployment of scientific applications in the cloud.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "batch_processing",
        "cloud_hpc"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Azure/batch-shipyard",
      "help_website": [
        "https://batch-shipyard.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "azure",
        "hpc",
        "batch-processing",
        "docker"
      ],
      "id": 6
    },
    {
      "name": "cyclecloud-lsf",
      "one_line_profile": "Enable Spectrum LSF job scheduler in Azure CycleCloud HPC clusters",
      "detailed_description": "An official Azure project providing the necessary configuration and scripts to integrate the IBM Spectrum LSF job scheduler with Azure CycleCloud, enabling hybrid or cloud-native HPC scheduling.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "scheduler_integration",
        "cluster_management"
      ],
      "application_level": "platform",
      "primary_language": "HTML",
      "repo_url": "https://github.com/Azure/cyclecloud-lsf",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lsf",
        "hpc",
        "azure",
        "scheduler"
      ],
      "id": 7
    },
    {
      "name": "ggVolcano",
      "one_line_profile": "R package for creating volcano plots from differential expression data",
      "detailed_description": "An R package designed to generate customizable volcano plots for visualizing differential gene expression analysis results, including gradient colors and GO term annotation.",
      "domains": [
        "Bioinformatics"
      ],
      "subtask_category": [
        "visualization",
        "differential_expression"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/BioSenior/ggVolcano",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bioinformatics",
        "visualization",
        "r",
        "volcano-plot"
      ],
      "id": 8
    },
    {
      "name": "cobamp",
      "one_line_profile": "Constraint-based modeling framework for pathway analysis concepts",
      "detailed_description": "A Python framework for constraint-based modeling of metabolic networks, specifically focused on the enumeration of pathway analysis concepts in systems biology.",
      "domains": [
        "Bioinformatics",
        "Systems Biology"
      ],
      "subtask_category": [
        "metabolic_modeling",
        "pathway_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/BioSystemsUM/cobamp",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "systems-biology",
        "metabolic-networks",
        "constraint-based-modeling"
      ],
      "id": 9
    },
    {
      "name": "pyvolcans",
      "one_line_profile": "Python tool to identify analogue volcanoes",
      "detailed_description": "A Python tool developed by the British Geological Survey to identify analogue volcanoes based on various geological and physical parameters, aiding in volcanology research.",
      "domains": [
        "Geology"
      ],
      "subtask_category": [
        "data_analysis",
        "classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/BritishGeologicalSurvey/pyvolcans",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "volcanology",
        "geology",
        "analogue-identification"
      ],
      "id": 10
    },
    {
      "name": "scrapi",
      "one_line_profile": "Data processing pipeline for research metadata harvesting",
      "detailed_description": "A data processing pipeline developed by the Center for Open Science that schedules and runs content harvesters to normalize research metadata from various sources into a unified dataset.",
      "domains": [
        "AI6",
        "Open Science"
      ],
      "subtask_category": [
        "data_harvesting",
        "metadata_normalization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/CenterForOpenScience/scrapi",
      "help_website": [
        "https://osf.io/share/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "open-science",
        "metadata",
        "harvesting",
        "pipeline"
      ],
      "id": 11
    },
    {
      "name": "go-socker",
      "one_line_profile": "Wrapper for secure running of Docker containers on Slurm",
      "detailed_description": "A Go-based wrapper tool that enables the secure execution of Docker containers within a Slurm HPC environment, bridging the gap between containerized workflows and traditional batch schedulers.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "container_runtime",
        "job_submission"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/China-HPC/go-socker",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "docker",
        "hpc",
        "container"
      ],
      "id": 12
    },
    {
      "name": "Toil",
      "one_line_profile": "Scalable, efficient, cross-platform workflow engine for scientific pipelines",
      "detailed_description": "Toil is a workflow engine written in pure Python that supports widely used scientific workflow languages like WDL and CWL. It is designed to run scalable scientific pipelines on various platforms, including commercial clouds (AWS, Google, Azure) and high-performance computing (HPC) environments.",
      "domains": [
        "AI6",
        "AI6-02",
        "Bioinformatics"
      ],
      "subtask_category": [
        "workflow_management",
        "pipeline_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/DataBiosphere/toil",
      "help_website": [
        "https://toil.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "wdl",
        "cwl",
        "hpc",
        "cloud-computing"
      ],
      "id": 13
    },
    {
      "name": "HyperGBM",
      "one_line_profile": "Full pipeline AutoML tool for tabular data",
      "detailed_description": "HyperGBM is an AutoML tool designed for tabular data that integrates data cleaning, preprocessing, feature generation, and model selection into a unified pipeline. It leverages gradient boosting models and hyperparameter optimization to automate the construction of machine learning models for scientific and industrial data analysis.",
      "domains": [
        "AI4S",
        "Machine Learning"
      ],
      "subtask_category": [
        "automl",
        "model_training",
        "tabular_data_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DataCanvasIO/HyperGBM",
      "help_website": [
        "https://hypergbm.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "automl",
        "tabular-data",
        "gradient-boosting",
        "hyperparameter-optimization"
      ],
      "id": 14
    },
    {
      "name": "Bolt",
      "one_line_profile": "Batch job submission script generator for HPC environments",
      "detailed_description": "Bolt is a tool developed by EPCC to automate the production of batch job submission scripts. It simplifies the process of configuring and submitting jobs to high-performance computing clusters by generating the necessary scheduler directives.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "hpc_utility"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/EPCCed/bolt",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "hpc",
        "batch-jobs",
        "script-generation",
        "epcc"
      ],
      "id": 15
    },
    {
      "name": "cubo",
      "one_line_profile": "On-Demand Earth System Data Cubes generation tool",
      "detailed_description": "cubo is a Python library for creating Earth System Data Cubes (ESDCs) on demand. It facilitates the access and processing of geospatial data from various sources (like Sentinel imagery) into structured data cubes suitable for scientific analysis and machine learning applications.",
      "domains": [
        "Earth Science",
        "Geospatial"
      ],
      "subtask_category": [
        "data_access",
        "data_cube_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ESDS-Leipzig/cubo",
      "help_website": [
        "https://cubo.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "earth-observation",
        "data-cubes",
        "geospatial",
        "sentinel"
      ],
      "id": 16
    },
    {
      "name": "VSM",
      "one_line_profile": "Volcano and Seismic source Modeling tool",
      "detailed_description": "VSM (Volcano and Seismic source Modeling) is a Python tool for modeling volcanic and seismic sources. It allows researchers to invert deformation data to estimate source parameters, supporting various source geometries used in geophysics.",
      "domains": [
        "Geophysics",
        "Seismology"
      ],
      "subtask_category": [
        "modeling",
        "inversion",
        "source_characterization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/EliTras/VSM",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "volcanology",
        "seismology",
        "geophysics",
        "modeling"
      ],
      "id": 17
    },
    {
      "name": "EngineCL",
      "one_line_profile": "Heterogeneous computing scheduling and usability framework",
      "detailed_description": "EngineCL is a framework designed to improve usability and performance in heterogeneous computing environments. It acts as a scheduler and wrapper for OpenCL, managing device selection and kernel execution across different hardware accelerators.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "task_scheduling",
        "heterogeneous_computing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/EngineCL/EngineCL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "opencl",
        "hpc",
        "scheduling",
        "heterogeneous-computing"
      ],
      "id": 18
    },
    {
      "name": "Daft",
      "one_line_profile": "High-performance distributed data engine for multimodal AI workloads",
      "detailed_description": "Daft is a distributed query engine written in Rust, designed for ETL, analytics, and data processing for multimodal AI datasets. It provides a Python DataFrame API and is optimized for handling large-scale scientific and AI data workloads.",
      "domains": [
        "AI Infra",
        "Data Science"
      ],
      "subtask_category": [
        "data_processing",
        "etl",
        "distributed_computing"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/Eventual-Inc/Daft",
      "help_website": [
        "https://www.getdaft.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dataframe",
        "distributed-computing",
        "etl",
        "multimodal-ai"
      ],
      "id": 19
    },
    {
      "name": "simple_gpu_scheduler",
      "one_line_profile": "Lightweight scheduler for managing GPU jobs",
      "detailed_description": "A simple Python-based scheduler designed to manage and queue jobs on machines with multiple GPUs. It allows users to submit commands that require GPU resources and executes them as devices become available.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ExpectationMax/simple_gpu_scheduler",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "gpu",
        "scheduling",
        "queue",
        "python"
      ],
      "id": 20
    },
    {
      "name": "FedML",
      "one_line_profile": "Unified library for distributed training and federated learning",
      "detailed_description": "FedML is a comprehensive library for federated learning and distributed training. It includes a cross-cloud scheduler (FedML Launch) that enables running AI jobs across diverse GPU clouds and on-premise clusters, facilitating large-scale scientific ML experiments.",
      "domains": [
        "AI6",
        "AI6-02",
        "Machine Learning"
      ],
      "subtask_category": [
        "distributed_training",
        "federated_learning",
        "job_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/FedML-AI/FedML",
      "help_website": [
        "https://doc.fedml.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "federated-learning",
        "distributed-systems",
        "scheduler",
        "edge-computing"
      ],
      "id": 21
    },
    {
      "name": "GENIE Generator",
      "one_line_profile": "Universal neutrino event generator and simulation tool",
      "detailed_description": "The GENIE Generator is a large-scale physics simulation tool used by neutrino experiments. It simulates neutrino interactions across a wide energy range (MeV–PeV) and handles flux generation, detector geometry, and event reweighting.",
      "domains": [
        "Physics",
        "High Energy Physics"
      ],
      "subtask_category": [
        "simulation",
        "event_generation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/GENIE-MC/Generator",
      "help_website": [
        "http://www.genie-mc.org/"
      ],
      "license": null,
      "tags": [
        "neutrino",
        "physics-simulation",
        "monte-carlo",
        "particle-physics"
      ],
      "id": 22
    },
    {
      "name": "gpu-topo-aware",
      "one_line_profile": "GPU topology-aware job scheduler",
      "detailed_description": "A scheduler designed to optimize job placement based on GPU topology. It aims to improve performance for distributed training or HPC tasks by considering the interconnect architecture of GPU resources.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HiEST/gpu-topo-aware",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu",
        "topology",
        "scheduling",
        "hpc"
      ],
      "id": 23
    },
    {
      "name": "lsf-slurm-wrappers",
      "one_line_profile": "Wrappers to execute LSF commands using Slurm syntax",
      "detailed_description": "A set of wrapper scripts developed by IBM Spectrum Computing to assist users in migrating from Slurm to LSF. It allows users to run common Slurm commands which are then translated to execute LSF commands in the background.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "migration_utility"
      ],
      "application_level": "solver",
      "primary_language": "Perl",
      "repo_url": "https://github.com/IBMSpectrumComputing/lsf-slurm-wrappers",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "slurm",
        "lsf",
        "scheduler-migration"
      ],
      "id": 24
    },
    {
      "name": "PaRSEC",
      "one_line_profile": "Generic framework for architecture-aware micro-task scheduling",
      "detailed_description": "PaRSEC is a runtime system for distributed, GPU-accelerated, heterogeneous architectures. It manages micro-tasks with a dynamic, fully-distributed scheduler that optimizes for data locality, communication overlap, and architectural features like NUMA nodes.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "task_scheduling",
        "runtime_system"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/ICLDisco/parsec",
      "help_website": [
        "http://icl.utk.edu/parsec/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "distributed-computing",
        "task-scheduling",
        "heterogeneous-computing"
      ],
      "id": 25
    },
    {
      "name": "Maui-Simulation",
      "one_line_profile": "Simulation environment for HPC job scheduling",
      "detailed_description": "A simulation tool for modeling and analyzing the behavior of the Maui/PBS job scheduler in large-scale HPC clusters. It allows researchers and administrators to simulate job scheduling scenarios based on real cluster data.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "simulation",
        "scheduler_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/It4innovations/Maui-Simulation",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "hpc",
        "scheduling-simulation",
        "maui",
        "pbs"
      ],
      "id": 26
    },
    {
      "name": "Kartothek",
      "one_line_profile": "Consistent table management library for datasets",
      "detailed_description": "Kartothek is a Python library for managing consistent tabular datasets backed by cloud object stores. It builds on Apache Arrow and Parquet to provide reliable data storage and retrieval for data-intensive scientific and analytical workflows.",
      "domains": [
        "Data Science",
        "AI Infra"
      ],
      "subtask_category": [
        "data_management",
        "storage"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/JDASoftwareGroup/kartothek",
      "help_website": [
        "https://kartothek.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "parquet",
        "arrow",
        "dataset-management",
        "python"
      ],
      "id": 27
    },
    {
      "name": "xESMF",
      "one_line_profile": "Universal Regridder for Geospatial Data",
      "detailed_description": "xESMF is a Python package for regridding geospatial data (e.g., climate model outputs). It wraps the ESMF (Earth System Modeling Framework) regridding algorithms and integrates with Xarray to handle complex grid transformations in Earth Science.",
      "domains": [
        "Earth Science",
        "Climate Science"
      ],
      "subtask_category": [
        "data_processing",
        "regridding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/JiaweiZhuang/xESMF",
      "help_website": [
        "https://xesmf.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "geospatial",
        "regridding",
        "climate-data",
        "xarray"
      ],
      "id": 28
    },
    {
      "name": "VolcaNoseR",
      "one_line_profile": "Web app for generating and annotating Volcano plots",
      "detailed_description": "VolcaNoseR is an R Shiny application designed for the interactive creation and annotation of volcano plots, which are widely used in bioinformatics to visualize differential expression data.",
      "domains": [
        "Bioinformatics"
      ],
      "subtask_category": [
        "visualization",
        "data_plotting"
      ],
      "application_level": "solver",
      "primary_language": "R",
      "repo_url": "https://github.com/JoachimGoedhart/VolcaNoseR",
      "help_website": [
        "https://huygens.science.uva.nl/VolcaNoseR/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "volcano-plot",
        "bioinformatics",
        "shiny",
        "visualization"
      ],
      "id": 29
    },
    {
      "name": "ClusterManagers.jl",
      "one_line_profile": "Julia interface for HPC job schedulers",
      "detailed_description": "ClusterManagers.jl provides an interface for the Julia programming language to submit and manage jobs on various HPC schedulers, including Slurm, PBS, LSF, and SGE, enabling distributed scientific computing in Julia.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaParallel/ClusterManagers.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "julia",
        "hpc",
        "slurm",
        "pbs",
        "distributed-computing"
      ],
      "id": 30
    },
    {
      "name": "mass",
      "one_line_profile": "Batch job management system for complex pipelines",
      "detailed_description": "mass is a computer farm management system based on AWS SWF, designed to handle complex pipelines of batch jobs. It serves as a lightweight scheduler for managing computational workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "pipeline_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/KKBOX/mass",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "batch-jobs",
        "workflow",
        "aws-swf",
        "scheduler"
      ],
      "id": 31
    },
    {
      "name": "volcano3D",
      "one_line_profile": "3D visualization tool for differential expression analysis",
      "detailed_description": "volcano3D is an R package that enables the plotting of interactive three-way differential expression analysis results. It extends standard 2D volcano plots to 3D to visualize gene expression changes across three groups simultaneously.",
      "domains": [
        "Bioinformatics"
      ],
      "subtask_category": [
        "visualization",
        "differential_expression"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/KatrionaGoldmann/volcano3D",
      "help_website": [
        "https://katrionagoldmann.github.io/volcano3D/"
      ],
      "license": null,
      "tags": [
        "bioinformatics",
        "visualization",
        "3d-plot",
        "r-package"
      ],
      "id": 32
    },
    {
      "name": "Magpie",
      "one_line_profile": "Scripts for running Big Data software in HPC environments",
      "detailed_description": "Magpie provides a set of scripts to deploy and run Big Data frameworks like Hadoop and Spark within traditional HPC environments (using schedulers like Slurm, Moab, LSF). It bridges the gap between HPC schedulers and big data analytics stacks.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "framework_integration"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/LLNL/magpie",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "hpc",
        "hadoop",
        "spark",
        "slurm",
        "lustre"
      ],
      "id": 33
    },
    {
      "name": "Yoda-Scheduler",
      "one_line_profile": "GPU-metric based scheduler for Kubernetes clusters",
      "detailed_description": "Yoda is a Kubernetes scheduler extension that optimizes pod placement based on GPU metrics, designed to improve resource utilization for AI and scientific workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/Mr-Linus/Yoda-Scheduler",
      "help_website": [],
      "license": null,
      "tags": [
        "kubernetes",
        "scheduler",
        "gpu",
        "hpc"
      ],
      "id": 34
    },
    {
      "name": "qhist",
      "one_line_profile": "Historical job query utility for PBS Pro",
      "detailed_description": "A command-line utility developed by NCAR to query and analyze historical job data from the PBS Pro workload manager, facilitating HPC usage analysis.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "hpc_analytics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NCAR/qhist",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pbs-pro",
        "hpc",
        "job-history",
        "ncar"
      ],
      "id": 35
    },
    {
      "name": "KAI-Scheduler",
      "one_line_profile": "Kubernetes native scheduler for large-scale AI workloads",
      "detailed_description": "An open-source Kubernetes scheduler optimized for large-scale AI and HPC workloads, providing advanced scheduling capabilities for GPU resources.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/NVIDIA/KAI-Scheduler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "scheduler",
        "ai-infrastructure",
        "gpu"
      ],
      "id": 36
    },
    {
      "name": "pyxis",
      "one_line_profile": "Slurm container execution plugin",
      "detailed_description": "A SPANK plugin for Slurm that enables unprivileged users to execute containerized workloads (via Enroot) seamlessly within HPC environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "container_runtime",
        "job_execution"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/NVIDIA/pyxis",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "slurm",
        "container",
        "hpc",
        "enroot"
      ],
      "id": 37
    },
    {
      "name": "mlforecast",
      "one_line_profile": "Scalable machine learning framework for time series forecasting",
      "detailed_description": "A framework for performing scalable time series forecasting using machine learning models, applicable to scientific domains such as weather, climate, and energy load forecasting.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "time_series_forecasting",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Nixtla/mlforecast",
      "help_website": [
        "https://nixtla.github.io/mlforecast/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "time-series",
        "forecasting",
        "machine-learning"
      ],
      "id": 38
    },
    {
      "name": "Slurm_tools",
      "one_line_profile": "Collection of administration and user tools for Slurm",
      "detailed_description": "A set of scripts and utilities for managing and interacting with the Slurm HPC workload manager, aiding in job submission, monitoring, and accounting.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "cluster_administration"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/OleHolmNielsen/Slurm_tools",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "slurm",
        "hpc",
        "administration"
      ],
      "id": 39
    },
    {
      "name": "CSGHub",
      "one_line_profile": "Open-source platform for managing LLMs and datasets",
      "detailed_description": "A platform for managing the lifecycle of Large Language Models (LLMs), datasets, and agents, providing infrastructure for AI model hosting and deployment relevant to AI4S workflows.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "model_management",
        "dataset_management"
      ],
      "application_level": "platform",
      "primary_language": "Vue",
      "repo_url": "https://github.com/OpenCSGs/csghub",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "model-registry",
        "ai-infrastructure"
      ],
      "id": 40
    },
    {
      "name": "PipelineDP",
      "one_line_profile": "Differential privacy framework for large dataset processing",
      "detailed_description": "A Python framework for applying differentially private aggregations to large datasets using batch processing systems like Spark and Beam, enabling secure scientific data analysis.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_processing",
        "privacy_preservation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenMined/PipelineDP",
      "help_website": [
        "https://pipelinedp.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "differential-privacy",
        "data-processing",
        "spark",
        "beam"
      ],
      "id": 41
    },
    {
      "name": "OpenRLHF",
      "one_line_profile": "High-performance RLHF framework based on Ray",
      "detailed_description": "A scalable framework for Reinforcement Learning from Human Feedback (RLHF) built on Ray, facilitating the training and alignment of large models used in various AI applications including scientific domains.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "model_training",
        "reinforcement_learning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenRLHF/OpenRLHF",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "ray",
        "llm-training",
        "distributed-training"
      ],
      "id": 42
    },
    {
      "name": "xclim",
      "one_line_profile": "Library for calculating climate indicators",
      "detailed_description": "A Python library based on xarray for calculating climate indices and indicators from climate model output and observational data.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "climate_analysis",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Ouranosinc/xclim",
      "help_website": [
        "https://xclim.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "climate-science",
        "xarray",
        "meteorology"
      ],
      "id": 43
    },
    {
      "name": "HybriMoE",
      "one_line_profile": "Hybrid CPU-GPU scheduling for MoE inference",
      "detailed_description": "A system for efficient Mixture-of-Experts (MoE) inference that utilizes hybrid CPU-GPU scheduling and cache management to optimize resource usage.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "inference_scheduling",
        "resource_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PKU-SEC-Lab/HybriMoE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "moe",
        "scheduling",
        "inference",
        "gpu"
      ],
      "id": 44
    },
    {
      "name": "condor",
      "one_line_profile": "R interface for HTCondor",
      "detailed_description": "An R package that enables interaction with the HTCondor high-throughput computing system via SSH, allowing users to submit and manage jobs from R.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/PacificCommunity/condor",
      "help_website": [],
      "license": null,
      "tags": [
        "htcondor",
        "r",
        "hpc",
        "ssh"
      ],
      "id": 45
    },
    {
      "name": "paddle-operator",
      "one_line_profile": "Kubernetes operator for PaddlePaddle training jobs",
      "detailed_description": "A Kubernetes operator that facilitates elastic deep learning training for PaddlePaddle by leveraging Volcano for scheduling and resource management.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/PaddleFlow/paddle-operator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "paddlepaddle",
        "operator",
        "volcano"
      ],
      "id": 46
    },
    {
      "name": "Liquid",
      "one_line_profile": "Resource estimation and scheduling for DL jobs",
      "detailed_description": "A system for intelligent resource requirement estimation and scheduling of deep learning jobs on distributed GPU clusters, developed by PasaLab.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_estimation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PasaLab/Liquid",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "scheduling",
        "deep-learning",
        "gpu-cluster",
        "hpc"
      ],
      "id": 47
    },
    {
      "name": "volcano-vgpu-device-plugin",
      "one_line_profile": "Volcano vGPU device plugin for Kubernetes",
      "detailed_description": "A Kubernetes device plugin designed for the Volcano scheduler to support hard resource isolation and scheduling of virtual GPUs (vGPUs).",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "resource_management",
        "scheduling"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/Project-HAMi/volcano-vgpu-device-plugin",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "volcano",
        "gpu",
        "virtualization"
      ],
      "id": 48
    },
    {
      "name": "pyslurm",
      "one_line_profile": "Python interface to Slurm C API",
      "detailed_description": "A Python extension that provides an interface to the Slurm Workload Manager's C API, allowing programmatic interaction with Slurm for job control and querying.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "api_binding"
      ],
      "application_level": "library",
      "primary_language": "Cython",
      "repo_url": "https://github.com/PySlurm/pyslurm",
      "help_website": [
        "https://pyslurm.github.io/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "slurm",
        "python",
        "hpc",
        "api"
      ],
      "id": 49
    },
    {
      "name": "Embree",
      "one_line_profile": "High-performance ray tracing kernels",
      "detailed_description": "A collection of high-performance ray tracing kernels developed by Intel, widely used in scientific visualization and rendering engines to accelerate geometric calculations.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "scientific_visualization",
        "rendering"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/RenderKit/embree",
      "help_website": [
        "https://www.embree.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ray-tracing",
        "visualization",
        "rendering",
        "hpc"
      ],
      "id": 50
    },
    {
      "name": "REEF",
      "one_line_profile": "GPU-accelerated DNN inference serving system",
      "detailed_description": "A high-performance DNN inference serving system that supports instant kernel preemption and biased concurrent execution for optimized GPU scheduling.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "inference_serving",
        "gpu_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/SJTU-IPADS/reef",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "gpu",
        "scheduling",
        "preemption"
      ],
      "id": 51
    },
    {
      "name": "Slurm",
      "one_line_profile": "A highly scalable workload manager for HPC clusters",
      "detailed_description": "Slurm is an open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters. It is the de facto standard for HPC job scheduling in scientific research.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/SchedMD/slurm",
      "help_website": [
        "https://slurm.schedmd.com/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "scheduler",
        "workload-manager"
      ],
      "id": 52
    },
    {
      "name": "Slurm on GCP",
      "one_line_profile": "Deployment tools for running Slurm clusters on Google Cloud Platform",
      "detailed_description": "A set of tools and scripts to deploy and manage Slurm clusters on Google Cloud Platform (GCP), enabling scalable HPC workloads in the cloud.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cloud_deployment",
        "cluster_management"
      ],
      "application_level": "platform",
      "primary_language": "HCL",
      "repo_url": "https://github.com/SchedMD/slurm-gcp",
      "help_website": [
        "https://github.com/SchedMD/slurm-gcp"
      ],
      "license": "Apache-2.0",
      "tags": [
        "gcp",
        "slurm",
        "cloud-hpc"
      ],
      "id": 53
    },
    {
      "name": "Slurm in Docker",
      "one_line_profile": "Dockerized Slurm environment for testing and development",
      "detailed_description": "Provides Docker images and configurations to run Slurm clusters in containers, facilitating the development, testing, and reproducibility of HPC workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "environment_setup",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/SciDAS/slurm-in-docker",
      "help_website": [
        "https://github.com/SciDAS/slurm-in-docker"
      ],
      "license": "MIT",
      "tags": [
        "docker",
        "slurm",
        "containerization"
      ],
      "id": 54
    },
    {
      "name": "TRTIS Kubernetes Scheduler",
      "one_line_profile": "Custom Kubernetes scheduler for deploying ML models to TensorRT Inference Server",
      "detailed_description": "A custom scheduler designed to optimize the deployment of machine learning models to NVIDIA's TensorRT Inference Server (TRTIS) on Kubernetes, specifically handling GPU sharing.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "inference_scheduling",
        "gpu_sharing"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/SeldonIO/trtis-k8s-scheduler",
      "help_website": [
        "https://github.com/SeldonIO/trtis-k8s-scheduler"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "inference",
        "gpu"
      ],
      "id": 55
    },
    {
      "name": "Slurm Operator",
      "one_line_profile": "Kubernetes Operator for managing Slurm clusters",
      "detailed_description": "An operator to deploy and manage Slurm clusters on Kubernetes, bridging traditional HPC scheduling with cloud-native infrastructure.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_management",
        "cloud_native_hpc"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/SlinkyProject/slurm-operator",
      "help_website": [
        "https://github.com/SlinkyProject/slurm-operator"
      ],
      "license": null,
      "tags": [
        "kubernetes",
        "slurm",
        "operator"
      ],
      "id": 56
    },
    {
      "name": "spark.condor",
      "one_line_profile": "Utilities to run Apache Spark on HTCondor clusters",
      "detailed_description": "Scripts and tools to submit and manage Apache Spark jobs in standalone mode on HTCondor clusters, enabling big data processing in scientific HPC environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "big_data_processing"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/SmartDataInnovationLab/spark.condor",
      "help_website": [
        "https://github.com/SmartDataInnovationLab/spark.condor"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "spark",
        "htcondor",
        "hpc"
      ],
      "id": 57
    },
    {
      "name": "Snakemake HTCondor Profile",
      "one_line_profile": "Snakemake profile for executing workflows on HTCondor",
      "detailed_description": "A configuration profile for Snakemake that allows scientific workflows to be executed on HTCondor clusters, managing job submission and resource allocation.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_execution",
        "job_submission"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Snakemake-Profiles/htcondor",
      "help_website": [
        "https://github.com/Snakemake-Profiles/htcondor"
      ],
      "license": "MIT",
      "tags": [
        "snakemake",
        "htcondor",
        "workflow"
      ],
      "id": 58
    },
    {
      "name": "watchmen",
      "one_line_profile": "Toolkit for GPU scheduling and monitoring",
      "detailed_description": "A simple toolkit designed to assist with GPU scheduling and monitoring, useful for managing resources in deep learning and scientific computing experiments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "gpu_scheduling",
        "resource_monitoring"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Spico197/watchmen",
      "help_website": [
        "https://github.com/Spico197/watchmen"
      ],
      "license": "MIT",
      "tags": [
        "gpu",
        "scheduling",
        "monitoring"
      ],
      "id": 59
    },
    {
      "name": "SEML",
      "one_line_profile": "Slurm Experiment Management Library for machine learning",
      "detailed_description": "SEML allows researchers to manage and track machine learning experiments on Slurm clusters, handling job submission, configuration management, and results collection.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "experiment_management",
        "job_scheduling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TUM-DAML/seml",
      "help_website": [
        "https://github.com/TUM-DAML/seml"
      ],
      "license": "NOASSERTION",
      "tags": [
        "slurm",
        "experiment-tracking",
        "machine-learning"
      ],
      "id": 60
    },
    {
      "name": "Caelus",
      "one_line_profile": "Kubernetes solution for reusing idle node resources for batch jobs",
      "detailed_description": "Caelus is a set of Kubernetes solutions designed to improve resource utilization by running extra batch jobs (often scientific or AI workloads) on idle node resources.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "resource_optimization",
        "batch_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/Tencent/caelus",
      "help_website": [
        "https://github.com/Tencent/caelus"
      ],
      "license": "NOASSERTION",
      "tags": [
        "kubernetes",
        "batch-jobs",
        "resource-management"
      ],
      "id": 61
    },
    {
      "name": "TimeEval",
      "one_line_profile": "Evaluation tool for time series anomaly detection algorithms",
      "detailed_description": "TimeEval is a tool for evaluating and benchmarking anomaly detection algorithms on time series data, automating the execution and scoring of algorithms.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "benchmarking",
        "algorithm_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/TimeEval/TimeEval",
      "help_website": [
        "https://timeeval.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "time-series",
        "anomaly-detection",
        "benchmarking"
      ],
      "id": 62
    },
    {
      "name": "Orca",
      "one_line_profile": "Task orchestration library for UrbanSim and data science",
      "detailed_description": "Orca is a Python library for task orchestration, primarily used within the UrbanSim ecosystem for urban data science and modeling simulations.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "task_orchestration",
        "simulation_pipeline"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/UDST/orca",
      "help_website": [
        "https://udst.github.io/orca/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "orchestration",
        "urban-science",
        "pipeline"
      ],
      "id": 63
    },
    {
      "name": "slurmR",
      "one_line_profile": "Lightweight R wrapper for Slurm",
      "detailed_description": "slurmR provides a lightweight wrapper for Slurm, allowing R users to submit and manage jobs on Slurm clusters directly from their R environment.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "parallel_computing"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/USCbiostats/slurmR",
      "help_website": [
        "https://github.com/USCbiostats/slurmR"
      ],
      "license": "NOASSERTION",
      "tags": [
        "r",
        "slurm",
        "hpc"
      ],
      "id": 64
    },
    {
      "name": "pbsweb",
      "one_line_profile": "Web interface for monitoring PBS Pro HPC clusters",
      "detailed_description": "A web interface designed to display the status of nodes, queues, and jobs on High Performance Compute (HPC) clusters using the PBS Pro scheduler.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_monitoring",
        "job_visualization"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/UTS-eResearch/pbsweb",
      "help_website": [
        "https://github.com/UTS-eResearch/pbsweb"
      ],
      "license": "GPL-3.0",
      "tags": [
        "pbs-pro",
        "hpc",
        "monitoring"
      ],
      "id": 65
    },
    {
      "name": "vector-inference",
      "one_line_profile": "Efficient LLM inference on Slurm clusters",
      "detailed_description": "A tool for running efficient Large Language Model (LLM) inference on Slurm-managed clusters using vLLM, facilitating AI research on HPC infrastructure.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "inference_scheduling",
        "llm_deployment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/VectorInstitute/vector-inference",
      "help_website": [
        "https://github.com/VectorInstitute/vector-inference"
      ],
      "license": "MIT",
      "tags": [
        "slurm",
        "llm",
        "inference"
      ],
      "id": 66
    },
    {
      "name": "pyglidein",
      "one_line_profile": "Scripts to launch HTCondor glideins",
      "detailed_description": "Python scripts to launch HTCondor glideins, used for distributed computing in particle astrophysics research (e.g., IceCube).",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_computing",
        "job_submission"
      ],
      "application_level": "utility",
      "primary_language": "Python",
      "repo_url": "https://github.com/WIPACrepo/pyglidein",
      "help_website": [
        "https://github.com/WIPACrepo/pyglidein"
      ],
      "license": "MIT",
      "tags": [
        "htcondor",
        "distributed-computing",
        "physics"
      ],
      "id": 67
    },
    {
      "name": "xsched",
      "one_line_profile": "Scheduling framework for diverse XPUs (GPUs, NPUs, FPGAs)",
      "detailed_description": "A scheduling framework designed for multitasking over heterogeneous computing units (XPUs) such as GPUs, NPUs, ASICs, and FPGAs, optimizing resource usage in accelerated computing.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "heterogeneous_scheduling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/XpuOS/xsched",
      "help_website": [
        "https://github.com/XpuOS/xsched"
      ],
      "license": "Apache-2.0",
      "tags": [
        "scheduling",
        "xpu",
        "accelerators"
      ],
      "id": 68
    },
    {
      "name": "Grove",
      "one_line_profile": "Kubernetes scheduler extensions for gang scheduling and topology awareness",
      "detailed_description": "Grove provides Kubernetes enhancements for Network Topology Aware Gang Scheduling and Autoscaling, which are critical for distributed AI training and HPC workloads to ensure efficient resource utilization and job coordination.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "scheduling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/ai-dynamo/grove",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "gang-scheduling",
        "hpc",
        "autoscaling"
      ],
      "id": 69
    },
    {
      "name": "slurm_gpustat",
      "one_line_profile": "Command line tool for monitoring GPU usage on Slurm clusters",
      "detailed_description": "A simple command line utility designed to display GPU usage statistics specifically for jobs running on a SLURM cluster, aiding in resource monitoring and optimization for HPC workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "monitoring",
        "resource_management"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/albanie/slurm_gpustat",
      "help_website": [],
      "license": null,
      "tags": [
        "slurm",
        "gpu",
        "monitoring",
        "hpc"
      ],
      "id": 70
    },
    {
      "name": "GPU-scheduler-for-deep-learning",
      "one_line_profile": "GPU scheduler designed for deep learning workloads",
      "detailed_description": "A specialized scheduler for managing GPU resources in deep learning environments, optimizing the allocation and execution of training jobs.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "scheduling",
        "resource_management"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/alibaba/GPU-scheduler-for-deep-learning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "scheduling",
        "deep-learning"
      ],
      "id": 71
    },
    {
      "name": "simple_slurm",
      "one_line_profile": "Python wrapper for Slurm Workload Manager",
      "detailed_description": "A Python library that provides a simple wrapper around the Slurm Workload Manager, allowing users to submit and manage HPC jobs programmatically.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/amq92/simple_slurm",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "slurm",
        "python",
        "hpc",
        "job-management"
      ],
      "id": 72
    },
    {
      "name": "Whippletree",
      "one_line_profile": "Dynamic scheduling framework for irregular GPU workloads",
      "detailed_description": "A novel approach and framework for scheduling dynamic, irregular workloads directly on the GPU, bypassing some of the limitations of traditional kernel launch overheads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "scheduling",
        "gpu_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/apc-llc/whippletree",
      "help_website": [],
      "license": null,
      "tags": [
        "cuda",
        "gpu",
        "scheduling",
        "hpc"
      ],
      "id": 73
    },
    {
      "name": "Spark on Kubernetes Batch Processing Gateway",
      "one_line_profile": "Gateway for managing Spark batch jobs on Kubernetes",
      "detailed_description": "A gateway component designed to simplify the submission and management of Spark batch processing jobs on Kubernetes clusters, facilitating large-scale data processing workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "batch_processing"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/apple/batch-processing-gateway",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "spark",
        "kubernetes",
        "batch-processing"
      ],
      "id": 74
    },
    {
      "name": "Armada",
      "one_line_profile": "Multi-cluster batch queuing system for Kubernetes",
      "detailed_description": "A high-throughput batch queuing system for Kubernetes that spans multiple clusters, designed to handle massive scale scientific and AI workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "scheduling",
        "queue_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/armadaproject/armada",
      "help_website": [
        "https://armadaproject.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "batch-processing",
        "hpc",
        "multi-cluster"
      ],
      "id": 75
    },
    {
      "name": "Escalator",
      "one_line_profile": "Batch-optimized horizontal autoscaler for Kubernetes",
      "detailed_description": "A horizontal autoscaler for Kubernetes optimized for batch jobs and large-scale compute workloads, ensuring efficient resource scaling based on job demand.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "autoscaling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/atlassian/escalator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "autoscaling",
        "batch-jobs"
      ],
      "id": 76
    },
    {
      "name": "Kolibri",
      "one_line_profile": "Framework for concurrent batch processing and ranking evaluation",
      "detailed_description": "A Scala-based framework for concurrent multi-node batch processing and evaluation of search systems, providing out-of-the-box functionality for IR metrics (NDCG, Precision, Recall).",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "batch_processing",
        "evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Scala",
      "repo_url": "https://github.com/awagen/kolibri",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "batch-processing",
        "evaluation",
        "scala",
        "distributed-computing"
      ],
      "id": 77
    },
    {
      "name": "TwinGraph",
      "one_line_profile": "Distributed container orchestration framework for simulations",
      "detailed_description": "A Python framework for distributed container orchestration on AWS (Lambda, Batch, EKS), specifically targeting high-throughput simulations, simulation-driven optimization, and Digital Twins.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "orchestration",
        "simulation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/aws-samples/twingraph",
      "help_website": [],
      "license": "MIT-0",
      "tags": [
        "simulation",
        "orchestration",
        "digital-twin",
        "aws"
      ],
      "id": 78
    },
    {
      "name": "AWS SDK for pandas",
      "one_line_profile": "Pandas integration for AWS data services",
      "detailed_description": "An open-source Python library that extends pandas to easily integrate with AWS data services like Athena, Glue, Redshift, and S3, facilitating scientific data processing pipelines on AWS.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_processing",
        "data_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aws/aws-sdk-pandas",
      "help_website": [
        "https://aws-sdk-pandas.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "pandas",
        "aws",
        "data-processing",
        "etl"
      ],
      "id": 79
    },
    {
      "name": "Floto",
      "one_line_profile": "Task orchestration tool based on AWS SWF",
      "detailed_description": "A task orchestration tool built on top of AWS Simple Workflow Service (SWF) and boto3, allowing for the definition and execution of distributed data processing workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "orchestration",
        "workflow_management"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/babbel/floto",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "orchestration",
        "aws-swf",
        "workflow"
      ],
      "id": 80
    },
    {
      "name": "Bodywork",
      "one_line_profile": "ML pipeline orchestration and model deployment on Kubernetes",
      "detailed_description": "A tool for orchestrating machine learning pipelines and deploying models on Kubernetes, supporting continuous training and batch scoring workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "orchestration",
        "mlops"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/bodywork-ml/bodywork-core",
      "help_website": [
        "https://bodywork.readthedocs.io/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "kubernetes",
        "mlops",
        "orchestration",
        "pipeline"
      ],
      "id": 81
    },
    {
      "name": "slurmpy",
      "one_line_profile": "Python wrapper for submitting jobs to the Slurm workload manager",
      "detailed_description": "A lightweight Python library that simplifies the submission of jobs to the Slurm scheduler, allowing users to define job properties and scripts programmatically within Python code.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/brentp/slurmpy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "hpc",
        "python",
        "job-scheduling"
      ],
      "id": 82
    },
    {
      "name": "Uchuva",
      "one_line_profile": "Scientific web portal for submitting workflows to HPC schedulers",
      "detailed_description": "A web-based portal designed to facilitate the creation and submission of scientific workflows to various HPC schedulers including HTCondor, Slurm, OpenLava, and Torque.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "workflow_management"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/carlochess/uchuva",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "hpc",
        "web-portal",
        "htcondor",
        "slurm",
        "workflow"
      ],
      "id": 83
    },
    {
      "name": "JobSchedulers.jl",
      "one_line_profile": "Julia-based job scheduler and workload manager",
      "detailed_description": "A pure Julia implementation of a job scheduler and workload manager, inspired by Slurm and PBS, designed to manage scientific computations and tasks within the Julia ecosystem.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "workload_management"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/cihga39871/JobSchedulers.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "scheduler",
        "hpc",
        "parallel-computing"
      ],
      "id": 84
    },
    {
      "name": "ClearML Agent",
      "one_line_profile": "MLOps orchestration agent for experiment scheduling",
      "detailed_description": "The agent component of the ClearML platform, responsible for pulling experiment execution tasks from the queue and running them on local or remote resources, facilitating reproducible AI research workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "experiment_orchestration",
        "mlops"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/clearml/clearml-agent",
      "help_website": [
        "https://clear.ml/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "orchestration",
        "reproducibility",
        "scheduler"
      ],
      "id": 85
    },
    {
      "name": "GPUTasker",
      "one_line_profile": "Lightweight GPU task scheduler for single-node clusters",
      "detailed_description": "A lightweight and easy-to-use GPU task scheduling tool designed to manage and queue tasks on GPU servers, optimizing resource utilization for small-scale AI research environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "gpu_scheduling",
        "resource_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cnstark/gputasker",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "scheduler",
        "python",
        "deep-learning"
      ],
      "id": 86
    },
    {
      "name": "vGPU Manager",
      "one_line_profile": "Kubernetes device plugin for vGPU scheduling and allocation",
      "detailed_description": "A Kubernetes device plugin that enables the scheduling and allocation of virtualized GPU resources, allowing for fine-grained sharing of GPUs in containerized scientific workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "resource_allocation",
        "container_orchestration"
      ],
      "application_level": "service",
      "primary_language": "C",
      "repo_url": "https://github.com/coldzerofear/vgpu-manager",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "gpu",
        "virtualization",
        "scheduler"
      ],
      "id": 87
    },
    {
      "name": "MetaVolcanoR",
      "one_line_profile": "Gene expression meta-analysis visualization tool",
      "detailed_description": "An R package designed for the visualization of gene expression meta-analysis results, specifically creating volcano plots to identify differentially expressed genes across multiple studies.",
      "domains": [
        "Bioinformatics",
        "Visualization"
      ],
      "subtask_category": [
        "visualization",
        "differential_expression_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/csbl-usp/MetaVolcanoR",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "genomics",
        "visualization",
        "r",
        "meta-analysis"
      ],
      "id": 88
    },
    {
      "name": "DanteGPU Core",
      "one_line_profile": "Core microservices for decentralized GPU computing network",
      "detailed_description": "The core infrastructure for the DanteGPU network, enabling decentralized orchestration of AI job scheduling and management of distributed GPU providers.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_computing",
        "resource_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/dante-gpu/dantegpu-core",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "decentralized-computing",
        "scheduler",
        "go"
      ],
      "id": 89
    },
    {
      "name": "FluxPrune.jl",
      "one_line_profile": "Pruning framework for Flux machine learning models",
      "detailed_description": "A Julia library providing methods and a framework for pruning neural networks built with Flux.jl, facilitating model compression and efficiency in scientific machine learning.",
      "domains": [
        "Scientific Machine Learning"
      ],
      "subtask_category": [
        "model_optimization",
        "pruning"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/darsnack/FluxPrune.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "flux",
        "machine-learning",
        "model-compression"
      ],
      "id": 90
    },
    {
      "name": "Dask SQL",
      "one_line_profile": "Distributed SQL Engine for Dask DataFrames",
      "detailed_description": "A distributed SQL engine that allows users to query Dask DataFrames using SQL, enabling scalable data analysis and processing on large scientific datasets using familiar SQL syntax.",
      "domains": [
        "AI6",
        "Data Science"
      ],
      "subtask_category": [
        "data_querying",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask-contrib/dask-sql",
      "help_website": [
        "https://dask-sql.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "sql",
        "dask",
        "distributed-computing",
        "python"
      ],
      "id": 91
    },
    {
      "name": "Dask",
      "one_line_profile": "Flexible library for parallel computing in Python",
      "detailed_description": "A core library for parallel computing in Python that integrates with the scientific Python stack (NumPy, Pandas, Scikit-Learn) to enable scalable data analysis and task scheduling.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "parallel_computing",
        "task_scheduling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask",
      "help_website": [
        "https://dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "parallel-computing",
        "python",
        "scheduler",
        "big-data"
      ],
      "id": 92
    },
    {
      "name": "Dask Cloudprovider",
      "one_line_profile": "Cloud provider cluster managers for Dask",
      "detailed_description": "A library for deploying and managing Dask clusters on various cloud providers (AWS, Azure, GCP), facilitating the scaling of scientific workloads in cloud environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_management",
        "cloud_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask-cloudprovider",
      "help_website": [
        "https://cloudprovider.dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "dask",
        "cloud",
        "cluster-management",
        "python"
      ],
      "id": 93
    },
    {
      "name": "Dask Gateway",
      "one_line_profile": "Multi-tenant server for securely deploying and managing Dask clusters",
      "detailed_description": "A secure, multi-tenant server for managing Dask clusters, allowing users to launch and use Dask clusters in a shared environment with authentication and resource limits.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_management",
        "job_scheduling"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask-gateway",
      "help_website": [
        "https://gateway.dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "dask",
        "cluster-management",
        "distributed-computing"
      ],
      "id": 94
    },
    {
      "name": "dask-image",
      "one_line_profile": "Distributed image processing library using Dask",
      "detailed_description": "A library for distributed image processing that integrates with Dask arrays, allowing for scalable analysis of large scientific image datasets.",
      "domains": [
        "AI6",
        "AI4"
      ],
      "subtask_category": [
        "image_processing",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask-image",
      "help_website": [
        "https://image.dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "image-processing",
        "dask",
        "distributed"
      ],
      "id": 95
    },
    {
      "name": "dask-jobqueue",
      "one_line_profile": "Integration of Dask with HPC job schedulers (PBS, Slurm, SGE)",
      "detailed_description": "A library that deploys Dask workers on common HPC job schedulers like PBS, Slurm, SGE, and LSF, enabling scalable scientific computing on existing cluster infrastructure.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "hpc_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask-jobqueue",
      "help_website": [
        "https://jobqueue.dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "slurm",
        "pbs",
        "dask"
      ],
      "id": 96
    },
    {
      "name": "dask-kubernetes",
      "one_line_profile": "Native Kubernetes integration for deploying Dask clusters",
      "detailed_description": "Provides utilities for deploying and managing Dask clusters on Kubernetes, including a native operator and a classic cluster manager.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_management",
        "container_orchestration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask-kubernetes",
      "help_website": [
        "https://kubernetes.dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "kubernetes",
        "dask",
        "cloud-native"
      ],
      "id": 97
    },
    {
      "name": "dask-labextension",
      "one_line_profile": "JupyterLab extension for managing and monitoring Dask clusters",
      "detailed_description": "A JupyterLab extension that provides a dashboard for managing Dask clusters and visualizing task progress directly within the scientific research environment.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_management",
        "monitoring"
      ],
      "application_level": "plugin",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/dask/dask-labextension",
      "help_website": [
        "https://github.com/dask/dask-labextension"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyterlab",
        "dask",
        "visualization"
      ],
      "id": 98
    },
    {
      "name": "dask-ml",
      "one_line_profile": "Scalable machine learning library compatible with Scikit-Learn",
      "detailed_description": "A library for scalable machine learning in Python, providing parallel implementations of common ML algorithms and integration with Dask for handling large datasets.",
      "domains": [
        "AI3",
        "AI6"
      ],
      "subtask_category": [
        "machine_learning",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask-ml",
      "help_website": [
        "https://ml.dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "machine-learning",
        "distributed",
        "scikit-learn"
      ],
      "id": 99
    },
    {
      "name": "Dask Distributed",
      "one_line_profile": "Distributed task scheduler for the Dask ecosystem",
      "detailed_description": "The core distributed scheduling engine for Dask, managing task execution across clusters of machines with low latency and high throughput.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/distributed",
      "help_website": [
        "https://distributed.dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "scheduler",
        "distributed",
        "python"
      ],
      "id": 100
    },
    {
      "name": "Cube Studio",
      "one_line_profile": "Cloud-native one-stop MLOps and LLM platform",
      "detailed_description": "An open-source AI platform supporting the full lifecycle of machine learning and large model development, including distributed training, inference, and resource management on Kubernetes.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "mlops",
        "platform_orchestration",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/data-infra/cube-studio",
      "help_website": [
        "https://github.com/data-infra/cube-studio"
      ],
      "license": "NOASSERTION",
      "tags": [
        "mlops",
        "kubernetes",
        "llm",
        "distributed-training"
      ],
      "id": 101
    },
    {
      "name": "ec2cluster",
      "one_line_profile": "Tool for launching and managing MPI clusters on Amazon EC2",
      "detailed_description": "A Rails-based web service and dashboard for provisioning MPI-ready clusters on AWS EC2 and managing user-submitted HPC jobs.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_provisioning",
        "job_submission"
      ],
      "application_level": "tool",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/datawrangling/ec2cluster",
      "help_website": [],
      "license": null,
      "tags": [
        "aws",
        "mpi",
        "hpc",
        "cluster-management"
      ],
      "id": 102
    },
    {
      "name": "cwm-simulator",
      "one_line_profile": "Simulator for Slurm-like cluster workload managers",
      "detailed_description": "A simulation tool for modeling and analyzing the behavior of cluster workload managers (like Slurm), useful for research on scheduling algorithms.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "scheduling_simulation",
        "performance_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dchasap/cwm-simulator",
      "help_website": [],
      "license": null,
      "tags": [
        "slurm",
        "simulator",
        "scheduling"
      ],
      "id": 103
    },
    {
      "name": "dpdispatcher",
      "one_line_profile": "Job submission and management tool for DeepModeling ecosystem",
      "detailed_description": "A Python tool to generate HPC scheduler scripts, submit jobs, and monitor their status, specifically designed for the DeepModeling scientific workflow.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "workflow_automation"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepmodeling/dpdispatcher",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "hpc",
        "deepmodeling",
        "scheduler"
      ],
      "id": 104
    },
    {
      "name": "DeepSquare Grid",
      "one_line_profile": "Decentralized HPC platform with Slurm-like interface",
      "detailed_description": "A decentralized high-performance computing grid based on blockchain technology, offering an abstracted Slurm interface for job scheduling and meta-scheduling strategies.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_computing",
        "resource_allocation"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/deepsquare-io/grid",
      "help_website": [
        "https://docs.deepsquare.io/"
      ],
      "license": null,
      "tags": [
        "hpc",
        "decentralized",
        "blockchain",
        "slurm"
      ],
      "id": 105
    },
    {
      "name": "Omnia",
      "one_line_profile": "Toolkit for deploying and managing HPC and AI clusters",
      "detailed_description": "An open-source toolkit using Ansible and Kubernetes to deploy and manage high-performance clusters for HPC, AI, and data analytics workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_provisioning",
        "infrastructure_management"
      ],
      "application_level": "tool",
      "primary_language": "YAML",
      "repo_url": "https://github.com/dell/omnia",
      "help_website": [
        "https://omnia-doc.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "ansible",
        "kubernetes",
        "cluster-deployment"
      ],
      "id": 106
    },
    {
      "name": "High-Performance-Integer-Factorization-Suite",
      "one_line_profile": "High-performance suite for integer factorization algorithms",
      "detailed_description": "A suite implementing GNFS, MPQS, and QS algorithms with optimizations like GPU acceleration and NUMA-aware scheduling for computational number theory research.",
      "domains": [
        "AI4",
        "AI6"
      ],
      "subtask_category": [
        "integer_factorization",
        "cryptanalysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/devatnull/High-Performance-Integer-Factorization-Suite-GNFS-MPQS-QS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "number-theory",
        "factorization",
        "gpu",
        "hpc"
      ],
      "id": 107
    },
    {
      "name": "opt_einsum",
      "one_line_profile": "Optimizer for tensor contraction orders in scientific computing",
      "detailed_description": "A library that optimizes the contraction order of einsum functions in NumPy, TensorFlow, and Dask, significantly speeding up tensor operations in quantum chemistry and physics.",
      "domains": [
        "AI4",
        "AI6"
      ],
      "subtask_category": [
        "numerical_optimization",
        "tensor_contraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dgasmith/opt_einsum",
      "help_website": [
        "https://optimized-einsum.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "tensor",
        "optimization",
        "numpy",
        "quantum-chemistry"
      ],
      "id": 108
    },
    {
      "name": "qsub",
      "one_line_profile": "Command line utility for submitting batch jobs to Kubernetes",
      "detailed_description": "A Go-based utility that emulates the traditional 'qsub' command to submit batch jobs to Kubernetes clusters, bridging the gap between HPC and Cloud Native workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "hpc_emulation"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/dgruber/qsub",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "kubernetes",
        "hpc",
        "batch-jobs"
      ],
      "id": 109
    },
    {
      "name": "XGBoost",
      "one_line_profile": "Scalable and distributed gradient boosting library",
      "detailed_description": "An optimized distributed gradient boosting library designed to be highly efficient, flexible and portable, widely used in scientific data analysis and machine learning competitions.",
      "domains": [
        "AI3",
        "AI6"
      ],
      "subtask_category": [
        "machine_learning",
        "gradient_boosting"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/dmlc/xgboost",
      "help_website": [
        "https://xgboost.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "gbdt",
        "machine-learning",
        "distributed"
      ],
      "id": 110
    },
    {
      "name": "cms-htcondor-es",
      "one_line_profile": "ElasticSearch integration for CMS HTCondor pool monitoring",
      "detailed_description": "A tool for integrating the CMS experiment's HTCondor pool with ElasticSearch, enabling monitoring and analysis of high-throughput computing jobs in high-energy physics.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "monitoring",
        "hpc_infrastructure"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/dmwm/cms-htcondor-es",
      "help_website": [],
      "license": null,
      "tags": [
        "cms",
        "cern",
        "htcondor",
        "monitoring"
      ],
      "id": 111
    },
    {
      "name": "dstack",
      "one_line_profile": "Control plane for running AI jobs on GPUs across clouds",
      "detailed_description": "An open-source control plane that simplifies running development, training, and inference jobs on GPUs across various cloud providers and on-premise clusters.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "mlops",
        "resource_orchestration",
        "job_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/dstackai/dstack",
      "help_website": [
        "https://dstack.ai/"
      ],
      "license": "MPL-2.0",
      "tags": [
        "mlops",
        "gpu",
        "cloud-computing"
      ],
      "id": 112
    },
    {
      "name": "Metview Python",
      "one_line_profile": "Python interface to Metview meteorological workstation",
      "detailed_description": "A Python interface to Metview, enabling meteorological data processing, analysis, and visualization, as well as interaction with batch systems for weather forecasting workflows.",
      "domains": [
        "AI6",
        "AI4"
      ],
      "subtask_category": [
        "meteorology",
        "data_visualization",
        "workflow_automation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ecmwf/metview-python",
      "help_website": [
        "https://metview.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "meteorology",
        "ecmwf",
        "visualization"
      ],
      "id": 113
    },
    {
      "name": "elastic-gpu-scheduler",
      "one_line_profile": "Kubernetes scheduler extender for GPU resources",
      "detailed_description": "A Kubernetes scheduler extender designed to optimize GPU resource scheduling, supporting elastic scaling for AI and HPC workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "resource_scheduling",
        "gpu_management"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/elastic-ai/elastic-gpu-scheduler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "gpu",
        "scheduler"
      ],
      "id": 114
    },
    {
      "name": "ElastiCluster",
      "one_line_profile": "Tool to create and configure compute clusters on cloud providers",
      "detailed_description": "A command-line tool to create, manage, and setup computing clusters (with Slurm, GridEngine, etc.) on various cloud providers using Ansible.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_provisioning",
        "cloud_hpc"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/elasticluster/elasticluster",
      "help_website": [
        "https://elasticluster.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "cloud",
        "hpc",
        "ansible",
        "cluster-management"
      ],
      "id": 115
    },
    {
      "name": "TESK API",
      "one_line_profile": "GA4GH Task Execution Service implementation for Kubernetes",
      "detailed_description": "An implementation of the GA4GH Task Execution Service (TES) API that translates scientific task descriptions into Kubernetes Batch API calls, facilitating interoperable genomics workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_execution",
        "genomics_infrastructure"
      ],
      "application_level": "service",
      "primary_language": "Java",
      "repo_url": "https://github.com/elixir-cloud-aai/tesk-api",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ga4gh",
        "genomics",
        "kubernetes",
        "workflow"
      ],
      "id": 116
    },
    {
      "name": "Paella",
      "one_line_profile": "Low-latency model serving system with virtualized GPU scheduling",
      "detailed_description": "A research system for low-latency machine learning model serving that utilizes virtualized GPU scheduling to optimize resource usage and response times.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "model_serving",
        "gpu_scheduling"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/eniac/paella",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "model-serving",
        "gpu",
        "scheduling"
      ],
      "id": 117
    },
    {
      "name": "Proteus",
      "one_line_profile": "Heterogeneous database engine with adaptive scheduling",
      "detailed_description": "A research database engine designed for heterogeneous environments, featuring GPU acceleration and adaptive scheduling to handle variable scientific and analytical workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "data_management",
        "adaptive_scheduling"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/epfl-dias/proteus",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "database",
        "gpu",
        "heterogeneous-computing"
      ],
      "id": 118
    },
    {
      "name": "Orion",
      "one_line_profile": "Interference-aware scheduler for fine-grained GPU sharing",
      "detailed_description": "A scheduler designed to manage fine-grained GPU sharing by being aware of interference between tasks, optimizing throughput for deep learning workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "gpu_scheduling",
        "resource_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/eth-easl/orion",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "scheduling",
        "deep-learning"
      ],
      "id": 119
    },
    {
      "name": "submitit",
      "one_line_profile": "Python toolbox for submitting jobs to Slurm",
      "detailed_description": "A lightweight Python library for submitting and managing jobs on Slurm clusters, enabling easy switching between local execution and cluster execution for research experiments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "experiment_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookincubator/submitit",
      "help_website": [
        "https://github.com/facebookincubator/submitit"
      ],
      "license": "MIT",
      "tags": [
        "slurm",
        "python",
        "hpc"
      ],
      "id": 120
    },
    {
      "name": "GPUTaskScheduler",
      "one_line_profile": "Lightweight Python library for scheduling tasks on available GPUs",
      "detailed_description": "A simple Python-based scheduler designed to manage and distribute tasks across available GPU resources, useful for local scientific experiment management.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fjxmlzn/GPUTaskScheduler",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "scheduling",
        "python"
      ],
      "id": 121
    },
    {
      "name": "Flux Core",
      "one_line_profile": "Next-generation resource manager and scheduler for HPC centers",
      "detailed_description": "The core framework of the Flux project, providing a hierarchical resource management system and job scheduler designed for modern High Performance Computing (HPC) environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/flux-framework/flux-core",
      "help_website": [
        "http://flux-framework.org"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "hpc",
        "scheduler",
        "resource-manager",
        "flux"
      ],
      "id": 122
    },
    {
      "name": "Flux K8s",
      "one_line_profile": "Integration components for running Flux resource manager on Kubernetes",
      "detailed_description": "A project to manage Flux tasks and standardize Kubernetes HPC scheduling interfaces, enabling the use of the Flux scheduler within Cloud Native environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "orchestration"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/flux-framework/flux-k8s",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "hpc",
        "flux",
        "scheduling"
      ],
      "id": 123
    },
    {
      "name": "Fugue",
      "one_line_profile": "Unified interface for distributed computing on Spark, Dask, and Ray",
      "detailed_description": "An abstraction layer that allows users to write code in native Python or SQL and execute it on distributed computing engines like Spark, Dask, and Ray, facilitating scalable scientific data processing.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_computing",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fugue-project/fugue",
      "help_website": [
        "https://fugue-tutorials.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-computing",
        "spark",
        "dask",
        "ray",
        "abstraction"
      ],
      "id": 124
    },
    {
      "name": "Furiko",
      "one_line_profile": "Kubernetes-native batch job platform for complex workflows",
      "detailed_description": "A high-performance cron and batch job platform for Kubernetes, suitable for managing scientific batch workloads with advanced scheduling features.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "batch_processing"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/furiko-io/furiko",
      "help_website": [
        "https://furiko.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "batch-jobs",
        "cron",
        "scheduling"
      ],
      "id": 125
    },
    {
      "name": "Ansible Role for Slurm",
      "one_line_profile": "Ansible role for deploying Slurm Workload Manager",
      "detailed_description": "An Ansible role maintained by the Galaxy Project for installing and managing the Slurm Workload Manager, essential for setting up scientific HPC clusters.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_management",
        "deployment"
      ],
      "application_level": "service",
      "primary_language": "Jinja",
      "repo_url": "https://github.com/galaxyproject/ansible-slurm",
      "help_website": [],
      "license": null,
      "tags": [
        "slurm",
        "ansible",
        "hpc",
        "deployment"
      ],
      "id": 126
    },
    {
      "name": "Hypertunity",
      "one_line_profile": "Toolset for black-box hyperparameter optimisation",
      "detailed_description": "A lightweight and modular Python library for black-box hyperparameter optimization, supporting various schedulers and optimization algorithms for scientific ML models.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "hyperparameter_optimization",
        "model_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gdikov/hypertunity",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hpo",
        "optimization",
        "machine-learning"
      ],
      "id": 127
    },
    {
      "name": "GeodMod",
      "one_line_profile": "Geodetic Modeling Software in Matlab",
      "detailed_description": "A MATLAB-based software suite for geodetic modeling, used for analyzing deformation data and geophysical parameters.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "scientific_modeling",
        "geodesy"
      ],
      "application_level": "solver",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/geodesymiami/GeodMod",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "geodesy",
        "matlab",
        "modeling",
        "earth-science"
      ],
      "id": 128
    },
    {
      "name": "Dask-GeoPandas",
      "one_line_profile": "Parallel GeoPandas with Dask",
      "detailed_description": "A library that enables parallel processing of geospatial data by integrating GeoPandas with Dask, facilitating large-scale spatial analysis.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_processing",
        "spatial_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/geopandas/dask-geopandas",
      "help_website": [
        "https://dask-geopandas.readthedocs.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "geospatial",
        "dask",
        "parallel-computing",
        "gis"
      ],
      "id": 129
    },
    {
      "name": "foamlib",
      "one_line_profile": "Modern Python package for interacting with OpenFOAM",
      "detailed_description": "A Python interface for OpenFOAM, allowing users to automate CFD simulations, manipulate cases, and interact with OpenFOAM utilities programmatically.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "simulation_interface",
        "cfd"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gerlero/foamlib",
      "help_website": [
        "https://foamlib.readthedocs.io"
      ],
      "license": "GPL-3.0",
      "tags": [
        "openfoam",
        "cfd",
        "python",
        "simulation"
      ],
      "id": 130
    },
    {
      "name": "Docker CentOS7 Slurm",
      "one_line_profile": "Slurm Docker Container on CentOS 7",
      "detailed_description": "A Docker image providing a pre-configured Slurm Workload Manager environment on CentOS 7, useful for testing and developing HPC workflows locally.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "environment_simulation",
        "hpc_testing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/giovtorres/docker-centos7-slurm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "docker",
        "hpc",
        "centos"
      ],
      "id": 131
    },
    {
      "name": "Slurm Docker Cluster",
      "one_line_profile": "A Slurm cluster using docker-compose",
      "detailed_description": "A tool to deploy a multi-node Slurm cluster using Docker Compose, enabling reproducible local simulation of HPC environments for job scheduling development.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_simulation",
        "job_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/giovtorres/slurm-docker-cluster",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "docker-compose",
        "hpc",
        "cluster"
      ],
      "id": 132
    },
    {
      "name": "stackstac",
      "one_line_profile": "Turn a STAC catalog into a dask-based xarray",
      "detailed_description": "A library for converting SpatioTemporal Asset Catalogs (STAC) into Dask-backed Xarray objects, streamlining the analysis of large-scale satellite and earth science data.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_loading",
        "earth_observation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gjoseph92/stackstac",
      "help_website": [
        "https://stackstac.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "stac",
        "xarray",
        "dask",
        "remote-sensing"
      ],
      "id": 133
    },
    {
      "name": "SDSC ibrun",
      "one_line_profile": "SDSC's implementation of the ibrun MPI launcher",
      "detailed_description": "A wrapper script used at the San Diego Supercomputer Center (SDSC) to simplify MPI job launching across different batch schedulers and MPI implementations.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_launching",
        "mpi_execution"
      ],
      "application_level": "solver",
      "primary_language": "Perl",
      "repo_url": "https://github.com/glennklockwood/sdsc-ibrun",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "mpi",
        "hpc",
        "job-launcher",
        "sdsc"
      ],
      "id": 134
    },
    {
      "name": "PathwaysJob API",
      "one_line_profile": "Kubernetes-native API to deploy ML training and batch inference using Pathways",
      "detailed_description": "An API and controller for deploying Machine Learning training and batch inference workloads on Google Kubernetes Engine (GKE) using the Pathways runtime.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "ml_orchestration",
        "batch_inference"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/google/pathways-job",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "machine-learning",
        "pathways",
        "gke"
      ],
      "id": 135
    },
    {
      "name": "Xarray-Beam",
      "one_line_profile": "Distributed Xarray with Apache Beam",
      "detailed_description": "A library that adapts Xarray data structures for use with Apache Beam, enabling distributed processing of massive multi-dimensional scientific datasets.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "distributed_processing",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google/xarray-beam",
      "help_website": [
        "https://xarray-beam.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "xarray",
        "apache-beam",
        "distributed-computing",
        "big-data"
      ],
      "id": 136
    },
    {
      "name": "grid-control",
      "one_line_profile": "Versatile job submission and management tool for grid computing",
      "detailed_description": "A job submission tool designed for High Energy Physics and other scientific domains, supporting parameterized jobs and automatic resubmission on Grid and local batch systems.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "grid_computing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/grid-control/grid-control",
      "help_website": [
        "https://grid-control.github.io"
      ],
      "license": null,
      "tags": [
        "grid-computing",
        "batch-jobs",
        "hep",
        "job-management"
      ],
      "id": 137
    },
    {
      "name": "VodaScheduler",
      "one_line_profile": "GPU scheduler for elastic and distributed deep learning workloads on Kubernetes",
      "detailed_description": "VodaScheduler is a GPU scheduler designed for Kubernetes clusters to optimize elastic and distributed deep learning workloads. It improves resource utilization and training efficiency by managing GPU allocation dynamically.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_allocation"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/heyfey/vodascheduler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "gpu-scheduling",
        "deep-learning",
        "distributed-training"
      ],
      "id": 138
    },
    {
      "name": "Kubernetes Scheduler Simulator",
      "one_line_profile": "Simulator for evaluating Kubernetes schedulers",
      "detailed_description": "A tool designed to simulate the behavior of Kubernetes schedulers, allowing researchers and developers to evaluate scheduling algorithms and cluster behavior without deploying a real cluster. Useful for optimizing HPC/AI workload placement.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "simulation",
        "scheduling_research"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/hkust-adsl/kubernetes-scheduler-simulator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "simulator",
        "scheduling",
        "hpc"
      ],
      "id": 139
    },
    {
      "name": "hvPlot",
      "one_line_profile": "High-level plotting API for scientific data visualization",
      "detailed_description": "A high-level plotting API built on HoloViews that provides a general and consistent interface for visualizing data from Pandas, Dask, XArray, and NetworkX. Widely used in geoscience and physics for interactive data exploration.",
      "domains": [
        "AI6",
        "Scientific Visualization"
      ],
      "subtask_category": [
        "visualization",
        "data_exploration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/holoviz/hvplot",
      "help_website": [
        "https://hvplot.holoviz.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "visualization",
        "pandas",
        "xarray",
        "dask",
        "interactive-plots"
      ],
      "id": 140
    },
    {
      "name": "Horovod",
      "one_line_profile": "Distributed deep learning training framework",
      "detailed_description": "A distributed deep learning training framework for TensorFlow, Keras, PyTorch, and Apache MXNet. It makes distributed training easy and efficient, often used in HPC environments (via MPI) for large-scale scientific AI models.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_training",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/horovod/horovod",
      "help_website": [
        "https://horovod.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "deep-learning",
        "distributed-training",
        "mpi",
        "hpc"
      ],
      "id": 141
    },
    {
      "name": "HTCondor",
      "one_line_profile": "High-Throughput Computing (HTC) workload management system",
      "detailed_description": "A specialized workload management system for compute-intensive jobs. It provides a job queueing mechanism, scheduling policy, priority scheme, resource monitoring, and resource management, widely used in physics (e.g., CERN) and genomics.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "workload_management"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/htcondor/htcondor",
      "help_website": [
        "https://htcondor.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "htc",
        "batch-system",
        "scheduling",
        "grid-computing"
      ],
      "id": 142
    },
    {
      "name": "HTCondor-CE",
      "one_line_profile": "Grid gatekeeper for HTCondor compute elements",
      "detailed_description": "A site grid gatekeeper technology based on HTCondor components, used to authorize and route incoming grid jobs to the local batch system. Essential for federated scientific computing grids.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "grid_computing",
        "job_routing"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/htcondor/htcondor-ce",
      "help_website": [
        "https://htcondor-ce.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "grid",
        "gatekeeper",
        "htcondor",
        "compute-element"
      ],
      "id": 143
    },
    {
      "name": "HTCondor-RESTD",
      "one_line_profile": "REST API interface for HTCondor",
      "detailed_description": "Provides a RESTful interface to the HTCondor High-Throughput Computing system, enabling remote job submission, query, and management via HTTP, facilitating integration with modern scientific web portals.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "api_interface"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/htcondor/htcondor-restd",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rest-api",
        "htcondor",
        "job-management"
      ],
      "id": 144
    },
    {
      "name": "HTMap",
      "one_line_profile": "Pythonic high-throughput computing library powered by HTCondor",
      "detailed_description": "A library that wraps HTCondor to provide a map-reduce style interface for Python, allowing researchers to easily scale out function calls across a cluster without managing job files directly.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "high_throughput_computing",
        "parallel_execution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/htcondor/htmap",
      "help_website": [
        "https://htmap.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "python",
        "htcondor",
        "map-reduce",
        "parallel-computing"
      ],
      "id": 145
    },
    {
      "name": "llm-swarm",
      "one_line_profile": "Scalable LLM inference on Slurm clusters",
      "detailed_description": "A tool to manage and scale open LLM inference endpoints within Slurm-managed HPC clusters. It facilitates the deployment of large language models for scientific research using existing HPC infrastructure.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "inference_serving",
        "resource_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/llm-swarm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "llm",
        "inference",
        "hpc"
      ],
      "id": 146
    },
    {
      "name": "Opara",
      "one_line_profile": "DNN Operator parallel scheduling framework",
      "detailed_description": "A lightweight and resource-aware DNN Operator parallel scheduling framework designed to accelerate the execution of DNN inference on GPUs by optimizing operator execution order.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "inference_optimization",
        "operator_scheduling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/icloud-ecnu/Opara",
      "help_website": [],
      "license": null,
      "tags": [
        "dnn",
        "scheduling",
        "gpu",
        "inference"
      ],
      "id": 147
    },
    {
      "name": "Prophet",
      "one_line_profile": "Communication scheduling strategy for distributed training",
      "detailed_description": "A predictable communication scheduling strategy to schedule gradient transfers in an adequate order, aiming to maximize GPU and network resource utilization during distributed DNN training.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_training",
        "communication_scheduling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/icloud-ecnu/Prophet",
      "help_website": [],
      "license": null,
      "tags": [
        "distributed-training",
        "gradient-scheduling",
        "network-optimization"
      ],
      "id": 148
    },
    {
      "name": "Argo Volcano Executor Plugin",
      "one_line_profile": "Argo Workflows plugin for executing Volcano Jobs",
      "detailed_description": "A plugin that allows Argo Workflows to trigger and manage Volcano jobs. Volcano is a batch scheduling system for Kubernetes, widely used for AI and Big Data workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "job_submission"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/iflytek/argo-volcano-executor-plugin",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "argo",
        "volcano",
        "kubernetes",
        "workflow"
      ],
      "id": 149
    },
    {
      "name": "udocker",
      "one_line_profile": "Tool to execute Docker containers in user space without root",
      "detailed_description": "A basic user tool to execute simple docker containers in batch or interactive systems without root privileges. Critical for running scientific containers on shared HPC clusters where users lack root access.",
      "domains": [
        "AI6",
        "HPC"
      ],
      "subtask_category": [
        "container_runtime",
        "environment_reproducibility"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/indigo-dc/udocker",
      "help_website": [
        "https://indigo-dc.github.io/udocker/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "docker",
        "hpc",
        "containers",
        "user-space"
      ],
      "id": 150
    },
    {
      "name": "MintPy",
      "one_line_profile": "Miami InSAR time-series software",
      "detailed_description": "An open-source software package for Interferometric Synthetic Aperture Radar (InSAR) time-series analysis. It reads stack of interferograms and estimates the ground displacement time-series.",
      "domains": [
        "Geoscience",
        "Remote Sensing"
      ],
      "subtask_category": [
        "time_series_analysis",
        "image_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/insarlab/MintPy",
      "help_website": [
        "https://mintpy.readthedocs.io/"
      ],
      "license": null,
      "tags": [
        "insar",
        "geodesy",
        "remote-sensing",
        "deformation"
      ],
      "id": 151
    },
    {
      "name": "BigDL",
      "one_line_profile": "Distributed deep learning on Big Data platforms",
      "detailed_description": "A distributed deep learning framework for Apache Spark and Ray. It allows users to write deep learning applications as standard Spark/Ray programs, facilitating the integration of AI models into big data pipelines.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_training",
        "big_data_analytics"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/intel/BigDL",
      "help_website": [
        "https://bigdl.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "spark",
        "ray",
        "deep-learning",
        "distributed-computing"
      ],
      "id": 152
    },
    {
      "name": "CRI Resource Manager",
      "one_line_profile": "Hardware resource aware workload placement for Kubernetes",
      "detailed_description": "A Kubernetes Container Runtime Interface (CRI) proxy service that applies hardware resource-aware policies (e.g., NUMA topology, cache allocation) to optimize workload placement, essential for high-performance AI/HPC jobs.",
      "domains": [
        "AI6",
        "HPC"
      ],
      "subtask_category": [
        "resource_management",
        "workload_placement"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/intel/cri-resource-manager",
      "help_website": [
        "https://intel.github.io/cri-resource-manager/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "numa",
        "resource-management",
        "hpc"
      ],
      "id": 153
    },
    {
      "name": "cellxgene_VIP",
      "one_line_profile": "Visualization in Plugin for cellxgene",
      "detailed_description": "A plugin for cellxgene that provides advanced visualization capabilities (violin plots, heatmaps, volcano plots) and differential gene expression analysis for single-cell transcriptomics data.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "visualization",
        "differential_expression_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/interactivereport/cellxgene_VIP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "single-cell",
        "visualization",
        "genomics",
        "cellxgene"
      ],
      "id": 154
    },
    {
      "name": "Slurm Bank",
      "one_line_profile": "Resource accounting wrapper for Slurm",
      "detailed_description": "A collection of wrapper scripts for Slurm to provide banking/accounting capabilities (similar to GOLD), allowing HPC centers to manage compute allocations and project budgets.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "resource_accounting",
        "allocation_management"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/jcftang/slurm-bank",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "slurm",
        "accounting",
        "hpc",
        "resource-management"
      ],
      "id": 155
    },
    {
      "name": "autoray",
      "one_line_profile": "Abstract array operations for backend-agnostic scientific computing",
      "detailed_description": "A lightweight library that abstracts array operations, allowing scientific code to run transparently on NumPy, PyTorch, JAX, TensorFlow, Dask, and CuPy. Heavily used in quantum physics simulations (e.g., tensor networks).",
      "domains": [
        "AI6",
        "Scientific Computing"
      ],
      "subtask_category": [
        "array_computing",
        "backend_abstraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jcmgray/autoray",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "numpy",
        "pytorch",
        "jax",
        "tensor-networks"
      ],
      "id": 156
    },
    {
      "name": "smk-simple-slurm",
      "one_line_profile": "Simple Slurm profile for Snakemake",
      "detailed_description": "A configuration profile for Snakemake that simplifies the execution of scientific workflows on Slurm clusters, handling job submission and resource specification without complex cluster configuration files.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_execution",
        "job_submission"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/jdblischak/smk-simple-slurm",
      "help_website": [],
      "license": "CC0-1.0",
      "tags": [
        "snakemake",
        "slurm",
        "workflow",
        "hpc"
      ],
      "id": 157
    },
    {
      "name": "GeoWombat",
      "one_line_profile": "Utilities for geospatial data processing",
      "detailed_description": "A Python package for processing geospatial data at scale. It simplifies tasks like reading/writing rasters, tiling, and applying functions over large satellite imagery datasets, often used in earth science research.",
      "domains": [
        "Geoscience",
        "Remote Sensing"
      ],
      "subtask_category": [
        "geospatial_analysis",
        "image_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jgrss/geowombat",
      "help_website": [
        "https://geowombat.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "geospatial",
        "remote-sensing",
        "raster",
        "satellite-imagery"
      ],
      "id": 158
    },
    {
      "name": "Swifter",
      "one_line_profile": "Efficiently applies any function to a pandas dataframe or series in the fastest available manner",
      "detailed_description": "A library that accelerates pandas DataFrame operations by automatically vectorizing or parallelizing computations using Dask or multiprocessing, essential for processing large scientific datasets.",
      "domains": [
        "AI6",
        "Data Science"
      ],
      "subtask_category": [
        "data_processing",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jmcarpenter2/swifter",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pandas",
        "acceleration",
        "parallel-computing",
        "data-processing"
      ],
      "id": 159
    },
    {
      "name": "BatchSpawner",
      "one_line_profile": "Custom Spawner for Jupyterhub to start servers in batch scheduled systems",
      "detailed_description": "A JupyterHub spawner that enables launching Jupyter notebook servers as batch jobs on HPC schedulers like Slurm, HTCondor, and Torque, bridging interactive computing with HPC infrastructure.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "interactive_computing"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/jupyterhub/batchspawner",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyterhub",
        "hpc",
        "slurm",
        "batch-scheduling"
      ],
      "id": 160
    },
    {
      "name": "Task Spooler",
      "one_line_profile": "A UNIX batch system where tasks submitted from a shell are run one after another",
      "detailed_description": "A lightweight job scheduling tool for single machines that allows users to queue commands (tasks) for sequential execution, useful for managing scientific simulations or data processing jobs on workstations.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "task_queue"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/justanhduc/task-spooler",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "scheduler",
        "batch-system",
        "cli",
        "queue"
      ],
      "id": 161
    },
    {
      "name": "Turm",
      "one_line_profile": "TUI for the Slurm Workload Manager",
      "detailed_description": "A terminal user interface (TUI) for monitoring and managing jobs on the Slurm Workload Manager, providing a visual way to interact with HPC clusters.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "monitoring"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/kabouzeid/turm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "hpc",
        "tui",
        "monitoring"
      ],
      "id": 162
    },
    {
      "name": "EnhancedVolcano",
      "one_line_profile": "Publication-ready volcano plots with enhanced colouring and labeling",
      "detailed_description": "An R package for generating highly customizable volcano plots to visualize differential expression results in bioinformatics and genomics research.",
      "domains": [
        "Bioinformatics"
      ],
      "subtask_category": [
        "visualization",
        "differential_expression"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/kevinblighe/EnhancedVolcano",
      "help_website": [
        "https://bioconductor.org/packages/release/bioc/html/EnhancedVolcano.html"
      ],
      "license": "GPL-3.0",
      "tags": [
        "volcano-plot",
        "genomics",
        "visualization",
        "r-package"
      ],
      "id": 163
    },
    {
      "name": "kube-batch",
      "one_line_profile": "A batch scheduler of kubernetes for high performance workload",
      "detailed_description": "A batch scheduler for Kubernetes designed for high-performance workloads such as AI/ML, Big Data, and HPC, supporting advanced scheduling policies like gang scheduling.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "workload_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubernetes-retired/kube-batch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "batch-scheduling",
        "hpc",
        "gang-scheduling"
      ],
      "id": 164
    },
    {
      "name": "JobSet",
      "one_line_profile": "A Kubernetes-native API for distributed ML training and HPC workloads",
      "detailed_description": "A Kubernetes controller that manages groups of related jobs (JobSets) as a single unit, specifically designed to handle distributed machine learning training and HPC workloads with failure recovery policies.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workload_management",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubernetes-sigs/jobset",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "hpc",
        "machine-learning",
        "distributed-training"
      ],
      "id": 165
    },
    {
      "name": "Kueue",
      "one_line_profile": "Kubernetes-native Job Queueing",
      "detailed_description": "A job queueing controller for Kubernetes that manages quotas and job admission, enabling batch scheduling capabilities similar to traditional HPC schedulers within a cloud-native environment.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_queueing",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubernetes-sigs/kueue",
      "help_website": [
        "https://kueue.sigs.k8s.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "batch-queueing",
        "job-management",
        "hpc"
      ],
      "id": 166
    },
    {
      "name": "ggvolc",
      "one_line_profile": "Translates differential expression datasets into informative volcano plots",
      "detailed_description": "An R package designed to simplify the creation of volcano plots for RNA-seq and differential expression data, allowing for easy visualization of genes of interest.",
      "domains": [
        "Bioinformatics"
      ],
      "subtask_category": [
        "visualization",
        "differential_expression"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/loukesio/ggvolc",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "volcano-plot",
        "visualization",
        "rnaseq",
        "r"
      ],
      "id": 167
    },
    {
      "name": "Mars",
      "one_line_profile": "Tensor-based unified framework for scaling numpy, pandas, and scikit-learn",
      "detailed_description": "Mars is a tensor-based unified framework for large-scale data computation which scales Python scientific libraries like numpy, pandas, and scikit-learn. It allows researchers to run data-intensive scientific computing tasks on distributed clusters with minimal code changes.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_computing",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mars-project/mars",
      "help_website": [
        "https://mars-project.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-computing",
        "tensor",
        "numpy-compatible",
        "parallel-computing"
      ],
      "id": 168
    },
    {
      "name": "LiCSAlert",
      "one_line_profile": "Volcano monitoring system using Sentinel-1 InSAR data",
      "detailed_description": "LiCSAlert is a tool for automatic volcano monitoring that processes Sentinel-1 InSAR data to detect ground deformation. It is designed to assist in the surveillance of volcanic activity through satellite remote sensing data analysis.",
      "domains": [
        "Earth Science",
        "Geophysics"
      ],
      "subtask_category": [
        "remote_sensing_analysis",
        "anomaly_detection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/matthew-gaddes/LiCSAlert",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "volcanology",
        "insar",
        "remote-sensing",
        "monitoring"
      ],
      "id": 169
    },
    {
      "name": "ssubmit",
      "one_line_profile": "CLI tool to submit Slurm jobs without writing sbatch scripts",
      "detailed_description": "ssubmit is a command-line utility that simplifies the submission of jobs to the Slurm workload manager. It allows users to submit jobs directly without the need to create and manage temporary sbatch scripts, streamlining the HPC workflow.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "workflow_management"
      ],
      "application_level": "tool",
      "primary_language": "Rust",
      "repo_url": "https://github.com/mbhall88/ssubmit",
      "help_website": [],
      "license": "Unlicense",
      "tags": [
        "slurm",
        "hpc",
        "cli",
        "productivity"
      ],
      "id": 170
    },
    {
      "name": "TorchX",
      "one_line_profile": "Universal job launcher for PyTorch applications on HPC and Cloud",
      "detailed_description": "TorchX is a universal job launcher and workflow engine for PyTorch applications. It supports submitting distributed training and batch inference jobs to various schedulers including Slurm, Kubernetes, AWS Batch, and Ray, facilitating reproducible AI research.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/meta-pytorch/torchx",
      "help_website": [
        "https://pytorch.org/torchx/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "pytorch",
        "job-launcher",
        "slurm",
        "kubernetes",
        "mlops"
      ],
      "id": 171
    },
    {
      "name": "CRA",
      "one_line_profile": "Common Runtime for Applications for distributed dataflow",
      "detailed_description": "Common Runtime for Applications (CRA) is a library designed to simplify the creation and deployment of distributed dataflow-style applications. It abstracts resource management on clusters like Kubernetes and YARN, useful for building custom scientific distributed computing systems.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "distributed_computing",
        "resource_management"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/microsoft/CRA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "distributed-systems",
        "dataflow",
        "runtime",
        "microsoft-research"
      ],
      "id": 172
    },
    {
      "name": "OpenPAI",
      "one_line_profile": "Resource scheduling and cluster management platform for AI",
      "detailed_description": "OpenPAI is an open-source platform that provides complete AI model training and resource management capabilities. It supports job scheduling, cluster monitoring, and efficient resource utilization for large-scale AI for Science workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_management",
        "job_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/microsoft/pai",
      "help_website": [
        "https://openpai.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "ai-platform",
        "cluster-management",
        "kubernetes",
        "gpu-scheduling"
      ],
      "id": 173
    },
    {
      "name": "stui",
      "one_line_profile": "Terminal-based dashboard for monitoring Slurm jobs",
      "detailed_description": "stui is a terminal user interface (TUI) for the Slurm workload manager. It allows researchers and administrators to monitor job status, node utilization, and cluster health directly from the command line in an interactive dashboard.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "monitoring",
        "job_management"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/mil-ad/stui",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "tui",
        "monitoring",
        "hpc"
      ],
      "id": 174
    },
    {
      "name": "batchtools",
      "one_line_profile": "R package for high-performance computing on batch systems",
      "detailed_description": "batchtools is an R package that provides a unified interface for parallel computing on batch systems like Slurm, LSF, SGE, and Torque. It handles job submission, status monitoring, and result collection, enabling scalable scientific data analysis in R.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "parallel_computing"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/mlr-org/batchtools",
      "help_website": [
        "https://mllg.github.io/batchtools/"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "r",
        "hpc",
        "slurm",
        "parallel-computing"
      ],
      "id": 175
    },
    {
      "name": "pbrt-v4",
      "one_line_profile": "Physically based rendering system for light transport simulation",
      "detailed_description": "pbrt-v4 is the source code for the fourth edition of 'Physically Based Rendering'. It is a comprehensive rendering system that simulates the physical behavior of light, widely used in computer graphics research and optical simulation.",
      "domains": [
        "Physics",
        "Computer Graphics"
      ],
      "subtask_category": [
        "simulation",
        "rendering"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/mmp/pbrt-v4",
      "help_website": [
        "https://pbrt.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rendering",
        "ray-tracing",
        "physics-simulation",
        "optics"
      ],
      "id": 176
    },
    {
      "name": "clustermq",
      "one_line_profile": "Efficient parallelization of R function calls on HPC clusters",
      "detailed_description": "clustermq is an R package that sends function calls as jobs to HPC schedulers (Slurm, LSF, SGE, etc.) or via SSH. It reduces the overhead of job submission and management compared to traditional batch scripts, optimizing high-throughput scientific computing in R.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "parallel_computing"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/mschubert/clustermq",
      "help_website": [
        "https://mschubert.github.io/clustermq/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "r",
        "hpc",
        "slurm",
        "parallelization"
      ],
      "id": 177
    },
    {
      "name": "Lexcube",
      "one_line_profile": "Interactive 3D visualization for Earth system data cubes",
      "detailed_description": "Lexcube is a tool for the interactive 3D visualization of large Earth system data cubes within Jupyter Notebooks. It enables scientists to explore and analyze massive spatiotemporal datasets (e.g., climate data) efficiently.",
      "domains": [
        "Earth Science",
        "Climate Science"
      ],
      "subtask_category": [
        "visualization",
        "data_exploration"
      ],
      "application_level": "tool",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/msoechting/lexcube",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "visualization",
        "earth-science",
        "data-cube",
        "jupyter"
      ],
      "id": 178
    },
    {
      "name": "Narwhals",
      "one_line_profile": "Compatibility layer for scientific dataframe libraries",
      "detailed_description": "Narwhals is a lightweight compatibility layer that allows library developers to write dataframe-agnostic code. It supports pandas, Polars, and other dataframe libraries, facilitating the development of interoperable scientific data analysis tools.",
      "domains": [
        "AI6",
        "Data Science"
      ],
      "subtask_category": [
        "data_processing",
        "interoperability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/narwhals-dev/narwhals",
      "help_website": [
        "https://narwhals-dev.github.io/narwhals/"
      ],
      "license": "MIT",
      "tags": [
        "dataframe",
        "pandas",
        "polars",
        "compatibility"
      ],
      "id": 179
    },
    {
      "name": "scores",
      "one_line_profile": "Metrics for verification and evaluation of weather and climate forecasts",
      "detailed_description": "scores is a Python package containing mathematical functions for the verification, evaluation, and optimization of forecasts, predictions, or models, specifically tailored for meteorology and climate science applications.",
      "domains": [
        "Earth Science",
        "Meteorology"
      ],
      "subtask_category": [
        "model_evaluation",
        "verification"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/nci/scores",
      "help_website": [
        "https://scores.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "meteorology",
        "verification",
        "metrics",
        "climate-science"
      ],
      "id": 180
    },
    {
      "name": "NCSA Scheduler",
      "one_line_profile": "Aggregate job launcher for HPC environments",
      "detailed_description": "The NCSA Scheduler is a tool designed to aggregate and launch single-core or single-node applications on HPC sites. It helps optimize job scheduling and resource usage on supercomputing clusters.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "workload_management"
      ],
      "application_level": "tool",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/ncsa/Scheduler",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "scheduler",
        "ncsa",
        "job-launcher"
      ],
      "id": 181
    },
    {
      "name": "Nebari",
      "one_line_profile": "Open source data science platform for scalable collaboration",
      "detailed_description": "Nebari is an opinionated, open-source data science platform that integrates JupyterHub, Dask, and Conda. It provides a reproducible and scalable environment for scientific collaboration and data analysis on cloud or on-premise infrastructure.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "collaborative_science"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/nebari-dev/nebari",
      "help_website": [
        "https://www.nebari.dev/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "data-science",
        "jupyterhub",
        "dask",
        "platform"
      ],
      "id": 182
    },
    {
      "name": "soperator",
      "one_line_profile": "Kubernetes operator for running Slurm clusters",
      "detailed_description": "soperator is a Kubernetes operator that manages the deployment and lifecycle of Slurm clusters on Kubernetes. It enables the convergence of HPC and cloud-native workflows by running Slurm workloads within a Kubernetes environment.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_management",
        "orchestration"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/nebius/soperator",
      "help_website": [
        "https://nebius.ai/slurm-operator"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "slurm",
        "operator",
        "hpc-on-k8s"
      ],
      "id": 183
    },
    {
      "name": "Slurm-Mail",
      "one_line_profile": "Enhanced email notification system for Slurm jobs",
      "detailed_description": "A drop-in replacement for standard Slurm email notifications that provides users with comprehensive job information, including resource usage and status details, improving observability for HPC workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_monitoring",
        "hpc_utility"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/neilmunday/slurm-mail",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "slurm",
        "hpc",
        "monitoring",
        "email-notifications"
      ],
      "id": 184
    },
    {
      "name": "Nextflow",
      "one_line_profile": "Scalable workflow management system for scientific pipelines",
      "detailed_description": "A domain-specific language (DSL) and runtime for creating portable, scalable, and reproducible data-driven computational pipelines. It supports deployment on various execution platforms including local, HPC schedulers (Slurm, PBS), and cloud environments (AWS Batch, K8s).",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "pipeline_management"
      ],
      "application_level": "workflow",
      "primary_language": "Groovy",
      "repo_url": "https://github.com/nextflow-io/nextflow",
      "help_website": [
        "https://www.nextflow.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "bioinformatics",
        "pipeline",
        "hpc",
        "cloud-computing"
      ],
      "id": 185
    },
    {
      "name": "OAR",
      "one_line_profile": "Versatile resource and task manager for HPC clusters",
      "detailed_description": "A batch scheduler and resource manager for high-performance computing clusters. It provides a flexible architecture for managing jobs, resources, and scheduling policies, widely used in research infrastructures like Grid'5000.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Perl",
      "repo_url": "https://github.com/oar-team/oar",
      "help_website": [
        "http://oar.imag.fr/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "hpc",
        "scheduler",
        "batch-system",
        "cluster-management"
      ],
      "id": 186
    },
    {
      "name": "OAR3",
      "one_line_profile": "Next-generation Python-based OAR scheduler",
      "detailed_description": "The third generation of the OAR resource and job manager, rewritten in Python to provide a more modern, maintainable, and extensible architecture for cluster scheduling.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/oar-team/oar3",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "scheduler",
        "python",
        "cluster"
      ],
      "id": 187
    },
    {
      "name": "Funnel",
      "one_line_profile": "Distributed task execution toolkit implementing GA4GH TES",
      "detailed_description": "A toolkit for distributed task execution that implements the GA4GH Task Execution Schema (TES), enabling standardized job submission and execution across various compute backends (HPC, Cloud) for genomics and bioinformatics workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "task_execution",
        "genomics_workflow"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/ohsu-comp-bio/funnel",
      "help_website": [
        "https://ohsu-comp-bio.github.io/funnel/"
      ],
      "license": "MIT",
      "tags": [
        "ga4gh",
        "tes",
        "bioinformatics",
        "distributed-computing",
        "task-runner"
      ],
      "id": 188
    },
    {
      "name": "CCQHub",
      "one_line_profile": "Meta-scheduler for linking disparate HPC environments",
      "detailed_description": "A meta-scheduler designed to connect different HPC environments, allowing jobs to be treated as payloads that can be routed and executed across disparate computing resources.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "meta_scheduling",
        "hpc_interoperability"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/omnibond/CCQHub",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "hpc",
        "meta-scheduler",
        "cloud-bursting",
        "job-management"
      ],
      "id": 189
    },
    {
      "name": "CoexecutorRuntime",
      "one_line_profile": "Runtime for heterogeneous computing scheduling in oneAPI",
      "detailed_description": "A runtime environment associated with Intel's oneAPI ecosystem, designed to facilitate straightforward heterogeneous computing and scheduling across different accelerator architectures.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "heterogeneous_scheduling",
        "runtime_acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/oneAPI-scheduling/CoexecutorRuntime",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "oneapi",
        "hpc",
        "heterogeneous-computing",
        "scheduling"
      ],
      "id": 190
    },
    {
      "name": "Kubernetes EC2 Autoscaler",
      "one_line_profile": "Batch-optimized scaling manager for Kubernetes on AWS",
      "detailed_description": "A Kubernetes autoscaler optimized for batch workloads (like AI training and scientific simulations), managing EC2 ASGs to efficiently scale compute resources based on pending job requirements.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "resource_scaling",
        "cloud_hpc"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/openai/kubernetes-ec2-autoscaler",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kubernetes",
        "autoscaling",
        "batch-processing",
        "aws",
        "ai-infra"
      ],
      "id": 191
    },
    {
      "name": "Gridscale",
      "one_line_profile": "Scala library for accessing grid and batch schedulers",
      "detailed_description": "A library used by the OpenMOLE workflow engine to abstract interactions with various computing backends, including local execution, SSH, Slurm, PBS, and grid middlewares, facilitating distributed scientific computing.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "grid_computing"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/openmole/gridscale",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "scala",
        "hpc",
        "grid-computing",
        "middleware",
        "job-submission"
      ],
      "id": 192
    },
    {
      "name": "OpenPBS",
      "one_line_profile": "HPC workload manager and job scheduler",
      "detailed_description": "An open-source version of the Portable Batch System (PBS), a widely used workload manager for HPC clusters, clouds, and supercomputers, responsible for scheduling and managing computational jobs.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "workload_management"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/openpbs/openpbs",
      "help_website": [
        "https://www.openpbs.org"
      ],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "scheduler",
        "workload-manager",
        "cluster"
      ],
      "id": 193
    },
    {
      "name": "Kueue Operator",
      "one_line_profile": "Operator for managing Kueue job queuing system on Kubernetes",
      "detailed_description": "A Kubernetes operator to deploy and manage Kueue, a cloud-native job queueing system that manages batch jobs and resource quotas, essential for running AI/ML and scientific batch workloads on Kubernetes.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "batch_scheduling",
        "k8s_operator"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/openshift/kueue-operator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "batch-jobs",
        "operator",
        "kueue",
        "ai-infra"
      ],
      "id": 194
    },
    {
      "name": "django-remote-submission",
      "one_line_profile": "Django app for remote job submission to HPC clusters",
      "detailed_description": "A Django application developed at ORNL that facilitates asynchronous task submission and monitoring on remote HPC resources (via Celery and Redis), typically used to build science gateways and web portals for research.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "science_gateway"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ornl-ndav/django-remote-submission",
      "help_website": [],
      "license": "ISC",
      "tags": [
        "hpc",
        "django",
        "celery",
        "job-submission",
        "science-gateway"
      ],
      "id": 195
    },
    {
      "name": "ATOS",
      "one_line_profile": "Multi-GPU dynamic scheduler with PGAS communication",
      "detailed_description": "A research scheduler for multi-GPU environments that utilizes PGAS-style cross-GPU communication to optimize dynamic task scheduling and execution efficiency in high-performance computing contexts.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "gpu_scheduling",
        "parallel_computing"
      ],
      "application_level": "solver",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/owensgroup/ATOS",
      "help_website": [],
      "license": null,
      "tags": [
        "gpu",
        "cuda",
        "scheduling",
        "hpc",
        "pgas"
      ],
      "id": 196
    },
    {
      "name": "mgpuscheduler",
      "one_line_profile": "Multi-GPU CUDA-based scheduler",
      "detailed_description": "A scheduler designed for managing and executing tasks across multiple GPUs using CUDA, developed for research into efficient GPU utilization and parallel task management.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "gpu_scheduling",
        "parallel_computing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/owensgroup/mgpuscheduler",
      "help_website": [],
      "license": null,
      "tags": [
        "gpu",
        "cuda",
        "scheduler",
        "hpc"
      ],
      "id": 197
    },
    {
      "name": "Climpred",
      "one_line_profile": "Verification tool for weather and climate forecasts",
      "detailed_description": "A python package for the verification and analysis of weather and climate forecasts. It provides statistical tools to assess the skill of prediction models against observations.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "forecast_verification",
        "climate_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pangeo-data/climpred",
      "help_website": [
        "https://climpred.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "climate-science",
        "weather-forecasting",
        "verification",
        "geoscience",
        "pangeo"
      ],
      "id": 198
    },
    {
      "name": "mpify",
      "one_line_profile": "MPI-like multiprocessing for Python in Jupyter",
      "detailed_description": "A simple API to launch Python functions on multiple ranked processes, enabling interactive distributed data parallel experiments (e.g., for AI training) directly from Jupyter/IPython environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_computing",
        "interactive_hpc"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/philtrade/mpify",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multiprocessing",
        "jupyter",
        "distributed-training",
        "mpi",
        "python"
      ],
      "id": 199
    },
    {
      "name": "Pipefunc",
      "one_line_profile": "Lightweight pipeline creation for scientific HPC workflows",
      "detailed_description": "A Python library for creating lightweight, fast function pipelines (DAGs) specifically designed for scientific and HPC workflows, facilitating modular code structure and execution.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_creation",
        "pipeline_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pipefunc/pipefunc",
      "help_website": [
        "https://pipefunc.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "pipeline",
        "dag",
        "hpc",
        "scientific-computing",
        "workflow"
      ],
      "id": 200
    },
    {
      "name": "slurm-rs",
      "one_line_profile": "Rust bindings for Slurm workload manager",
      "detailed_description": "Rust language bindings for interacting with the Slurm workload manager API, enabling the development of high-performance tools and utilities for HPC job management in Rust.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "hpc_development",
        "job_management_api"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/pkgw/slurm-rs",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rust",
        "slurm",
        "hpc",
        "bindings"
      ],
      "id": 201
    },
    {
      "name": "Soopervisor",
      "one_line_profile": "Exporter for Ploomber pipelines to HPC and Cloud platforms",
      "detailed_description": "A tool that exports Ploomber data science pipelines to various execution environments including Kubernetes (Argo), Airflow, AWS Batch, and SLURM, bridging local development and production/HPC execution.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "pipeline_deployment",
        "workflow_export"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/ploomber/soopervisor",
      "help_website": [
        "https://soopervisor.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ploomber",
        "pipeline",
        "slurm",
        "kubernetes",
        "mlops"
      ],
      "id": 202
    },
    {
      "name": "ScanTools",
      "one_line_profile": "Genomic selection analysis tools and Slurm wrapper",
      "detailed_description": "A collection of tools for analyzing selection in genomic data, including a wrapper for simplifying job submission to Slurm clusters, tailored for bioinformatics research.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "genomics_analysis",
        "job_submission"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/pmonnahan/ScanTools",
      "help_website": [],
      "license": null,
      "tags": [
        "genomics",
        "bioinformatics",
        "slurm",
        "selection-analysis"
      ],
      "id": 203
    },
    {
      "name": "TraceML",
      "one_line_profile": "ML/Data tracking and visualization engine for Polyaxon",
      "detailed_description": "The tracking and visualization engine for the Polyaxon platform, providing capabilities for logging experiments, visualizing metrics, and detecting drift in machine learning workflows used in research and production.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "experiment_tracking",
        "mlops"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/polyaxon/traceml",
      "help_website": [
        "https://polyaxon.com/docs/experimentation/tracking/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "tracking",
        "visualization",
        "polyaxon",
        "experiment-management"
      ],
      "id": 204
    },
    {
      "name": "AppWrapper",
      "one_line_profile": "Kueue controller for managing AI/HPC applications on Kubernetes",
      "detailed_description": "Part of the Project CodeFlare, AppWrapper is a Kubernetes controller that integrates with Kueue to provide advanced queuing, resource management, and lifecycle handling for complex AI and HPC applications.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "application_management",
        "batch_scheduling"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/project-codeflare/appwrapper",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "hpc",
        "ai",
        "controller",
        "codeflare"
      ],
      "id": 205
    },
    {
      "name": "MLBatch",
      "one_line_profile": "Queuing and quota management for AI/ML batch jobs",
      "detailed_description": "A system for managing queuing and resource quotas specifically for AI/ML batch jobs on Kubernetes, ensuring efficient utilization of cluster resources for training and inference workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "batch_management",
        "resource_quota"
      ],
      "application_level": "service",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/project-codeflare/mlbatch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "ml",
        "batch-jobs",
        "quota-management"
      ],
      "id": 206
    },
    {
      "name": "PyCondor",
      "one_line_profile": "Python utility for HTCondor workflow submission",
      "detailed_description": "A Python package that simplifies the process of building and submitting workflows to the HTCondor high-throughput computing system, allowing users to define jobs and DAGs using Python objects.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pycondor/pycondor",
      "help_website": [
        "https://pycondor.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "htcondor",
        "hpc",
        "workflow",
        "python",
        "high-throughput-computing"
      ],
      "id": 207
    },
    {
      "name": "xarray",
      "one_line_profile": "N-D labeled arrays and datasets in Python",
      "detailed_description": "Xarray introduces labels in the form of dimensions, coordinates and attributes on top of raw NumPy-like arrays, which allows for a more intuitive, more concise, and less error-prone developer experience. It is widely used in physics, climate science, and oceanography for handling multi-dimensional scientific data.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "data_processing",
        "multidimensional_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pydata/xarray",
      "help_website": [
        "https://docs.xarray.dev"
      ],
      "license": "Apache-2.0",
      "tags": [
        "scientific-computing",
        "multi-dimensional-arrays",
        "netcdf"
      ],
      "id": 208
    },
    {
      "name": "pyresample",
      "one_line_profile": "Geospatial image resampling in Python",
      "detailed_description": "A Python package for resampling geospatial image data. It is primarily designed for resampling earth observation satellite data and handling various map projections.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_processing",
        "resampling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pytroll/pyresample",
      "help_website": [
        "https://pyresample.readthedocs.io"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "geospatial",
        "remote-sensing",
        "resampling"
      ],
      "id": 209
    },
    {
      "name": "satpy",
      "one_line_profile": "Python package for earth-observing satellite data processing",
      "detailed_description": "Satpy is a python library for reading, manipulating, and writing meteorological remote sensing data. It supports various satellite instrument formats and provides functionality for compositing and resampling.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_processing",
        "satellite_imaging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pytroll/satpy",
      "help_website": [
        "https://satpy.readthedocs.io"
      ],
      "license": "GPL-3.0",
      "tags": [
        "remote-sensing",
        "meteorology",
        "satellite-data"
      ],
      "id": 210
    },
    {
      "name": "Slurm-web",
      "one_line_profile": "Open source web interface for Slurm HPC & AI clusters",
      "detailed_description": "A web interface for the Slurm workload manager, providing a dashboard for monitoring cluster status and jobs, tailored for HPC and AI research environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "cluster_monitoring"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/rackslab/Slurm-web",
      "help_website": [
        "https://rackslab.github.io/Slurm-web"
      ],
      "license": "MIT",
      "tags": [
        "hpc",
        "slurm",
        "web-interface"
      ],
      "id": 211
    },
    {
      "name": "Crater",
      "one_line_profile": "Cloud-native AI training & inference platform",
      "detailed_description": "A platform designed to streamline AI training and inference workloads on cloud-native infrastructure, facilitating the execution of scientific machine learning models.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "model_training",
        "inference_serving"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/raids-lab/crater",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-platform",
        "training",
        "inference"
      ],
      "id": 212
    },
    {
      "name": "cuDF",
      "one_line_profile": "GPU DataFrame Library",
      "detailed_description": "A GPU DataFrame library for loading, joining, aggregating, filtering, and manipulating data, built on the Apache Arrow columnar memory format. It accelerates scientific data processing pipelines.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_processing",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/rapidsai/cudf",
      "help_website": [
        "https://docs.rapids.ai/api/cudf/stable/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "gpu",
        "dataframe",
        "rapids"
      ],
      "id": 213
    },
    {
      "name": "dask-cuda",
      "one_line_profile": "Utilities for Dask and CUDA interactions",
      "detailed_description": "Utilities for using Dask with CUDA-enabled GPUs, including cluster management and worker configuration, enabling distributed parallel computing for scientific workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_computing",
        "gpu_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rapidsai/dask-cuda",
      "help_website": [
        "https://docs.rapids.ai/api/dask-cuda/stable/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dask",
        "cuda",
        "distributed-computing"
      ],
      "id": 214
    },
    {
      "name": "dask-cudf",
      "one_line_profile": "Dask support for distributed GDF object",
      "detailed_description": "A library that connects Dask and cuDF to provide distributed GPU DataFrames, allowing for scaling of scientific data processing across multiple GPUs.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_processing",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rapidsai/dask-cudf",
      "help_website": [
        "https://docs.rapids.ai/api/dask-cudf/stable/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dask",
        "cudf",
        "gpu"
      ],
      "id": 215
    },
    {
      "name": "KubeRay",
      "one_line_profile": "A toolkit to run Ray applications on Kubernetes",
      "detailed_description": "KubeRay is a Kubernetes operator for managing Ray clusters, simplifying the deployment and management of distributed AI and scientific computing applications on K8s.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_management",
        "distributed_computing"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/ray-project/kuberay",
      "help_website": [
        "https://ray-project.github.io/kuberay/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ray",
        "kubernetes",
        "operator"
      ],
      "id": 216
    },
    {
      "name": "Ray",
      "one_line_profile": "Unified framework for scaling AI and Python applications",
      "detailed_description": "Ray provides a simple, universal API for building distributed applications. It is widely used for scaling scientific AI workloads like reinforcement learning, hyperparameter tuning, and model training.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_computing",
        "model_training"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ray-project/ray",
      "help_website": [
        "https://docs.ray.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-computing",
        "machine-learning",
        "scaling"
      ],
      "id": 217
    },
    {
      "name": "XGBoost on Ray",
      "one_line_profile": "Distributed XGBoost on Ray",
      "detailed_description": "A library for training XGBoost models at scale using Ray clusters, enabling efficient processing of large-scale scientific datasets.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "model_training",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ray-project/xgboost_ray",
      "help_website": [
        "https://docs.ray.io/en/latest/ray-air/examples/xgboost_example.html"
      ],
      "license": "Apache-2.0",
      "tags": [
        "xgboost",
        "ray",
        "distributed-ml"
      ],
      "id": 218
    },
    {
      "name": "ezpz",
      "one_line_profile": "Distributed training utility for PyTorch",
      "detailed_description": "A lightweight wrapper to simplify distributed training across multiple devices and nodes, facilitating scientific machine learning experiments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "model_training",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/saforem2/ezpz",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "distributed-training",
        "ddp"
      ],
      "id": 219
    },
    {
      "name": "Kuscia",
      "one_line_profile": "Kubernetes-based privacy-preserving computing task orchestration framework",
      "detailed_description": "A lightweight, privacy-preserving computing task orchestration framework based on Kubernetes, designed for secure collaborative analysis of sensitive scientific or medical data.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "task_orchestration",
        "privacy_preserving_computing"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/secretflow/kuscia",
      "help_website": [
        "https://www.secretflow.org.cn/docs/kuscia/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "privacy-computing",
        "kubernetes",
        "orchestration"
      ],
      "id": 220
    },
    {
      "name": "gpushare-scheduler-extender",
      "one_line_profile": "Kubernetes GPU Sharing Scheduler",
      "detailed_description": "A Kubernetes scheduler extender that enables GPU sharing among multiple pods, optimizing resource utilization for AI and scientific computing workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "resource_scheduling",
        "gpu_sharing"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/seculayer/gpushare-scheduler-extender",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "gpu",
        "scheduler"
      ],
      "id": 221
    },
    {
      "name": "spark-gateway",
      "one_line_profile": "REST API for interacting with batch Spark Applications on Kubernetes",
      "detailed_description": "A gateway service that provides a REST API to submit and manage Spark batch applications on Kubernetes clusters, facilitating big data processing for scientific research.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "batch_processing"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/slackhq/spark-gateway",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "spark",
        "kubernetes",
        "batch-processing"
      ],
      "id": 222
    },
    {
      "name": "snakemake-executor-plugin-kueue",
      "one_line_profile": "Snakemake executor plugin for Kueue on Kubernetes",
      "detailed_description": "A plugin for Snakemake that allows scientific workflow jobs to be executed via the Kueue job queueing system on Kubernetes, enabling scalable workflow execution.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_execution",
        "job_scheduling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake/snakemake-executor-plugin-kueue",
      "help_website": [
        "https://snakemake.github.io/snakemake-plugin-catalog/plugins/executor/kueue.html"
      ],
      "license": "MIT",
      "tags": [
        "snakemake",
        "kueue",
        "kubernetes"
      ],
      "id": 223
    },
    {
      "name": "STUMPY",
      "one_line_profile": "Scalable Python library for modern time series analysis using Matrix Profiles",
      "detailed_description": "STUMPY is a powerful and scalable Python library that efficiently computes the matrix profile for time series data. It is used for pattern discovery, anomaly detection, and semantic segmentation in scientific and industrial time series analysis.",
      "domains": [
        "AI1",
        "AI1-01"
      ],
      "subtask_category": [
        "time_series_analysis",
        "motif_discovery",
        "anomaly_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/stumpy-dev/stumpy",
      "help_website": [
        "https://stumpy.readthedocs.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "time-series",
        "matrix-profile",
        "data-analysis"
      ],
      "id": 224
    },
    {
      "name": "wlm-operator",
      "one_line_profile": "Kubernetes operator for interacting with Slurm workloads via Singularity",
      "detailed_description": "A Kubernetes operator that serves as a bridge between Kubernetes and Slurm Workload Manager. It allows for the submission and management of Slurm jobs directly from a Kubernetes environment, utilizing Singularity containers for HPC compatibility.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "workload_management",
        "hpc_integration"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/sylabs/wlm-operator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "slurm",
        "kubernetes",
        "singularity",
        "hpc"
      ],
      "id": 225
    },
    {
      "name": "pbstools",
      "one_line_profile": "Administration and management utilities for PBS/TORQUE HPC schedulers",
      "detailed_description": "A collection of utilities designed to assist in the administration, use, and management of PBS (Portable Batch System) variants, including OpenPBS, PBS Pro, and TORQUE, facilitating HPC cluster operations.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_administration",
        "job_management"
      ],
      "application_level": "library",
      "primary_language": "PHP",
      "repo_url": "https://github.com/tabaer/pbstools",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "pbs",
        "torque",
        "hpc",
        "scheduler"
      ],
      "id": 226
    },
    {
      "name": "Slurm4Azure",
      "one_line_profile": "Deployment scripts for Slurm Workload Manager on Microsoft Azure",
      "detailed_description": "A set of tools and scripts to deploy and configure the Slurm Workload Manager on Ubuntu instances within the Microsoft Azure cloud environment, enabling cloud-based HPC clusters.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_deployment",
        "cloud_hpc"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/tamhinsf/Slurm4Azure",
      "help_website": [],
      "license": null,
      "tags": [
        "slurm",
        "azure",
        "hpc",
        "cloud-computing"
      ],
      "id": 227
    },
    {
      "name": "GooseSLURM",
      "one_line_profile": "Command line wrappers and utilities for Slurm job submission",
      "detailed_description": "A collection of Python-based command line tools and scripts that simplify the interaction with the Slurm Workload Manager, providing convenient wrappers for job submission and management tasks.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "cli_utility"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tdegeus/GooseSLURM",
      "help_website": [
        "https://gooseslurm.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "slurm",
        "cli",
        "hpc",
        "job-management"
      ],
      "id": 228
    },
    {
      "name": "Cube Studio",
      "one_line_profile": "Cloud-native one-stop MLOps and AI platform supporting distributed training",
      "detailed_description": "An open-source, cloud-native AI platform that provides a full MLOps lifecycle, including notebook development, pipeline orchestration, and distributed training support (Ray, Volcano, Horovod). It integrates with Kubernetes for resource management and supports large model fine-tuning and inference.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "mlops",
        "distributed_training",
        "pipeline_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/tencentmusic/cube-studio",
      "help_website": [
        "https://github.com/tencentmusic/cube-studio/wiki"
      ],
      "license": "NOASSERTION",
      "tags": [
        "mlops",
        "kubernetes",
        "distributed-training",
        "volcano",
        "ray"
      ],
      "id": 229
    },
    {
      "name": "condorpy",
      "one_line_profile": "Python interface for HTCondor high-throughput computing system",
      "detailed_description": "A Python module that provides an interface to interact with HTCondor, allowing users to create, submit, and manage high-throughput computing jobs programmatically from Python scripts.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "htc_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tethysplatform/condorpy",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "htcondor",
        "htc",
        "job-scheduling",
        "python-wrapper"
      ],
      "id": 230
    },
    {
      "name": "Paperboy",
      "one_line_profile": "Web frontend for scheduling and executing Jupyter notebook reports",
      "detailed_description": "A web-based application for scheduling and running Jupyter notebooks as reports. It allows users to parameterize notebooks and schedule their execution, facilitating reproducible scientific reporting and automated analysis workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "notebook_scheduling",
        "workflow_automation",
        "reporting"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/tkp-archive/paperboy",
      "help_website": [
        "https://paperboy.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "jupyter",
        "scheduling",
        "reporting",
        "reproducibility"
      ],
      "id": 231
    },
    {
      "name": "Tuplex",
      "one_line_profile": "Parallel big data processing framework for optimizing Python data science pipelines",
      "detailed_description": "Tuplex is a parallel big data processing framework that compiles Python data science pipelines into optimized LLVM bytecode. It is designed to run Python code at the speed of compiled languages like C++, specifically targeting data cleaning and transformation tasks in scientific data analysis.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "data_processing",
        "pipeline_optimization",
        "parallel_computing"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/tuplex/tuplex",
      "help_website": [
        "https://tuplex.cs.brown.edu/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-science",
        "llvm",
        "parallel-processing",
        "python-optimization"
      ],
      "id": 232
    },
    {
      "name": "Cook",
      "one_line_profile": "Fair job scheduler for batch workloads and Spark on Kubernetes/Mesos",
      "detailed_description": "Cook is a fair job scheduler designed for batch workloads and Spark jobs, running on Kubernetes and Mesos. It provides advanced scheduling features like preemption, fair sharing, and resource pooling, suitable for high-performance computing and quantitative research environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "batch_scheduling",
        "resource_management",
        "spark_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Clojure",
      "repo_url": "https://github.com/twosigma/Cook",
      "help_website": [
        "https://github.com/twosigma/Cook/wiki"
      ],
      "license": "Apache-2.0",
      "tags": [
        "scheduler",
        "kubernetes",
        "batch-processing",
        "spark"
      ],
      "id": 233
    },
    {
      "name": "socker",
      "one_line_profile": "Wrapper for securely running Docker containers on Slurm clusters",
      "detailed_description": "A tool that wraps Docker execution to allow secure running of containers within a Slurm HPC environment. It addresses security concerns associated with running Docker in multi-user clusters by managing permissions and execution contexts.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_runtime",
        "hpc_security"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/unioslo/socker",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "docker",
        "slurm",
        "hpc",
        "container"
      ],
      "id": 234
    },
    {
      "name": "HTGS",
      "one_line_profile": "Hybrid Task Graph Scheduler API for high-performance computing",
      "detailed_description": "The Hybrid Task Graph Scheduler (HTGS) is an abstract execution model and API designed to facilitate the implementation of workflow systems for high-performance computing. It helps manage data dependencies and task scheduling across hybrid architectures.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "task_scheduling",
        "workflow_execution"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/usnistgov/HTGS",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "task-graph",
        "scheduler",
        "cpp"
      ],
      "id": 235
    },
    {
      "name": "Tensor Fusion",
      "one_line_profile": "GPU virtualization and pooling solution for optimizing AI cluster utilization",
      "detailed_description": "Tensor Fusion is a GPU virtualization and pooling solution designed to maximize GPU cluster utilization. It supports dynamic resource allocation and sharing for AI inference and training workloads, integrating with tools like Karpenter and PyTorch.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "gpu_virtualization",
        "resource_optimization",
        "ai_infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/veneratedcoin/tensor-fusion",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu-virtualization",
        "ai-infrastructure",
        "resource-pooling",
        "cuda"
      ],
      "id": 236
    },
    {
      "name": "Volcano",
      "one_line_profile": "Cloud Native Batch Scheduling System for Kubernetes",
      "detailed_description": "Volcano is a batch system built on Kubernetes, designed for high-performance computing (HPC) and big data workloads. It provides powerful scheduling capabilities such as gang scheduling, fair share, and queue management, making it a critical component for running AI and scientific workloads in cloud-native environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "batch_scheduling",
        "workload_management",
        "resource_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/volcano-sh/volcano",
      "help_website": [
        "https://volcano.sh/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "batch-processing",
        "scheduler",
        "hpc",
        "cncf"
      ],
      "id": 237
    },
    {
      "name": "Volcano Global",
      "one_line_profile": "Federation scheduler for multi-cluster management in Volcano ecosystem",
      "detailed_description": "A federation scheduler component for the Volcano batch system, enabling cross-cluster job scheduling and resource management for cloud-native AI and HPC workloads.",
      "domains": [
        "Infra/HPC",
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "scheduling",
        "cluster_federation"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/volcano-sh/volcano-global",
      "help_website": [
        "https://volcano.sh"
      ],
      "license": "Apache-2.0",
      "tags": [
        "scheduler",
        "kubernetes",
        "hpc",
        "federation",
        "volcano"
      ],
      "id": 238
    },
    {
      "name": "veTurboIO",
      "one_line_profile": "High-performance I/O library for PyTorch model files",
      "detailed_description": "A library developed by Volcano Engine to accelerate reading and writing of PyTorch model files, optimizing I/O performance for large-scale AI model training and inference.",
      "domains": [
        "Infra/HPC",
        "AI6"
      ],
      "subtask_category": [
        "io_optimization",
        "model_loading"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/volcengine/veTurboIO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pytorch",
        "io-optimization",
        "hpc",
        "ai-infrastructure"
      ],
      "id": 239
    },
    {
      "name": "verl",
      "one_line_profile": "Volcano Engine Reinforcement Learning library for LLMs",
      "detailed_description": "A high-performance Reinforcement Learning (RL) library designed for Large Language Models (LLMs), supporting flexible and scalable RLHF (Reinforcement Learning from Human Feedback) training workflows.",
      "domains": [
        "Infra/HPC",
        "AI6"
      ],
      "subtask_category": [
        "model_training",
        "reinforcement_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/volcengine/verl",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "rlhf",
        "reinforcement-learning",
        "training-framework"
      ],
      "id": 240
    },
    {
      "name": "prometheus-slurm-exporter",
      "one_line_profile": "Prometheus exporter for Slurm metrics",
      "detailed_description": "A tool that collects performance and status metrics from the Slurm workload manager and exports them for monitoring via Prometheus, essential for HPC cluster observability.",
      "domains": [
        "Infra/HPC",
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "monitoring",
        "cluster_management"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/vpenso/prometheus-slurm-exporter",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "slurm",
        "prometheus",
        "monitoring",
        "hpc",
        "exporter"
      ],
      "id": 241
    },
    {
      "name": "Slurmer",
      "one_line_profile": "TUI application for Slurm job management",
      "detailed_description": "A Terminal User Interface (TUI) tool for monitoring and managing jobs on Slurm-based HPC clusters, providing a user-friendly way to interact with the scheduler.",
      "domains": [
        "Infra/HPC",
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "monitoring"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/wjwei-handsome/Slurmer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "tui",
        "hpc",
        "job-management",
        "rust"
      ],
      "id": 242
    },
    {
      "name": "tmux-mpi",
      "one_line_profile": "Tool for launching MPI processes in tmux",
      "detailed_description": "A utility for launching and managing MPI (Message Passing Interface) processes within tmux windows, facilitating debugging and interactive monitoring of parallel HPC applications.",
      "domains": [
        "Infra/HPC",
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "process_launching",
        "debugging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wrs20/tmux-mpi",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mpi",
        "tmux",
        "hpc",
        "parallel-computing",
        "debugging"
      ],
      "id": 243
    },
    {
      "name": "xcube",
      "one_line_profile": "Python package for Earth observation data cubes",
      "detailed_description": "A Python package for generating, manipulating, and analyzing Earth observation data cubes, leveraging xarray, dask, and zarr for scalable scientific data processing.",
      "domains": [
        "Earth Science",
        "Scientific Data Analysis"
      ],
      "subtask_category": [
        "data_cube_generation",
        "geospatial_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/xcube-dev/xcube",
      "help_website": [
        "https://xcube.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "earth-observation",
        "data-cubes",
        "xarray",
        "dask",
        "geospatial"
      ],
      "id": 244
    },
    {
      "name": "slurm-for-ml",
      "one_line_profile": "Machine Learning workflow scripts for Slurm",
      "detailed_description": "A collection of scripts and configurations designed to streamline running Machine Learning workflows on Slurm-managed HPC clusters, handling job submission and environment setup.",
      "domains": [
        "Infra/HPC",
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_management",
        "job_submission"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/y0ast/slurm-for-ml",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "machine-learning",
        "hpc",
        "workflow"
      ],
      "id": 245
    },
    {
      "name": "cuda_scheduling_examiner",
      "one_line_profile": "Tool for examining GPU scheduling behavior",
      "detailed_description": "A utility for analyzing and understanding CUDA GPU scheduling behavior, useful for performance optimization and debugging of GPU-accelerated scientific applications.",
      "domains": [
        "Infra/HPC",
        "AI6"
      ],
      "subtask_category": [
        "performance_analysis",
        "scheduling_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/yalue/cuda_scheduling_examiner_mirror",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "cuda",
        "gpu",
        "scheduling",
        "performance-analysis",
        "hpc"
      ],
      "id": 246
    },
    {
      "name": "HPC-NOW",
      "one_line_profile": "Cross-platform multi-cloud HPC platform manager",
      "detailed_description": "A command-line tool to quickly deploy and manage High-Performance Computing (HPC) clusters across multiple cloud providers or local environments, simplifying scientific computing infrastructure setup.",
      "domains": [
        "Infra/HPC",
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_deployment",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/zhenrong-wang/hpc-now",
      "help_website": [
        "https://hpc-now.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "hpc",
        "cloud-computing",
        "cluster-management",
        "infrastructure"
      ],
      "id": 247
    }
  ]
}