{
  "generated_at": "2025-12-16T10:02:11.003205+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "AI4",
      "leaf_cluster_name": "科研评测-基准/指标/复现实验生态",
      "domain": "AI Toolchain",
      "typical_objects": "datasets/tasks",
      "task_chain": "任务→指标→自动评测→leaderboard→回归",
      "tool_form": "benchmark + eval harness"
    },
    "unit": {
      "unit_id": "AI4-02",
      "unit_name": "指标/统计检验/置信区间",
      "target_scale": "150–300",
      "coverage_tools": "metrics libs、stats"
    },
    "search": {
      "target_candidates": 300,
      "queries": [
        "[GH] Seaborn",
        "[GH] Yellowbrick",
        "[GH] Pingouin",
        "[GH] BERTScore",
        "[GH] SacreBLEU",
        "[GH] Statsmodels",
        "[GH] SciPy",
        "[GH] Scikit-learn",
        "[GH] Hugging Face Evaluate",
        "[GH] TorchMetrics",
        "[GH] evaluation metrics",
        "[GH] statistical significance",
        "[GH] confidence interval",
        "[GH] hypothesis testing",
        "[GH] model evaluation library",
        "[GH] performance metrics",
        "[GH] torchmetrics",
        "[GH] nlp metrics",
        "[GH] vision metrics",
        "[GH] bootstrap statistics",
        "[GH] significance test",
        "[GH] error analysis tool",
        "[GH] metric learning",
        "[GH] ranking metrics",
        "[WEB] machine learning evaluation metrics library github",
        "[WEB] statistical significance testing python github",
        "[WEB] model performance analysis tools github",
        "[WEB] confidence interval bootstrap library github",
        "[WEB] nlp evaluation metrics rouge bleu github",
        "[WEB] computer vision metrics library github"
      ],
      "total_candidates": 1283,
      "tool_candidates": 881,
      "final_tools": 337
    }
  },
  "tools": [
    {
      "name": "dabestr",
      "one_line_profile": "Data analysis tool using bootstrap estimation for robust statistical inference",
      "detailed_description": "A package for Data Analysis with Bootstrap-coupled ESTimation (DABEST). It provides a user-friendly interface to calculate and visualize effect sizes and their confidence intervals using bootstrap methods, moving away from traditional significance testing.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "estimation",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/ACCLAB/dabestr",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "statistics",
        "bootstrap",
        "estimation-plots",
        "r-package"
      ],
      "id": 1
    },
    {
      "name": "continual_rl",
      "one_line_profile": "Baselines and metrics library for continual reinforcement learning",
      "detailed_description": "A repository containing baselines, experiment specifications, and common metrics for continual reinforcement learning. It is designed to be easily extensible for new methods and facilitates reproducible research in continual RL.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "benchmarking",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AGI-Labs/continual_rl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "reinforcement-learning",
        "continual-learning",
        "benchmarks",
        "metrics"
      ],
      "id": 2
    },
    {
      "name": "MTT",
      "one_line_profile": "Bayesian multi-target tracking algorithms and evaluation metrics",
      "detailed_description": "Implementation of several Bayesian multi-target tracking algorithms, including Poisson multi-Bernoulli mixture filters. It specifically includes implementations of GOSPA and T-GOSPA metrics for evaluating tracking performance.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "object_tracking",
        "evaluation_metrics",
        "bayesian_filtering"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/Agarciafernandez/MTT",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "multi-target-tracking",
        "bayesian-methods",
        "gospa",
        "metrics"
      ],
      "id": 3
    },
    {
      "name": "eval4imagecaption",
      "one_line_profile": "Evaluation metrics toolkit for image captioning tasks",
      "detailed_description": "A collection of evaluation tools for image captioning, implementing standard metrics including BLEU, ROUGE-L, CIDEr, METEOR, and SPICE scores to assess the quality of generated captions.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "image_captioning",
        "evaluation_metrics",
        "nlp_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Aldenhovel/bleu-rouge-meteor-cider-spice-eval4imagecaption",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "image-captioning",
        "bleu",
        "rouge",
        "cider",
        "meteor"
      ],
      "id": 4
    },
    {
      "name": "GuardBench",
      "one_line_profile": "Evaluation library for guardrail models in AI safety",
      "detailed_description": "A Python library designed for the evaluation of guardrail models, facilitating the assessment of safety and compliance mechanisms in AI systems.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "ai_safety",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AmenRa/GuardBench",
      "help_website": [],
      "license": "EUPL-1.2",
      "tags": [
        "guardrails",
        "evaluation",
        "ai-safety",
        "benchmarking"
      ],
      "id": 5
    },
    {
      "name": "ttest",
      "one_line_profile": "JavaScript library for performing Student's t hypothesis tests",
      "detailed_description": "A lightweight JavaScript library to perform the Student's t hypothesis test, enabling statistical analysis directly within JavaScript environments.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_testing",
        "hypothesis_testing"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/AndreasMadsen/ttest",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "statistics",
        "t-test",
        "hypothesis-testing",
        "javascript"
      ],
      "id": 6
    },
    {
      "name": "rexmex",
      "one_line_profile": "General purpose recommender systems metrics library",
      "detailed_description": "A general-purpose library for evaluating recommender systems, providing a comprehensive set of metrics to ensure fair and standardized evaluation of recommendation algorithms.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "recommender_systems",
        "evaluation_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AstraZeneca/rexmex",
      "help_website": [],
      "license": null,
      "tags": [
        "recommender-systems",
        "metrics",
        "evaluation",
        "data-science"
      ],
      "id": 7
    },
    {
      "name": "SORDI-AI-Evaluation-GUI",
      "one_line_profile": "GUI tool for evaluating computer vision models on SORDI datasets",
      "detailed_description": "A graphical user interface tool developed by BMW Innovation Lab to evaluate trained computer vision models, specifically designed to work with the SORDI dataset ecosystem, providing general information and evaluation metrics.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "computer_vision",
        "metrics_visualization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/BMW-InnovationLab/SORDI-AI-Evaluation-GUI",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "computer-vision",
        "evaluation",
        "gui",
        "sordi"
      ],
      "id": 8
    },
    {
      "name": "scikit-llm",
      "one_line_profile": "Integration of Large Language Models into scikit-learn framework",
      "detailed_description": "A library that seamlessly integrates Large Language Models (LLMs) into the scikit-learn framework, allowing users to utilize LLMs for text analysis tasks (like classification and embedding) using the familiar sklearn API.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "text_analysis",
        "modeling",
        "nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BeastByteAI/scikit-llm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scikit-learn",
        "llm",
        "nlp",
        "text-classification"
      ],
      "id": 9
    },
    {
      "name": "madmom",
      "one_line_profile": "Python audio and music signal processing library",
      "detailed_description": "A comprehensive Python library for audio and music signal processing. It includes tools for feature extraction, beat tracking, onset detection, and other music information retrieval (MIR) tasks.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "signal_processing",
        "audio_analysis",
        "feature_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CPJKU/madmom",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "audio-processing",
        "music-information-retrieval",
        "signal-processing",
        "mir"
      ],
      "id": 10
    },
    {
      "name": "mAP",
      "one_line_profile": "Evaluation code for object detection neural networks",
      "detailed_description": "A widely used tool to calculate the mean Average Precision (mAP) for object detection models. It provides a standardized way to evaluate the performance of neural networks on detection tasks.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "object_detection",
        "evaluation_metrics",
        "performance_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Cartucho/mAP",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "computer-vision",
        "object-detection",
        "map",
        "metrics"
      ],
      "id": 11
    },
    {
      "name": "pymar",
      "one_line_profile": "Markov Switching Models extension for Statsmodels",
      "detailed_description": "A Python library that implements Markov Switching Models, designed to work with and extend the capabilities of the Statsmodels library for time series analysis.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "time_series_analysis",
        "statistical_modeling",
        "markov_models"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChadFulton/pymar",
      "help_website": [],
      "license": null,
      "tags": [
        "statsmodels",
        "time-series",
        "markov-switching",
        "statistics"
      ],
      "id": 12
    },
    {
      "name": "metric-learning-divide-and-conquer",
      "one_line_profile": "Implementation of Divide and Conquer the Embedding Space for Metric Learning",
      "detailed_description": "A PyTorch implementation of the 'Divide and Conquer the Embedding Space for Metric Learning' (CVPR 2019) approach, providing a solver for deep metric learning tasks by partitioning the embedding space.",
      "domains": [
        "AI4",
        "AI4-01"
      ],
      "subtask_category": [
        "metric_learning",
        "embedding_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CompVis/metric-learning-divide-and-conquer",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "metric-learning",
        "computer-vision",
        "embedding"
      ],
      "id": 13
    },
    {
      "name": "Deep-Metric-Learning-Baselines",
      "one_line_profile": "PyTorch implementation for Deep Metric Learning pipelines and baselines",
      "detailed_description": "A comprehensive library providing implementations of various deep metric learning algorithms and baselines in PyTorch, facilitating benchmarking and reproduction of metric learning experiments.",
      "domains": [
        "AI4",
        "AI4-01"
      ],
      "subtask_category": [
        "metric_learning",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Confusezius/Deep-Metric-Learning-Baselines",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deep-metric-learning",
        "pytorch",
        "benchmark"
      ],
      "id": 14
    },
    {
      "name": "Revisiting_Deep_Metric_Learning_PyTorch",
      "one_line_profile": "Code for benchmarking training strategies in Deep Metric Learning",
      "detailed_description": "The official repository for the ICML 2020 paper 'Revisiting Training Strategies and Generalization Performance in Deep Metric Learning', providing a framework for consistent research and evaluation in deep metric learning.",
      "domains": [
        "AI4",
        "AI4-01"
      ],
      "subtask_category": [
        "metric_learning",
        "evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Confusezius/Revisiting_Deep_Metric_Learning_PyTorch",
      "help_website": [
        "https://arxiv.org/abs/2002.08473"
      ],
      "license": "MIT",
      "tags": [
        "metric-learning",
        "generalization",
        "icml-2020"
      ],
      "id": 15
    },
    {
      "name": "Avalanche",
      "one_line_profile": "End-to-End Library for Continual Learning based on PyTorch",
      "detailed_description": "A comprehensive library for Continual Learning (CL) research, providing benchmarks, metrics, and evaluation protocols to assess the performance of CL algorithms.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "continual_learning",
        "evaluation_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ContinualAI/avalanche",
      "help_website": [
        "https://avalanche.continualai.org"
      ],
      "license": "MIT",
      "tags": [
        "continual-learning",
        "pytorch",
        "benchmarks"
      ],
      "id": 16
    },
    {
      "name": "Yellowbrick",
      "one_line_profile": "Visual analysis and diagnostic tools for machine learning model selection",
      "detailed_description": "A suite of visual analysis and diagnostic tools designed to facilitate machine learning model selection, enabling data scientists to steer the model selection process.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_visualization",
        "model_selection",
        "diagnostics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DistrictDataLabs/yellowbrick",
      "help_website": [
        "https://www.scikit-yb.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "machine-learning",
        "model-selection"
      ],
      "id": 17
    },
    {
      "name": "ESMValTool",
      "one_line_profile": "Community diagnostic and performance metrics tool for Earth system models",
      "detailed_description": "A community diagnostic and performance metrics tool for routine evaluation of Earth system models in CMIP, facilitating the analysis of climate data and model performance.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "climate_model_evaluation",
        "diagnostics",
        "earth_system_modeling"
      ],
      "application_level": "platform",
      "primary_language": "NCL",
      "repo_url": "https://github.com/ESMValGroup/ESMValTool",
      "help_website": [
        "https://esmvaltool.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "climate-science",
        "cmip",
        "model-evaluation"
      ],
      "id": 18
    },
    {
      "name": "BlonDe",
      "one_line_profile": "Automatic Evaluation Metric for Document-level Machine Translation",
      "detailed_description": "Official implementation of BlonDe, an automatic evaluation metric designed for document-level machine translation, focusing on discourse-related phenomena.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "machine_translation_evaluation",
        "nlp_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EleanorJiang/BlonDe",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "metrics",
        "machine-translation"
      ],
      "id": 19
    },
    {
      "name": "TPOT",
      "one_line_profile": "Automated Machine Learning tool using genetic programming",
      "detailed_description": "A Python Automated Machine Learning (AutoML) tool that optimizes machine learning pipelines using genetic programming to automate the process of feature selection, model selection, and parameter tuning.",
      "domains": [
        "AI4",
        "AI4-01"
      ],
      "subtask_category": [
        "automl",
        "pipeline_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/EpistasisLab/tpot",
      "help_website": [
        "http://epistasislab.github.io/tpot/"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "automl",
        "genetic-programming",
        "machine-learning"
      ],
      "id": 20
    },
    {
      "name": "LanguageGuidance_for_DML",
      "one_line_profile": "Integrating Language Guidance into Vision-based Deep Metric Learning",
      "detailed_description": "Implementation of a method for integrating language guidance into vision-based deep metric learning, as presented in CVPR 2022.",
      "domains": [
        "AI4",
        "AI4-01"
      ],
      "subtask_category": [
        "metric_learning",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ExplainableML/LanguageGuidance_for_DML",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deep-metric-learning",
        "vision-language",
        "cvpr-2022"
      ],
      "id": 21
    },
    {
      "name": "Dolmen",
      "one_line_profile": "Library to parse, typecheck, and evaluate automated deduction languages",
      "detailed_description": "A library and binary tool to parse, typecheck, and evaluate various languages used in automated deduction and formal verification.",
      "domains": [
        "AI4",
        "AI4-01"
      ],
      "subtask_category": [
        "automated_deduction",
        "parsing",
        "formal_methods"
      ],
      "application_level": "library",
      "primary_language": "OCaml",
      "repo_url": "https://github.com/Gbury/dolmen",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "automated-deduction",
        "parsing",
        "logic"
      ],
      "id": 22
    },
    {
      "name": "PixTrack",
      "one_line_profile": "Object Tracking using NeRF templates and feature-metric alignment",
      "detailed_description": "A Computer Vision method for Object Tracking which uses NeRF templates and feature-metric alignment to robustly track the 6DoF pose of a known object.",
      "domains": [
        "AI4",
        "AI4-01"
      ],
      "subtask_category": [
        "object_tracking",
        "nerf",
        "pose_estimation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/GiantAI/pixtrack",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "computer-vision",
        "nerf",
        "tracking"
      ],
      "id": 23
    },
    {
      "name": "TextDescriptives",
      "one_line_profile": "Library for calculating a large variety of metrics from text",
      "detailed_description": "A Python library for calculating a wide range of text metrics, including readability, complexity, and other linguistic features, useful for NLP analysis.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "text_metrics",
        "nlp_analysis",
        "readability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HLasse/TextDescriptives",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "metrics",
        "text-analysis"
      ],
      "id": 24
    },
    {
      "name": "MM-SHAP",
      "one_line_profile": "Metric for Measuring Multimodal Contributions in Vision and Language Models",
      "detailed_description": "Official implementation of MM-SHAP, a performance-agnostic metric for measuring multimodal contributions in vision and language models and tasks.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_interpretability",
        "multimodal_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Heidelberg-NLP/MM-SHAP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "shap",
        "multimodal",
        "interpretability"
      ],
      "id": 25
    },
    {
      "name": "Few-shot-via-ensembling-Transformer-with-Mahalanobis-distance",
      "one_line_profile": "Few-Shot Bearing Fault Diagnosis via Ensembling Transformer and Mahalanobis Distance",
      "detailed_description": "Implementation of a few-shot bearing fault diagnosis method using an ensembling Transformer-based model with Mahalanobis distance metric learning.",
      "domains": [
        "AI4",
        "AI4-01"
      ],
      "subtask_category": [
        "fault_diagnosis",
        "metric_learning",
        "few_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HungVu307/Few-shot-via-ensembling-Transformer-with-Mahalanobis-distance",
      "help_website": [],
      "license": null,
      "tags": [
        "fault-diagnosis",
        "transformer",
        "metric-learning"
      ],
      "id": 26
    },
    {
      "name": "MUTIS",
      "one_line_profile": "Analysis of correlations of light curves and their statistical significance",
      "detailed_description": "A Python package developed by IAA-CSIC for the analysis of correlations of light curves and their statistical significance in astrophysical data.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "time_series_analysis",
        "correlation_analysis",
        "astrophysics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IAA-CSIC/MUTIS",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "astronomy",
        "statistics",
        "light-curves"
      ],
      "id": 27
    },
    {
      "name": "transition-amr-parser",
      "one_line_profile": "AMR parsing with word-node alignments and Smatch metrics",
      "detailed_description": "State-of-the-Art Abstract Meaning Representation (AMR) parsing tool with word-node alignments, including tools for statistical significance testing using Smatch.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "amr_parsing",
        "nlp_evaluation",
        "smatch_metric"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/IBM/transition-amr-parser",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "amr",
        "parsing"
      ],
      "id": 28
    },
    {
      "name": "ImagePy",
      "one_line_profile": "Image processing framework based on plugins",
      "detailed_description": "An image processing framework based on a plugin architecture (similar to ImageJ), designed to easily integrate with Scipy, Scikit-image, OpenCV, and other Numpy-based libraries for scientific image analysis.",
      "domains": [
        "AI4",
        "AI4-01"
      ],
      "subtask_category": [
        "image_processing",
        "scientific_imaging"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Image-Py/imagepy",
      "help_website": [],
      "license": "BSD-4-Clause",
      "tags": [
        "image-processing",
        "microscopy",
        "scientific-imaging"
      ],
      "id": 29
    },
    {
      "name": "TrackEval",
      "one_line_profile": "Evaluation metrics library for Multi-Object Tracking (MOT)",
      "detailed_description": "A Python library providing implementations of various evaluation metrics for Multi-Object Tracking (MOT), including HOTA, CLEAR, and Identity metrics.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics_calculation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/JonathonLuiten/TrackEval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mot",
        "evaluation-metrics",
        "computer-vision"
      ],
      "id": 30
    },
    {
      "name": "Distances.jl",
      "one_line_profile": "Julia package for evaluating distances and metrics between vectors",
      "detailed_description": "A Julia package that provides a collection of distance metrics and divergence measures for evaluating the similarity or dissimilarity between vectors, essential for statistical analysis and machine learning.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metrics_calculation",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaStats/Distances.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "julia",
        "distance-metrics",
        "statistics"
      ],
      "id": 31
    },
    {
      "name": "HypothesisTests.jl",
      "one_line_profile": "Hypothesis testing library for Julia",
      "detailed_description": "A comprehensive Julia package for conducting various statistical hypothesis tests, including t-tests, chi-squared tests, and non-parametric tests.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_testing",
        "hypothesis_testing"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaStats/HypothesisTests.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "statistics",
        "hypothesis-testing"
      ],
      "id": 32
    },
    {
      "name": "StatsModels.jl",
      "one_line_profile": "Statistical model specification and fitting in Julia",
      "detailed_description": "A Julia package for specifying, fitting, and evaluating statistical models using a formula-based interface similar to R, facilitating statistical analysis and inference.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_modeling",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaStats/StatsModels.jl",
      "help_website": [],
      "license": null,
      "tags": [
        "julia",
        "statistical-modeling",
        "data-analysis"
      ],
      "id": 33
    },
    {
      "name": "common_metrics_on_video_quality",
      "one_line_profile": "Video quality evaluation metrics calculator",
      "detailed_description": "A Python toolkit to calculate common video quality metrics such as FVD, PSNR, SSIM, and LPIPS for evaluating generated or predicted videos.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "quality_control",
        "metrics_calculation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/JunyaoHu/common_metrics_on_video_quality",
      "help_website": [],
      "license": null,
      "tags": [
        "video-quality",
        "fvd",
        "psnr",
        "ssim"
      ],
      "id": 34
    },
    {
      "name": "deep-significance",
      "one_line_profile": "Statistical significance testing for deep neural networks",
      "detailed_description": "A Python tool designed to facilitate statistical significance testing specifically for comparing deep neural network models, ensuring robust performance evaluation.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_testing",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Kaleidophon/deep-significance",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "deep-learning",
        "significance-testing",
        "statistics"
      ],
      "id": 35
    },
    {
      "name": "DocumentFeatureSelection",
      "one_line_profile": "Metrics for feature selection from text data",
      "detailed_description": "A Python library providing a set of metrics and methods for selecting features from text data, aiding in NLP model optimization and analysis.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "feature_selection",
        "metrics_calculation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Kensuke-Mitsuzawa/DocumentFeatureSelection",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "nlp",
        "feature-selection",
        "text-mining"
      ],
      "id": 36
    },
    {
      "name": "pytorch-metric-learning",
      "one_line_profile": "Deep metric learning library for PyTorch",
      "detailed_description": "A comprehensive and modular PyTorch library for deep metric learning, providing loss functions, miners, and trainers to learn distance metrics for various applications.",
      "domains": [
        "AI4",
        "AI4-01",
        "AI4-02"
      ],
      "subtask_category": [
        "metric_learning",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KevinMusgrave/pytorch-metric-learning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "metric-learning",
        "deep-learning"
      ],
      "id": 37
    },
    {
      "name": "YACHT",
      "one_line_profile": "Hypothesis test for organism presence in metagenomes",
      "detailed_description": "A mathematically characterized hypothesis testing tool for determining the presence or absence of organisms in metagenomic samples, enabling scalable and accurate metagenome profiling.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "hypothesis_testing",
        "metagenomics"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/KoslickiLab/YACHT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "metagenomics",
        "hypothesis-testing"
      ],
      "id": 38
    },
    {
      "name": "FPChecker",
      "one_line_profile": "Floating-point error detection for HPC applications",
      "detailed_description": "A dynamic analysis tool developed by LLNL to detect floating-point errors and instabilities in High-Performance Computing (HPC) applications.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "quality_control",
        "numerical_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LLNL/FPChecker",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "floating-point",
        "debugging"
      ],
      "id": 39
    },
    {
      "name": "torchmetrics",
      "one_line_profile": "Machine learning metrics for PyTorch",
      "detailed_description": "A collection of machine learning metrics for distributed, scalable PyTorch applications, offering implementations of common metrics for classification, regression, and more.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metrics_calculation",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lightning-AI/torchmetrics",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pytorch",
        "metrics",
        "machine-learning"
      ],
      "id": 40
    },
    {
      "name": "MAC-VO",
      "one_line_profile": "Metrics-aware Covariance for Stereo Visual Odometry",
      "detailed_description": "A learning-based Stereo Visual Odometry solver that incorporates metrics-aware covariance estimation to improve trajectory accuracy and reliability.",
      "domains": [
        "AI4",
        "AI4-01",
        "AI4-02"
      ],
      "subtask_category": [
        "visual_odometry",
        "state_estimation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MAC-VO/MAC-VO",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visual-odometry",
        "robotics",
        "covariance-estimation"
      ],
      "id": 41
    },
    {
      "name": "SparseOcc",
      "one_line_profile": "Sparse 3D Occupancy Prediction and Evaluation",
      "detailed_description": "A fully sparse 3D occupancy prediction method that includes the RayIoU evaluation metric for assessing geometric accuracy in 3D vision tasks.",
      "domains": [
        "AI4",
        "AI4-01",
        "AI4-02"
      ],
      "subtask_category": [
        "occupancy_prediction",
        "model_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MCG-NJU/SparseOcc",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "3d-vision",
        "occupancy-prediction",
        "evaluation-metric"
      ],
      "id": 42
    },
    {
      "name": "opinionated",
      "one_line_profile": "Clean stylesheets for scientific plotting",
      "detailed_description": "A Python library providing opinionated, clean stylesheets for matplotlib and seaborn to create publication-quality scientific plots.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "visualization",
        "plotting"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/MNoichl/opinionated",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "matplotlib",
        "seaborn"
      ],
      "id": 43
    },
    {
      "name": "dcurves",
      "one_line_profile": "Decision Curve Analysis for prediction models",
      "detailed_description": "A Python package for performing Decision Curve Analysis (DCA), a method to evaluate prediction models and diagnostic tests by calculating net benefit.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "decision_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MSKCC-Epi-Bio/dcurves",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "decision-curve-analysis",
        "statistics",
        "medical-statistics"
      ],
      "id": 44
    },
    {
      "name": "pcr",
      "one_line_profile": "Analysis and statistical testing of qPCR data",
      "detailed_description": "An R package for quality assessment, analysis, and statistical significance testing of real-time quantitative PCR (qPCR) data.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "bioinformatics"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/MahShaaban/pcr",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "qpcr",
        "bioinformatics",
        "statistics"
      ],
      "id": 45
    },
    {
      "name": "nlg-eval",
      "one_line_profile": "Evaluation metrics for Natural Language Generation",
      "detailed_description": "A Python library containing code for various unsupervised automated metrics for evaluating Natural Language Generation (NLG) systems.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics_calculation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Maluuba/nlg-eval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "nlg",
        "evaluation-metrics",
        "nlp"
      ],
      "id": 46
    },
    {
      "name": "nervaluate",
      "one_line_profile": "Named Entity Recognition evaluation metrics",
      "detailed_description": "A Python library for full named-entity evaluation metrics based on SemEval-2013 standards, allowing for detailed performance analysis of NER models.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics_calculation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MantisAI/nervaluate",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ner",
        "evaluation-metrics",
        "nlp"
      ],
      "id": 47
    },
    {
      "name": "localization_evaluation_toolkit",
      "one_line_profile": "Toolkit for localization evaluation in robotics",
      "detailed_description": "A toolkit for evaluating localization algorithms, supporting CSV and ROS 2 bag formats, and providing error analysis and NDT performance metrics.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "robotics_localization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MapIV/localization_evaluation_toolkit",
      "help_website": [],
      "license": null,
      "tags": [
        "localization",
        "robotics",
        "evaluation"
      ],
      "id": 48
    },
    {
      "name": "volkscv",
      "one_line_profile": "Computer vision research toolbox",
      "detailed_description": "A Python toolbox designed to facilitate computer vision research and projects, providing common utilities and implementations.",
      "domains": [
        "AI4",
        "AI4-01",
        "AI4-02"
      ],
      "subtask_category": [
        "image_processing",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Media-Smart/volkscv",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "computer-vision",
        "toolbox",
        "research"
      ],
      "id": 49
    },
    {
      "name": "evo",
      "one_line_profile": "Evaluation package for odometry and SLAM",
      "detailed_description": "A Python package for the evaluation of odometry and SLAM trajectories, providing tools for trajectory alignment, error calculation, and visualization.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "slam_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MichaelGrupp/evo",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "slam",
        "odometry",
        "evaluation"
      ],
      "id": 50
    },
    {
      "name": "PySR",
      "one_line_profile": "High-performance symbolic regression",
      "detailed_description": "A high-performance symbolic regression library for Python and Julia, used to discover mathematical expressions that best describe a dataset.",
      "domains": [
        "AI4",
        "AI4-01"
      ],
      "subtask_category": [
        "symbolic_regression",
        "scientific_discovery"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MilesCranmer/PySR",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "symbolic-regression",
        "scientific-discovery",
        "machine-learning"
      ],
      "id": 51
    },
    {
      "name": "IOHMM",
      "one_line_profile": "Input Output Hidden Markov Models",
      "detailed_description": "A Python library for Input Output Hidden Markov Models (IOHMM), enabling statistical modeling of sequential data with inputs.",
      "domains": [
        "AI4",
        "AI4-01"
      ],
      "subtask_category": [
        "statistical_modeling",
        "sequence_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Mogeng/IOHMM",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "hmm",
        "statistical-modeling",
        "sequence-analysis"
      ],
      "id": 52
    },
    {
      "name": "Model_Log",
      "one_line_profile": "Lightweight ML/DL training metrics visualization",
      "detailed_description": "A lightweight Python tool for logging and visualizing machine learning and deep learning model training metrics such as loss, accuracy, precision, and F1 score.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "visualization",
        "experiment_tracking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NLP-LOVE/Model_Log",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "metrics",
        "experiment-tracking"
      ],
      "id": 53
    },
    {
      "name": "NVIDIA-NeMo/Evaluator",
      "one_line_profile": "Scalable and reproducible evaluation library for AI models and benchmarks",
      "detailed_description": "A library designed for the evaluation of AI models, particularly in the domains of Large Language Models (LLMs), Automatic Speech Recognition (ASR), and Text-to-Speech (TTS). It provides tools for running benchmarks and computing metrics.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking",
        "metrics_calculation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA-NeMo/Evaluator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "benchmarks",
        "llm",
        "asr",
        "tts"
      ],
      "id": 54
    },
    {
      "name": "CanarySEFI",
      "one_line_profile": "Framework for evaluating the robustness of deep learning image recognition models",
      "detailed_description": "A framework designed to evaluate model robustness and the effectiveness of attack/defense algorithms. It encompasses 26 metrics, supports multiple pre-trained models (CIFAR, ImageNet), and includes various attack and defense methods.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "robustness_evaluation",
        "adversarial_attack",
        "model_defense"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NeoSunJZ/Canary_Master",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "robustness",
        "adversarial-attacks",
        "deep-learning",
        "metrics"
      ],
      "id": 55
    },
    {
      "name": "ggforestplot",
      "one_line_profile": "R package for creating forest plots with confidence intervals",
      "detailed_description": "An R package designed to visualize measures of effects and their confidence intervals using forest plots, commonly used in medical and statistical research.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_visualization",
        "confidence_intervals"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/NightingaleHealth/ggforestplot",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "forestplot",
        "confidence-intervals",
        "r-package"
      ],
      "id": 56
    },
    {
      "name": "Open Metric Learning",
      "one_line_profile": "Library for metric learning pipelines and models",
      "detailed_description": "A library providing pipelines, models, and a model zoo for metric learning and retrieval tasks. It facilitates the training and evaluation of models designed to learn distance metrics.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metric_learning",
        "image_retrieval",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OML-Team/open-metric-learning",
      "help_website": [
        "https://oml-team.github.io/open-metric-learning/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "metric-learning",
        "retrieval",
        "pytorch"
      ],
      "id": 57
    },
    {
      "name": "Thermo4PFM",
      "one_line_profile": "Library to evaluate alloy compositions in Phase-Field models",
      "detailed_description": "A C++ library developed by ORNL for evaluating thermodynamic properties of alloy compositions, specifically designed for use within Phase-Field modeling simulations in materials science.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "materials_modeling",
        "thermodynamic_evaluation",
        "phase_field_simulation"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/ORNL/Thermo4PFM",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "materials-science",
        "thermodynamics",
        "phase-field",
        "calphad"
      ],
      "id": 58
    },
    {
      "name": "PyTorch-NLP",
      "one_line_profile": "Basic utilities for PyTorch Natural Language Processing",
      "detailed_description": "A library providing basic utilities, datasets, and metrics for Natural Language Processing (NLP) tasks using PyTorch. It simplifies common NLP operations and data handling.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "nlp_utilities",
        "text_processing",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PetrochukM/PyTorch-NLP",
      "help_website": [
        "https://pytorchnlp.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "nlp",
        "pytorch",
        "utilities"
      ],
      "id": 59
    },
    {
      "name": "basicTrendline",
      "one_line_profile": "R package for adding trendlines and confidence intervals",
      "detailed_description": "An R package that facilitates adding trendlines and confidence intervals for basic linear or nonlinear models to plots, including displaying the equation.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_visualization",
        "trendline_fitting",
        "confidence_intervals"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/PhDMeiwp/basicTrendline",
      "help_website": [],
      "license": null,
      "tags": [
        "r-package",
        "visualization",
        "statistics",
        "trendline"
      ],
      "id": 60
    },
    {
      "name": "ggtrendline",
      "one_line_profile": "R package for adding trendlines and confidence intervals to ggplot",
      "detailed_description": "An R package designed to add trendlines, confidence intervals, and regression equations to 'ggplot2' visualizations.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_visualization",
        "trendline_fitting",
        "confidence_intervals"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/PhDMeiwp/ggtrendline",
      "help_website": [],
      "license": null,
      "tags": [
        "r-package",
        "ggplot2",
        "visualization",
        "statistics"
      ],
      "id": 61
    },
    {
      "name": "Causal Canvas",
      "one_line_profile": "Tool for Causal discovery and Structural Learning",
      "detailed_description": "A tool for Causal discovery using Structural Learning and Probabilistic modelling. It includes features for error analysis of the learnt structure and Pearlian do-why inference.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "causal_discovery",
        "structural_learning",
        "probabilistic_modeling"
      ],
      "application_level": "platform",
      "primary_language": "HTML",
      "repo_url": "https://github.com/PlaytikaOSS/causal-canvas",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "causal-inference",
        "structural-learning",
        "probabilistic-modeling"
      ],
      "id": 62
    },
    {
      "name": "Person ReID Benchmark",
      "one_line_profile": "Systematic evaluation and benchmark for Person Re-Identification",
      "detailed_description": "A comprehensive benchmark and evaluation system for Person Re-Identification (ReID), covering features, metrics, and datasets to standardize performance assessment in the field.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "benchmarking",
        "model_evaluation",
        "person_reid"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/RSL-NEU/person-reid-benchmark",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "reid",
        "benchmark",
        "evaluation",
        "computer-vision"
      ],
      "id": 63
    },
    {
      "name": "LLMBox",
      "one_line_profile": "Comprehensive library for LLM training and evaluation",
      "detailed_description": "A library for implementing Large Language Models (LLMs), featuring a unified training pipeline and a comprehensive model evaluation framework.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "llm_evaluation",
        "model_training",
        "pipeline_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/RUCAIBox/LLMBox",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "evaluation",
        "training",
        "nlp"
      ],
      "id": 64
    },
    {
      "name": "Multi-Camera Object Tracking via Deep Metric Learning",
      "one_line_profile": "Implementation of multi-camera object tracking using deep metric learning",
      "detailed_description": "A solver implementation for multi-camera object tracking that leverages deep metric learning to transfer representations to a top-view perspective.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "object_tracking",
        "metric_learning",
        "computer_vision"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Robootx/Multi-Camera-Object-Tracking-via-Transferring-Representation-to-Top-View",
      "help_website": [],
      "license": null,
      "tags": [
        "tracking",
        "metric-learning",
        "multi-camera"
      ],
      "id": 65
    },
    {
      "name": "wv",
      "one_line_profile": "R package for standard and robust wavelet variance analysis",
      "detailed_description": "An R package providing tools to perform standard and robust wavelet variance analysis for time series signal processing, including inference tools like confidence intervals.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "time_series_analysis",
        "wavelet_variance",
        "statistical_inference"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/SMAC-Group/wv",
      "help_website": [],
      "license": null,
      "tags": [
        "wavelet-analysis",
        "time-series",
        "statistics",
        "r-package"
      ],
      "id": 66
    },
    {
      "name": "Hypothesis Testing for MT",
      "one_line_profile": "Statistical hypothesis testing for Machine Translation metrics",
      "detailed_description": "A tool to evaluate the statistical significance of BLEU scores by comparing Reference and Target files among different machine translation systems.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "hypothesis_testing",
        "mt_evaluation",
        "statistical_significance"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/STC-MT-i2/Hypothesis-Testing-for-MT",
      "help_website": [],
      "license": null,
      "tags": [
        "machine-translation",
        "hypothesis-testing",
        "bleu-score",
        "statistics"
      ],
      "id": 67
    },
    {
      "name": "guardians-mt-eval",
      "one_line_profile": "Metrics for Machine Translation Meta-Evaluation",
      "detailed_description": "Official repository for the ACL 2024 paper 'Guardians of the Machine Translation Meta-Evaluation', providing sentinel metrics for evaluating MT systems.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "mt_evaluation",
        "meta_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SapienzaNLP/guardians-mt-eval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "machine-translation",
        "evaluation",
        "metrics",
        "nlp"
      ],
      "id": 68
    },
    {
      "name": "TADAM",
      "one_line_profile": "Implementation of Task-Dependent Adaptive Metric for few-shot learning",
      "detailed_description": "Implementation of the TADAM algorithm (Task-Dependent Adaptive Metric) for improved few-shot learning, developed by ServiceNow Research.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "few_shot_learning",
        "metric_learning",
        "image_classification"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ServiceNow/TADAM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "few-shot-learning",
        "metric-learning",
        "computer-vision"
      ],
      "id": 69
    },
    {
      "name": "QAConv",
      "one_line_profile": "Interpretable and Generalizable Person Re-Identification methods",
      "detailed_description": "Implementation of QAConv (Query-Adaptive Convolution) and GS (Graph Sampling Based Deep Metric Learning) for Person Re-Identification tasks.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "person_reid",
        "metric_learning",
        "graph_sampling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ShengcaiLiao/QAConv",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "reid",
        "metric-learning",
        "computer-vision"
      ],
      "id": 70
    },
    {
      "name": "onemetric",
      "one_line_profile": "Unified metrics library for machine learning",
      "detailed_description": "A library designed to provide a unified interface for calculating various machine learning metrics, simplifying the evaluation process.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metrics_calculation",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SkalskiP/onemetric",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "metrics",
        "machine-learning",
        "evaluation"
      ],
      "id": 71
    },
    {
      "name": "Nyoka",
      "one_line_profile": "Python library for exporting ML models to PMML",
      "detailed_description": "A Python library that facilitates the export of machine learning models into PMML (Predictive Model Markup Language) standard, enabling model interoperability.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_export",
        "interoperability",
        "pmml"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SoftwareAG/nyoka",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pmml",
        "model-export",
        "machine-learning"
      ],
      "id": 72
    },
    {
      "name": "stable-audio-metrics",
      "one_line_profile": "Metrics for evaluating music and audio generative models",
      "detailed_description": "A library providing metrics specifically designed for evaluating long-form, full-band, and stereo generations from music and audio generative models.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "audio_evaluation",
        "generative_model_metrics",
        "music_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Stability-AI/stable-audio-metrics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "audio",
        "metrics",
        "generative-ai",
        "evaluation"
      ],
      "id": 73
    },
    {
      "name": "EasyCNTK",
      "one_line_profile": "C# wrapper library for CNTK Deep Learning API",
      "detailed_description": "A C# library that wraps the CNTK API to provide an easier interface for Deep Learning and Deep Reinforcement Learning, including implementation of layers, optimizers, and evaluation helpers.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "deep_learning",
        "model_training",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/StanislavGrigoriev/EasyCNTK",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "cntk",
        "deep-learning",
        "c-sharp",
        "wrapper"
      ],
      "id": 74
    },
    {
      "name": "valor",
      "one_line_profile": "Lightweight library for fast evaluation of machine learning models",
      "detailed_description": "A numpy-based library designed for fast and seamless evaluation of machine learning models, providing tools for computing various performance metrics.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics_calculation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Striveworks/valor",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation",
        "metrics",
        "machine-learning"
      ],
      "id": 75
    },
    {
      "name": "emh",
      "one_line_profile": "R Package for testing the Efficient Market Hypothesis",
      "detailed_description": "An R package providing statistical tests and tools for evaluating the Efficient Market Hypothesis (EMH) in financial economics.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "hypothesis_testing",
        "financial_analysis",
        "statistical_testing"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/StuartGordonReid/emh",
      "help_website": [],
      "license": null,
      "tags": [
        "economics",
        "finance",
        "hypothesis-testing",
        "r-package"
      ],
      "id": 76
    },
    {
      "name": "ImagenHub",
      "one_line_profile": "Standardized evaluation and inference library for conditional image generation models",
      "detailed_description": "A comprehensive library designed to standardize the inference and evaluation processes for various conditional image generation models, facilitating fair comparison and benchmarking.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking",
        "image_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TIGER-AI-Lab/ImagenHub",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "generative-ai",
        "evaluation",
        "benchmarking",
        "image-generation"
      ],
      "id": 77
    },
    {
      "name": "VideoGenHub",
      "one_line_profile": "Standardized evaluation and inference library for conditional video generation models",
      "detailed_description": "A one-stop library to standardize the inference and evaluation of conditional video generation models, providing metrics and workflows for assessing video quality and consistency.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking",
        "video_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TIGER-AI-Lab/VideoGenHub",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "video-generation",
        "evaluation",
        "benchmarking"
      ],
      "id": 78
    },
    {
      "name": "DiscreteSpeechMetrics",
      "one_line_profile": "Reference-aware automatic speech evaluation toolkit",
      "detailed_description": "A toolkit providing reference-aware automatic evaluation metrics for speech generation tasks, focusing on discrete speech representations.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "speech_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Takaaki-Saeki/DiscreteSpeechMetrics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "speech-processing",
        "evaluation-metrics",
        "audio"
      ],
      "id": 79
    },
    {
      "name": "eli5",
      "one_line_profile": "Library for debugging and explaining machine learning classifiers",
      "detailed_description": "A Python library which allows to visualize and debug various machine learning models using unified API. It has built-in support for several ML frameworks and provides ways to explain black-box models.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_interpretation",
        "debugging",
        "explanation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TeamHG-Memex/eli5",
      "help_website": [
        "https://eli5.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "interpretability",
        "machine-learning",
        "debugging"
      ],
      "id": 80
    },
    {
      "name": "tonic_validate",
      "one_line_profile": "Metrics framework for evaluating RAG application responses",
      "detailed_description": "A library providing metrics to evaluate the quality of responses from Retrieval Augmented Generation (RAG) applications, helping developers assess answer correctness and relevance.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "rag_evaluation",
        "metrics",
        "llm_validation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TonicAI/tonic_validate",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "llm",
        "evaluation",
        "metrics"
      ],
      "id": 81
    },
    {
      "name": "AIF360",
      "one_line_profile": "Comprehensive toolkit for fairness metrics and bias mitigation",
      "detailed_description": "The AI Fairness 360 toolkit is an extensible open source library to help detect and mitigate bias in machine learning models throughout the AI application lifecycle.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "fairness_evaluation",
        "bias_mitigation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Trusted-AI/AIF360",
      "help_website": [
        "https://aif360.mybluemix.net/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "fairness",
        "bias",
        "machine-learning",
        "ethics"
      ],
      "id": 82
    },
    {
      "name": "HtFLlib",
      "one_line_profile": "Heterogeneous Federated Learning library",
      "detailed_description": "A library designed to support model heterogeneity in Federated Learning, allowing consistent GPU memory usage for single or multiple clients and simplifying configuration.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "federated_learning",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TsingZ0/HtFLlib",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "federated-learning",
        "heterogeneity",
        "distributed-systems"
      ],
      "id": 83
    },
    {
      "name": "MI-optimize",
      "one_line_profile": "Tool for quantization and evaluation of LLMs",
      "detailed_description": "A versatile tool designed for the quantization and evaluation of large language models (LLMs), integrating various quantization methods and evaluation techniques.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_quantization",
        "model_evaluation",
        "llm"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TsingmaoAI/MI-optimize",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "quantization",
        "llm",
        "evaluation"
      ],
      "id": 84
    },
    {
      "name": "LLM-judge-reporting",
      "one_line_profile": "Framework for bias correction and confidence intervals in LLM evaluation",
      "detailed_description": "A plug-in framework that corrects bias and computes confidence intervals in reporting LLM-as-a-judge evaluation, including an adaptive algorithm for sample allocation.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "bias_correction",
        "llm_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/UW-Madison-Lee-Lab/LLM-judge-reporting",
      "help_website": [],
      "license": null,
      "tags": [
        "statistics",
        "llm-as-a-judge",
        "confidence-intervals"
      ],
      "id": 85
    },
    {
      "name": "scope",
      "one_line_profile": "Package for detecting oscillatory signals in time series",
      "detailed_description": "A Python-based package for detecting oscillatory signals in observational or experimental time series using the Empirical Mode Decomposition (EMD) technique and assessing statistical significance.",
      "domains": [
        "AI4",
        "Physics"
      ],
      "subtask_category": [
        "time_series_analysis",
        "signal_detection",
        "statistical_testing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Warwick-Solar/scope",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "time-series",
        "oscillations",
        "emd",
        "physics"
      ],
      "id": 86
    },
    {
      "name": "Adansons Base",
      "one_line_profile": "Data programming tool for error-analysis and dataset organization",
      "detailed_description": "A tool for error-analysis of training results that organizes metadata of unstructured data, creates datasets, and helps find low-quality data to improve AI performance.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "data_quality_control",
        "error_analysis",
        "dataset_management"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/adansons/base",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-centric-ai",
        "error-analysis",
        "dataset-creation"
      ],
      "id": 87
    },
    {
      "name": "Flower",
      "one_line_profile": "A Friendly Federated AI Framework",
      "detailed_description": "A unified framework for federated learning, analytics, and evaluation. It allows running federated learning workloads on heterogeneous devices and scales to large numbers of clients.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "federated_learning",
        "distributed_training",
        "privacy_preserving_ml"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/adap/flower",
      "help_website": [
        "https://flower.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "federated-learning",
        "distributed-ml",
        "privacy"
      ],
      "id": 88
    },
    {
      "name": "object-centric-library",
      "one_line_profile": "Library for training and evaluation of object-centric models",
      "detailed_description": "A library dedicated to the training and evaluation of object-centric machine learning models, facilitating research in object-centric representation learning.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_training",
        "model_evaluation",
        "object_centric_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/addtt/object-centric-library",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "object-centric",
        "representation-learning",
        "evaluation"
      ],
      "id": 89
    },
    {
      "name": "ahkab",
      "one_line_profile": "SPICE-like electronic circuit simulator",
      "detailed_description": "A SPICE-like electronic circuit simulator written in Python, capable of performing time-domain analysis, AC analysis, and operating point analysis.",
      "domains": [
        "Physics",
        "Electronics"
      ],
      "subtask_category": [
        "circuit_simulation",
        "scientific_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ahkab/ahkab",
      "help_website": [
        "https://ahkab.readthedocs.io/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "circuit-simulation",
        "spice",
        "electronics"
      ],
      "id": 90
    },
    {
      "name": "Featuretools",
      "one_line_profile": "Automated feature engineering library for transforming temporal and relational datasets",
      "detailed_description": "Featuretools is an open source library for performing automated feature engineering. It excels at transforming temporal and relational datasets into feature matrices for machine learning, using a method known as Deep Feature Synthesis.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "feature_engineering",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/alteryx/featuretools",
      "help_website": [
        "https://featuretools.alteryx.com/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "feature-engineering",
        "automl",
        "data-science"
      ],
      "id": 91
    },
    {
      "name": "BOLD",
      "one_line_profile": "Dataset and metrics for measuring biases in open-ended language generation",
      "detailed_description": "BOLD (Bias in Open-Ended Language Generation Dataset) is a dataset and associated metrics designed to evaluate fairness and bias in open-ended language generation models across multiple domains.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "bias_evaluation",
        "fairness_metrics"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/amazon-science/bold",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "bias",
        "nlp",
        "evaluation-metrics"
      ],
      "id": 92
    },
    {
      "name": "werpy",
      "one_line_profile": "Fast Python package for calculating Word Error Rate (WER) in speech recognition",
      "detailed_description": "A lightweight and fast Python library specifically designed for calculating and analyzing the Word Error Rate (WER), a common metric for evaluating automatic speech recognition (ASR) systems.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "speech_recognition_evaluation",
        "metric_calculation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/analyticsinmotion/werpy",
      "help_website": [
        "https://pypi.org/project/werpy/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "wer",
        "speech-recognition",
        "metrics"
      ],
      "id": 93
    },
    {
      "name": "newsreclib",
      "one_line_profile": "PyTorch-Lightning library for neural news recommendation models",
      "detailed_description": "A library built on PyTorch-Lightning for developing, training, and evaluating neural news recommendation systems, providing standard metrics and model implementations.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "recommendation_system",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/andreeaiana/newsreclib",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "recommender-system",
        "pytorch-lightning",
        "news-recommendation"
      ],
      "id": 94
    },
    {
      "name": "ml_uncertainty",
      "one_line_profile": "Library for prediction intervals and uncertainty estimation in ML models",
      "detailed_description": "A Python library to obtain prediction intervals, confidence intervals, and parameter uncertainties for various machine learning models, aiding in the reliability assessment of predictions.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "uncertainty_estimation",
        "confidence_intervals"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/architdatar/ml_uncertainty",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "uncertainty",
        "confidence-intervals",
        "machine-learning"
      ],
      "id": 95
    },
    {
      "name": "PCAtest",
      "one_line_profile": "R package for statistical significance testing of PCA",
      "detailed_description": "An R package designed to evaluate the statistical significance of Principal Component Analysis (PCA) results, helping to determine the number of significant axes and variable contributions.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_testing",
        "pca_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/arleyc/PCAtest",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pca",
        "statistics",
        "significance-testing"
      ],
      "id": 96
    },
    {
      "name": "FactScoreLite",
      "one_line_profile": "Lightweight implementation of FactScore metric for text generation",
      "detailed_description": "A Python package implementing the FactScore metric for assessing the factual accuracy of generated text, serving as a maintained alternative to the original repository.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "text_generation_evaluation",
        "factuality_metric"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/armingh2000/FactScoreLite",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "metrics",
        "factuality"
      ],
      "id": 97
    },
    {
      "name": "T-NER",
      "one_line_profile": "Library for Transformer-based Named Entity Recognition evaluation and fine-tuning",
      "detailed_description": "T-NER is a Python library for fine-tuning transformer-based language models on Named Entity Recognition (NER) tasks, featuring cross-domain evaluation capabilities and an easy-to-use interface.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "ner_evaluation",
        "model_finetuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/asahi417/tner",
      "help_website": [
        "https://pypi.org/project/tner/"
      ],
      "license": "MIT",
      "tags": [
        "ner",
        "transformers",
        "evaluation"
      ],
      "id": 98
    },
    {
      "name": "hypothetical",
      "one_line_profile": "Hypothesis and statistical testing library for Python",
      "detailed_description": "A Python library dedicated to hypothesis testing and statistical analysis, providing a collection of statistical tests and tools similar to those found in R or other statistical software.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "hypothesis_testing",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aschleg/hypothetical",
      "help_website": [
        "https://hypothetical.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "statistics",
        "hypothesis-testing",
        "python"
      ],
      "id": 99
    },
    {
      "name": "SimSIMD",
      "one_line_profile": "High-performance SIMD-accelerated similarity metrics and dot products",
      "detailed_description": "SimSIMD provides ultra-fast implementations of distance and similarity metrics (like cosine similarity, dot product) using SIMD instructions (AVX2, AVX-512, NEON, SVE) for multiple languages including Python and C.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "similarity_metric",
        "vector_math"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/ashvardanian/SimSIMD",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "simd",
        "metrics",
        "performance"
      ],
      "id": 100
    },
    {
      "name": "hypors",
      "one_line_profile": "Hypothesis testing library for Polars dataframes",
      "detailed_description": "A Rust-based library that brings statistical hypothesis testing capabilities directly to Polars dataframes, enabling efficient statistical analysis on large datasets.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "hypothesis_testing",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/astronights/hypors",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "polars",
        "statistics",
        "rust"
      ],
      "id": 101
    },
    {
      "name": "AutoGluon",
      "one_line_profile": "Automated machine learning library for tabular, text, and image data",
      "detailed_description": "AutoGluon automates machine learning tasks, enabling users to achieve strong predictive performance with minimal code. It handles feature engineering, model selection, and ensembling.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "automl",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/autogluon/autogluon",
      "help_website": [
        "https://auto.gluon.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "automl",
        "machine-learning",
        "deep-learning"
      ],
      "id": 102
    },
    {
      "name": "auto-sklearn",
      "one_line_profile": "Automated machine learning toolkit based on scikit-learn",
      "detailed_description": "auto-sklearn is an automated machine learning toolkit and a drop-in replacement for a scikit-learn estimator. It leverages Bayesian optimization, meta-learning, and ensemble construction to automate the ML pipeline.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "automl",
        "model_selection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/automl/auto-sklearn",
      "help_website": [
        "https://automl.github.io/auto-sklearn/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "automl",
        "scikit-learn",
        "optimization"
      ],
      "id": 103
    },
    {
      "name": "Kolibri",
      "one_line_profile": "Framework for search system evaluation and batch processing",
      "detailed_description": "Kolibri is a Scala-based framework designed for concurrent multi-node execution of search system evaluations. It provides out-of-the-box functionality for common IR metrics like NDCG, ERR, Precision, and Recall.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "search_evaluation",
        "ranking_metrics"
      ],
      "application_level": "workflow",
      "primary_language": "Scala",
      "repo_url": "https://github.com/awagen/kolibri",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "information-retrieval",
        "metrics"
      ],
      "id": 104
    },
    {
      "name": "ErrorAnalysisToolkit",
      "one_line_profile": "MATLAB toolkit for image registration and tracking error analysis",
      "detailed_description": "A collection of MATLAB tools designed to examine and quantify errors in image registration and tracking tasks, useful for medical imaging or computer vision research.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "image_registration",
        "error_analysis"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/awiles/ErrorAnalysisToolkit",
      "help_website": [],
      "license": null,
      "tags": [
        "matlab",
        "image-processing",
        "error-analysis"
      ],
      "id": 105
    },
    {
      "name": "fmeval",
      "one_line_profile": "Library for evaluating Foundation Models",
      "detailed_description": "A library provided by AWS to evaluate Foundation Models (FMs) across various dimensions such as accuracy, toxicity, bias, and robustness, facilitating responsible AI development.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "llm_evaluation",
        "foundation_model_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aws/fmeval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "evaluation",
        "responsible-ai"
      ],
      "id": 106
    },
    {
      "name": "ggBrackets",
      "one_line_profile": "ggplot2 extension for annotating plots with statistical significance brackets",
      "detailed_description": "An R package that adds a layer to ggplot2 for drawing brackets annotated with p-values and significance testing results, facilitating the visualization of statistical comparisons.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_visualization",
        "significance_annotation"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/azzoam/ggBrackets",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "r",
        "ggplot2",
        "visualization"
      ],
      "id": 107
    },
    {
      "name": "fancylit",
      "one_line_profile": "Streamlit wrapper for data visualization and modeling tasks",
      "detailed_description": "A Python module that provides pre-packaged Streamlit components to facilitate data exploration, visualization, and running simple modeling tasks, acting as a lightweight data science tool.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "data_visualization",
        "data_exploration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/banjtheman/fancylit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "streamlit",
        "visualization",
        "data-science"
      ],
      "id": 108
    },
    {
      "name": "nlg-metrics",
      "one_line_profile": "Library for Natural Language Generation evaluation metrics",
      "detailed_description": "A Python library implementing various metrics for evaluating Natural Language Generation (NLG) systems, helping researchers assess the quality of generated text.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "nlg_evaluation",
        "text_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/baojunshan/nlg-metrics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlg",
        "metrics",
        "nlp"
      ],
      "id": 109
    },
    {
      "name": "linearmodels",
      "one_line_profile": "Extended linear models for Python including panel data and IV",
      "detailed_description": "A Python library that extends statsmodels with additional linear models, specifically focusing on instrumental variable models, panel data models, and asset pricing tests.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_modeling",
        "econometrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bashtage/linearmodels",
      "help_website": [
        "https://bashtage.github.io/linearmodels/"
      ],
      "license": "NCSA",
      "tags": [
        "econometrics",
        "statistics",
        "panel-data"
      ],
      "id": 110
    },
    {
      "name": "timbre-dissimilarity-metrics",
      "one_line_profile": "Metrics for evaluating audio timbre dissimilarity",
      "detailed_description": "A collection of metrics implemented using the TorchMetrics API for evaluating timbre dissimilarity in audio signals, useful for music information retrieval and audio synthesis research.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "audio_analysis",
        "timbre_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ben-hayes/timbre-dissimilarity-metrics",
      "help_website": [],
      "license": null,
      "tags": [
        "audio",
        "metrics",
        "timbre"
      ],
      "id": 111
    },
    {
      "name": "Metrics",
      "one_line_profile": "Collection of machine learning evaluation metrics",
      "detailed_description": "A repository containing implementations of various machine learning evaluation metrics in Python, R, Haskell, and MATLAB, often used in data science competitions.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metric_calculation",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/benhamner/Metrics",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "metrics",
        "machine-learning",
        "evaluation"
      ],
      "id": 112
    },
    {
      "name": "drtmle",
      "one_line_profile": "Nonparametric estimators of average treatment effect with doubly-robust confidence intervals",
      "detailed_description": "An R package that implements nonparametric estimators of the average treatment effect with doubly-robust confidence intervals and hypothesis tests, suitable for causal inference.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_inference",
        "hypothesis_testing"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/benkeser/drtmle",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "causal-inference",
        "statistics",
        "confidence-intervals"
      ],
      "id": 113
    },
    {
      "name": "Orange3",
      "one_line_profile": "Interactive data analysis and visualization workflow tool",
      "detailed_description": "An open-source machine learning and data visualization software. It features a visual programming front-end for explorative data analysis and interactive data visualization, and can also be used as a Python library.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "data_analysis",
        "visualization",
        "modeling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/biolab/orange3",
      "help_website": [
        "https://orangedatamining.com/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "data-mining",
        "machine-learning",
        "visualization"
      ],
      "id": 114
    },
    {
      "name": "Deep_Metric",
      "one_line_profile": "Library for Deep Metric Learning algorithms",
      "detailed_description": "A repository providing implementations for various Deep Metric Learning algorithms, facilitating the learning of distance metrics for tasks like image retrieval and clustering.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metric_learning",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bnu-wangxun/Deep_Metric",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "metric-learning",
        "deep-learning",
        "computer-vision"
      ],
      "id": 115
    },
    {
      "name": "freqtables",
      "one_line_profile": "R package for creating descriptive statistics tables",
      "detailed_description": "A package designed to quickly make tables of descriptive statistics (counts, percentages, confidence intervals) for categorical variables, compatible with tidyverse pipelines.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "descriptive_statistics",
        "reporting"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/brad-cannell/freqtables",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "statistics",
        "r-package",
        "data-analysis"
      ],
      "id": 116
    },
    {
      "name": "poverlap",
      "one_line_profile": "Significance testing over interval overlaps",
      "detailed_description": "A tool for calculating the significance of overlaps between genomic intervals or other interval data, useful in bioinformatics and statistical analysis of spatial data.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_testing",
        "genomics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/brentp/poverlap",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "statistics",
        "intervals"
      ],
      "id": 117
    },
    {
      "name": "Granger",
      "one_line_profile": "Frequency-domain Granger causality with significance testing",
      "detailed_description": "Matlab code for performing frequency-domain Granger causality analysis, including significance testing to determine causal relationships in time series data.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "causality_analysis",
        "time_series_analysis"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/brian-lau/Granger",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "granger-causality",
        "matlab",
        "statistics"
      ],
      "id": 118
    },
    {
      "name": "MatlabAUC",
      "one_line_profile": "AUC calculation with confidence intervals in Matlab",
      "detailed_description": "Matlab code for calculating the area under the receiver operating characteristic curve (AUC) and estimating confidence intervals, essential for evaluating classifier performance.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "performance_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/brian-lau/MatlabAUC",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "auc",
        "roc",
        "statistics"
      ],
      "id": 119
    },
    {
      "name": "modeltime.resample",
      "one_line_profile": "Resampling tools for time series forecasting",
      "detailed_description": "An R package providing resampling tools for time series forecasting validation, designed to work with the Modeltime ecosystem.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "time_series_validation",
        "resampling"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/business-science/modeltime.resample",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "time-series",
        "forecasting",
        "validation"
      ],
      "id": 120
    },
    {
      "name": "MediationToolbox",
      "one_line_profile": "Mediation analysis toolbox for neuroimaging and behavioral data",
      "detailed_description": "A toolbox for single-level and multi-level mediation analyses with bootstrap-based significance testing, featuring neuroimaging-oriented functions for parametric mapping.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "neuroimaging"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/canlab/MediationToolbox",
      "help_website": [],
      "license": null,
      "tags": [
        "mediation-analysis",
        "neuroscience",
        "statistics"
      ],
      "id": 121
    },
    {
      "name": "scikit-hts",
      "one_line_profile": "Hierarchical Time Series Forecasting library",
      "detailed_description": "A Python library for hierarchical time series forecasting, providing a familiar scikit-learn like API for modeling and analyzing hierarchical data structures.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "time_series_forecasting",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/carlomazzaferro/scikit-hts",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "time-series",
        "forecasting",
        "hierarchical"
      ],
      "id": 122
    },
    {
      "name": "TreeMix-Pipeline",
      "one_line_profile": "Pipeline for TreeMix analysis with bootstrapping and visualization",
      "detailed_description": "Scripts to automate and enhance data analysis using TreeMix, including bootstrapping, migration event estimation, consensus tree creation, and statistical plotting.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "population_genetics",
        "phylogenetics",
        "statistical_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/carolindahms/TreeMix",
      "help_website": [],
      "license": null,
      "tags": [
        "genetics",
        "treemix",
        "visualization"
      ],
      "id": 123
    },
    {
      "name": "BinningAnalysis.jl",
      "one_line_profile": "Statistical standard error estimation for correlated data",
      "detailed_description": "A Julia package for statistical standard error estimation tools specifically designed for correlated data, often used in Monte Carlo simulations.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "error_estimation",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/carstenbauer/BinningAnalysis.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "statistics",
        "julia",
        "monte-carlo"
      ],
      "id": 124
    },
    {
      "name": "catacomb",
      "one_line_profile": "ML library for launching UIs and running evaluations",
      "detailed_description": "A machine learning library designed to simplify the process of launching user interfaces, running model evaluations, and comparing performance metrics.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "experiment_tracking"
      ],
      "application_level": "library",
      "primary_language": null,
      "repo_url": "https://github.com/catacomb-ai/catacomb",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "machine-learning",
        "evaluation",
        "ui"
      ],
      "id": 125
    },
    {
      "name": "scikits-bootstrap",
      "one_line_profile": "Bootstrap confidence interval estimation for Python",
      "detailed_description": "A Python library providing functions for bootstrap confidence interval estimation, built on top of NumPy.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_estimation",
        "bootstrap"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cgevans/scikits-bootstrap",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "statistics",
        "bootstrap",
        "confidence-intervals"
      ],
      "id": 126
    },
    {
      "name": "CollMetric",
      "one_line_profile": "Collaborative Metric Learning (CML) implementation",
      "detailed_description": "A TensorFlow implementation of Collaborative Metric Learning (CML), a method for recommendation systems that learns a joint metric space for users and items.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metric_learning",
        "recommendation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/changun/CollMetric",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "metric-learning",
        "tensorflow",
        "recommender-systems"
      ],
      "id": 127
    },
    {
      "name": "sr-metric",
      "one_line_profile": "No-Reference Quality Metric for Single-Image Super-Resolution",
      "detailed_description": "Implementation of a learning-based no-reference quality metric specifically designed for evaluating single-image super-resolution results.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "image_quality_assessment",
        "super_resolution"
      ],
      "application_level": "solver",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/chaoma99/sr-metric",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "image-quality",
        "super-resolution",
        "metrics"
      ],
      "id": 128
    },
    {
      "name": "PointNet++",
      "one_line_profile": "Deep Hierarchical Feature Learning on Point Sets",
      "detailed_description": "Implementation of PointNet++, a deep neural network architecture for processing point sets in a metric space, widely used for 3D data analysis.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "3d_analysis",
        "feature_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/charlesq34/pointnet2",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "point-cloud",
        "deep-learning",
        "3d-vision"
      ],
      "id": 129
    },
    {
      "name": "bootstrap",
      "one_line_profile": "Library for bootstrapping statistics",
      "detailed_description": "A Python library designed to facilitate bootstrapping statistics, allowing for robust statistical inference.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_inference",
        "bootstrap"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/christopherjenness/bootstrap",
      "help_website": [],
      "license": null,
      "tags": [
        "statistics",
        "bootstrap",
        "python"
      ],
      "id": 130
    },
    {
      "name": "piecewise_linear_fit_py",
      "one_line_profile": "Piecewise linear data fitting tool",
      "detailed_description": "A Python tool to fit piecewise linear data for a specified number of line segments, useful for modeling non-linear relationships with linear approximations.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "curve_fitting",
        "data_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cjekel/piecewise_linear_fit_py",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "curve-fitting",
        "optimization",
        "modeling"
      ],
      "id": 131
    },
    {
      "name": "Pingouin.jl",
      "one_line_profile": "Statistical package for Julia",
      "detailed_description": "A reimplementation of the Python Pingouin statistical package in Julia, providing simple yet exhaustive statistical functions.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "hypothesis_testing"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/clementpoiret/Pingouin.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "statistics",
        "julia",
        "pingouin"
      ],
      "id": 132
    },
    {
      "name": "TedEval",
      "one_line_profile": "Evaluation metric for Scene Text Detectors",
      "detailed_description": "Implementation of TedEval, a fair evaluation metric for scene text detectors that accounts for instance-level matching and coverage.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "evaluation_metric",
        "computer_vision"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/clovaai/TedEval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ocr",
        "evaluation",
        "metrics"
      ],
      "id": 133
    },
    {
      "name": "generative-evaluation-prdc",
      "one_line_profile": "Precision, Recall, Density, and Coverage metrics for generative models",
      "detailed_description": "Code base for calculating precision, recall, density, and coverage metrics to evaluate the performance and diversity of generative models.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "generative_model_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/clovaai/generative-evaluation-prdc",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "generative-models",
        "evaluation",
        "gan"
      ],
      "id": 134
    },
    {
      "name": "voxceleb_trainer",
      "one_line_profile": "Metric learning framework for speaker recognition",
      "detailed_description": "A training framework for speaker recognition focusing on metric learning approaches, providing state-of-the-art baselines and loss functions.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "speaker_recognition",
        "metric_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/clovaai/voxceleb_trainer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "speaker-recognition",
        "metric-learning",
        "deep-learning"
      ],
      "id": 135
    },
    {
      "name": "gec-ranking",
      "one_line_profile": "Ground Truth for Grammatical Error Correction Metrics",
      "detailed_description": "Data and code for evaluating Grammatical Error Correction (GEC) metrics, providing a ground truth ranking for metric comparison.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metric_evaluation",
        "nlp_benchmark"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/cnap/gec-ranking",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "evaluation",
        "benchmark"
      ],
      "id": 136
    },
    {
      "name": "deepeval",
      "one_line_profile": "LLM Evaluation Framework",
      "detailed_description": "A comprehensive framework for evaluating Large Language Models (LLMs), providing various metrics and test cases to ensure model quality and safety.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "llm_evaluation",
        "metrics"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/confident-ai/deepeval",
      "help_website": [
        "https://docs.confident-ai.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "evaluation",
        "testing"
      ],
      "id": 137
    },
    {
      "name": "SpectralGV",
      "one_line_profile": "Spectral Geometric Verification for Metric Localization",
      "detailed_description": "Implementation of Spectral Geometric Verification (SGV) for re-ranking point cloud retrieval, enhancing metric localization accuracy.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "localization",
        "geometric_verification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/csiro-robotics/SpectralGV",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "robotics",
        "localization",
        "point-cloud"
      ],
      "id": 138
    },
    {
      "name": "sacrerouge",
      "one_line_profile": "Library for text generation evaluation metrics",
      "detailed_description": "A library dedicated to the use and development of evaluation metrics for text generation tasks, with a strong emphasis on summarization.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "text_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/danieldeutsch/sacrerouge",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "summarization",
        "evaluation"
      ],
      "id": 139
    },
    {
      "name": "Dask",
      "one_line_profile": "Flexible parallel computing library for analytic computing",
      "detailed_description": "A flexible library for parallel computing in Python that scales NumPy, Pandas, and Scikit-Learn workflows. It provides advanced parallelism for analytics, enabling performance at scale for scientific computing tasks.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "parallel_computing",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask",
      "help_website": [
        "https://dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "parallel-computing",
        "distributed-systems",
        "scaling"
      ],
      "id": 140
    },
    {
      "name": "NER-Evaluation",
      "one_line_profile": "Evaluation metrics for Named Entity Recognition (NER) systems",
      "detailed_description": "An implementation of named-entity evaluation metrics based on SemEval'13 Task 9. It evaluates NER performance by considering full entity spans rather than just tag/token level accuracy.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/davidsbatista/NER-Evaluation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ner",
        "evaluation-metrics",
        "nlp"
      ],
      "id": 141
    },
    {
      "name": "WEFE",
      "one_line_profile": "Word Embeddings Fairness Evaluation Framework",
      "detailed_description": "An open source library for measuring and mitigating bias in word embedding models. It standardizes the execution of fairness metrics and provides a unified framework for evaluating bias in NLP models.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "fairness_evaluation",
        "bias_measurement"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dccuchile/wefe",
      "help_website": [
        "https://wefe.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "fairness",
        "word-embeddings",
        "bias-metrics"
      ],
      "id": 142
    },
    {
      "name": "multiway_bootstrap",
      "one_line_profile": "Implementation of the multiway bootstrap for R",
      "detailed_description": "Provides an implementation of the multiway bootstrap (including Pigeonhole bootstrap and reweighting tensor bootstrap) for bootstrapping data arrays of arbitrary order, useful for statistical inference in complex data structures.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_inference",
        "bootstrap"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/deaneckles/multiway_bootstrap",
      "help_website": [],
      "license": null,
      "tags": [
        "bootstrap",
        "statistics",
        "inference"
      ],
      "id": 143
    },
    {
      "name": "CK-Caffe",
      "one_line_profile": "Collective Knowledge workflow for Caffe optimization",
      "detailed_description": "A Collective Knowledge (CK) workflow to automate the installation, evaluation, and optimization of Caffe-based workloads across diverse hardware and software platforms. It facilitates reproducible research and benchmarking.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "benchmarking",
        "reproducibility"
      ],
      "application_level": "workflow",
      "primary_language": "CMake",
      "repo_url": "https://github.com/dividiti/ck-caffe",
      "help_website": [
        "http://cKnowledge.org/ai"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "caffe",
        "benchmarking",
        "optimization"
      ],
      "id": 144
    },
    {
      "name": "AB Test Advanced Toolkit",
      "one_line_profile": "Advanced toolkit for A/B testing analysis",
      "detailed_description": "A suite of tools for A/B testing that includes advanced techniques like CUPED (Controlled-experiment Using Pre-Experiment Data) and Gradient Boosting for variance reduction and faster statistical significance.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "ab_testing",
        "statistical_significance"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dmitry-brazhenko/ab-test-advanced-toolkit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ab-testing",
        "cuped",
        "statistics"
      ],
      "id": 145
    },
    {
      "name": "Delay Discounting Analysis",
      "one_line_profile": "Hierarchical Bayesian estimation for delay discounting",
      "detailed_description": "A MATLAB toolbox for hierarchical Bayesian estimation and hypothesis testing specifically designed for delay discounting tasks. It allows for robust parameter estimation and statistical inference in behavioral economics research.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "bayesian_estimation",
        "hypothesis_testing"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/drbenvincent/delay-discounting-analysis",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bayesian",
        "matlab",
        "behavioral-science"
      ],
      "id": 146
    },
    {
      "name": "LANLGeoMag",
      "one_line_profile": "Library for magnetic field models and coordinate transforms",
      "detailed_description": "A C-based library from Los Alamos National Laboratory for computing geophysical quantities, including magnetic field models and high-precision coordinate transformations. Used for geospace research and magnetic field line tracing.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "magnetic_field_modeling",
        "coordinate_conversion"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/drsteve/LANLGeoMag",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "geophysics",
        "magnetic-field",
        "lanl"
      ],
      "id": 147
    },
    {
      "name": "performance",
      "one_line_profile": "Assessment of regression models performance",
      "detailed_description": "An R package to compute various performance metrics for regression models, including R2, ICC, LOO, AIC, BIC, and Bayes Factor. It provides a unified interface for assessing model quality.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "performance_metrics"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/easystats/performance",
      "help_website": [
        "https://easystats.github.io/performance/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "r-package",
        "model-metrics",
        "statistics"
      ],
      "id": 148
    },
    {
      "name": "report",
      "one_line_profile": "Automated statistical reporting for R objects",
      "detailed_description": "An R package that automatically generates reports from statistical models and data frames. It interprets the results of statistical tests and models, providing text descriptions suitable for scientific publication.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_reporting",
        "automated_reporting"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/easystats/report",
      "help_website": [
        "https://easystats.github.io/report/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "r-package",
        "reporting",
        "reproducibility"
      ],
      "id": 149
    },
    {
      "name": "Pybotics",
      "one_line_profile": "Python toolbox for robotics kinematics and calibration",
      "detailed_description": "A Python toolbox for robot kinematics and calibration. It provides tools for modeling robot geometry, calculating forward/inverse kinematics, and performing calibration tasks, useful for robotics research.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "robotics_kinematics",
        "calibration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/engnadeau/pybotics",
      "help_website": [
        "https://pybotics.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "robotics",
        "kinematics",
        "calibration"
      ],
      "id": 150
    },
    {
      "name": "Seismometer",
      "one_line_profile": "AI model evaluation framework for healthcare",
      "detailed_description": "A framework for evaluating AI models with a specific focus on healthcare applications. It provides tools for assessing model performance, fairness, and calibration in clinical settings.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "healthcare_ai"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/epic-open-source/seismometer",
      "help_website": [
        "https://epic-open-source.github.io/seismometer/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "healthcare",
        "evaluation",
        "fairness"
      ],
      "id": 151
    },
    {
      "name": "Evidently",
      "one_line_profile": "Open-source ML and LLM observability framework",
      "detailed_description": "An open-source framework to evaluate, test, and monitor ML models and LLMs. It provides reports and metrics for data drift, model performance, and data quality, supporting the entire ML lifecycle.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_monitoring",
        "data_drift_detection"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/evidentlyai/evidently",
      "help_website": [
        "https://docs.evidentlyai.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "monitoring",
        "data-drift"
      ],
      "id": 152
    },
    {
      "name": "bootstrapped",
      "one_line_profile": "Library for generating bootstrapped confidence intervals for A/B testing",
      "detailed_description": "A Python library designed to generate bootstrapped confidence intervals for A/B testing purposes. It allows researchers to estimate the sampling distribution of a statistic by resampling with replacement from the original data.",
      "domains": [
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_inference",
        "confidence_intervals",
        "ab_testing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookarchive/bootstrapped",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "statistics",
        "bootstrapping",
        "confidence-intervals"
      ],
      "id": 153
    },
    {
      "name": "fronni",
      "one_line_profile": "Fast ML performance metrics and charts with confidence intervals",
      "detailed_description": "A library for calculating machine learning model performance metrics and generating charts with confidence intervals. It is optimized with Numba for high-performance computation.",
      "domains": [
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "performance_metrics",
        "confidence_intervals"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookarchive/fronni",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "metrics",
        "numba",
        "visualization"
      ],
      "id": 154
    },
    {
      "name": "EvalGIM",
      "one_line_profile": "Evaluation library for generative image models",
      "detailed_description": "EvalGIM (EvalGym) is a library designed for the automatic evaluation of text-to-image generative models. It supports reproducible evaluations with user-defined metrics, datasets, and visualizations.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "generative_models",
        "image_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/EvalGIM",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "generative-ai",
        "evaluation",
        "text-to-image"
      ],
      "id": 155
    },
    {
      "name": "unibench",
      "one_line_profile": "Evaluation library for VLM robustness across benchmarks",
      "detailed_description": "A Python library specifically designed to evaluate the robustness of Vision-Language Models (VLMs) across a diverse set of benchmarks.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "robustness_testing",
        "vlm"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/facebookresearch/unibench",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "vision-language-models",
        "benchmarking",
        "robustness"
      ],
      "id": 156
    },
    {
      "name": "pooch",
      "one_line_profile": "Data fetching and management library for scientific datasets",
      "detailed_description": "Pooch manages your Python library's sample data files. It automatically downloads and stores data files, checking their integrity via hash comparisons, which is essential for reproducible scientific workflows.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "data_management",
        "data_retrieval",
        "reproducibility"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fatiando/pooch",
      "help_website": [
        "https://www.fatiando.org/pooch"
      ],
      "license": "NOASSERTION",
      "tags": [
        "data-fetching",
        "reproducibility",
        "scientific-python"
      ],
      "id": 157
    },
    {
      "name": "verde",
      "one_line_profile": "Spatial data processing and gridding library",
      "detailed_description": "Verde is a Python library for processing and gridding spatial data using a machine-learning style API. It provides tools for interpolation, trend removal, and cross-validation of spatial models.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "spatial_analysis",
        "gridding",
        "interpolation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fatiando/verde",
      "help_website": [
        "https://www.fatiando.org/verde"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "geospatial",
        "interpolation",
        "machine-learning"
      ],
      "id": 158
    },
    {
      "name": "prediction-interval-NN",
      "one_line_profile": "Confidence and prediction intervals for Neural Networks",
      "detailed_description": "A library providing methods to estimate confidence and prediction intervals for feedforward neural networks and RNNs, enabling uncertainty quantification in deep learning models.",
      "domains": [
        "AI4-02"
      ],
      "subtask_category": [
        "uncertainty_quantification",
        "prediction_intervals",
        "neural_networks"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fishjh2/prediction-interval-NN",
      "help_website": [],
      "license": null,
      "tags": [
        "uncertainty",
        "neural-networks",
        "intervals"
      ],
      "id": 159
    },
    {
      "name": "medmnistc-api",
      "one_line_profile": "Robustness evaluation library for medical image analysis",
      "detailed_description": "A Python library developed for evaluating and enhancing the robustness of machine learning models in medical image analysis, associated with the ADSMI@MICCAI2024 workshop.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "robustness",
        "medical_imaging"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/francescodisalvo05/medmnistc-api",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-imaging",
        "robustness",
        "miccai"
      ],
      "id": 160
    },
    {
      "name": "DeepMatch",
      "one_line_profile": "Deep learning library for metric and embedding learning",
      "detailed_description": "A library for metric and embedding learning using convolutional neural networks, with applications in keypoint matching, stereo matching, and image retrieval.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "metric_learning",
        "image_matching",
        "embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/galad-loth/DeepMatch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deep-learning",
        "computer-vision",
        "matching"
      ],
      "id": 161
    },
    {
      "name": "NLPMetrics",
      "one_line_profile": "Collection of NLP evaluation metrics",
      "detailed_description": "A Python repository providing implementations for various Natural Language Processing (NLP) metrics, facilitating the evaluation of language models.",
      "domains": [
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "nlp_metrics"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/gcunhase/NLPMetrics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "metrics",
        "evaluation"
      ],
      "id": 162
    },
    {
      "name": "long-form-factuality",
      "one_line_profile": "Benchmark for long-form factuality in LLMs",
      "detailed_description": "A library and benchmark suite from Google DeepMind for evaluating the factuality of long-form text generated by Large Language Models (LLMs).",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "factuality_checking",
        "llm_benchmark"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google-deepmind/long-form-factuality",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "factuality",
        "benchmarking"
      ],
      "id": 163
    },
    {
      "name": "surface-distance",
      "one_line_profile": "Surface distance metrics for segmentation evaluation",
      "detailed_description": "A library to compute surface distance-based performance metrics (e.g., Hausdorff distance) for segmentation tasks, widely used in medical imaging and computer vision.",
      "domains": [
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "segmentation_metrics",
        "surface_distance"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google-deepmind/surface-distance",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "segmentation",
        "metrics",
        "medical-imaging"
      ],
      "id": 164
    },
    {
      "name": "bleurt",
      "one_line_profile": "Learned metric for Natural Language Generation",
      "detailed_description": "BLEURT is a metric for evaluating Natural Language Generation systems based on transfer learning, providing a more human-correlated evaluation than traditional metrics.",
      "domains": [
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "nlg_metrics",
        "learned_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google-research/bleurt",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "evaluation",
        "transfer-learning"
      ],
      "id": 165
    },
    {
      "name": "rl-reliability-metrics",
      "one_line_profile": "Metrics for measuring reliability of RL algorithms",
      "detailed_description": "A library providing a set of metrics and statistical tools for measuring and comparing the reliability and performance stability of reinforcement learning (RL) algorithms.",
      "domains": [
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "reinforcement_learning",
        "reliability_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google-research/rl-reliability-metrics",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reinforcement-learning",
        "statistics",
        "reliability"
      ],
      "id": 166
    },
    {
      "name": "best",
      "one_line_profile": "Bam Error Stats Tool for aligned reads analysis",
      "detailed_description": "Bam Error Stats Tool (best) is a utility for analyzing error types in aligned sequencing reads (BAM files), useful for quality control in bioinformatics workflows.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "bioinformatics_analysis",
        "quality_control",
        "sequencing_error_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/google/best",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "bam",
        "genomics"
      ],
      "id": 167
    },
    {
      "name": "yggdrasil-decision-forests",
      "one_line_profile": "Library for decision forest models",
      "detailed_description": "A comprehensive library to train, evaluate, interpret, and productionize decision forest models such as Random Forest and Gradient Boosted Decision Trees.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "scientific_modeling",
        "machine_learning",
        "decision_trees"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/google/yggdrasil-decision-forests",
      "help_website": [
        "https://ydf.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "machine-learning",
        "decision-forests",
        "random-forest"
      ],
      "id": 168
    },
    {
      "name": "nlp-metrics",
      "one_line_profile": "Implementations of BLEU and ROUGE metrics",
      "detailed_description": "A Python implementation of standard NLP evaluation metrics, specifically BLEU and ROUGE, used for assessing text generation quality.",
      "domains": [
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "nlp_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/harpribot/nlp-metrics",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "bleu",
        "rouge"
      ],
      "id": 169
    },
    {
      "name": "hcrystalball",
      "one_line_profile": "Unified API for time-series forecasting",
      "detailed_description": "A library that unifies the API for various time-series forecasting libraries and modeling techniques in the Python ecosystem, facilitating scientific data analysis and prediction.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "time_series_forecasting",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/heidelbergcement/hcrystalball",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "time-series",
        "forecasting",
        "machine-learning"
      ],
      "id": 170
    },
    {
      "name": "ros-network-analysis",
      "one_line_profile": "Network analysis tools for ROS",
      "detailed_description": "A ROS package providing tools to analyze wireless network metrics (signal quality, latency, throughput) between ROS nodes, useful for robotics research and engineering.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "network_analysis",
        "robotics_evaluation",
        "performance_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/herolab-uga/ros-network-analysis",
      "help_website": [],
      "license": null,
      "tags": [
        "ros",
        "robotics",
        "network-analysis"
      ],
      "id": 171
    },
    {
      "name": "hmmlearn",
      "one_line_profile": "Hidden Markov Models in Python",
      "detailed_description": "A library for Hidden Markov Models (HMM) in Python, featuring a scikit-learn like API. It is widely used for modeling sequence data in various scientific domains.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "scientific_modeling",
        "sequence_analysis",
        "statistical_inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hmmlearn/hmmlearn",
      "help_website": [
        "https://hmmlearn.readthedocs.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "hmm",
        "machine-learning",
        "sequence-modeling"
      ],
      "id": 172
    },
    {
      "name": "huggingface/evaluate",
      "one_line_profile": "A library for easily evaluating machine learning models and datasets",
      "detailed_description": "A library for easily evaluating machine learning models and datasets. It provides a unified API for a wide range of evaluation metrics, comparison statistics, and measurements, supporting various domains including NLP, Computer Vision, and Audio.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/evaluate",
      "help_website": [
        "https://huggingface.co/docs/evaluate"
      ],
      "license": "Apache-2.0",
      "tags": [
        "metrics",
        "evaluation",
        "nlp",
        "machine-learning"
      ],
      "id": 173
    },
    {
      "name": "ing-bank/sparse_dot_topn",
      "one_line_profile": "Fast sparse matrix multiplication and top-n similarity selection",
      "detailed_description": "A Python package to accelerate sparse matrix multiplication and top-n similarity selection. It is widely used for string matching, entity resolution, and other tasks requiring efficient cosine similarity calculations on large datasets.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "similarity_calculation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/ing-bank/sparse_dot_topn",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sparse-matrix",
        "similarity",
        "cosine-similarity",
        "optimization"
      ],
      "id": 174
    },
    {
      "name": "insysbio/LikelihoodProfiler.jl",
      "one_line_profile": "Practical identifiability analysis and confidence intervals estimation in Julia",
      "detailed_description": "LikelihoodProfiler is a Julia package designed for practical identifiability analysis and confidence intervals estimation in dynamic modeling, particularly useful in systems biology and pharmacology.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "confidence_intervals",
        "identifiability_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/insysbio/LikelihoodProfiler.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "statistics",
        "confidence-intervals",
        "systems-biology"
      ],
      "id": 175
    },
    {
      "name": "interpretml/interpret",
      "one_line_profile": "Fit interpretable models and explain blackbox machine learning",
      "detailed_description": "InterpretML is a library for training interpretable models and explaining blackbox systems. It includes the Explainable Boosting Machine (EBM) and supports various visualization and metric tools for model analysis.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "interpretability",
        "model_analysis"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/interpretml/interpret",
      "help_website": [
        "https://interpret.ml"
      ],
      "license": "MIT",
      "tags": [
        "interpretability",
        "xai",
        "machine-learning",
        "visualization"
      ],
      "id": 176
    },
    {
      "name": "jacobgil/confidenceinterval",
      "one_line_profile": "Library for calculating confidence intervals in Python",
      "detailed_description": "A Python library dedicated to calculating confidence intervals for various statistical distributions and machine learning metrics, filling a gap in standard libraries.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "confidence_intervals"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jacobgil/confidenceinterval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "statistics",
        "confidence-intervals",
        "python"
      ],
      "id": 177
    },
    {
      "name": "jhclark/multeval",
      "one_line_profile": "Bootstrap Resampling and Approximate Randomization for MT metrics",
      "detailed_description": "A tool for statistical hypothesis testing in Machine Translation evaluation. It implements bootstrap resampling and approximate randomization to control for optimizer instability and provide reliable significance testing for metrics like BLEU, METEOR, and TER.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_testing",
        "evaluation",
        "nlp_metrics"
      ],
      "application_level": "solver",
      "primary_language": "Groff",
      "repo_url": "https://github.com/jhclark/multeval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "machine-translation",
        "significance-testing",
        "bootstrap",
        "evaluation"
      ],
      "id": 178
    },
    {
      "name": "jiwei0921/Saliency-Evaluation-Toolbox",
      "one_line_profile": "Evaluation metrics toolbox for salient object detection",
      "detailed_description": "A MATLAB toolbox providing comprehensive evaluation metrics for salient object detection, including E-measure, S-measure, weighted F-measure, MAE, and PR curves.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "evaluation",
        "metrics",
        "computer_vision"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/jiwei0921/Saliency-Evaluation-Toolbox",
      "help_website": [],
      "license": null,
      "tags": [
        "saliency-detection",
        "evaluation-metrics",
        "matlab"
      ],
      "id": 179
    },
    {
      "name": "jlsuarezdiaz/pyDML",
      "one_line_profile": "Distance Metric Learning Algorithms for Python",
      "detailed_description": "A Python library implementing various Distance Metric Learning (DML) algorithms. It allows learning distance metrics from data to improve the performance of distance-based machine learning algorithms like k-NN.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metric_learning",
        "distance_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jlsuarezdiaz/pyDML",
      "help_website": [
        "https://pydml.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "metric-learning",
        "machine-learning",
        "distance-metric"
      ],
      "id": 180
    },
    {
      "name": "jm4474/SVARIV",
      "one_line_profile": "Inference and confidence intervals for Structural Vector Autoregressions",
      "detailed_description": "A Matlab suite to construct weak-instrument robust confidence intervals for impulse response coefficients in Structural Vector Autoregressions (SVAR) identified with an external instrument.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_inference",
        "confidence_intervals",
        "econometrics"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/jm4474/SVARIV",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "econometrics",
        "confidence-intervals",
        "matlab",
        "time-series"
      ],
      "id": 181
    },
    {
      "name": "jongwook/spark-ranking-metrics",
      "one_line_profile": "Offline Recommender System Evaluation for Spark",
      "detailed_description": "A library for calculating ranking metrics (like MAP, NDCG) for recommender system evaluation on Apache Spark, enabling scalable offline evaluation.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "evaluation",
        "metrics",
        "recommender_systems"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/jongwook/spark-ranking-metrics",
      "help_website": [],
      "license": "Unlicense",
      "tags": [
        "spark",
        "evaluation",
        "ranking-metrics",
        "recommender-system"
      ],
      "id": 182
    },
    {
      "name": "icp",
      "one_line_profile": "Python implementation of Invariant Causal Prediction (ICP) algorithm",
      "detailed_description": "A Python implementation of the Invariant Causal Prediction (ICP) algorithm for causal inference, enabling identification of causal relationships and confidence intervals from data.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "causal_inference",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/juangamella/icp",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "causal-inference",
        "statistics",
        "python"
      ],
      "id": 183
    },
    {
      "name": "Bootstrap.jl",
      "one_line_profile": "Statistical bootstrapping library for Julia",
      "detailed_description": "A Julia library for statistical bootstrapping, providing methods to estimate sampling distributions and confidence intervals for various statistics.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "confidence_intervals"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/juliangehring/Bootstrap.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "julia",
        "statistics",
        "bootstrapping"
      ],
      "id": 184
    },
    {
      "name": "mantel",
      "one_line_profile": "Python implementation of the Mantel test for correlation between distance matrices",
      "detailed_description": "A Python library implementing the Mantel test, a statistical test used to evaluate the correlation between two distance matrices, commonly used in ecology and genetics.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "hypothesis_testing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jwcarr/mantel",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "statistics",
        "mantel-test",
        "correlation"
      ],
      "id": 185
    },
    {
      "name": "CodeBLEU",
      "one_line_profile": "Evaluation metric for code generation tasks",
      "detailed_description": "A Python implementation of CodeBLEU, a metric designed to evaluate the quality of code generated by AI models by considering syntactic and semantic features.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metrics",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/k4black/codebleu",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "metrics",
        "code-generation"
      ],
      "id": 186
    },
    {
      "name": "boundedline-pkg",
      "one_line_profile": "Matlab tool for plotting lines with error bounds/confidence intervals",
      "detailed_description": "A Matlab package for visualizing data with associated uncertainty, allowing the plotting of lines with shaded error bounds or confidence intervals.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "visualization",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/kakearney/boundedline-pkg",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "matlab",
        "visualization",
        "plotting",
        "error-bars"
      ],
      "id": 187
    },
    {
      "name": "matrixTests",
      "one_line_profile": "R package for high-performance matrix-based hypothesis testing",
      "detailed_description": "An R package designed for efficient computation of multiple hypothesis tests (t-tests, F-tests, etc.) on rows or columns of matrices, useful for high-dimensional biological data.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "hypothesis_testing"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/karoliskoncevicius/matrixTests",
      "help_website": [],
      "license": null,
      "tags": [
        "r",
        "statistics",
        "matrix-operations"
      ],
      "id": 188
    },
    {
      "name": "ROUGE-2.0",
      "one_line_profile": "Toolkit for evaluating automatic summarization using ROUGE metrics",
      "detailed_description": "A Java-based toolkit for computing ROUGE metrics (Recall-Oriented Understudy for Gisting Evaluation) to evaluate automatic text summarization systems.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metrics",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/kavgan/ROUGE-2.0",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "summarization",
        "metrics",
        "rouge"
      ],
      "id": 189
    },
    {
      "name": "rouge",
      "one_line_profile": "JavaScript implementation of ROUGE evaluation metric",
      "detailed_description": "A JavaScript library implementing the ROUGE metric for evaluating automatic summarization, enabling evaluation in web-based or Node.js environments.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metrics",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/kenlimmj/rouge",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "javascript",
        "nlp",
        "metrics"
      ],
      "id": 190
    },
    {
      "name": "hera",
      "one_line_profile": "Dashboard for tracking and visualizing Keras model training metrics",
      "detailed_description": "A tool to stream and visualize metrics from Keras model training to a browser-based dashboard, facilitating experiment monitoring.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "visualization",
        "experiment_tracking"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/keplr-io/hera",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "keras",
        "visualization",
        "dashboard",
        "deep-learning"
      ],
      "id": 191
    },
    {
      "name": "abacus",
      "one_line_profile": "Fast hypothesis testing and experiment design solution",
      "detailed_description": "A Python library for conducting fast hypothesis testing and designing experiments (A/B testing), providing statistical tools for decision making.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "hypothesis_testing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kolmogorov-lab/abacus",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "statistics",
        "ab-testing",
        "experiment-design"
      ],
      "id": 192
    },
    {
      "name": "globox",
      "one_line_profile": "Object detection dataset converter and evaluator",
      "detailed_description": "A Python package to read, convert, and evaluate object detection datasets (COCO, YOLO, PascalVOC, etc.) using standard metrics like mAP.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metrics",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/laclouis5/globox",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "object-detection",
        "metrics",
        "dataset-conversion"
      ],
      "id": 193
    },
    {
      "name": "langfuse",
      "one_line_profile": "Open source LLM engineering platform for observability and evaluation",
      "detailed_description": "A comprehensive platform for LLM engineering that includes tools for observability, metrics tracking, evaluation, and prompt management.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metrics",
        "model_evaluation",
        "experiment_tracking"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/langfuse/langfuse",
      "help_website": [
        "https://langfuse.com"
      ],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "observability",
        "metrics",
        "evaluation"
      ],
      "id": 194
    },
    {
      "name": "PyIRSTDMetrics",
      "one_line_profile": "Evaluation metrics for Infrared Small Target Detection",
      "detailed_description": "A Python toolbox providing specialized evaluation metrics for the task of Infrared Small Target Detection (IRSTD).",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metrics",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lartpang/PyIRSTDMetrics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "computer-vision",
        "metrics",
        "infrared-detection"
      ],
      "id": 195
    },
    {
      "name": "PySODEvalToolkit",
      "one_line_profile": "Evaluation toolbox for Salient and Camouflaged Object Detection",
      "detailed_description": "A Python-based evaluation toolbox designed for assessing the performance of models in Salient Object Detection (SOD) and Camouflaged Object Detection (COD).",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metrics",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lartpang/PySODEvalToolkit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "computer-vision",
        "saliency-detection",
        "metrics"
      ],
      "id": 196
    },
    {
      "name": "dgm-eval",
      "one_line_profile": "Evaluation metrics for deep generative models",
      "detailed_description": "A codebase for evaluating deep generative models, addressing flaws in existing metrics and providing fairer assessment for diffusion models.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metrics",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/layer6ai-labs/dgm-eval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "generative-models",
        "metrics",
        "diffusion-models"
      ],
      "id": 197
    },
    {
      "name": "deception",
      "one_line_profile": "Benchmark for evaluating LLM disinformation capabilities",
      "detailed_description": "A benchmark suite designed to evaluate Large Language Models on their ability to create and resist disinformation, including standardized metrics.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metrics",
        "model_evaluation",
        "benchmark"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/lechmazur/deception",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "benchmark",
        "safety",
        "evaluation"
      ],
      "id": 198
    },
    {
      "name": "cvAUC",
      "one_line_profile": "Confidence intervals for cross-validated AUC estimates in R",
      "detailed_description": "An R package for computationally efficient estimation of confidence intervals for cross-validated Area Under the ROC Curve (AUC) estimates.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/ledell/cvAUC",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "r",
        "statistics",
        "auc",
        "confidence-intervals"
      ],
      "id": 199
    },
    {
      "name": "rouge-metric",
      "one_line_profile": "Python wrapper and re-implementation of ROUGE metrics",
      "detailed_description": "A Python package that wraps the official ROUGE script and provides a native re-implementation for evaluating text summarization.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metrics",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Perl",
      "repo_url": "https://github.com/li-plus/rouge-metric",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "metrics",
        "rouge"
      ],
      "id": 200
    },
    {
      "name": "librosa",
      "one_line_profile": "Python library for audio and music analysis",
      "detailed_description": "A comprehensive Python library for audio and music analysis, providing tools for feature extraction, signal processing, and visualization.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "signal_processing",
        "feature_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/librosa/librosa",
      "help_website": [
        "https://librosa.org"
      ],
      "license": "ISC",
      "tags": [
        "audio",
        "signal-processing",
        "music-analysis"
      ],
      "id": 201
    },
    {
      "name": "t2v_metrics",
      "one_line_profile": "Evaluation metrics for text-to-visual models using VQAScore",
      "detailed_description": "A toolkit for evaluating text-to-image, text-to-video, and text-to-3D models using VQAScore, a metric based on Visual Question Answering.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metrics",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/linzhiqiu/t2v_metrics",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "generative-ai",
        "metrics",
        "multimodal"
      ],
      "id": 202
    },
    {
      "name": "lmfit-py",
      "one_line_profile": "Non-Linear Least Squares Minimization and Curve Fitting",
      "detailed_description": "A Python library for non-linear least-squares minimization and curve fitting, building on scipy.optimize to provide a high-level interface for modeling data.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "curve_fitting"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lmfit/lmfit-py",
      "help_website": [
        "https://lmfit.github.io/lmfit-py/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "curve-fitting",
        "optimization",
        "statistics"
      ],
      "id": 203
    },
    {
      "name": "KoBERTScore",
      "one_line_profile": "BERTScore implementation for Korean language",
      "detailed_description": "A Python implementation of the BERTScore metric specifically adapted for evaluating Korean text generation.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metrics",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lovit/KoBERTScore",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "metrics",
        "korean"
      ],
      "id": 204
    },
    {
      "name": "ConfidenceIntervals",
      "one_line_profile": "Confidence interval computation for ML evaluation",
      "detailed_description": "A Python package to calculate confidence intervals for machine learning evaluation metrics using bootstrapping methods.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/luferrer/ConfidenceIntervals",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "statistics",
        "machine-learning",
        "confidence-intervals"
      ],
      "id": 205
    },
    {
      "name": "waipy",
      "one_line_profile": "Wavelet analysis library for time series with significance testing",
      "detailed_description": "A Python library for Continuous Wavelet Transform (CWT) and Cross Wavelet Analysis (CWA), including significance tests based on Torrence and Compo (1998) for analyzing time series data.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "time_series_analysis",
        "statistical_test",
        "signal_processing"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mabelcalim/waipy",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "wavelet-transform",
        "time-series",
        "significance-test"
      ],
      "id": 206
    },
    {
      "name": "Mars",
      "one_line_profile": "Tensor-based unified framework for large-scale data computation",
      "detailed_description": "A tensor-based framework for large-scale data computation that scales libraries like numpy, pandas, and scikit-learn, enabling distributed scientific computing and data analysis.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "distributed_computing",
        "data_processing",
        "scientific_computing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/mars-project/mars",
      "help_website": [
        "https://mars-project.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-systems",
        "tensor-computation",
        "numpy-compatible"
      ],
      "id": 207
    },
    {
      "name": "py-img-seg-eval",
      "one_line_profile": "Evaluation metrics for image segmentation",
      "detailed_description": "A Python library implementing standard evaluation metrics for image segmentation tasks, such as pixel accuracy and Intersection over Union (IoU), inspired by FCN literature.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "image_segmentation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/martinkersner/py-img-seg-eval",
      "help_website": [],
      "license": null,
      "tags": [
        "computer-vision",
        "segmentation",
        "evaluation-metrics"
      ],
      "id": 208
    },
    {
      "name": "ml-stat-util",
      "one_line_profile": "Statistical functions for comparing ML models",
      "detailed_description": "A collection of statistical functions based on bootstrapping for computing confidence intervals and p-values to compare machine learning models against human readers or other models.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_test",
        "model_comparison",
        "confidence_interval"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mateuszbuda/ml-stat-util",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bootstrapping",
        "p-value",
        "model-evaluation"
      ],
      "id": 209
    },
    {
      "name": "AMeThyst",
      "one_line_profile": "Metrics and hypothesis testing tools for artifact analysis",
      "detailed_description": "A set of tools for calculating metrics and performing hypothesis tests, designed for analyzing specific artifacts or datasets (implied 'Art Metrics').",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "hypothesis_testing",
        "metrics",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mattyamonaca/AMeThyst",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hypothesis-test",
        "metrics",
        "analysis"
      ],
      "id": 210
    },
    {
      "name": "SAMFailureMetrics",
      "one_line_profile": "Metrics for assessing segmentation object properties",
      "detailed_description": "A library providing metrics for quantifying tree-likeness and textural contrast of objects, used for analyzing failure modes in segmentation models (e.g., SAM).",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "error_analysis",
        "segmentation_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mazurowski-lab/SAMFailureMetrics",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "segmentation",
        "failure-analysis",
        "metrics"
      ],
      "id": 211
    },
    {
      "name": "torcheval",
      "one_line_profile": "Performant PyTorch model metrics library",
      "detailed_description": "A library containing a rich collection of performant PyTorch model metrics, tools for creating new metrics, and utilities for distributed training evaluation.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/meta-pytorch/torcheval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "pytorch",
        "metrics",
        "evaluation"
      ],
      "id": 212
    },
    {
      "name": "FLAML",
      "one_line_profile": "Fast and lightweight AutoML library",
      "detailed_description": "A fast library for Automated Machine Learning (AutoML) and hyperparameter tuning, designed to find accurate models with low computational cost.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "automl",
        "hyperparameter_tuning",
        "model_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/microsoft/FLAML",
      "help_website": [
        "https://microsoft.github.io/FLAML/"
      ],
      "license": "MIT",
      "tags": [
        "automl",
        "tuning",
        "optimization"
      ],
      "id": 213
    },
    {
      "name": "FeatureBroker",
      "one_line_profile": "Feature collection and inference library for ML evaluation",
      "detailed_description": "A library for collecting features and performing inference for machine learning evaluations, facilitating scenarios where feature publishing is decoupled from model consumption.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "feature_extraction",
        "model_inference",
        "evaluation_infrastructure"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/microsoft/FeatureBroker",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "feature-engineering",
        "inference",
        "evaluation"
      ],
      "id": 214
    },
    {
      "name": "LMChallenge",
      "one_line_profile": "Library and tools for evaluating predictive language models",
      "detailed_description": "A library and set of tools designed to evaluate predictive language models against standard benchmarks and challenges.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "nlp_metrics",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/LMChallenge",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "nlp",
        "language-models",
        "evaluation"
      ],
      "id": 215
    },
    {
      "name": "dstoolkit-e2e-presidio-evaluation",
      "one_line_profile": "End-to-end evaluation toolkit for PII detection",
      "detailed_description": "A toolkit for assessing PII detection frameworks (specifically Presidio) using Hugging Face transformers and Azure services, providing an end-to-end evaluation pipeline.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "pii_detection",
        "security_metrics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/dstoolkit-e2e-presidio-evaluation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pii",
        "evaluation",
        "presidio"
      ],
      "id": 216
    },
    {
      "name": "Hummingbird",
      "one_line_profile": "Compiler for translating ML models to tensor computations",
      "detailed_description": "A library that compiles trained traditional machine learning models into tensor computations (e.g., PyTorch, TorchScript, ONNX) for faster inference.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "model_compilation",
        "inference_optimization",
        "scientific_computing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/hummingbird",
      "help_website": [
        "https://microsoft.github.io/hummingbird/"
      ],
      "license": "MIT",
      "tags": [
        "inference",
        "compiler",
        "optimization"
      ],
      "id": 217
    },
    {
      "name": "ONNX Runtime",
      "one_line_profile": "Cross-platform high-performance ML inference accelerator",
      "detailed_description": "A cross-platform, high-performance engine for machine learning inference and training, supporting models from various frameworks via the ONNX format.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "model_inference",
        "model_training",
        "acceleration"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/microsoft/onnxruntime",
      "help_website": [
        "https://onnxruntime.ai/"
      ],
      "license": "MIT",
      "tags": [
        "onnx",
        "inference",
        "acceleration"
      ],
      "id": 218
    },
    {
      "name": "rankerEval",
      "one_line_profile": "Numpy-based ranking metrics implementation",
      "detailed_description": "A fast, numpy-based implementation of ranking metrics (such as NDCG, ERR) for evaluating information retrieval and recommendation systems.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "ranking_evaluation",
        "metrics",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/rankerEval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ranking",
        "metrics",
        "ir"
      ],
      "id": 219
    },
    {
      "name": "Table Transformer",
      "one_line_profile": "Table extraction model and GriTS evaluation metric",
      "detailed_description": "A deep learning model for extracting tables from unstructured documents, which includes the official implementation of the GriTS evaluation metric for table structure recognition.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "table_extraction",
        "model_evaluation",
        "metrics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/table-transformer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "table-extraction",
        "grits-metric",
        "document-analysis"
      ],
      "id": 220
    },
    {
      "name": "sacrebleu",
      "one_line_profile": "Standardized BLEU score implementation for NLP",
      "detailed_description": "A reference implementation of the BLEU metric that automatically downloads test sets and reports version strings to facilitate reproducible cross-lab comparisons in machine translation.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "nlp_evaluation",
        "metrics",
        "translation_quality"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mjpost/sacrebleu",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bleu",
        "nlp",
        "reproducibility"
      ],
      "id": 221
    },
    {
      "name": "ML Workspace",
      "one_line_profile": "All-in-one web-based IDE for machine learning",
      "detailed_description": "A web-based Integrated Development Environment (IDE) specialized for machine learning and data science, pre-configured with popular libraries and tools.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "development_environment",
        "scientific_workflow",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ml-tooling/ml-workspace",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ide",
        "docker",
        "data-science"
      ],
      "id": 222
    },
    {
      "name": "mljar-supervised",
      "one_line_profile": "AutoML for tabular data with explanation generation",
      "detailed_description": "A Python package for Automated Machine Learning (AutoML) on tabular data, featuring automatic feature engineering, hyperparameter tuning, model explanations, and documentation generation.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "automl",
        "tabular_data",
        "explainable_ai"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mljar/mljar-supervised",
      "help_website": [
        "https://supervised.mljar.com/"
      ],
      "license": "MIT",
      "tags": [
        "automl",
        "tabular",
        "explainability"
      ],
      "id": 223
    },
    {
      "name": "EvalScope",
      "one_line_profile": "Framework for large model evaluation and benchmarking",
      "detailed_description": "A streamlined and customizable framework for evaluating and benchmarking large language models (LLMs), vision-language models (VLMs), and AIGC models.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking",
        "llm_metrics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/modelscope/evalscope",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "evaluation",
        "benchmark"
      ],
      "id": 224
    },
    {
      "name": "glm-sklearn",
      "one_line_profile": "Scikit-learn wrappers for Statsmodels GLM",
      "detailed_description": "A library providing scikit-learn compatible wrappers for Generalized Linear Models (GLM) from the statsmodels library, facilitating their use in scikit-learn pipelines.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_modeling",
        "regression",
        "glm"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/modusdatascience/glm-sklearn",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "sklearn",
        "statsmodels",
        "glm"
      ],
      "id": 225
    },
    {
      "name": "Pweave",
      "one_line_profile": "Scientific report generator and literate programming tool for Python",
      "detailed_description": "Pweave is a scientific report generator and a literate programming tool for Python, capable of capturing results and plots from data analysis, similar to R Markdown.",
      "domains": [
        "AI4",
        "Scientific Reporting"
      ],
      "subtask_category": [
        "literate_programming",
        "report_generation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/mpastell/Pweave",
      "help_website": [
        "http://mpastell.com/pweave"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "literate-programming",
        "reporting",
        "reproducible-research"
      ],
      "id": 226
    },
    {
      "name": "MS-Loss",
      "one_line_profile": "Multi-Similarity Loss implementation for Deep Metric Learning",
      "detailed_description": "Implementation of Multi-Similarity Loss for Deep Metric Learning, designed to improve the training of models requiring metric learning objectives.",
      "domains": [
        "AI4",
        "Deep Learning"
      ],
      "subtask_category": [
        "metric_learning",
        "loss_function"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/msight-tech/research-ms-loss",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "metric-learning",
        "loss-function",
        "deep-learning"
      ],
      "id": 227
    },
    {
      "name": "Crab",
      "one_line_profile": "Flexible recommender engine for Python",
      "detailed_description": "Crab is a recommender engine for Python that integrates classic information filtering recommendation algorithms within the scientific Python ecosystem (numpy, scipy).",
      "domains": [
        "AI4",
        "Recommender Systems"
      ],
      "subtask_category": [
        "recommendation",
        "information_filtering"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/muricoca/crab",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "recommender-system",
        "collaborative-filtering",
        "scikit"
      ],
      "id": 228
    },
    {
      "name": "Seaborn",
      "one_line_profile": "Statistical data visualization library based on matplotlib",
      "detailed_description": "Seaborn is a Python data visualization library based on matplotlib that provides a high-level interface for drawing attractive and informative statistical graphics.",
      "domains": [
        "AI4",
        "Visualization"
      ],
      "subtask_category": [
        "data_visualization",
        "statistical_plotting"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mwaskom/seaborn",
      "help_website": [
        "https://seaborn.pydata.org"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "visualization",
        "statistics",
        "plotting"
      ],
      "id": 229
    },
    {
      "name": "NASA Prognostic Algorithms",
      "one_line_profile": "Framework for model-based prognostics of engineering systems",
      "detailed_description": "A python framework for model-based prognostics (computation of remaining useful life) of engineering systems, providing algorithms for state estimation, prediction, and uncertainty propagation.",
      "domains": [
        "AI4",
        "Systems Engineering"
      ],
      "subtask_category": [
        "prognostics",
        "state_estimation",
        "uncertainty_propagation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nasa/prog_algs",
      "help_website": [],
      "license": "NASA Open Source Agreement",
      "tags": [
        "prognostics",
        "nasa",
        "estimation"
      ],
      "id": 230
    },
    {
      "name": "scores",
      "one_line_profile": "Metrics for verification and evaluation of forecasts and models",
      "detailed_description": "A library containing metrics for the verification, evaluation, and optimisation of forecasts, predictions, or models, particularly in scientific contexts.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "forecasting_verification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nci/scores",
      "help_website": [
        "https://scores.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "metrics",
        "forecasting",
        "evaluation"
      ],
      "id": 231
    },
    {
      "name": "cute_ranking",
      "one_line_profile": "Python module for calculating ranking metrics",
      "detailed_description": "A lightweight Python module for calculating various information retrieval ranking metrics such as MAP, NDCG, etc.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "ranking_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ncoop57/cute_ranking",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ranking",
        "metrics",
        "information-retrieval"
      ],
      "id": 232
    },
    {
      "name": "image-similarity-measures",
      "one_line_profile": "Evaluation metrics for image similarity",
      "detailed_description": "Implementation of eight evaluation metrics to assess the similarity between two images, including RMSE, PSNR, SSIM, ISSM, FSIM, SRE, SAM, and UIQ.",
      "domains": [
        "AI4",
        "AI4-02",
        "Computer Vision"
      ],
      "subtask_category": [
        "image_similarity",
        "evaluation_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nekhtiari/image-similarity-measures",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "image-processing",
        "metrics",
        "similarity"
      ],
      "id": 233
    },
    {
      "name": "CodeBERTScore",
      "one_line_profile": "Automatic metric for code generation based on BERTScore",
      "detailed_description": "An automatic evaluation metric for code generation tasks, adapting BERTScore to evaluate the quality of generated code.",
      "domains": [
        "AI4",
        "AI4-02",
        "NLP"
      ],
      "subtask_category": [
        "code_generation_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/neulab/code-bert-score",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation",
        "code-generation",
        "bertscore"
      ],
      "id": 234
    },
    {
      "name": "ROUGE (Perl)",
      "one_line_profile": "Implementation of ROUGE metrics for summarization",
      "detailed_description": "An implementation of the ROUGE family of metrics, widely used for evaluating automatic summarization and machine translation.",
      "domains": [
        "AI4",
        "AI4-02",
        "NLP"
      ],
      "subtask_category": [
        "summarization_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Perl",
      "repo_url": "https://github.com/neural-dialogue-metrics/rouge",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rouge",
        "nlp",
        "evaluation"
      ],
      "id": 235
    },
    {
      "name": "hyppo",
      "one_line_profile": "Multivariate hypothesis testing library",
      "detailed_description": "A comprehensive Python package for multivariate hypothesis testing, including independence testing and k-sample testing.",
      "domains": [
        "AI4",
        "AI4-02",
        "Statistics"
      ],
      "subtask_category": [
        "hypothesis_testing",
        "statistical_inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/neurodata/hyppo",
      "help_website": [
        "https://hyppo.neurodata.io"
      ],
      "license": "MIT",
      "tags": [
        "statistics",
        "hypothesis-testing",
        "multivariate"
      ],
      "id": 236
    },
    {
      "name": "fit_neuron",
      "one_line_profile": "Estimation and evaluation of neural models from recordings",
      "detailed_description": "A neuroscience package for the estimation and evaluation of neural models from patch clamp neural recordings, including spike distance metrics.",
      "domains": [
        "AI4",
        "Neuroscience"
      ],
      "subtask_category": [
        "neural_modeling",
        "parameter_estimation",
        "spike_metrics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nicodjimenez/fit_neuron",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "neuroscience",
        "modeling",
        "spiking-neurons"
      ],
      "id": 237
    },
    {
      "name": "Igel",
      "one_line_profile": "CLI tool for training and using machine learning models",
      "detailed_description": "A machine learning tool that allows users to train, test, and use models without writing code, using a YAML configuration approach.",
      "domains": [
        "AI4",
        "AutoML"
      ],
      "subtask_category": [
        "model_training",
        "automl"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/nidhaloff/igel",
      "help_website": [
        "https://igel.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "automl",
        "cli",
        "machine-learning"
      ],
      "id": 238
    },
    {
      "name": "NMSLIB",
      "one_line_profile": "Non-Metric Space Library for efficient similarity search",
      "detailed_description": "An efficient similarity search library and a toolkit for evaluation of k-NN methods for generic non-metric spaces.",
      "domains": [
        "AI4",
        "Algorithms"
      ],
      "subtask_category": [
        "similarity_search",
        "knn",
        "nearest_neighbor"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/nmslib/nmslib",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "similarity-search",
        "knn",
        "indexing"
      ],
      "id": 239
    },
    {
      "name": "NTUSD-Fin",
      "one_line_profile": "Financial sentiment dictionary and scoring methods",
      "detailed_description": "A financial sentiment analysis resource providing scoring methods (frequency, CFIDF, etc.) and a dictionary of words, hashtags, and emojis with sentiment scores.",
      "domains": [
        "AI4",
        "Finance NLP"
      ],
      "subtask_category": [
        "sentiment_analysis",
        "lexicon_creation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/ntunlplab/Finance-NTUSD-Fin",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sentiment-analysis",
        "finance",
        "nlp-dataset"
      ],
      "id": 240
    },
    {
      "name": "nuclia-eval",
      "one_line_profile": "Library for evaluating RAG pipelines",
      "detailed_description": "A library designed for evaluating Retrieval-Augmented Generation (RAG) systems using Nuclia's models and metrics.",
      "domains": [
        "AI4",
        "AI4-02",
        "NLP"
      ],
      "subtask_category": [
        "rag_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nuclia/nuclia-eval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "llm"
      ],
      "id": 241
    },
    {
      "name": "nullranges",
      "one_line_profile": "Generation of null hypothesis ranges for genomic analysis",
      "detailed_description": "A modular R package for generating sets of genomic ranges representing the null hypothesis, including bootstrapped ranges and matched control ranges.",
      "domains": [
        "AI4",
        "Genomics"
      ],
      "subtask_category": [
        "statistical_genomics",
        "null_hypothesis_generation"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/nullranges/nullranges",
      "help_website": [
        "https://nullranges.github.io/nullranges/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "genomics",
        "statistics",
        "bioconductor"
      ],
      "id": 242
    },
    {
      "name": "cuPyNumeric",
      "one_line_profile": "NumPy and SciPy drop-in replacement for multi-node multi-GPU systems",
      "detailed_description": "A library that enables NumPy and SciPy code to run on multi-node multi-GPU systems with minimal code changes, leveraging the Legate system.",
      "domains": [
        "AI4",
        "HPC"
      ],
      "subtask_category": [
        "numerical_computing",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nv-legate/cupynumeric",
      "help_website": [
        "https://cupynumeric.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "gpu",
        "numpy"
      ],
      "id": 243
    },
    {
      "name": "cosine_metric_learning",
      "one_line_profile": "Deep Cosine Metric Learning for Person Re-identification",
      "detailed_description": "Implementation of Deep Cosine Metric Learning, a method for training deep networks to learn a metric space suitable for person re-identification tasks.",
      "domains": [
        "AI4",
        "Computer Vision"
      ],
      "subtask_category": [
        "metric_learning",
        "person_reidentification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nwojke/cosine_metric_learning",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "metric-learning",
        "reid",
        "deep-learning"
      ],
      "id": 244
    },
    {
      "name": "Jury",
      "one_line_profile": "Comprehensive NLP Evaluation System",
      "detailed_description": "A comprehensive evaluation system for Natural Language Processing (NLP) tasks, providing a unified interface for various metrics.",
      "domains": [
        "AI4",
        "AI4-02",
        "NLP"
      ],
      "subtask_category": [
        "nlp_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/obss/jury",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "evaluation",
        "metrics"
      ],
      "id": 245
    },
    {
      "name": "blurr",
      "one_line_profile": "Library integrating Hugging Face Transformers with fastai for model training and evaluation",
      "detailed_description": "A library that provides fastai developers with utilities to train, evaluate, and deploy transformer-specific models by integrating with the Hugging Face ecosystem.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_training",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ohmeow/blurr",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fastai",
        "transformers",
        "deep-learning"
      ],
      "id": 246
    },
    {
      "name": "ONNX",
      "one_line_profile": "Open standard format and tools for machine learning model interoperability",
      "detailed_description": "Open Neural Network Exchange (ONNX) is an open standard format for representing machine learning models, enabling interoperability between different frameworks and providing tools for model optimization and validation.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_interoperability",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/onnx/onnx",
      "help_website": [
        "https://onnx.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "interoperability",
        "deep-learning",
        "standard"
      ],
      "id": 247
    },
    {
      "name": "MMEval",
      "one_line_profile": "Unified evaluation library for multiple machine learning frameworks",
      "detailed_description": "A unified evaluation library that provides a wide range of metrics for various machine learning tasks, supporting multiple frameworks like PyTorch and TensorFlow, designed to streamline the model evaluation process.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics_calculation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/open-mmlab/mmeval",
      "help_website": [
        "https://mmeval.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "metrics",
        "computer-vision"
      ],
      "id": 248
    },
    {
      "name": "OpenLIT",
      "one_line_profile": "OpenTelemetry-native platform for LLM observability and evaluation",
      "detailed_description": "An open-source platform for AI engineering that provides observability, monitoring, and evaluation capabilities for Large Language Models (LLMs) and GPUs, integrating with OpenTelemetry standards.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "llm_evaluation",
        "observability",
        "monitoring"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/openlit/openlit",
      "help_website": [
        "https://docs.openlit.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "observability",
        "opentelemetry",
        "evaluation"
      ],
      "id": 249
    },
    {
      "name": "XProf",
      "one_line_profile": "Profiling and performance analysis tool for machine learning workloads",
      "detailed_description": "A profiling tool designed to analyze the performance of machine learning models and workloads, helping developers identify bottlenecks and optimize execution on various hardware accelerators.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "performance_profiling",
        "optimization"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/openxla/xprof",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "profiling",
        "performance",
        "machine-learning"
      ],
      "id": 250
    },
    {
      "name": "optimagic",
      "one_line_profile": "Unified interface for numerical optimization and statistical inference",
      "detailed_description": "A Python package for numerical optimization that provides a unified interface to various optimizers (SciPy, NlOpt, etc.) and includes tools for diagnostic analysis and parallel numerical derivatives.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "numerical_optimization",
        "parameter_estimation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/optimagic-dev/optimagic",
      "help_website": [
        "https://optimagic.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "optimization",
        "statistics",
        "numerical-methods"
      ],
      "id": 251
    },
    {
      "name": "pandas-ml",
      "one_line_profile": "Integration library for pandas, scikit-learn, and xgboost",
      "detailed_description": "A library that integrates pandas with scikit-learn, xgboost, and seaborn to streamline data analysis, modeling, and visualization workflows in Python.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "data_analysis",
        "machine_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pandas-ml/pandas-ml",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "pandas",
        "scikit-learn",
        "integration"
      ],
      "id": 252
    },
    {
      "name": "dtreeviz",
      "one_line_profile": "Visualization and interpretation library for decision trees",
      "detailed_description": "A Python library for visualizing decision trees and interpreting their structure and prediction paths, aiding in model analysis and explainability.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_visualization",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/parrt/dtreeviz",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "decision-trees",
        "explainable-ai"
      ],
      "id": 253
    },
    {
      "name": "sigclust2",
      "one_line_profile": "Statistical significance testing for clustering results",
      "detailed_description": "An R package for testing the statistical significance of clustering results, helping to determine if identified clusters are genuine or artifacts of random sampling.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_testing",
        "clustering_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/pkimes/sigclust2",
      "help_website": [],
      "license": null,
      "tags": [
        "statistics",
        "clustering",
        "significance-test"
      ],
      "id": 254
    },
    {
      "name": "patchworklib",
      "one_line_profile": "Subplot manager for matplotlib and seaborn layouts",
      "detailed_description": "A library that provides an intuitive interface for creating complex subplot layouts with matplotlib and seaborn, facilitating scientific data visualization.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "scientific_visualization",
        "plotting"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ponnhide/patchworklib",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "matplotlib",
        "visualization",
        "plotting"
      ],
      "id": 255
    },
    {
      "name": "SecML-Torch",
      "one_line_profile": "Library for robustness evaluation of deep learning models",
      "detailed_description": "A library designed for evaluating the robustness of deep learning models against adversarial attacks, providing tools for security analysis in AI.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "robustness_evaluation",
        "adversarial_attacks"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pralab/secml-torch",
      "help_website": [
        "https://secml-torch.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "security",
        "robustness",
        "adversarial-ml"
      ],
      "id": 256
    },
    {
      "name": "Skore",
      "one_line_profile": "Library for ML model evaluation and reporting",
      "detailed_description": "An open-source Python library that accelerates machine learning model development by providing automated evaluation reports, methodological guidance, and cross-validation analysis.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "reporting"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/probabl-ai/skore",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation",
        "data-science",
        "reporting"
      ],
      "id": 257
    },
    {
      "name": "Psi4NumPy",
      "one_line_profile": "Interactive quantum chemistry programming environment using Psi4 and NumPy",
      "detailed_description": "A framework and collection of tutorials that bridges the Psi4 quantum chemistry package with NumPy, allowing for the development and prototyping of new quantum chemical methods and algorithms in Python.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "quantum_chemistry_modeling",
        "electronic_structure_calculation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/psi4/psi4numpy",
      "help_website": [
        "http://psi4numpy.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "quantum-chemistry",
        "psi4",
        "numpy"
      ],
      "id": 258
    },
    {
      "name": "MultiPy",
      "one_line_profile": "Python library for multiple hypothesis testing",
      "detailed_description": "A Python library dedicated to controlling error rates in multiple hypothesis testing, implementing various statistical correction methods like Bonferroni and FDR.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "hypothesis_testing",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/puolival/multipy",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "statistics",
        "hypothesis-testing",
        "p-value"
      ],
      "id": 259
    },
    {
      "name": "pyannote-metrics",
      "one_line_profile": "Evaluation toolkit for speaker diarization systems",
      "detailed_description": "A toolkit for reproducible evaluation, diagnostic, and error analysis of speaker diarization systems, providing standard metrics for audio processing research.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "speaker_diarization_evaluation",
        "error_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pyannote/pyannote-metrics",
      "help_website": [
        "http://pyannote.github.io/pyannote-metrics"
      ],
      "license": "MIT",
      "tags": [
        "audio",
        "speaker-diarization",
        "metrics"
      ],
      "id": 260
    },
    {
      "name": "PyTorch Ignite",
      "one_line_profile": "High-level library for training and evaluating neural networks in PyTorch",
      "detailed_description": "A high-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently, providing metrics and event handlers.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_training",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pytorch/ignite",
      "help_website": [
        "https://pytorch.org/ignite/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "pytorch",
        "training",
        "evaluation"
      ],
      "id": 261
    },
    {
      "name": "Object-Detection-Metrics",
      "one_line_profile": "Implementation of common metrics for object detection evaluation",
      "detailed_description": "A repository providing implementations of the most popular metrics used to evaluate object detection algorithms, serving as a standard reference for performance measurement.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "object_detection_evaluation",
        "metrics_calculation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rafaelpadilla/Object-Detection-Metrics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "object-detection",
        "metrics",
        "computer-vision"
      ],
      "id": 262
    },
    {
      "name": "Pingouin",
      "one_line_profile": "Statistical package in Python based on Pandas",
      "detailed_description": "A statistical package written in Python that provides a wide range of statistical tests and plotting functions, designed to be a simple yet exhaustive alternative to other statistical libraries.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "hypothesis_testing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/raphaelvallat/pingouin",
      "help_website": [
        "https://pingouin-stats.org/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "statistics",
        "pandas",
        "hypothesis-testing"
      ],
      "id": 263
    },
    {
      "name": "stable-worldmodel",
      "one_line_profile": "Library for evaluating and conducting world model research",
      "detailed_description": "A reliable, minimal, and scalable library designed to facilitate research and evaluation of world models in reinforcement learning and AI.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "reinforcement_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rbalestr-lab/stable-worldmodel",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "world-models",
        "reinforcement-learning",
        "evaluation"
      ],
      "id": 264
    },
    {
      "name": "esci",
      "one_line_profile": "Estimation Statistics with Confidence Intervals for R",
      "detailed_description": "An R package for estimation statistics, focusing on effect sizes and confidence intervals to support better statistical practices in scientific research.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "estimation_statistics"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/rcalinjageman/esci",
      "help_website": [],
      "license": null,
      "tags": [
        "statistics",
        "confidence-intervals",
        "effect-size",
        "r-package"
      ],
      "id": 265
    },
    {
      "name": "scikit-plot",
      "one_line_profile": "Visualization library for scikit-learn objects",
      "detailed_description": "An intuitive library to add plotting functionality to scikit-learn objects, facilitating the visualization of machine learning metrics like confusion matrices, ROC curves, and precision-recall curves.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "visualization",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/reiinakano/scikit-plot",
      "help_website": [
        "https://scikit-plot.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "visualization",
        "scikit-learn",
        "machine-learning",
        "plotting"
      ],
      "id": 266
    },
    {
      "name": "supervision",
      "one_line_profile": "Reusable computer vision tools for processing and visualization",
      "detailed_description": "A comprehensive library for computer vision tasks, providing utilities for filtering, processing, and visualizing detections, segmentations, and other vision data.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "visualization",
        "data_processing",
        "computer_vision"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/roboflow/supervision",
      "help_website": [
        "https://supervision.roboflow.com"
      ],
      "license": "MIT",
      "tags": [
        "computer-vision",
        "visualization",
        "object-detection",
        "metrics"
      ],
      "id": 267
    },
    {
      "name": "eulerian-remote-heartrate-detection",
      "one_line_profile": "Remote heart rate detection via Eulerian video magnification",
      "detailed_description": "A tool that implements Eulerian magnification to detect heart rates remotely from face videos, serving as a solver for physiological signal extraction.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "signal_processing",
        "physiological_measurement"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/rohintangirala/eulerian-remote-heartrate-detection",
      "help_website": [],
      "license": null,
      "tags": [
        "computer-vision",
        "signal-processing",
        "heart-rate",
        "eulerian-magnification"
      ],
      "id": 268
    },
    {
      "name": "deep_metric_learning",
      "one_line_profile": "Deep metric learning methods implemented in Chainer",
      "detailed_description": "A library implementing various deep metric learning algorithms and loss functions using the Chainer framework.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metric_learning",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ronekko/deep_metric_learning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "metric-learning",
        "chainer",
        "deep-learning"
      ],
      "id": 269
    },
    {
      "name": "abcTau",
      "one_line_profile": "Unbiased estimation of timescales and hypothesis testing",
      "detailed_description": "A Python package for unbiased estimation of timescales from autocorrelation functions and performing hypothesis testing, useful in neuroscience and time series analysis.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "time_series_analysis",
        "hypothesis_testing"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/roxana-zeraati/abcTau",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "neuroscience",
        "timescales",
        "statistics",
        "hypothesis-testing"
      ],
      "id": 270
    },
    {
      "name": "pylift",
      "one_line_profile": "Uplift modeling and evaluation library",
      "detailed_description": "A library designed for uplift modeling, providing tools for model training and evaluation to measure the incremental impact of treatments.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "causal_inference",
        "model_evaluation",
        "uplift_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rsyi/pylift",
      "help_website": [
        "https://pylift.readthedocs.io"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "uplift-modeling",
        "causal-inference",
        "machine-learning"
      ],
      "id": 271
    },
    {
      "name": "paired-perm-test",
      "one_line_profile": "Exact paired permutation significance test for accuracy",
      "detailed_description": "A Python implementation of the exact paired permutation test for comparing the accuracy of two classifiers, endorsed by Rycolab.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_testing",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rycolab/paired-perm-test",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "statistics",
        "significance-test",
        "permutation-test",
        "nlp"
      ],
      "id": 272
    },
    {
      "name": "nbashots",
      "one_line_profile": "NBA shot chart visualization tool",
      "detailed_description": "A tool for creating and visualizing NBA shot charts using matplotlib, seaborn, and bokeh, facilitating sports analytics.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "visualization",
        "sports_analytics"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/savvastj/nbashots",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "visualization",
        "sports-analytics",
        "nba",
        "matplotlib"
      ],
      "id": 273
    },
    {
      "name": "pysepm",
      "one_line_profile": "Speech enhancement performance metrics implementation",
      "detailed_description": "A Python implementation of standard objective quality metrics for speech enhancement (e.g., PESQ, STOI) based on Loizou's book.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "signal_processing",
        "quality_metrics",
        "speech_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/schmiph2/pysepm",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "speech-enhancement",
        "metrics",
        "pesq",
        "stoi"
      ],
      "id": 274
    },
    {
      "name": "scikit-fuzzy",
      "one_line_profile": "Fuzzy logic toolkit for SciPy",
      "detailed_description": "A collection of fuzzy logic algorithms for use in Python, working on top of NumPy and SciPy.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "modeling",
        "fuzzy_logic"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/scikit-fuzzy/scikit-fuzzy",
      "help_website": [
        "https://pythonhosted.org/scikit-fuzzy/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "fuzzy-logic",
        "scipy",
        "control-systems"
      ],
      "id": 275
    },
    {
      "name": "pyhf",
      "one_line_profile": "Pure-Python HistFactory implementation with tensors and autodiff",
      "detailed_description": "A library for statistical modeling in High Energy Physics (HEP), implementing the HistFactory specification with support for automatic differentiation and hardware acceleration.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_modeling",
        "high_energy_physics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/scikit-hep/pyhf",
      "help_website": [
        "https://pyhf.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "physics",
        "statistics",
        "histfactory",
        "fitting"
      ],
      "id": 276
    },
    {
      "name": "forest-confidence-interval",
      "one_line_profile": "Confidence intervals for scikit-learn forest algorithms",
      "detailed_description": "A library that adds the capability to calculate confidence intervals for predictions made by scikit-learn's random forest regressors.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "uncertainty_estimation",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/scikit-learn-contrib/forest-confidence-interval",
      "help_website": [
        "http://scikit-learn-contrib.github.io/forest-confidence-interval/"
      ],
      "license": "MIT",
      "tags": [
        "random-forest",
        "confidence-intervals",
        "uncertainty",
        "scikit-learn"
      ],
      "id": 277
    },
    {
      "name": "metric-learn",
      "one_line_profile": "Metric learning algorithms in Python",
      "detailed_description": "A Python module implementing various supervised and weakly supervised metric learning algorithms, compatible with scikit-learn.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metric_learning",
        "dimensionality_reduction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/scikit-learn-contrib/metric-learn",
      "help_website": [
        "http://contrib.scikit-learn.org/metric-learn/"
      ],
      "license": "MIT",
      "tags": [
        "metric-learning",
        "scikit-learn",
        "machine-learning"
      ],
      "id": 278
    },
    {
      "name": "scikit-learn",
      "one_line_profile": "Machine learning in Python",
      "detailed_description": "A comprehensive machine learning library for Python, providing simple and efficient tools for data mining, data analysis, and modeling.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "machine_learning",
        "data_analysis",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/scikit-learn/scikit-learn",
      "help_website": [
        "https://scikit-learn.org"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "machine-learning",
        "data-science",
        "statistics"
      ],
      "id": 279
    },
    {
      "name": "scikit-optimize",
      "one_line_profile": "Sequential model-based optimization",
      "detailed_description": "A library for sequential model-based optimization, built on top of NumPy, SciPy, and scikit-learn, useful for hyperparameter tuning and black-box optimization.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "optimization",
        "hyperparameter_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/scikit-optimize/scikit-optimize",
      "help_website": [
        "https://scikit-optimize.github.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "optimization",
        "bayesian-optimization",
        "hyperparameter-tuning"
      ],
      "id": 280
    },
    {
      "name": "scipy",
      "one_line_profile": "Scientific computing library for Python",
      "detailed_description": "A fundamental library for scientific computing in Python, providing algorithms for optimization, integration, interpolation, eigenvalue problems, algebraic equations, and more.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "scientific_computing",
        "mathematical_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/scipy/scipy",
      "help_website": [
        "https://scipy.org"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "scientific-computing",
        "mathematics",
        "physics",
        "engineering"
      ],
      "id": 281
    },
    {
      "name": "SDMetrics",
      "one_line_profile": "Metrics library for evaluating the quality and efficacy of synthetic datasets",
      "detailed_description": "A Python library designed to evaluate synthetic data by comparing it with real data using various statistical metrics and machine learning efficacy tests.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "data_evaluation",
        "synthetic_data_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sdv-dev/SDMetrics",
      "help_website": [
        "https://docs.sdv.dev/sdmetrics"
      ],
      "license": "MIT",
      "tags": [
        "synthetic-data",
        "evaluation-metrics",
        "statistics"
      ],
      "id": 282
    },
    {
      "name": "PermTest",
      "one_line_profile": "Permutation algorithms for statistical significance testing",
      "detailed_description": "A C++ library implementing efficient permutation-based statistical tests to evaluate the significance of experimental results, particularly useful in information retrieval and machine learning.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_testing",
        "significance_test"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/searchivarius/PermTest",
      "help_website": [],
      "license": null,
      "tags": [
        "permutation-test",
        "statistics",
        "significance"
      ],
      "id": 283
    },
    {
      "name": "matchmaker",
      "one_line_profile": "Library for training and evaluating neural re-ranking and retrieval models",
      "detailed_description": "A PyTorch-based library for the training, evaluation, and analysis of dense retrieval and neural re-ranking models in information retrieval tasks.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sebastian-hofstaetter/matchmaker",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "neural-ir",
        "re-ranking",
        "evaluation"
      ],
      "id": 284
    },
    {
      "name": "mht",
      "one_line_profile": "Multiple Hypothesis Testing Procedure implementation",
      "detailed_description": "A MATLAB implementation of the Multiple Hypothesis Testing procedures described in List, Shaikh, and Xu (2015) for robust statistical inference.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_testing",
        "hypothesis_testing"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/seidelj/mht",
      "help_website": [],
      "license": null,
      "tags": [
        "statistics",
        "multiple-hypothesis",
        "matlab"
      ],
      "id": 285
    },
    {
      "name": "pycomets",
      "one_line_profile": "Significance testing for supervised learning with multimodal data",
      "detailed_description": "A Python package for performing algorithm-agnostic statistical significance testing on the performance of supervised learning models, specifically designed for multimodal data contexts.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_testing",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shimenghuang/pycomets",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "significance-testing",
        "multimodal-learning",
        "statistics"
      ],
      "id": 286
    },
    {
      "name": "qstest",
      "one_line_profile": "Significance test for individual communities in networks",
      "detailed_description": "A Python implementation of a generalized significance test for evaluating the quality and statistical significance of individual communities detected in network data.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_testing",
        "network_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/skojaku/qstest",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "network-science",
        "community-detection",
        "significance-test"
      ],
      "id": 287
    },
    {
      "name": "skorch",
      "one_line_profile": "Scikit-learn compatible neural network library wrapping PyTorch",
      "detailed_description": "A library that wraps PyTorch to provide a scikit-learn compatible interface, facilitating the training, evaluation, and pipeline integration of neural networks.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_training",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/skorch-dev/skorch",
      "help_website": [
        "https://skorch.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "pytorch",
        "scikit-learn",
        "wrapper"
      ],
      "id": 288
    },
    {
      "name": "sktime",
      "one_line_profile": "Unified framework for machine learning with time series",
      "detailed_description": "A comprehensive library for time series analysis in Python, providing unified interfaces for various learning tasks including forecasting, classification, and regression, along with evaluation tools.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "time_series_analysis",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sktime/sktime",
      "help_website": [
        "https://www.sktime.net/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "time-series",
        "machine-learning",
        "forecasting"
      ],
      "id": 289
    },
    {
      "name": "POPPER",
      "one_line_profile": "Automated Hypothesis Testing with Agentic Sequential Falsifications",
      "detailed_description": "A framework for automated scientific discovery that uses agentic sequential falsifications to test hypotheses, designed to support the scientific inference process.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "hypothesis_testing",
        "scientific_discovery"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/snap-stanford/POPPER",
      "help_website": [],
      "license": null,
      "tags": [
        "hypothesis-testing",
        "automated-discovery",
        "falsification"
      ],
      "id": 290
    },
    {
      "name": "snips-nlu-metrics",
      "one_line_profile": "Metrics for NLU intent parsing pipelines",
      "detailed_description": "A Python package providing metrics to evaluate the performance of Natural Language Understanding (NLU) intent parsing pipelines, including precision, recall, and f1-scores.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "nlp_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/snipsco/snips-nlu-metrics",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "metrics",
        "intent-parsing"
      ],
      "id": 291
    },
    {
      "name": "FPTaylor",
      "one_line_profile": "Rigorous estimation of round-off floating-point errors",
      "detailed_description": "A tool for the formal verification and rigorous estimation of round-off errors in floating-point computations, useful for ensuring numerical stability in scientific computing.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "numerical_analysis",
        "error_estimation"
      ],
      "application_level": "solver",
      "primary_language": "OCaml",
      "repo_url": "https://github.com/soarlab/FPTaylor",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "floating-point",
        "error-analysis",
        "formal-methods"
      ],
      "id": 292
    },
    {
      "name": "TidyDensity",
      "one_line_profile": "Tidy probability/density tibbles and plots in R",
      "detailed_description": "An R package that provides functions to generate and visualize probability distributions and density estimates in a tidy format, facilitating statistical analysis.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/spsanderson/TidyDensity",
      "help_website": [
        "https://www.spsanderson.com/TidyDensity/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "r-package",
        "statistics",
        "probability-distributions"
      ],
      "id": 293
    },
    {
      "name": "pauc",
      "one_line_profile": "ROC AUC calculation with confidence intervals",
      "detailed_description": "A Python package to calculate the Area Under the ROC Curve (AUC) along with confidence intervals using DeLong's method, essential for rigorous model evaluation.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "statistical_metrics"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/srijitseal/pauc",
      "help_website": [],
      "license": null,
      "tags": [
        "roc-auc",
        "confidence-intervals",
        "delong-method"
      ],
      "id": 294
    },
    {
      "name": "recmetrics",
      "one_line_profile": "Metrics library for evaluating recommender systems",
      "detailed_description": "A Python library containing a suite of metrics specifically designed for evaluating the performance and quality of recommender systems.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "recommender_metrics"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/statisticianinstilettos/recmetrics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "recommender-systems",
        "evaluation",
        "metrics"
      ],
      "id": 295
    },
    {
      "name": "dnn-inference",
      "one_line_profile": "Significance tests of feature relevance for black-box learners",
      "detailed_description": "A Python library for conducting statistical significance tests on feature relevance in deep neural networks and other black-box models, aiding in interpretability.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_testing",
        "feature_importance"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/statmlben/dnn-inference",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "significance-testing",
        "interpretability",
        "deep-learning"
      ],
      "id": 296
    },
    {
      "name": "statsmodels",
      "one_line_profile": "Statistical modeling and econometrics in Python",
      "detailed_description": "A comprehensive Python module that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests and statistical data exploration.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "statistical_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/statsmodels/statsmodels",
      "help_website": [
        "https://www.statsmodels.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "statistics",
        "econometrics",
        "data-analysis"
      ],
      "id": 297
    },
    {
      "name": "XCurve",
      "one_line_profile": "Library for X-Curve metrics optimizations in machine learning",
      "detailed_description": "An end-to-end PyTorch library focused on optimizing and evaluating X-Curve metrics (like AUROC, AUPRC) for machine learning models, particularly in imbalance learning scenarios.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_optimization",
        "evaluation_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/statusrank/XCurve",
      "help_website": [],
      "license": null,
      "tags": [
        "optimization",
        "metrics",
        "auroc"
      ],
      "id": 298
    },
    {
      "name": "mean-opinion-score",
      "one_line_profile": "Calculate MOS and confidence intervals for TTS ratings",
      "detailed_description": "A Python library for calculating the Mean Opinion Score (MOS) and its 95% confidence interval from text-to-speech ratings, implementing standard statistical methods.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "audio_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/stefantaubert/mean-opinion-score",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mos",
        "statistics",
        "tts"
      ],
      "id": 299
    },
    {
      "name": "nestedcv",
      "one_line_profile": "Nested cross-validation for prediction error confidence intervals",
      "detailed_description": "An R package implementing nested cross-validation procedures to provide accurate confidence intervals for prediction errors in statistical learning models.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_validation",
        "error_estimation"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/stephenbates19/nestedcv",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cross-validation",
        "confidence-intervals",
        "r-package"
      ],
      "id": 300
    },
    {
      "name": "sjstats",
      "one_line_profile": "Effect size measures and significance tests in R",
      "detailed_description": "An R package providing a collection of convenient functions for common statistical computations, including effect size measures and significance tests.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "effect_size"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/strengejacke/sjstats",
      "help_website": [],
      "license": null,
      "tags": [
        "r-package",
        "statistics",
        "significance-tests"
      ],
      "id": 301
    },
    {
      "name": "randomForestCI",
      "one_line_profile": "Confidence intervals for random forests (Deprecated)",
      "detailed_description": "An R package for calculating confidence intervals for predictions made by random forests. (Note: Deprecated in favor of 'grf' or 'ranger').",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "uncertainty_quantification"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/swager/randomForestCI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "random-forest",
        "confidence-intervals",
        "r-package"
      ],
      "id": 302
    },
    {
      "name": "ESSENCE",
      "one_line_profile": "Statistical significance evaluation for interferometric images",
      "detailed_description": "A Python package for evaluating the statistical significance of image analysis and signal detection under correlated noise, specifically for interferometric data (e.g., ALMA, NOEMA).",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "image_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/takafumi291/ESSENCE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "astronomy",
        "interferometry",
        "statistics"
      ],
      "id": 303
    },
    {
      "name": "GAN_Metrics-Tensorflow",
      "one_line_profile": "Tensorflow implementation of GAN evaluation metrics",
      "detailed_description": "A library providing Tensorflow implementations of standard metrics for evaluating Generative Adversarial Networks (GANs), including Inception Score, FID, and KID.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "generative_models"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/taki0112/GAN_Metrics-Tensorflow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gan",
        "metrics",
        "tensorflow"
      ],
      "id": 304
    },
    {
      "name": "wer-sigtest",
      "one_line_profile": "Statistical significance test for ASR hypotheses",
      "detailed_description": "A script to perform statistical significance testing (e.g., bootstrap tests) between Automatic Speech Recognition (ASR) hypotheses, evaluating Word Error Rate (WER) differences.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_testing",
        "speech_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/talhanai/wer-sigtest",
      "help_website": [],
      "license": null,
      "tags": [
        "asr",
        "significance-test",
        "wer"
      ],
      "id": 305
    },
    {
      "name": "Skflow",
      "one_line_profile": "Simplified interface for TensorFlow mimicking Scikit Learn",
      "detailed_description": "Scikit Flow (skflow) provides a simplified interface for TensorFlow, allowing users to build and train deep learning models using a syntax similar to Scikit Learn. It serves as a high-level wrapper to facilitate rapid prototyping and experimentation in machine learning research.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "model_training",
        "api_wrapper"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tensorflow/skflow",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tensorflow",
        "scikit-learn",
        "deep-learning",
        "wrapper"
      ],
      "id": 306
    },
    {
      "name": "financial-data-science",
      "one_line_profile": "Library for financial data science workflows and econometrics",
      "detailed_description": "A Python library designed to support financial data science workflows. It provides tools for managing large structured and unstructured datasets and applying financial econometrics and machine learning techniques for analysis and modeling.",
      "domains": [
        "AI4",
        "FinTech"
      ],
      "subtask_category": [
        "data_analysis",
        "econometrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/terence-lim/financial-data-science",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "finance",
        "econometrics",
        "data-science"
      ],
      "id": 307
    },
    {
      "name": "COTK",
      "one_line_profile": "Toolkit for fast development and fair evaluation of text generation",
      "detailed_description": "Conversational Toolkit (COTK) is an open-source library designed to facilitate the development and fair evaluation of text generation models. It provides standard metrics and benchmark datasets to ensure reproducible research in natural language processing.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "evaluation",
        "metrics",
        "text_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-coai/cotk",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "evaluation",
        "benchmark",
        "text-generation"
      ],
      "id": 308
    },
    {
      "name": "edaviz",
      "one_line_profile": "Library for Exploratory Data Analysis and Visualization in Jupyter",
      "detailed_description": "Edaviz is a Python library tailored for Exploratory Data Analysis (EDA) and visualization within Jupyter Notebook or Jupyter Lab environments. It aims to streamline the process of inspecting data distributions and relationships for data science tasks.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "visualization",
        "exploratory_data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tkrabel/edaviz",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "eda",
        "visualization",
        "jupyter",
        "data-analysis"
      ],
      "id": 309
    },
    {
      "name": "torch-fidelity",
      "one_line_profile": "High-fidelity performance metrics for generative models in PyTorch",
      "detailed_description": "Torch-fidelity is a library for calculating high-fidelity performance metrics for generative models, such as Inception Score (IS) and Fréchet Inception Distance (FID), within the PyTorch framework. It ensures precise and reproducible evaluation of generative AI models.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "evaluation",
        "metrics",
        "generative_models"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/toshas/torch-fidelity",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "pytorch",
        "metrics",
        "fid",
        "inception-score",
        "generative-ai"
      ],
      "id": 310
    },
    {
      "name": "statannotations",
      "one_line_profile": "Statistical significance annotations for seaborn plots",
      "detailed_description": "Statannotations is a Python library that adds statistical significance annotations (such as p-values) to plots generated by seaborn. It automates the process of conducting statistical tests and visualizing the results on boxplots, barplots, and other visualizations.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "visualization",
        "statistical_test"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/trevismd/statannotations",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "statistics",
        "visualization",
        "seaborn",
        "significance-testing"
      ],
      "id": 311
    },
    {
      "name": "sovereign",
      "one_line_profile": "Tools for state-dependent empirical analysis and forecasting",
      "detailed_description": "Sovereign is an R package providing tools for state-dependent empirical analysis, including state-dependent forecasts, impulse response functions, historical decomposition, and forecast error variance decomposition. It is designed for econometric and time-series research.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "forecasting",
        "time_series_analysis",
        "econometrics"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/tylerJPike/sovereign",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "econometrics",
        "forecasting",
        "time-series",
        "r-package"
      ],
      "id": 312
    },
    {
      "name": "deltacomp",
      "one_line_profile": "Analysis of compositional data with confidence intervals",
      "detailed_description": "Deltacomp is an R package containing functions to analyze compositional data. It specifically produces confidence intervals for relative increases and decreases in compositional components, aiding in statistical inference for compositional datasets.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "confidence_intervals"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/tystan/deltacomp",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "compositional-data",
        "statistics",
        "confidence-intervals",
        "r-package"
      ],
      "id": 313
    },
    {
      "name": "Petastorm",
      "one_line_profile": "Library for training and evaluation from Parquet datasets",
      "detailed_description": "Petastorm is a library that enables single-machine or distributed training and evaluation of deep learning models directly from datasets in Apache Parquet format. It supports major ML frameworks like Tensorflow, Pytorch, and PySpark, facilitating efficient data loading for scientific AI workflows.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "data_loading",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/uber/petastorm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "parquet",
        "deep-learning",
        "data-loader",
        "distributed-training"
      ],
      "id": 314
    },
    {
      "name": "HyperLearn",
      "one_line_profile": "High-performance machine learning algorithms library",
      "detailed_description": "HyperLearn is a machine learning library designed for speed and efficiency, offering algorithms that are significantly faster and use less memory than traditional implementations. It aims to accelerate data science and scientific computing tasks on modern hardware.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "machine_learning",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/unslothai/hyperlearn",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "machine-learning",
        "performance",
        "optimization",
        "acceleration"
      ],
      "id": 315
    },
    {
      "name": "KAIROS Scoring",
      "one_line_profile": "Scoring and analysis software for KAIROS evaluation",
      "detailed_description": "Software developed by NIST for the scoring and analysis of the Knowledge Directed Artificial Intelligence Reasoning Over Schemas (KAIROS) program. It provides tools for evaluating AI reasoning capabilities against defined schemas.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "evaluation",
        "scoring"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/usnistgov/KAIROS",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "evaluation",
        "nist",
        "ai-reasoning",
        "scoring"
      ],
      "id": 316
    },
    {
      "name": "Errudite",
      "one_line_profile": "Interactive tool for scalable and reproducible error analysis",
      "detailed_description": "Errudite is an interactive tool designed for scalable and reproducible error analysis in NLP models. It allows researchers to group and analyze error patterns to better understand model failure modes.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "error_analysis",
        "evaluation"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/uwdata/errudite",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "nlp",
        "error-analysis",
        "visualization",
        "debugging"
      ],
      "id": 317
    },
    {
      "name": "ulab",
      "one_line_profile": "Numpy-like fast vector module for MicroPython",
      "detailed_description": "ulab is a numpy-like fast vector module written in C for MicroPython and CircuitPython. It enables efficient numerical and scientific computing on embedded systems and microcontrollers.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "numerical_computing",
        "embedded_computing"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/v923z/micropython-ulab",
      "help_website": [
        "https://micropython-ulab.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "micropython",
        "numpy",
        "numerical-computing",
        "embedded"
      ],
      "id": 318
    },
    {
      "name": "open-rag-eval",
      "one_line_profile": "RAG evaluation tool without golden answers",
      "detailed_description": "open-rag-eval is a library for evaluating Retrieval-Augmented Generation (RAG) systems without the need for ground truth 'golden answers'. It provides metrics to assess the quality of retrieved context and generated responses.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "evaluation",
        "metrics",
        "rag"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vectara/open-rag-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "llm",
        "metrics"
      ],
      "id": 319
    },
    {
      "name": "HyPhy",
      "one_line_profile": "Hypothesis testing using Phylogenies",
      "detailed_description": "HyPhy (Hypothesis Testing using Phylogenies) is a software package for the analysis of genetic sequences using techniques from phylogenetics, molecular evolution, and machine learning. It is widely used for detecting natural selection and evolutionary modeling.",
      "domains": [
        "AI4",
        "Bio"
      ],
      "subtask_category": [
        "phylogenetics",
        "hypothesis_testing",
        "evolutionary_analysis"
      ],
      "application_level": "solver",
      "primary_language": "HyPhy",
      "repo_url": "https://github.com/veg/hyphy",
      "help_website": [
        "http://hyphy.org/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "bioinformatics",
        "phylogenetics",
        "evolution",
        "hypothesis-testing"
      ],
      "id": 320
    },
    {
      "name": "RC-FIAP",
      "one_line_profile": "Platform for seismic vulnerability evaluation of reinforced concrete frames",
      "detailed_description": "RC-FIAP is an open virtual platform for evaluating the seismic vulnerability of reinforced concrete frames. Built on OpenSeesPy, it facilitates performance-based earthquake engineering, risk assessment, and fragility analysis of structural archetypes.",
      "domains": [
        "AI4",
        "CivilEng"
      ],
      "subtask_category": [
        "simulation",
        "risk_assessment",
        "structural_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/vfceball/RC-FIAP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "seismic-analysis",
        "civil-engineering",
        "opensees",
        "simulation"
      ],
      "id": 321
    },
    {
      "name": "PyUMLS_Similarity",
      "one_line_profile": "Similarity metrics for UMLS concepts",
      "detailed_description": "PyUMLS_Similarity is a package that computes various similarity metrics between concepts in the Unified Medical Language System (UMLS). It serves as an interface to UMLS and supports biomedical informatics research.",
      "domains": [
        "AI4",
        "Bio"
      ],
      "subtask_category": [
        "similarity_calculation",
        "metrics",
        "biomedical_informatics"
      ],
      "application_level": "library",
      "primary_language": "Perl",
      "repo_url": "https://github.com/victormurcia/PyUMLS_Similarity",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "umls",
        "similarity-metrics",
        "biomedical",
        "perl"
      ],
      "id": 322
    },
    {
      "name": "marginaleffects",
      "one_line_profile": "R package for model predictions, comparisons, and hypothesis tests",
      "detailed_description": "marginaleffects is an R package to compute and plot predictions, slopes, marginal means, and comparisons for over 100 classes of statistical and ML models. It supports linear and non-linear hypothesis tests and uncertainty estimation.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "statistical_analysis",
        "hypothesis_testing",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/vincentarelbundock/marginaleffects",
      "help_website": [
        "https://vincentarelbundock.github.io/marginaleffects/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "statistics",
        "r-package",
        "hypothesis-testing",
        "marginal-effects"
      ],
      "id": 323
    },
    {
      "name": "MagnetLoss-PyTorch",
      "one_line_profile": "PyTorch implementation of Magnet Loss for deep metric learning",
      "detailed_description": "A PyTorch implementation of Magnet Loss, a deep metric learning technique. This repository provides a reusable component for training models with advanced metric learning objectives.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "metric_learning",
        "loss_function"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vithursant/MagnetLoss-PyTorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "metric-learning",
        "loss-function",
        "deep-learning"
      ],
      "id": 324
    },
    {
      "name": "Hemm",
      "one_line_profile": "Holistic evaluation library for multi-modal generative models",
      "detailed_description": "Hemm is a library for the holistic evaluation of multi-modal generative models. It integrates with Weave to provide comprehensive metrics and tracking for generative AI research.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "evaluation",
        "metrics",
        "multimodal_ai"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wandb/Hemm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "generative-ai",
        "multimodal",
        "metrics"
      ],
      "id": 325
    },
    {
      "name": "pretty-print-confusion-matrix",
      "one_line_profile": "Utility for plotting confusion matrices in Python",
      "detailed_description": "A Python utility to plot aesthetically pleasing confusion matrices using seaborn and matplotlib, similar to Matlab's style. It aids in the visualization of classification model performance metrics.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "visualization",
        "metrics_visualization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wcipriano/pretty-print-confusion-matrix",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "confusion-matrix",
        "visualization",
        "python",
        "matplotlib"
      ],
      "id": 326
    },
    {
      "name": "statannot",
      "one_line_profile": "Statistical annotations for seaborn boxplots",
      "detailed_description": "Statannot is a Python package that adds statistical significance annotations (p-values) to existing boxplots generated by seaborn. It helps in visualizing the results of statistical tests directly on data plots.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "visualization",
        "statistical_test"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/webermarcolivier/statannot",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "statistics",
        "visualization",
        "seaborn",
        "p-value"
      ],
      "id": 327
    },
    {
      "name": "LangKit",
      "one_line_profile": "Open-source toolkit for monitoring and evaluating Large Language Models (LLMs)",
      "detailed_description": "A comprehensive toolkit designed for monitoring LLMs by extracting signals from prompts and responses. It provides metrics for text quality, relevance, sentiment analysis, and safety, ensuring the security and reliability of LLM applications.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "monitoring",
        "text_quality_metrics",
        "sentiment_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/whylabs/langkit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "observability",
        "nlp",
        "metrics"
      ],
      "id": 328
    },
    {
      "name": "neleval",
      "one_line_profile": "Evaluation and error analysis tool for Named Entity Linking (NEL) systems",
      "detailed_description": "A tool designed to evaluate entity disambiguation and named entity linking systems. It facilitates error analysis and provides standard metrics to assess the performance of NEL models.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "entity_linking",
        "evaluation",
        "error_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wikilinks/neleval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nel",
        "nlp",
        "evaluation",
        "disambiguation"
      ],
      "id": 329
    },
    {
      "name": "wmt-format-tools",
      "one_line_profile": "Tools for formatting WMT hypothesis and test sets",
      "detailed_description": "A collection of utilities for processing and formatting data for the Workshop on Machine Translation (WMT). It handles XML conversion and standardization of hypothesis and test sets for translation benchmarks.",
      "domains": [
        "AI4",
        "AI4-01"
      ],
      "subtask_category": [
        "data_formatting",
        "benchmark_preparation"
      ],
      "application_level": "workflow",
      "primary_language": "Hare",
      "repo_url": "https://github.com/wmt-conference/wmt-format-tools",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "wmt",
        "machine-translation",
        "xml",
        "formatting"
      ],
      "id": 330
    },
    {
      "name": "bm25s",
      "one_line_profile": "Fast Python implementation of BM25 algorithm for lexical search",
      "detailed_description": "A high-performance implementation of the BM25 ranking function using Numpy, Numba, and Scipy. It is designed for fast lexical search and information retrieval tasks in Python.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "information_retrieval",
        "ranking",
        "search"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/xhluca/bm25s",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bm25",
        "search",
        "ranking",
        "numba"
      ],
      "id": 331
    },
    {
      "name": "AB3DMOT",
      "one_line_profile": "3D Multi-Object Tracking baseline and evaluation metrics",
      "detailed_description": "An official implementation providing a baseline for 3D Multi-Object Tracking (MOT) along with new evaluation metrics. It serves as a standard benchmark tool for autonomous driving perception tasks.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "object_tracking",
        "benchmark",
        "evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/xinshuoweng/AB3DMOT",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "3d-tracking",
        "autonomous-driving",
        "metrics",
        "benchmark"
      ],
      "id": 332
    },
    {
      "name": "GAN-Metrics",
      "one_line_profile": "Evaluation metrics library for Generative Adversarial Networks",
      "detailed_description": "A library implementing various empirical evaluation metrics for Generative Adversarial Networks (GANs), including Inception Score and FID, facilitating the quantitative assessment of generative models.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "generative_model_evaluation",
        "image_quality_metrics"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/xuqiantong/GAN-Metrics",
      "help_website": [],
      "license": null,
      "tags": [
        "gan",
        "metrics",
        "inception-score",
        "fid"
      ],
      "id": 333
    },
    {
      "name": "MLmetrics",
      "one_line_profile": "Collection of Machine Learning evaluation metrics for R",
      "detailed_description": "An R package that provides a comprehensive set of standard evaluation metrics for machine learning tasks, including classification and regression performance indicators.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/yanyachen/MLmetrics",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "r",
        "machine-learning",
        "evaluation",
        "metrics"
      ],
      "id": 334
    },
    {
      "name": "summary-reward-no-reference",
      "one_line_profile": "Reference-free metric for measuring text summary quality",
      "detailed_description": "A Python implementation of a reference-free metric for evaluating the quality of text summaries. The metric is learned from human ratings, allowing for quality assessment without ground truth references.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "text_summarization",
        "evaluation_metric"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yg211/summary-reward-no-reference",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "summarization",
        "metrics",
        "reference-free"
      ],
      "id": 335
    },
    {
      "name": "AlignScore",
      "one_line_profile": "Metric for factual consistency evaluation in text generation",
      "detailed_description": "An implementation of AlignScore, a metric designed to evaluate the factual consistency of generated text against source information, addressing hallucination issues in NLP models.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "factual_consistency",
        "evaluation_metric",
        "hallucination_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yuh-zha/AlignScore",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "consistency",
        "metrics",
        "hallucination"
      ],
      "id": 336
    },
    {
      "name": "ashpy",
      "one_line_profile": "TensorFlow 2.0 library for distributed training and evaluation",
      "detailed_description": "A library built on TensorFlow 2.0 that facilitates distributed training, evaluation, model selection, and fast prototyping of deep learning models.",
      "domains": [
        "AI4",
        "AI4-02"
      ],
      "subtask_category": [
        "model_training",
        "evaluation",
        "model_selection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zurutech/ashpy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tensorflow",
        "training",
        "evaluation",
        "deep-learning"
      ],
      "id": 337
    }
  ]
}