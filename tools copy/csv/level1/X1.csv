id,name,one_line_profile,detailed_description,domains,subtask_category,application_level,primary_language,repo_url,help_website,license,tags
1,hamiltorch,PyTorch-based library for Riemannian Manifold Hamiltonian Monte Carlo (RMHMC) and Bayesian inference,A library enabling Hamiltonian Monte Carlo (HMC) and Riemannian Manifold HMC (RMHMC) sampling for Bayesian Neural Networks and general probabilistic models within the PyTorch framework.,X1;X1-01,inference;modeling,library,Python,https://github.com/AdamCobb/hamiltorch,,BSD-2-Clause,bayesian-inference;hmc;pytorch;uncertainty-quantification
2,BCUS,"Bayesian Calibration, Uncertainty, and Sensitivity analysis for OpenStudio building energy models","A Ruby-based tool developed by Argonne National Laboratory for performing Bayesian calibration, uncertainty quantification, and sensitivity analysis specifically for OpenStudio building energy models.",X1;X1-01;Energy,calibration;uncertainty_quantification;sensitivity_analysis,tool,Ruby,https://github.com/Argonne-National-Laboratory/BCUS,,NOASSERTION,energy-modeling;bayesian-calibration;openstudio
3,FOQUS,Framework for Optimization and Quantification of Uncertainty and Surrogates,"A Python framework developed by the CCSI Toolset for advanced simulation-based optimization, uncertainty quantification, and surrogate modeling, primarily for carbon capture and energy systems.",X1;X1-01;Chemistry;Energy,optimization;uncertainty_quantification;surrogate_modeling,platform,Python,https://github.com/CCSI-Toolset/FOQUS,,NOASSERTION,optimization;uncertainty-quantification;surrogate-models;ccsi
4,EnsembleKalmanProcesses.jl,Julia library for Ensemble Kalman Inversion and uncertainty quantification,A Julia library from the Climate Modeling Alliance (CliMA) implementing Ensemble Kalman Processes for gradient-free optimization and approximate uncertainty quantification in scientific problems.,X1;X1-01;Climate,calibration;uncertainty_quantification;optimization,library,Julia,https://github.com/CliMA/EnsembleKalmanProcesses.jl,,Apache-2.0,julia;kalman-filter;uncertainty-quantification;climate-modeling
5,pyvale,"Package for sensor simulation, uncertainty quantification, and validation","A virtual engineering laboratory package designed for sensor simulation, optimal sensor placement, and uncertainty quantification in validation experiments.",X1;X1-01;Engineering,simulation;uncertainty_quantification;experimental_design,library,C++,https://github.com/Computer-Aided-Validation-Laboratory/pyvale,,MIT,sensor-simulation;uncertainty-quantification;validation
6,net:cal,Calibration framework for measuring and mitigating miscalibration in neural networks,"A Python library dedicated to measuring and mitigating uncertainty miscalibration in deep learning models, providing various calibration methods and metrics.",X1;X1-01,calibration;uncertainty_quantification,library,Python,https://github.com/EFS-OpenSource/calibration-framework,,Apache-2.0,calibration;uncertainty-estimation;neural-networks
7,torch-uncertainty,Framework for uncertainty quantification in PyTorch models,An open-source PyTorch library designed to facilitate the development and evaluation of uncertainty quantification methods in deep learning models.,X1;X1-01,uncertainty_quantification;modeling,library,Python,https://github.com/ENSTA-U2IS-AI/torch-uncertainty,,Apache-2.0,pytorch;uncertainty-quantification;deep-learning
8,pyroms,Python tools for the Regional Ocean Modeling System (ROMS),"A collection of Python tools for pre- and post-processing data for the Regional Ocean Modeling System (ROMS), facilitating oceanographic simulations.",Oceanography,simulation;data_processing,library,Python,https://github.com/ESMG/pyroms,,NOASSERTION,ocean-modeling;roms;simulation
9,emukit,"Toolbox for decision making, uncertainty quantification and statistical emulation","A highly adaptable Python toolkit for enriching decision-making with uncertainty quantification, supporting multi-fidelity modeling, Bayesian optimization, and experimental design.",X1;X1-01,uncertainty_quantification;emulation;optimization,library,Python,https://github.com/EmuKit/emukit,,Apache-2.0,bayesian-optimization;uncertainty-quantification;emulation;experimental-design
10,Ensemble-Conformalized-Quantile-Regression,Valid and adaptive prediction intervals for probabilistic time series forecasting,A Python implementation of Ensemble Conformalized Quantile Regression (EnsembleCQR) for generating valid and adaptive prediction intervals in time series forecasting.,X1;X1-01,uncertainty_quantification;time_series_forecasting,solver,Jupyter Notebook,https://github.com/FilippoMB/Ensemble-Conformalized-Quantile-Regression,,MIT,conformal-prediction;time-series;quantile-regression
11,GEEConformal,Conformal prediction library for Google Earth Engine,"A library that brings conformal prediction capabilities to Google Earth Engine, enabling uncertainty quantification for remote sensing and geospatial data analysis.",X1;X1-01,uncertainty_quantification;remote_sensing,library,Jupyter Notebook,https://github.com/Geethen/GEEConformal,,MIT,google-earth-engine;conformal-prediction;geospatial
12,Probabilistic-Backpropagation,Implementation of Probabilistic Backpropagation for Bayesian neural networks,A reference implementation of the Probabilistic Backpropagation (PBP) method for scalable Bayesian inference in deep neural networks.,X1;X1-01,bayesian_inference;probabilistic_modeling,library,C,https://github.com/HIPS/Probabilistic-Backpropagation,,BSD-3-Clause,bayesian-neural-networks;probabilistic-backpropagation;inference
13,torchbnn,PyTorch library for Bayesian Neural Networks,"A Python library that provides implementations of Bayesian Neural Networks (BNN) for PyTorch, including Bayes By Backprop and other inference methods.",X1;X1-01,probabilistic_modeling;uncertainty_quantification,library,Python,https://github.com/Harry24k/bayesian-neural-network-pytorch,,MIT,pytorch;bayesian-neural-networks;bnn
14,HumBugDB,Acoustic mosquito detection dataset and Bayesian Neural Network models,"A repository containing code and models for acoustic mosquito detection using Bayesian Neural Networks, associated with the HumBugDB dataset.",X1;X1-01,bioacoustics;classification;uncertainty_quantification,dataset,Jupyter Notebook,https://github.com/HumBug-Mosquito/HumBugDB,,MIT,mosquito-detection;bayesian-neural-networks;bioacoustics
15,UQ360,Uncertainty Quantification 360 toolkit,"An extensible open-source toolkit by IBM to estimate, communicate, and use uncertainty in machine learning model predictions, providing a comprehensive set of UQ algorithms and metrics.",X1;X1-01,uncertainty_quantification;model_evaluation,library,Python,https://github.com/IBM/UQ360,https://ibm.github.io/UQ360/,Apache-2.0,uncertainty-quantification;machine-learning;trustworthy-ai
16,snowline,Tool for fast model fitting and comparison,"A Python tool designed to fit and compare complex models quickly using techniques like Laplace Approximation, Variational Bayes, and Importance Sampling.",X1;X1-01,model_fitting;bayesian_inference;model_comparison,solver,Python,https://github.com/JohannesBuchner/snowline,,NOASSERTION,model-fitting;bayesian;inference
17,ApproximateGPs.jl,Approximate Gaussian Processes in Julia,"A Julia library for approximate inference in Gaussian Processes, supporting sparse variational inducing point approximations and Laplace approximation.",X1;X1-01,probabilistic_modeling;gaussian_processes,library,Julia,https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl,,NOASSERTION,julia;gaussian-processes;variational-inference
18,ConformalPrediction.jl,Conformal Prediction for Julia,"A Julia package for predictive uncertainty quantification through Conformal Prediction, designed to work with machine learning models trained in MLJ.",X1;X1-01,uncertainty_quantification;conformal_prediction,library,Julia,https://github.com/JuliaTrustworthyAI/ConformalPrediction.jl,,MIT,julia;conformal-prediction;uq
19,LaplaceRedux.jl,Laplace Approximation for Flux.jl neural networks,A Julia library enabling effortless Bayesian Deep Learning through Laplace Approximation for neural networks built with Flux.jl.,X1;X1-01,bayesian_deep_learning;laplace_approximation,library,Julia,https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl,,MIT,julia;bayesian-deep-learning;laplace-approximation
20,UncertaintyQuantification.jl,Uncertainty Quantification framework for Julia,"A Julia library providing a framework for uncertainty quantification, including methods for reliability analysis, sensitivity analysis, and metamodeling.",X1;X1-01,uncertainty_quantification;sensitivity_analysis,library,Julia,https://github.com/JuliaUQ/UncertaintyQuantification.jl,,MIT,julia;uq;reliability-analysis
21,nlp-uncertainty-zoo,Model zoo for uncertainty quantification in NLP,A PyTorch library providing implementations of various uncertainty quantification methods specifically tailored for Natural Language Processing tasks.,X1;X1-01,uncertainty_quantification;nlp,library,Python,https://github.com/Kaleidophon/nlp-uncertainty-zoo,,NOASSERTION,nlp;uncertainty-quantification;pytorch
22,Pyroomacoustics,A comprehensive python package for audio signal processing and room acoustics simulation,Pyroomacoustics is a software package aimed at the rapid development and testing of audio array processing algorithms. It provides a simulation engine for room acoustics (using the image source method) and implements various beamforming and source separation algorithms.,Acoustics;Signal_Processing,simulation;beamforming;signal_processing,library,Python,https://github.com/LCAV/pyroomacoustics,https://pyroomacoustics.readthedocs.io/,MIT,acoustics;simulation;beamforming;audio-processing
23,Brancher,A user-centered Python library for differentiable probabilistic programming and variational inference,"Brancher is a python library for stochastic variational inference and differentiable probabilistic programming. It is designed to be user-friendly and allows for the definition of probabilistic models using a clean and intuitive syntax, leveraging PyTorch for automatic differentiation.",Probabilistic_Programming;X1,variational_inference;probabilistic_modeling;bayesian_inference,library,Python,https://github.com/LucaAmbrogioni/Brancher,,MIT,probabilistic-programming;variational-inference;pytorch;bayesian
24,DeepProbLog,A neuro-symbolic framework integrating probabilistic logic programming with deep learning,"DeepProbLog extends ProbLog to integrate Probabilistic Logic Programming with deep learning. It allows for the definition of probabilistic logic models where some probabilities are parameterized by neural networks, enabling neuro-symbolic learning and reasoning.",Logic_Programming;Neuro_Symbolic_AI;X1,probabilistic_reasoning;neuro_symbolic_learning;modeling,library,Python,https://github.com/ML-KULeuven/deepproblog,https://deepproblog.readthedocs.io/,Apache-2.0,neuro-symbolic;problog;probabilistic-logic;deep-learning
25,Deep4Cast,A toolkit for probabilistic multivariate time series forecasting,"Deep4Cast is a library for probabilistic multivariate time series forecasting using deep learning. It provides a unified interface for training and evaluating various deep learning models for forecasting tasks, with a focus on uncertainty quantification.",Time_Series;X1,forecasting;uncertainty_quantification;time_series_analysis,library,Python,https://github.com/MSRDL/Deep4Cast,,BSD-3-Clause,time-series;forecasting;probabilistic-modeling;deep-learning
26,UNIQUE,Benchmarking library for uncertainty estimation in machine learning,UNIQUE is a Python library designed for benchmarking uncertainty estimation and quantification methods for Machine Learning model predictions. It provides a standardized framework to evaluate the quality of uncertainty estimates.,X1;Machine_Learning,benchmarking;uncertainty_estimation;evaluation,library,Python,https://github.com/Novartis/UNIQUE,,BSD-3-Clause,uncertainty-quantification;benchmarking;metrics;machine-learning
27,PaddleTS,Comprehensive deep time series modeling library based on PaddlePaddle,"PaddleTS is an easy-to-use deep time series modeling library based on PaddlePaddle. It includes modules for data loading, analysis, transformation, and modeling, supporting tasks such as time series forecasting, representation learning, and anomaly detection.",Time_Series;X1,forecasting;anomaly_detection;representation_learning;time_series_analysis,library,Python,https://github.com/PaddlePaddle/PaddleTS,https://paddlets.readthedocs.io/,Apache-2.0,time-series;paddlepaddle;forecasting;deep-learning
28,UQpy,General purpose toolbox for modeling uncertainty in physical and mathematical systems,"UQpy (Uncertainty Quantification with python) is a general purpose Python toolbox for modeling uncertainty in physical and mathematical systems. It serves as a comprehensive library for uncertainty quantification, offering modules for sampling, reliability analysis, and stochastic process generation.",X1;X1-01,uncertainty_quantification;reliability_analysis;stochastic_modeling,library,Python,https://github.com/SURGroup/UQpy,,MIT,uncertainty-quantification;reliability-analysis;stochastic-processes
29,SciMLExpectations.jl,Fast uncertainty quantification for scientific machine learning and differential equations,A package within the SciML ecosystem for calculating expectations and performing uncertainty quantification on differential equation solutions and scientific machine learning models.,X1;X1-01,uncertainty_quantification;differential_equations,library,Julia,https://github.com/SciML/SciMLExpectations.jl,,NOASSERTION,sciml;julia;uncertainty-quantification
30,PyRoss,"Library for inference, forecasts, and optimised control of epidemiological models","PyRoss is a library for numerical simulation, Bayesian inference, and optimal control of age-structured contact matrix based epidemiological compartmental models.",X1;X1-01,epidemiological_modeling;bayesian_inference,library,Jupyter Notebook,https://github.com/SoftMatterGroupCambridge/pyross,https://github.com/rajeshrinet/pyross,MIT,epidemiology;inference;control-theory
31,AgReFed-ML,Machine learning tools for modelling and predicting agriculture systems and their uncertainties,"A collection of machine learning tools and workflows developed by the Sydney Informatics Hub for modeling agricultural systems, specifically focusing on uncertainty quantification in predictions.",X1;X1-01,agricultural_modeling;uncertainty_quantification,library,Jupyter Notebook,https://github.com/Sydney-Informatics-Hub/AgReFed-ML,,LGPL-3.0,agriculture;machine-learning;uncertainty
32,Ensemble-Pytorch,Unified ensemble framework for PyTorch to improve model performance and robustness,"A comprehensive library for implementing ensemble learning methods in PyTorch, aiming to enhance the performance and uncertainty estimation robustness of deep learning models.",X1;X1-01,ensemble_learning;uncertainty_estimation,library,Python,https://github.com/TorchEnsemble-Community/Ensemble-Pytorch,,BSD-3-Clause,ensemble-learning;pytorch;robustness
33,TorchUQ,Library for uncertainty quantification and calibration based on PyTorch,"A library dedicated to uncertainty quantification in deep learning, providing implementations for various UQ methods and calibration techniques compatible with PyTorch.",X1;X1-01,uncertainty_quantification;calibration,library,Jupyter Notebook,https://github.com/TorchUQ/torchuq,,MIT,uncertainty-quantification;pytorch;calibration
34,AdvancedVI.jl,Implementation of variational Bayes inference algorithms for the Turing ecosystem,"A Julia library providing advanced Variational Inference (VI) algorithms, serving as a core component for probabilistic programming and Bayesian inference within the Turing.jl ecosystem.",X1;X1-01,variational_inference;bayesian_inference,library,Julia,https://github.com/TuringLang/AdvancedVI.jl,,MIT,variational-inference;julia;bayesian
35,EasyVVUQ,"Framework to facilitate verification, validation, and uncertainty quantification for simulations","A Python framework designed to simplify the process of Verification, Validation, and Uncertainty Quantification (VVUQ) for a wide range of scientific simulations and computational models.",X1;X1-01,vvuq;simulation_analysis,workflow,Jupyter Notebook,https://github.com/UCL-CCS/EasyVVUQ,,LGPL-3.0,vvuq;simulation;uncertainty-quantification
36,Doubly-Stochastic-DGP,Implementation of Deep Gaussian Processes with Doubly Stochastic Variational Inference,"A library/solver implementing Deep Gaussian Processes using Doubly Stochastic Variational Inference, enabling scalable and deep probabilistic modeling.",X1;X1-01,gaussian_processes;variational_inference,solver,Python,https://github.com/UCL-SML/Doubly-Stochastic-DGP,,Apache-2.0,gaussian-processes;deep-learning;variational-inference
37,NeuralBKI,Neural Network Bayesian Kernel Inference solver for robotics and perception,"A solver implementing Neural Network Bayesian Kernel Inference, combining deep learning with Bayesian kernel methods for uncertainty-aware perception and mapping.",X1;X1-01,bayesian_inference;kernel_methods,solver,Jupyter Notebook,https://github.com/UMich-CURLY/NeuralBKI,,MIT,bayesian-inference;robotics;neural-networks
38,LLM-judge-reporting,Framework for bias correction and confidence interval computation in LLM-based evaluation,"A plug-in framework for statistical analysis of LLM-as-a-judge evaluations, providing tools to correct bias and compute confidence intervals to quantify uncertainty in model reporting.",X1;X1-01,statistical_evaluation;uncertainty_quantification,library,Jupyter Notebook,https://github.com/UW-Madison-Lee-Lab/LLM-judge-reporting,,None,llm-evaluation;statistics;confidence-intervals
39,tfcausalimpact,Python implementation of Causal Impact based on Google's R package using TensorFlow Probability,"A Python library for causal inference using Bayesian structural time-series models, built on top of TensorFlow Probability. It estimates the causal effect of a designed intervention on a time series.",X1;X1-01,causal_inference;time_series_analysis,library,Python,https://github.com/WillianFuks/tfcausalimpact,,Apache-2.0,causal-inference;tensorflow-probability;time-series
40,chemprop,Message passing neural networks for molecular property prediction with uncertainty quantification,"A library for training message passing neural networks (MPNNs) for molecular property prediction. It includes features for fast and scalable uncertainty quantification, accelerated optimization, and guided virtual screening.",X1;X1-01,molecular_property_prediction;uncertainty_quantification,library,Python,https://github.com/aamini/chemprop,,MIT,chemistry;molecular-modeling;uncertainty-quantification
41,evidential-deep-learning,Library for learning calibrated measures of uncertainty using neural networks,"A codebase for Evidential Deep Learning (EDL), allowing neural networks to learn fast, scalable, and calibrated measures of uncertainty directly from data.",X1;X1-01,uncertainty_quantification;model_calibration,library,Python,https://github.com/aamini/evidential-deep-learning,,Apache-2.0,evidential-learning;uncertainty;deep-learning
42,conformal-risk,PyTorch implementation for conformal risk control,"A lightweight library providing PyTorch implementations for conformal risk control, enabling control of monotonic risk functions in computer vision and NLP tasks.",X1;X1-01,risk_control;uncertainty_quantification,library,Python,https://github.com/aangelopoulos/conformal-risk,,MIT,conformal-prediction;risk-control;pytorch
43,im2im-uq,Image-to-image regression with distribution-free uncertainty quantification,"A PyTorch library for image-to-image regression tasks that provides rigorous, distribution-free uncertainty quantification.",X1;X1-01,image_regression;uncertainty_quantification,library,Python,https://github.com/aangelopoulos/im2im-uq,,MIT,image-to-image;uncertainty-quantification;pytorch
44,vistan,Library to run variational inference on Stan models,A simple Python library designed to facilitate running variational inference algorithms on models defined in the Stan probabilistic programming language.,X1;X1-01,variational_inference;probabilistic_modeling,library,Python,https://github.com/abhiagwl/vistan,,GPL-3.0,stan;variational-inference;bayesian
45,dpmm,Variational inference for Dirichlet process mixture models,A Python implementation of variational inference for Dirichlet process mixture models (DPMM) with multinomial mixture components.,X1;X1-01,statistical_inference;clustering,library,Python,https://github.com/abietti/dpmm,,None,dirichlet-process;variational-inference;mixture-models
46,pyvbmc,Variational Bayesian Monte Carlo algorithm in Python,"A Python implementation of the Variational Bayesian Monte Carlo (VBMC) algorithm for posterior and model inference, suitable for computationally expensive black-box likelihoods.",X1;X1-01,bayesian_inference;model_inference,library,Python,https://github.com/acerbilab/pyvbmc,,BSD-3-Clause,vbmc;bayesian-inference;monte-carlo
47,vbmc,Variational Bayesian Monte Carlo algorithm in MATLAB,A MATLAB implementation of the Variational Bayesian Monte Carlo (VBMC) algorithm for posterior and model inference.,X1;X1-01,bayesian_inference;model_inference,library,MATLAB,https://github.com/acerbilab/vbmc,,BSD-3-Clause,vbmc;matlab;bayesian-inference
48,stan2tfp,Interface to the TensorFlow Probability backend of the Stan compiler,A lightweight interface that provides the necessary objects and functions to compile a Stan program and fit the model to data using TensorFlow Probability (TFP).,X1;X1-01,probabilistic_modeling;interoperability,library,Python,https://github.com/adamhaber/stan2tfp,,BSD-3-Clause,stan;tensorflow-probability;interface
49,Fortuna.jl,Julia package for structural and system reliability analysis,"A general-purpose Julia package designed for structural and system reliability analysis, providing tools for uncertainty quantification in engineering systems.",X1;X1-01,reliability_analysis;uncertainty_quantification,library,Julia,https://github.com/akchurinda/Fortuna.jl,,MIT,reliability-analysis;julia;uncertainty
50,Laplace,Laplace approximations for Deep Learning,A Python library for applying Laplace approximations to deep learning models to estimate uncertainty and improve calibration.,X1;X1-01,uncertainty_quantification;model_calibration,library,Python,https://github.com/aleximmer/Laplace,,MIT,laplace-approximation;deep-learning;uncertainty
51,pyrodigal,Python interface to Prodigal ORF finder,"Cython bindings and Python interface to Prodigal, a fast and reliable tool for finding open reading frames (ORFs) in genomes and metagenomes.",X1,genome_annotation;orf_finding,library,Cython,https://github.com/althonos/pyrodigal,,GPL-3.0,bioinformatics;genomics;prodigal
52,bnn,Bayesian Neural Network implementation in PyTorch,"A PyTorch implementation of Bayesian Neural Networks, providing modules and tools for training BNNs and estimating uncertainty.",X1;X1-01,bayesian_neural_networks;uncertainty_quantification,library,Python,https://github.com/anassinator/bnn,,MIT,bnn;pytorch;bayesian-deep-learning
53,SparseGaussianProcesses.jl,Julia implementation of sparse Gaussian processes via variational inference,"A Julia package implementing sparse Gaussian processes using path-wise doubly stochastic variational inference, designed for efficient probabilistic modeling.",X1;X1-01,gaussian_processes;variational_inference,library,Julia,https://github.com/aterenin/SparseGaussianProcesses.jl,,NOASSERTION,julia;gaussian-processes;variational-inference
54,pybnn,Python package for training Bayesian Neural Networks,"A Python library for implementing and training Bayesian Neural Networks, providing tools for uncertainty estimation in deep learning models.",X1;X1-01,bayesian_neural_networks;uncertainty_quantification,library,Jupyter Notebook,https://github.com/automl/pybnn,,BSD-3-Clause,bayesian-neural-networks;bnn;uncertainty
55,Fortuna,Library for Uncertainty Quantification in Deep Learning,A library for uncertainty quantification that provides calibration and conformal prediction methods to estimate predictive uncertainty in deep learning models.,X1;X1-01,uncertainty_quantification;calibration;conformal_prediction,library,Python,https://github.com/awslabs/fortuna,https://aws-fortuna.readthedocs.io,Apache-2.0,uncertainty-quantification;calibration;deep-learning
56,BayesFlow,Library for amortized Bayesian workflows using generative networks,"A Python library for performing amortized Bayesian inference using invertible neural networks and other generative models, facilitating complex simulation-based inference.",X1;X1-01,bayesian_inference;simulation_based_inference;generative_models,library,Python,https://github.com/bayesflow-org/bayesflow,https://bayesflow.org,MIT,bayesian-inference;amortized-inference;generative-networks
57,pyrouge,Python wrapper for the ROUGE summarization evaluation package,"A Python library that wraps the ROUGE evaluation metric, commonly used in Natural Language Processing for evaluating automatic summarization and text generation.",NLP,evaluation;text_summarization,library,Python,https://github.com/bheinzerling/pyrouge,,MIT,nlp;evaluation;rouge
58,ctr,C++ implementation of Collaborative Topic Regression,"A C++ solver implementing variational inference for collaborative topic models, combining topic modeling with collaborative filtering for recommendation systems.",Machine Learning,topic_modeling;recommendation;variational_inference,solver,C++,https://github.com/blei-lab/ctr,,GPL-2.0,topic-modeling;collaborative-filtering;cpp
59,Edward,Probabilistic programming language built on TensorFlow,"A probabilistic programming library for probabilistic modeling, inference, and criticism, enabling the development of deep generative models and variational inference methods.",X1;X1-01,probabilistic_programming;variational_inference;deep_generative_models,library,Jupyter Notebook,https://github.com/blei-lab/edward,http://edwardlib.org,NOASSERTION,probabilistic-programming;tensorflow;bayesian-inference
60,pyroki,Modular toolkit for robot kinematic optimization,"A Python toolkit designed for robot kinematic optimization, providing modules for modeling and solving kinematics problems in robotics research.",Robotics,kinematics;optimization;robotics_modeling,library,Python,https://github.com/chungmin99/pyroki,,MIT,robotics;kinematics;optimization
61,GPyTorch,Efficient Gaussian Processes in PyTorch,"A highly efficient implementation of Gaussian Processes using PyTorch, designed for scalability and flexibility in probabilistic modeling and uncertainty quantification.",X1;X1-01,gaussian_processes;probabilistic_modeling;uncertainty_quantification,library,Python,https://github.com/cornellius-gp/gpytorch,https://gpytorch.ai,MIT,gaussian-processes;pytorch;machine-learning
62,LinearOperator,Linear operator abstractions for GPyTorch,"A library providing LinearOperator abstractions to handle numerical operations efficiently, serving as the mathematical backend for GPyTorch and other scientific computing tasks.",Scientific Computing,linear_algebra;optimization;numerical_methods,library,Python,https://github.com/cornellius-gp/linear_operator,,MIT,linear-algebra;numerical-computing;pytorch
63,OpenCossan,Toolbox for uncertainty quantification and management,"An open-source MATLAB toolbox for uncertainty quantification, reliability analysis, and risk management in engineering systems.",X1;Engineering,uncertainty_quantification;reliability_analysis;risk_management,library,MATLAB,https://github.com/cossan-working-group/OpenCossan,http://www.cossan.co.uk,NOASSERTION,uncertainty-quantification;matlab;reliability
64,pyvarinf,Bayesian Deep Learning methods with Variational Inference for PyTorch,"A Python package that facilitates the implementation of Bayesian Deep Learning models using Variational Inference within the PyTorch framework, enabling uncertainty estimation in neural networks.",X1;X1-01,variational_inference;bayesian_deep_learning,library,Python,https://github.com/ctallec/pyvarinf,,MIT,pytorch;bayesian-inference;variational-inference
65,UQLM,Uncertainty Quantification for Language Models,"A Python package designed for uncertainty quantification in Large Language Models (LLMs), specifically targeting the detection of hallucinations through UQ-based methods.",X1;X1-01;NLP,hallucination_detection;uncertainty_quantification,library,Python,https://github.com/cvs-health/uqlm,,Apache-2.0,llm;hallucination;uncertainty-quantification
66,DALIA,Implementation of Integrated Nested Laplace Approximations (INLA),"A Python implementation of the Integrated Nested Laplace Approximations (INLA) methodology, used for approximate Bayesian inference in latent Gaussian models.",X1;X1-01;Statistics,bayesian_inference;approximate_inference,solver,Python,https://github.com/dalia-project/DALIA,,BSD-3-Clause,inla;bayesian;laplace-approximation
67,DeepNano,Nanobody-antigen interaction prediction,A deep learning tool for predicting nanobody-antigen interactions using ensemble deep learning and prompt-based protein language models.,Biology;X1-01,interaction_prediction;protein_engineering,solver,Python,https://github.com/ddd9898/DeepNano,,MIT,nanobody;deep-learning;protein-interaction
68,plmc,Inference of couplings in proteins and RNAs,"A tool for inferring couplings in proteins and RNAs from sequence variation data, often used for contact prediction and structure inference.",Biology;Statistics,sequence_analysis;coupling_inference,solver,C,https://github.com/debbiemarkslab/plmc,,MIT,bioinformatics;protein-structure;inference
69,puncc,Predictive uncertainty quantification using conformal prediction,A Python library for predictive uncertainty quantification that implements various conformal prediction algorithms to provide valid coverage guarantees.,X1;X1-01,conformal_prediction;uncertainty_quantification,library,Python,https://github.com/deel-ai/puncc,https://deel-ai.github.io/puncc/,None,conformal-prediction;uncertainty;python
70,pysvihmm,Stochastic variational inference for Bayesian HMMs,"A Python implementation of stochastic variational inference for Bayesian hidden Markov models, enabling scalable inference on time-series data.",X1;X1-01;Statistics,hidden_markov_model;variational_inference,library,Python,https://github.com/dillonalaird/pysvihmm,,None,hmm;bayesian;svi
71,coverforest,Conformal predictions with random forests,A library providing sklearn-compatible conformal prediction implementations using random forests for classification and regression tasks.,X1;X1-01,conformal_prediction;regression,library,Jupyter Notebook,https://github.com/donlapark/coverforest,,BSD-3-Clause,random-forest;conformal-prediction;sklearn
72,nonconformist,Conformal prediction framework for Python,"A mature Python implementation of the conformal prediction framework, allowing for the creation of prediction intervals with guaranteed validity.",X1;X1-01,conformal_prediction;uncertainty_quantification,library,Python,https://github.com/donlnz/nonconformist,,MIT,conformal-prediction;machine-learning;python
73,PyTorchAVITM,Autoencoding Variational Inference for Topic Models,"A PyTorch implementation of the Autoencoding Variational Inference for Topic Models (AVITM) algorithm, used for probabilistic topic modeling.",NLP;Statistics,topic_modeling;variational_inference,solver,Python,https://github.com/estebandito22/PyTorchAVITM,,MIT,topic-modeling;pytorch;variational-inference
74,AEPsych,Adaptive experimentation for psychophysics,"A framework for adaptive experimentation in psychophysics and perception research, utilizing Gaussian Processes and Bayesian Optimization (via BoTorch/GPyTorch).",Psychophysics;X1,adaptive_experimentation;bayesian_optimization,platform,HTML,https://github.com/facebookresearch/aepsych,http://aepsych.org,NOASSERTION,psychophysics;adaptive-experimentation;botorch
75,PyRobot,Open Source Robotics Research Platform,"A high-level interface for controlling different robots, designed to facilitate robotics research and data collection.",Robotics,robot_control;data_collection,platform,Python,https://github.com/facebookresearch/pyrobot,https://pyrobot.org/,MIT,robotics;ros;research-platform
76,riadd.aucmedi,Multi-Disease Detection in Retinal Imaging,"A deep learning framework for multi-disease detection in retinal imaging, utilizing ensemble methods for improved performance.",Medical Imaging;X1-01,disease_detection;medical_image_analysis,solver,Python,https://github.com/frankkramer-lab/riadd.aucmedi,,GPL-3.0,retinal-imaging;deep-learning;medical-ai
77,ThermoNet,Protein thermodynamic stability prediction,A computational method using an ensemble of deep 3D convolutional neural networks to predict the impact of single-point mutations on protein thermodynamic stability.,Biology;X1-01,stability_prediction;mutation_analysis,solver,Python,https://github.com/gersteinlab/ThermoNet,,GPL-3.0,protein-stability;deep-learning;bioinformatics
78,SAM2,Deep generative modeling of protein structural ensembles,"A deep generative model for predicting protein structural ensembles, capturing the conformational heterogeneity of proteins.",Biology;X1,structure_prediction;generative_modeling,solver,Python,https://github.com/giacomo-janson/sam2,,Apache-2.0,protein-structure;generative-model;molecular-dynamics
79,uncertain_ground_truth,Jax implementations of Monte Carlo conformal prediction and dermatology dataset,"A repository containing Jax implementations of Monte Carlo conformal prediction, plausibility regions, and statistical annotation aggregation methods, alongside a dermatology differential diagnosis dataset.",X1;X1-01,uncertainty_quantification;conformal_prediction;medical_diagnosis,library,Python,https://github.com/google-deepmind/uncertain_ground_truth,,Apache-2.0,jax;conformal-prediction;dermatology;uncertainty
80,Uncertainty Baselines,High-quality implementations of standard and SOTA uncertainty quantification methods,"A library providing high-quality implementations of standard and state-of-the-art methods for uncertainty estimation across a variety of tasks, serving as a benchmark for research.",X1;X1-01,uncertainty_quantification;benchmarking;model_evaluation,library,Python,https://github.com/google/uncertainty-baselines,,Apache-2.0,uncertainty-estimation;benchmarks;deep-learning;tensorflow
81,H2O-3,Distributed and scalable machine learning platform for data analysis,"An open-source, distributed, fast, and scalable machine learning platform supporting Deep Learning, Gradient Boosting, Random Forest, and AutoML, widely used for scientific data analysis and modeling.",X1,data_analysis;modeling;automl,platform,Java,https://github.com/h2oai/h2o-3,https://docs.h2o.ai/h2o/latest-stable/h2o-docs/index.html,Apache-2.0,machine-learning;distributed-computing;automl;data-science
82,crepes,Python package for conformal prediction and uncertainty quantification,"A Python package implementing conformal prediction methods to produce valid prediction intervals and sets, supporting various types of regressors and classifiers.",X1;X1-01,uncertainty_quantification;conformal_prediction,library,Python,https://github.com/henrikbostrom/crepes,https://crepes.readthedocs.io,BSD-3-Clause,conformal-prediction;uncertainty;calibration;python
83,RAVEN,"Probabilistic risk analysis, validation, and uncertainty quantification framework","A flexible and multi-purpose framework for probabilistic risk analysis, validation, uncertainty quantification, parameter optimization, and model reduction, developed by Idaho National Laboratory.",X1;X1-01,risk_analysis;uncertainty_quantification;optimization;model_validation,framework,Python,https://github.com/idaholab/raven,https://raven.inl.gov,Apache-2.0,risk-analysis;uncertainty-quantification;nuclear-engineering;simulation
84,cca_zoo,Collection of Canonical Correlation Analysis methods in a scikit-learn style,"A library providing a collection of Regularized, Deep Learning based, Kernel, and Probabilistic Canonical Correlation Analysis (CCA) methods, designed with a scikit-learn style interface for scientific data analysis.",X1,statistical_analysis;correlation_analysis;multiview_learning,library,Python,https://github.com/jameschapman19/cca_zoo,https://cca-zoo.readthedocs.io,MIT,canonical-correlation-analysis;statistics;multiview-learning;scikit-learn
85,SPOT-RNA,RNA secondary structure prediction using deep neural networks,"A tool for predicting RNA secondary structures using an ensemble of two-dimensional deep neural networks and transfer learning, enabling accurate structural inference for biological research.",X1,structure_prediction;rna_folding,solver,Perl,https://github.com/jaswindersingh2/SPOT-RNA,,MPL-2.0,rna-structure;deep-learning;bioinformatics;structure-prediction
86,Oryx,Probabilistic programming and deep learning library built on JAX,"Oryx is a library for probabilistic programming and deep learning built on top of JAX. It provides a system for building and transforming probabilistic models, enabling efficient inference and uncertainty quantification in deep learning workflows.",X1;X1-01,probabilistic_programming;inference;uncertainty_quantification,library,Python,https://github.com/jax-ml/oryx,https://oryx.readthedocs.io/,Apache-2.0,jax;probabilistic-programming;bayesian-inference
87,DeepStack,Library for ensembling Keras deep learning models,"DeepStack is a Python library designed to facilitate the creation of ensembles of Keras deep learning models. It supports various ensemble strategies to improve predictive performance and robustness, which is a key technique in uncertainty quantification.",X1;X1-01,ensembling;model_stacking,library,Python,https://github.com/jcborges/DeepStack,,MIT,keras;ensemble-learning;deep-learning
88,viabel,Efficient variational inference and approximation bounds library,"Viabel is a Python package for efficient, lightweight variational inference (VI). It provides tools for computing approximation bounds and improving the reliability of posterior approximations in Bayesian modeling.",X1;X1-01,variational_inference;bayesian_approximation,library,Python,https://github.com/jhuggins/viabel,,MIT,variational-inference;bayesian;optimization
89,conditional-conformal,Package for conformal prediction with conditional guarantees,A Python package implementing methods for conformal prediction that provide conditional coverage guarantees. It is designed to quantify uncertainty in predictive models by constructing valid prediction intervals.,X1;X1-01,conformal_prediction;uncertainty_quantification,library,Jupyter Notebook,https://github.com/jjcherian/conditional-conformal,,MIT,conformal-prediction;statistics;uncertainty
90,VENI-VINDy-VICI,Framework for generative reduced order models with uncertainty quantification,An interpretable data-driven framework for building generative reduced order models (ROMs) that embed uncertainty quantification. It combines physics-informed modeling with data-driven approaches for scientific simulation.,X1;X1-01,reduced_order_modeling;uncertainty_quantification;generative_modeling,solver,Python,https://github.com/jkneifl/VENI-VINDy-VICI,,MIT,rom;physics-informed;scientific-machine-learning
91,VinDsl.jl,Domain-specific language for variational inference in Julia,"VinDsl.jl is a domain-specific language (DSL) designed to simplify the specification and execution of variational inference tasks within the Julia programming environment, facilitating Bayesian analysis.",X1;X1-01,variational_inference;probabilistic_programming,library,Jupyter Notebook,https://github.com/jmxpearson/VinDsl.jl,,MIT,julia;variational-inference;dsl
92,nautilus,Neural Network-Boosted Importance Nested Sampling for Bayesian Statistics,Nautilus is a Python package for efficient Bayesian posterior sampling and evidence estimation using neural network-boosted importance nested sampling. It is designed for complex astronomical and physical modeling problems.,X1;X1-01,nested_sampling;bayesian_inference;posterior_estimation,library,Python,https://github.com/johannesulf/nautilus,https://nautilus-sampler.readthedocs.io/,MIT,nested-sampling;bayesian;astronomy
93,pyroSAR,Framework for large-scale SAR satellite data processing,"pyroSAR is a Python framework for large-scale processing of Synthetic Aperture Radar (SAR) satellite data. It provides tools for organizing, processing, and analyzing SAR data from various missions.",X1,remote_sensing;data_processing;sar_analysis,platform,Python,https://github.com/johntruckenbrodt/pyroSAR,https://pyrosar.readthedocs.io/,MIT,sar;remote-sensing;satellite-data
94,chaospy,Toolbox for performing uncertainty quantification,Chaospy is a numerical toolbox for performing uncertainty quantification using polynomial chaos expansions and Monte Carlo methods. It allows for the modeling of uncertainty in physical simulations.,X1;X1-01,uncertainty_quantification;polynomial_chaos;sensitivity_analysis,library,Python,https://github.com/jonathf/chaospy,https://chaospy.readthedocs.io/,MIT,uncertainty-quantification;polynomial-chaos;numerical-methods
95,TyXe,Library for Bayesian Neural Networks in PyTorch,TyXe is a library for building and training Bayesian Neural Networks (BNNs) using PyTorch. It leverages Pyro for probabilistic inference and aims to make BNNs accessible for deep learning practitioners.,X1;X1-01,bayesian_neural_networks;probabilistic_modeling,library,Jupyter Notebook,https://github.com/karalets/TyXe,,None,bayesian-deep-learning;pytorch;pyro
96,PyTorch-BayesianCNN,Bayesian Convolutional Neural Network implementation with Variational Inference,A widely used PyTorch implementation of Bayesian Convolutional Neural Networks using Variational Inference (Bayes by Backprop). It provides reusable layers and modules for constructing Bayesian deep learning models.,X1;X1-01,bayesian_neural_networks;variational_inference,library,Python,https://github.com/kumar-shridhar/PyTorch-BayesianCNN,,MIT,bayesian-cnn;pytorch;variational-inference
97,laplax,Laplace approximations in JAX,Laplax is a library for computing Laplace approximations of posterior distributions in JAX. It facilitates uncertainty quantification and model selection in Bayesian workflows.,X1;X1-01,laplace_approximation;bayesian_inference,library,Python,https://github.com/laplax-org/laplax,,MIT,jax;laplace-approximation;bayesian
98,DeepSuperLearner,Implementation of the deep ensemble algorithm for uncertainty quantification,"A Python implementation of the Deep Super Learner algorithm, which utilizes deep ensembles to improve predictive performance and uncertainty estimation in deep learning models.",X1;X1-01,ensemble_learning;uncertainty_quantification,solver,Python,https://github.com/levyben/DeepSuperLearner,,MIT,deep-ensemble;super-learner;uncertainty
99,QUESO,C++ library for uncertainty quantification in estimation and simulation,"QUESO (Quantification of Uncertainty for Estimation, Simulation and Optimization) is a collection of algorithms and C++ classes intended to support research in uncertainty quantification, specifically for inverse problems and statistical calibration.",X1;X1-01,uncertainty_quantification;bayesian_inference;inverse_problems,library,C++,https://github.com/libqueso/queso,,NOASSERTION,uq;bayesian;c++
100,Lightning-UQ-Box,Uncertainty Quantification toolbox for Neural Networks with PyTorch Lightning,"A comprehensive library designed to simplify the implementation and evaluation of uncertainty quantification methods for neural networks, leveraging the PyTorch Lightning framework.",X1;X1-01,uncertainty_quantification;model_evaluation,library,Python,https://github.com/lightning-uq-box/lightning-uq-box,https://lightning-uq-box.readthedocs.io,Apache-2.0,pytorch-lightning;uq;neural-networks
101,Mr.LDA,Scalable Topic Modeling using Variational Inference in MapReduce,"A scalable implementation of Latent Dirichlet Allocation (LDA) using variational inference, designed to run on MapReduce clusters for processing large-scale text corpora.",X1;X1-01,topic_modeling;variational_inference,solver,Java,https://github.com/lintool/Mr.LDA,,Apache-2.0,lda;mapreduce;variational-inference
102,DREML,Deep Randomized Ensembles for Metric Learning,"A PyTorch implementation of Deep Randomized Ensembles for Metric Learning, providing a method to improve robustness and uncertainty estimation in metric learning tasks.",X1;X1-01,metric_learning;ensemble_learning,solver,Python,https://github.com/littleredxh/DREML,,None,metric-learning;ensemble;pytorch
103,GParML,Distributed Variational Inference for Gaussian Processes,"A library for performing distributed variational inference in sparse Gaussian Process regression and latent variable models, enabling scalable probabilistic modeling.",X1;X1-01,gaussian_processes;variational_inference,library,Python,https://github.com/markvdw/GParML,,NOASSERTION,gaussian-processes;variational-inference;distributed-computing
104,CREPE,Convolutional Representation for Pitch Estimation,A pre-trained deep learning model and tool for high-accuracy monophonic pitch estimation from raw audio signals.,Audio,pitch_estimation;signal_processing,solver,Python,https://github.com/marl/crepe,,MIT,audio;pitch-detection;deep-learning
105,torchcrepe,PyTorch implementation of the CREPE pitch tracker,"A PyTorch implementation of the CREPE pitch estimation algorithm, allowing for GPU acceleration and integration into PyTorch-based audio processing workflows.",Audio,pitch_estimation;signal_processing,library,Python,https://github.com/maxrmorrison/torchcrepe,,MIT,pytorch;audio;pitch-tracking
106,Bayesianize,Bayesian neural network wrapper for PyTorch,A lightweight wrapper to convert standard PyTorch neural networks into Bayesian Neural Networks (BNNs) to enable uncertainty estimation.,X1;X1-01,bayesian_inference;uncertainty_quantification,library,Python,https://github.com/microsoft/bayesianize,,MIT,pytorch;bnn;wrapper
107,BioEmu,Emulator for protein equilibrium ensembles using generative deep learning,"A generative deep learning framework for scalable emulation of protein equilibrium ensembles, facilitating the study of protein dynamics and conformational heterogeneity.",Bio,protein_dynamics;molecular_simulation;generative_modeling,solver,Python,https://github.com/microsoft/bioemu,,MIT,protein-folding;generative-ai;molecular-dynamics
108,Horseshoe-BNN,Bayesian Neural Network with horseshoe prior,Implementation of a Bayesian Neural Network utilizing the horseshoe prior to enhance model interpretability and sparsity.,X1;X1-01,bayesian_inference;model_interpretability,solver,Python,https://github.com/microsoft/horseshoe-bnn,,NOASSERTION,bnn;horseshoe-prior;sparsity
109,VI-HDS,Variational inference for hierarchical dynamical systems,"A library for applying variational inference methods to hierarchical dynamical systems, enabling probabilistic modeling of complex time-dependent processes.",X1;X1-01,variational_inference;dynamical_systems,solver,Python,https://github.com/microsoft/vi-hds,,MIT,variational-inference;time-series;hierarchical-models
110,SIVI,Semi-Implicit Variational Inference implementation,"Implementation of Semi-Implicit Variational Inference (SIVI), a method for accurate uncertainty estimation using a hierarchical variational family.",X1;X1-01,variational_inference;uncertainty_estimation,solver,MATLAB,https://github.com/mingzhang-yin/SIVI,,MIT,variational-inference;matlab;probabilistic-modeling
111,BayesianRecurrentNN,Implementation of Bayesian Recurrent Neural Networks,"A reusable implementation of Bayesian Recurrent Neural Networks (RNNs) based on Fortunato et al., enabling uncertainty quantification in sequence modeling.",X1;X1-01,bayesian_inference;sequence_modeling,solver,Python,https://github.com/mirceamironenco/BayesianRecurrentNN,,MIT,rnn;bayesian;lstm
112,PersonalizedMultitaskLearning,Library for multitask machine learning methods including Hierarchical Bayesian models,"A codebase providing implementations for multitask learning approaches, including deep neural networks, Multitask Multi-kernel Learning (MTMKL), and Hierarchical Bayesian Linear Regression (HBLR).",X1;X1-01,multitask_learning;bayesian_modeling,library,Python,https://github.com/mitmedialab/PersonalizedMultitaskLearning,,None,multitask-learning;bayesian;machine-learning
113,HopCPT,Conformal Prediction for Time Series with Modern Hopfield Networks,"A tool for applying conformal prediction to time series data using Modern Hopfield Networks, providing rigorous uncertainty bounds.",X1;X1-01,conformal_prediction;time_series_forecasting,solver,Python,https://github.com/ml-jku/HopCPT,,MIT,conformal-prediction;hopfield-networks;time-series
114,SDLG,Method for estimating aleatoric semantic uncertainty in LLMs,An efficient method implementation for accurately estimating aleatoric semantic uncertainty in Large Language Models (LLMs).,X1;X1-01,uncertainty_quantification;llm_analysis,solver,Jupyter Notebook,https://github.com/ml-jku/SDLG,,None,llm;aleatoric-uncertainty;semantic-uncertainty
115,TorchCP,Conformal prediction toolbox for deep learning in PyTorch,"A comprehensive Python toolbox for research and application of conformal prediction methods on deep learning models, built on PyTorch.",X1;X1-01,conformal_prediction;uncertainty_quantification,library,Python,https://github.com/ml-stat-Sustech/TorchCP,https://torchcp.readthedocs.io,LGPL-3.0,conformal-prediction;pytorch;toolbox
116,DeepSEA,Similarity Ensemble Approach with deep learning for chemical substance fingerprints,"A Python implementation of the Similarity Ensemble Approach (SEA) using deep learning fingerprints, designed for chemoinformatics applications such as drug discovery and target prediction.",X1;Chemistry;Chemoinformatics,molecular_similarity;virtual_screening,library,Python,https://github.com/momeara/DeepSEA,,None,chemoinformatics;drug-discovery;similarity-ensemble-approach
117,pyrolite,Geochemical data analysis and visualization toolset,"A Python package designed for working with geochemical data, providing functions for transformation, normalization, and visualization of compositional data.",X1;Geochemistry;Earth Science,data_analysis;visualization;compositional_data,library,Python,https://github.com/morganjwilliams/pyrolite,https://pyrolite.readthedocs.io,NOASSERTION,geochemistry;compositional-data;visualization
118,MTUQ,Moment Tensor Uncertainty Quantification for seismology,"A Python package for moment tensor inversion and uncertainty quantification in seismology, allowing researchers to estimate earthquake source parameters with associated uncertainties.",X1;Seismology;Geophysics,uncertainty_quantification;moment_tensor_inversion,library,Python,https://github.com/mtuqorg/mtuq,https://mtuq.readthedocs.io,BSD-2-Clause,seismology;uncertainty-quantification;moment-tensor
119,keras-uncertainty,Uncertainty quantification utilities for Keras models,"A library providing utilities to perform uncertainty quantification on Keras models, including implementations of various Bayesian deep learning techniques.",X1;X1-01,uncertainty_quantification;model_evaluation,library,Python,https://github.com/mvaldenegro/keras-uncertainty,,LGPL-3.0,keras;uncertainty-quantification;bayesian-deep-learning
120,SMCPy,Parallel sequential Monte Carlo sampler for uncertainty quantification,"A Python module for uncertainty quantification using a parallel sequential Monte Carlo sampler, developed by NASA for probabilistic analysis.",X1;X1-01,uncertainty_quantification;sampling,library,Python,https://github.com/nasa/SMCPy,,NOASSERTION,monte-carlo;uncertainty-quantification;nasa
121,UQPCE,Uncertainty Quantification using Polynomial Chaos Expansion,An open-source Python research code for uncertainty quantification using non-intrusive polynomial chaos expansion surrogate modeling techniques.,X1;X1-01,uncertainty_quantification;surrogate_modeling,library,Python,https://github.com/nasa/UQPCE,,NOASSERTION,polynomial-chaos-expansion;uncertainty-quantification;surrogate-modeling
122,toupee,Library for Deep Learning Ensembles,"A Python library designed to facilitate the creation and training of deep learning ensembles, often used for improving predictive performance and uncertainty estimation.",X1;X1-01,ensemble_learning;uncertainty_quantification,library,Python,https://github.com/nitbix/toupee,,None,deep-learning;ensembles;machine-learning
123,posteriors,Uncertainty quantification library for PyTorch,"A library for uncertainty quantification in PyTorch, providing tools for Bayesian inference and posterior estimation in deep learning models.",X1;X1-01,uncertainty_quantification;bayesian_inference,library,Python,https://github.com/normal-computing/posteriors,,Apache-2.0,pytorch;uncertainty-quantification;bayesian
124,UnaryBayes,Bayesian framework for thermodynamic property models,"A Bayesian framework for the selection, calibration, and uncertainty quantification of thermodynamic property models.",X1;Thermodynamics;Physics,model_calibration;uncertainty_quantification,library,Python,https://github.com/npaulson/UnaryBayes,,BSD-3-Clause,thermodynamics;bayesian;calibration
125,uncertainty_gbm,Gradient Boosting Machines with uncertainty quantification,An sklearn-compatible implementation of Gradient Boosting Machines (GBM) designed to predict both the mean and standard deviation on heteroscedastic data.,X1;X1-01,uncertainty_quantification;regression,library,Python,https://github.com/ofirnachum/uncertainty_gbm,,BSD-3-Clause,gbm;uncertainty;sklearn-compatible
126,OpenTURNS,Library for probabilistic modeling and uncertainty quantification,"A comprehensive C++ library (with Python bindings) for probabilistic modeling, uncertainty quantification, and reliability analysis.",X1;X1-01,uncertainty_quantification;probabilistic_modeling;reliability_analysis,library,C++,https://github.com/openturns/openturns,http://openturns.github.io/openturns/latest/,NOASSERTION,uncertainty-quantification;probabilistic-modeling;reliability
127,blapsr,Bayesian inference with Laplace approximations and P-splines,"An R package for performing Bayesian inference using Laplace approximations and P-splines, suitable for statistical modeling and smoothing.",X1;Statistics,bayesian_inference;statistical_modeling,library,R,https://github.com/oswaldogressani/blapsr,,None,bayesian;p-splines;r-package
128,verified_calibration,Library for verified uncertainty calibration,"A library implementing methods for verified uncertainty calibration in machine learning models, as presented in the NeurIPS 2019 paper.",X1;X1-01,model_calibration;uncertainty_quantification,library,Python,https://github.com/p-lambda/verified_calibration,,MIT,calibration;uncertainty;machine-learning
129,CalibrationWizard,Guidance system for camera calibration,A tool designed to guide users through the camera calibration process by modeling geometric and corner uncertainty to ensure high-quality calibration results.,X1;Computer Vision,camera_calibration;uncertainty_modeling,solver,C++,https://github.com/pengsongyou/CalibrationWizard,,MIT,camera-calibration;computer-vision;uncertainty
130,bayesian-torch,Framework for Bayesian neural networks in PyTorch,A framework that allows users to easily convert standard PyTorch neural network definitions into Bayesian neural networks for uncertainty estimation.,X1;X1-01,bayesian_deep_learning;uncertainty_quantification,library,Python,https://github.com/peustr/bayesian-torch,,NOASSERTION,pytorch;bayesian-neural-networks;uncertainty
131,plot_utils,Utility functions for Conformal Prediction plotting,"A repository containing utility functions for plotting metrics related to Conformal Prediction, developed for pharmaceutical bioinformatics applications.",X1;Bioinformatics;Pharma,visualization;conformal_prediction,library,Jupyter Notebook,https://github.com/pharmbio/plot_utils,,None,conformal-prediction;visualization;bioinformatics
132,BLiTZ,PyTorch layer library for Bayesian Deep Learning,"A simple and extensible library to create Bayesian Neural Network layers on PyTorch, enabling uncertainty estimation in deep learning models.",X1;X1-01,uncertainty_quantification;bayesian_modeling,library,Python,https://github.com/piEsposito/blitz-bayesian-deep-learning,,GPL-3.0,bayesian-neural-networks;pytorch;uncertainty-quantification
133,crepes-weighted,Weighted conformal prediction extension for crepes,Extension of the crepes package to enable weighted conformal prediction and conformal predictive systems that can handle covariate shifts.,X1;X1-01,uncertainty_quantification;conformal_prediction,library,Python,https://github.com/predict-idlab/crepes-weighted,,BSD-3-Clause,conformal-prediction;covariate-shift;uncertainty
134,Funsor,Tensor-like library for probabilistic programming,"Functional tensors for probabilistic programming, providing a unified interface for probabilistic inference algorithms.",X1;X1-01,probabilistic_programming;inference,library,Python,https://github.com/pyro-ppl/funsor,http://funsor.pyro.ai,Apache-2.0,probabilistic-programming;tensors;inference
135,NumPyro,JAX-based probabilistic programming library,"Probabilistic programming with NumPy powered by JAX for autograd and JIT compilation to GPU/TPU/CPU, serving as a backend for Pyro or standalone.",X1;X1-01,probabilistic_programming;bayesian_inference;mcmc,library,Python,https://github.com/pyro-ppl/numpyro,http://num.pyro.ai,Apache-2.0,jax;bayesian-inference;probabilistic-programming
136,Pyro,Deep universal probabilistic programming language,"A flexible, scalable deep universal probabilistic programming language built on PyTorch, supporting variational inference and MCMC.",X1;X1-01,probabilistic_programming;variational_inference;bayesian_modeling,library,Python,https://github.com/pyro-ppl/pyro,http://pyro.ai,Apache-2.0,pytorch;probabilistic-programming;bayesian
137,Pyrocko,Seismology toolkit for Python,"A comprehensive toolkit for seismology, providing tools for seismic data processing, analysis, and visualization.",Cross-domain,seismic_data_processing;geophysics_modeling,library,Python,https://github.com/pyrocko/pyrocko,https://pyrocko.org,GPL-3.0,seismology;geophysics;data-processing
138,Pyrosm,Fast OpenStreetMap data reader for Python,"A Python library for reading OpenStreetMap data from Protobuf files into GeoDataFrame, optimized for performance in spatial analysis.",Cross-domain,spatial_data_processing;gis,library,Python,https://github.com/pyrosm/pyrosm,https://pyrosm.readthedocs.io,MIT,openstreetmap;gis;geodataframe
139,pyro2,Hydrodynamics exploration framework,"A framework for hydrodynamics explorations and prototyping, used for simulation and education in computational fluid dynamics.",Cross-domain,hydrodynamics_simulation;fluid_dynamics,solver,Python,https://github.com/python-hydro/pyro2,https://pyro2.readthedocs.io,BSD-3-Clause,hydrodynamics;cfd;simulation
140,PyTorch,Deep learning framework with dynamic computation graphs,"A widely used open source machine learning framework that accelerates the path from research prototyping to production deployment, serving as a foundation for many AI4S tools.",Cross-domain,deep_learning;scientific_computing,platform,Python,https://github.com/pytorch/pytorch,https://pytorch.org,NOASSERTION,deep-learning;tensor-computation;autograd
141,admc,Automatic differentiation for Monte Carlo,"Infinite order automatic differentiation for Monte Carlo with unnormalized probability distribution, useful for advanced scientific computing and inference.",X1;X1-01,automatic_differentiation;monte_carlo_methods,library,Python,https://github.com/refraction-ray/admc,,MIT,automatic-differentiation;monte-carlo;scientific-computing
142,PyRoboLearn,Framework for Robot Learning,"A Python framework for Robot Learning, providing environments, robots, and algorithms for robotics research.",Cross-domain,robotics_simulation;robot_learning,workflow,Python,https://github.com/robotlearn/pyrobolearn,,Apache-2.0,robotics;reinforcement-learning;simulation
143,tfprobability,R interface to TensorFlow Probability,"R interface to TensorFlow Probability, bringing probabilistic reasoning and statistical analysis tools to the R scientific community.",X1;X1-01,probabilistic_programming;statistical_analysis,library,R,https://github.com/rstudio/tfprobability,https://rstudio.github.io/tfprobability/,NOASSERTION,r;tensorflow-probability;statistics
144,online_conformal,Methods for online conformal prediction,"A library providing methods for online conformal prediction, enabling uncertainty quantification in streaming data settings.",X1;X1-01,uncertainty_quantification;conformal_prediction,library,Python,https://github.com/salesforce/online_conformal,,Apache-2.0,conformal-prediction;online-learning;uncertainty
145,ACPI,Adaptive Conformal Prediction Intervals,A Python package that enhances predictive intervals provided by split conformal approaches using a weighting strategy.,X1;X1-01,uncertainty_quantification;conformal_prediction,library,Python,https://github.com/salimamoukou/ACPI,,MIT,conformal-prediction;predictive-intervals;python
146,UQTk,Sandia Uncertainty Quantification Toolkit,"A lightweight C++/Python library for uncertainty quantification, offering tools for sampling, inference, and polynomial chaos expansions.",X1;X1-01,uncertainty_quantification;sampling;inference,library,C++,https://github.com/sandialabs/UQTk,http://www.sandia.gov/UQ/QT/,NOASSERTION,uncertainty-quantification;sandia;scientific-computing
147,pyapprox,High-dimensional approximation and uncertainty quantification tools,"A flexible and efficient library for high-dimensional approximation, scientific machine learning, and uncertainty quantification, supporting various sparse grid and polynomial chaos expansion methods.",X1;X1-01,uncertainty_quantification;approximation;sensitivity_analysis,library,Python,https://github.com/sandialabs/pyapprox,,MIT,uq;scientific-machine-learning;approximation
148,Suncal,Sandia PSL Uncertainty Calculator,"A specialized uncertainty calculator tool developed by Sandia National Laboratories, designed for metrology and physical standards laboratory applications.",X1;X1-01,uncertainty_calculation;metrology,solver,Python,https://github.com/sandialabs/suncal,,GPL-3.0,metrology;uncertainty-calculator;calibration
149,MAPIE,Model Agnostic Prediction Interval Estimator,"A scikit-learn-compatible library for estimating prediction intervals and controlling risks using conformal prediction methods, applicable to regression and classification tasks.",X1;X1-01,uncertainty_quantification;conformal_prediction;risk_control,library,Python,https://github.com/scikit-learn-contrib/MAPIE,https://mapie.readthedocs.io/,BSD-3-Clause,conformal-prediction;prediction-intervals;scikit-learn
150,monaco,Monte Carlo library for uncertainty and sensitivity analysis,"An industry-grade Monte Carlo library designed to quantify uncertainty and sensitivities in computer models, providing tools for sampling, simulation, and statistical analysis.",X1;X1-01,uncertainty_quantification;sensitivity_analysis;monte_carlo_simulation,library,Python,https://github.com/scottshambaugh/monaco,,MIT,monte-carlo;sensitivity-analysis;simulation
151,scvi-tools,Deep probabilistic analysis for single-cell omics,"A comprehensive library for deep probabilistic analysis of single-cell and spatial omics data, utilizing variational inference and generative models for scientific discovery in biology.",X1;X1-01,probabilistic_modeling;single_cell_analysis;generative_modeling,library,Python,https://github.com/scverse/scvi-tools,https://scvi-tools.org/,BSD-3-Clause,single-cell;probabilistic-modeling;genomics
152,pyrobosim,ROS 2 enabled 2D mobile robot simulator,"A 2D mobile robot simulator for behavior prototyping, supporting ROS 2, used for generating synthetic data and testing robotic algorithms in a simulated environment.",X1,simulation;robotics_modeling;synthetic_data_generation,solver,Python,https://github.com/sea-bass/pyrobosim,,MIT,robotics;simulation;ros2
153,Uncertainpy,Uncertainty quantification for computational neuroscience,"A Python toolbox for uncertainty quantification and sensitivity analysis, specifically tailored towards computational neuroscience models and simulations.",X1;X1-01,uncertainty_quantification;sensitivity_analysis;neuroscience_modeling,library,Python,https://github.com/simetenn/uncertainpy,https://uncertainpy.readthedocs.io/,GPL-3.0,neuroscience;uq;sensitivity-analysis
154,theano_pyglm,Bayesian inference for generalized linear models in neuroscience,"A library for generalized linear models (GLMs) tailored for neural spike train modeling, supporting GPU-accelerated fully-Bayesian inference and MAP inference.",X1;X1-01,bayesian_inference;spike_train_modeling;neuroscience,library,Python,https://github.com/slinderman/theano_pyglm,,MIT,neuroscience;glm;bayesian-inference
155,LLM-Uncertainty-Bench,Benchmarking framework for LLM uncertainty quantification,"A benchmarking tool designed to evaluate and quantify the uncertainty of Large Language Models (LLMs), facilitating the assessment of model reliability.",X1;X1-01,model_evaluation;uncertainty_benchmarking;llm_analysis,library,Python,https://github.com/smartyfh/LLM-Uncertainty-Bench,,MIT,llm;benchmarking;uncertainty
156,folktexts,Benchmark for evaluating LLM uncertainty and fairness,"A package providing datasets and tools to evaluate uncertainty, calibration, accuracy, and fairness of Large Language Models on real-world survey data.",X1;X1-01,model_evaluation;fairness_analysis;calibration,dataset,Python,https://github.com/socialfoundations/folktexts,,MIT,llm;fairness;calibration
157,conformal-tights,Conformal prediction for scikit-learn and Darts,"A library that adds conformal prediction capabilities to any scikit-learn regressor or Darts forecaster, enabling the generation of coherent quantiles and prediction intervals.",X1;X1-01,conformal_prediction;uncertainty_quantification;time_series_forecasting,library,Python,https://github.com/superlinear-ai/conformal-tights,,MIT,conformal-prediction;scikit-learn;forecasting
158,R-SWAT,Interactive web application for SWAT model calibration and uncertainty analysis,"R-SWAT is an interactive web-based application designed to facilitate parallel parameter sensitivity analysis, calibration, and uncertainty analysis for the Soil and Water Assessment Tool (SWAT and SWAT+). It provides a graphical interface for hydrologists and environmental scientists to perform complex model evaluations.",X1;X1-01,sensitivity_analysis;calibration;uncertainty_analysis,solver,R,https://github.com/tamnva/R-SWAT,,GPL-3.0,swat;hydrology;calibration;uncertainty-analysis;shiny-app
159,ConformalImpact,Causal inference tool with conformal prediction intervals,ConformalImpact extends the Causal Impact methodology by incorporating MFLES (Model Free Locally Estimated Scatterplot Smoothing) and conformal prediction intervals. It allows for robust causal inference and uncertainty quantification in time series analysis.,X1;X1-01,causal_inference;uncertainty_quantification;time_series_analysis,library,Python,https://github.com/tblume1992/ConformalImpact,,MIT,causal-inference;conformal-prediction;time-series;uncertainty
160,evidential-learning-pytorch,PyTorch implementation of Evidential Deep Learning for uncertainty quantification,"A library implementing Evidential Deep Learning (EDL) in PyTorch, enabling deep neural networks to quantify classification and regression uncertainty by placing Dirichlet priors on class probabilities or evidential distributions on continuous targets.",X1;X1-01,uncertainty_quantification;classification;regression,library,Python,https://github.com/teddykoker/evidential-learning-pytorch,,MIT,pytorch;evidential-deep-learning;uncertainty-quantification;edl
161,TensorFlow Probability,Library for probabilistic reasoning and statistical analysis in TensorFlow,"TensorFlow Probability is a library for probabilistic reasoning and statistical analysis. It provides tools for building probabilistic models, performing Bayesian inference, and analyzing data with statistical distributions, integrated seamlessly with the TensorFlow ecosystem.",X1;X1-01,probabilistic_modeling;bayesian_inference;statistical_analysis,library,Python,https://github.com/tensorflow/probability,https://www.tensorflow.org/probability,Apache-2.0,probabilistic-programming;bayesian;statistics;tensorflow
162,ZhuSuan,Probabilistic programming library for Bayesian deep learning,"ZhuSuan is a python probabilistic programming library for Bayesian deep learning, built on Tensorflow. It provides primitives for building generative models and performing variational inference, bridging the gap between deep learning and Bayesian methods.",X1;X1-01,bayesian_deep_learning;generative_modeling;variational_inference,library,Python,https://github.com/thu-ml/zhusuan,https://zhusuan.readthedocs.io,MIT,probabilistic-programming;bayesian-deep-learning;variational-inference
163,ZhuSuan-PyTorch,PyTorch version of the ZhuSuan probabilistic programming library,"ZhuSuan-PyTorch is a port of the ZhuSuan library to the PyTorch framework, enabling Bayesian deep learning and probabilistic programming capabilities for PyTorch users.",X1;X1-01,bayesian_deep_learning;generative_modeling;variational_inference,library,Python,https://github.com/thuwzy/ZhuSuan-PyTorch,,MIT,pytorch;bayesian-deep-learning;probabilistic-programming
164,Orbit,Bayesian forecasting library with object-oriented design,"Orbit is a Python package for Bayesian time series forecasting and inference. It provides a flexible and intuitive interface for building probabilistic models, handling seasonality, trend, and regression components using MCMC or variational inference.",X1;X1-01,time_series_forecasting;bayesian_inference;uncertainty_quantification,library,Python,https://github.com/uber/orbit,https://orbit-ml.readthedocs.io,Apache-2.0,forecasting;bayesian;time-series;probabilistic-modeling
165,Uncertainty Toolbox,"Toolbox for predictive uncertainty quantification, calibration, and metrics","Uncertainty Toolbox is a Python library designed to evaluate and improve the uncertainty estimates of predictive models. It provides standard metrics (calibration error, sharpness), visualization tools, and recalibration methods for regression and classification tasks.",X1;X1-01,uncertainty_quantification;calibration;model_evaluation,library,Python,https://github.com/uncertainty-toolbox/uncertainty-toolbox,https://uncertainty-toolbox.github.io,MIT,uncertainty-quantification;calibration;metrics;visualization
166,Pearsonify,Classification intervals using Pearson residuals and conformal prediction,Pearsonify is a lightweight Python package for generating classification intervals in binary classification tasks. It leverages Pearson residuals and conformal prediction techniques to provide statistically valid uncertainty estimates.,X1;X1-01,uncertainty_quantification;classification;conformal_prediction,library,Python,https://github.com/xRiskLab/pearsonify,,MIT,conformal-prediction;classification;uncertainty
167,conformalForecast,Methods and tools for multistep-ahead time series conformal prediction,"A package providing methods and tools for performing multistep-ahead conformal prediction on time series data, enabling uncertainty quantification in forecasting.",X1;X1-01,time_series_forecasting;uncertainty_quantification,library,R,https://github.com/xqnwang/conformalForecast,,GPL-3.0,conformal-prediction;time-series;forecasting
168,flex,Probabilistic deep learning library for data streams,"A library designed for probabilistic deep learning on data streams, providing implementations for estimating probability distributions in streaming environments.",X1;X1-01,probabilistic_modeling;data_stream_analysis,library,Scala,https://github.com/xxxnell/flex,,MIT,probabilistic-deep-learning;streaming-data;scala
169,BayeFormers,API for Deep Bayesian Variational Inference in Transformers,"A general API for Deep Bayesian Variational Inference by Backpropagation, designed to work with Transformer architectures and compatible with HuggingFace models.",X1;X1-01,variational_inference;uncertainty_quantification,library,Python,https://github.com/yliess86/BayeFormers,,MIT,bayesian-deep-learning;transformers;variational-inference
170,zfit,Scalable model manipulation and fitting library for probability density functions,"A model manipulation and fitting library based on TensorFlow, optimised for simple and direct manipulation of probability density functions, with a focus on scalability and parallelisation.",X1;X1-01,model_fitting;probability_density_estimation,library,Python,https://github.com/zfit/zfit,https://zfit.readthedocs.io/,BSD-3-Clause,fitting;probability-density-function;tensorflow
171,Lightweight VIO,Statistical uncertainty learning framework for robust visual-inertial state estimation,A lightweight visual-inertial odometry (VIO) system that incorporates statistical uncertainty learning to improve robustness and accuracy in state estimation for robotics and autonomous systems.,X1;X1-02;Robotics,state_estimation;uncertainty_quantification;visual_inertial_odometry,solver,C++,https://github.com/93won/lightweight_vio,,MIT,vio;robotics;uncertainty-learning;state-estimation
172,RaPId,Framework for parameter identification and calibration of dynamical systems,"RaPId (Rapid Parameter Identification) is a toolbox for model validation and calibration of dynamical systems, with a specific focus on power systems. It utilizes optimization and simulation technologies to align models with observed data.",X1;X1-02;Power Systems,parameter_identification;model_calibration;dynamical_systems,library,Modelica,https://github.com/ALSETLab/RaPId,,LGPL-3.0,modelica;calibration;power-systems;parameter-estimation
173,CalibrationNN,Library for model calibration using neural networks,"A Python library designed to perform probability calibration for machine learning models using neural network-based approaches, aiming to produce more accurate confidence estimates.",X1;X1-02,probability_calibration;confidence_estimation,library,Python,https://github.com/Andres-Hernandez/CalibrationNN,,GPL-3.0,calibration;neural-networks;uncertainty
174,rosdyn,Automated robot dynamics model calibration package,A ROS-based package that implements a fully automated procedure for calibrating robot dynamics models. It leverages the ROS ecosystem to standardize data exchange and robot driver access for identification of dynamic parameters.,X1;X1-02;Robotics,dynamics_calibration;parameter_identification;robot_modeling,solver,C++,https://github.com/CNR-STIIMA-IRAS/rosdyn,,Apache-2.0,ros;robotics;calibration;dynamics
175,allan_ros2,IMU noise parameter analysis using Allan deviation plots,"A ROS2 package for analyzing Inertial Measurement Unit (IMU) noise characteristics by generating and analyzing Allan deviation plots, essential for sensor calibration in robotics and navigation.",X1;X1-02;Robotics,sensor_calibration;noise_analysis;allan_deviation,solver,C++,https://github.com/CruxDevStuff/allan_ros2,,BSD-3-Clause,imu;calibration;ros2;allan-variance
176,PyESD,Empirical Statistical Downscaling tool for climate variables,"A Python package for Empirical Statistical Downscaling (ESD) of climate variables (e.g., precipitation, temperature) from reanalysis datasets to point scale, utilizing machine learning methods as transfer functions.",Climate Science;X1,statistical_downscaling;climate_data_analysis,library,Python,https://github.com/Dan-Boat/PyESD,,MIT,climate;downscaling;meteorology;machine-learning
177,Emukit,Toolbox for decision making and uncertainty quantification,"A highly adaptable Python toolkit for enriching decision-making processes with uncertainty quantification. It supports multi-fidelity modeling, experimental design, Bayesian optimization, and Bayesian quadrature.",X1;X1-02,uncertainty_quantification;bayesian_optimization;experimental_design;emulation,library,Python,https://github.com/EmuKit/emukit,https://emukit.readthedocs.io,Apache-2.0,uncertainty-quantification;bayesian-optimization;experimental-design;gaussian-processes
178,HiRAM,GFDL High Resolution Atmospheric Model,"The GFDL global High Resolution Atmospheric Model (HiRAM), designed to simulate the statistics of tropical storms and weather events with high fidelity. It is a key tool for studying climate variability and global warming effects on storm activity.",Climate Science;Atmospheric Physics,atmospheric_modeling;climate_simulation;weather_prediction,solver,Fortran,https://github.com/FMS-ESM/HiRAM,http://www.gfdl.noaa.gov/hiram,None,climate-model;atmospheric-science;gfdl;simulation
179,OpenSA,Comprehensive library for spectral analysis algorithms,"OpenSA (Open Spectrum Analysis) is a complete algorithm library for spectral analysis, covering dataset splitting, spectrum preprocessing, wavelength selection, and calibration model algorithms.",Spectroscopy;Chemometrics;X1-02,spectral_analysis;wavelength_selection;calibration_modeling;preprocessing,library,Python,https://github.com/FuSiry/OpenSA,,Apache-2.0,spectral-analysis;chemometrics;calibration;preprocessing
180,GaussianLSS,Depth uncertainty estimation via Gaussian Splatting,"Official PyTorch implementation of GaussianLSS, a method for depth uncertainty estimation in real-world BEV perception using Gaussian Splatting.",X1;X1-02,depth_estimation;uncertainty_estimation,solver,Jupyter Notebook,https://github.com/HCIS-Lab/GaussianLSS,,MIT,gaussian-splatting;depth-estimation;uncertainty;cvpr
181,ESL,Library for economic and financial agent-based models,"The Economic Simulation Library provides tools to develop, test, analyze, and calibrate economic and financial agent-based models, supporting parallel computation and large-scale sampling.",X1;X1-02,economic_simulation;agent_based_modeling;calibration,library,C++,https://github.com/INET-Complexity/ESL,,Apache-2.0,economics;simulation;agent-based-model;calibration
182,DifFlow3D,Robust uncertainty-aware scene flow estimation,"Implementation of DifFlow3D, a method for robust uncertainty-aware scene flow estimation using iterative diffusion-based refinement.",X1;X1-02,scene_flow_estimation;uncertainty_estimation,solver,Python,https://github.com/IRMVLab/DifFlow3D,,None,scene-flow;diffusion-model;uncertainty;cvpr
183,crepe-vamp-plugin,Vamp plugin for CREPE monophonic pitch tracker,"A Vamp plugin implementation of the CREPE monophonic pitch tracker, based on a deep convolutional neural network operating directly on time-domain waveform input.",X1,pitch_tracking;audio_analysis,solver,C++,https://github.com/Ircam-Partiels/crepe-vamp-plugin,,MIT,audio;pitch-tracking;vamp-plugin;neural-network
184,KinectUtil,Calibration tool for Kinect RGB and depth cameras,"A utility to solve the mismatch between RGB and depth cameras of Kinect by calibrating parameters and re-projecting images, improving point cloud quality.",X1;X1-02,camera_calibration;sensor_fusion,solver,C++,https://github.com/JasonZhu1313/KinectUtil,,None,kinect;calibration;point-cloud;rgb-d
185,FisherRF,Active view selection and UQ for radiance fields,"Implementation of FisherRF, a method for active view selection and uncertainty quantification for radiance fields using Fisher Information.",X1;X1-02,view_selection;uncertainty_quantification;radiance_fields,solver,Python,https://github.com/JiangWenPL/FisherRF,,NOASSERTION,nerf;fisher-information;active-learning;uncertainty
186,PALoc,SLAM benchmarking with prior-assisted trajectory generation,A tool for advancing SLAM benchmarking with prior-assisted 6-DoF trajectory generation and uncertainty estimation.,X1;X1-02,slam;trajectory_generation;uncertainty_estimation,solver,C++,https://github.com/JokerJohn/PALoc,,None,slam;benchmarking;trajectory;uncertainty
187,calibration-toolbox,NumPy library for calibration metrics,A NumPy-based library providing various metrics for evaluating the calibration of machine learning models.,X1;X1-02,calibration_metrics;model_evaluation,library,Python,https://github.com/Jonathan-Pearce/calibration-toolbox,,None,calibration;metrics;numpy;machine-learning
188,RGGNet,Tolerance-aware LiDAR-camera online calibration,"Official Tensorflow implementation of RGGNet, a method for tolerance-aware LiDAR-camera online calibration using geometric deep learning.",X1;X1-02,lidar_camera_calibration;sensor_calibration,solver,Python,https://github.com/KleinYuan/RGGNet,,None,lidar;camera;calibration;deep-learning
189,PyDREAM,Algorithm for model optimization and calibration in biology,"Implementation of the MT-DREAM(ZS) algorithm for model optimization, calibration, and selection, often used in systems biology.",X1;X1-02,model_calibration;bayesian_inference;systems_biology,library,Python,https://github.com/LoLab-MSM/PyDREAM,,GPL-3.0,systems-biology;bayesian;calibration;optimization
190,Guiding-Pseudo-labels-with-Uncertainty-Estimation,Uncertainty-guided pseudo-labels for domain adaptation,Implementation of a method for guiding pseudo-labels with uncertainty estimation for source-free unsupervised domain adaptation.,X1;X1-02,domain_adaptation;uncertainty_estimation,solver,Python,https://github.com/MattiaLitrico/Guiding-Pseudo-labels-with-Uncertainty-Estimation-for-Source-free-Unsupervised-Domain-Adaptation,,None,domain-adaptation;unsupervised-learning;uncertainty;cvpr
191,neuralrgbd,Per-pixel depth and uncertainty estimation from RGB video,"Implementation of Neural RGB->D Sensing, providing per-pixel depth and its uncertainty estimation from a monocular RGB video.",X1;X1-02,depth_estimation;uncertainty_estimation,solver,Python,https://github.com/NVlabs/neuralrgbd,,NOASSERTION,depth-estimation;video;neural-network;uncertainty
192,calisim,Toolbox for the calibration and evaluation of simulation models,"A Python toolbox designed for the calibration and evaluation of simulation models, providing methods to adjust model parameters to match observed data.",X1;X1-02,calibration;simulation_evaluation,library,Python,https://github.com/Plant-Food-Research-Open/calisim,,Apache-2.0,calibration;simulation;modeling
193,NeuralABM,Neural parameter calibration for multi-agent models,A tool that uses neural networks to estimate marginal densities on parameters and networks for the calibration of multi-agent based models (ABMs).,X1;X1-02,calibration;parameter_estimation;agent_based_modeling,solver,Jupyter Notebook,https://github.com/ThGaskin/NeuralABM,,None,abm;calibration;neural-networks
194,torchuq,Library for uncertainty quantification based on PyTorch,"A PyTorch-based library for uncertainty quantification, providing implementations of various UQ methods including calibration, conformal prediction, and Bayesian approximation.",X1;X1-02,uncertainty_quantification;calibration;conformal_prediction,library,Jupyter Notebook,https://github.com/TorchUQ/torchuq,,MIT,pytorch;uncertainty-quantification;calibration
195,pycalibrate,Library to visually analyze model calibration,"A Python library designed to visually analyze and diagnose the calibration of machine learning models, providing various plotting and metric calculation utilities.",X1;X1-02,calibration;visualization;model_evaluation,library,Jupyter Notebook,https://github.com/VIDA-NYU/pycalibrate,,MIT,calibration;visualization;machine-learning
196,vbll,Simple and cheap neural network uncertainty estimation,"A library for Variational Bayesian Last Layer (VBLL) implementation, providing a simple and computationally efficient method for uncertainty estimation in neural networks.",X1;X1-01,uncertainty_estimation;bayesian_deep_learning,library,Python,https://github.com/VectorInstitute/vbll,,MIT,uncertainty;bayesian;neural-networks
197,kyle,Library for calibrating classifiers and computing calibration metrics,"A library focused on the calibration of probabilistic classifiers, offering tools to compute calibration metrics and apply calibration methods.",X1;X1-02,calibration;metrics_calculation,library,Jupyter Notebook,https://github.com/aai-institute/kyle,,NOASSERTION,calibration;classification;metrics
198,conformal-time-series,Conformal prediction for time-series applications,"An implementation of conformal prediction methods specifically designed for time-series data, including the EnbPI (Ensemble Batch Prediction Intervals) algorithm.",X1;X1-02,time_series_forecasting;conformal_prediction;uncertainty_quantification,solver,Jupyter Notebook,https://github.com/aangelopoulos/conformal-time-series,,MIT,time-series;conformal-prediction;enbpi
199,conformal_classification,Wrapper for PyTorch classifiers to output conformal prediction sets,A wrapper tool for PyTorch classifiers that enables them to output prediction sets with theoretical guarantees of containing the true class with high probability via conformal prediction.,X1;X1-02,classification;conformal_prediction;uncertainty_quantification,solver,Jupyter Notebook,https://github.com/aangelopoulos/conformal_classification,,MIT,pytorch;conformal-prediction;classification
200,LakeEnsemblR,R package for lake thermodynamics multi-model ensembles and calibration,"An R package that facilitates multi-model ensembles for lake thermodynamics. It includes tools for calibration, sensitivity analysis, and data visualization, enabling researchers to quantify uncertainty in lake models.",X1;X1-02;Environmental Science,calibration;sensitivity_analysis;modeling,library,R,https://github.com/aemon-j/LakeEnsemblR,,GPL-2.0,lake-modeling;ensemble;calibration;r-package
201,ml-calibration,Utilities for measuring calibration and plotting reliability diagrams,A library providing utilities for measuring model calibration and plotting reliability diagrams (relplot). It helps in assessing the trustworthiness of machine learning model predictions.,X1;X1-02,calibration;visualization;reliability_assessment,library,Jupyter Notebook,https://github.com/apple/ml-calibration,,NOASSERTION,calibration;reliability-diagrams;uncertainty
202,MDN-Keras,Mixture Density Networks implementation for Keras,A generic implementation of Mixture Density Networks (MDN) for distribution and uncertainty estimation using Keras (TensorFlow). It allows for modeling complex output distributions.,X1;X1-01,uncertainty_estimation;distribution_modeling,solver,Jupyter Notebook,https://github.com/axelbrando/Mixture-Density-Networks-for-distribution-and-uncertainty-estimation,,Apache-2.0,mixture-density-networks;keras;uncertainty
203,tsai-calibration,Implementation of Tsai's camera calibration algorithm,"A Python implementation of Tsai's camera calibration model, used for estimating the parameters of a physical camera model.",X1;Computer Vision,camera_calibration;parameter_estimation,solver,Python,https://github.com/bailus/tsai-calibration,,MIT,camera-calibration;tsai-model
204,velo2cam_gazebo,Gazebo simulation toolkit for Lidar-camera calibration,"A repository containing Gazebo models, plugins, and worlds designed to test and validate calibration algorithms for Lidar-camera setups in a simulated environment.",X1;Robotics,calibration;simulation;sensor_fusion,platform,C++,https://github.com/beltransen/velo2cam_gazebo,,GPL-2.0,gazebo;lidar-camera-calibration;simulation
205,forestError,Unified Framework for Random Forest Prediction Error Estimation,"An R package that implements a unified framework for estimating the prediction error of Random Forest models, aiding in uncertainty quantification for tree-based ensembles.",X1;X1-01,error_estimation;uncertainty_quantification,library,R,https://github.com/benjilu/forestError,,None,random-forest;error-estimation;r-package
206,cnn-surrogate,Bayesian deep CNNs for surrogate modeling and UQ,"A framework for creating surrogate models using Bayesian deep convolutional encoder-decoder networks, specifically designed for uncertainty quantification in scientific modeling.",X1;X1-01;Scientific Modeling,surrogate_modeling;uncertainty_quantification,solver,Python,https://github.com/cics-nd/cnn-surrogate,,MIT,surrogate-modeling;bayesian-deep-learning;uq
207,pde-surrogate,Physics-constrained deep learning for PDE surrogate modeling,"A tool for high-dimensional surrogate modeling and uncertainty quantification using physics-constrained deep learning, enabling label-free training for PDE systems.",X1;X1-01;Physics,surrogate_modeling;pde_solving;uncertainty_quantification,solver,Python,https://github.com/cics-nd/pde-surrogate,,MIT,physics-informed;surrogate-modeling;pde
208,rans-uncertainty,Uncertainty Quantification for RANS Turbulence Modeling,A toolkit for quantifying uncertainty in data-driven Reynolds-Averaged Navier-Stokes (RANS) turbulence modeling.,X1;Fluid Dynamics,uncertainty_quantification;turbulence_modeling,solver,C++,https://github.com/cics-nd/rans-uncertainty,,MIT,cfd;rans;uncertainty-quantification
209,PyCalib,Python library for classifier calibration,"A Python library dedicated to classifier calibration, providing various methods to calibrate the probabilities of machine learning classifiers.",X1;X1-02,calibration;classification,library,Python,https://github.com/classifier-calibration/PyCalib,,BSD-3-Clause,calibration;classifier;python-library
210,matilda,Tool for modeling water resources in glacierized catchments,MATILDA (Model for Water Resources in Glacierized Catchments) combines a temperature-index melt model with the conceptual catchment model HBV to simulate hydrological processes in glacierized regions.,Hydrology;Glaciology,hydrological_modeling;water_resources_simulation;melt_modeling,solver,Python,https://github.com/cryotools/matilda,https://github.com/cryotools/matilda,MIT,hydrology;glacier;catchment-modeling
211,probmetrics,Library for classification metrics and post-hoc calibration,"probmetrics provides tools for evaluating probabilistic classification models, including various metrics and methods for post-hoc calibration.",X1;X1-02,model_evaluation;calibration;metrics,library,Python,https://github.com/dholzmueller/probmetrics,https://github.com/dholzmueller/probmetrics,Apache-2.0,calibration;metrics;classification
212,Hagelslag,Object-based severe weather forecast verification and tracking tool,"Hagelslag is an object-based verification and tracking tool for weather forecasting models. It supports segmentation, tracking of weather fields, and scalable verification including reliability diagrams.",Meteorology;X1-02,weather_tracking;forecast_verification;segmentation,solver,Jupyter Notebook,https://github.com/djgagne/hagelslag,https://github.com/djgagne/hagelslag,MIT,meteorology;weather-forecasting;verification
213,Fisheye-Calib-Adapter,Tool for Fisheye Camera Model Conversion,"A tool designed to convert between different fisheye camera models, facilitating calibration and integration in computer vision pipelines.",Computer Vision;Robotics,camera_calibration;model_conversion;fisheye_projection,solver,C++,https://github.com/eowjd0512/fisheye-calib-adapter,https://github.com/eowjd0512/fisheye-calib-adapter,MIT,camera-calibration;fisheye;computer-vision
214,MapAnything,Universal Feed-Forward Metric 3D Reconstruction Tool,"MapAnything is a system for metric 3D reconstruction from images, capable of estimating depth and geometry in a feed-forward manner.",Computer Vision;Geospatial,3d_reconstruction;depth_estimation;mapping,solver,Python,https://github.com/facebookresearch/map-anything,https://github.com/facebookresearch/map-anything,Apache-2.0,3d-reconstruction;computer-vision;mapping
215,Selective,Feature Selection Library,"Selective is a library dedicated to feature selection in machine learning pipelines, helping to identify relevant variables for modeling.",Data Science;X1,feature_selection;dimensionality_reduction;data_analysis,library,Python,https://github.com/fidelity/selective,https://github.com/fidelity/selective,Apache-2.0,feature-selection;machine-learning;data-science
216,bayesian-yolov3,YOLOv3 object detection with uncertainty estimation,"An implementation of the YOLOv3 object detection architecture augmented with uncertainty estimation capabilities, allowing for probabilistic object detection.",Computer Vision;X1-02,object_detection;uncertainty_estimation;bayesian_deep_learning,solver,Python,https://github.com/flkraus/bayesian-yolov3,https://github.com/flkraus/bayesian-yolov3,MIT,yolo;uncertainty;object-detection
217,rsofun,Simulating Optimal FUNctioning framework for ecosystem processes,"rsofun implements the Simulating Optimal FUNctioning framework for site-scale simulations of ecosystem processes, including modules for P-model, SPLASH, and BiomeE.",Ecology;Environmental Science,ecosystem_simulation;biogeochemical_modeling;plant_physiology,solver,Fortran,https://github.com/geco-bern/rsofun,https://github.com/geco-bern/rsofun,GPL-3.0,ecosystem-modeling;fortran;ecology
218,temperature_scaling,Simple calibration tool for neural networks,"A PyTorch implementation of temperature scaling, a simple and effective method for calibrating the probabilities of neural networks.",X1;X1-02,model_calibration;temperature_scaling;probability_calibration,library,Python,https://github.com/gpleiss/temperature_scaling,https://github.com/gpleiss/temperature_scaling,MIT,calibration;pytorch;neural-networks
219,conformal,R package for conformal prediction,"An R package that implements conformal prediction methods, allowing for the calculation of prediction intervals with valid coverage guarantees for regression and classification problems.",X1;X1-02,conformal_prediction;prediction_intervals,library,R,https://github.com/isidroc/conformal,,None,r;conformal-prediction;statistics
220,extreme-deconvolution,Density estimation using Gaussian mixtures with noisy data,"A technique and software for density estimation using Gaussian mixtures in the presence of noisy, heterogeneous, and incomplete data. Widely used in astronomy and physics for inferring underlying distributions from uncertain measurements.",X1;X1-02;Astronomy,density_estimation;deconvolution;uncertainty_handling,library,Python,https://github.com/jobovy/extreme-deconvolution,,NOASSERTION,density-estimation;gaussian-mixture;astronomy;statistics
221,Chaospy,Toolbox for performing uncertainty quantification,Chaospy is a numerical toolbox for performing uncertainty quantification using polynomial chaos expansions and Monte Carlo methods. It provides tools for creating surrogate models and analyzing the propagation of uncertainty in physical models.,X1;X1-02,uncertainty_quantification;polynomial_chaos;sensitivity_analysis,library,Python,https://github.com/jonathf/chaospy,https://chaospy.readthedocs.io,MIT,uncertainty-quantification;polynomial-chaos;monte-carlo;surrogate-modeling
222,icp,Implementation of Invariant Causal Prediction (ICP),A Python implementation of the Invariant Causal Prediction (ICP) algorithm. ICP is a method for causal inference that exploits invariance across different environments to identify causal predictors and construct confidence intervals.,X1;Causal Inference,causal_inference;invariant_prediction;confidence_intervals,library,Python,https://github.com/juangamella/icp,,BSD-3-Clause,causal-inference;icp;statistics
223,diploSHIC,Feature-based deep learning tool for identifying selective sweeps in genomic data,"A deep learning tool that uses feature vectors calculated from genomic data to classify genomic regions into neutral, hard sweep, or soft sweep categories, aiding in the study of evolutionary biology.",X1;X1-02,scientific_inference;genomic_analysis,solver,Python,https://github.com/kr-colab/diploSHIC,,MIT,genomics;deep-learning;selective-sweeps;evolutionary-biology
224,shIC,Tool for detecting hard and soft selective sweeps in population genomics,The Soft/Hard Inference through Classification (shIC) tool is designed to detect and classify selective sweeps (hard vs soft) in population genomic data using supervised machine learning.,X1;X1-02,scientific_inference;genomic_analysis,solver,C,https://github.com/kr-colab/shIC,,None,genomics;population-genetics;selective-sweeps;classification
225,LandsatTS,R package for processing and phenological modeling of Landsat time-series data,"An R package designed to facilitate the retrieval, cleaning, cross-calibration, and phenological modeling of Landsat time-series data for earth science and ecological research.",X1;X1-02,data_processing;scientific_modeling;calibration,library,R,https://github.com/logan-berner/LandsatTS,,NOASSERTION,remote-sensing;landsat;time-series;phenology;r-package
226,model-diagnostics,Python tools for diagnostics and calibration assessment of machine learning models,"A library providing tools for the diagnostics and assessment of machine learning models, with a focus on calibration, reliability diagrams, and other performance metrics.",X1;X1-02,model_evaluation;calibration,library,Python,https://github.com/lorentzenchr/model-diagnostics,https://model-diagnostics.readthedocs.io,MIT,machine-learning;calibration;diagnostics;model-evaluation
227,Mads.jl,"Julia framework for model analysis, decision support, and uncertainty quantification","MADS (Model Analysis & Decision Support) is a Julia framework that provides high-level tools for model calibration, sensitivity analysis, uncertainty quantification, and decision support in scientific modeling.",X1;X1-02,scientific_modeling;uncertainty_quantification;calibration,library,Julia,https://github.com/madsjulia/Mads.jl,https://madsjulia.github.io/Mads.jl,GPL-3.0,julia;model-analysis;uncertainty-quantification;decision-support
228,workboots,R package for generating bootstrap prediction intervals in tidymodels workflows,"An R package that integrates with the tidymodels ecosystem to generate bootstrap prediction intervals, aiding in uncertainty quantification for predictive models.",X1;X1-02,uncertainty_quantification;statistical_analysis,library,R,https://github.com/markjrieke/workboots,https://markjrieke.github.io/workboots/,NOASSERTION,r;tidymodels;prediction-intervals;bootstrap;uncertainty
229,kuenm,R package for calibration and construction of Maxent Ecological Niche Models,"An R package designed to streamline the process of calibrating, creating, and evaluating Maxent ecological niche models, ensuring robust and reproducible ecological modeling.",X1;X1-02,scientific_modeling;calibration;ecological_modeling,library,R,https://github.com/marlonecobos/kuenm,,None,ecological-niche-modeling;maxent;calibration;r-package
230,NSGA-II_Python_for_SWAT_model,Python tool for multi-objective calibration of SWAT hydrological models,A Python-based tool implementing the NSGA-II algorithm for multi-site and multi-objective calibration of the Soil and Water Assessment Tool (SWAT) model.,X1;X1-02,scientific_modeling;calibration;hydrology,solver,Python,https://github.com/mehmetbercan/NSGA-II_Python_for_SWAT_model,,None,swat-model;calibration;hydrology;nsga-ii;optimization
231,uncertainty_modeller,Machine learning library for uncertainty estimation of black-box classification systems,"A library designed to estimate uncertainty in black-box classification models, providing tools to assess confidence and reliability of predictions.",X1;X1-02,uncertainty_quantification;model_evaluation,library,Python,https://github.com/menajosep/uncertainty_modeller,,NOASSERTION,uncertainty-estimation;machine-learning;classification;black-box
232,Prognostic Algorithm Package,Framework for model-based prognostics and uncertainty propagation,"A Python framework for model-based prognostics of engineering systems, providing algorithms for state estimation, prediction, and uncertainty propagation.",Engineering;Systems Engineering,prognostics;uncertainty_propagation;state_estimation,library,Python,https://github.com/nasa/prog_algs,,None,prognostics;nasa;uncertainty-propagation
233,Kinematic-Calibration,Automatic kinematic calibration for serial manipulators,"An algorithm to determine the kinematic model of any serial manipulator, including methods based on circle fitting and dual vector geometry for Denavit-Hartenberg parameter determination.",Robotics;Engineering,kinematic_calibration;robot_modeling,solver,MATLAB,https://github.com/neuebot/Kinematic-Calibration,,GPL-3.0,robotics;calibration;kinematics
234,ProbDiffEq,Probabilistic solvers for differential equations in JAX,"A library providing probabilistic numerical solvers for differential equations using JAX, featuring adaptive ODE solvers with calibration and state-space model factorisations.",Scientific Computing;Mathematics,differential_equations;uncertainty_quantification;numerical_solver,library,Python,https://github.com/pnkraemer/probdiffeq,,MIT,jax;ode-solver;probabilistic-numerics
235,camera_calibration,Geometric camera calibration with generic models,"A library for accurate geometric camera calibration supporting generic camera models, suitable for computer vision and robotics applications.",Computer Vision;Robotics,camera_calibration;geometric_modeling,library,C++,https://github.com/puzzlepaint/camera_calibration,,BSD-3-Clause,camera-calibration;computer-vision;optimization
236,WaveBlocks,Optimization framework for optics and deep learning,A PyTorch-based optimization framework that allows for the calibration and joint optimization of optical systems and deep learning models.,Optics;Computer Science,calibration;optimization;optical_modeling,workflow,Jupyter Notebook,https://github.com/pvjosue/WaveBlocks,,None,optics;deep-learning;calibration
237,ros-perception/calibration,Sensor and robot model calibration toolchain for ROS,"A toolchain within the ROS ecosystem for calibrating sensors and URDF robot models, essential for accurate robotic perception and manipulation.",Robotics,sensor_calibration;robot_calibration,solver,Python,https://github.com/ros-perception/calibration,,None,ros;calibration;robotics
238,SUO-SLAM,Symmetry and Uncertainty-Aware Object SLAM,A SLAM system for 6DoF object pose estimation that explicitly handles object symmetry and incorporates uncertainty quantification.,Robotics;Computer Vision,slam;pose_estimation;uncertainty_quantification,solver,Python,https://github.com/rpng/suo_slam,,MIT,slam;uncertainty-aware;pose-estimation
239,Distribution System Model Calibration,Algorithms for calibrating power grid distribution models,"A set of algorithms developed by Sandia National Laboratories for calibrating models of power grid distribution systems, ensuring simulation accuracy.",Energy;Power Systems,model_calibration;power_grid_simulation,solver,Python,https://github.com/sandialabs/distribution-system-model-calibration,,BSD-3-Clause,power-systems;calibration;grid-modeling
240,pytuq,Python Toolkit for Uncertainty Quantification from Sandia National Laboratories,"A Python library designed to perform uncertainty quantification (UQ) tasks, likely supporting sampling, sensitivity analysis, and statistical inference for computational models, developed by Sandia National Laboratories.",X1;X1-02,uncertainty_quantification;sensitivity_analysis,library,Python,https://github.com/sandialabs/pytuq,,NOASSERTION,uncertainty-quantification;sandia-labs;statistics
241,nestedcv,Nested cross-validation for accurate confidence intervals of prediction error,"An R package that implements nested cross-validation methods to provide more accurate confidence intervals for prediction errors in machine learning models, addressing bias in standard CV estimates.",X1;X1-02,cross_validation;confidence_intervals;error_estimation,library,R,https://github.com/stephenbates19/nestedcv,,MIT,cross-validation;confidence-intervals;statistics
242,TISSUE,Transcript Imputation with Spatial Single-cell Uncertainty Estimation,A toolkit for estimating well-calibrated uncertainty measures for gene expression predictions in single-cell spatial transcriptomics datasets. It enables uncertainty-aware downstream analyses.,X1;X1-02,spatial_transcriptomics;uncertainty_estimation;imputation,library,Python,https://github.com/sunericd/TISSUE,https://tissue.readthedocs.io/,MIT,single-cell;spatial-transcriptomics;uncertainty
243,linguistic_calibration,Methods for aligning Language Models to express calibrated confidence,"A library/framework for aligning Large Language Models (LLMs) to produce calibrated verbal statements of confidence in their long-form generations, improving the reliability of model outputs.",X1;X1-02,model_alignment;calibration;llm_reliability,solver,Python,https://github.com/tatsu-lab/linguistic_calibration,,Apache-2.0,llm;calibration;alignment
244,LTS,Local Temperature Scaling for Probability Calibration,"An implementation of Local Temperature Scaling (LTS), a method for probability calibration of deep learning models, developed by the Biomedical Image Analysis Group at UNC.",X1;X1-02,probability_calibration;model_calibration,solver,Python,https://github.com/uncbiag/LTS,,Apache-2.0,calibration;deep-learning;temperature-scaling
245,uncertainty-toolbox,"Toolbox for predictive uncertainty quantification, calibration, and metrics","A comprehensive Python toolbox for predictive uncertainty quantification. It provides tools for calibration, metrics calculation, and visualization of uncertainty estimates for regression and classification models.",X1;X1-02,uncertainty_quantification;calibration;metrics;visualization,library,Python,https://github.com/uncertainty-toolbox/uncertainty-toolbox,https://uncertainty-toolbox.github.io/,MIT,uncertainty-quantification;calibration;visualization
246,pestpp,Scalable parameter estimation and uncertainty analysis tools from USGS,"A software suite for parameter estimation, uncertainty analysis, and sensitivity analysis, designed to be independent of the model being analyzed. Widely used in environmental and groundwater modeling.",X1;X1-02,parameter_estimation;uncertainty_analysis;sensitivity_analysis,solver,C++,https://github.com/usgs/pestpp,https://pestpp.web.app/,NOASSERTION,parameter-estimation;uncertainty-analysis;environmental-modeling
247,deep_uncertainty_estimation,General framework for uncertainty estimation in deep learning,"A framework and codebase implementing methods for estimating total uncertainty (aleatoric and epistemic) in deep learning models, particularly for robotics and perception tasks.",X1;X1-02,uncertainty_estimation;deep_learning;robotics,library,Python,https://github.com/uzh-rpg/deep_uncertainty_estimation,,MIT,deep-learning;uncertainty;robotics
248,pearsonify,Python package for classification intervals using conformal prediction,A lightweight Python package designed to generate classification intervals for binary classification tasks. It utilizes Pearson residuals and conformal prediction techniques to provide calibrated uncertainty estimates.,X1;X1-02,conformal_prediction;uncertainty_quantification,library,Python,https://github.com/xRiskLab/pearsonify,,MIT,conformal-prediction;classification;uncertainty
249,LibQPEP,Library for generalized quadratic pose estimation and uncertainty,"A C++/MATLAB library dedicated to solving generalized quadratic pose estimation problems. It includes functionality for describing related uncertainties, suitable for robotics and computer vision research.",X1;X1-02,pose_estimation;uncertainty_quantification,library,MATLAB,https://github.com/zarathustr/LibQPEP,,None,pose-estimation;robotics;uncertainty
250,classifier-calibration,Utilities for classifier calibration and reliability diagrams,"A Python toolkit providing implementations for reliability diagrams, Platt's scaling, and isotonic regression, designed to evaluate and improve the calibration of probability predictions from classifiers.",X1;X1-02,calibration;visualization,library,Python,https://github.com/zygmuntz/classifier-calibration,,MIT,calibration;reliability-diagram;isotonic-regression
251,VeriGauge,A united toolbox for running major robustness verification approaches for Deep Neural Networks,"VeriGauge is a comprehensive toolbox designed for the robustness verification of Deep Neural Networks (DNNs). It integrates various state-of-the-art verification methods, allowing researchers to evaluate and compare the robustness of DNNs against adversarial perturbations and other uncertainties.",X1;X1-03,robustness_verification;model_evaluation,library,C,https://github.com/AI-secure/VeriGauge,,None,robustness;verification;dnn;security
252,Advertorch,A toolbox for adversarial robustness research in PyTorch,"Advertorch is a Python toolbox for adversarial robustness research, specifically designed for PyTorch. It provides implementations of various adversarial attacks, defenses, and robust training methods, enabling researchers to evaluate and improve the resilience of machine learning models.",X1;X1-03,adversarial_attack;robustness_evaluation;defense_mechanism,library,Jupyter Notebook,https://github.com/BorealisAI/advertorch,,LGPL-3.0,adversarial-attacks;pytorch;robustness;security
253,Robust Statistical Toolbox,MATLAB toolbox for robust statistical analyses,"The Robust Statistical Toolbox is a collection of MATLAB functions designed to perform robust statistical analyses. It includes methods for robust correlation, regression, and other statistical tests that are resistant to outliers and violations of parametric assumptions, suitable for scientific data analysis.",X1;X1-03,statistical_analysis;robust_estimation,library,MATLAB,https://github.com/CPernet/Robust_Statistical_Toolbox,,GPL-2.0,statistics;robustness;matlab;data-analysis
254,DeepRobust,A PyTorch adversarial library for attack and defense methods on images and graphs,"DeepRobust is a comprehensive PyTorch library for adversarial attacks and defenses, covering both image and graph data. It provides a unified platform for researchers to simulate attacks, evaluate model robustness, and develop defense mechanisms against adversarial examples.",X1;X1-03,adversarial_attack;graph_robustness;image_robustness,library,Python,https://github.com/DSE-MSU/DeepRobust,https://deeprobust.readthedocs.io/,MIT,adversarial-learning;graph-neural-networks;pytorch;robustness
255,DataShifts,Library for quantifying and analyzing distribution shifts in data,"A Python library designed to quantify and analyze distribution shifts (covariate shift, prior probability shift, and concept shift) in machine learning datasets, helping to diagnose model performance degradation.",X1-03;Machine Learning,drift_detection;data_analysis,library,Python,https://github.com/DataShifts/datashifts,,MIT,distribution-shift;concept-drift;machine-learning
256,Evidently,Simulation library for Evidence Accumulation Models in cognitive science,"A Python library for simulating Evidence Accumulation Models (EAMs), which are used in cognitive science and psychology to model decision-making processes and reaction times.",Cognitive Science;Psychology,simulation;modeling,library,Python,https://github.com/EoinTravers/Evidently,,GPL-3.0,cognitive-modeling;decision-making;simulation
257,Adaptive Alerting,Anomaly detection system for streaming time series,"A library for performing anomaly detection on streaming time series data, featuring automated model selection to adapt to changing data patterns, suitable for monitoring scientific or industrial sensor data.",X1-03;Time Series Analysis,anomaly_detection;monitoring,library,Java,https://github.com/ExpediaGroup/adaptive-alerting,,Apache-2.0,anomaly-detection;streaming-data;time-series
258,PeakPickingTools,MATLAB toolbox for modal parameter extraction,"A MATLAB toolbox designed to extract modal parameters from frequency response functions using a robust peak-picking identification technique, applicable in structural dynamics and signal processing.",Signal Processing;Structural Dynamics,data_analysis;parameter_extraction,library,MATLAB,https://github.com/FredericAblitzer/PeakPickingTools,,None,modal-analysis;peak-picking;frequency-response
259,PolaronMobility.jl,Feynman's variational path-integral model for Frhlich polarons,A Julia package that implements Feynman's variational path-integral model to calculate temperature-dependent polaron mobilities and other observables in materials science physics.,Physics;Materials Science,scientific_modeling;simulation,library,Jupyter Notebook,https://github.com/Frost-group/PolaronMobility.jl,,MIT,polaron;path-integral;condensed-matter
260,Robustar,Interactive toolbox for robust vision classification,"An interactive toolbox designed to improve the robustness of vision classification models through data augmentation and adversarial training, facilitating the creation of robust AI models.",X1-03;Computer Vision,robustness_evaluation;model_training,solver,HTML,https://github.com/HaohanWang/Robustar,,MIT,adversarial-robustness;computer-vision;interactive-tool
261,URET,Universal Robustness Evaluation Toolkit for NLP,"A toolkit developed by IBM for evaluating the robustness of Natural Language Processing (NLP) models against evasion attacks, supporting various attack methods and metrics.",X1-03;NLP,robustness_evaluation;adversarial_attack,solver,Jupyter Notebook,https://github.com/IBM/URET,,MIT,nlp;robustness;adversarial-evaluation
262,HEART Library,Hardened Extension of the Adversarial Robustness Toolbox,"An extension of the Adversarial Robustness Toolbox (ART) designed to support the assessment of adversarial AI vulnerabilities in Test & Evaluation workflows, providing hardened implementations for practical deployment.",X1-03;AI Security,robustness_evaluation;security_assessment,library,Jupyter Notebook,https://github.com/IBM/heart-library,,MIT,adversarial-robustness;ai-security;testing
263,Frouros,Library for drift detection in machine learning systems,"An open-source Python library dedicated to drift detection in machine learning systems, providing implementations of various concept drift and data drift detection algorithms.",X1-03;Machine Learning,drift_detection;monitoring,library,Python,https://github.com/IFCA-Advanced-Computing/frouros,https://frouros.readthedocs.io/,BSD-3-Clause,concept-drift;data-drift;ml-monitoring
264,fd-shifts,Benchmark and toolkit for failure detection under distribution shifts,"A benchmark and toolkit for evaluating failure detection methods under distribution shifts in image classification, specifically focused on biomedical imaging applications.",X1-03;Medical Imaging,robustness_evaluation;failure_detection,solver,Python,https://github.com/IML-DKFZ/fd-shifts,,Apache-2.0,medical-imaging;distribution-shift;uncertainty-quantification
265,2DMatGMM,Platform for detection and classification of 2D material flakes,An open-source robust machine learning platform designed for the real-time detection and classification of 2D material flakes from optical microscopy images.,Materials Science;Microscopy,image_analysis;classification,platform,Python,https://github.com/Jaluus/2DMatGMM,,MIT,2d-materials;microscopy;automated-detection
266,OpenOOD,Comprehensive benchmarking codebase for generalized Out-of-Distribution (OOD) detection,"OpenOOD provides a unified and standardized benchmark for Generalized Out-of-Distribution (OOD) detection, covering various OOD detection methods, datasets, and evaluation metrics to facilitate fair comparison and research.",X1;X1-03,ood_detection;benchmarking;model_evaluation,library,Python,https://github.com/Jingkang50/OpenOOD,,MIT,ood-detection;benchmark;computer-vision;pytorch
267,CellDrift,Tool for inferring temporal perturbation effects in single-cell data,"CellDrift is a Python tool designed to evaluate the effects of temporal perturbations on single-cell data, helping to identify and analyze drift or changes in cell states over time.",X1-03;Bioinformatics,perturbation_analysis;single_cell_analysis;drift_detection,library,Python,https://github.com/KANG-BIOINFO/CellDrift,,MIT,single-cell;bioinformatics;temporal-analysis;perturbation
268,robust-elm-irls,Robust Regularized Extreme Learning Machine for regression,A MATLAB implementation of Robust Regularized Extreme Learning Machine (ELM) using Iteratively Reweighted Least Squares (IRLS) to provide robust regression capabilities in the presence of outliers.,X1-03,regression;robust_learning;extreme_learning_machine,solver,MATLAB,https://github.com/KaenChan/robust-elm-irls,,None,elm;regression;robust-statistics;matlab
269,Decorrelated-Weighted-Regression,Stable prediction algorithm for model misspecification and distribution shift,A Python implementation of Decorrelated Weighted Regression (DWR) designed to achieve stable predictions and handle agnostic distribution shifts and model misspecification.,X1-03,stable_prediction;distribution_shift;causal_inference,solver,Python,https://github.com/KunKuang/Decorrelated-Weighted-Regression,,None,distribution-shift;regression;stable-learning
270,kramersmoyal,Library for calculating Kramers-Moyal coefficients from stochastic data,"A Python library to compute Kramers-Moyal coefficients for stochastic data of any dimension and to any desired order, useful for analyzing stochastic processes and drift-diffusion dynamics.",X1;Physics,stochastic_analysis;time_series_analysis;coefficient_estimation,library,Python,https://github.com/LRydin/KramersMoyal,,MIT,stochastic-processes;kramers-moyal;physics;data-analysis
271,SDDObench,Benchmark for Streaming Data-Driven Optimization with Concept Drift,"SDDObench is a benchmark suite designed for evaluating algorithms in the context of Streaming Data-Driven Optimization (SDDO), specifically focusing on scenarios involving concept drift.",X1-03,benchmarking;optimization;concept_drift,library,Python,https://github.com/LabGong/SDDObench,,BSD-3-Clause,benchmark;optimization;concept-drift;streaming-data
272,Eurybia,Library for monitoring model drift and data validation,Eurybia is a Python library designed to monitor machine learning model drift over time and ensure model deployment security through data validation and consistency checks.,X1-03,drift_monitoring;data_validation;model_security,library,Jupyter Notebook,https://github.com/MAIF/eurybia,https://eurybia.readthedocs.io/,Apache-2.0,drift-detection;mlops;data-validation;monitoring
273,CIFAR-10 Challenge,Framework for evaluating adversarial robustness on CIFAR-10,A challenge framework and codebase provided by MadryLab to explore and benchmark the adversarial robustness of neural networks specifically on the CIFAR-10 dataset.,X1-03,adversarial_robustness;benchmarking;model_evaluation,library,Python,https://github.com/MadryLab/cifar10_challenge,,MIT,adversarial-attacks;robustness;cifar10;benchmark
274,MNIST Challenge,Framework for evaluating adversarial robustness on MNIST,A challenge framework and codebase provided by MadryLab to explore and benchmark the adversarial robustness of neural networks specifically on the MNIST dataset.,X1-03,adversarial_robustness;benchmarking;model_evaluation,library,Python,https://github.com/MadryLab/mnist_challenge,,MIT,adversarial-attacks;robustness;mnist;benchmark
275,robustness,Library for training and evaluating neural networks with adversarial robustness,"A PyTorch library developed by MadryLab for experimenting with, training, and evaluating neural networks, with a primary focus on adversarial robustness and robust optimization.",X1-03,adversarial_training;robustness_evaluation;model_training,library,Jupyter Notebook,https://github.com/MadryLab/robustness,https://robustness.readthedocs.io/,MIT,pytorch;adversarial-robustness;deep-learning;library
276,T2N,Interface between MATLAB and NEURON for robust electrophysiological modeling,"T2N is a toolbox that provides an interface between MATLAB and the NEURON simulation environment, facilitating robust electrophysiological modeling and compartmental modeling of neurons.",X1;Neuroscience,electrophysiological_modeling;simulation;interface,library,MATLAB,https://github.com/MarcelBeining/T2N,http://www.treestoolbox.org/T2N/index.html,MIT,neuroscience;matlab;neuron;modeling
277,drifter,R library for concept drift and shift detection in predictive models,"Drifter is an R package designed to identify and visualize concept drift and concept shift in predictive models, helping to maintain model performance over time.",X1-03,concept_drift_detection;model_monitoring;statistical_analysis,library,R,https://github.com/ModelOriented/drifter,,None,r;concept-drift;model-monitoring;data-science
278,NannyML,Post-deployment data science library for drift detection and performance estimation,NannyML is a Python library for post-deployment monitoring of machine learning models. It estimates model performance without ground truth and detects data drift to ensure reliability in production.,X1-03,performance_estimation;drift_detection;model_monitoring,library,Python,https://github.com/NannyML/nannyml,https://nannyml.readthedocs.io/,Apache-2.0,mlops;drift-detection;performance-estimation;monitoring
279,CanarySEFI,Framework for evaluating robustness of image recognition models,"CanarySEFI is a comprehensive framework for evaluating the robustness of deep learning-based image recognition models, incorporating various attack and defense algorithms and evaluation metrics.",X1-03,robustness_evaluation;adversarial_attack;model_defense,library,Python,https://github.com/NeoSunJZ/Canary_Master,,Apache-2.0,robustness;security;deep-learning;evaluation-framework
280,OODRobustBench,Benchmark for adversarial robustness under distribution shift,OODRobustBench is a benchmark suite designed to analyze and evaluate the adversarial robustness of machine learning models specifically under conditions of distribution shift.,X1-03,benchmarking;adversarial_robustness;distribution_shift,library,Python,https://github.com/OODRobustBench/OODRobustBench,,MIT,benchmark;robustness;ood;adversarial-ml
281,PkBoost,Adaptive GBDT implementation in Rust for concept drift,PkBoost is a Gradient Boosting Decision Tree (GBDT) library built in Rust that features adaptive mechanisms to handle concept drift and changing data distributions efficiently.,X1-03,gradient_boosting;concept_drift;adaptive_learning,library,Rust,https://github.com/Pushp-Kharat1/PkBoost,,None,rust;gbdt;concept-drift;machine-learning
282,RobustBench,Standardized adversarial robustness benchmark,"RobustBench is a standardized benchmark and library for evaluating the adversarial robustness of image classification models, providing a leaderboard and easy access to robust models.",X1-03,benchmarking;adversarial_robustness;model_evaluation,library,Python,https://github.com/RobustBench/robustbench,https://robustbench.github.io/,NOASSERTION,benchmark;robustness;adversarial-ml;computer-vision
283,RobustSP Toolbox,MATLAB toolbox for robust signal processing,"The RobustSP toolbox provides a collection of robust statistical methods and algorithms for signal processing, accompanying the book 'Robust Statistics for Signal Processing'.",X1-03;Signal Processing,signal_processing;robust_statistics;data_analysis,library,MATLAB,https://github.com/RobustSP/toolbox,,None,signal-processing;robust-statistics;matlab;toolbox
284,OnlineTSF,Proactive model adaptation framework against concept drift for online time series forecasting,A framework designed to handle concept drift in online time series forecasting by proactively adapting models. It implements the method from KDD'25 to maintain forecasting accuracy in dynamic environments.,X1;X1-03,drift_adaptation;time_series_forecasting,solver,Python,https://github.com/SJTU-DMTai/OnlineTSF,,None,concept-drift;time-series;online-learning
285,alibi-detect,"Algorithms for outlier, adversarial, and drift detection","An open-source Python library focused on outlier detection, adversarial detection, and drift detection. It provides a suite of algorithms to monitor machine learning models and data distributions for deviations and anomalies.",X1;X1-03,drift_detection;outlier_detection;adversarial_detection,library,Python,https://github.com/SeldonIO/alibi-detect,https://docs.seldon.io/projects/alibi-detect/en/latest/,Apache-2.0,drift-detection;outlier-detection;adversarial-robustness;monitoring
286,GEO-Bench,Benchmark for Foundation Models in Earth Monitoring,A benchmark suite designed to evaluate foundation models for Earth monitoring tasks. It facilitates the assessment of model performance across various geospatial data analysis scenarios.,X1;X1-03;Earth Science,benchmarking;model_evaluation,dataset,Python,https://github.com/ServiceNow/geo-bench,,Apache-2.0,earth-monitoring;foundation-models;benchmark;geospatial
287,Face-Robustness-Benchmark,Adversarial robustness evaluation library for face recognition,A library and benchmark for evaluating the adversarial robustness of face recognition models. It provides tools to test models against various adversarial attacks to ensure reliability.,X1;X1-03;Computer Vision,robustness_evaluation;adversarial_attack,library,Python,https://github.com/ShawnXYang/Face-Robustness-Benchmark,,Apache-2.0,face-recognition;adversarial-robustness;benchmark
288,odin-pytorch,Out-of-Distribution detection method for neural networks,"Implementation of the ODIN (Out-of-DIstribution detector for Neural networks) method, which improves the detection of out-of-distribution examples in pre-trained neural networks.",X1;X1-03,ood_detection;model_reliability,solver,Python,https://github.com/ShiyuLiang/odin-pytorch,,None,ood-detection;pytorch;neural-networks
289,GRB,Graph Robustness Benchmark for Graph Machine Learning,"A scalable, unified, modular, and reproducible benchmark for evaluating the adversarial robustness of Graph Machine Learning models. It aids in understanding model vulnerabilities under adversarial attacks on graph data.",X1;X1-03;Graph Learning,robustness_benchmarking;adversarial_defense,library,Python,https://github.com/THUDM/grb,https://grb.readthedocs.io/,MIT,graph-neural-networks;robustness;benchmark;adversarial-attack
290,parallel-ADWIN,Scalable detection of concept drifts with Parallel Adaptive Windowing,"An implementation of the Parallel Adaptive Windowing (ADWIN) algorithm for scalable detection of concept drifts in data streams, enabling efficient monitoring of changing data distributions.",X1;X1-03,drift_detection;stream_mining,solver,Java,https://github.com/TU-Berlin-DIMA/parallel-ADWIN,,None,concept-drift;adwin;data-streams;parallel-computing
291,DIW,Deep Importance Weighting for distribution shift,"Implementation of 'Rethinking Importance Weighting for Deep Learning under Distribution Shift', providing methods to handle distribution shifts in deep learning models via importance weighting.",X1;X1-03,distribution_shift_adaptation;importance_weighting,solver,Python,https://github.com/TongtongFANG/DIW,,MIT,distribution-shift;deep-learning;importance-weighting
292,TorchDrift,Drift detection library for PyTorch models,"A library dedicated to drift detection for PyTorch models, offering various statistical tests and methods to monitor data distribution changes and model performance degradation.",X1;X1-03,drift_detection;model_monitoring,library,Python,https://github.com/TorchDrift/TorchDrift,https://torchdrift.org/,None,pytorch;drift-detection;ml-monitoring
293,MagNet,Defense framework against adversarial examples,"Implementation of MagNet, a two-pronged defense mechanism against adversarial examples in neural networks, focusing on detecting and reforming adversarial inputs.",X1;X1-03,adversarial_defense;robustness,solver,Python,https://github.com/Trevillie/MagNet,,BSD-2-Clause,adversarial-defense;neural-networks;security
294,Adversarial Robustness Toolbox (ART),Python library for Machine Learning Security and Robustness,"A comprehensive library for machine learning security, providing tools for evasion, poisoning, extraction, and inference attacks and defenses. It enables robust evaluation and hardening of ML models.",X1;X1-03,adversarial_robustness;model_security;attack_simulation,library,Python,https://github.com/Trusted-AI/adversarial-robustness-toolbox,https://adversarial-robustness-toolbox.readthedocs.io/,MIT,adversarial-ml;robustness;security;red-teaming
295,UB-GOLD,Benchmark for Unsupervised Graph-Level OOD and Anomaly Detection,"A benchmark unifying unsupervised graph-level out-of-distribution (OOD) detection and anomaly detection, facilitating the evaluation of methods on graph data.",X1;X1-03;Graph Learning,ood_detection;anomaly_detection;benchmarking,dataset,Python,https://github.com/UB-GOLD/UB-GOLD,,MIT,graph-learning;ood-detection;anomaly-detection
296,DoM_Utrecht,ImageJ plugin for molecule detection and drift correction,"An ImageJ plugin for Detection of Molecules (DoM), offering features for SMLM 2D/3D localizations, drift correction, and chromatic aberration correction in microscopy data.",X1;X1-03;Microscopy,drift_correction;image_analysis;localization,solver,Java,https://github.com/UU-cellbiology/DoM_Utrecht,,GPL-3.0,imagej;microscopy;drift-correction;smlm
297,Adv-SS-Pretraining,Adversarial Robustness via Self-Supervised Pre-Training,"Code implementation for improving adversarial robustness through self-supervised pre-training followed by fine-tuning, as presented in CVPR 2020.",X1;X1-03,robust_training;adversarial_defense,solver,Python,https://github.com/VITA-Group/Adv-SS-Pretraining,,None,self-supervised-learning;adversarial-robustness;pre-training
298,Adversarial-Contrastive-Learning,Robust Pre-Training by Adversarial Contrastive Learning,"Implementation of Adversarial Contrastive Learning (ACL) for robust pre-training of deep learning models, enhancing their resistance to adversarial attacks.",X1;X1-03,robust_training;contrastive_learning,solver,Python,https://github.com/VITA-Group/Adversarial-Contrastive-Learning,,None,contrastive-learning;adversarial-training;robustness
299,AugMax,Adversarial Composition of Random Augmentations for Robust Training,A framework for robust training that uses adversarial composition of random augmentations (AugMax) to improve model robustness and generalization.,X1;X1-03,robust_training;data_augmentation,solver,Python,https://github.com/VITA-Group/AugMax,,MIT,augmentation;robustness;adversarial-training
300,Ordinal-patterns-based-analysis,Toolbox for ordinal patterns based entropy analysis,"A MATLAB toolbox for ordinal-patterns-based analysis, including permutation entropy, robust permutation entropy, and conditional entropy, useful for time series analysis.",X1;X1-03;Signal Processing,entropy_analysis;time_series_analysis,library,MATLAB,https://github.com/ValentinaUn/Ordinal-patterns-based-analysis,,BSD-2-Clause,permutation-entropy;time-series;matlab
301,cyclops,Toolkit for evaluating and monitoring clinical AI models,"A toolkit designed for the healthcare domain to evaluate and monitor AI models, specifically addressing drift and robustness in clinical settings.",X1;X1-03;Healthcare,model_monitoring;clinical_evaluation;drift_detection,library,Python,https://github.com/VectorInstitute/cyclops,https://vectorinstitute.github.io/cyclops/,NOASSERTION,clinical-ai;monitoring;healthcare;drift
302,anomaly_detection_bootstrapping,Bootstrapped statistical workflow for anomaly detection,"A software system applying bootstrapped statistical workflows to identify and quantify data abnormalities, such as measurement errors and out-of-distribution samples in large datasets.",X1;X1-03,anomaly_detection;data_quality_control,solver,Python,https://github.com/Vlad1808/anomaly_detection_bootstrapping,,MIT,anomaly-detection;bootstrapping;statistics
303,Defect-GLM,Large Visual-Language Model for Industrial Defect Monitoring,"A large visual-language model specifically designed for monitoring and detecting defects in industrial settings, serving as a specialized tool for robust visual inspection.",X1;X1-03;Industrial AI,defect_detection;visual_inspection,solver,Python,https://github.com/WH-HuanWang/Defect-GLM,,None,defect-detection;vlm;industrial-monitoring
304,MOA,Framework for Big Data stream mining and concept drift detection,"Massive Online Analysis (MOA) is a framework for data stream mining, including a collection of machine learning algorithms for classification, regression, clustering, and specifically concept drift detection.",X1;X1-03,stream_mining;drift_detection;online_learning,platform,Java,https://github.com/Waikato/moa,https://moa.cms.waikato.ac.nz/,GPL-3.0,data-stream;concept-drift;big-data;java
305,MetaShift,Dataset for evaluating contextual distribution shifts,"A dataset collection derived from Visual Genome for evaluating contextual distribution shifts and training conflicts, aiding in the development of robust ML models.",X1;X1-03,benchmarking;distribution_shift_evaluation,dataset,Jupyter Notebook,https://github.com/Weixin-Liang/MetaShift,https://github.com/Weixin-Liang/MetaShift,MIT,distribution-shift;dataset;evaluation
306,AutoML-IDS-Defense,AutoML-based IDS and adversarial attack defense,Code implementing AutoML-based Intrusion Detection Systems (IDS) and defense mechanisms against adversarial attacks for zero-touch network security.,X1;X1-03;Network Security,adversarial_defense;intrusion_detection,solver,Jupyter Notebook,https://github.com/Western-OC2-Lab/AutoML-and-Adversarial-Attack-Defense-for-Zero-Touch-Network-Security,,MIT,automl;adversarial-defense;network-security
307,MSANA,Multi-Stage Automated Online Network Data Stream Analytics,A framework for online data stream analytics that implements methods to address concept drift and model drift in IIoT systems.,X1;X1-03;IIoT,drift_adaptation;stream_analytics,solver,Jupyter Notebook,https://github.com/Western-OC2-Lab/MSANA-Online-Data-Stream-Analytics-And-Concept-Drift-Adaptation,,MIT,concept-drift;online-learning;iiot
308,OASW,Lightweight Concept Drift Detection and Adaptation Framework,An online learning method and framework designed to detect and adapt to concept drift in IoT data streams efficiently.,X1;X1-03;IoT,drift_detection;online_learning,solver,Jupyter Notebook,https://github.com/Western-OC2-Lab/OASW-Concept-Drift-Detection-and-Adaptation,,MIT,concept-drift;iot;adaptive-learning
309,PWPAE,Ensemble Framework for Concept Drift Adaptation,"An ensemble framework (PWPAE) for adapting to concept drift in IoT data streams, utilizing the River library for online learning.",X1;X1-03;IoT,drift_adaptation;ensemble_learning,solver,Jupyter Notebook,https://github.com/Western-OC2-Lab/PWPAE-Concept-Drift-Detection-and-Adaptation,,MIT,concept-drift;ensemble-methods;river-library
310,ULDA,Unsupervised Few-Shot Learning via Distribution Shift-based Augmentation,"Implementation of ULDA, a method for unsupervised few-shot learning that leverages distribution shift-based augmentation to improve model generalization.",X1;X1-03,distribution_shift_adaptation;few_shot_learning,solver,Python,https://github.com/WonderSeven/ULDA,,MIT,distribution-shift;few-shot-learning;augmentation
311,GraphMETRO,Mitigating Complex Graph Distribution Shifts,A method (GraphMETRO) for mitigating complex distribution shifts in graph data using a Mixture of Aligned Experts approach.,X1;X1-03;Graph Learning,distribution_shift_mitigation;graph_learning,solver,Python,https://github.com/Wuyxin/GraphMETRO,,None,graph-distribution-shift;mixture-of-experts;gnn
312,IF-Defense,3D Adversarial Point Cloud Defense via Implicit Function,"Implementation of IF-Defense, a method for defending against adversarial attacks on 3D point clouds using implicit function-based restoration.",X1;X1-03;3D Vision,adversarial_defense;point_cloud_restoration,solver,Python,https://github.com/Wuziyi616/IF-Defense,,MIT,3d-point-cloud;adversarial-defense;implicit-function
313,Likelihood-Regret,Out-of-Distribution Detection Score for VAEs,"Implementation of Likelihood Regret, an effective score for detecting out-of-distribution samples using Variational Auto-encoders (VAEs).",X1;X1-03,ood_detection;vae,solver,Python,https://github.com/XavierXiao/Likelihood-Regret,,MIT,ood-detection;variational-autoencoder;likelihood-regret
314,NegLabel,Negative Label Guided OOD Detection with VLMs,"Implementation of NegLabel, a method for Out-of-Distribution detection that utilizes negative labels and pre-trained Vision-Language Models.",X1;X1-03,ood_detection;vision_language_models,solver,Python,https://github.com/XueJiang16/NegLabel,,Apache-2.0,ood-detection;vlm;negative-labels
315,DeePCtools,A wrapped package for Data-enabled Predictive Control (DeePC) implementation,"DeePCtools is a Python package designed for implementing Data-enabled Predictive Control (DeePC) and Robust DeePC designs. It supports multiple objective functions, facilitating the application of data-driven control strategies in engineering and scientific systems.",Control Theory;Engineering,predictive_control;robust_control_design,library,Python,https://github.com/Zhang-Xuewen/DeePCtools,,Apache-2.0,deepc;predictive-control;robust-control
316,ADWIN,Adaptive sliding window algorithm for detecting change and concept drift in data streams,"ADWIN (ADaptive WINdowing) is an algorithm for detecting changes in the distribution of a data stream. It maintains updated statistics by automatically adjusting the window size based on the detected drift, serving as a black-box component for learning and mining algorithms.",X1-03;Data Stream Mining,drift_detection;concept_drift_monitoring,library,Java,https://github.com/abifet/adwin,,None,concept-drift;stream-mining;change-detection
317,AdvBox,Toolbox to generate adversarial examples and benchmark model robustness,"AdvBox is a comprehensive toolbox for generating adversarial examples to fool neural networks across multiple frameworks (PaddlePaddle, PyTorch, Caffe2, MxNet, Keras, TensorFlow). It provides command-line tools and APIs to benchmark the robustness of machine learning models against adversarial attacks.",X1-03;AI Safety,adversarial_attack;robustness_benchmarking,platform,Python,https://github.com/advboxes/AdvBox,,Apache-2.0,adversarial-examples;model-robustness;ai-security
318,StrikePy,Python toolbox for structural identifiability and observability analysis of nonlinear models,"StrikePy is a Python toolbox designed for analyzing the structural properties of nonlinear dynamic models, specifically focusing on structural identifiability and observability. It is useful in systems biology and control theory for model validation and experimental design.",Systems Biology;Control Theory,identifiability_analysis;observability_analysis,library,Python,https://github.com/afvillaverde/StrikePy,,GPL-3.0,identifiability;observability;nonlinear-models
319,STRIKE-GOLDD,MATLAB toolbox for analysing structural properties of nonlinear models,"STRIKE-GOLDD is a MATLAB toolbox for analyzing structural identifiability, observability, accessibility, and controllability of nonlinear dynamic models. It aids researchers in determining whether model parameters can be uniquely estimated from experimental data.",Systems Biology;Control Theory,identifiability_analysis;observability_analysis,library,MATLAB,https://github.com/afvillaverde/strike-goldd,,GPL-3.0,identifiability;nonlinear-systems;matlab-toolbox
320,PromptInject,Framework for quantitative analysis of LLM robustness to adversarial prompt attacks,PromptInject is a modular framework designed to assemble prompts and quantitatively analyze the robustness of Large Language Models (LLMs) against adversarial prompt attacks (prompt injection). It helps researchers evaluate safety risks in LLM applications.,X1-03;LLM Safety,robustness_analysis;prompt_injection_testing,workflow,Python,https://github.com/agencyenterprise/PromptInject,,MIT,llm-robustness;prompt-injection;adversarial-testing
321,dryft,Tool for correcting signal drift in ground reaction force data,dryft is a Python package specifically designed to correct signal drift in ground reaction force (GRF) data collected during treadmill running. It provides signal processing utilities to improve the quality of biomechanical data.,Biomechanics;Signal Processing,signal_drift_correction;data_processing,library,Python,https://github.com/alcantarar/dryft,,MIT,biomechanics;signal-processing;drift-correction
322,KeystoneML,Framework for robust end-to-end machine learning on Apache Spark,"KeystoneML is a software framework designed to simplify the construction of large-scale, robust machine learning pipelines on Apache Spark. It focuses on end-to-end optimization and robustness in ML workflows.",X1;Machine Learning Systems,ml_pipeline_construction;robust_learning,platform,Scala,https://github.com/amplab/keystone,,Apache-2.0,spark;ml-pipelines;robust-ml
323,Foolbox,A Python toolbox to create adversarial examples that fool neural networks,"Foolbox is a Python library that provides a comprehensive collection of adversarial attacks to benchmark the robustness of machine learning models. It supports multiple frameworks including PyTorch, TensorFlow, and JAX, allowing researchers to evaluate model vulnerability to perturbations.",X1;X1-03,robustness_testing;adversarial_attack,library,Python,https://github.com/bethgelab/foolbox,https://foolbox.jonasrauber.de/,MIT,adversarial-attacks;robustness;pytorch;tensorflow
324,model-vs-human,Benchmark for evaluating model robustness against human perception on OOD datasets,A benchmarking tool and dataset designed to compare the out-of-distribution (OOD) generalization capabilities of deep learning models against human visual perception. It provides a standardized evaluation protocol for measuring robustness shifts.,X1;X1-03,benchmarking;ood_detection,library,Python,https://github.com/bethgelab/model-vs-human,https://github.com/bethgelab/model-vs-human,None,benchmarking;ood;robustness;human-comparison
325,concept-drift,Algorithms for detecting concept drift in data streams,"A Python library implementing various algorithms for detecting concept drift and changes in data streams, useful for monitoring the stability of data distributions in scientific and industrial applications.",X1;X1-03,drift_detection;stream_mining,library,Python,https://github.com/blablahaha/concept-drift,https://github.com/blablahaha/concept-drift,None,concept-drift;change-detection;data-stream
326,boxkite,Concept drift monitoring instrumentation for model servers,A library designed to monitor machine learning models in production for concept drift. It integrates with model serving infrastructure to track distribution shifts and ensure model reliability over time.,X1;X1-03,drift_monitoring;ml_observability,library,Python,https://github.com/boxkite-ml/boxkite,https://boxkite.ml/,Apache-2.0,monitoring;concept-drift;mlops;prometheus
327,RobustToolbox,Robust regression toolbox for neuroimaging data analysis,"A toolbox developed by the Cognitive & Affective Neuroscience Lab for performing robust regression analysis specifically tailored for neuroimaging data, helping to handle outliers and noise in brain imaging studies.",X1;X1-03,robust_regression;neuroimaging_analysis,library,HTML,https://github.com/canlab/RobustToolbox,https://github.com/canlab/RobustToolbox,GPL-2.0,neuroimaging;robust-statistics;regression;matlab
328,nn_robust_attacks,Implementation of robust evasion attacks against neural networks,A reference implementation of the Carlini & Wagner (C&W) attacks and other robust evasion techniques. It serves as a standard tool for evaluating the adversarial robustness of neural network models.,X1;X1-03,adversarial_attack;robustness_evaluation,library,Python,https://github.com/carlini/nn_robust_attacks,https://github.com/carlini/nn_robust_attacks,BSD-2-Clause,adversarial-attacks;security;deep-learning
329,TreeMix Scripts,Analysis pipeline for TreeMix population genetics tool,"A collection of scripts and workflows to automate the analysis of population data using TreeMix. It includes functionality for bootstrapping, selecting migration events, and visualizing maximum likelihood trees with drift and residual statistics.",X1;X1-03,population_genetics;drift_analysis,workflow,R,https://github.com/carolindahms/TreeMix,https://github.com/carolindahms/TreeMix,None,population-genetics;treemix;migration;phylogenetics
330,POMDP,Solver for Partially Observable Markov Decision Processes,"A MATLAB implementation of algorithms for solving Partially Observable Markov Decision Processes (POMDPs), which are mathematical frameworks used for modeling decision-making under uncertainty in various scientific and engineering domains.",X1;X1-03,decision_making;reinforcement_learning,solver,MATLAB,https://github.com/catohaste/POMDP,https://github.com/catohaste/POMDP,NOASSERTION,pomdp;reinforcement-learning;decision-theory
331,CleverHans,Adversarial example library for constructing attacks and defenses,A Python library to benchmark machine learning systems' vulnerability to adversarial examples. It provides standard implementations of attacks and defenses to help researchers build more robust models.,X1;X1-03,adversarial_defense;robustness_benchmarking,library,Jupyter Notebook,https://github.com/cleverhans-lab/cleverhans,https://github.com/cleverhans-lab/cleverhans,MIT,adversarial-examples;security;machine-learning
332,data-drift,Metrics observability and troubleshooting tool for data drift,"A tool designed for metrics observability and troubleshooting, specifically focusing on data drift detection and monitoring in data pipelines.",X1;X1-03,drift_detection;monitoring,solver,HTML,https://github.com/data-drift/data-drift,,GPL-3.0,data-drift;observability;troubleshooting
333,Minotor,Machine learning production monitoring and bias detection tool,"Open source software for monitoring machine learning models in production, enabling users to maintain control over models, detect bias, and explain results.",X1;X1-03,monitoring;bias_detection;explainability,platform,JavaScript,https://github.com/datarmada/minotor,,Apache-2.0,ml-monitoring;bias-detection;production-ml
334,oodeel,Post-hoc out-of-distribution detection library for TensorFlow and PyTorch,"A simple, compact, and hackable library for post-hoc deep out-of-distribution (OOD) detection, compatible with already trained TensorFlow or PyTorch image classifiers.",X1;X1-03,ood_detection;model_robustness,library,Python,https://github.com/deel-ai/oodeel,,MIT,ood-detection;pytorch;tensorflow;robustness
335,Deepchecks,Continuous validation and testing suite for ML models and data,"A holistic open-source solution for AI & ML validation, enabling thorough testing of data and models from research to production, including drift and robustness checks.",X1;X1-03,validation;drift_detection;robustness_testing,library,Python,https://github.com/deepchecks/deepchecks,https://docs.deepchecks.com,NOASSERTION,validation;ml-testing;drift-detection;data-integrity
336,Deepchecks Monitoring,Continuous validation and monitoring service for ML models in production,"The monitoring component of the Deepchecks ecosystem, designed for continuous validation of machine learning models and data in production environments.",X1;X1-03,monitoring;continuous_validation,service,Python,https://github.com/deepchecks/monitoring,,NOASSERTION,ml-monitoring;production;validation
337,Delve,PyTorch model training and layer saturation monitor,"A tool for monitoring PyTorch model training dynamics, specifically focusing on layer saturation to aid in debugging and optimizing deep learning models.",X1;X1-03,model_monitoring;debugging;training_dynamics,library,Python,https://github.com/delve-team/delve,,MIT,pytorch;monitoring;saturation;debugging
338,Gate,Drift detection module for machine learning pipelines,"A dedicated module for detecting data drift within machine learning pipelines, facilitating robust model maintenance.",X1;X1-03,drift_detection,library,Python,https://github.com/dm4ml/gate,,MIT,drift-detection;ml-pipeline;monitoring
339,Watermark Robustness Toolbox,Toolbox for evaluating DNN image classification watermarking robustness,"The official implementation of the IEEE S&P'22 paper, providing a toolbox to evaluate the robustness of deep neural network image classification watermarking techniques.",X1;X1-03,robustness_evaluation;security_auditing,library,Python,https://github.com/dnn-security/Watermark-Robustness-Toolbox,,GPL-3.0,watermarking;robustness;dnn-security
340,DiffAI,System for training provably robust neural networks,"A certifiable defense system against adversarial examples that trains neural networks to be provably robust, developed by ETH SRI Lab.",X1;X1-03,robust_training;adversarial_defense,library,Python,https://github.com/eth-sri/diffai,,MIT,robustness;adversarial-defense;verification
341,ETSI Watchdog,Real-time data drift detection for ML pipelines,"A tool for real-time data drift detection and monitoring within machine learning pipelines, ensuring model reliability over time.",X1;X1-03,drift_detection;monitoring,solver,Python,https://github.com/etsi-ai/etsi-watchdog,,BSD-2-Clause,drift-detection;real-time;ml-monitoring
342,Dredge,Robust online multiband drift estimation for electrophysiology data,"A tool for robust online multiband drift estimation specifically designed for electrophysiology data analysis, enabling stable tracking of neural signals over time.",X1-03;Neuroscience,drift_estimation;signal_processing,solver,Jupyter Notebook,https://github.com/evarol/dredge,,MIT,electrophysiology;drift-estimation;neuroscience
343,Adversarial Image Defenses,Library for countering adversarial images using input transformations,"A library providing implementations of input transformation techniques to defend against adversarial attacks on image classifiers, supporting research in robust computer vision.",X1-03;Computer Vision,adversarial_defense;image_processing,library,Python,https://github.com/facebookarchive/adversarial_image_defenses,,NOASSERTION,adversarial-defense;robustness;input-transformation
344,ImageNet Adversarial Training,State-of-the-art adversarially robust ImageNet classifiers,"Provides pre-trained models and training code for ImageNet classifiers that achieve state-of-the-art adversarial robustness, serving as a benchmark and resource for robustness research.",X1-03;Computer Vision,adversarial_training;model_robustness,solver,Python,https://github.com/facebookresearch/ImageNet-Adversarial-Training,,NOASSERTION,adversarial-training;imagenet;robustness
345,FastForward Concept Drift,Unsupervised methods for detecting concept drift,"A repository containing implementations of unsupervised methods for detecting concept drift in data streams, developed as part of the Fast Forward Labs research cycle.",X1-03,drift_detection;unsupervised_learning,library,Jupyter Notebook,https://github.com/fastforwardlabs/concept-drift,http://blog.fastforwardlabs.com/2017/01/25/concept-drift.html,Apache-2.0,concept-drift;unsupervised;streaming-data
346,FairPut,Machine Learning Fairness Framework with LightGBM,"A framework designed to enhance fairness, robustness, and explainability in machine learning models, specifically leveraging LightGBM for tabular data.",X1-03;Fairness,fairness_evaluation;robust_modeling,framework,Jupyter Notebook,https://github.com/firmai/ml-fairness-framework,,None,fairness;lightgbm;robustness
347,AutoGBT,AutoML for lifelong learning under concept drift,"An AutoML tool designed for lifelong machine learning settings, capable of classifying large volume high cardinality data streams while adapting to concept drift.",X1-03;AutoML,automl;drift_adaptation;stream_classification,solver,Python,https://github.com/flytxtds/AutoGBT,,NOASSERTION,automl;concept-drift;lifelong-learning
348,AutoAttack,Reliable evaluation of adversarial robustness,A widely used framework for reliably evaluating the adversarial robustness of image classifiers using an ensemble of diverse parameter-free attacks.,X1-03;Computer Vision,robustness_evaluation;adversarial_attack,library,Python,https://github.com/fra31/auto-attack,,MIT,adversarial-robustness;benchmarking;security
349,LeanVerifier,Formal verification framework for ML properties using Lean 4,"A framework for specifying and proving properties such as robustness, fairness, and interpretability of machine learning models using the Lean 4 theorem prover.",X1-03;Formal Methods,formal_verification;robustness_proof,framework,Lean,https://github.com/fraware/leanverifier,,MIT,formal-verification;lean4;robustness
350,FedDC,Federated Learning with Local Drift Decoupling and Correction,An implementation of the FedDC algorithm for handling non-IID data in federated learning via local drift decoupling and correction.,X1-03;Federated Learning,federated_learning;drift_correction,solver,Python,https://github.com/gaoliang13/FedDC,,MIT,federated-learning;non-iid;drift-correction
351,RobNets,Neural Architecture Search for robust architectures,A framework for searching for robust neural network architectures against adversarial attacks using Neural Architecture Search (NAS).,X1-03;NAS,neural_architecture_search;robust_modeling,solver,Python,https://github.com/gmh14/RobNets,,MIT,nas;adversarial-robustness;architecture-search
352,Distribution Shift Framework,Framework for analyzing distribution shifts,"A framework for fine-grained analysis of distribution shifts in machine learning, supporting research into generalization and robustness.",X1-03,distribution_shift_analysis;generalization_evaluation,framework,Python,https://github.com/google-deepmind/distribution_shift_framework,,Apache-2.0,distribution-shift;deepmind;robustness
353,RETVec,Efficient and adversarially-robust text vectorizer,"A multilingual, adversarially-robust text vectorizer designed to be efficient and resilient against character-level manipulations and attacks.",X1-03;NLP,text_vectorization;adversarial_defense,library,Jupyter Notebook,https://github.com/google-research/retvec,,Apache-2.0,nlp;robustness;vectorizer
354,StableCox,Stable Cox Regression for Survival Analysis under Distribution Shifts,An implementation of Stable Cox Regression for performing survival analysis that is robust to distribution shifts in the data.,X1-03;Biostatistics,survival_analysis;robust_regression,solver,Python,https://github.com/googlebaba/StableCox,,None,survival-analysis;distribution-shift;cox-regression
355,ft-drift,Drift detection for OpenAI fine-tuning datasets,"A tool to check for data drift between two OpenAI multi-turn chat JSONL files, useful for monitoring dataset quality in LLM fine-tuning workflows.",X1-03;LLM,data_drift_detection;dataset_validation,solver,Jupyter Notebook,https://github.com/hamelsmu/ft-drift,,Apache-2.0,llm;fine-tuning;drift-detection
356,OOD Error Detection Baseline,Baseline for detecting misclassified and OOD examples,"A baseline implementation for detecting misclassified and out-of-distribution examples in neural networks, serving as a standard benchmark for OOD detection research.",X1-03,ood_detection;error_detection,solver,Jupyter Notebook,https://github.com/hendrycks/error-detection,,MIT,ood;misclassification;benchmark
357,SS-OOD,Self-Supervised Learning for OOD Detection,Implements self-supervised learning techniques to improve out-of-distribution detection in neural networks.,X1-03,ood_detection;self_supervised_learning,solver,Python,https://github.com/hendrycks/ss-ood,,MIT,ood;self-supervised;robustness
358,CROWN-IBP,Certified defense against adversarial examples,"A certified defense framework against adversarial examples using CROWN (bound propagation) and IBP (Interval Bound Propagation), including GPU implementations for verification.",X1-03;Formal Verification,adversarial_defense;formal_verification,solver,Python,https://github.com/huanzhang12/CROWN-IBP,,BSD-2-Clause,certified-defense;verification;adversarial-robustness
359,Wild-Time,Benchmark for Natural Temporal Distribution Shift,"A benchmark suite for evaluating machine learning models under natural temporal distribution shifts, providing datasets and evaluation protocols.",X1-03,benchmarking;distribution_shift_evaluation,dataset,Python,https://github.com/huaxiuyao/Wild-Time,https://wild-time.github.io/,MIT,temporal-shift;benchmark;distribution-shift
360,Adversarial Robustness PyTorch,PyTorch implementation of adversarial training and robustness methods,"A PyTorch library implementing various adversarial training techniques and robustness methods, including those from DeepMind papers, facilitating research in robust ML.",X1-03,adversarial_training;robustness_modeling,library,Python,https://github.com/imrahulr/adversarial_robustness_pytorch,,MIT,pytorch;adversarial-training;robustness
361,PatchCleanser,Certifiably robust defense against adversarial patches,A defense mechanism that provides certifiable robustness against adversarial patch attacks for image classifiers.,X1-03;Computer Vision,adversarial_defense;image_processing,solver,Python,https://github.com/inspire-group/PatchCleanser,,MIT,adversarial-patch;certified-defense;robustness
362,PatchGuard,Provably robust defense against adversarial patches,A provably robust defense framework against adversarial patches utilizing small receptive fields and masking techniques.,X1-03;Computer Vision,adversarial_defense;image_processing,solver,Python,https://github.com/inspire-group/PatchGuard,,MIT,adversarial-patch;provable-robustness;defense
363,OptiSpline,Toolbox for robust optimization with spline relaxations,"A user-friendly C++ toolbox designed for solving robust optimization problems using spline relaxations, developed by the MECO research group.",Optimization;Mathematics,robust_optimization;numerical_solver,solver,C++,https://github.com/meco-group/optispline,,None,optimization;splines;robustness
364,Sync Toolbox,Efficient and robust music synchronization library,"A Python package providing reference implementations for efficient, robust, and accurate music synchronization based on dynamic time warping (DTW).",Audio Processing;Signal Processing,synchronization;signal_alignment,library,Python,https://github.com/meinardmueller/synctoolbox,https://meinardmueller.github.io/synctoolbox/,NOASSERTION,music-synchronization;dtw;audio-analysis
365,Responsible AI Toolbox,Suite of tools for model assessment and monitoring,"A suite of tools providing model and data exploration and assessment user interfaces and libraries that enable a better understanding of AI systems, including error analysis, fairness, and interpretability.",X1;X1-03;Responsible AI,model_assessment;error_analysis;fairness_monitoring,platform,TypeScript,https://github.com/microsoft/responsible-ai-toolbox,https://responsibleaitoolbox.ai/,MIT,responsible-ai;model-monitoring;error-analysis
366,RobustDG,Toolkit for domain generalization and robust ML,"A toolkit for building machine learning models that generalize to unseen domains and are robust to privacy and other attacks, facilitating research in domain generalization.",X1;X1-03;Machine Learning,domain_generalization;robustness_evaluation,library,Python,https://github.com/microsoft/robustdg,,MIT,domain-generalization;robustness;privacy
367,RobustLearn,Library for robust machine learning algorithms,"A library focused on robust machine learning techniques for responsible AI, providing implementations of algorithms designed to handle noise and distribution shifts.",X1;X1-03;Machine Learning,robust_learning;noise_handling,library,Python,https://github.com/microsoft/robustlearn,,MIT,robust-learning;responsible-ai;machine-learning
368,MIT-LL Responsible AI Toolbox,Library for evaluating AI robustness,A PyTorch-centric library developed by MIT Lincoln Laboratory for evaluating and enhancing the robustness of AI technologies against various threats and shifts.,X1;X1-03;Machine Learning,robustness_evaluation;adversarial_defense,library,Jupyter Notebook,https://github.com/mit-ll-responsible-ai/responsible-ai-toolbox,,MIT,robustness;pytorch;evaluation
369,Menelaus,Concept and data drift detection library,A Python library providing online and batch-based concept and data drift detection algorithms to monitor and maintain machine learning model performance.,X1;X1-03;MLOps,drift_detection;model_monitoring,library,Python,https://github.com/mitre/menelaus,https://menelaus.readthedocs.io/,Apache-2.0,drift-detection;concept-drift;monitoring
370,MLflow,Platform for end-to-end machine learning lifecycle,"An open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry, essential for scientific experiment tracking.",MLOps;Data Science,experiment_tracking;model_registry;workflow_management,platform,Python,https://github.com/mlflow/mlflow,https://mlflow.org/,Apache-2.0,experiment-tracking;mlops;model-management
371,TableShift,Benchmark for distribution shift in tabular data,A benchmark library for evaluating machine learning models under distribution shift specifically for tabular data datasets.,X1;X1-03;Machine Learning,benchmarking;distribution_shift_evaluation,dataset,Python,https://github.com/mlfoundations/tableshift,https://tableshift.org/,MIT,tabular-data;distribution-shift;benchmark
372,ModelFox,"Platform to train, deploy, and monitor ML models","A platform that simplifies the training, deployment, and monitoring of machine learning models, providing tools for observing model performance in production.",MLOps;X1-03,model_monitoring;deployment,platform,Rust,https://github.com/modelfoxdotdev/modelfox,https://modelfox.dev/,NOASSERTION,monitoring;mlops;deployment
373,ImageNet Testbed,Benchmark for measuring robustness to distribution shifts,A codebase and dataset collection serving as a testbed for measuring the robustness of image classification models to natural distribution shifts.,X1;X1-03;Computer Vision,robustness_benchmarking;distribution_shift,dataset,Python,https://github.com/modestyachts/imagenet-testbed,,MIT,imagenet;robustness;benchmark
374,NIC-RobustBench,Toolkit for neural image compression and robustness analysis,A comprehensive open-source toolkit designed for analyzing the robustness of neural image compression models.,X1;X1-03;Image Compression,robustness_analysis;compression_evaluation,library,Python,https://github.com/msu-video-group/NIC-RobustBench,,Apache-2.0,image-compression;robustness;benchmark
375,LTrack,Security observability framework for model file loading,"A security observability framework designed to capture, inspect, and investigate file loading operations during ML/AI model initialization, aiding in forensic analysis.",Security;MLOps,security_monitoring;forensics,library,C,https://github.com/mxcrafts/ltrack,,NOASSERTION,security;observability;model-loading
376,WhyShift,Benchmark package for distribution shift patterns,A Python package providing a benchmark with various specified distribution shift patterns to evaluate model performance under shifting conditions.,X1;X1-03;Machine Learning,benchmarking;distribution_shift,library,Jupyter Notebook,https://github.com/namkoong-lab/whyshift,,NOASSERTION,distribution-shift;benchmark;evaluation
377,ENTERPRISE,Pulsar timing analysis and noise analysis toolbox,"ENTERPRISE (Enhanced Numerical Toolbox Enabling a Robust PulsaR Inference SuitE) is a code for pulsar timing analysis, aimed at noise analysis, gravitational-wave searches, and timing model analysis.",Astronomy;Physics,pulsar_timing_analysis;gravitational_wave_search;noise_analysis,solver,Python,https://github.com/nanograv/enterprise,https://enterprise.readthedocs.io/,MIT,pulsar-timing;gravitational-waves;astronomy
378,Neptune Client,Client library for Neptune experiment tracking,"The client library for Neptune.ai, an experiment tracker for foundation model training that provides tracking, observability, and evaluations.",MLOps;Data Science,experiment_tracking;model_evaluation,library,Python,https://github.com/neptune-ai/neptune-client,https://docs.neptune.ai/,Apache-2.0,experiment-tracking;mlops;observability
379,ML Performance Monitoring,Package for sending model inference data and metrics,"A Python package developed by New Relic for sending model inference data, data metrics, and model metrics to their observability platform.",MLOps;X1-03,model_monitoring;inference_tracking,library,Python,https://github.com/newrelic-experimental/ml-performance-monitoring,,Apache-2.0,monitoring;observability;metrics
380,SRQL,Semi-automated Robust Quantification of Lesions Toolbox,"A shell-based toolbox for the semi-automated and robust quantification of lesions in medical imaging, designed to facilitate neuroimaging analysis.",X1;X1-03,medical_imaging;quantification;lesion_detection,solver,Shell,https://github.com/npnl/SRQL,,None,medical-imaging;lesion-quantification;neuroscience
381,WILDS,Benchmark of in-the-wild distribution shifts,"A benchmark toolkit for evaluating machine learning models against distribution shifts, providing data loaders, evaluators, and default models for robust ML research.",X1;X1-03,benchmarking;distribution_shift;robustness_evaluation,library,Python,https://github.com/p-lambda/wilds,https://wilds.stanford.edu,MIT,distribution-shift;benchmarking;robustness
382,BibMon,Predictive models for fault detection and condition monitoring,"A Python package providing predictive models and tools for fault detection, soft sensing, and process condition monitoring in industrial and scientific contexts.",X1;X1-03,fault_detection;condition_monitoring;anomaly_detection,library,Python,https://github.com/petrobras/BibMon,,Apache-2.0,fault-detection;process-monitoring;soft-sensing
383,TraceML,Engine for ML/Data tracking and drift detection,"A library for tracking machine learning experiments, visualizing data, and detecting drift, serving as the tracking engine for Polyaxon.",X1;X1-03,drift_detection;experiment_tracking;observability,library,Python,https://github.com/polyaxon/traceml,https://polyaxon.com/docs/traceml/,Apache-2.0,drift-detection;mlops;tracking
384,SecML,Library for Secure and Explainable Machine Learning,A Python library for evaluating the security of machine learning algorithms against adversarial attacks and explaining their decisions.,X1;X1-03,adversarial_robustness;security_evaluation;explainability,library,Python,https://github.com/pralab/secml,https://secml.readthedocs.io,Apache-2.0,adversarial-attacks;security;explainable-ai
385,Radicalbit AI Monitoring,Solution for monitoring AI models in production,"A comprehensive library and platform for monitoring AI models, detecting data drift, and ensuring model reliability in production environments.",X1;X1-03,model_monitoring;drift_detection;reliability,platform,Python,https://github.com/radicalbit/radicalbit-ai-monitoring,https://docs.radicalbit.ai,Apache-2.0,monitoring;drift-detection;mlops
386,driftscan,Data analysis for transit radio interferometers,"A tool for the data analysis of transit radio interferometers, specifically designed for 21cm cosmology research.",X1;X1-03,data_analysis;radio_astronomy;interferometry,solver,Python,https://github.com/radiocosmology/driftscan,,NOASSERTION,cosmology;radio-astronomy;data-analysis
387,MC-Calib,Robust calibration toolbox for multi-camera systems,"A generic and robust calibration toolbox for multi-camera systems, facilitating precise geometric calibration for computer vision and robotics applications.",X1;X1-03,calibration;computer_vision;measurement,solver,C++,https://github.com/rameau-fr/MC-Calib,,MIT,calibration;multi-camera;computer-vision
388,Robustness Gym,Evaluation toolkit for machine learning robustness,A comprehensive toolkit for evaluating the robustness of machine learning models through structured testing and slice-based analysis.,X1;X1-03,robustness_evaluation;model_testing;error_analysis,library,Python,https://github.com/robustness-gym/robustness-gym,https://robustnessgym.com,Apache-2.0,robustness;evaluation;testing
389,vetiver-r,"MLOps tool for versioning, deploying, and monitoring models in R","An R package for MLOps that provides tools to version, share, deploy, and monitor machine learning models, including functionality for drift monitoring.",X1;X1-03,model_monitoring;deployment;mlops,library,R,https://github.com/rstudio/vetiver-r,https://vetiver.rstudio.com,NOASSERTION,mlops;monitoring;r
390,POHMM,Python implementation of Partially Observable Hidden Markov Models,"A Python library implementing the Partially Observable Hidden Markov Model (POHMM), suitable for statistical modeling and time series analysis in scientific contexts where states are not directly observable.",X1;Cross-domain,statistical_modeling;time_series_analysis,solver,Python,https://github.com/vmonaco/pohmm,,BSD-3-Clause,hmm;markov-model;statistics
391,LangKit,Open-source toolkit for monitoring Large Language Models (LLMs),"A comprehensive toolkit for monitoring Large Language Models, extracting signals from prompts and responses to ensure safety, security, and quality. It provides metrics for text quality, relevance, and sentiment analysis, aiding in the robust deployment of LLMs in research and production.",X1;X1-03,model_monitoring;safety_check;drift_detection,library,Python,https://github.com/whylabs/langkit,https://github.com/whylabs/langkit,Apache-2.0,llm-monitoring;safety;observability
392,whylogs,Open-source standard for data and ML logging,"A library for data logging that enables data quality monitoring and model performance tracking over time. It supports privacy-preserving data collection and drift detection, essential for maintaining the robustness of machine learning pipelines in scientific and industrial applications.",X1;X1-03,data_logging;drift_detection;data_quality_check,library,Python,https://github.com/whylabs/whylogs,https://whylogs.readthedocs.io,Apache-2.0,data-logging;drift-detection;ml-monitoring
393,whylogs-java,Java library for whylogs data logging and monitoring,"The Java implementation of the whylogs library, allowing for profiling and monitoring of ML data pipelines within Java-based environments. It provides capabilities for tracking data quality and detecting drift.",X1;X1-03,data_logging;drift_detection,library,Java,https://github.com/whylabs/whylogs-java,,Apache-2.0,java;data-logging;monitoring
394,PyABSA,Framework for aspect-based sentiment analysis and text adversarial defense,"An open-source framework for Aspect-based Sentiment Analysis (ABSA) that includes modules for text classification, augmentation, and adversarial defense. It serves as a tool for robust NLP research and application.",X1;X1-03,sentiment_analysis;adversarial_defense;text_augmentation,library,Python,https://github.com/yangheng95/PyABSA,https://pyabsa.readthedocs.io,MIT,nlp;adversarial-defense;sentiment-analysis
395,RcppML,High-performance R package for NMF and machine learning,"A high-performance R package providing fast and robust Non-negative Matrix Factorization (NMF) and divisive clustering algorithms. It is designed for scientific data analysis, particularly in fields like bioinformatics where NMF is a key method.",Cross-domain,dimensionality_reduction;clustering;matrix_factorization,library,C++,https://github.com/zdebruine/RcppML,https://github.com/zdebruine/RcppML,GPL-2.0,nmf;clustering;r-package
396,CinnaMon,"Library to detect, explain, and correct data drift","A Python library offering tools to detect, explain, and correct data drift in machine learning systems. It helps in maintaining model reliability by monitoring distribution shifts.",X1;X1-03,drift_detection;drift_explanation,library,Python,https://github.com/zelros/cinnamon,https://cinnamon.readthedocs.io,MIT,data-drift;monitoring;explainability
397,KERMIT,Lightweight library to encode and interpret Universal Syntactic Embeddings,"A JavaScript library designed to encode and interpret Universal Syntactic Embeddings, facilitating the analysis of syntactic structures in natural language processing research.",NLP;Linguistics,embedding_interpretation;syntactic_analysis,library,JavaScript,https://github.com/ART-Group-it/KERMIT,,MIT,nlp;embeddings;syntax;interpretability
398,shparkley,Spark implementation of Shapley Values using Monte-Carlo approximation,"A PySpark library for computing Shapley values to explain machine learning model predictions at scale, utilizing Monte-Carlo approximation for efficiency.",X1;X1-04,feature_attribution;shapley_value_estimation,library,Python,https://github.com/Affirm/shparkley,,BSD-3-Clause,shapley-values;pyspark;model-interpretability;xai
399,splinecam,Exact method for visualizing partitions of a Deep Neural Network,"A tool for visualizing the decision boundaries and partitions of deep neural networks, providing exact visualizations to aid in understanding model behavior.",X1;X1-04,model_visualization;decision_boundary_analysis,library,Python,https://github.com/AhmedImtiazPrio/splinecam,,MIT,visualization;neural-networks;interpretability;cvpr
400,bvh-parser,C++ library for parsing and interpreting BVH motion capture files,"A library for parsing BioVision Hierarchy (BVH) files, commonly used in biomechanics and computer graphics for storing motion capture data.",Biomechanics;Computer_Graphics,data_parsing;motion_capture_processing,library,C++,https://github.com/BartekkPL/bvh-parser,,Apache-2.0,bvh;motion-capture;parser;cpp
401,Style-CheXplain,GAN-based method for counterfactual explanations in chest X-rays,"A tool implementing a GAN-based approach to generate counterfactual explanations for chest X-ray classifiers, aiding in the interpretability of medical imaging models.",X1;X1-04;Medical_Imaging,counterfactual_generation;medical_image_analysis,solver,Python,https://github.com/CAMP-eXplain-AI/Style-CheXplain,,MIT,gan;counterfactuals;chest-x-ray;medical-ai
402,XBrainLab,Software for interpretation of neural patterns from EEG data,"An open-source software platform designed for the accelerated interpretation and analysis of neural patterns derived from EEG data, supporting neuroscience research.",Neuroscience;X1-04,eeg_analysis;neural_pattern_interpretation,platform,Python,https://github.com/CECNL/XBrainLab,,GPL-3.0,eeg;neuroscience;interpretability;brain-computer-interface
403,IntegratedGradientsPytorch,PyTorch implementation of Integrated Gradients attribution method,"A PyTorch library implementing the Integrated Gradients method for feature attribution, allowing users to explain the predictions of deep learning models.",X1;X1-04,feature_attribution;model_explanation,library,Python,https://github.com/CVxTz/IntegratedGradientsPytorch,,MIT,integrated-gradients;pytorch;xai;feature-attribution
404,ICAM,Interpretable Classification via Disentangled Representations,"An implementation of ICAM, a method for interpretable classification that utilizes disentangled representations and feature attribution mapping to provide model explanations.",X1;X1-04,interpretable_classification;feature_attribution,solver,Python,https://github.com/CherBass/ICAM,,MIT,disentangled-representation;interpretability;classification;xai
405,CLEAR,Counterfactual Local Explanations of AI systems,"A tool for generating counterfactual local explanations for AI systems, helping to understand individual predictions by identifying minimal changes required to alter the outcome.",X1;X1-04,counterfactual_explanation;local_explanation,library,Python,https://github.com/ClearExplanationsAI/CLEAR,,MIT,counterfactuals;xai;explanation;machine-learning
406,thermostat,Collection of NLP model explanations and analysis tools,"A toolkit and dataset for generating, storing, and analyzing explanations for NLP models, facilitating research into the interpretability of language models.",X1;X1-04;NLP,model_explanation;nlp_analysis,library,Jsonnet,https://github.com/DFKI-NLP/thermostat,,Apache-2.0,nlp;xai;explanations;dataset
407,sliceline,Fast slice finding for Machine Learning model debugging,"A tool for identifying data slices where a machine learning model performs poorly, aiding in model debugging and error analysis.",X1;X1-04,model_debugging;slice_finding,library,Jupyter Notebook,https://github.com/DataDome/sliceline,,BSD-3-Clause,debugging;ml-ops;slice-finding;error-analysis
408,E-measure,Enhanced-alignment Measure for Binary Foreground Map Evaluation,"A MATLAB tool implementing the Enhanced-alignment Measure (E-measure) for evaluating binary foreground maps, commonly used in saliency detection and segmentation tasks.",Computer_Vision;X1-04,evaluation_metric;saliency_evaluation,solver,MATLAB,https://github.com/DengPingFan/E-measure,,None,evaluation;metrics;saliency;computer-vision
409,S-measure,Structure-measure for evaluating foreground maps,"A MATLAB tool implementing the Structure-measure (S-measure) for evaluating foreground maps, focusing on structural similarity in tasks like saliency detection.",Computer_Vision;X1-04,evaluation_metric;saliency_evaluation,solver,MATLAB,https://github.com/DengPingFan/S-measure,,BSD-3-Clause,evaluation;metrics;saliency;computer-vision
410,Boruta-Shap,Tree-based feature selection tool combining Boruta algorithm with Shapley values,A Python tool that combines the Boruta feature selection algorithm with SHAP (SHapley Additive exPlanations) values to identify the most important features in a dataset. It provides a robust method for feature selection in scientific modeling and data analysis.,X1;X1-04,feature_selection;attribution,library,Python,https://github.com/Ekeany/Boruta-Shap,,MIT,feature-selection;shap;boruta;xai
411,delphi,Automated interpretability library for language models,"A library designed to help language models 'know themselves' through automated interpretability techniques. It provides tools for analyzing model behaviors and internal representations, contributing to the understanding of large language models.",X1;X1-04,interpretability;model_analysis,library,Python,https://github.com/EleutherAI/delphi,,Apache-2.0,interpretability;llm;mechanistic-interpretability
412,knowledge-neurons,Library for finding knowledge neurons in pretrained transformer models,A Python library specifically designed to locate and analyze 'knowledge neurons' within pretrained transformer models. It facilitates mechanistic interpretability research by linking specific model weights to factual knowledge.,X1;X1-04,mechanistic_interpretability;model_analysis,library,Python,https://github.com/EleutherAI/knowledge-neurons,,MIT,transformer;knowledge-neurons;interpretability
413,FAST,High-performance framework for medical image processing and visualization,"A cross-platform framework for high-performance medical image processing, neural network inference, and visualization. It is designed to handle large medical datasets and provides tools for real-time processing and analysis.",Medical Imaging;X1-04,image_processing;visualization;inference,framework,C++,https://github.com/FAST-Imaging/FAST,https://fast.eriksmistad.no,BSD-2-Clause,medical-imaging;visualization;deep-learning
414,LLMDebugger,Debugging tool for Large Language Models via runtime execution verification,"LDB (LLM Debugger) is a tool that enables debugging of Large Language Models by verifying runtime execution step-by-step. It helps in understanding model reasoning and identifying errors in generated code or logic, enhancing interpretability and reliability.",X1;X1-04,debugging;interpretability;verification,tool,Python,https://github.com/FloridSleeves/LLMDebugger,,Apache-2.0,llm;debugging;interpretability
415,gReLU,Library to train and interpret deep learning models for DNA sequences,"gReLU is a Python library designed for training, interpreting, and applying deep learning models to DNA sequences. It provides functionalities for genomic data analysis and model interpretation, specifically tailored for bioinformatics applications.",Biology;Genomics;X1-04,modeling;interpretation;sequence_analysis,library,Python,https://github.com/Genentech/gReLU,,MIT,genomics;dna;deep-learning;interpretability
416,explainable_ai_sdk,SDK for Google Cloud Explainable AI service,The Explainable AI SDK helps users build explanation metadata for their models and visualize feature attributions returned from Google Cloud's Explainable AI service. It facilitates the integration of interpretability features into machine learning workflows.,X1;X1-04,interpretability;visualization;attribution,library,Python,https://github.com/GoogleCloudPlatform/explainable_ai_sdk,,Apache-2.0,xai;cloud;attribution;visualization
417,Seq2Seq-Vis,Visualization tool for Sequential Neural Networks with Attention,"A visual debugging and interpretation tool for sequence-to-sequence models, particularly those using attention mechanisms. It allows users to explore the internal state and attention dynamics of models used in translation and other sequential tasks.",X1;X1-04;NLP,visualization;interpretability;debugging,tool,Python,https://github.com/HendrikStrobelt/Seq2Seq-Vis,http://seq2seq-vis.io/,Apache-2.0,visualization;seq2seq;attention;nlp
418,Infosys-Responsible-AI-Toolkit,Toolkit for ensuring AI solutions are trustworthy and transparent,"A comprehensive toolkit incorporating features for safety, security, explainability, fairness, bias detection, and hallucination detection. It aims to ensure that AI models are responsible and transparent, suitable for enterprise and scientific applications.",X1;X1-04,interpretability;fairness;safety_check,library,Python,https://github.com/Infosys/Infosys-Responsible-AI-Toolkit,,MIT,responsible-ai;explainability;fairness;security
419,segmentation_metrics,Package to compute medical segmentation metrics,A Python package dedicated to computing various metrics for evaluating medical image segmentation results. It provides a standardized way to assess the performance of segmentation models in medical imaging.,Medical Imaging;X1-04,evaluation;metrics;quality_control,library,Python,https://github.com/Jingnan-Jia/segmentation_metrics,,MIT,medical-imaging;segmentation;metrics
420,CounterfactualExplanations.jl,Counterfactual Explanations and Algorithmic Recourse in Julia,"A Julia package for generating counterfactual explanations and algorithmic recourse for machine learning models. It allows users to understand how changes in input features would affect model predictions, a key aspect of explainable AI.",X1;X1-04,counterfactuals;interpretability,library,Julia,https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl,https://www.patalt.org/CounterfactualExplanations.jl/dev/,MIT,julia;counterfactuals;xai;interpretability
421,Gcam,"PyTorch library for generating attention maps (Grad-CAM, etc.)","An easy-to-use PyTorch library for making model predictions interpretable. It supports generating attention maps using methods like Guided Backpropagation, Grad-CAM, Guided Grad-CAM, and Grad-CAM++, aiding in the visualization of CNN decisions.",X1;X1-04;Computer Vision,visualization;attribution;interpretability,library,Python,https://github.com/Karol-G/Gcam,,MIT,grad-cam;pytorch;visualization;xai
422,asent,Efficient and transparent sentiment analysis library using spaCy,"A Python library for performing efficient and transparent sentiment analysis. It emphasizes interpretability in sentiment scoring, making it useful for social science research or analyzing scientific text data where transparency is required.",X1;X1-04;NLP,sentiment_analysis;interpretability,library,Python,https://github.com/KennethEnevoldsen/asent,https://kennethenevoldsen.github.io/asent/,MIT,sentiment-analysis;spacy;interpretability;nlp
423,fastcam,Efficient computation of saliency maps for explainable AI attribution,"A toolkit developed at Lawrence Livermore National Laboratory for generating saliency maps to explain AI model predictions, focusing on efficient computation for attribution tasks.",X1;X1-04,interpretability;saliency_maps;attribution,library,Jupyter Notebook,https://github.com/LLNL/fastcam,,BSD-3-Clause,xai;saliency-map;attribution;computer-vision
424,Genome_Factory,"Integrated library for tuning, deploying, and interpreting genomic models","A comprehensive library designed for the genomics domain to facilitate the tuning, deployment, and interpretation of machine learning models applied to genomic data.",X1;X1-04;B2,genomics;model_interpretation;model_tuning,library,Python,https://github.com/MAGICS-LAB/Genome_Factory,,None,genomics;interpretability;bioinformatics;machine-learning
425,Shapash,User-friendly explainability and interpretability library for ML models,A Python library that provides visualization and interpretability tools to make machine learning models transparent and understandable for everyone.,X1;X1-04,interpretability;visualization;model_audit,library,Jupyter Notebook,https://github.com/MAIF/shapash,https://shapash.readthedocs.io,Apache-2.0,xai;visualization;shap;interpretability
426,SurvSHAP(t),Time-dependent explanations for survival analysis models,"A library for explaining machine learning survival models using time-dependent Shapley values, allowing for interpretation of predictions over time.",X1;X1-04,survival_analysis;interpretability;shapley_values,library,Jupyter Notebook,https://github.com/MI2DataLab/survshap,https://mi2datalab.github.io/survshap/,MIT,survival-analysis;xai;shap;time-series
427,Receptive Field Analysis Toolbox,Toolbox for analyzing and visualizing neural network receptive fields,"A Python toolbox designed to analyze and visualize the receptive fields of neural network architectures, aiding in model understanding and design.",X1;X1-04,model_analysis;visualization;receptive_field,library,Python,https://github.com/MLRichter/receptive_field_analysis_toolbox,,MIT,neural-networks;visualization;analysis;deep-learning
428,GRETEL,Graph Counterfactual Explanation Evaluation Framework,A framework for evaluating counterfactual explanation methods specifically for graph neural networks and graph data.,X1;X1-04,counterfactuals;graph_neural_networks;evaluation,library,Jupyter Notebook,https://github.com/MarioTheOne/GRETEL,,MIT,graph-learning;counterfactuals;xai;evaluation
429,FlashTorch,Visualization toolkit for neural networks in PyTorch,A visualization toolkit for PyTorch that helps users visualize feature maps and saliency maps to understand what neural networks have learned.,X1;X1-04,visualization;saliency_maps;feature_visualization,library,HTML,https://github.com/MisaOgura/flashtorch,,MIT,pytorch;visualization;xai;computer-vision
430,modelStudio,Interactive Studio for Explanatory Model Analysis,"An R package that generates interactive dashboards for explanatory model analysis, allowing users to explore model explanations and feature importance.",X1;X1-04,visualization;model_analysis;interactive_dashboard,library,R,https://github.com/ModelOriented/modelStudio,https://modeloriented.github.io/modelStudio/,GPL-3.0,r;xai;visualization;dashboard
431,shapr,Accurate Shapley value estimation for machine learning models,"An R package for explaining the output of machine learning models by computing estimated Shapley values, handling dependent features more accurately.",X1;X1-04,interpretability;shapley_values;feature_importance,library,HTML,https://github.com/NorskRegnesentral/shapr,https://norskregnesentral.github.io/shapr/,NOASSERTION,r;shap;xai;statistics
432,InterpretDL,Interpretation toolkit for Deep Learning models based on PaddlePaddle,"A comprehensive interpretation toolkit for deep learning models built on the PaddlePaddle framework, offering various algorithms for model explanation.",X1;X1-04,interpretability;attribution;model_analysis,library,Python,https://github.com/PaddlePaddle/InterpretDL,https://interpretdl.readthedocs.io/,Apache-2.0,paddlepaddle;xai;deep-learning;interpretability
433,VisualDL,Deep Learning Visualization Toolkit for PaddlePaddle,"A visualization tool for deep learning models, supporting scalar, image, audio, and graph visualization to assist in model training and debugging.",X1;X1-04,visualization;training_monitoring;model_graph,platform,HTML,https://github.com/PaddlePaddle/VisualDL,https://www.paddlepaddle.org.cn/paddle/visualdl,Apache-2.0,visualization;paddlepaddle;dashboard;deep-learning
434,tft-torch,Temporal Fusion Transformers for Interpretable Time Series Forecasting,"A PyTorch implementation of Temporal Fusion Transformers, designed for interpretable multi-horizon time series forecasting.",X1;X1-04,forecasting;time_series;interpretability,library,Python,https://github.com/PlaytikaOSS/tft-torch,,MIT,time-series;forecasting;pytorch;interpretability
435,ViT-Prisma,Mechanistic interpretability library for Vision Transformers,"A library dedicated to mechanistic interpretability research for Vision and Video Transformers, enabling deep analysis of model internal states.",X1;X1-04,interpretability;mechanistic_interpretability;model_analysis,library,Jupyter Notebook,https://github.com/Prisma-Multimodal/ViT-Prisma,,MIT,vision-transformers;mechanistic-interpretability;xai;research-tool
436,ann-visualizer,Python library for visualizing Artificial Neural Networks (ANN) architecture,A Python library that uses Graphviz to create a visualization of the Artificial Neural Network graph. It supports Keras and helps in understanding the model architecture.,X1;X1-04,visualization;model_inspection,library,Python,https://github.com/RedaOps/ann-visualizer,,MIT,visualization;neural-networks;keras;graphviz
437,RobustX,Benchmarking library for robustness of counterfactual explanation methods,"RobustX is an open-source Python library designed for benchmarking the robustness of counterfactual explanation (CE) methods. It provides a systematic framework for generating, evaluating, and comparing CEs with a focus on robustness.",X1;X1-04,benchmarking;counterfactual_explanation;robustness_evaluation,library,Python,https://github.com/RobustCounterfactualX/RobustX,,MIT,counterfactuals;robustness;benchmarking;xai
438,InterpretME,Interpretable machine learning pipeline over knowledge graphs,An interpretable machine learning pipeline that integrates knowledge graphs to provide enhanced interpretability for ML models. It assists in tracing predictions back to domain knowledge.,X1;X1-04,interpretability;knowledge_graph;pipeline,workflow,Jupyter Notebook,https://github.com/SDM-TIB/InterpretME,,MIT,knowledge-graph;interpretability;machine-learning;pipeline
439,alibi,Algorithms for explaining machine learning models,"Alibi is an open source Python library aimed at machine learning model inspection and interpretation. The focus of the library is to provide high-quality implementations of black-box, white-box, local and global explanation methods for classification and regression models.",X1;X1-04,interpretability;explanation;model_inspection,library,Python,https://github.com/SeldonIO/alibi,https://docs.seldon.io/projects/alibi/en/latest/,Apache-2.0,xai;interpretability;machine-learning;black-box-explanation
440,PiML-Toolbox,Python Interpretable Machine Learning toolbox for model development and diagnostics,PiML (Python Interpretable Machine Learning) is a toolbox for model development and diagnostics. It provides a suite of interpretable ML models and diagnostic tools to assess model reliability and trustworthiness.,X1;X1-04,interpretable_modeling;model_diagnostics;trustworthiness,library,Jupyter Notebook,https://github.com/SelfExplainML/PiML-Toolbox,https://selfexplainml.github.io/PiML-Toolbox/,Apache-2.0,interpretable-ml;diagnostics;trustworthiness;toolbox
441,eli5,Library for debugging/inspecting machine learning classifiers,ELI5 is a Python library which allows to visualize and debug various Machine Learning models using unified API. It has built-in support for several ML frameworks and provides ways to explain black-box models.,X1;X1-04,debugging;inspection;explanation,library,Jupyter Notebook,https://github.com/TeamHG-Memex/eli5,https://eli5.readthedocs.io/,MIT,debugging;inspection;visualization;xai
442,shapkit,Interpret machine learning predictions using Shapley Values,Shapkit provides agnostic local feature importance based on Shapley Values to interpret machine learning predictions.,X1;X1-04,feature_attribution;shapley_values;interpretability,library,Jupyter Notebook,https://github.com/ThalesGroup/shapkit,,MIT,shapley-values;feature-importance;xai
443,TransformerLens,Library for mechanistic interpretability of GPT-style language models,A library for mechanistic interpretability of GPT-style language models. It allows researchers to inspect the internal activations and weights of transformers to understand how they work.,X1;X1-04,mechanistic_interpretability;model_inspection;transformer_analysis,library,Python,https://github.com/TransformerLensOrg/TransformerLens,,MIT,mechanistic-interpretability;transformers;gpt;analysis
444,AIX360,Interpretability and explainability of data and machine learning models,The AI Explainability 360 (AIX360) toolkit is an open-source library that supports the interpretability and explainability of datasets and machine learning models. It includes a comprehensive set of algorithms for different explanation needs.,X1;X1-04,explainability;interpretability;dataset_analysis,library,Python,https://github.com/Trusted-AI/AIX360,http://aix360.mybluemix.net/,Apache-2.0,xai;explainability;toolkit;ibm
445,xaitk-saliency,Explainable AI framework for visual saliency algorithms,"XAITK-Saliency is an open source, explainable AI framework for visual saliency algorithm interfaces and implementations, built for analytics and autonomy applications. It provides a standard API for saliency generation.",X1;X1-04,saliency_map;visual_explanation;xai_framework,library,Python,https://github.com/XAITK/xaitk-saliency,https://xaitk-saliency.readthedocs.io/,Apache-2.0,saliency;xai;computer-vision;explainability
446,VaLSe,Visualization library for interpretability and hallucination analysis of Large Vision-Language Models,"A library of visualization tools designed to analyze the interpretability and hallucination phenomena in Large Vision-Language Models (LVLMs), aiding in model understanding and debugging.",X1-04;Computer Vision;NLP,interpretability;visualization;hallucination_analysis,library,Python,https://github.com/Ziwei-Zheng/VaLSe,,None,lvlm;interpretability;visualization;hallucination
447,XAI-Bench,Benchmarking library for feature attribution explainability techniques,"A library designed to benchmark and evaluate various feature attribution methods in explainable AI, providing metrics to assess the quality and reliability of explanations.",X1-04,benchmarking;evaluation;feature_attribution,library,Python,https://github.com/abacusai/xai-bench,,Apache-2.0,xai;benchmarking;feature-attribution;evaluation
448,ShapleyValueFL,Library for calculating Shapley Values in Federated Learning,"A pip-installable library for computing the marginal contribution of clients in a Federated Learning environment using Shapley Values, aiding in data valuation and incentive mechanism design.",X1-04;Federated Learning,data_valuation;shapley_value;federated_learning,library,Python,https://github.com/akassharjun/ShapleyValueFL,,MIT,federated-learning;shapley-value;data-valuation
449,pySaliencyMap,Python implementation of Itti's saliency map algorithm,"A Python implementation of the classic Itti-Koch-Niebur saliency map algorithm, used for modeling visual attention and extracting salient features in images.",X1-04;Computer Vision,saliency_detection;visual_attention;feature_extraction,library,Python,https://github.com/akisatok/pySaliencyMap,,MIT,saliency-map;computer-vision;itti-model;attention
450,familiar,End-to-end pipeline for interpretable machine learning of tabular data,"An R package that implements an end-to-end pipeline for interpretable machine learning on tabular data, including feature selection, model training, and explanation generation.",X1-04;Bioinformatics,interpretable_ml;tabular_data_analysis;feature_selection,library,R,https://github.com/alexzwanenburg/familiar,,EUPL-1.2,r-package;interpretable-ml;tabular-data;pipeline
451,ml-mycelium,Interactive web viewer for exploring large neural networks,"A web-based visualization tool designed to explore and interact with large neural network graphs, powering the visualization capabilities of systems like Talaria.",X1-04;Deep Learning,visualization;model_exploration;network_graph,library,JavaScript,https://github.com/apple/ml-mycelium,,NOASSERTION,visualization;neural-networks;interactive;graph
452,HyperSHAP,Framework for explaining hyperparameter optimization using Shapley values,"A framework that applies Shapley value-based attribution to explain the results of hyperparameter optimization (HPO) processes, helping researchers understand hyperparameter importance and interactions.",X1-04;AutoML,hpo_explanation;shapley_value;automl,framework,Python,https://github.com/automl/HyperSHAP,,BSD-3-Clause,automl;hpo;shapley-values;explainability
453,Shape As Points,Differentiable Poisson Solver for 3D shape reconstruction,"A differentiable Poisson solver that reconstructs 3D shapes from point clouds, enabling gradient-based optimization for 3D geometry tasks.",Scientific Modeling;Computer Vision,3d_reconstruction;differentiable_physics;geometry_processing,solver,Python,https://github.com/autonomousvision/shape_as_points,,MIT,3d-reconstruction;differentiable-rendering;poisson-solver;point-cloud
454,shapley,Implementation of Shapley Value for classifiers in ensemble games,"A Python library implementing the Shapley Value of Classifiers in Ensemble Games, providing attribution methods for machine learning models.",X1;X1-04,attribution;model_interpretation,library,Python,https://github.com/benedekrozemberczki/shapley,,MIT,shapley-values;xai;attribution
455,fastshap,Fast approximate Shapley values in R,"An R package for computing fast approximate Shapley values, enabling efficient feature attribution for machine learning models.",X1;X1-04,attribution;model_interpretation,library,R,https://github.com/bgreenwell/fastshap,,None,r-package;shapley-values;xai
456,CARLA,Benchmark library for algorithmic recourse and counterfactual explanations,"A Python library designed to benchmark and evaluate algorithmic recourse and counterfactual explanation algorithms, providing a standardized framework for XAI research.",X1;X1-04,benchmarking;counterfactual_explanation,library,Python,https://github.com/carla-recourse/CARLA,,MIT,counterfactuals;benchmarking;xai
457,transformers-interpret,Model explainability for Hugging Face Transformers,"A Python package providing model explainability features specifically for Transformers models, enabling easy visualization of feature attribution.",X1;X1-04,model_interpretation;attribution,library,Jupyter Notebook,https://github.com/cdpierse/transformers-interpret,,Apache-2.0,transformers;nlp;xai
458,shap-hypetune,Hyperparameter tuning and feature selection using SHAP,"A Python package for simultaneous hyperparameter tuning and feature selection for gradient boosting models, leveraging SHAP values for feature importance.",X1;X1-04,feature_selection;hyperparameter_tuning,library,Jupyter Notebook,https://github.com/cerlymarco/shap-hypetune,,MIT,shap;automl;feature-selection
459,mace,Model Agnostic Counterfactual Explanations,"A Python library for generating model-agnostic counterfactual explanations, aiding in the interpretation of machine learning models.",X1;X1-04,counterfactual_explanation;model_interpretation,library,Python,https://github.com/charmlab/mace,,None,counterfactuals;xai;model-agnostic
460,counterfactuals,R package for Counterfactual Explanation Methods,"An R package providing various methods for generating counterfactual explanations for machine learning models, facilitating model interpretability.",X1;X1-04,counterfactual_explanation;model_interpretation,library,HTML,https://github.com/dandls/counterfactuals,,LGPL-3.0,r-package;counterfactuals;xai
461,CVVideoPlayer,Video player for CV model debugging and analysis,"A Python-based customizable video player designed for computer vision practitioners to develop, analyze, and debug video-related algorithms and models.",X1;X1-04,visualization;debugging,solver,Python,https://github.com/danieltomer1/CVVideoPlayer,,MIT,computer-vision;debugging;visualization
462,darkon,Toolkit to Hack Your Deep Learning Models,"A toolkit for understanding deep learning models, providing methods for influence analysis and visualization to interpret model behavior.",X1;X1-04,model_interpretation;influence_analysis,library,Python,https://github.com/darkonhub/darkon,,Apache-2.0,xai;influence-functions;visualization
463,portal,Visualization tool for deep neural networks,"A tool to load and visualize deep neural networks on images and videos, facilitating model inspection and debugging.",X1;X1-04,visualization;model_inspection,platform,Python,https://github.com/datature/portal,,Apache-2.0,visualization;computer-vision;deep-learning
464,xplique,Neural Networks Explainability Toolbox,A comprehensive Neural Networks Explainability Toolbox providing a wide range of attribution methods and visualization tools for XAI.,X1;X1-04,model_interpretation;attribution;visualization,library,Python,https://github.com/deel-ai/xplique,,NOASSERTION,xai;explainability;attribution
465,LIMES,Link discovery framework for metric spaces and knowledge graphs,"A framework for link discovery on the Semantic Web, implementing time-efficient approaches for large-scale link discovery in metric spaces.",X1;Data Science,data_alignment;link_discovery,workflow,Java,https://github.com/dice-group/LIMES,,AGPL-3.0,semantic-web;link-discovery;knowledge-graph
466,DICe,Digital Image Correlation Engine for material deformation analysis,"A stereo Digital Image Correlation (DIC) application that computes full-field displacement and strain from sequences of digital images, used in experimental mechanics.",Materials Science;Physics,image_analysis;deformation_measurement,solver,C++,https://github.com/dicengine/dice,https://dicengine.github.io/dice/,NOASSERTION,digital-image-correlation;strain-measurement;experimental-mechanics
467,Concept-based XAI,Library for concept-based and disentanglement learning methods in XAI,"A Python library implementing state-of-the-art Concept-based Explainable AI methods, focusing on disentanglement learning to provide human-interpretable explanations.",X1-04,interpretability;concept_learning,library,Python,https://github.com/dmitrykazhdan/concept-based-xai,,MIT,xai;concept-based-explanations;disentanglement
468,GNNLens2,Interactive visualization tool for Graph Neural Networks,A visualization tool designed to help researchers and developers understand and debug Graph Neural Networks (GNNs) through interactive graph exploration.,X1-04;Graph Learning,visualization;model_debugging,solver,TypeScript,https://github.com/dmlc/GNNLens2,,Apache-2.0,gnn;visualization;graph-neural-networks
469,dominance-analysis,Library for dominance analysis and Shapley Value Regression,A Python package for determining the relative importance of predictors in statistical models using dominance analysis and Shapley Value Regression.,X1-04;Statistics,feature_importance;statistical_analysis,library,Python,https://github.com/dominance-analysis/dominance-analysis,,MIT,shapley-value;feature-importance;regression-analysis
470,SBSCL,Systems Biology Simulation Core Library,"A Java implementation for interpreting and simulating models encoded in the Systems Biology Markup Language (SBML), providing numerical solution methods.",Systems Biology,simulation;model_interpretation,library,Java,https://github.com/draeger-lab/SBSCL,,LGPL-3.0,sbml;systems-biology;simulation
471,DataScope,Tool for measuring data importance in ML pipelines,"A library for measuring the importance of training data points in machine learning pipelines using Shapley values, facilitating data debugging and selection.",X1-04;Data-Centric AI,data_valuation;attribution,library,Python,https://github.com/easeml/datascope,,MIT,shapley-value;data-importance;ml-debugging
472,ELI5,Library for debugging and explaining machine learning classifiers,"A Python library for inspecting machine learning classifiers and explaining their predictions, supporting various frameworks like scikit-learn and XGBoost.",X1-04,interpretability;model_debugging,library,Python,https://github.com/eli5-org/eli5,https://eli5.readthedocs.io/,MIT,xai;model-inspection;feature-importance
473,emergent,Biologically based neural network simulator,"A comprehensive simulation environment for biologically based neural networks of the brain, featuring a 3D GUI and written in Go.",Neuroscience;Computational Biology,simulation;neural_modeling,platform,Go,https://github.com/emer/emergent,https://github.com/emer/emergent/wiki,BSD-3-Clause,neuroscience;neural-network-simulation;brain-modeling
474,BioData,Arduino library for interpreting biological signals,An Arduino library designed to facilitate the reading and interpretation of biological signals such as GSR and EMG for experimental data acquisition.,Biomedical Engineering,data_acquisition;signal_processing,library,C++,https://github.com/eringee/BioData,,GPL-3.0,arduino;biosignals;sensor-interface
475,LIME-MATLAB,Low-Light Image Enhancement via Illumination Map Estimation,"A MATLAB implementation of the LIME algorithm for enhancing low-light images by estimating illumination maps, used in image processing research.",Image Processing,image_enhancement;illumination_estimation,solver,MATLAB,https://github.com/estija/LIME,,None,image-enhancement;low-light;matlab
476,Netscope,Web-based neural network architecture visualizer,"A tool for visualizing the structure of neural networks, particularly supporting Caffe prototxt format, aiding in model design and inspection.",Deep Learning,visualization;model_inspection,solver,JavaScript,https://github.com/ethereon/netscope,http://ethereon.github.io/netscope/,None,neural-network-visualization;caffe;model-graph
477,deep-viz-keras,Saliency map implementations for Keras models,"A toolkit providing implementations of popular saliency map algorithms (like Saliency Maps, Grad-CAM) for visualizing and interpreting Keras models.",X1-04,interpretability;visualization,library,Jupyter Notebook,https://github.com/experiencor/deep-viz-keras,,None,saliency-maps;keras;visualization
478,explainX,Explainable AI framework for data scientists,"An open-source library for explaining and debugging black-box machine learning models, providing dashboards and metrics for model interpretability.",X1-04,interpretability;model_debugging,workflow,Jupyter Notebook,https://github.com/explainX/explainx,,MIT,xai;model-explanation;dashboard
479,ELI5 Dataset Scripts,Scripts to recreate the ELI5 (Explain Like I'm 5) dataset,"Provides the necessary scripts and documentation to download, process, and recreate the ELI5 dataset, a benchmark for question answering and explanation generation.",NLP;X1-04,dataset_creation;data_processing,dataset,Python,https://github.com/facebookresearch/ELI5,,NOASSERTION,dataset;nlp;question-answering
480,PytorchRevelio,Visualization toolkit for PyTorch neural networks,"A toolkit for visualizing learned features in PyTorch models, including implementations of Saliency Maps, Grad-CAM, and DeepDream.",X1-04,visualization;interpretability,library,Python,https://github.com/farhad-dalirani/PytorchRevelio,,MIT,pytorch;visualization;grad-cam
481,BME280 Library,Arduino library for BME280 environmental sensor,"A library for interfacing with the Bosch BME280 sensor to read temperature, humidity, and pressure data, facilitating environmental data acquisition.",Environmental Science;IoT,data_acquisition;sensor_interface,library,C++,https://github.com/finitespace/BME280,,GPL-3.0,arduino;sensor;environmental-data
482,ML Fairness Framework,Fairness and robustness framework for LightGBM,"A framework (FairPut) designed to enhance fairness, robustness, and explainability in machine learning models, specifically targeting LightGBM implementations.",X1-04;X1-01,fairness_audit;model_optimization,workflow,Jupyter Notebook,https://github.com/firmai/ml-fairness-framework,,None,fairness;lightgbm;robustness
483,TSInterpret,Interpretability library for time series classifiers,"An open-source Python library dedicated to the interpretability of time series classification models, providing various attribution and explanation methods tailored for temporal data.",X1;X1-04,interpretability;time_series_analysis,library,Python,https://github.com/fzi-forschungszentrum-informatik/TSInterpret,,BSD-3-Clause,time-series;interpretability;xai;classification
484,cnnshapes,CNN intermediate activation visualizer for Keras,"A tool for visualizing intermediate activations in Convolutional Neural Networks (CNNs) built with Keras, aiding in the understanding of feature extraction processes.",X1;X1-04,visualization;model_debugging,library,Python,https://github.com/gabrielpierobon/cnnshapes,,None,keras;cnn;visualization;activations
485,iml,Interpretable Machine Learning R package,"An R package that provides a toolbox for analyzing and interpreting machine learning models, featuring model-agnostic methods like partial dependence plots, feature importance, and Shapley values.",X1;X1-04,interpretability;model_analysis,library,R,https://github.com/giuseppec/iml,,NOASSERTION,r;interpretability;machine-learning;feature-importance
486,Model Explorer,Modern model graph visualizer and debugger,"A visualization tool designed to help researchers and engineers visualize, debug, and understand the structure and behavior of complex machine learning models.",X1;X1-04,visualization;model_debugging,platform,JavaScript,https://github.com/google-ai-edge/model-explorer,,Apache-2.0,visualization;neural-networks;debugging;graph
487,Penzai,JAX toolkit for building and visualizing neural networks,"A JAX-based research toolkit that facilitates the construction, editing, and visualization of neural networks, designed to support interpretability research and model understanding.",X1;X1-04,modeling;visualization;interpretability,library,Python,https://github.com/google-deepmind/penzai,,Apache-2.0,jax;neural-networks;visualization;interpretability
488,Yggdrasil Decision Forests,Library for decision forest models,"A library to train, evaluate, interpret, and productionize decision forest models such as Random Forest and Gradient Boosted Decision Trees, with a focus on efficiency and interpretability.",X1;X1-04,modeling;interpretability,library,C++,https://github.com/google/yggdrasil-decision-forests,https://yggdrasil-decision-forests.github.io/,Apache-2.0,decision-forests;random-forest;gbdt;interpretability
489,Booster,Accelerator for LLM inference and debugging,An open accelerator tool designed to improve inference performance and provide debugging capabilities for Large Language Models (LLMs).,X1,inference;model_debugging,solver,C++,https://github.com/gotzmann/booster,,NOASSERTION,llm;inference;optimization;debugging
490,OptBinning,Optimal binning and scorecard modelling library,"A library for optimal binning with constraints, supporting batch and stream processing, scorecard modelling, and counterfactual explanations for credit risk and other applications.",X1;X1-04,modeling;interpretability;counterfactuals,library,Python,https://github.com/guillermo-navas-palencia/optbinning,,Apache-2.0,binning;scorecard;counterfactuals;credit-risk
491,Blase,Interpretable ML for astronomical spectroscopy,"A PyTorch and JAX-based library for interpretable machine learning applications in astronomical spectroscopy, enabling analysis of spectral data.",X1;X1-04;Astronomy,scientific_analysis;modeling,library,Jupyter Notebook,https://github.com/gully/blase,,MIT,astronomy;spectroscopy;interpretability;pytorch
492,DeepVisualization,Deep Neural Network visualization tool,A MATLAB-based tool for visualizing Deep Neural Networks by alternately applying image blurring and deblurring techniques to reveal feature activations.,X1;X1-04,visualization;model_analysis,library,MATLAB,https://github.com/happynear/DeepVisualization,,MIT,matlab;visualization;cnn;deep-learning
493,IntegratedGradients,Integrated Gradients implementation for Keras,A Python/Keras implementation of the Integrated Gradients axiomatic attribution method for explaining deep network predictions.,X1;X1-04,attribution;interpretability,library,Jupyter Notebook,https://github.com/hiranumn/IntegratedGradients,,MIT,integrated-gradients;keras;attribution;xai
494,DiceLoss-PyTorch,Dice Loss implementation for PyTorch,"A reusable implementation of Dice Loss for PyTorch, supporting both binary and multi-class segmentation tasks, commonly used in medical image analysis.",Computer Vision;Modeling,modeling;loss_function,library,Python,https://github.com/hubutui/DiceLoss-PyTorch,,None,pytorch;dice-loss;segmentation;medical-imaging
495,Saliency,PyTorch implementation of various saliency mapping methods for model interpretability,"A PyTorch library implementing 'Vanilla' Gradient, Grad-CAM, Guided Backprop, Integrated Gradients, and SmoothGrad variants for explaining deep learning model predictions.",X1;X1-04,interpretability;attribution,library,Jupyter Notebook,https://github.com/hummat/saliency,,GPL-3.0,pytorch;saliency-maps;grad-cam;xai
496,FastSHAP,Amortized approach for calculating local Shapley value explanations,"A Python library for fast estimation of Shapley values to explain model predictions, utilizing an amortized approach to speed up computation compared to standard sampling methods.",X1;X1-04,interpretability;attribution,library,Python,https://github.com/iancovert/fastshap,,MIT,shapley-values;feature-importance;xai
497,SAGE,Global feature importance calculation using Shapley values,"Shapley Additive Global Importance (SAGE) is a method for quantifying the global importance of features in machine learning models, providing a theoretically sound alternative to permutation importance.",X1;X1-04,interpretability;feature_importance,library,Python,https://github.com/iancovert/sage,,MIT,shapley-values;global-importance;xai
498,Shapley Regression,Calculation of Shapley values via linear regression,"A library implementing methods to estimate Shapley values by formulating the problem as a weighted linear regression, enabling efficient attribution for machine learning models.",X1;X1-04,interpretability;attribution,library,Python,https://github.com/iancovert/shapley-regression,,MIT,shapley-values;regression;xai
499,FullGrad Saliency,Full-gradient saliency maps for neural network interpretation,"Implementation of Full-Gradient Saliency Maps, a method that aggregates gradients from all layers to provide a more complete explanation of neural network predictions.",X1;X1-04,interpretability;saliency_map,library,Python,https://github.com/idiap/fullgrad-saliency,,NOASSERTION,saliency-maps;deep-learning;xai
500,Inseq,Interpretability toolkit for sequence generation models,"A toolkit for interpreting sequence generation models (like Transformers) in NLP and potentially biological sequence analysis, offering feature attribution and visualization methods.",X1;X1-04;Bioinformatics,interpretability;sequence_analysis,library,Python,https://github.com/inseq-team/inseq,https://inseq.readthedocs.io,Apache-2.0,nlp;transformers;attribution;sequence-generation
501,DiCE,Diverse Counterfactual Explanations for machine learning models,"A library for generating diverse counterfactual explanations for any machine learning model, helping to understand how to change inputs to achieve a desired prediction.",X1;X1-04,interpretability;counterfactuals,library,Python,https://github.com/interpretml/DiCE,https://interpretml.github.io/DiCE/,MIT,counterfactuals;xai;machine-learning
502,InterpretML,Toolkit for fitting interpretable models and explaining blackbox models,A comprehensive package for training interpretable models (like EBMs) and explaining blackbox systems using methods like SHAP and LIME. It serves as a unified framework for model interpretability.,X1;X1-04,interpretability;modeling,library,C++,https://github.com/interpretml/interpret,https://interpret.ml,MIT,ebm;shap;lime;glassbox
503,dev-survivors,Reliable and interpretable survival analysis library,"A Python library for survival analysis, providing interpretable models and reliable metrics for time-to-event data, commonly used in medical and biological research.",X1;X1-04;Biostatistics,survival_analysis;modeling,library,Python,https://github.com/iuliivasilev/dev-survivors,,BSD-3-Clause,survival-analysis;interpretability;time-to-event
504,BioAutoMATED,Automated machine learning for biological sequence analysis and design,"An automated machine learning system specifically designed for analyzing, interpreting, and designing biological sequences (DNA, proteins), facilitating model selection and interpretation for biologists.",Biology;X1-04,modeling;sequence_design;interpretability,workflow,Jupyter Notebook,https://github.com/jackievaleri/BioAutoMATED,,MIT,automl;biology;sequences;synthetic-biology
505,Saliency from Backproj,Saliency map generation via histogram back-projection,"A lightweight tool to generate saliency maps by back-projecting image histograms and refining with GrabCut, useful for basic image region importance analysis.",X1-04;Computer Vision,interpretability;saliency_map,solver,Python,https://github.com/jacobgil/saliency-from-backproj,,None,saliency;image-processing;grabcut
506,Time Interpret,Unified model interpretability library for time series,"A Python library dedicated to interpreting machine learning models applied to time series data, offering methods tailored for temporal dependencies and feature importance.",X1;X1-04,interpretability;time_series_analysis,library,Python,https://github.com/josephenguehard/time_interpret,,MIT,time-series;xai;feature-importance
507,CF-SHAP,Counterfactual SHAP framework for feature importance,A framework combining counterfactual explanations with Shapley values to provide feature importance scores that reflect the changes needed to alter a model's prediction.,X1;X1-04,interpretability;counterfactuals;attribution,library,HTML,https://github.com/jpmorganchase/cf-shap,,Apache-2.0,shap;counterfactuals;xai
508,nn_vis,Neural network visualization and rendering tool,A tool for processing neural network architectures and rendering decluttered visualizations to gain insights into model structure and parameters.,X1-04,visualization;model_inspection,solver,Python,https://github.com/julrog/nn_vis,,MIT,neural-networks;visualization;architecture
509,Visualize Neural Network,Tool to visualize neural network architectures with weights,"A Python utility to generate visualizations of neural network structures, optionally displaying weight connections, aiding in model understanding and debugging.",X1-04,visualization;model_inspection,solver,Python,https://github.com/jzliu-100/visualize-neural-network,,GPL-3.0,visualization;neural-networks;weights
510,tf-keras-vis,Neural network visualization toolkit for tf.keras,"A visualization toolkit for TensorFlow Keras models, supporting various saliency map methods (Grad-CAM, Saliency, etc.) to interpret model decisions.",X1;X1-04,interpretability;visualization,library,Python,https://github.com/keisen/tf-keras-vis,https://keisen.github.io/tf-keras-vis-docs/,MIT,keras;tensorflow;visualization;grad-cam
511,Interpret,PyTorch implementation of SmoothGrad and Integrated Gradients for NLP,A PyTorch library implementing interpretability methods like SmoothGrad and Integrated Gradients specifically tailored for Natural Language Processing models.,X1;X1-04,interpretability;attribution,library,Python,https://github.com/koren-v/Interpret,,None,nlp;pytorch;integrated-gradients;xai
512,PIZZA,Attribution library for Large Language Models,"A library designed for attribution analysis in Large Language Models (LLMs), helping to identify which parts of the input contribute to the model's generation.",X1;X1-04,interpretability;attribution,library,Python,https://github.com/leap-laboratories/PIZZA,,NOASSERTION,llm;attribution;xai
513,NNView,Neural network architecture visualizer,"A C-based library for visualizing the structure and connectivity of neural networks, aiding in model understanding and debugging.",X1;X1-04,model_visualization;interpretability,library,C,https://github.com/lighttransport/nnview,,MIT,visualization;neural-networks;debugging
514,FastTreeSHAP,Fast SHAP value computation for tree-based models,A Python package designed to accelerate the computation of SHAP (SHapley Additive exPlanations) values for interpreting predictions from tree ensemble models.,X1;X1-04,interpretability;feature_attribution,library,Python,https://github.com/linkedin/FastTreeSHAP,,BSD-2-Clause,shap;tree-models;explainable-ai
515,TE2Rules,Rule-based explainer for Tree Ensemble models,"A Python library that translates Tree Ensemble models (like XGBoost) into a list of interpretable rules, facilitating model transparency and verification.",X1;X1-04,interpretability;model_translation,library,Python,https://github.com/linkedin/TE2Rules,,NOASSERTION,xgboost;rule-extraction;explainable-ai
516,DeepVis-PredDiff,Prediction Difference Analysis for DNN visualization,"A tool for visualizing deep neural network decisions using Prediction Difference Analysis, helping to identify which input features contribute to specific predictions.",X1;X1-04,interpretability;visualization,library,Python,https://github.com/lmzintgraf/DeepVis-PredDiff,,MIT,visualization;deep-learning;attribution
517,KRLS,Kernel-based Regularized Least Squares for interpretable modeling,"An R package implementing Kernel-based Regularized Least Squares (KRLS), a machine learning technique to fit flexible, interpretable functional forms for continuous and binary outcomes without strong parametric assumptions.",X1;X1-04,modeling;statistical_inference,library,R,https://github.com/lukesonnet/KRLS,,NOASSERTION,statistics;interpretable-ml;regression
518,Netron,Visualizer for neural network and ML models,"A viewer for neural network, deep learning, and machine learning models. It supports visualizing the architecture of models exported in various formats (ONNX, Keras, Core ML, etc.).",X1;X1-04,model_visualization;inspection,platform,JavaScript,https://github.com/lutzroeder/netron,https://netron.app,MIT,visualization;onnx;deep-learning
519,DeepExplain,Perturbation and gradient-based attribution framework,"A unified framework for Deep Neural Network interpretability, implementing various perturbation and gradient-based attribution methods, including support for Shapley Values sampling.",X1;X1-04,interpretability;attribution,library,Python,https://github.com/marcoancona/DeepExplain,,MIT,gradient-attribution;shapley-values;pytorch
520,LIME,Local Interpretable Model-agnostic Explanations,A widely used library for explaining the predictions of any machine learning classifier by approximating it locally with an interpretable model.,X1;X1-04,interpretability;local_explanation,library,JavaScript,https://github.com/marcotcr/lime,,BSD-2-Clause,model-agnostic;explanation;classifier
521,SEARs,Semantically Equivalent Adversarial Rules for NLP debugging,A tool for debugging NLP models by generating semantically equivalent adversarial rules to identify model inconsistencies and bugs.,X1;X1-04,debugging;adversarial_testing,library,Python,https://github.com/marcotcr/sears,,BSD-2-Clause,nlp;debugging;adversarial
522,ENNUI,Drag-and-drop neural network builder and visualizer,"An interactive user interface to build neural networks via drag-and-drop, train them in the browser, visualize the training process, and export the model to Python.",X1;X1-04,modeling;visualization;education,platform,TypeScript,https://github.com/martinjm97/ENNUI,https://math.mit.edu/ennui/,MIT,gui;neural-network-builder;visualization
523,shapefile,Streaming parser for ESRI Shapefile format,"A cross-platform streaming parser for the ESRI Shapefile spatial data format, essential for processing geospatial data in scientific research.",X1,data_processing;geospatial_analysis,library,JavaScript,https://github.com/mbostock/shapefile,,NOASSERTION,gis;geospatial;data-parsing
524,TensorCast.jl,Tensor manipulation and broadcasting for Julia,"A Julia library for convenient tensor slicing, dicing, and splicing using Einstein summation-like notation, facilitating scientific computing and modeling.",X1,scientific_computing;tensor_operations,library,Julia,https://github.com/mcabbott/TensorCast.jl,,NOASSERTION,julia;tensor;broadcasting
525,LM-Debugger,Interactive inspection tool for transformer language models,"An interactive tool for inspection and intervention in transformer-based language models, allowing researchers to debug and understand model behavior.",X1;X1-04,debugging;interpretability,solver,Python,https://github.com/mega002/lm-debugger,,Apache-2.0,transformers;debugging;nlp
526,shape_based_matching,Implementation of Halcon-like shape based matching,"An implementation of shape-based matching algorithms for computer vision, useful for object detection and alignment in scientific imaging tasks.",X1,image_analysis;object_detection,library,C++,https://github.com/meiqua/shape_based_matching,,BSD-2-Clause,computer-vision;pattern-matching;halcon
527,debug-mistakes-cce,Conceptual counterfactual explanations for model debugging,"A tool for debugging model mistakes using conceptual counterfactual explanations, helping to identify high-level conceptual errors in model reasoning.",X1;X1-04,debugging;counterfactuals,library,Python,https://github.com/mertyg/debug-mistakes-cce,,MIT,debugging;counterfactuals;concepts
528,Captum,Model interpretability and understanding for PyTorch,"A comprehensive library for model interpretability in PyTorch, offering a wide range of attribution algorithms (Integrated Gradients, DeepLIFT, SHAP, etc.) to understand model predictions.",X1;X1-04,interpretability;attribution,library,Python,https://github.com/meta-pytorch/captum,https://captum.ai,BSD-3-Clause,pytorch;interpretability;feature-attribution
529,vision-explanation-methods,Saliency map generation for computer vision models,A library implementing various methods for creating saliency maps to explain the predictions of computer vision models.,X1;X1-04,interpretability;saliency_maps,library,Python,https://github.com/microsoft/vision-explanation-methods,,MIT,computer-vision;saliency;explanation
530,TSCaptum,Captum wrapper for Time Series XAI,A wrapper around the Captum library specifically designed to facilitate explainable AI (XAI) for time series data and models.,X1;X1-04,interpretability;time_series_analysis,library,TypeScript,https://github.com/mlgig/tscaptum,,MIT,time-series;captum;xai
531,shapiq,Shapley Interactions and Values for Machine Learning,"A Python library for computing Shapley values and Shapley interactions to explain machine learning models, focusing on higher-order feature interactions.",X1;X1-04,interpretability;interaction_quantification,library,Python,https://github.com/mmschlk/shapiq,https://shapiq.readthedocs.io/,MIT,shapley-values;interactions;game-theory
532,DeepGaze,Computer Vision library for HCI and gaze estimation,"A computer vision library implementing head pose estimation, gaze direction estimation, and saliency mapping, widely used in human-computer interaction and behavioral research.",X1,image_analysis;behavioral_analysis,library,Python,https://github.com/mpatacchiola/deepgaze,,MIT,gaze-estimation;head-pose;saliency
533,x264_saliency_mod,x264 encoder with custom saliency map support,A modification of the x264 video encoder that supports custom saliency maps as input to improve the perceptual quality of salient objects in video compression.,X1,data_processing;video_compression,solver,C,https://github.com/msu-video-group/x264_saliency_mod,,GPL-2.0,video-encoding;saliency;compression
534,Archipelago,Interpretable attribution for feature interactions,"A tool for generating interpretable attributions for feature interactions in machine learning models, helping to understand how features combine to affect predictions.",X1;X1-04,interpretability;interaction_analysis,library,Python,https://github.com/mtsang/archipelago,,NOASSERTION,feature-interactions;attribution;xai
535,shapy,3D body shape regression model using metric and semantic attributes,"A framework for accurate 3D body shape regression that leverages metric and semantic attributes to provide interpretable control over the generated shapes, useful for computer vision and anthropometric analysis.",Computer Vision;X1-04,scientific_modeling;inference,solver,Python,https://github.com/muelea/shapy,,None,3d-reconstruction;body-shape;attributes;interpretability
536,AutoScore,Interpretable ML-based automatic clinical score generator,"An R package that automatically generates interpretable clinical scoring models from machine learning based variable selection, designed for medical research and clinical decision support.",Medical Informatics;X1-04,scientific_modeling;clinical_scoring,library,R,https://github.com/nliulab/AutoScore,,None,clinical-scores;interpretable-ml;healthcare
537,ShapleyVIC,Shapley Variable Importance Cloud for interpretable machine learning,"A tool for visualizing and interpreting variable importance in machine learning models using Shapley values, providing a 'cloud' visualization to understand global and local feature effects.",X1-04,model_interpretation;visualization,library,R,https://github.com/nliulab/ShapleyVIC,,NOASSERTION,shapley-values;visualization;variable-importance
538,ShapML.jl,Julia package for interpretable ML with stochastic Shapley values,"A Julia library that implements stochastic Shapley value estimation for interpreting machine learning models, offering performance benefits for large datasets.",X1-04,model_interpretation,library,Julia,https://github.com/nredell/ShapML.jl,,MIT,julia;shapley-values;interpretable-ml
539,shapFlex,R package for asymmetric Shapley values and causality assessment,"An R package designed to compute asymmetric Shapley values, allowing researchers to assess causal relationships and feature importance in trained machine learning models.",X1-04;Causal Inference,causal_inference;model_interpretation,library,R,https://github.com/nredell/shapFlex,,NOASSERTION,causality;shapley-values;r-package
540,explanation_explorer,User interface to interpret machine learning models,"A web-based user interface that allows users to interactively explore and interpret predictions from machine learning models, facilitating error analysis and model understanding.",X1-04,visualization;model_debugging,platform,JavaScript,https://github.com/nyuvis/explanation_explorer,,BSD-3-Clause,ui;interactive-visualization;xai
541,explainerdashboard,Framework to build interactive Explainable AI dashboards,"A Python library that allows users to quickly build and deploy interactive web-based dashboards for explaining the inner workings of machine learning models, including feature importance, shapley values, and individual predictions.",X1-04,visualization;reporting,library,Python,https://github.com/oegedijk/explainerdashboard,http://explainerdashboard.readthedocs.io/,MIT,dashboard;shap;interactive;model-monitoring
542,shap-e,Conditional 3D object generation model,"A generative model that produces 3D objects (represented as implicit functions) conditioned on text or images, useful for synthesizing 3D assets for simulation and modeling.",Computer Vision;Generative AI,scientific_data_generation;3d_modeling,solver,Python,https://github.com/openai/shap-e,,MIT,generative-model;text-to-3d;image-to-3d
543,OpenVINO XAI,Explainable AI toolkit for OpenVINO models,"A toolkit providing visual explanation algorithms (like saliency maps) for models optimized with OpenVINO, enabling interpretation of inference results on edge devices.",X1-04;Edge AI,model_interpretation;inference,library,Python,https://github.com/openvinotoolkit/openvino_xai,,Apache-2.0,openvino;saliency-map;edge-inference
544,Visual-Feature-Attribution-VAGANs,Visual Feature Attribution using Wasserstein GANs,A PyTorch implementation of Visual Feature Attribution using Wasserstein GANs (VAGANs) to generate counterfactual maps for explaining classifier decisions in medical imaging and other domains.,X1-04;Medical Imaging,model_interpretation;counterfactual_generation,solver,Python,https://github.com/orobix/Visual-Feature-Attribution-Using-Wasserstein-GANs-Pytorch,,MIT,gan;counterfactuals;feature-attribution
545,LimeGPS,Real-time GPS signal simulator for LimeSDR,"A command-line tool that generates GPS L1 signals for transmission via LimeSDR, used for testing GPS receivers and conducting GNSS research.",Signal Processing;Navigation,scientific_data_generation;simulation,solver,C,https://github.com/osqzss/LimeGPS,,MIT,gps;sdr;simulator
546,ICE,Interactive Composition Explorer for language model programs,"A visual debugger and interactive exploration tool for compositional language model programs, helping researchers understand and debug complex chains of LLM calls.",X1-04;NLP,model_debugging;visualization,platform,Python,https://github.com/oughtinc/ice,,MIT,llm;debugging;compositionality
547,stanford-shapenet-renderer,Batch rendering scripts for ShapeNet models,"A set of Blender scripts for batch rendering 3D models from the ShapeNet dataset, facilitating the creation of 2D image datasets for computer vision research.",Computer Vision,scientific_data_processing;rendering,workflow,Python,https://github.com/panmari/stanford-shapenet-renderer,,MIT,blender;shapenet;rendering
548,Concuerror,Stateless model checking tool for Erlang programs,"A systematic testing tool (model checker) for concurrent Erlang programs that explores execution interleavings to detect concurrency errors, serving the domain of formal verification.",X1;Formal Methods,verification;model_checking,solver,Erlang,https://github.com/parapluu/Concuerror,http://parapluu.github.io/Concuerror/,BSD-2-Clause,model-checking;concurrency;erlang
549,visualkeras,Visualization library for Keras neural network architectures,"A Python package to generate layered or graph-style visualizations of Keras/TensorFlow neural network architectures, useful for scientific communication and model documentation.",X1-04,scientific_visualization;model_documentation,library,Python,https://github.com/paulgavrikov/visualkeras,,MIT,keras;visualization;neural-networks
550,CoMTE,Counterfactual Explanations for Multivariate Time Series,"A library for generating counterfactual explanations specifically for multivariate time series classifiers, helping to identify minimal changes needed to alter model predictions.",X1-04;Time Series,model_interpretation;counterfactual_generation,library,Jupyter Notebook,https://github.com/peaclab/CoMTE,,BSD-3-Clause,time-series;counterfactuals;xai
551,webshap,In-browser Shapley value computation library,"A JavaScript library that enables the computation of Shapley values directly in the web browser, allowing for client-side, privacy-preserving machine learning model explanation.",X1-04,model_interpretation,library,TypeScript,https://github.com/poloclub/webshap,,MIT,javascript;shapley-values;client-side-ml
552,secml,Library for Secure and Explainable Machine Learning,"A Python library designed for the security evaluation of machine learning algorithms, providing tools for adversarial attacks, robustness testing, and explainability.",X1;X1-04,security_evaluation;model_interpretation,library,Jupyter Notebook,https://github.com/pralab/secml,https://secml.readthedocs.io/,Apache-2.0,adversarial-ml;security;explainability
553,PyC (Pytorch Concepts),Library for training concept-based interpretable deep learning models,"PyC is a PyTorch-based library designed to facilitate the training and evaluation of concept-based interpretable deep learning models, enabling users to define and utilize high-level concepts for model explanations.",X1-04;Computer Science,interpretability;concept_learning,library,Python,https://github.com/pyc-team/pytorch_concepts,,Apache-2.0,pytorch;interpretability;concept-based-learning;xai
554,XRD Symmetry Prediction,Interpretable ML for symmetry prediction from X-ray diffraction patterns,"A tool leveraging interpretable machine learning approaches to predict symmetry and discover knowledge from X-ray diffraction (XRD) patterns, specifically designed for materials science applications.",X1-04;Materials Science,scientific_inference;interpretability;pattern_recognition,solver,Jupyter Notebook,https://github.com/quantumbeam/xrd-symmetry-prediction,,MIT,xrd;materials-science;interpretable-ml;symmetry-prediction
555,Zennit-CRP,XAI toolkit for Concept Relevance Propagation and Relevance Maximization,"An Explainable AI (XAI) toolkit that implements Concept Relevance Propagation (CRP) and Relevance Maximization, allowing for detailed attribution and visualization of neural network decisions.",X1-04;Computer Science,attribution;visualization;model_debugging,library,Jupyter Notebook,https://github.com/rachtibat/zennit-crp,,NOASSERTION,xai;concept-relevance-propagation;attribution;visualization
556,keras-vis,Neural network visualization toolkit for Keras,"A toolkit for visualizing and debugging trained Keras neural network models. It provides implementations for saliency maps, activation maximization, and class activation maps to interpret model behavior.",X1-04;Computer Science,visualization;saliency_maps;model_debugging,library,Python,https://github.com/raghakot/keras-vis,https://raghakot.github.io/keras-vis/,MIT,keras;visualization;saliency-maps;grad-cam
557,TCAV (PyTorch),Quantitative testing with Concept Activation Vectors in PyTorch,"A PyTorch implementation of Testing with Concept Activation Vectors (TCAV), a method to interpret the internal state of deep learning models using high-level concepts.",X1-04;Computer Science,interpretability;concept_activation,library,Python,https://github.com/rakhimovv/tcav,,None,tcav;pytorch;interpretability;concept-activation-vectors
558,Causing,Causal interpretation using graphs,"A Python package for causal interpretation using structural equation models and graphs, allowing for the analysis of causal effects in multivariate data.",X1-04;Statistics,causal_inference;structural_equation_modeling,library,Python,https://github.com/realrate/Causing,,MIT,causality;structural-equation-modeling;interpretation;graphs
559,ShapleyR,Shapley value usage for mlr in R,An R package designed to facilitate the calculation and usage of Shapley values for model interpretation within the mlr (Machine Learning in R) framework.,X1-04;Statistics,interpretability;feature_importance,library,R,https://github.com/redichh/ShapleyR,,None,r;shapley-values;mlr;interpretability
560,pastalog,Realtime visualization of neural network training performance,"A simple, realtime visualization server for monitoring neural network training metrics, useful for tracking model performance and convergence.",X1;Computer Science,visualization;training_monitoring,platform,JavaScript,https://github.com/rewonc/pastalog,,MIT,visualization;deep-learning;monitoring;training-metrics
561,SIRUS.jl,Interpretable Machine Learning via Rule Extraction in Julia,"A Julia package for Stable and Interpretable RUle Set (SIRUS) algorithms, providing interpretable machine learning models via rule extraction.",X1-04;Computer Science,interpretability;rule_extraction,library,Julia,https://github.com/rikhuijzer/SIRUS.jl,,MIT,julia;interpretable-ml;rule-extraction;sirus
562,ChainPlots.jl,Visualization for Flux.Chain neural networks,"A Julia package for visualizing the structure and connections of neural networks built with Flux.Chain, aiding in model understanding and debugging.",X1-04;Computer Science,visualization;model_inspection,library,Julia,https://github.com/rmsrosa/ChainPlots.jl,,MIT,julia;flux;visualization;neural-networks
563,OmniXAI,Comprehensive library for eXplainable AI,"OmniXAI is a library for explainable AI (XAI) that offers omni-way explanation capabilities for various machine learning models and data types, including tabular, image, text, and time-series data.",X1-04;Computer Science,interpretability;explanation_generation;feature_importance,library,Jupyter Notebook,https://github.com/salesforce/OmniXAI,https://salesforce.github.io/OmniXAI/,BSD-3-Clause,xai;interpretability;machine-learning;visualization
564,ACV,Active Coalition of Variables for model explanation,"ACV is a Python library that provides local rule-based explanations and different Shapley Value estimations for any machine learning model, with specific optimizations for tree-based models.",X1-04;Computer Science,interpretability;shapley_values;rule_extraction,library,Jupyter Notebook,https://github.com/salimamoukou/acv00,https://acv.readthedocs.io/,MIT,xai;shapley-values;interpretability;random-forest
565,CellBox,Interpretable Machine Learning for Perturbation Biology,"CellBox is a framework for modeling biological networks using interpretable machine learning, specifically designed to predict cellular responses to perturbations.",X1-04;Biology,biological_modeling;perturbation_analysis;interpretability,library,Jupyter Notebook,https://github.com/sanderlab/CellBox,,MIT,biology;interpretable-ml;perturbation;network-modeling
566,convisualize_nb,Visualisations for Convolutional Neural Networks in Pytorch,"A collection of visualization techniques for Convolutional Neural Networks (CNNs) implemented in PyTorch, aiding in the interpretation of learned features.",X1-04;Computer Science,visualization;feature_visualization;cnn_interpretation,library,Jupyter Notebook,https://github.com/sar-gupta/convisualize_nb,,MIT,pytorch;visualization;cnn;interpretability
567,Graph Saliency Maps,Graph saliency maps through spectral convolutional networks for brain mapping,"A tool for generating saliency maps on graphs using spectral convolutional networks, specifically applied to brain mapping tasks to identify relevant brain regions.",X1-04;Neuroscience,saliency_mapping;brain_mapping;graph_neural_networks,solver,Python,https://github.com/sarslancs/graph_saliency_maps,,MIT,neuroscience;graph-neural-networks;saliency-maps;brain-mapping
568,Data_Driven_Symbolic_Regression,Symbolic regression tool for identifying physical processes and turbulence models,"A Python library implementing data-driven symbolic regression using Genetic Programming and Gene Expression Programming. It is specifically designed to identify physical processes, numerical schemes, and Large Eddy Simulation (LES) subgrid-scale turbulence models from data, offering interpretable machine learning capabilities for physics and fluid dynamics.",X1;X1-04;Physics;Fluid Dynamics,scientific_modeling;symbolic_regression;equation_discovery,library,Python,https://github.com/sayin/Data_Driven_Symbolic_Regression,,GPL-3.0,symbolic-regression;turbulence-modeling;interpretable-ml;physics-informed
569,AutoMLWhitebox,Automated machine learning library for building interpretable 'whitebox' models,"A library designed to automatically construct interpretable machine learning models (Whitebox AutoML). It focuses on transparency and explainability in automated model generation, making it suitable for scientific applications where model rationale is critical.",X1;X1-04,model_building;automl;interpretability,library,Python,https://github.com/sb-ai-lab/AutoMLWhitebox,,Apache-2.0,automl;interpretable-ml;whitebox-models
570,pyss3,Interpretable text classification library using the SS3 model,"A Python library implementing the SS3 text classifier, designed to be naturally interpretable. It includes visualization tools for Explainable AI (XAI) to analyze text classification decisions, applicable in social science and literature analysis.",X1;X1-04;NLP,text_classification;interpretability;visualization,library,Python,https://github.com/sergioburdisso/pyss3,https://pyss3.readthedocs.io,MIT,nlp;explainable-ai;text-classification;ss3
571,SHAP,Game theoretic approach to explain the output of any machine learning model,"A unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations) assigns each feature an importance value for a particular prediction. It is widely used across scientific disciplines (genomics, physics, chemistry) to understand complex black-box models.",X1;X1-04,feature_attribution;model_interpretation,library,Python,https://github.com/shap/shap,https://shap.readthedocs.io,MIT,xai;shapley-values;feature-importance;interpretability
572,AxBench,Benchmarking library for LLM interpretability methods,A Python library developed by Stanford NLP for benchmarking the utility of Large Language Model (LLM) interpretability methods. It provides a standardized framework to evaluate how well explanation methods work.,X1;X1-04;NLP,benchmarking;evaluation;interpretability,library,Python,https://github.com/stanfordnlp/axbench,,Apache-2.0,llm;interpretability;benchmark;xai
573,pyreft,Library for Representation Finetuning (ReFT) of language models,"A Python library for Representation Finetuning (ReFT), a method for intervening on internal model representations to steer behavior. It is a tool for mechanistic interpretability and model control.",X1;X1-04;NLP,model_steering;intervention;finetuning,library,Python,https://github.com/stanfordnlp/pyreft,,Apache-2.0,representation-learning;intervention;interpretability
574,pyvene,Library for intervention-based model understanding and improvement,"A Python library for performing interventions on PyTorch models to understand their internal mechanisms. It supports causal abstraction and interchange intervention training, facilitating mechanistic interpretability research.",X1;X1-04,causal_intervention;mechanistic_interpretability;model_analysis,library,Python,https://github.com/stanfordnlp/pyvene,https://stanfordnlp.github.io/pyvene/,Apache-2.0,intervention;causality;pytorch;interpretability
575,attributionpriors,Tools for training explainable models using attribution priors,"A library for training machine learning models with attribution priors, which constrain the model's explanations to align with prior domain knowledge. This improves model interpretability and reliability in scientific contexts.",X1;X1-04,model_training;regularization;interpretability,library,Jupyter Notebook,https://github.com/suinleelab/attributionpriors,,MIT,attribution-priors;explainable-ai;regularization
576,path_explain,Feature attribution and interaction analysis for deep neural networks,"A repository and library for explaining feature attributions and feature interactions in deep neural networks, particularly using path-integrated gradients. Developed by the Su-In Lee lab, it is used for interpreting deep learning models in genomics and healthcare.",X1;X1-04,feature_attribution;interaction_analysis;interpretability,library,Jupyter Notebook,https://github.com/suinleelab/path_explain,,MIT,feature-interactions;integrated-gradients;deep-learning
577,Lucid,Infrastructure and tools for neural network interpretability research,"A collection of infrastructure and tools for research in neural network interpretability, primarily focused on feature visualization. It allows researchers to visualize what specific neurons or layers in a neural network are detecting.",X1;X1-04,feature_visualization;interpretability;model_analysis,library,Jupyter Notebook,https://github.com/tensorflow/lucid,,Apache-2.0,feature-visualization;tensorflow;interpretability
578,TensorSpace,3D visualization framework for neural networks,"A framework for building interactive 3D visualizations of neural network models in the browser. It supports models from TensorFlow, Keras, and TensorFlow.js, helping researchers and users intuitively understand model architecture and data flow.",X1;X1-04,scientific_visualization;model_visualization,platform,JavaScript,https://github.com/tensorspace-team/tensorspace,https://tensorspace.org,Apache-2.0,visualization;3d;neural-networks;browser-based
579,GGOS_Tropospheric_Delay_Solver,C project for solving tropospheric delay using GGOS products,A C-based tool developed to solve tropospheric delay using GGOS (Global Geodetic Observing System) tropospheric products. It is based on RTKLIB and is designed to facilitate GNSS research by providing a tool for atmospheric delay estimation.,X1;Geodesy;Atmospheric Science,data_processing;atmospheric_correction;gnss_analysis,solver,C,https://github.com/tianruivpn1001/C-project-for-solving-tropospheric-delay-using-GGOS-tropospheric-products,,None,gnss;troposphere;rtklib;geodesy
580,lime (R),R port of Local Interpretable Model-Agnostic Explanations (LIME),"The R implementation of LIME, a method for explaining the predictions of any machine learning classifier. It approximates the black-box model locally with an interpretable model to explain individual predictions.",X1;X1-04,model_explanation;local_interpretation,library,R,https://github.com/tidymodels/lime,https://lime.data-imaginist.com,NOASSERTION,xai;lime;model-agnostic;r-package
581,causalglm,Causal inference for heterogeneous treatment effects using GLMs,"An R package for interpretable and model-robust causal inference. It estimates heterogeneous treatment effects using generalized linear working models combined with targeted machine learning, suitable for biostatistics and epidemiology.",X1;X1-04;Statistics,causal_inference;statistical_modeling,library,R,https://github.com/tlverse/causalglm,,GPL-3.0,causal-inference;heterogeneous-treatment-effects;targeted-learning
582,sklearn-interpretable-tree,Simplified tree-based classifier and regressor for interpretable machine learning,"A Python library that provides a simplified, scikit-learn compatible implementation of tree-based classifiers and regressors designed specifically for interpretable machine learning workflows.",X1;X1-04,interpretable_modeling;model_explanation,library,Python,https://github.com/tmadl/sklearn-interpretable-tree,,None,interpretable-ml;decision-trees;scikit-learn
583,nshap,Computation of interaction indices extending the Shapley Value,"A Python package developed by the Trustworthy Machine Learning group at University of Tbingen to compute interaction indices that extend the Shapley Value, as presented at AISTATS 2023.",X1;X1-04,feature_attribution;interaction_analysis,library,Jupyter Notebook,https://github.com/tml-tuebingen/nshap,,MIT,shapley-values;interaction-indices;xai
584,shap-select,Feature selection for gradient boosting models using Shapley values,A library designed for performing feature selection on gradient boosting models by utilizing regression on feature Shapley values to identify the most impactful features.,X1;X1-04,feature_selection;model_optimization,library,Python,https://github.com/transferwise/shap-select,,Apache-2.0,feature-selection;shapley-values;gradient-boosting
585,DICE,Disentangling User Interest and Conformity for Recommendation with Causal Embedding,"Implementation of the DICE framework (WWW '21) which uses causal embedding to disentangle user interest from conformity in recommendation systems, aiding in causal modeling of user behavior.",X1;X1-04,causal_inference;disentanglement,solver,Python,https://github.com/tsinghua-fib-lab/DICE,,MIT,causal-embedding;recommender-systems;disentanglement
586,Manifold,Model-agnostic visual debugging tool for machine learning,A visual debugging tool for machine learning that provides model-agnostic visualizations to help researchers identify performance issues and understand model behavior across different data subsets.,X1;X1-04,visual_debugging;model_evaluation,platform,JavaScript,https://github.com/uber/manifold,https://eng.uber.com/manifold/,Apache-2.0,visualization;debugging;model-agnostic
587,Quantus,Toolkit for responsible evaluation of neural network explanations,"An eXplainable AI (XAI) toolkit designed for the quantitative evaluation of neural network explanations, providing metrics to assess the reliability and faithfulness of explanation methods.",X1;X1-04,xai_evaluation;explanation_metrics,library,Jupyter Notebook,https://github.com/understandable-machine-intelligence-lab/Quantus,,NOASSERTION,xai;evaluation;neural-networks
588,pytorch-cnn-visualizations,PyTorch implementation of convolutional neural network visualization techniques,"A comprehensive collection of PyTorch implementations for various convolutional neural network visualization techniques, aiding in the interpretability of deep learning models.",X1;X1-04,visualization;feature_attribution,library,Python,https://github.com/utkuozbulak/pytorch-cnn-visualizations,,MIT,pytorch;cnn;visualization
589,cnn-fixations,Visualising predictions of deep neural networks,"A tool for visualizing the predictions of deep neural networks, focusing on identifying fixations or salient regions that contribute to model decisions.",X1;X1-04,visualization;saliency_mapping,library,,https://github.com/val-iisc/cnn-fixations,,None,visualization;deep-learning;saliency
590,OCTET,Object-aware Counterfactual Explanations,"Implementation of OCTET (CVPR 2023), a method for generating object-aware counterfactual explanations to improve the interpretability of computer vision models.",X1;X1-04,counterfactual_explanation;image_interpretability,solver,Python,https://github.com/valeoai/OCTET,,None,counterfactuals;computer-vision;xai
591,STEEX,Steering Counterfactual Explanations with Semantics,"A tool for generating counterfactual explanations that can be steered using semantic attributes, enhancing the control and interpretability of model explanations.",X1;X1-04,counterfactual_explanation;semantic_steering,solver,Python,https://github.com/valeoai/STEEX,,NOASSERTION,counterfactuals;semantics;xai
592,Data2Vis,Automatic Generation of Data Visualizations Using Sequence to Sequence RNNs,An automatic visualization generation tool that uses sequence-to-sequence recurrent neural networks to convert data specifications into visualization specifications.,X1;X1-04,scientific_visualization;automated_visualization,solver,Python,https://github.com/victordibia/data2vis,,Apache-2.0,visualization;seq2seq;rnn
593,OCEAN,Optimal Counterfactual Explanations in Tree Ensembles,"Implementation of OCEAN (ICML 2021), a method for finding optimal counterfactual explanations specifically for tree ensemble models.",X1;X1-04,counterfactual_explanation;tree_ensembles,solver,Python,https://github.com/vidalt/OCEAN,,MIT,counterfactuals;tree-ensembles;optimization
594,Net2Vis,Automatic neural network visualizations generated in your browser,"A web-based tool for automatically generating abstract visualizations of neural network architectures from code, facilitating the documentation and communication of model structures.",X1;X1-04,network_visualization;architecture_diagram,platform,JavaScript,https://github.com/viscom-ulm/Net2Vis,https://viscom.net2vis.uni-ulm.de/,MIT,visualization;neural-networks;architecture
595,WindowSHAP,Model-agnostic framework for explaining time-series classifiers using Shapley values,A framework designed to provide explanations for time-series classifiers by adapting Shapley values to work with sliding windows over temporal data.,X1;X1-04,time_series_explanation;shapley_values,library,Jupyter Notebook,https://github.com/vsubbian/WindowSHAP,,None,time-series;shapley-values;xai
596,cnn-visualization,Visualize How Convolutional Neural Networks Work with Keras,"A collection of Keras-based implementations for visualizing the internal workings of Convolutional Neural Networks (CNNs), including feature maps and filters.",X1;X1-04,visualization;feature_inspection,library,Jupyter Notebook,https://github.com/waleedka/cnn-visualization,,None,keras;cnn;visualization
597,HiddenLayer,"Neural network graphs and training metrics for PyTorch, Tensorflow, and Keras","A lightweight library for visualizing neural network graphs and tracking training metrics in real-time for PyTorch, TensorFlow, and Keras models.",X1;X1-04,network_visualization;training_monitoring,library,Python,https://github.com/waleedka/hiddenlayer,,MIT,visualization;pytorch;tensorflow
598,CFAI,A collection of algorithms of counterfactual explanations,"A repository collecting various algorithms and implementations for generating counterfactual explanations, serving as a resource for XAI research and application.",X1;X1-04,counterfactual_explanation;algorithm_collection,library,Python,https://github.com/wangyongjie-ntu/CFAI,,MIT,counterfactuals;xai;algorithms
599,VisualTorch,Visualization of Torch-based neural network architectures,"A library to help visualize the architecture of Torch-based neural networks, generating diagrams to inspect model structure.",X1;X1-04,network_visualization;architecture_inspection,library,Python,https://github.com/willyfh/visualtorch,,MIT,pytorch;visualization;architecture
600,ClusterShapley,Explaining dimensionality results using SHAP values,A tool for explaining the results of dimensionality reduction and clustering algorithms by applying Shapley value analysis to understand feature contributions.,X1;X1-04,clustering_explanation;dimensionality_reduction_analysis,library,C++,https://github.com/wilsonjr/ClusterShapley,,BSD-3-Clause,shapley-values;clustering;dimensionality-reduction
601,NLP-Loss-Pytorch,"Implementation of unbalanced loss functions like focal_loss, dice_loss","A PyTorch implementation of various loss functions designed for handling unbalanced data, such as Focal Loss, Dice Loss, and GHM Loss, useful for robust model training.",X1;X1-04,model_training;loss_functions,library,Python,https://github.com/xinyi-code/NLP-Loss-Pytorch,,MIT,loss-functions;pytorch;imbalanced-learning
602,Arrakis,"Library to conduct, track and visualize mechanistic interpretability experiments","A library designed for mechanistic interpretability research, providing tools to conduct, track, and visualize experiments aimed at reverse-engineering neural network behaviors.",X1;X1-04,mechanistic_interpretability;experiment_tracking,library,Jupyter Notebook,https://github.com/yash-srivastava19/arrakis,,None,mechanistic-interpretability;visualization;neural-networks
603,WeightedSHAP,Analyzing and improving Shapley based feature attributions,"Implementation of WeightedSHAP (NeurIPS 2022), a method for analyzing and improving the reliability of Shapley-based feature attribution methods in machine learning.",X1;X1-04,feature_attribution;shapley_values,library,Jupyter Notebook,https://github.com/ykwon0407/WeightedSHAP,,None,shapley-values;feature-attribution;xai
604,fast_dist_shapley,Efficient Computation and Analysis of Distributional Shapley Values,"Code for efficient computation and analysis of Distributional Shapley Values (AISTATS 2021), enabling faster estimation of feature importance in distributional settings.",X1;X1-04,feature_attribution;shapley_values,library,Python,https://github.com/ykwon0407/fast_dist_shapley,,None,shapley-values;distributional-analysis;efficiency
605,convnet-drawer,Script for illustrating Convolutional Neural Networks using Keras-like definitions,"A Python script that generates illustrations of Convolutional Neural Network (CNN) architectures using Keras-like model definitions, useful for visualizing and documenting model structures.",X1;X1-04,network_visualization;architecture_diagram,library,Python,https://github.com/yu4u/convnet-drawer,,MIT,visualization;cnn;keras
606,3D-Human-Body-Shape,3D Human Body Reshaping with Anthropometric Modeling,"Implementation of a method for 3D human body reshaping based on anthropometric modeling, allowing for the manipulation and analysis of 3D body shapes.",X1;X1-04,3d_modeling;anthropometry,solver,Python,https://github.com/zengyh1900/3D-Human-Body-Shape,,MIT,3d-reconstruction;human-body;modeling
607,RAW2RGB-GAN,Saliency map-aided GAN for Auto-demosaic+denosing,A PyTorch implementation of a Generative Adversarial Network (GAN) that uses saliency maps to aid in the joint task of demosaicing and denoising RAW images.,X1;X1-04,image_restoration;saliency_guided_generation,solver,Python,https://github.com/zhaoyuzhi/RAW2RGB-GAN,,None,gan;image-processing;saliency
608,SCGAN,Saliency-map Guided Colorization with Generative Adversarial Network,"Implementation of SCGAN (IEEE TCSVT 2020), a method for image colorization that leverages saliency maps to guide the generation process for more realistic results.",X1;X1-04,image_colorization;saliency_guided_generation,solver,Python,https://github.com/zhaoyuzhi/Semantic-Colorization-GAN,,MIT,gan;colorization;saliency
609,cnnvisualizer,Visualization tool for inspecting internal activations of Deep Neural Networks,"A toolkit designed to visualize and diagnose Deep Neural Networks (DNNs) by displaying the activation maps of network layers. It helps researchers understand the features learned by CNNs, supporting model interpretability and debugging in scientific deep learning applications.",X1;X1-04,model_interpretation;scientific_visualization,solver,C++,https://github.com/zhoubolei/cnnvisualizer,,MIT,visualization;cnn;interpretability;deep-learning
610,rexmex,A general purpose recommender metrics library for fair evaluation,"A general purpose recommender metrics library designed for fair evaluation of recommender systems. It provides a comprehensive set of metrics to assess the performance and fairness of recommendation algorithms, supporting the development of trustworthy AI systems.",X1;X1-05,fairness_evaluation;metrics_calculation,library,Python,https://github.com/AstraZeneca/rexmex,,None,recommender-systems;fairness;metrics;evaluation
611,advertorch,A Toolbox for Adversarial Robustness Research,"A Python toolbox for adversarial robustness research, specifically designed for PyTorch. It provides implementations of various adversarial attacks, defenses, and robust training methods to evaluate and improve the security of machine learning models.",X1;X1-05,adversarial_attack;robustness_evaluation;defense,library,Python,https://github.com/BorealisAI/advertorch,,LGPL-3.0,adversarial-machine-learning;robustness;pytorch;security
612,CartAI,AI supervisor agent for intelligent E2E oversight and compliance in the AI lifecycle,CartAI acts as an open-source AI supervisor agent designed to provide intelligent end-to-end oversight and compliance monitoring for trustworthy AI systems. It facilitates the auditing and governance of AI models throughout their lifecycle.,X1;X1-05,auditing;compliance_monitoring,platform,Jupyter Notebook,https://github.com/ContrastoAI/cartai,,Apache-2.0,ai-governance;compliance;auditing;trustworthy-ai
613,RobustART,Comprehensive robustness investigation benchmark for ImageNet models,RobustART is a benchmark toolkit designed to investigate the robustness of large-scale image classification models (specifically on ImageNet) regarding architecture design and training techniques against diverse noises and adversarial attacks.,X1;X1-05,robustness_evaluation;benchmarking,library,Python,https://github.com/DIG-Beihang/RobustART,,Apache-2.0,robustness;benchmark;computer-vision;adversarial-defense
614,EqualityML,Evidence-based tools for algorithmic bias detection and mitigation,"EqualityML provides a suite of tools and algorithms designed to detect and mitigate algorithmic bias in machine learning models, fostering community collaboration for fair data science practices.",X1;X1-05,fairness_auditing;bias_mitigation,library,Jupyter Notebook,https://github.com/EqualityAI/EqualityML,,Apache-2.0,fairness;bias-detection;machine-learning;auditing
615,EuroEval,Robust benchmark for European language models,"EuroEval is a benchmarking framework designed to evaluate the performance and robustness of language models specifically for European languages, providing standardized metrics for model assessment.",X1;X1-05,model_evaluation;benchmarking,library,Python,https://github.com/EuroEval/EuroEval,,MIT,nlp;benchmark;european-languages;model-evaluation
616,FAIR Metrics,Reference implementations of FAIR Maturity Indicators,"This repository contains the reference implementations (Ruby scripts/YAML definitions) of the FAIR (Findable, Accessible, Interoperable, Reusable) Maturity Indicators, used to programmatically evaluate the FAIRness of digital resources.",X1;X1-05,data_auditing;fairness_evaluation,library,Ruby,https://github.com/FAIRMetrics/Metrics,,MIT,fair-principles;data-auditing;metrics;reproducibility
617,Phare,LLM benchmark for AI security and safety evaluation,"Phare is a benchmark tool designed to evaluate Large Language Models (LLMs) across key AI security and safety dimensions, helping auditors and developers assess model trustworthiness.",X1;X1-05,safety_evaluation;benchmarking,library,Python,https://github.com/Giskard-AI/phare,,None,llm;safety;security;benchmark
618,TrustLLM,Comprehensive benchmark for trustworthiness in Large Language Models,"TrustLLM is a comprehensive framework and benchmark for evaluating the trustworthiness of Large Language Models across multiple dimensions, including truthfulness, safety, fairness, and robustness.",X1;X1-05,trustworthiness_evaluation;benchmarking,library,Python,https://github.com/HowieHwong/TrustLLM,,MIT,llm;trustworthiness;benchmark;safety
619,inFairness,PyTorch package for training and auditing ML models for Individual Fairness,"inFairness is a PyTorch-based library designed to train, audit, and evaluate machine learning models with a focus on Individual Fairness, providing algorithms and metrics to ensure equitable model outcomes.",X1;X1-05,fairness_auditing;model_training,library,Python,https://github.com/IBM/inFairness,,Apache-2.0,individual-fairness;pytorch;auditing;bias-mitigation
620,qux360,AI-assisted trustworthy qualitative data analysis toolkit,"A toolkit designed to assist in qualitative data analysis with a focus on trustworthiness, providing features for analyzing and auditing qualitative datasets.",X1;X1-05,qualitative_analysis;auditing,library,Python,https://github.com/IBM/qux360,,Apache-2.0,qualitative-analysis;trustworthy-ai;auditing
621,Infosys Responsible AI Toolkit,Toolkit for ensuring AI solutions are trustworthy and transparent,"A comprehensive toolkit incorporating features for safety, security, explainability, fairness, bias, and hallucination detection to audit and evaluate AI models.",X1;X1-05,auditing;fairness_analysis;safety_check,library,Python,https://github.com/Infosys/Infosys-Responsible-AI-Toolkit,,MIT,responsible-ai;fairness;explainability;security
622,JailbreakBench,Open robustness benchmark for jailbreaking language models,"A benchmark suite designed to evaluate the robustness of Large Language Models (LLMs) against jailbreaking attacks, providing standardized metrics and datasets.",X1;X1-05,robustness_evaluation;security_auditing,library,Python,https://github.com/JailbreakBench/jailbreakbench,https://jailbreakbench.github.io/,MIT,llm;jailbreak;robustness;benchmark
623,MM_Robustness,Benchmark for robustness of multimodal image-text models,A benchmarking tool for evaluating the robustness of multimodal image-text models under various distribution shifts.,X1;X1-05,robustness_evaluation;benchmarking,library,Python,https://github.com/Jielin-Qiu/MM_Robustness,,Apache-2.0,multimodal;robustness;benchmark
624,FairRankTune,Toolkit for fairness-aware ranking and data generation,"A Python toolkit providing fairness-aware data generation, fairness metrics, and fair ranking algorithms for evaluating and mitigating bias in ranking systems.",X1;X1-05,fairness_analysis;ranking_evaluation,library,Python,https://github.com/KCachel/fairranktune,,BSD-3-Clause,fairness;ranking;metrics
625,RAOS,Robustness evaluation benchmark for abdominal organ segmentation,"A benchmark for evaluating the robustness of abdominal organ segmentation models in clinical scenarios, focusing on challenging cases.",X1;X1-05,robustness_evaluation;medical_image_segmentation,dataset,Python,https://github.com/Luoxd1996/RAOS,,GPL-3.0,medical-imaging;segmentation;robustness;benchmark
626,Lyzr Agent Framework,Agent framework with integrated Safe AI and Responsible AI modules,"An agent framework that natively integrates Safe AI and Responsible AI modules, allowing for the development of auditable and transparent AI agents.",X1;X1-05,safety_auditing;agent_development,library,Python,https://github.com/LyzrCore/lyzr-framework,,Apache-2.0,responsible-ai;agents;safety
627,MME-CoT,Benchmarking Chain-of-Thought in LMMs,"A benchmark suite for evaluating the reasoning quality, robustness, and efficiency of Chain-of-Thought capabilities in Large Multimodal Models.",X1;X1-05,reasoning_evaluation;robustness_benchmarking,library,Python,https://github.com/MME-Benchmarks/MME-CoT,,None,multimodal;chain-of-thought;benchmark
628,fair-test,Library to build and deploy FAIR metrics tests,"A library to build and deploy FAIR (Findable, Accessible, Interoperable, Reusable) metrics tests APIs for evaluating scientific data quality and stewardship.",X1;X1-05,data_quality_control;fair_evaluation,library,Python,https://github.com/MaastrichtU-IDS/fair-test,,MIT,fair-data;metrics;evaluation
629,CIFAR10 Adversarial Challenge,Benchmark harness for adversarial robustness on CIFAR10,A challenge framework and codebase for exploring and benchmarking adversarial robustness of neural networks on the CIFAR10 dataset.,X1;X1-05,robustness_benchmarking;adversarial_defense,library,Python,https://github.com/MadryLab/cifar10_challenge,,MIT,adversarial-robustness;cifar10;benchmark
630,MNIST Adversarial Challenge,Benchmark harness for adversarial robustness on MNIST,A challenge framework and codebase for exploring and benchmarking adversarial robustness of neural networks on the MNIST dataset.,X1;X1-05,robustness_benchmarking;adversarial_defense,library,Python,https://github.com/MadryLab/mnist_challenge,,MIT,adversarial-robustness;mnist;benchmark
631,explabox,"Toolbox for model exploration, examination, and explanation","A toolbox designed to help users explore, examine, explain, and expose machine learning models, facilitating transparency and auditing.",X1;X1-05,explainability;model_auditing,library,Python,https://github.com/MarcelRobeer/explabox,,LGPL-3.0,xai;explainability;auditing
632,CIL-ReID,Benchmark for Corruption Invariant Person Re-identification,A benchmark suite for evaluating the robustness of person re-identification models against various image corruptions.,X1;X1-05,robustness_benchmarking;computer_vision,library,Python,https://github.com/MinghuiChen43/CIL-ReID,,MIT,re-identification;robustness;benchmark
633,auditor,"Model verification, validation, and error analysis tool for R","A tool for model verification, validation, and error analysis. It provides methods for assessing model performance, analyzing residuals, and detecting potential issues in predictive models.",X1;X1-05,model_auditing;error_analysis;validation,library,R,https://github.com/ModelOriented/auditor,https://modeloriented.github.io/auditor/,GPL-2.0,model-validation;auditing;error-analysis;r-package
634,fairmodels,"Flexible tool for bias detection, visualization, and mitigation in R","An R package that facilitates fairness analysis in machine learning models. It offers tools for detecting bias, visualizing fairness metrics, and applying mitigation techniques to ensure equitable model outcomes.",X1;X1-05,bias_detection;fairness_auditing;bias_mitigation,library,R,https://github.com/ModelOriented/fairmodels,https://fairmodels.drwhy.ai/,GPL-3.0,fairness;bias-detection;machine-learning;r-package
635,farsight,In situ interactive widgets for responsible AI auditing,A collection of interactive widgets designed to help researchers and practitioners audit AI models for responsibility and fairness directly within their development environment.,X1;X1-05,auditing;visualization;responsible_ai,library,TypeScript,https://github.com/PAIR-code/farsight,,Apache-2.0,visualization;responsible-ai;auditing
636,Know Your Data,Tool for dataset understanding and bias mitigation,"A tool developed to assist researchers and product teams in understanding datasets, improving data quality, and identifying and mitigating fairness and bias issues.",X1;X1-05,data_auditing;bias_detection;data_quality,platform,CSS,https://github.com/PAIR-code/knowyourdata,https://knowyourdata.withgoogle.com/,Apache-2.0,dataset-auditing;fairness;visualization
637,What-If Tool,Interactive visual interface for model understanding and fairness auditing,"An interactive visual interface designed to help users probe, understand, and debug machine learning models. It enables fairness auditing, counterfactual analysis, and performance visualization.",X1;X1-05,model_auditing;fairness_analysis;counterfactual_analysis,platform,HTML,https://github.com/PAIR-code/what-if-tool,https://pair-code.github.io/what-if-tool/,Apache-2.0,visualization;fairness;model-debugging
638,BeaverTails,Dataset for safety alignment in large language models,"A collection of datasets specifically designed to facilitate research on safety alignment in large language models (LLMs), covering various safety-related scenarios.",X1;X1-05,safety_alignment;dataset,dataset,Makefile,https://github.com/PKU-Alignment/beavertails,https://huggingface.co/datasets/PKU-Alignment/BeaverTails,Apache-2.0,safety-alignment;llm;dataset
639,Safe-RLHF,Library for constrained value alignment via safe RLHF,"A library implementing Safe Reinforcement Learning from Human Feedback (Safe RLHF) for constrained value alignment of large language models, ensuring helpfulness and harmlessness.",X1;X1-05,safety_alignment;rlhf;model_training,library,Python,https://github.com/PKU-Alignment/safe-rlhf,https://safe-rlhf.readthedocs.io/,Apache-2.0,rlhf;safety;alignment;llm
640,SafeSora,Human preference dataset for text-to-video safety alignment,"A human preference dataset designed to support safety alignment research in the text-to-video generation field, aiming to enhance the helpfulness and harmlessness of Large Vision Models.",X1;X1-05,safety_alignment;dataset;video_generation,dataset,Python,https://github.com/PKU-Alignment/safe-sora,,None,text-to-video;safety;alignment;dataset
641,RLAIF-V,Dataset and method for AI feedback-based safety alignment,"A framework and dataset for Reinforcement Learning from AI Feedback (RLAIF) applied to Vision-Language Models, aiming to improve trustworthiness and safety alignment.",X1;X1-05,safety_alignment;rlaif;dataset,dataset,Python,https://github.com/RLHF-V/RLAIF-V,,None,rlaif;safety;alignment;vlm
642,responsibly,Toolkit for auditing and mitigating bias and fairness in ML systems,"A toolkit designed for auditing and mitigating bias and fairness issues in machine learning systems, providing practical tools for researchers and practitioners.",X1;X1-05,bias_auditing;fairness_mitigation;model_evaluation,library,Python,https://github.com/ResponsiblyAI/responsibly,https://docs.responsibly.ai/,MIT,fairness;bias;auditing;toolkit
643,CipherChat,Framework to evaluate safety alignment generalization in LLMs,"A framework designed to evaluate the generalization capability of safety alignment in Large Language Models (LLMs), particularly focusing on cipher-based scenarios to test robustness.",X1;X1-05,safety_evaluation;alignment_generalization;robustness_testing,solver,Python,https://github.com/RobustNLP/CipherChat,,MIT,safety-alignment;llm;evaluation
644,WORKBank,Database of worker desire and capability for AI agents,"A database derived from a large-scale audit of worker desire and technological capability of AI agents, serving as a resource for researching the social impact and alignment of AI in the workforce.",X1;X1-05,social_impact_audit;dataset;ai_alignment,dataset,Jupyter Notebook,https://github.com/SALT-NLP/workbank,,None,dataset;ai-ethics;workforce-alignment
645,JailBreakV-28K,Benchmark for evaluating jailbreak transferability to MLLMs,A comprehensive benchmark designed to evaluate the transferability of LLM jailbreak attacks to Multimodal Large Language Models (MLLMs) and assess their robustness and safety.,X1;X1-05,safety_benchmarking;jailbreak_evaluation;robustness_testing,dataset,Python,https://github.com/SaFo-Lab/JailBreakV_28K,https://jailbreakv.github.io/,None,benchmark;jailbreak;mllm;safety
646,Robust Gymnasium,Unified modular benchmark for robust reinforcement learning,"A unified modular benchmark designed for evaluating Robust Reinforcement Learning algorithms, providing a standardized environment for testing agent robustness.",X1;X1-05,robustness_benchmarking;reinforcement_learning;evaluation,library,Python,https://github.com/SafeRL-Lab/Robust-Gymnasium,,MIT,reinforcement-learning;robustness;benchmark
647,VINE,Robust watermarking method using generative priors against image editing,"Official implementation of a robust watermarking technique that leverages generative priors to protect images against editing, serving as a solver for image provenance and integrity.",X1;X1-05,watermarking;image_protection,solver,Python,https://github.com/Shilin-LU/VINE,,NOASSERTION,watermarking;generative-priors;robustness
648,SpeechIO Leaderboard,Comprehensive benchmarking platform for Automatic Speech Recognition (ASR),A robust and comprehensive leaderboard and benchmarking platform designed to evaluate the performance of Automatic Speech Recognition systems across various metrics.,X1;X1-05,model_evaluation;benchmarking,platform,Python,https://github.com/SpeechColab/Leaderboard,,None,asr;leaderboard;benchmarking
649,Graph Robustness Benchmark (GRB),Scalable benchmark for evaluating adversarial robustness of Graph Machine Learning,"A unified, modular, and reproducible benchmark framework for assessing the adversarial robustness of Graph Machine Learning (GML) models against various attacks.",X1;X1-05,robustness_evaluation;graph_learning,library,Python,https://github.com/THUDM/grb,,MIT,graph-neural-networks;adversarial-robustness;benchmark
650,MMLU-Pro,Robust and challenging multi-task language understanding benchmark,"An enhanced benchmark dataset and evaluation suite for Large Language Models, designed to be more robust and challenging than the standard MMLU benchmark.",X1;X1-05,model_evaluation;benchmarking,dataset,Python,https://github.com/TIGER-AI-Lab/MMLU-Pro,,Apache-2.0,llm;benchmark;mmlu
651,AI-Infra-Guard,Comprehensive AI Red Teaming and safety evaluation platform,"A platform developed by Tencent Zhuque Lab for AI Red Teaming, offering intelligent and easy-to-use tools for assessing AI system security and safety.",X1;X1-05,red_teaming;safety_evaluation,platform,Python,https://github.com/Tencent/AI-Infra-Guard,,NOASSERTION,red-teaming;ai-safety;security
652,trust-safety-evals,Reference stack for AI model and system evaluation,"A project by The AI Alliance providing a reference stack, benchmarks, and leaderboards for evaluating the trust and safety of AI models and systems.",X1;X1-05,safety_evaluation;benchmarking,workflow,Makefile,https://github.com/The-AI-Alliance/trust-safety-evals,,None,ai-safety;evaluation;benchmarks
653,AIF360,Comprehensive toolkit for fairness metrics and bias mitigation,The AI Fairness 360 toolkit is an open-source library to help detect and remove bias in machine learning models. It translates algorithmic research from the lab into practice.,X1;X1-05,fairness_evaluation;bias_mitigation,library,Python,https://github.com/Trusted-AI/AIF360,https://aif360.mybluemix.net/,Apache-2.0,fairness;bias-mitigation;machine-learning
654,STAR-1,Method for safer alignment of reasoning LLMs,"Implementation of the STAR-1 approach for aligning reasoning Large Language Models (LLMs) to improve safety, serving as a solver for alignment tasks.",X1;X1-05,safety_alignment;model_training,solver,Python,https://github.com/UCSC-VLAA/STAR-1,,Apache-2.0,llm-alignment;safety;reasoning
655,vllm-safety-benchmark,Safety evaluation benchmark for Vision LLMs,"A benchmark suite designed to evaluate the safety of Vision Large Language Models (VLLMs), specifically assessing risks like hallucinations or misinterpretations in visual contexts.",X1;X1-05,safety_evaluation;benchmarking,dataset,Python,https://github.com/UCSC-VLAA/vllm-safety-benchmark,,None,vision-llm;safety;benchmark
656,Inspect,Framework for large language model evaluations,"A framework developed by the UK AI Safety Institute for evaluating large language models, facilitating the creation and execution of safety and capability assessments.",X1;X1-05,model_evaluation;safety_assessment,framework,Python,https://github.com/UKGovernmentBEIS/inspect_ai,,MIT,llm-evaluation;ai-safety;framework
657,fair-sense-ai,AI-powered tool for bias detection and risk management,"A tool developed by Vector Institute for detecting bias and managing risks in AI systems, promoting sustainable and trustworthy AI.",X1;X1-05,bias_detection;risk_management,tool,Python,https://github.com/VectorInstitute/fair-sense-ai,,NOASSERTION,bias-detection;risk-management;trustworthy-ai
658,MarsFL,"Benchmark for Federated Learning generalization, robustness, and fairness","A benchmark framework for evaluating Federated Learning algorithms with a focus on generalization, robustness, and fairness.",X1;X1-05,benchmarking;federated_learning,library,Python,https://github.com/WenkeHuang/MarsFL,,None,federated-learning;robustness;fairness
659,SLAM-under-Perturbation,Scalable benchmarking for robust SLAM and 3D reconstruction,A benchmarking tool for evaluating the robustness of SLAM (Simultaneous Localization and Mapping) and 3D reconstruction algorithms under noisy conditions.,X1;X1-05,robustness_evaluation;slam,library,C++,https://github.com/Xiaohao-Xu/SLAM-under-Perturbation,,Apache-2.0,slam;robustness;benchmarking
660,FairDiverse,Toolkit for fairness and diversity in Information Retrieval,A toolkit designed to implement and evaluate fairness-aware and diversity-aware algorithms within the context of Information Retrieval systems.,X1;X1-05,fairness_evaluation;information_retrieval,library,Python,https://github.com/XuChen0427/FairDiverse,,MIT,fairness;diversity;information-retrieval
661,Veridical Flow,Framework for building stable and trustworthy data-science pipelines based on PCS,"A Python framework designed to facilitate the construction of stable and trustworthy data science pipelines using the PCS (Predictability, Computability, and Stability) framework. It aids in managing the data science lifecycle with a focus on reliability.",X1;X1-05,pipeline_management;trustworthiness_assurance,framework,Python,https://github.com/Yu-Group/veridical-flow,,MIT,data-science;pipeline;trustworthiness;PCS-framework
662,Perceptron Benchmark,Robustness benchmark for Deep Neural Network models,A benchmarking tool designed to evaluate the robustness of Deep Neural Network (DNN) models. It provides a standardized environment and metrics for assessing model performance under various adversarial conditions.,X1;X1-05,robustness_benchmarking;model_evaluation,platform,Python,https://github.com/advboxes/perceptron-benchmark,,Apache-2.0,benchmark;robustness;dnn;evaluation
663,EMERALD,Tool for calculating safety-windows in suboptimal alignment space,"A C++ tool that calculates safety-windows by exploring the suboptimal alignment space, primarily used in bioinformatics for sequence alignment analysis. It helps in understanding the reliability and robustness of alignment results.",Bioinformatics,sequence_alignment;reliability_analysis,solver,C++,https://github.com/algbio/emerald,,GPL-3.0,bioinformatics;alignment;safety-window
664,BlackBoxAuditing,Tool for auditing and exploring black box machine learning models,Research code and library for auditing black-box machine learning models to detect bias and ensure fairness. It provides methods to explore model behavior and identify potential discrimination without access to model internals.,X1;X1-05,model_auditing;fairness_evaluation,library,Python,https://github.com/algofairness/BlackBoxAuditing,,Apache-2.0,auditing;fairness;black-box;machine-learning
665,GRIT Benchmark,Benchmark for General Robust Image Task (GRIT),"The official repository for the General Robust Image Task (GRIT) Benchmark, designed to evaluate the robustness and generalization capabilities of computer vision models across various distortions and distribution shifts.",X1;X1-05,robustness_benchmarking;image_analysis,dataset,Jupyter Notebook,https://github.com/allenai/grit_official,,Apache-2.0,benchmark;computer-vision;robustness;generalization
666,safety-eval,Evaluation tool for generative language models and safety classifiers,A simple yet effective evaluation tool for assessing the safety of generative language models and the performance of safety classifiers. It helps in identifying potential safety issues in generated text.,X1;X1-05,safety_evaluation;model_auditing,library,Python,https://github.com/allenai/safety-eval,,NOASSERTION,safety;evaluation;llm;generative-ai
667,Fairness.jl,Julia toolkit for fairness metrics and bias mitigation,A Julia toolkit providing a collection of fairness metrics and bias mitigation algorithms for machine learning models. It enables researchers and practitioners to evaluate and improve the fairness of their models within the Julia ecosystem.,X1;X1-05,fairness_evaluation;bias_mitigation,library,Julia,https://github.com/ashryaagr/Fairness.jl,,MIT,julia;fairness;bias-mitigation;metrics
668,MLIP Arena,Benchmark for machine learning interatomic potentials,A fair and transparent benchmark platform for evaluating machine learning interatomic potentials (MLIPs). It goes beyond basic error metrics to assess the performance of MLIPs in materials science applications.,X1;X1-05;Materials Science,benchmarking;model_evaluation,platform,Jupyter Notebook,https://github.com/atomind-ai/mlip-arena,,Apache-2.0,materials-science;interatomic-potentials;benchmark;mlip
669,Geocomplexity,Tool for mitigating spatial bias through geographical complexity,A C++ tool designed to mitigate spatial bias in geographical data analysis by leveraging the concept of geographical complexity. It aids in producing more accurate and unbiased spatial models.,X1;X1-05;Earth Science,spatial_analysis;bias_mitigation,solver,C++,https://github.com/ausgis/geocomplexity,,None,spatial-bias;geography;complexity;gis
670,Amazon SageMaker Clarify,Fairness aware machine learning library for bias detection and mitigation,An open-source library (part of the broader SageMaker ecosystem) for detecting and mitigating bias in machine learning datasets and models. It provides tools for fairness-aware machine learning and model explainability.,X1;X1-05,bias_detection;fairness_mitigation,library,Python,https://github.com/aws/amazon-sagemaker-clarify,,Apache-2.0,fairness;bias;machine-learning;explainability
671,AI Compliance Auditor,Compliance auditing tool for E-Commerce AI systems,A Python-based tool designed to audit AI systems in the e-commerce sector for compliance with regulations and standards. It helps in assessing the trustworthiness and adherence to safety guidelines of deployed AI models.,X1;X1-05,compliance_auditing;model_evaluation,tool,Python,https://github.com/awsdataarchitect/ai-compliance-auditor,,None,compliance;auditing;e-commerce;ai-safety
672,BenchENAS,Benchmarking platform for Evolutionary Neural Architecture Search (ENAS) algorithms,"A platform designed to facilitate fair comparisons and reproducible research for Evolutionary Neural Architecture Search (ENAS) algorithms, providing standard benchmarks and evaluation protocols.",X1;X1-05,model_evaluation;benchmarking;neural_architecture_search,platform,Python,https://github.com/benchenas/BenchENAS,,MIT,enas;benchmarking;evolutionary-algorithms;automl
673,robust-detection-benchmark,Benchmark for object detection robustness in autonomous driving,"A benchmark suite containing code and data to evaluate the robustness of object detection models under varying environmental conditions (e.g., weather, corruption), specifically focused on autonomous driving scenarios.",X1;X1-05,robustness_evaluation;object_detection;benchmarking,dataset,Jupyter Notebook,https://github.com/bethgelab/robust-detection-benchmark,,MIT,object-detection;robustness;autonomous-driving;benchmark
674,biological-alignment-gridworlds-benchmarks,Gridworld environments for AI safety and biological alignment,"A set of gridworld-based benchmark environments designed to test AI agents' ability to learn and act safely in biologically and economically relevant scenarios, focusing on alignment and safety challenges.",X1;X1-05,safety_evaluation;reinforcement_learning;alignment,dataset,Python,https://github.com/biological-alignment-benchmarks/biological-alignment-gridworlds-benchmarks,,MPL-2.0,ai-safety;alignment;gridworld;benchmark
675,EvalWise,Platform for LLM evaluation and red teaming,"A developer-friendly platform designed for evaluating Large Language Models (LLMs) and conducting red teaming exercises to test for safety, compliance, and performance issues.",X1;X1-05,model_evaluation;red_teaming;safety_auditing,platform,Python,https://github.com/bluewave-labs/evalwise,,None,llm;evaluation;red-teaming;safety
676,ConvolutionalNeuralOperator,Convolutional Neural Operators for PDE solving,"An implementation of Convolutional Neural Operators (CNO), a deep learning architecture designed for robust and accurate learning and solving of Partial Differential Equations (PDEs).",X1;X1-05,scientific_modeling;pde_solving;neural_operators,solver,Python,https://github.com/camlab-ethz/ConvolutionalNeuralOperator,,MIT,pde;neural-operators;scientific-machine-learning;deep-learning
677,ImageNet-D,Benchmark dataset for evaluating object detection robustness,A benchmark dataset (ImageNet-D) designed to evaluate the robustness of object detection models against various domain shifts and corruptions.,X1;X1-05,robustness_evaluation;benchmarking;dataset,dataset,Python,https://github.com/chenshuang-zhang/imagenet_d,,MIT,object-detection;robustness;benchmark;dataset
678,ResponsibleAI,Library for responsible AI development and evaluation,"A Python library designed to assist AI developers in various aspects of responsible AI, including fairness, robustness, and explainability evaluation.",X1;X1-05,fairness_evaluation;robustness_evaluation;responsible_ai,library,Python,https://github.com/cisco-open/ResponsibleAI,,Apache-2.0,responsible-ai;fairness;robustness;audit
679,TedEval,Fair evaluation metric for scene text detectors,"An implementation of a fair evaluation metric for scene text detectors that addresses issues with traditional IoU-based metrics, handling one-to-many and many-to-one matches.",X1;X1-05,model_evaluation;metric_calculation;scene_text_detection,library,Python,https://github.com/clovaai/TedEval,,MIT,evaluation-metric;scene-text;ocr;fairness
680,DeepEval,Framework for LLM evaluation and unit testing,"An open-source evaluation framework for Large Language Models (LLMs) that allows developers to unit test their LLM applications for metrics such as hallucination, bias, toxicity, and relevance.",X1;X1-05,model_evaluation;unit_testing;llm_auditing,framework,Python,https://github.com/confident-ai/deepeval,https://docs.confident-ai.com,Apache-2.0,llm;evaluation;testing;metrics
681,DeepTeam,Framework for automated red teaming of LLMs,"A framework designed to automate the red teaming process for Large Language Models (LLMs) and LLM systems, helping to identify vulnerabilities, safety issues, and biases.",X1;X1-05,red_teaming;safety_auditing;vulnerability_scanning,framework,Python,https://github.com/confident-ai/deepteam,,Apache-2.0,red-teaming;llm;security;safety
682,themis-ml,Library for fairness-aware machine learning,"A Python library that implements various fairness-aware machine learning algorithms and metrics, enabling researchers to measure and mitigate bias in ML models.",X1;X1-05,fairness_evaluation;bias_mitigation;model_training,library,Jupyter Notebook,https://github.com/cosmicBboy/themis-ml,,MIT,fairness;machine-learning;bias-mitigation;ethics
683,VerifyML,Toolkit for responsible AI workflows and reporting,"An open-source toolkit designed to help organizations implement responsible AI workflows, facilitating the documentation, verification, and reporting of model fairness and performance.",X1;X1-05,workflow_management;fairness_auditing;reporting,workflow,Python,https://github.com/cylynx/verifyml,,Apache-2.0,responsible-ai;workflow;documentation;audit
684,WEFE,Word Embeddings Fairness Evaluation Framework,"A framework for measuring and mitigating bias in word embedding models, providing a standardized way to evaluate fairness in natural language processing tasks.",X1;X1-05,fairness_evaluation;bias_measurement;nlp,framework,Python,https://github.com/dccuchile/wefe,https://wefe.readthedocs.io/,MIT,word-embeddings;fairness;bias;nlp
685,DebiAI,Bias detection and contextual evaluation tool for AI models,"A tool for detecting bias and performing contextual evaluation of AI models, allowing users to visualize model performance across different data subsets and identify potential fairness issues.",X1;X1-05,bias_detection;model_evaluation;visualization,platform,Vue,https://github.com/debiai/DebiAI,https://debiai.io/,Apache-2.0,bias-detection;evaluation;visualization;fairness
686,Coupled-Biased-Random-Walks,Outlier detection library for categorical data using coupled biased random walks,A Python implementation of the Coupled Biased Random Walks (CBRW) algorithm for outlier detection in categorical data. It models feature value interactions to identify anomalies in complex datasets.,X1;X1-05,anomaly_detection;data_analysis,library,Python,https://github.com/dkaslovsky/Coupled-Biased-Random-Walks,,MIT,outlier-detection;categorical-data;anomaly-detection
687,Aequitas,Open-source bias auditing and fair machine learning toolkit,A toolkit for auditing bias and fairness in machine learning models. It enables users to define and measure various fairness metrics across different population subgroups and visualize the results to inform mitigation strategies.,X1;X1-05,bias_auditing;fairness_evaluation,library,Python,https://github.com/dssg/aequitas,http://aequitas.dssg.io,MIT,fairness;bias-audit;machine-learning
688,acceptance-bench,Robust LLM evaluation framework for measuring acceptance vs refusal,"A framework for evaluating Large Language Models (LLMs) by measuring their acceptance or refusal of prompts across varying difficulty levels. It supports multi-prompt variations, temperature sweeping, and LLM-as-judge evaluation methods, focusing on safety and alignment.",X1;X1-05,safety_evaluation;alignment_testing;llm_benchmarking,platform,Python,https://github.com/ellydee/acceptance-bench,,MIT,llm-evaluation;safety;red-teaming
689,fairpy,Library of fair division algorithms,"An open-source Python library implementing various algorithms for fair division and resource allocation, supporting research in algorithmic game theory and economics.",X1;X1-05,fair_division;resource_allocation;mathematical_modeling,library,Python,https://github.com/erelsgl/fairpy,,GPL-3.0,fair-division;game-theory;algorithms
690,grafana-panel-what-if,Grafana panel for What-If predictive analysis with AI models,"A Grafana plugin designed for conducting What-If analysis on Artificial Intelligence models. It allows users to interactively manipulate input variables and observe predicted outcomes, facilitating model explainability and decision support within monitoring dashboards.",X1;X1-05,model_analysis;explainability;visualization,service,TypeScript,https://github.com/ertis-research/grafana-panel-what-if,,Apache-2.0,grafana;what-if-analysis;explainable-ai
691,Detectron,Research platform for object detection and segmentation,"FAIR's research platform for object detection research, implementing popular algorithms like Mask R-CNN and RetinaNet. It serves as a foundation for developing and evaluating computer vision models for scientific image analysis.",Cross-domain,object_detection;image_segmentation;image_analysis,platform,Python,https://github.com/facebookresearch/Detectron,,Apache-2.0,computer-vision;object-detection;deep-learning
692,disentangling-correlated-factors,Benchmarking suite for disentanglement algorithms,"A benchmarking suite designed to evaluate disentanglement algorithms, specifically focusing on robustness to correlated factors in data. It provides tools for generating datasets and measuring disentanglement metrics.",X1;X1-05,disentanglement_evaluation;robustness_benchmarking,library,Python,https://github.com/facebookresearch/disentangling-correlated-factors,,MIT,disentanglement;benchmarking;representation-learning
693,Polymath,AI agent framework for symbolic reasoning and mathematics,An AI agent framework that leverages symbolic reasoning and auxiliary tools to solve complex problems in mathematics and logic. It integrates neural networks with symbolic solvers to enhance reasoning capabilities.,X1;X1-05,symbolic_reasoning;mathematical_solving;inference,platform,Python,https://github.com/facebookresearch/polymath,,NOASSERTION,neuro-symbolic;reasoning;mathematics
694,UniBench,Library for evaluating VLM robustness across benchmarks,A Python library for evaluating the robustness of Vision-Language Models (VLMs) across a diverse set of benchmarks. It provides a unified interface for testing models against various distribution shifts and adversarial conditions.,X1;X1-05,robustness_evaluation;vlm_benchmarking,library,Jupyter Notebook,https://github.com/facebookresearch/unibench,,NOASSERTION,vlm;robustness;evaluation
695,Fairlearn,Toolkit to assess and improve fairness of machine learning models,A Python package that empowers developers of artificial intelligence systems to assess their systems' fairness and mitigate any observed unfairness issues. It contains mitigation algorithms and metrics for model evaluation.,X1;X1-05,fairness_assessment;bias_mitigation;model_evaluation,library,Python,https://github.com/fairlearn/fairlearn,https://fairlearn.org,MIT,fairness;machine-learning;responsible-ai
696,fairCORELS,Algorithm for learning fair and interpretable rule lists,"An implementation of an algorithm for learning fair rule lists, balancing predictive accuracy, interpretability, and fairness. It extends the CORELS (Certifiably Optimal RulE ListS) algorithm to include fairness constraints.",X1;X1-05,interpretable_ml;fair_modeling;rule_learning,solver,C++,https://github.com/ferryjul/fairCORELS,,GPL-3.0,fairness;interpretability;rule-lists
697,Jurity,Fairness and evaluation library for ML models,A Python library for evaluating the fairness and performance of machine learning models. It provides a set of metrics and tools to detect bias and assess model quality in a trustworthy AI context.,X1;X1-05,fairness_evaluation;model_auditing;metrics_calculation,library,Python,https://github.com/fidelity/jurity,,Apache-2.0,fairness;evaluation;metrics
698,infembed,Influence functions and embedding analysis for model debugging,A library for analyzing and debugging generative models by identifying test samples where the model fails. It likely uses influence functions or embedding analysis to trace errors back to training data or model characteristics.,X1;X1-05,debugging;interpretability;error_analysis,library,Python,https://github.com/guidelabs/infembed,,BSD-3-Clause,generative-ai;debugging;influence-functions
699,Gyro Diagnostics,AI Safety Diagnostics and Alignment Evaluation Lab,A toolkit for evaluating the safety and alignment of AI models. It provides diagnostic tools to assess potential risks and alignment issues in model behavior.,X1;X1-05,safety_evaluation;alignment,library,Python,https://github.com/gyrogovernance/diagnostics,,MIT,ai-safety;alignment;evaluation
700,EvalView,Test harness for AI agents focusing on safety and cost,"A pytest-style test harness designed for evaluating AI agents. It supports YAML-based scenarios, tool-call checks, and provides metrics for cost, latency, and safety evaluations, generating CI-friendly reports.",X1;X1-05,safety_evaluation;auditing;agent_evaluation,library,Python,https://github.com/hidai25/eval-view,,Apache-2.0,ai-agents;evaluation;safety;testing
701,HolisticAI,Library to assess and improve the trustworthiness of AI systems,"An open-source library for auditing AI systems across multiple dimensions of trustworthiness, including bias, fairness, efficacy, and safety. It provides metrics and mitigation techniques.",X1;X1-05,auditing;fairness_evaluation;safety_evaluation,library,Jupyter Notebook,https://github.com/holistic-ai/holisticai,,Apache-2.0,trustworthy-ai;audit;fairness;risk-management
702,Circular Bias Detection,Framework for detecting circular reasoning bias in AI evaluation,A statistical framework designed to detect circular reasoning bias in the evaluation of AI algorithms. It helps ensure the validity and reliability of model performance assessments.,X1;X1-05,bias_detection;evaluation_audit,library,Python,https://github.com/hongping-zh/circular-bias-detection,,MIT,bias;evaluation;statistics
703,ScoreCardModel,Library for developing credit scoring scorecards,"A Python library for building scorecard models, commonly used in credit scoring. It implements statistical methods like Weight of Evidence (WoE) and Information Value (IV) for feature engineering and logistic regression for modeling, providing interpretable risk models.",X1;X1-05,modeling;interpretability;risk_assessment,library,Python,https://github.com/hsz1273327/ScoreCardModel,,NOASSERTION,scorecard;credit-scoring;logistic-regression;interpretability
704,LLM Prompt Testing,Framework for testing LLM prompts with Responsible AI metrics,A testing framework specifically for Large Language Models (LLMs) that computes NLP and Responsible AI metrics for model-generated answers. It helps in auditing and evaluating the safety and quality of LLM outputs.,X1;X1-05,safety_evaluation;auditing;prompt_testing,library,Python,https://github.com/iamarunbrahma/llm-prompt-testing,,MIT,llm;responsible-ai;testing;metrics
705,MultiCorrupt,Benchmark for robust multi-modal 3D object detection,"A benchmark toolkit for evaluating the robustness of LiDAR-Camera fusion models in autonomous driving. It simulates diverse corruption types (e.g., misalignment, weather) to assess model performance under challenging conditions.",X1;X1-05,robustness_evaluation;benchmarking,library,Jupyter Notebook,https://github.com/ika-rwth-aachen/MultiCorrupt,,MIT,autonomous-driving;robustness;benchmark;3d-object-detection
706,ModelNet40-C,Benchmark dataset and toolkit for 3D point cloud robustness against common corruptions,"A benchmark suite designed to evaluate the robustness of 3D point cloud recognition models. It provides a set of common corruptions (e.g., noise, density changes) and tools to generate these corrupted datasets for rigorous model testing.",X1;X1-05,robustness_evaluation;data_corruption,dataset,Python,https://github.com/jiachens/ModelNet40-C,https://arxiv.org/abs/2201.12296,BSD-3-Clause,3d-point-cloud;robustness;benchmark;corruptions
707,ModelNet-C,Benchmarking toolkit for analyzing point cloud classification under corruptions,A comprehensive benchmark for evaluating the robustness of point cloud classification models. It includes generated corrupted data variants and evaluation scripts to analyze model performance under various noise and distortion conditions.,X1;X1-05,robustness_evaluation;data_corruption,dataset,Python,https://github.com/jiawei-ren/ModelNet-C,https://arxiv.org/abs/2202.03377,Apache-2.0,point-cloud;robustness;classification;benchmark
708,MobileSafetyBench,Benchmark for evaluating safety of autonomous agents in mobile device control,A safety evaluation benchmark specifically designed for autonomous agents operating in mobile environments. It provides scenarios and metrics to assess agent behavior and alignment with safety constraints.,X1;X1-05,safety_evaluation;agent_benchmarking,dataset,Jupyter Notebook,https://github.com/jylee425/mobilesafetybench,,Apache-2.0,ai-safety;autonomous-agents;benchmark;mobile-control
709,LiDAR-Camera Robust Benchmark,Toolkit to convert clean LiDAR-camera datasets into robustness benchmarks,A toolkit designed to generate robust benchmark datasets from clean LiDAR-camera data. It simulates various corruption scenarios to facilitate the evaluation of multi-modal perception models' robustness.,X1;X1-05,data_generation;robustness_evaluation,library,Python,https://github.com/kcyu2014/lidar-camera-robust-benchmark,,NOASSERTION,lidar;camera;robustness;data-generation
710,fairness,R package for computing and visualizing fair ML metrics,"An R library dedicated to calculating, visualizing, and comparing various fairness metrics for machine learning models. It supports multiple definitions of fairness to aid in algorithmic auditing.",X1;X1-05,fairness_evaluation;auditing,library,R,https://github.com/kozodoi/fairness,,NOASSERTION,r-package;fairness-metrics;visualization;algorithmic-bias
711,PointCloud-C,Benchmarking toolkit for point cloud perception robustness,A toolkit and benchmark for analyzing the robustness of point cloud perception models against various corruptions. It includes code for generating corrupted data and evaluating model performance.,X1;X1-05,robustness_evaluation;data_corruption,dataset,Python,https://github.com/ldkong1205/PointCloud-C,,NOASSERTION,point-cloud;robustness;benchmark;corruption-toolkit
712,RobustMVD,Benchmark for robust multi-view depth estimation,A benchmark suite for evaluating multi-view depth estimation models under robust conditions. It provides datasets and evaluation protocols to test model stability and accuracy.,X1;X1-05,robustness_evaluation;depth_estimation,dataset,Python,https://github.com/lmb-freiburg/robustmvd,,Apache-2.0,multi-view-depth;robustness;benchmark;computer-vision
713,convex_adversarial,Library for training neural networks with provable adversarial robustness,"A Python library that implements methods for training neural networks that are provably robust to adversarial attacks, utilizing convex relaxation techniques.",X1;X1-05,robust_training;verification,library,Python,https://github.com/locuslab/convex_adversarial,,MIT,adversarial-robustness;provable-defense;neural-networks;convex-relaxation
714,smoothing,Code for randomized smoothing to achieve certified adversarial robustness,An implementation of randomized smoothing techniques to provide certified adversarial robustness for deep learning models at ImageNet scale.,X1;X1-05,robustness_certification;randomized_smoothing,library,Python,https://github.com/locuslab/smoothing,https://arxiv.org/abs/1902.02918,NOASSERTION,certified-robustness;randomized-smoothing;imagenet;adversarial-defense
715,test-time-adaptation,Benchmark and library for online test-time adaptation methods,"A repository providing implementations and benchmarks for various online test-time adaptation (TTA) algorithms, allowing for the evaluation of model robustness and adaptation capabilities under distribution shifts.",X1;X1-05,robustness_evaluation;model_adaptation,library,Python,https://github.com/mariodoebler/test-time-adaptation,,MIT,test-time-adaptation;robustness;benchmark
716,Square Attack,Query-efficient black-box adversarial attack implementation,"An implementation of Square Attack, a score-based black-box adversarial attack that does not rely on local gradient information, used for evaluating the robustness of image classifiers.",X1;X1-05,adversarial_attack;robustness_evaluation,solver,Python,https://github.com/max-andr/square-attack,,BSD-3-Clause,adversarial-attacks;robustness;black-box-attack
717,FairBench,Comprehensive framework for AI fairness exploration and benchmarking,"A framework designed to facilitate the exploration and evaluation of fairness in AI models, providing various metrics and tools to assess bias.",X1;X1-05,fairness_evaluation;bias_detection,library,Jupyter Notebook,https://github.com/mever-team/FairBench,,NOASSERTION,fairness;benchmark;ai-ethics
718,BIPIA,Benchmark for indirect prompt injection attacks on LLMs,A benchmark dataset and evaluation framework for assessing the robustness of Large Language Models (LLMs) and their defenses against indirect prompt injection attacks.,X1;X1-05,robustness_evaluation;safety_testing,dataset,Python,https://github.com/microsoft/BIPIA,,NOASSERTION,llm;prompt-injection;benchmark
719,AI Agent Evals,Evaluation tool for AI agent applications,"A tool (often used as a GitHub Action) to evaluate AI agent applications using model-as-a-judge techniques, focusing on content safety and mathematical metrics.",X1;X1-05,safety_evaluation;agent_assessment,tool,Python,https://github.com/microsoft/ai-agent-evals,,MIT,ai-agents;evaluation;safety
720,PromptBench,Unified evaluation framework for large language models,"A comprehensive framework for evaluating Large Language Models (LLMs) across various tasks, including robustness against adversarial prompts and other safety concerns.",X1;X1-05,robustness_evaluation;llm_benchmarking,library,Python,https://github.com/microsoft/promptbench,,MIT,llm;benchmark;robustness
721,GenBit,Gender bias identification tool for text,A library within the Responsible AI Toolbox focused on measuring and identifying gender bias in text corpora and model outputs.,X1;X1-05,bias_detection;fairness_evaluation,library,Python,https://github.com/microsoft/responsible-ai-toolbox-genbit,,NOASSERTION,gender-bias;nlp;responsible-ai
722,Responsible AI Mitigations,Library for implementing Responsible AI mitigations,A Python library designed to help practitioners implement mitigation strategies for data and model issues identified during responsible AI assessment.,X1;X1-05,bias_mitigation;data_processing,library,Jupyter Notebook,https://github.com/microsoft/responsible-ai-toolbox-mitigations,,MIT,mitigation;responsible-ai;fairness
723,Responsible AI Privacy,Privacy estimation library using membership inference attacks,"A library for statistically estimating the privacy risks of machine learning pipelines, specifically focusing on resistance to membership inference attacks.",X1;X1-05,privacy_auditing;membership_inference,library,Python,https://github.com/microsoft/responsible-ai-toolbox-privacy,,MIT,privacy;security;auditing
724,Responsible AI Tracker,JupyterLab extension for tracking RAI experiments,"A tool for tracking, managing, and comparing Responsible AI mitigations and experiments within JupyterLab, facilitating audit trails and reproducibility.",X1;X1-05,experiment_tracking;auditing,tool,TypeScript,https://github.com/microsoft/responsible-ai-toolbox-tracker,,MIT,jupyterlab-extension;tracking;responsible-ai
725,AudioMarkBench,Benchmark for audio watermarking robustness,A dataset and codebase for benchmarking the robustness of audio watermarking techniques against various attacks and perturbations.,X1;X1-05,robustness_evaluation;watermarking_analysis,dataset,Python,https://github.com/mileskuo42/AudioMarkBench,,MPL-2.0,audio;watermarking;robustness
726,FortisAVQA,Robustness evaluation and bias mitigation for AVQA,A toolkit for evaluating robustness and mitigating bias in Audio-Visual Question Answering (AVQA) models.,X1;X1-05,robustness_evaluation;bias_mitigation,library,Python,https://github.com/mira-ai-lab/fortisavqa,,GPL-3.0,avqa;robustness;bias
727,MAITE,Modular AI Trustworthy Engineering library,"A library of common types, protocols, and utilities designed to support AI test and evaluation workflows, developed by MIT Lincoln Laboratory.",X1;X1-05,test_and_evaluation;trustworthy_engineering,library,Python,https://github.com/mit-ll-ai-technology/maite,,MIT,testing;evaluation;protocols
728,Agentic Security,Agentic LLM vulnerability scanner and red teaming kit,A tool designed to scan for vulnerabilities in LLM agents and perform red teaming operations to assess security and safety risks.,X1;X1-05,red_teaming;vulnerability_scanning,tool,Python,https://github.com/msoedov/agentic_security,,Apache-2.0,llm;security;red-teaming
729,fairensics,Python library for discovering and mitigating biases in machine learning models,A Python library designed to help researchers and practitioners discover and mitigate biases in machine learning models and datasets. It provides implementations of various fairness metrics and mitigation algorithms.,X1;X1-05,bias_detection;fairness_mitigation,library,Python,https://github.com/nikikilbertus/fairensics,,MIT,fairness;bias-mitigation;machine-learning
730,GenAIEval,Evaluation framework for Generative AI performance and safety,"A comprehensive evaluation framework, benchmark, and scorecard for Generative AI models. It targets performance metrics like throughput and latency, as well as accuracy, safety, and hallucination detection.",X1;X1-05,model_evaluation;safety_benchmarking;hallucination_detection,platform,Jupyter Notebook,https://github.com/opea-project/GenAIEval,,Apache-2.0,genai;evaluation;benchmark;safety
731,huggingface_ding,Utility for integrating DI-engine RL models with Hugging Face,"Auxiliary tools for pulling and loading reinforcement learning models based on DI-engine from the Hugging Face Hub, and pushing them with auto-created model cards. Facilitates the management and sharing of scientific RL models.",X1;X1-05,model_management;reinforcement_learning,library,Python,https://github.com/opendilab/huggingface_ding,,Apache-2.0,reinforcement-learning;huggingface;model-loading
732,ethosai,Platform for automating AI testing and ensuring model trustworthiness,"A tool designed to automate the testing of AI models to ensure their trustworthiness. It likely provides interfaces for evaluating model performance, fairness, and robustness.",X1;X1-05,model_testing;trustworthiness_evaluation,platform,Vue,https://github.com/osnHQ/ethosai,,GPL-3.0,ai-testing;trustworthiness;automation
733,openpilot_in_carla,Integration of Openpilot with Carla simulator for safety evaluation,Provides configuration and tools to integrate the Openpilot autonomous driving stack with the Carla simulator. This setup is specifically designed for safety evaluation using almost-safe set based methods and includes radar input enhancements.,X1;X1-05,safety_evaluation;simulation;autonomous_driving,workflow,Python,https://github.com/pgchui/openpilot_in_carla,,None,carla;openpilot;safety-evaluation;simulation
734,visual-auditor,Interactive tool for auditing model biases and vulnerabilities,An interactive tool for scalable auditing of machine learning model biases and vulnerabilities. It provides interpretable mitigation strategies and visualization to help researchers understand model behavior.,X1;X1-05,visual_auditing;bias_detection;interpretability,solver,Jupyter Notebook,https://github.com/poloclub/visual-auditor,,MIT,visualization;auditing;bias
735,REVISE,Tool for measuring and mitigating bias in visual datasets,REVISE (REvealing VIsual biaSEs) is a tool designed to measure and mitigate biases in visual datasets. It helps researchers identify potential issues in data distribution and representation before model training.,X1;X1-05,dataset_auditing;bias_mitigation;computer_vision,solver,Jupyter Notebook,https://github.com/princetonvisualai/revise-tool,,MIT,dataset-bias;computer-vision;auditing
736,promptfoo,CLI tool for evaluating and red-teaming LLMs,"A command-line tool for testing, evaluating, and red-teaming Large Language Models (LLMs). It allows users to compare performance across different models (GPT, Claude, Llama, etc.), scan for vulnerabilities, and ensure safety and accuracy in LLM applications.",X1;X1-05,llm_evaluation;red_teaming;vulnerability_scanning,solver,TypeScript,https://github.com/promptfoo/promptfoo,https://www.promptfoo.dev/,MIT,llm;evaluation;red-teaming;security
737,audit-ai,Library for detecting demographic bias in ML models,A Python library designed to detect demographic differences and biases in the output of machine learning models or other assessments. It provides statistical tests to evaluate fairness.,X1;X1-05,bias_detection;fairness_auditing,library,Python,https://github.com/pymetrics/audit-ai,,MIT,bias-detection;fairness;auditing
738,MAGICAL,Benchmark suite for robust imitation learning,The MAGICAL benchmark suite is designed to evaluate the robustness of imitation learning algorithms. It provides a set of tasks and environments to test how well agents generalize to variations in the environment.,X1;X1-05,imitation_learning;robustness_benchmarking,dataset,Python,https://github.com/qxcv/magical,,ISC,imitation-learning;benchmark;robustness
739,AuditNLG,Library for auditing and evaluating the trustworthiness of generative AI language models,"AuditNLG is a Python library developed by Salesforce for auditing Generative AI language models. It provides tools to measure and evaluate trustworthiness, safety, and fairness in text generation, helping researchers identify biases and risks in NLG systems.",X1;X1-05;Computer Science,auditing;evaluation;trustworthiness,library,Python,https://github.com/salesforce/AuditNLG,,BSD-3-Clause,nlp;auditing;trustworthiness;generative-ai
740,Fair-PCA,Implementation of Fair PCA algorithm for dimensionality reduction with fairness constraints,"This repository contains the MATLAB implementation of the Fair PCA algorithm. It provides a method for performing Principal Component Analysis while satisfying fairness constraints, ensuring that the dimensionality reduction process does not disproportionately disadvantage specific subgroups.",X1;X1-05;Mathematics,dimensionality_reduction;fairness,solver,MATLAB,https://github.com/samirasamadi/Fair-PCA,,MIT,pca;fairness;algorithm;dimensionality-reduction
741,OpenAgentSafety,Framework for evaluating the safety of AI agents in realistic environments,"OpenAgentSafety is a framework designed to evaluate the safety of AI agents. It provides realistic environments and scenarios to test agents for potential safety risks, ensuring they operate reliably and ethically in complex settings.",X1;X1-05;Computer Science,safety_evaluation;agent_auditing,workflow,Python,https://github.com/sani903/OpenAgentSafety,,MIT,ai-safety;agents;evaluation;benchmark
742,scabench,Benchmark framework for evaluating AI audit agents using real-world data,"SCABench is a framework for evaluating AI audit agents. It utilizes recent real-world data to benchmark the performance of agents designed to audit other AI systems, focusing on their ability to detect vulnerabilities or compliance issues.",X1;X1-05;Computer Science,benchmarking;auditing,library,Python,https://github.com/scabench-org/scabench,,MIT,benchmark;auditing;ai-agents;security
743,frai,"Toolkit for responsible AI auditing, reporting, and risk assessment","frai is an open-source toolkit for responsible AI that includes a CLI and SDK. It helps developers scan code, collect evidence, and generate model cards and risk files, facilitating the auditing and documentation process for AI models.",X1;X1-05;Computer Science,auditing;documentation;risk_assessment,workflow,JavaScript,https://github.com/sebuzdugan/frai,,MIT,responsible-ai;model-cards;auditing;cli
744,ChemBench,Benchmark datasets and tools for molecular machine learning,ChemBench provides benchmark datasets (MoleculeNet) and tools (MolMapNet) for evaluating machine learning models in chemistry. It serves as a standard resource for testing molecular property prediction and structure analysis algorithms.,Chemistry;X1-05,benchmarking;molecular_property_prediction,dataset,HTML,https://github.com/shenwanxiang/ChemBench,,NOASSERTION,chemistry;benchmark;moleculenet;drug-discovery
745,SIUO,Cross-modality safety alignment framework for multimodal models,"SIUO is a framework for Cross-Modality Safety Alignment, designed to improve the safety and robustness of multimodal AI models. It addresses challenges in aligning vision and language modalities to prevent harmful outputs.",X1;X1-05;Computer Science,safety_alignment;multimodal_learning,library,HTML,https://github.com/sinwang20/SIUO,,None,safety;alignment;multimodal;llm
746,ASTRA-RL,Adaptive Stress Testing for Robust AI toolbox,ASTRA-RL (Adaptive Stress Testing for Robust AI) is a toolbox for stress testing AI systems. It uses reinforcement learning to find failure modes and improve the robustness of AI models through adversarial training and adaptive testing scenarios.,X1;X1-05;Computer Science,stress_testing;robustness;adversarial_training,library,Python,https://github.com/sisl/astra-rl,,MIT,robustness;stress-testing;reinforcement-learning;safety
747,NoW Evaluation,Evaluation toolkit for 3D face reconstruction on the NoW benchmark,This repository contains the official evaluation scripts for the NoW Benchmark Dataset. It provides metrics to measure the accuracy and robustness of 3D face reconstruction methods from single images under varying conditions.,Computer Vision;X1-05,evaluation;3d_reconstruction,library,Python,https://github.com/soubhiksanyal/now_evaluation,,None,3d-face;benchmark;evaluation;computer-vision
748,VERITE,Benchmark for multimodal misinformation detection accounting for unimodal bias,VERITE is a robust benchmark designed for evaluating multimodal misinformation detection models. It specifically accounts for unimodal bias to ensure that models are truly leveraging multimodal information for verification.,X1;X1-05;Computer Science,misinformation_detection;benchmarking,dataset,Python,https://github.com/stevejpapad/image-text-verification,,Apache-2.0,misinformation;multimodal;benchmark;verification
749,LLaMA-MiLe-Loss,Loss function implementation for mitigating learning difficulty bias in LLMs,"This repository implements the MiLe (Mitigating Learning difficulty) Loss, a method designed to reduce bias in generative language models by accounting for the difficulty of learning different samples. It serves as a tool for improving model fairness and alignment.",X1;X1-05;Computer Science,bias_mitigation;model_training,solver,Python,https://github.com/suu990901/LLaMA-MiLe-Loss,,None,llm;bias-mitigation;loss-function;fairness
750,NVIDIA Quantum Hybrid,Prototype hybrid classical-quantum workflow with safety policy gates,"This project provides a prototype workflow for hybrid classical-quantum computing. It includes policy gates for AI safety and security, supports Qiskit backends, and emits audit logs, serving as a template for secure quantum-classical integrations.",Quantum Computing;X1;X1-05,workflow_orchestration;safety_policy,workflow,Python,https://github.com/sylvesterkaczmarek/nvidia-quantum-hybrid,,MIT,quantum-computing;hybrid-workflow;safety;audit
751,PhiSat-2 Trustworthy AI,Trustworthy onboard AI framework for satellite earth observation,"This repository contains code for trustworthy onboard AI for the PhiSat-2 satellite mission. It includes tools for model calibration, telemetry, and execution in constrained environments (ONNX/INT8), specifically for Earth Observation tasks.",Aerospace;X1;X1-05,onboard_inference;calibration;earth_observation,workflow,Python,https://github.com/sylvesterkaczmarek/phisat2-trustworthy-onboard-ai,,MIT,satellite;edge-ai;trustworthy-ai;earth-observation
752,LIBERO-plus,Benchmark for robustness analysis of vision-language-action models,LIBERO-plus is a generalized benchmark designed for in-depth robustness analysis of vision-language-action models in robotics. It provides environments and metrics to evaluate how well agents generalize and handle perturbations.,Robotics;X1;X1-05,robustness_analysis;benchmarking,dataset,Python,https://github.com/sylvestf/LIBERO-plus,,None,robotics;benchmark;robustness;vla-models
753,FairLens,Library for identifying bias and measuring fairness in data,FairLens is an open-source Python library used to identify bias and measure fairness in datasets. It provides statistical metrics and visualization tools to help data scientists understand and mitigate biases before model training.,X1;X1-05;Data Science,fairness_analysis;bias_detection,library,Python,https://github.com/synthesized-io/fairlens,,BSD-3-Clause,fairness;bias;data-analysis;visualization
754,Re-Align,Alignment framework to mitigate hallucinations in Vision Language Models,Re-Align is a framework that leverages image retrieval to mitigate hallucinations in Vision Language Models (VLMs). It aligns model outputs with retrieved visual evidence to improve factual accuracy and trustworthiness.,X1;X1-05;Computer Vision,alignment;hallucination_mitigation,workflow,Python,https://github.com/taco-group/Re-Align,,Apache-2.0,vlm;alignment;hallucination;trustworthiness
755,rGAN,Label-Noise Robust Generative Adversarial Networks implementation,"A PyTorch implementation of rGAN (Label-Noise Robust Generative Adversarial Networks), designed to learn clean data distributions from noisy training data in generative modeling tasks.",X1;X1-05,generative_modeling;robustness,solver,Python,https://github.com/takuhirok/rGAN,,MIT,gan;label-noise;robustness
756,Fairness Indicators,Fairness evaluation and visualization toolkit for TensorFlow models,"A library that enables easy computation of commonly-identified fairness metrics for binary and multiclass classifiers, allowing researchers to evaluate model performance across different user slices.",X1;X1-05,fairness_evaluation;auditing,library,Python,https://github.com/tensorflow/fairness-indicators,https://www.tensorflow.org/tfx/guide/fairness_indicators,Apache-2.0,fairness;evaluation;visualization
757,Model Card Toolkit,Toolkit for automating model card generation,"A toolkit that streamlines and automates the generation of Model Cards, which are documents that provide context and transparency into a machine learning model's development and performance.",X1;X1-05,auditing;documentation,library,Python,https://github.com/tensorflow/model-card-toolkit,https://www.tensorflow.org/responsible_ai/model_card_toolkit/guide,Apache-2.0,model-cards;transparency;auditing
758,AISafetyLab,"Comprehensive framework for AI safety attack, defense, and evaluation","A framework covering safety attack, defense, and evaluation for AI models, providing a collection of methods to assess and improve model robustness.",X1;X1-05,safety_evaluation;adversarial_attack;defense,platform,Python,https://github.com/thu-coai/AISafetyLab,,MIT,ai-safety;adversarial-attacks;defense
759,cotk,Toolkit for fast development and fair evaluation of text generation,"Conversational Toolkit (cotk) is an open-source toolkit designed for fast development and fair evaluation of text generation models, providing standard metrics and datasets.",X1;X1-05,evaluation;text_generation,library,Python,https://github.com/thu-coai/cotk,https://cotk.readthedocs.io/,Apache-2.0,nlp;evaluation;text-generation
760,3D_Corruptions_AD,Benchmark for 3D object detection robustness in autonomous driving,A benchmark suite for evaluating the robustness of 3D object detection models against common corruptions in autonomous driving scenarios.,X1;X1-05,robustness_benchmarking;object_detection,dataset,Python,https://github.com/thu-ml/3D_Corruptions_AD,,MIT,robustness;autonomous-driving;3d-detection
761,MMTrustEval,Toolbox for benchmarking trustworthiness of multimodal LLMs,"A toolbox designed for benchmarking the trustworthiness of multimodal large language models, covering various safety and reliability dimensions.",X1;X1-05,trustworthiness_benchmarking;multimodal_evaluation,library,Python,https://github.com/thu-ml/MMTrustEval,,CC-BY-SA-4.0,multimodal;trustworthiness;llm
762,STAIR,Safety alignment with introspective reasoning,"Codebase for 'STAIR: Improving Safety Alignment with Introspective Reasoning', providing methods to align language models for safety using introspective reasoning techniques.",X1;X1-05,safety_alignment;reasoning,solver,Python,https://github.com/thu-ml/STAIR,,MIT,safety-alignment;llm;reasoning
763,ARES,Python library for adversarial machine learning and robustness benchmarking,"A Python library focused on adversarial machine learning, specifically for benchmarking adversarial robustness of models against various attacks.",X1;X1-05,adversarial_robustness;benchmarking,library,Python,https://github.com/thu-ml/ares,https://ares-ml.readthedocs.io/,Apache-2.0,adversarial-ml;robustness;benchmarking
764,Tiger,Toolkit for building trustworthy LLM applications,"An open-source LLM toolkit that includes modules for AI safety (TigerArmor), RAG (TigerRAG), and fine-tuning (TigerTune) to build trustworthy applications.",X1;X1-05,safety_alignment;rag;fine_tuning,library,Jupyter Notebook,https://github.com/tigerlab-ai/tiger,,Apache-2.0,llm;trustworthiness;safety
765,Fast Adversarial Training,Implementation of fast adversarial training methods,"Code for 'Understanding and Improving Fast Adversarial Training', providing implementations for efficient adversarial training to improve model robustness.",X1;X1-05,adversarial_training;robustness,solver,Python,https://github.com/tml-epfl/understanding-fast-adv-training,,None,adversarial-training;robustness;optimization
766,Image Crop Analysis,Code for analyzing fairness metrics in image cropping,"A repository containing code and metrics for analyzing fairness and representation in image cropping algorithms, specifically focusing on Twitter's saliency algorithm.",X1;X1-05,fairness_analysis;auditing,library,Jupyter Notebook,https://github.com/twitter-research/image-crop-analysis,,Apache-2.0,fairness;image-cropping;bias-analysis
767,Armory,Adversarial robustness evaluation test bed,A container-based test bed for evaluating the adversarial robustness of machine learning models against various attacks and scenarios.,X1;X1-05,robustness_evaluation;adversarial_defense,platform,Python,https://github.com/twosixlabs/armory,https://armory.readthedocs.io/,MIT,adversarial-robustness;evaluation;testbed
768,Metric-Fairness,Analysis of social bias in language model-based metrics,"Code for analyzing social bias in language model-based metrics (like BERTScore) for text generation, providing tools to assess metric fairness.",X1;X1-05,fairness_analysis;metric_evaluation,library,Jupyter Notebook,https://github.com/txsun1997/Metric-Fairness,,MIT,fairness;nlp;metrics
769,CarDreamer,World model based autonomous driving platform,"A world model-based autonomous driving platform implemented in CARLA, enabling simulation and training of autonomous driving agents.",X1;X1-05,autonomous_driving_simulation;world_modeling,platform,Python,https://github.com/ucd-dare/CarDreamer,,NOASSERTION,autonomous-driving;world-model;simulation
770,WAVES,Benchmark for image watermark robustness,Code for benchmarking the robustness of image watermarks against various attacks and distortions.,X1;X1-05,watermark_robustness;benchmarking,dataset,Python,https://github.com/umd-huang-lab/WAVES,,None,watermarking;robustness;benchmarking
771,Balanced-Datasets-Are-Not-Enough,Gender bias estimation and mitigation in deep image representations,"Implementation of methods to estimate and mitigate gender bias in deep image representations, going beyond simple dataset balancing.",X1;X1-05,bias_mitigation;fairness_analysis,solver,Python,https://github.com/uvavision/Balanced-Datasets-Are-Not-Enough,,None,bias-mitigation;computer-vision;fairness
772,Double-Hard-Debias,Word embedding gender bias mitigation tool,"Implementation of Double-Hard Debias, a method for tailoring word embeddings to mitigate gender bias.",X1;X1-05,bias_mitigation;nlp,solver,Jupyter Notebook,https://github.com/uvavision/Double-Hard-Debias,,None,debiasing;word-embeddings;fairness
773,MagnetLoss-PyTorch,PyTorch implementation of Magnet Loss for deep metric learning,"A PyTorch implementation of Magnet Loss, a deep metric learning technique used for learning embeddings where local structure is preserved.",X1;X1-05,metric_learning;loss_function,library,Python,https://github.com/vithursant/MagnetLoss-PyTorch,,MIT,metric-learning;loss-function;pytorch
774,SDN,Scene bias mitigation in action recognition,"Implementation of a method to mitigate scene bias in action recognition models, improving generalization to unseen environments.",X1;X1-05,bias_mitigation;action_recognition,solver,Python,https://github.com/vt-vl-lab/SDN,,MIT,bias-mitigation;computer-vision;action-recognition
775,Trojan-Activation-Attack,Trojan activation attack for LLM safety alignment,"Implementation of Trojan Activation Attack, a method to attack Large Language Models using activation steering to test safety alignment.",X1;X1-05,adversarial_attack;safety_alignment,solver,Python,https://github.com/wang2226/Trojan-Activation-Attack,,None,llm;adversarial-attack;safety
776,RoboBEV,Benchmark for BEV perception robustness in autonomous driving,A benchmark for evaluating and improving the robustness of Bird's Eye View (BEV) perception models in autonomous driving scenarios.,X1;X1-05,robustness_benchmarking;autonomous_driving,dataset,Python,https://github.com/worldbench/RoboBEV,,None,robustness;bev;autonomous-driving
777,Adversarial_Long-Tail,Adversarial robustness under long-tailed distribution,PyTorch implementation of methods for improving adversarial robustness in models trained on long-tailed distributions.,X1;X1-05,robustness;adversarial_defense,solver,Python,https://github.com/wutong16/Adversarial_Long-Tail,,None,robustness;long-tail;adversarial-learning
778,Structural Crack Detection,Deep learning tool for structural crack detection and classification,"A deep learning-based tool for automated visual inspection in aircraft maintenance, specifically for detecting and classifying structural cracks.",X1;X1-05,defect_detection;image_classification,solver,Python,https://github.com/xaviergoby/Deep-Learning-and-Computer-Vision-for-Structural-Crack-Detection-And-Classification,,None,crack-detection;computer-vision;maintenance
779,BETA,Method for mitigating confirmation bias in domain adaptation of black-box predictors,"A Python implementation of the 'Divide to Adapt' approach to mitigate confirmation bias during the domain adaptation process for black-box predictors, enhancing model reliability.",X1;X1-05,bias_mitigation;domain_adaptation,solver,Python,https://github.com/xyupeng/BETA,,None,domain-adaptation;bias-mitigation;black-box-optimization
780,semisup-adv,Semi-supervised learning framework for improving adversarial robustness,"Code implementation for using semi-supervised learning techniques to enhance the adversarial robustness of machine learning models, as presented in NeurIPS 2019.",X1;X1-05,adversarial_robustness;semi_supervised_learning,solver,Python,https://github.com/yaircarmon/semisup-adv,https://arxiv.org/pdf/1905.13736.pdf,MIT,adversarial-robustness;semi-supervised-learning;deep-learning
781,MLLM_safety_study,Safety alignment framework for multi-modal large language models,Official code for a CVPR 2025 paper investigating the necessity of curated malicious data for safety alignment in multi-modal large language models (MLLMs).,X1;X1-05,safety_alignment;model_auditing,solver,Python,https://github.com/ybwang119/MLLM_safety_study,,None,mllm;safety-alignment;multimodal
782,Robustness-Aware-Pruning-ADMM,Model pruning framework balancing adversarial robustness and compression,Implementation of a robustness-aware pruning method using ADMM (Alternating Direction Method of Multipliers) to achieve both model compression and adversarial robustness.,X1;X1-05,model_compression;adversarial_robustness,solver,Python,https://github.com/yeshaokai/Robustness-Aware-Pruning-ADMM,,None,pruning;admm;adversarial-robustness
783,pytorch-adversarial-training,PyTorch implementation of adversarial training for robust classification,"A PyTorch implementation for adversarial training on datasets like MNIST and CIFAR-10, including visualization tools for robustness classifiers.",X1;X1-05,adversarial_training;robustness_visualization,solver,Python,https://github.com/ylsung/pytorch-adversarial-training,,None,pytorch;adversarial-training;robustness
784,bursting-burden,Assessment tool for counterfactual-based fairness metrics,"Code accompanying a paper that assesses the 'Burden' metric, a counterfactual-based fairness metric, providing tools to evaluate algorithmic fairness.",X1;X1-05,fairness_evaluation;metric_assessment,solver,Jupyter Notebook,https://github.com/yochem/bursting-burden,,MIT,fairness;counterfactuals;metrics
785,fairml-farm,Collection of fair machine learning algorithm implementations,A library providing implementations of various fair machine learning algorithms to facilitate research and application of fairness in AI.,X1;X1-05,fairness_algorithms;bias_mitigation,library,Python,https://github.com/yoshavit/fairml-farm,,MIT,fair-ml;fairness;algorithms
786,VLGuard,Safety fine-tuning baseline for Vision Large Language Models,"Implementation of VLGuard, a method for safety fine-tuning of Vision Large Language Models (VLLMs) with minimal cost, as presented at ICML 2024.",X1;X1-05,safety_finetuning;vllm_alignment,solver,Python,https://github.com/ys-zong/VLGuard,,None,vllm;safety;fine-tuning
787,MT-Consistency,Framework for evaluating and mitigating acquiescence bias in LLMs,"A repository investigating LLMs' tendency to exhibit acquiescence bias in sequential QA interactions, including evaluation methods, datasets, and mitigation code.",X1;X1-05,bias_evaluation;consistency_check,benchmark,Python,https://github.com/yubol-bobo/MT-Consistency,,MIT,llm;bias;consistency
788,RoDLA,Benchmark for robustness of document layout analysis models,A benchmarking tool designed to evaluate the robustness of Document Layout Analysis (DLA) models against various perturbations.,X1;X1-05,robustness_benchmarking;document_analysis,benchmark,Python,https://github.com/yufanchen96/RoDLA,,Apache-2.0,robustness;benchmark;document-layout-analysis
789,MTSA,Multi-turn safety alignment for LLMs via multi-round red-teaming,"Official implementation of MTSA, a method for aligning Large Language Models for safety through multi-round red-teaming interactions.",X1;X1-05,safety_alignment;red_teaming,solver,Python,https://github.com/yuki-younai/MTSA,,None,llm;safety;red-teaming
790,CPP,Depth prediction improvement by mitigating pose distribution bias,"Code for the CVPR 2021 paper 'Camera Pose Matters', providing methods to improve depth prediction by mitigating pose distribution bias.",X1;X1-05,bias_mitigation;depth_prediction,solver,Python,https://github.com/yunhan-zhao/CPP,,MIT,computer-vision;bias;depth-prediction
791,EDITS,Modeling and mitigating data bias for Graph Neural Networks,"Open source code for the paper 'EDITS', focusing on modeling and mitigating data bias in Graph Neural Networks (GNNs).",X1;X1-05,bias_mitigation;graph_neural_networks,solver,Python,https://github.com/yushundong/EDITS,,None,gnn;bias;graph-mining
792,PyGDebias,Library for fairness-aware graph mining algorithms,An open-source library providing graph datasets and implementations of fairness-aware graph mining algorithms (PyGDebias).,X1;X1-05,fairness_algorithms;graph_mining,library,Python,https://github.com/yushundong/PyGDebias,,BSD-2-Clause,graph-mining;fairness;debiasing
793,What-If-Explainability,Explainability tool for LightGBM using FastTreeShap and What-If Tool,A notebook-based tool demonstrating how to explain LightGBM tree models using FastTreeShap (Shapley values) and Google's What-If Tool.,X1;X1-05,explainability;model_auditing,solver,Jupyter Notebook,https://github.com/zabir-nabil/What-If-Explainability,,MIT,explainability;shap;what-if-tool
794,dps-benchmark,Benchmark for diffusion posterior sampling in Bayesian inverse problems,A framework for fair and objective benchmarking of diffusion posterior sampling algorithms applied to Bayesian inverse problems.,X1;X1-05,benchmarking;bayesian_inference,benchmark,Python,https://github.com/zacmar/dps-benchmark,,None,diffusion-models;bayesian;inverse-problems
795,AIM-Fair,Algorithmic fairness via selective fine-tuning with synthetic data,"Implementation of AIM-Fair, a method to advance algorithmic fairness by selectively fine-tuning biased models using contextual synthetic data.",X1;X1-05,fairness_optimization;fine_tuning,solver,Python,https://github.com/zengqunzhao/AIM-Fair,,MIT,fairness;synthetic-data;fine-tuning
796,Debiased-Chat,Gender bias mitigation for neural dialogue generation,PyTorch implementation of adversarial learning techniques to mitigate gender bias in neural dialogue generation models.,X1;X1-05,bias_mitigation;dialogue_generation,solver,Python,https://github.com/zgahhblhc/Debiased-Chat,,MIT,gender-bias;dialogue-systems;adversarial-learning
797,DebiAN,Unknown bias discovery and mitigation network,"Official code for 'Discover and Mitigate Unknown Biases with Debiasing Alternate Networks', providing a framework to handle unknown biases in models.",X1;X1-05,bias_discovery;bias_mitigation,solver,Python,https://github.com/zhihengli-UR/DebiAN,,GPL-3.0,bias-mitigation;deep-learning;fairness
798,PE-RLHF,Safe autonomous driving via RLHF and physics knowledge,"Code for 'Trustworthy Human-AI Collaboration', integrating Reinforcement Learning with Human Feedback (RLHF) and physics knowledge for safe autonomous driving.",X1;X1-05,safety_alignment;rlhf,solver,Python,https://github.com/zilin-huang/PE-RLHF,,MIT,autonomous-driving;rlhf;safety
799,terrain_benchmark,Robustness benchmark for legged locomotion on terrains,A benchmark suite for evaluating the robustness of legged locomotion control policies across various terrain types.,X1;X1-05,robustness_benchmarking;robotics_control,benchmark,Jupyter Notebook,https://github.com/zita-ch/terrain_benchmark,,None,robotics;robustness;locomotion
800,AdvTrajectoryPrediction,Adversarial robustness evaluation for trajectory prediction,Implementation of methods to evaluate and improve the adversarial robustness of trajectory prediction models for autonomous vehicles.,X1;X1-05,adversarial_robustness;trajectory_prediction,solver,Python,https://github.com/zqzqz/AdvTrajectoryPrediction,https://arxiv.org/abs/2201.05057,None,autonomous-vehicles;adversarial-robustness;trajectory-prediction
