id,name,one_line_profile,detailed_description,domains,subtask_category,application_level,primary_language,repo_url,help_website,license,tags
1,telemetry-parser,Parser for real-time sensor telemetry metadata from video files and flight logs,"A tool to extract and parse real-time physical measurements (gyroscope, accelerometer, GPS) embedded in video files (GoPro GPMF, Sony, Insta360) and flight logs (Betaflight). This data is essential for drone dynamics analysis, SLAM research, and biomechanics.",D1;D1-01,data_extraction;sensor_processing,solver,Rust,https://github.com/AdrianEddy/telemetry-parser,,Apache-2.0,telemetry;gpmf;sensor-data;drone;blackbox
2,xsv,"A fast CSV command line toolkit for data slicing, indexing, and statistical analysis","A high-performance command-line toolkit for processing CSV data. It provides commands for indexing, slicing, partitioning, and computing summary statistics (mean, median, frequency) on large tabular datasets without loading them entirely into memory. Widely used in bioinformatics and data science pipelines for preprocessing.",D1;D1-01,data_processing;statistics;filtering,solver,Rust,https://github.com/BurntSushi/xsv,,Unlicense,csv;cli;data-processing;statistics
3,PySysML2,Parser for SysML 2.0 textual modeling language for data analysis,"A Python-based parser for the SysML 2.0 textual modeling language. It parses SysML 2.0 models into Python objects to enable data science and analysis on system engineering models, facilitating Model-Based Systems Engineering (MBSE) workflows.",D1;D1-01,parsing;modeling;systems_engineering,library,Python,https://github.com/DAF-Digital-Transformation-Office/PySysML2,,Apache-2.0,sysml;mbse;parsing;systems-engineering
4,configr,Configuration file parser (JSON/INI/YAML/TOML) for R language workflows,"An R package that implements parsers for multiple configuration formats (JSON, INI, YAML, TOML) to facilitate the setting and writing of configuration files in R-based scientific workflows and bioinformatics pipelines.",D1;D1-01,data_parsing;workflow_configuration,library,R,https://github.com/Miachol/configr,,NOASSERTION,r-package;configuration;parser;json;yaml
5,dataframely,Declarative data frame validation library for Polars and Pandas,A Python library for validating data frames (Polars and Pandas) using a declarative schema approach. It is used in data science and scientific data processing pipelines to ensure data quality and structural integrity.,D1;D1-01,data_validation;quality_control,library,Python,https://github.com/Quantco/dataframely,,BSD-3-Clause,validation;dataframe;polars;pandas;data-quality
6,missingno,Missing data visualization module for Python,A flexible and easy-to-use Python library for visualizing missing data in pandas dataframes. It provides a small toolset of flexible and easy-to-use missing data visualizations and utilities that allow data scientists to get a quick visual summary of the completeness (or lack thereof) of their dataset.,D1;D1-01,data_visualization;quality_control,library,Python,https://github.com/ResidentMario/missingno,,MIT,visualization;missing-data;pandas;data-cleaning
7,pyreadstat,"Reader and writer for SAS, SPSS, and Stata files in Python","A Python package to read and write SAS (sas7bdat, xport), SPSS (sav, zsav, por), and Stata (dta) data files into/from pandas and polars data frames. It serves as a critical bridge for processing statistical data formats common in social sciences and clinical research within the Python scientific ecosystem.",D1;D1-01,format_conversion;data_parsing,library,C,https://github.com/Roche/pyreadstat,,NOASSERTION,spss;sas;stata;pandas;polars;converter
8,SPARQL Anything,"System for querying any data format (JSON, CSV, XML, etc.) with SPARQL","A system for Semantic Web re-engineering that allows users to query heterogeneous file formats (JSON, CSV, XML, HTML, Markdown, etc.) using SPARQL. It is widely used in scientific data integration and knowledge graph construction to bridge non-RDF data with semantic workflows.",D1;D1-01,data_integration;format_conversion;semantic_query,solver,Java,https://github.com/SPARQL-Anything/sparql.anything,http://sparql-anything.cc,Apache-2.0,sparql;semantic-web;knowledge-graph;data-integration;rdf
9,StackExchange XML Converter,Converter for StackExchange data dumps from XML to CSV format,"A utility tool designed to parse and convert StackExchange data dumps (provided in XML format) into CSV format, facilitating data analysis in social computing and network science research.",D1;D1-01,data_conversion;parsing,solver,Go,https://github.com/SkobelevIgor/stackexchange-xml-converter,,MIT,xml;csv;converter;stackexchange;data-processing
10,jsonschema (Rust),High-performance JSON Schema validator for Rust,A fast and compliant JSON Schema validator written in Rust. It is essential for validating metadata and data structures in scientific workflows that rely on JSON-based standards.,D1;D1-01,validation;parsing,library,Rust,https://github.com/Stranger6667/jsonschema,https://docs.rs/jsonschema,MIT,json-schema;validation;rust;data-integrity
11,Preswald,WASM-based packager for interactive scientific data applications,"A tool to bundle Python-based data analysis and visualization workflows (using Pandas, DuckDB, Plotly) into single-file, browser-runnable applications via Pyodide, facilitating the sharing of scientific reports and dashboards.",D1,visualization;workflow_automation;reporting,platform,Python,https://github.com/StructuredLabs/preswald,,Apache-2.0,wasm;visualization;dashboard;python;data-science
12,Tablecruncher,Lightweight CSV editor and processor,"A desktop tool for opening, editing, and processing large CSV files, supporting JavaScript macros for data cleaning and manipulation tasks common in data science.",D1;D1-01,data_cleaning;data_editing,solver,C++,https://github.com/Tablecruncher/tablecruncher,https://tablecruncher.com,GPL-3.0,csv;editor;data-cleaning;macros
13,RapidJSON,Fast JSON parser and generator for C++,A high-performance C++ library for parsing and generating JSON. It is widely used in scientific computing applications for handling configuration files and data serialization due to its speed and DOM/SAX API support.,D1;D1-01,parsing;serialization,library,C++,https://github.com/Tencent/rapidjson,http://rapidjson.org/,NOASSERTION,json;parser;cpp;serialization;high-performance
14,NightConfig,"Configuration library for TOML, YAML, JSON, and HOCON","A Java library for reading and writing various configuration formats (TOML, YAML, JSON). It supports scientific software development by providing robust parsing for experiment configurations.",D1;D1-01,parsing;configuration_management,library,Java,https://github.com/TheElectronWill/night-config,,LGPL-3.0,toml;yaml;json;configuration;java
15,TinyCsvParser,High-performance CSV parsing library for .NET,"A library designed for easy and fast parsing of CSV data in .NET applications, suitable for ingesting large scientific datasets stored in CSV format.",D1;D1-01,parsing;data_ingestion,library,C#,https://github.com/TinyCsvParser/TinyCsvParser,,MIT,csv;parser;dotnet;csharp;data-ingestion
16,dasel,"Command-line tool for querying and converting data formats (JSON, YAML, TOML, XML, CSV)","A versatile command-line tool that allows selecting, updating, and deleting data from various structured formats (JSON, TOML, YAML, XML, CSV). It is useful in scientific workflows for data extraction and format conversion.",D1;D1-01,data_conversion;querying;parsing,solver,Go,https://github.com/TomWright/dasel,https://daseldocs.tomwright.me/,MIT,json;yaml;toml;xml;csv;cli
17,fastexcel,Fast Excel reader for Rust and Python,"A high-performance library for reading Excel files (XLSX), enabling efficient ingestion of spreadsheet data into Rust or Python-based scientific analysis pipelines.",D1;D1-01,parsing;data_ingestion,library,Rust,https://github.com/ToucanToco/fastexcel,,MIT,excel;xlsx;parser;rust;python
18,ccorp_yaml_include,YAML parser plugin for file inclusion,"A plugin for the Ruamel.YAML parser that adds support for the `!include` tag, allowing modular composition of YAML files, which is useful for managing complex scientific configurations.",D1;D1-01,parsing;configuration_management,library,Python,https://github.com/Tristan-Sweeney-CambridgeConsultants/ccorp_yaml_include,,MIT,yaml;parser-extension;python;configuration
19,VBA-JSON,JSON parsing and conversion library for VBA,"A library for parsing and generating JSON within Visual Basic for Applications (VBA), enabling Excel-based scientific workflows to interact with JSON data sources and APIs.",D1;D1-01,parsing;serialization,library,Visual Basic,https://github.com/VBA-tools/VBA-JSON,,MIT,json;vba;excel;parsing
20,jtoml,TOML parser library for Java,"A fully compliant TOML parser for Java, facilitating the use of TOML configuration files in Java-based scientific applications.",D1;D1-01,parsing;configuration_management,library,Java,https://github.com/WasabiThumb/jtoml,,Apache-2.0,toml;parser;java;configuration
21,flatted,Circular JSON parser,"A fast and minimal JavaScript parser for JSON structures with circular references, useful for serializing complex data graphs in scientific web applications.",D1;D1-01,parsing;serialization,library,JavaScript,https://github.com/WebReflection/flatted,,ISC,json;circular-reference;serialization;javascript
22,pxi,Command-line data processor for JSON and other formats,"A command-line tool for processing and transforming data, similar to jq and awk, supporting efficient data manipulation in scientific pipelines.",D1;D1-01,data_processing;transformation,solver,JavaScript,https://github.com/Yord/pxi,,MIT,cli;data-processing;json;transformation
23,PolarCodeDecodersInMatlab,Matlab implementation of Polar Code decoders,"A Matlab library implementing various Polar Code decoding algorithms (CA-SCL, BP), serving as a simulation tool for information theory and telecommunications research.",D1,simulation;decoding;algorithm_implementation,library,MATLAB,https://github.com/YuYongRun/PolarCodeDecodersInMatlab,,None,polar-codes;decoding;matlab;information-theory
24,construct (Java),Binary and textual data structure parsing library for Java,"A Java port of the Python 'construct' library, used for declarative parsing and building of binary data structures, essential for handling custom binary formats in scientific data.",D1;D1-01,parsing;binary_processing,library,Java,https://github.com/ZiglioUK/construct,,MIT,binary-parsing;java;data-structures
25,YamlDotNet,YAML library for .NET,A comprehensive .NET library for parsing and serializing YAML. It is a foundational tool for handling configuration and data serialization in scientific software developed in the .NET ecosystem.,D1;D1-01,parsing;serialization,library,C#,https://github.com/aaubry/YamlDotNet,https://github.com/aaubry/YamlDotNet/wiki,MIT,yaml;dotnet;serialization;parsing
26,saneyaml,Safer and simpler YAML parsing for Python,"A Python library built on top of PyYAML that provides a safer and cleaner interface for parsing and serializing YAML, reducing risks and complexity in scientific configuration management.",D1;D1-01,parsing;serialization,library,Python,https://github.com/aboutcode-org/saneyaml,,None,yaml;python;safety;parsing
27,polars_ds_extension,Polars extension for data science utilities,"An extension for the Polars dataframe library that adds general data science functionalities, enhancing data processing workflows in Rust and Python.",D1,data_analysis;statistics,library,Rust,https://github.com/abstractqqq/polars_ds_extension,,MIT,polars;data-science;rust;python;extension
28,node-csv,Full-featured CSV parser and generator for Node.js,"A comprehensive CSV parsing and generation library for Node.js, widely used for processing tabular data in JavaScript-based scientific applications and data pipelines.",D1;D1-01,parsing;serialization,library,JavaScript,https://github.com/adaltas/node-csv,https://csv.js.org/,MIT,csv;parser;nodejs;data-processing
29,node-csv-parse,Stream-based CSV parser for Node.js,"A CSV parsing module implementing the Node.js stream API, allowing efficient processing of large scientific datasets row-by-row.",D1;D1-01,parsing;stream_processing,library,JavaScript,https://github.com/adaltas/node-csv-parse,https://csv.js.org/parse/,None,csv;parser;stream;nodejs
30,node-csv-stringify,Stream-based CSV stringifier for Node.js,"A CSV generation module implementing the Node.js stream API, used for exporting scientific data to CSV format efficiently.",D1;D1-01,serialization;export,library,JavaScript,https://github.com/adaltas/node-csv-stringify,https://csv.js.org/stringify/,None,csv;generator;stream;nodejs
31,PandasGUI,GUI for analyzing Pandas DataFrames,"A graphical user interface tool for viewing, plotting, and analyzing Pandas DataFrames, facilitating interactive data exploration for scientists using Python.",D1,visualization;data_exploration,solver,Python,https://github.com/adamerose/PandasGUI,,MIT-0,pandas;gui;visualization;data-analysis
32,zaml,Fast YAML 1.2 parsing library,"A high-performance YAML 1.2 parsing library, providing fast configuration loading for performance-critical scientific applications.",D1;D1-01,parsing,library,Zig,https://github.com/adamserafini/zaml,,BSD-3-Clause,yaml;parser;zig;performance
33,Trafilatura,Web scraping and text extraction tool,"A tool and library for gathering text and metadata from the web, outputting to formats like CSV, JSON, and XML. It is valuable for creating datasets for NLP and social science research.",D1,data_collection;text_extraction;scraping,solver,Python,https://github.com/adbar/trafilatura,https://trafilatura.readthedocs.io/,Apache-2.0,scraping;text-extraction;nlp;dataset-creation
34,frontmatter,Go library for parsing content front matter,"A Go library for detecting and decoding front matter (YAML/JSON/TOML metadata) from content files, useful for managing metadata in scientific data repositories and static site generators.",D1;D1-01,parsing;metadata_extraction,library,Go,https://github.com/adrg/frontmatter,,MIT,frontmatter;metadata;parsing;go
35,Plotlars,Integration library for Polars dataframes and Plotly visualization,"A Rust library that facilitates the integration between the Polars data analysis library and the Plotly plotting library, enabling efficient visualization of scientific dataframes.",D1;D4,visualization;data_analysis,library,Rust,https://github.com/alceal/plotlars,,MIT,polars;plotly;visualization;rust
36,Ruby Polars,High-performance DataFrame library for Ruby based on Polars,"A Ruby binding for the Polars DataFrame library, providing blazingly fast data processing and analysis capabilities suitable for scientific datasets.",D1;D1-0X,data_processing;data_analysis,library,Ruby,https://github.com/ankane/ruby-polars,,NOASSERTION,dataframe;polars;ruby;data-science
37,nvParse,GPU-accelerated CSV parser,"A fast, GPU-based CSV parser designed to leverage CUDA for high-performance data loading and parsing, suitable for large-scale scientific datasets.",D1;D1-01,data_loading;parsing,library,Cuda,https://github.com/antonmks/nvParse,,Apache-2.0,csv;gpu;cuda;hpc
38,Apache Avro,Data serialization system for compact binary data exchange,"A data serialization system widely used in big data and scientific computing for efficient data storage and exchange, supporting rich data structures and schema evolution.",D1;D1-01,serialization;data_storage,library,Java,https://github.com/apache/avro,https://avro.apache.org/,Apache-2.0,serialization;big-data;format;schema
39,Apache Fesod,Efficient spreadsheet processing library,"A library designed for processing large spreadsheet files (Excel) efficiently without memory overflow (OOM), facilitating the ingestion of scientific data stored in spreadsheets.",D1;D1-01,data_loading;spreadsheet_processing,library,Java,https://github.com/apache/fesod,,Apache-2.0,excel;spreadsheet;data-processing;java
40,Apache XTable,Cross-table converter for lakehouse table formats,"A cross-table converter for lakehouse table formats (Hudi, Delta, Iceberg) that facilitates interoperability across data processing systems used in large-scale scientific data platforms.",D1;D1-0X,data_conversion;interoperability,library,Java,https://github.com/apache/incubator-xtable,https://xtable.apache.org/,Apache-2.0,lakehouse;hudi;delta-lake;iceberg;interoperability
41,MyDuckServer,DuckDB-powered SQL server for analytics,"A unified server powered by DuckDB that provides MySQL, Postgres, and FlightSQL interfaces, enabling efficient OLAP and data analysis on scientific datasets.",D1;D1-0X,data_analysis;database_service,service,Go,https://github.com/apecloud/myduckserver,,Apache-2.0,duckdb;olap;sql;analytics
42,jsonv.sh,Bash CLI tool for JSON to CSV conversion,"A Bash command line tool for converting JSON data to CSV format, useful for lightweight data wrangling and pipeline integration in scientific workflows.",D1;D1-01,data_conversion;format_conversion,solver,Awk,https://github.com/archan937/jsonv.sh,,MIT,json;csv;bash;cli
43,Airflow AI SDK,SDK for AI/LLM integration in Airflow workflows,"An SDK for integrating Large Language Models (LLMs) and AI Agents into Apache Airflow pipelines, enabling AI-driven scientific workflows and automation.",D1;D1-0X,workflow_orchestration;ai_integration,library,Python,https://github.com/astronomer/airflow-ai-sdk,,Apache-2.0,airflow;llm;workflow;ai-agent
44,csvdiff,Fast diff tool for comparing CSV files,"A fast command-line tool for comparing CSV files, useful for quality control, regression testing, and verifying data processing results in scientific pipelines.",D1;D1-01,quality_control;data_comparison,solver,Go,https://github.com/aswinkarthik/csvdiff,,MIT,csv;diff;cli;data-qc
45,AWS SDK for pandas,"Pandas integration for AWS data services (Athena, Glue, S3)","An open-source Python library that extends Pandas to easily connect with AWS data services. It simplifies the reading and writing of scientific datasets (Parquet, CSV, JSON) stored in AWS S3, Athena, and Redshift, acting as a critical data engineering tool for cloud-based scientific workflows.",D1;D1-01,data_integration;cloud_io;etl,library,Python,https://github.com/aws/aws-sdk-pandas,https://aws-sdk-pandas.readthedocs.io/,Apache-2.0,pandas;aws;etl;parquet;data-engineering
46,polars_ols,Least squares linear regression extension for Polars,A plugin for the Polars DataFrame library that enables efficient ordinary least squares (OLS) linear regression directly within Polars expressions. It facilitates fast statistical modeling and inference on large datasets without leaving the Polars ecosystem.,D1;D4,statistical_analysis;linear_modeling;regression,library,Rust,https://github.com/azmyrajab/polars_ols,,MIT,polars;statistics;linear-regression;least-squares
47,Orange3,Interactive data mining and machine learning toolkit,"An open-source data visualization, machine learning and data mining toolkit. It features a visual programming front-end for explorative data analysis and interactive data visualization, widely used in bioinformatics and social sciences.",D1;D4,data_mining;visualization;machine_learning,platform,Python,https://github.com/biolab/orange3,https://orangedatamining.com/,GPL-3.0,data-mining;visualization;bioinformatics;machine-learning
48,Blaze,Interface for querying big data using NumPy/Pandas syntax,"Blaze provides a Python interface to query data on various storage systems (SQL, NoSQL, Spark) using a subset of the NumPy and Pandas API. It abstracts computation and storage, allowing scientific users to process large datasets that exceed memory limits.",D1,data_processing;big_data_interface;computation_abstraction,library,Python,https://github.com/blaze/blaze,http://blaze.pydata.org/,BSD-3-Clause,numpy;pandas;big-data;interface
49,pytimetk,Time series analysis and forecasting toolkit,"A Python library designed to simplify time series analysis, feature engineering, and forecasting. It integrates with the Pandas and Polars ecosystems to provide fast, functional tools for processing temporal data in scientific and analytical contexts.",D1;D4,time_series_analysis;forecasting;feature_engineering,library,Python,https://github.com/business-science/pytimetk,https://business-science.github.io/pytimetk/,MIT,time-series;forecasting;pandas;polars
50,datacompy,"DataFrame comparison tool for Pandas, Polars, and Spark","A library for comparing two DataFrames (Pandas, Polars, Spark, or Snowpark) to identify differences. It is widely used in data quality control (QC) and validation steps within scientific data processing pipelines to ensure data integrity.",D1,quality_control;data_comparison;validation,library,Python,https://github.com/capitalone/datacompy,https://capitalone.github.io/datacompy/,Apache-2.0,data-quality;comparison;pandas;polars;spark
51,FastTableViewer,High-performance command-line viewer for CSV/TSV and delimited data files,"A fast, feature-rich command-line tool designed for viewing and inspecting large CSV, TSV, and other delimited data files. It supports key navigation, searching, and handling of large datasets, making it useful for quick inspection of tabular scientific data without loading into heavy GUI applications.",D1;D1-01,data_inspection;data_visualization,solver,Go,https://github.com/codechenx/FastTableViewer,,Apache-2.0,csv;tsv;cli;data-viewer;tabular-data
52,csv-to-json,Command-line utility for converting CSV files to JSON format,"A lightweight Node.js command-line tool for converting CSV data into JSON format. It supports standard CSV parsing and JSON output, facilitating data format conversion in scientific workflows where JSON is required for downstream analysis or web visualization.",D1;D1-01,format_conversion;data_processing,workflow,JavaScript,https://github.com/cparker15/csv-to-json,,LGPL-3.0,csv;json;converter;cli
53,OctoSQL,SQL query tool for analyzing data from multiple file formats and databases,"OctoSQL is a query tool that allows users to join, analyze, and transform data from multiple sources, including CSV, JSON, Parquet, and various databases, using standard SQL. It is highly applicable for scientific data analysis where data resides in heterogeneous file formats.",D1;D1-01,data_analysis;data_query;format_conversion,solver,Go,https://github.com/cube2222/octosql,,MPL-2.0,sql;csv;json;parquet;data-analysis;cli
54,csv2json,Ruby command-line tool for converting CSV to JSON,A Ruby gem providing a command-line interface to convert CSV files into JSON. It serves as a simple utility for data format transformation in data processing pipelines.,D1;D1-01,format_conversion;data_processing,workflow,Ruby,https://github.com/darwin/csv2json,,MIT,csv;json;converter;cli;ruby
55,Dask,Flexible parallel computing library for analytic computing,"Dask provides advanced parallelism for analytics, enabling performance at scale for the tools of the PyData ecosystem (NumPy, Pandas, and Scikit-Learn). It is fundamental for processing large scientific datasets (e.g., in geoscience, physics) that exceed memory limits.",D1;D1-01,data_processing;parallel_computing,library,Python,https://github.com/dask/dask,https://dask.org/,BSD-3-Clause,parallel-computing;distributed-systems;numpy;pandas;scaling
56,Yacman,YAML configuration manager for scientific workflows,"Developed by the Databio lab, Yacman is a configuration management tool designed to standardize how bioinformatics and scientific tools handle YAML configurations, often used in conjunction with tools like Looper and Peppy.",D1;D1-01,configuration_management;workflow_utility,library,Python,https://github.com/databio/yacman,http://yacman.databio.org/,BSD-2-Clause,yaml;configuration;bioinformatics;workflow
57,Koalas,Pandas API on Apache Spark for scalable data science,"Koalas (now integrated into PySpark) allows data scientists to use the familiar pandas API while leveraging the distributed processing power of Apache Spark, enabling the processing of massive scientific datasets.",D1;D1-01,data_processing;big_data_analytics,library,Python,https://github.com/databricks/koalas,https://koalas.readthedocs.io/,Apache-2.0,pandas;spark;big-data;data-science
58,cad2data,Automated conversion pipeline for CAD/BIM data formats,"A workflow tool for converting engineering and architectural CAD files (Revit .rvt, IFC, DWG) into data-accessible formats, facilitating the analysis of construction and structural data.",D1;D1-01,format_conversion;data_extraction,workflow,Jupyter Notebook,https://github.com/datadrivenconstruction/cad2data-Revit-IFC-DWG-DGN-pipeline-with-conversion-validation-qto,,MIT,cad;bim;revit;ifc;data-conversion
59,qsv,High-performance CSV data wrangling toolkit,"A command-line tool for indexing, slicing, analyzing, and manipulating CSV files. It is widely used in data science pipelines to handle large tabular datasets efficiently without loading them entirely into memory.",D1;D1-01,data_processing;data_wrangling,solver,Rust,https://github.com/dathere/qsv,https://qsv.dathere.com,Unlicense,csv;cli;rust;data-engineering;etl
60,xlsx2csv,Fast converter from XLSX to CSV for data pipelines,"A lightweight tool to convert Microsoft Excel (XLSX) files to CSV format. It is optimized for speed and handling large files, making it useful for ingesting scientific data stored in spreadsheets into analysis pipelines.",D1;D1-01,format_conversion;data_ingestion,solver,Python,https://github.com/dilshod/xlsx2csv,,MIT,xlsx;csv;excel;conversion
61,DocArray,Data structure for multimodal scientific data,"A library for representing, sending, storing, and searching multimodal data (text, image, audio, 3D meshes, tensors). It is used in AI pipelines to handle unstructured data structures common in deep learning applications.",D1;D1-01,data_representation;multimodal_processing,library,Python,https://github.com/docarray/docarray,https://docs.docarray.org/,Apache-2.0,multimodal;tensor;data-structure;ai;deep-learning
62,fit2gpx,Converter for FIT sensor data to GPX format,A library and tool to convert FIT files (commonly used by GPS devices and sensors) to GPX format. Useful for geospatial analysis and processing of physiological/tracking data in sports science or geography.,D1;D1-01,format_conversion;sensor_data_processing,solver,Python,https://github.com/dodo-saba/fit2gpx,,GPL-3.0,fit;gpx;geospatial;sensor-data;strava
63,arrow-tools,CLI tools for Apache Arrow and Parquet conversion,A collection of command-line tools to convert CSV and JSON data into Apache Arrow and Parquet formats. These formats are standard for high-performance scientific data analytics and interchange.,D1;D1-01,format_conversion;data_interchange,solver,Rust,https://github.com/domoritz/arrow-tools,,Apache-2.0,apache-arrow;parquet;csv;json;cli
64,dsgrid-legacy-efs-api,HDF5 data marshalling for energy grid models,"A Python package developed by NREL for marshalling dsgrid (Demand-Side Grid) data into a common HDF5 format, facilitating the analysis and exchange of energy system modeling data.",D1;D1-01,data_marshalling;format_conversion,library,Python,https://github.com/dsgrid/dsgrid-legacy-efs-api,,BSD-3-Clause,hdf5;energy-grid;nrel;data-marshalling
65,ScienceBeam Parser,Tool to convert PDF scientific articles into structured XML data,"A set of tools designed to convert scientific publications (PDFs) into structured XML documents, facilitating literature mining and scientific knowledge extraction.",D1;D1-01,literature_mining;document_parsing,workflow,Python,https://github.com/elifesciences/sciencebeam-parser,,MIT,pdf-parsing;xml;scientific-literature;nlp
66,MCAP,Modular container file format and libraries for robotics data recording,"A modular, performant, and serialization-agnostic container file format designed for robotics applications, serving as a modern alternative to ROS bags for sensor data logging and analysis.",D1;D1-01,data_serialization;sensor_logging,library,Python,https://github.com/foxglove/mcap,https://mcap.dev,MIT,robotics;serialization;ros;data-logging
67,fst,High-performance data frame serialization library for R,"A library for extremely fast serialization and deserialization of data frames in R. It supports random access, compression, and multi-threading, making it essential for handling large scientific datasets in R workflows.",D1;D1-01,data_serialization;data_io,library,R,https://github.com/fstpackage/fst,https://www.fstpackage.org/,AGPL-3.0,serialization;data-frame;high-performance;R
68,Fugue,Unified interface for distributed computing in scientific workflows,"A unified interface that allows users to execute Python, Pandas, and SQL code on distributed computing frameworks like Spark, Dask, and Ray without rewriting code. It facilitates scaling scientific data analysis workflows.",D1,distributed_computing;workflow_orchestration,library,Python,https://github.com/fugue-project/fugue,https://fugue-project.github.io/tutorials/,Apache-2.0,distributed-computing;pandas;spark;dask;workflow
69,functime,Scalable time-series machine learning library,"A library for time-series machine learning at scale, built on Polars. It provides parallel feature extraction and forecasting capabilities, suitable for analyzing large-scale scientific panel data (e.g., sensor data, environmental metrics).",D1,time_series_analysis;forecasting;feature_extraction,library,Python,https://github.com/functime-org/functime,https://docs.functime.ai/,Apache-2.0,time-series;machine-learning;polars;forecasting
70,german-nouns,Structured dataset and parser for German linguistic analysis,"A dataset containing ~100,000 German nouns with grammatical properties and a Python module for parsing compound words. It serves as a tool for computational linguistics and NLP research.",D1,linguistic_analysis;dataset;nlp,dataset,Python,https://github.com/gambolputty/german-nouns,,CC-BY-SA-4.0,linguistics;nlp;german;dataset
71,simdcsv,High-performance SIMD-accelerated CSV parser,"A fast CSV parser for C++ that leverages SIMD instructions. It is designed for high-throughput data loading, which is critical for processing large scientific datasets stored in CSV format.",D1;D1-01,parsing;data_loading,library,C++,https://github.com/geofflangdale/simdcsv,,Apache-2.0,csv;simd;high-performance;parsing
72,GeoPandas,Python tools for geographic data analysis,"An open source project to make working with geospatial data in python easier. It extends the datatypes used by pandas to allow spatial operations on geometric types, essential for earth sciences and geography.",D1,geospatial_analysis;data_manipulation,library,Python,https://github.com/geopandas/geopandas,https://geopandas.org/,BSD-3-Clause,geospatial;gis;pandas;python
73,reflect-cpp,Reflection-based serialization library for C++20,"A C++20 library for fast serialization and deserialization using reflection. It supports multiple formats relevant to scientific computing, including JSON, CSV, Parquet, Avro, and YAML, enabling efficient data exchange.",D1;D1-01,serialization;data_io,library,C++,https://github.com/getml/reflect-cpp,,MIT,serialization;reflection;parquet;avro;cpp
74,LangExtract,LLM-based structured information extraction library,A library for extracting structured information from unstructured text using LLMs with source grounding. It is applicable for scientific literature mining and knowledge extraction tasks.,D1,information_extraction;text_mining;nlp,library,Python,https://github.com/google/langextract,,Apache-2.0,llm;information-extraction;nlp;structured-data
75,struct2tensor,Structured data manipulation for TensorFlow,A library for parsing and manipulating structured data (like Protocol Buffers) inside TensorFlow. It is essential for preprocessing complex structured data in AI for Science pipelines.,D1,data_preprocessing;tensor_manipulation,library,Python,https://github.com/google/struct2tensor,,Apache-2.0,tensorflow;structured-data;preprocessing;protobuf
76,Hugging Face Datasets,"Library for easily accessing, sharing, and processing datasets for Audio, Computer Vision, and NLP","A lightweight and extensible library to easily share and access datasets and evaluation metrics. It features memory-mapped data loading for efficiency, interoperability with NumPy/Pandas/PyTorch/TensorFlow, and supports various data formats (JSON, CSV, Parquet, Arrow) essential for scientific data pipelines.",D1;D1-01,data_loading;data_processing;data_conversion,library,Python,https://github.com/huggingface/datasets,https://huggingface.co/docs/datasets,Apache-2.0,datasets;etl;data-processing;machine-learning
77,Ibis,Portable Python dataframe library for data analysis across various backends,"Ibis provides a standard API for data analysis and manipulation, decoupling the analytics from the backend execution. It supports multiple backends including SQL databases, Pandas, and BigQuery, making it a powerful tool for scientific data workflows and large-scale data processing.",D1;D1-01,data_analysis;data_manipulation;query_generation,library,Python,https://github.com/ibis-project/ibis,https://ibis-project.org,Apache-2.0,dataframe;analytics;sql;data-science
78,OpenStreetMap H3 Loader,High-performance tool to transform OpenStreetMap data into H3 partitioned formats,A specialized data processing tool that converts OpenStreetMap (OSM) planet dumps into H3 (Hexagonal Hierarchical Spatial Index) partitioned PostGIS or Arrow/Parquet formats. This facilitates large-scale geospatial scientific analysis and modeling.,D1;D1-01,data_conversion;geospatial_analysis;data_partitioning,tool,Java,https://github.com/igor-suhorukov/openstreetmap_h3,,Apache-2.0,openstreetmap;h3;geospatial;etl;parquet
79,Danfo.js,Pandas-like data analysis library for JavaScript,"Danfo.js is a JavaScript library that provides high-performance, intuitive data structures (DataFrame and Series) for manipulating and processing structured data, bringing data analysis capabilities similar to Pandas to the JavaScript ecosystem.",D1;D3,data_analysis;data_manipulation,library,TypeScript,https://github.com/javascriptdata/danfojs,https://danfo.jsdata.org/,MIT,dataframe;data-analysis;javascript;pandas
80,json2csv,Command-line tool for converting JSON to CSV,"A command-line utility and library for converting JSON data structures into CSV format, facilitating data exchange, integration, and preprocessing in scientific data workflows.",D1;D1-01,format_conversion;data_preprocessing,solver,Go,https://github.com/jehiah/json2csv,,MIT,json;csv;conversion;cli
81,jq,Command-line JSON processor,"A lightweight and flexible command-line JSON processor that is widely used in scientific data pipelines for filtering, mapping, transforming, and normalizing JSON-formatted data (e.g., metadata, API responses).",D1;D1-01,data_processing;filtering;transformation,solver,C,https://github.com/jqlang/jq,https://jqlang.github.io/jq/,MIT,json;cli;data-processing;filter
82,Flatterer,Opinionated JSON to CSV/Parquet/SQL converter for data analysis,"A high-performance CLI tool designed to convert nested JSON data into flat formats like CSV, Parquet, and SQLite. It is particularly useful in scientific data engineering pipelines for preparing large-scale JSON datasets (e.g., from APIs or instruments) for analysis in data science tools.",D1;D1-01,data_conversion;data_preparation,solver,Rust,https://github.com/kindly/flatterer,,MIT,json;parquet;csv;data-engineering;conversion
83,Patito,Data modelling and validation layer for Polars dataframes,"A library built on top of Polars and Pydantic that provides a data modeling layer for dataframe validation. It allows scientists and data engineers to define schemas for their dataframes, ensuring data quality and consistency in scientific data processing pipelines.",D1;D1-01,quality_control;data_validation,library,Python,https://github.com/kolonialno/patito,https://patito.readthedocs.io,MIT,polars;pydantic;validation;dataframe;data-science
84,Duckling,"Fast viewer for CSV, Parquet, and database files","A high-performance data viewer built with Tauri that supports opening and inspecting large CSV and Parquet files, as well as connecting to databases like DuckDB and PostgreSQL. Useful for quick inspection of scientific datasets.",D1;D1-01,data_visualization;data_inspection,solver,TypeScript,https://github.com/l1xnan/duckling,,MIT,csv;parquet;data-viewer;duckdb
85,Lance,Modern columnar data format for AI and multimodal data,"An open source data format designed for high-performance random access and vector search, optimized for ML workflows and multimodal data (images, text, vectors). It serves as a faster alternative to Parquet for AI training and retrieval tasks.",D1,data_storage;data_format;vector_search,library,Rust,https://github.com/lance-format/lance,https://lancedb.github.io/lance/,Apache-2.0,data-format;vector-search;machine-learning;parquet-alternative
86,LangChain,Framework for developing applications powered by language models,"A comprehensive framework for building agents and workflows using Large Language Models (LLMs). In scientific research (AI4S), it is widely used to orchestrate reasoning agents, automate literature reviews, and build autonomous laboratory controllers.",D1,workflow_orchestration;inference;agent_framework,library,Python,https://github.com/langchain-ai/langchain,https://python.langchain.com/,MIT,llm;agents;workflow;ai4s
87,Lark,Parsing toolkit for Python,"A modern parsing library for Python that can parse any context-free grammar. It is frequently used in scientific software to build parsers for domain-specific file formats (e.g., chemical formulas, biological sequence notations) and custom configuration languages.",D1;D1-01,parsing;grammar_definition,library,Python,https://github.com/lark-parser/lark,https://lark-parser.readthedocs.io/,MIT,parser;grammar;dsl;python
88,TinyXML2,"Simple, small, efficient C++ XML parser",A lightweight C++ XML parser widely integrated into scientific simulation software and high-performance computing applications for handling configuration files and data exchange formats.,D1;D1-01,parsing;io,library,C++,https://github.com/leethomason/tinyxml2,https://leethomason.github.io/tinyxml2/,Zlib,xml;parser;cpp;embedded
89,docker-csv,Docker container with CSV processing utilities,"A containerized environment pre-packaged with command-line tools like csvkit, csvcut, and csvsql. It provides a reproducible workflow environment for batch processing and cleaning of tabular scientific data.",D1;D1-01,data_processing;data_cleaning,workflow,Dockerfile,https://github.com/leplusorg/docker-csv,,Apache-2.0,csv;docker;etl;cli
90,libexpat,Fast streaming XML parser library,"A stream-oriented XML parser library written in C. It is a foundational dependency for many scientific computing packages (e.g., in Python, Perl, and system libraries) to handle XML-based data formats efficiently.",D1;D1-01,parsing;io,library,C,https://github.com/libexpat/libexpat,https://libexpat.github.io/,MIT,xml;parser;c;streaming
91,dataclasses-json,Serialization for Python Data Classes,"A library that provides simple APIs to convert Python Data Classes to and from JSON. It is extensively used in Python-based scientific data pipelines to structure, validate, and serialize experimental parameters and results.",D1;D1-01,serialization;data_binding,library,Python,https://github.com/lidatong/dataclasses-json,,MIT,json;serialization;python;dataclasses
92,zsv,High-performance CSV parser and CLI toolkit,"A fast, SIMD-accelerated CSV parser library and command-line utility. It is designed for processing large tabular datasets common in scientific research, offering significant speed advantages over standard parsers.",D1;D1-01,parsing;data_processing,solver,C,https://github.com/liquidaty/zsv,https://zsv-lib.github.io/,MIT,csv;simd;high-performance;cli
93,YAJL,Fast streaming JSON parsing library in C,"A small, event-driven (SAX-style) JSON parser written in C. It is used in high-performance computing environments to parse large JSON data streams with minimal memory overhead.",D1;D1-01,parsing;io,library,C,https://github.com/lloyd/yajl,http://lloyd.github.io/yajl/,ISC,json;parser;c;streaming
94,marshmallow_dataclass,Automatic marshmallow schemas from dataclasses,A library that automates the creation of Marshmallow schemas from Python dataclasses. It simplifies data validation and serialization/deserialization pipelines in scientific Python applications.,D1;D1-01,serialization;validation,library,Python,https://github.com/lovasoa/marshmallow_dataclass,,MIT,python;serialization;schema;validation
95,streamlit-pydantic,Auto-generate Streamlit UI from Pydantic Models,A utility that automatically generates Streamlit user interfaces based on Pydantic data models. It is useful for rapidly building interactive dashboards and parameter configuration forms for scientific models and data analysis scripts.,D1,visualization;ui_generation,library,Python,https://github.com/lukasmasuch/streamlit-pydantic,,MIT,streamlit;pydantic;dashboard;ui
96,Lux,Intelligent visual discovery for Pandas dataframes,A Python library that enhances Pandas dataframes by automatically suggesting and generating visualizations. It helps researchers quickly explore and understand trends and patterns in their data without writing complex plotting code.,D1,data_visualization;eda,library,Python,https://github.com/lux-org/lux,https://lux-api.readthedocs.io/,Apache-2.0,visualization;pandas;eda;data-analysis
97,Toasted Marshmallow,JIT compiler for Marshmallow serialization,A performance optimization library for Marshmallow that generates JIT-compiled code for serialization. It significantly speeds up data processing pipelines that rely on Marshmallow for handling large volumes of scientific data.,D1;D1-01,serialization;optimization,library,Python,https://github.com/lyft/toasted-marshmallow,,Apache-2.0,python;performance;serialization;marshmallow
98,dblp-parser,Parser for DBLP bibliography data,A Python tool to parse the DBLP computer science bibliography XML dataset into structured formats. It is used in scientometrics and network analysis research to study citation graphs and publication trends.,D1,data_parsing;scientometrics,solver,Python,https://github.com/macks22/dblp,,MIT,dblp;bibliography;xml-parser;scientometrics
99,Arctic,High performance datastore for time series and tick data,"A high-performance time-series and tick data store built on top of MongoDB. While developed for finance, it is applicable to any scientific domain requiring efficient storage and retrieval of large-scale numerical time-series data.",D1,data_storage;time_series,library,Python,https://github.com/man-group/arctic,https://arctic.readthedocs.io/,LGPL-2.1,time-series;database;mongodb;python
100,D-Tale,Visualizer for pandas data structures,"A tool that brings a Flask-based backend and a React frontend to visualize and analyze Pandas dataframes. It provides a GUI for data exploration, cleaning, and analysis, making it easier to interact with scientific datasets.",D1,data_visualization;eda;data_cleaning,solver,TypeScript,https://github.com/man-group/dtale,https://github.com/man-group/dtale,LGPL-2.1,pandas;visualization;gui;eda
101,json_repair,Repair invalid JSON from LLMs,"A Python module designed to fix malformed JSON strings, specifically those generated by Large Language Models (LLMs). This is a critical utility in AI4S workflows where LLMs are used to extract structured data from scientific literature or experiments.",D1;D1-01,data_cleaning;parsing;llm_utility,library,Python,https://github.com/mangiucugna/json_repair,,MIT,json;llm;parsing;repair
102,dataclasses-avroschema,Generate Avro schemas from Python dataclasses,"A library to generate Avro schemas from Python dataclasses and Pydantic models, and to serialize/deserialize data. Avro is a common format in large-scale scientific data processing (e.g., in bioinformatics and physics pipelines).",D1;D1-01,serialization;schema_generation,library,Python,https://github.com/marcosschroh/dataclasses-avroschema,https://marcosschroh.github.io/dataclasses-avroschema/,MIT,avro;schema;serialization;python
103,sqlparser,SQL parser for querying CSV files,A Go library that implements a SQL parser specifically for querying CSV files. It enables researchers to use standard SQL syntax to filter and aggregate data stored in flat CSV files without loading them into a full database.,D1;D1-01,data_querying;parsing,library,Go,https://github.com/marianogappa/sqlparser,,MIT,sql;csv;query;parser
104,tidypolars,Tidy interface to Polars,A Python library that provides a syntax similar to R's Tidyverse for the Polars dataframe library. It facilitates high-performance data analysis for researchers familiar with R/dplyr conventions.,D1,data_analysis;data_manipulation,library,Python,https://github.com/markfairbanks/tidypolars,https://tidypolars.readthedocs.io/,MIT,polars;tidyverse;data-analysis;python
105,OCT-Converter,Tool for extracting raw data from proprietary Optical Coherence Tomography (OCT) file formats,"A Python library designed to extract raw optical coherence tomography (OCT) and fundus data from proprietary file formats (e.g., .fda, .e2e, .img) used in medical imaging devices, facilitating ophthalmic research and data analysis.",D1;Medical Imaging,data_extraction;format_conversion,library,Python,https://github.com/marksgraham/OCT-Converter,,MIT,oct;medical-imaging;ophthalmology;file-conversion
106,nuclei,"Parser, viewer, and editor for Evaluated Nuclear Structure Data (ENSDF)","A C++ tool designed to parse, view, and edit files in the Evaluated Nuclear Structure Data File (ENSDF) format, which is the standard format for nuclear structure and decay data in nuclear physics research.",D1;Nuclear Physics,data_parsing;data_visualization,solver,C++,https://github.com/martukas/nuclei,,GPL-3.0,ensdf;nuclear-physics;nuclear-structure;parser
107,FHIR-Converter,Conversion utility to translate legacy healthcare data formats into FHIR,"An open-source project that provides a conversion utility to translate legacy data formats (such as HL7v2 and C-CDA) into the Fast Healthcare Interoperability Resources (FHIR) standard, supporting medical informatics research and data interoperability.",D1;Medical Informatics,format_conversion;data_standardization,library,Liquid,https://github.com/microsoft/FHIR-Converter,,MIT,fhir;hl7;medical-informatics;healthcare-data
108,caltech-pedestrian-dataset-converter,Converter for Caltech Pedestrian Dataset to standard image formats,"A Python utility to extract and convert the Caltech Pedestrian Dataset from its proprietary .seq video format into standard image files and labels, facilitating computer vision research and benchmarking.",D1;Computer Vision,data_extraction;format_conversion,library,Python,https://github.com/mitmul/caltech-pedestrian-dataset-converter,,None,computer-vision;dataset-tools;pedestrian-detection
109,Modin,Scalable Pandas implementation for distributed computing,"Modin is a library that scales Pandas workflows by changing a single line of code, utilizing Ray or Dask to distribute computation across cores or clusters for large-scale scientific data analysis.",D1;Data/Workflow,data_processing;parallel_computing,library,Python,https://github.com/modin-project/modin,https://modin.readthedocs.io/,Apache-2.0,pandas;distributed-computing;data-science
110,Seaborn,Statistical data visualization library,"Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics, essential for scientific data exploration.",Data/Workflow,visualization;statistical_analysis,library,Python,https://github.com/mwaskom/seaborn,https://seaborn.pydata.org/,BSD-3-Clause,visualization;statistics;plotting
111,itables,Interactive DataTables for Python DataFrames,"Itables renders Python DataFrames (Pandas, Polars) as interactive HTML DataTables in Jupyter notebooks, facilitating data exploration and inspection in scientific workflows.",Data/Workflow,visualization;data_exploration,library,Python,https://github.com/mwouts/itables,https://mwouts.github.io/itables/,MIT,jupyter;pandas;visualization
112,Pandarallel,Parallel processing tool for Pandas,"Pandarallel provides a simple interface to parallelize Pandas operations on all available CPUs, significantly speeding up data preprocessing and analysis tasks in scientific pipelines.",Data/Workflow,data_processing;parallel_computing,library,Python,https://github.com/nalepae/pandarallel,,BSD-3-Clause,pandas;parallelization;performance
113,Narwhals,Compatibility layer for dataframe libraries,"Narwhals is a lightweight compatibility layer that allows library maintainers to write dataframe-agnostic code, supporting Pandas, Polars, and others, facilitating the development of interoperable scientific tools.",Data/Workflow,data_interoperability;workflow_optimization,library,Python,https://github.com/narwhals-dev/narwhals,https://narwhals-dev.github.io/narwhals/,MIT,dataframe;interoperability;polars
114,trdsql,CLI tool to execute SQL queries on CSV/JSON/YAML,"trdsql is a command-line tool that allows executing SQL queries directly on CSV, LTSV, JSON, and YAML files, enabling efficient data filtering, aggregation, and transformation in scientific data pipelines.",D1;D1-01,data_querying;data_conversion,solver,Go,https://github.com/noborus/trdsql,,MIT,sql;csv;data-processing
115,MinerU,High-quality data extraction tool for scientific documents,"A data processing tool designed to transform complex scientific documents (PDFs) into machine-readable formats (Markdown/JSON). It handles formulas, tables, and layout analysis, specifically enabling LLM-based scientific literature mining and agentic workflows.",D1;D1-01,document_parsing;data_extraction;layout_analysis,solver,Python,https://github.com/opendatalab/MinerU,https://github.com/opendatalab/MinerU,AGPL-3.0,pdf-parsing;scientific-literature;llm-data-prep
116,Granola,Serialization library for Apple HealthKit clinical data,A library designed to serialize Apple HealthKit data into Open mHealth compliant JSON formats. It facilitates the standardization and interoperability of clinical and personal health data for medical informatics research.,D1;D1-01,data_serialization;health_informatics;data_standardization,library,Objective-C,https://github.com/openmhealth/Granola,https://www.openmhealth.org/,Apache-2.0,healthkit;openmhealth;clinical-data
117,Buckaroo,Interactive data exploration UI for scientific dataframes,"A GUI tool integrated into Jupyter Notebooks for exploring, cleaning, and visualizing Pandas and Polars dataframes. It accelerates the exploratory data analysis (EDA) phase of scientific workflows by providing instant summary statistics, histograms, and filtering capabilities.",D1;D1-01,exploratory_data_analysis;data_visualization;data_cleaning,library,Python,https://github.com/paddymul/buckaroo,https://buckaroo-data.readthedocs.io/,BSD-3-Clause,pandas;jupyter;eda;visualization
118,pandas,Fundamental library for scientific data analysis and manipulation,"The core library for data manipulation and analysis in Python, providing high-performance, easy-to-use data structures (DataFrames) and data analysis tools. It is the foundation for processing structured scientific data across all disciplines.",D1;D1-01,data_manipulation;statistical_analysis;data_cleaning,library,Python,https://github.com/pandas-dev/pandas,https://pandas.pydata.org/,BSD-3-Clause,dataframe;data-analysis;statistics
119,hAMRonization,Parser and harmonizer for antimicrobial resistance analysis reports,A bioinformatics tool designed to parse outputs from various Antimicrobial Resistance (AMR) prediction tools and harmonize them into a unified data structure. It facilitates the comparison and aggregation of AMR analysis results in microbiology research.,D1;D1-01,bioinformatics_parsing;data_harmonization;antimicrobial_resistance,solver,Python,https://github.com/pha4ge/hAMRonization,https://github.com/pha4ge/hAMRonization,LGPL-3.0,bioinformatics;amr;data-standardization
120,Placemark,Web-based editor and converter for geospatial data,"A versatile tool for creating, editing, converting, and visualizing geospatial data. It supports a wide range of formats (GeoJSON, KML, CSV, etc.) and is used in Earth Science and GIS workflows for data preparation and visualization.",D1;D1-01,geospatial_visualization;data_conversion;map_editing,platform,TypeScript,https://github.com/placemark/placemark,https://www.placemark.io/,MIT,gis;geospatial;geojson;visualization
121,GeoPolars,Geospatial extensions for the Polars DataFrame library,"GeoPolars extends the Polars DataFrame library with geospatial data types and operations, enabling fast processing of geographic data.",D1;D1-01,scientific_data_processing;geospatial_analysis,library,Python,https://github.com/pola-rs/geopolars,https://github.com/pola-rs/geopolars,MIT,geospatial;polars;gis;dataframe
122,Polars,High-performance DataFrame library for data manipulation and analysis,"Polars is a blazingly fast DataFrames library implemented in Rust using Apache Arrow Columnar Format as the memory model. It is a key tool for scientific data processing and analysis, serving as a modern alternative to Pandas.",D1;D1-01,scientific_data_processing;data_analysis,library,Rust,https://github.com/pola-rs/polars,https://pola.rs/,MIT,dataframe;data-analysis;arrow;rust
123,Polars CLI,Command-line interface for running SQL queries on data files using Polars,"A command-line tool that allows users to run SQL queries directly on CSV, Parquet, and JSON files using the Polars engine, facilitating quick scientific data inspection and processing.",D1;D1-01,scientific_data_processing;data_query,solver,Rust,https://github.com/pola-rs/polars-cli,https://github.com/pola-rs/polars-cli,MIT,cli;sql;data-processing;polars
124,polars-xdt,DateTime extension library for Polars,"A plugin for Polars that provides additional datetime functionality, such as business day calculations and holiday handling, useful for time-series analysis in scientific and economic research.",D1;D1-01,scientific_data_processing;time_series_analysis,library,Python,https://github.com/pola-rs/polars-xdt,https://github.com/pola-rs/polars-xdt,MIT,datetime;polars-plugin;time-series
125,r-polars,R bindings for the Polars DataFrame library,"Provides R language bindings for Polars, enabling high-performance data manipulation and analysis within the R scientific computing ecosystem.",D1;D1-01,scientific_data_processing;data_analysis,library,R,https://github.com/pola-rs/r-polars,https://rpolars.github.io/,MIT,r;dataframe;data-analysis;polars
126,esri2open,Tool to export ESRI Feature Classes to open data formats,"A Python toolbox that converts proprietary ESRI geospatial data formats into open standards like CSV, JSON, and GeoJSON, facilitating open science and geospatial data interoperability.",D1;D1-01,scientific_data_processing;format_conversion,solver,Python,https://github.com/project-open-data/esri2open,https://github.com/project-open-data/esri2open,MIT,gis;geospatial;data-conversion;esri
127,PyNLPl,Python library for Natural Language Processing and linguistic data parsing,"PyNLPl (Pineapple) is a library for Natural Language Processing that includes parsers for specific linguistic research formats like FoLiA, Giza, and Moses, supporting computational linguistics research.",D1;D1-01,scientific_data_processing;linguistic_analysis,library,Python,https://github.com/proycon/pynlpl,https://pynlpl.readthedocs.io/,GPL-3.0,nlp;computational-linguistics;folia;parser
128,xarray,N-D labeled arrays and datasets for physical sciences,"Xarray introduces labels in the form of dimensions, coordinates and attributes on top of raw NumPy-like arrays, making it a fundamental tool for processing multi-dimensional scientific data (e.g., climate, physics, oceanography).",D1;D1-01,scientific_data_processing;scientific_modeling,library,Python,https://github.com/pydata/xarray,https://docs.xarray.dev/,Apache-2.0,netcdf;climate-science;multi-dimensional-arrays;physics
129,windrose,Python library to manage wind data and draw windroses,"A specialized library for meteorology to analyze wind data, draw polar rose plots (windroses), and fit Weibull probability density functions.",D1;D1-01,scientific_visualization;scientific_data_analysis,library,Python,https://github.com/python-windrose/windrose,https://windrose.readthedocs.io/,NOASSERTION,meteorology;wind-data;visualization;weibull
130,cuDF,GPU-accelerated DataFrame library,"cuDF is a GPU DataFrame library for loading, joining, aggregating, filtering, and manipulating data. It is a core component of the RAPIDS ecosystem, enabling high-performance scientific data analysis on GPUs.",D1;D1-01,scientific_data_processing;data_analysis,library,C++,https://github.com/rapidsai/cudf,https://docs.rapids.ai/api/cudf/stable/,Apache-2.0,gpu;dataframe;cuda;rapids
131,Cufflinks,Productivity tool that binds Plotly to Pandas dataframes for easy scientific visualization,"Cufflinks connects the Pandas data analysis library with Plotly, enabling users to create interactive visualizations directly from Pandas DataFrames. It is widely used in scientific data analysis workflows to quickly generate charts for data exploration and reporting.",D1;D1-01,visualization;data_exploration,library,Jupyter Notebook,https://github.com/santosjorge/cufflinks,,MIT,visualization;pandas;plotly;data-analysis
132,VisiData,Terminal interface for exploring and arranging tabular data,"VisiData is an interactive multitool for exploring, analyzing, and manipulating tabular data (CSV, Excel, JSON, HDF5, etc.) directly in the terminal. It supports filtering, summarization, and basic statistical analysis, making it a powerful tool for scientific data quality control and quick inspection.",D1;D1-01,data_exploration;quality_control;data_processing,workflow,Python,https://github.com/saulpw/visidata,https://www.visidata.org/,GPL-3.0,cli;data-exploration;csv;tabular-data;statistics
133,PandasAI,Generative AI capability wrapper for pandas to enable conversational data analysis,"A Python library that integrates Large Language Models (LLMs) with pandas, allowing users to perform data analysis, manipulation, and visualization on scientific datasets (CSV, Parquet, SQL) using natural language queries.",D1;D4,data_analysis;data_visualization;natural_language_query,library,Python,https://github.com/sinaptik-ai/pandas-ai,https://docs.pandas-ai.com/,MIT,pandas;llm;data-analysis;conversational-ai
134,PyTorch Forecasting,Deep learning library for time series forecasting built on PyTorch,A high-level library for time series forecasting with neural networks. It provides state-of-the-art models (like Temporal Fusion Transformers) and facilitates data handling for scientific time-series tasks.,D4;M1,time_series_forecasting;modeling;deep_learning,library,Python,https://github.com/sktime/pytorch-forecasting,https://pytorch-forecasting.readthedocs.io/,MIT,pytorch;time-series;forecasting;deep-learning
135,pdbx,Python parser for Protein Data Bank (PDB) mmCIF format files,"A specialized parser module developed by the Soeding Lab for handling macromolecular structure data in the PDBx/mmCIF format, essential for structural biology and bioinformatics workflows.",D1;D1-01,data_parsing;structure_analysis,library,Python,https://github.com/soedinglab/pdbx,,NOASSERTION,pdb;mmcif;protein-structure;bioinformatics
136,GarminDB,Parser and database manager for Garmin/FitBit health and physiological data,"A tool that parses binary FIT files, TCX, and other proprietary formats from health wearables (Garmin, Fitbit) into a SQLite database for physiological data analysis and visualization.",D1;D1-01,data_parsing;physiological_data_analysis,workflow,Python,https://github.com/tcgoetz/GarminDB,,GPL-2.0,health-informatics;wearables;fit-format;sqlite;quantified-self
137,vroom,High-performance delimited file parser for R,"A fast data reading library for R that indexes delimited files (CSV, TSV) for rapid access, widely used in bioinformatics and data science workflows for handling large datasets.",D1;D1-01,data_loading;parsing,library,C++,https://github.com/tidyverse/vroom,https://vroom.r-lib.org,NOASSERTION,csv-parser;r-package;high-performance;data-science
138,pubmed_parser,Parser for PubMed Open-Access XML and MEDLINE XML datasets,"A Python library specifically designed to parse PubMed and MEDLINE XML datasets, enabling bibliometric analysis, text mining, and meta-science research on biomedical literature.",D1;D1-01,literature_mining;metadata_extraction,library,Python,https://github.com/titipata/pubmed_parser,,MIT,pubmed;medline;xml-parser;nlp;bibliometrics
139,gpxpy,GPX file parser and manipulator,"A Python library for parsing and manipulating GPX (GPS Exchange Format) files, commonly used in geospatial analysis, ecology (tracking), and sports science.",D1;D1-01,geospatial_parsing;trajectory_analysis,library,Python,https://github.com/tkrajina/gpxpy,,Apache-2.0,gpx;gps;geospatial;xml-parser
140,OSM2World,Converter creating 3D models from OpenStreetMap data,"A tool that parses OpenStreetMap (OSM) data and converts it into three-dimensional models, used for urban simulation, geospatial visualization, and cartography.",D1;D1-01,3d_reconstruction;geospatial_visualization,solver,Java,https://github.com/tordanik/OSM2World,http://osm2world.org/,LGPL-3.0,openstreetmap;3d-modeling;geospatial;visualization
141,Pandera,Statistical data validation and testing library for pandas dataframes,"Pandera provides a flexible and expressive API for performing statistical validation on dataframe-like objects. It is widely used in scientific data pipelines to ensure data quality, verify schema consistency, and perform hypothesis testing on tabular data structures.",D1;D1-01,quality_control;data_validation,library,Python,https://github.com/unionai-oss/pandera,https://pandera.readthedocs.io,MIT,data-validation;pandas;quality-control;schema-validation
142,BioBear,Bioinformatics file processing using Arrow and Polars,"BioBear is a library that enables reading and processing of standard bioinformatics file formats (FASTA, FASTQ, VCF, BAM, GFF) directly into Polars DataFrames or Arrow tables. It facilitates high-performance data analysis workflows for genomics and biological data.",D1;D1-01,data_parsing;format_conversion,library,Rust,https://github.com/wheretrue/biobear,https://www.wheretrue.com/biobear,MIT,bioinformatics;genomics;polars;arrow;fastq;vcf
143,csvkit,Command-line suite for converting and processing CSV data,"csvkit is a suite of command-line tools for converting to and working with CSV, the common tabular file format in scientific research. It allows researchers to inspect, filter, slice, join, and analyze tabular data directly from the terminal, facilitating reproducible data cleaning workflows.",D1;D1-01,data_cleaning;format_conversion;data_analysis,solver,Python,https://github.com/wireservice/csvkit,https://csvkit.readthedocs.io/,MIT,csv;data-cleaning;cli;tabular-data
144,ydata-profiling,Automated exploratory data analysis and quality profiling tool for Pandas and Spark DataFrames,"A primary tool for exploratory data analysis (EDA) in scientific data workflows. It generates comprehensive profile reports from dataframes, providing statistical insights, correlation analysis, missing value assessment, and distribution visualization, which are essential for scientific data quality control.",D1;D1-01,quality_control;exploratory_data_analysis;statistical_analysis,library,Python,https://github.com/ydataai/ydata-profiling,https://docs.profiling.ydata.ai/latest/,MIT,eda;data-profiling;quality-control;pandas;statistics
145,Dataset_to_VOC_converter,"Scripts to convert computer vision datasets (Caltech, COCO, HDA) to PASCAL VOC format","A set of utility scripts designed to convert various standard computer vision datasets (Caltech pedestrian, MS COCO, HDA) into the PASCAL VOC XML format. This facilitates the normalization of data inputs for object detection model training in scientific research.",D1;D1-01,data_conversion;dataset_preparation;normalization,workflow,Python,https://github.com/zongfan2/Dataset_to_VOC_converter,,MIT,computer-vision;dataset-conversion;pascal-voc;coco;object-detection
146,Jupyter Dock,Interactive molecular docking protocols and visualization workflow,"A set of Jupyter Notebooks serving as a workflow tool for performing molecular docking protocols, including file format conversion, visualization, and result analysis.",D1;D1-02,molecular_docking;visualization;format_conversion,workflow,Jupyter Notebook,https://github.com/AngelRuizMoreno/Jupyter_Dock,,MIT,molecular-docking;bioinformatics;visualization
147,ngio,Streamlined OME-Zarr image analysis workflow library,"A Python library designed to streamline OME-Zarr image analysis workflows, facilitating the handling of next-generation bioimaging formats.",D1;D1-02,image_analysis;bioimaging,library,Python,https://github.com/BioVisionCenter/ngio,,BSD-3-Clause,ome-zarr;bioimaging;microscopy
148,Rhtslib,HTSlib high-throughput sequencing library for R,"An R package providing the HTSlib C library for high-throughput sequencing data processing, enabling access to SAM/BAM/CRAM/VCF files within R.",D1;D1-02,sequencing_io;bioinformatics,library,C,https://github.com/Bioconductor/Rhtslib,https://bioconductor.org/packages/Rhtslib,LGPL-2.0,htslib;bioconductor;genomics
149,b2h5py,Optimized Blosc2 reading for h5py,"A library enabling transparent and optimized reading of n-dimensional Blosc2 slices within h5py, enhancing performance for HDF5 data access.",D1;D1-02,data_compression;io_optimization,library,Python,https://github.com/Blosc/b2h5py,,BSD-3-Clause,hdf5;blosc2;compression
150,grib22json,GRIB2 binary data decoder for JavaScript,"A Javascript decoder for parsing GRIB2 binary meteorological data, enabling web-based visualization and processing of weather data.",D1;D1-02,meteorology_io;data_decoding,library,JavaScript,https://github.com/BlueNetCat/grib22json,,None,grib2;meteorology;weather-data
151,BrkRaw,Tool to access raw Bruker Biospin MRI data,"A comprehensive tool designed to access and process raw MRI data from Bruker Biospin systems, facilitating medical imaging research.",D1;D1-02,mri_processing;medical_imaging,library,Python,https://github.com/BrkRaw/brkraw,,GPL-3.0,mri;bruker;medical-imaging
152,EleFits,Modern C++ API for FITS files,"A modern C++ API built on top of CFitsIO, developed by CNES, to facilitate reading and writing of FITS files in astronomical software.",D1;D1-02,astronomy_io;fits_handling,library,C++,https://github.com/CNES/EleFits,,NOASSERTION,fits;astronomy;cnes
153,zodipy,Zodiacal light simulation package,"An Astropy-affiliated Python package for simulating zodiacal light emission, used in cosmological and astronomical data analysis.",D1;D1-02,simulation;astronomy,library,Python,https://github.com/Cosmoglobe/zodipy,,GPL-3.0,astronomy;simulation;zodiacal-light
154,dkist,DKIST solar telescope data tools,"A Python library for obtaining, processing, and interacting with calibrated data from the Daniel K. Inouye Solar Telescope (DKIST).",D1;D1-02,solar_physics;data_access,library,Python,https://github.com/DKISTDC/dkist,https://docs.dkist.nso.edu/projects/python-tools/en/stable/,BSD-3-Clause,solar-physics;astronomy;dkist
155,geobipy,Geophysical Bayesian Inference in Python,"A Python package for performing Bayesian inference on geophysical data, developed by the USGS.",D1;D1-02,geophysics;bayesian_inference,solver,Python,https://github.com/DOI-USGS/geobipy,,NOASSERTION,geophysics;inference;usgs
156,h5pickle,Pickle wrapper for h5py,"A wrapper for h5py that adds pickling capabilities, facilitating the serialization of HDF5 file handles in parallel processing workflows.",D1;D1-02,data_serialization;parallel_computing,library,Python,https://github.com/DaanVanVugt/h5pickle,,MIT,hdf5;pickle;python
157,netcdf_to_gltf_converter,NetCDF to glTF converter for D-HYDRO,A tool developed by Deltares to convert D-HYDRO output NetCDF data into the glTF format for 3D visualization.,D1;D1-02,format_conversion;visualization,library,Python,https://github.com/Deltares-research/netcdf_to_gltf_converter,,MIT,netcdf;gltf;hydrology
158,BIDScoin,Neuroimaging to BIDS converter,"A tool that converts source-level neuroimaging data to the Brain Imaging Data Structure (BIDS) standard, facilitating data sharing and analysis.",D1;D1-02,format_conversion;neuroimaging,workflow,Python,https://github.com/Donders-Institute/bidscoin,https://bidscoin.readthedocs.io,GPL-3.0,bids;neuroimaging;mri
159,ebvcube,EBV NetCDF dataset access tool,"An R package for accessing, visualizing, and creating Essential Biodiversity Variables (EBV) NetCDF datasets from the EBV Data Portal.",D1;D1-02,biodiversity_informatics;data_access,library,R,https://github.com/EBVcube/ebvcube,,GPL-3.0,biodiversity;netcdf;ebv
160,Bio-DB-HTS,Perl interface to HTSlib,"A Perl module providing bindings to the HTSlib library, enabling high-performance processing of high-throughput sequencing data formats.",D1;D1-02,sequencing_io;bioinformatics,library,Perl,https://github.com/Ensembl/Bio-DB-HTS,,Apache-2.0,htslib;perl;genomics
161,pypx,Python PACS interaction wrapper,A Python wrapper based on DCMTK and PyDicom to interact with Picture Archiving and Communication Systems (PACS) for medical imaging data management.,D1;D1-02,medical_imaging;pacs_interface,library,Python,https://github.com/FNNDSC/pypx,,None,dicom;pacs;medical-imaging
162,sat-extractor,Satellite imagery extraction tool,"A tool to extract satellite imagery from public constellations at scale, facilitating the creation of datasets for earth observation research.",D1;D1-02,remote_sensing;data_extraction,workflow,Python,https://github.com/FrontierDevelopmentLab/sat-extractor,,BSD-2-Clause,satellite-imagery;remote-sensing;earth-observation
163,vcf-js,JavaScript VCF parser,"A high-performance Variant Call Format (VCF) parser written in pure JavaScript, enabling client-side genomic data processing.",D1;D1-02,genomics_io;variant_analysis,library,TypeScript,https://github.com/GMOD/vcf-js,,MIT,vcf;genomics;javascript
164,go-dicom-parser,Efficient DICOM parser in Go,"A lightweight and efficient library for parsing and processing DICOM medical imaging files, written in the Go programming language.",D1;D1-02,medical_imaging;dicom_parsing,library,Go,https://github.com/GoogleCloudPlatform/go-dicom-parser,,Apache-2.0,dicom;go;medical-imaging
165,h5pyd,Python client for HDF REST API,"A Python client library for the HDF REST API (HDF Server), enabling distributed access to HDF5 data in the cloud.",D1;D1-02,cloud_storage;data_access,library,Python,https://github.com/HDFGroup/h5pyd,,NOASSERTION,hdf5;cloud;rest-api
166,CFITSIO,Standard library for FITS file manipulation,"The standard C and Fortran library for reading and writing FITS (Flexible Image Transport System) data files, widely used in astronomy.",D1;D1-02,astronomy_io;fits_handling,library,C,https://github.com/HEASARC/cfitsio,https://heasarc.gsfc.nasa.gov/fitsio/,None,fits;astronomy;nasa
167,digital-elevation-model,DEM transformation and visualization tool,"A Python tool to transform, project, visualize, and read Digital Elevation Models (DEM) such as ASTER GDEM and EU-DEM.",D1;D1-02,geospatial_analysis;dem_processing,library,Python,https://github.com/HeZhang1994/digital-elevation-model,,MIT,dem;geospatial;visualization
168,Rarr,Native R reader for Zarr arrays,"A simple native R package for reading Zarr arrays, enabling efficient access to chunked, compressed N-dimensional arrays in R.",D1;D1-02,data_io;bioinformatics,library,R,https://github.com/Huber-group-EMBL/Rarr,https://bioconductor.org/packages/Rarr,NOASSERTION,zarr;r;bioconductor
169,paragraph,Graph realignment for structural variants,"A graph realignment tool designed for accurate genotyping of structural variants in genomic data, developed by Illumina.",D1;D1-02,variant_calling;genomics,solver,C++,https://github.com/Illumina/paragraph,,NOASSERTION,genomics;structural-variants;graph-alignment
170,dicomweb-client,Python client for DICOMweb services,"A Python client library for interacting with DICOMweb RESTful services, facilitating the exchange of medical imaging data over the web.",D1;D1-02,medical_imaging;web_services,library,Python,https://github.com/ImagingDataCommons/dicomweb-client,,MIT,dicomweb;medical-imaging;rest-api
171,highdicom,High-level DICOM abstractions for Python,"A Python library providing high-level abstractions for creating and handling complex DICOM objects, such as Structured Reports and Segmentation.",D1;D1-02,medical_imaging;dicom_creation,library,Python,https://github.com/ImagingDataCommons/highdicom,https://highdicom.readthedocs.io,MIT,dicom;medical-imaging;python
172,OiTools,Java library for OIFITS files,"A Java library dedicated to reading and writing OIFITS (Optical Interferometry FITS) files, the standard format for optical interferometry data.",D1;D1-02,astronomy_io;interferometry,library,Java,https://github.com/JMMC-OpenDev/oitools,,GPL-3.0,oifits;interferometry;astronomy
173,AstroImages.jl,Astronomical image visualization in Julia,"A Julia package for the visualization of astronomical images, providing tools to handle FITS files and display them with appropriate scaling.",D1;D1-02,astronomy_visualization;image_processing,library,Julia,https://github.com/JuliaAstro/AstroImages.jl,,NOASSERTION,astronomy;julia;visualization
174,CFITSIO.jl,C-style interface to the libcfitsio library for Julia,"A Julia wrapper for the CFITSIO library, providing low-level access to FITS (Flexible Image Transport System) files, widely used in astronomy.",D1;D1-02;Astronomy,io;data_access,library,Julia,https://github.com/JuliaAstro/CFITSIO.jl,https://juliaastro.github.io/CFITSIO.jl/stable/,MIT,fits;astronomy;io;julia-wrapper
175,FITSIO.jl,Flexible Image Transport System (FITS) file support for Julia,"A high-level Julia library for reading and writing FITS files, providing a more Julian interface compared to the low-level CFITSIO wrapper.",D1;D1-02;Astronomy,io;data_manipulation,library,Julia,https://github.com/JuliaAstro/FITSIO.jl,https://juliaastro.github.io/FITSIO.jl/stable/,MIT,fits;astronomy;io;images
176,GeoIO.jl,Geospatial data IO compatible with GeoStats.jl,"A Julia library for loading and saving geospatial data, designed to integrate seamlessly with the GeoStats.jl framework for geostatistical analysis.",D1;D1-02;Earth Science,io;data_loading,library,Julia,https://github.com/JuliaEarth/GeoIO.jl,https://juliaearth.github.io/GeoIO.jl/stable/,MIT,geospatial;io;geostats;gis
177,GDAL.jl,Julia wrapper for the Geospatial Data Abstraction Library (GDAL),"A thin Julia wrapper around the GDAL library, enabling reading and writing of a vast number of raster and vector geospatial data formats.",D1;D1-02;Earth Science,io;format_conversion;data_transformation,library,Julia,https://github.com/JuliaGeo/GDAL.jl,https://juliageo.org/GDAL.jl/stable/,MIT,gdal;geospatial;raster;vector;gis
178,GeoFormatTypes.jl,Wrapper types for spatial data formats in Julia,"Provides Julia type definitions for various spatial data formats (WKT, KML, Proj4, etc.) to facilitate interoperability between geospatial libraries.",D1;D1-02;Earth Science,data_modeling;interoperability,library,Julia,https://github.com/JuliaGeo/GeoFormatTypes.jl,,MIT,geospatial;types;wkt;kml
179,GeoJSON.jl,Utilities for working with GeoJSON data in Julia,"A Julia library for parsing and generating GeoJSON, a format for encoding a variety of geographic data structures.",D1;D1-02;Earth Science,io;parsing,library,Julia,https://github.com/JuliaGeo/GeoJSON.jl,,MIT,geojson;geospatial;json;io
180,GeoParquet.jl,Julia support for Geospatial Parquet files,"A library for reading and writing GeoParquet files in Julia, enabling efficient storage and retrieval of geospatial data in the Parquet format.",D1;D1-02;Earth Science,io;storage,library,Julia,https://github.com/JuliaGeo/GeoParquet.jl,,MIT,geoparquet;parquet;geospatial;io
181,iCGIS,Simple GIS program based on Qt and GDAL,"A lightweight Geographic Information System (GIS) desktop application for visualizing and processing geospatial data, built with C++, Qt, and GDAL.",D1;Earth Science,visualization;data_processing,application,C++,https://github.com/Leopard-C/iCGIS,,None,gis;qt;gdal;visualization
182,mwalib,Library to read Murchison Widefield Array (MWA) data,"A Rust library to read raw visibilities, voltages, and metadata from the Murchison Widefield Array (MWA) radio telescope into a common structure.",D1;D1-02;Astronomy,io;data_access,library,Rust,https://github.com/MWATelescope/mwalib,https://docs.rs/mwalib/,MPL-2.0,radio-astronomy;mwa;io;rust
183,MapServer,Open source platform for publishing spatial data to the web,"A major open-source platform for rendering geospatial data and creating map applications for the web, supporting numerous standard data formats.",D1;Earth Science,visualization;data_serving,platform,C,https://github.com/MapServer/MapServer,https://mapserver.org/,NOASSERTION,gis;mapping;web-map-server;geospatial
184,NEFFy,NEFF Calculator and MSA File Converter,A tool to calculate the Number of Effective Sequences (NEFF) and convert between Multiple Sequence Alignment (MSA) file formats.,D1;D1-02;Bioinformatics,format_conversion;data_analysis,solver,C++,https://github.com/Maryam-Haghani/NEFFy,,GPL-3.0,msa;bioinformatics;converter;neff
185,gdal.netcore,GDAL bindings for .NET applications,"Provides C# and F# bindings for the GDAL library, enabling .NET applications to read and write geospatial raster and vector data formats.",D1;D1-02;Earth Science,io;data_access,library,PowerShell,https://github.com/MaxRev-Dev/gdal.netcore,,MIT,gdal;dotnet;csharp;geospatial
186,WOSS,World Ocean Simulation System for underwater acoustic channels,A framework integrating underwater channel simulators (like Bellhop) with network simulators (ns-3) to provide realistic underwater acoustic channel realizations based on environmental data.,Physics;Oceanography,simulation;modeling,workflow,C++,https://github.com/MetalKnight/woss-ns3,http://woss.dei.unipd.it/,None,underwater-acoustics;simulation;ns-3;bellhop
187,pyMeteo,Python library for processing meteorological data,"A collection of Python utilities for handling and processing meteorological datasets, likely including format handling and domain-specific calculations.",D1;Atmospheric Science,data_processing;analysis,library,,https://github.com/Mo-Dabao/pyMeteo,,AGPL-3.0,meteorology;weather-data;python
188,PyActiveStorage,Python implementation of Active Storage for scientific data,"A library implementing Active Storage concepts to push data reduction tasks (like filtering and aggregation) down to the storage layer, optimized for scientific formats like NetCDF/HDF5.",D1;D1-02;Computer Science,io_optimization;data_reduction,library,Python,https://github.com/NCAS-CMS/PyActiveStorage,,Apache-2.0,active-storage;netcdf;hdf5;io-optimization
189,cfdm,Python reference implementation of the CF data model,"A complete Python implementation of the Climate and Forecast (CF) data model, used for representing and manipulating earth science data structures and metadata.",D1;D1-02;Atmospheric Science,data_modeling;metadata_handling,library,Python,https://github.com/NCAS-CMS/cfdm,https://ncas-cms.github.io/cfdm/,MIT,cf-conventions;climate-data;netcdf;data-model
190,ZarrDAP,OPeNDAP interface for Zarr and NetCDF data in object storage,"A FastAPI-based server that provides OPeNDAP access to Zarr and NetCDF datasets stored in remote object storage (S3), facilitating remote scientific data access.",D1;D1-02;Earth Science,data_serving;data_access,service,Python,https://github.com/NCEI-NOAAGov/zarrdap,,NOASSERTION,opendap;zarr;netcdf;s3;data-access
191,dicomtk,DICOM Toolkit for parsing and exporting medical images,A Python library that parses DICOM files into an SQLite database for metadata management and supports exporting data to other formats.,D1;D1-02;Medical Physics,io;parsing;metadata_extraction,library,Python,https://github.com/NKI-AI/dicomtk,,MIT,dicom;medical-imaging;sqlite;parser
192,NCEPLIBS-g2c,C decoder/encoder routines for GRIB2 format,"A library containing C routines for decoding and encoding GRIB edition 2 (GRIB2) messages, a standard format for meteorological data.",D1;D1-02;Atmospheric Science,io;encoding;decoding,library,C,https://github.com/NOAA-EMC/NCEPLIBS-g2c,,NOASSERTION,grib2;meteorology;noaa;decoder
193,zarr-cesium,CesiumJS providers for Zarr data visualization,A library enabling interactive 2D and 3D visualization of environmental and geospatial data stored in Zarr format within the CesiumJS globe platform.,D1;Earth Science,visualization;web_mapping,library,TypeScript,https://github.com/NOC-OI/zarr-cesium,,MIT,cesiumjs;zarr;visualization;geospatial
194,zarr-vis,Browser-based visualization for Zarr multidimensional data,"A JavaScript library for fast, scalable visualization of Zarr-based multidimensional scientific data directly in web browsers.",D1;Earth Science,visualization;data_exploration,library,JavaScript,https://github.com/NOC-OI/zarr-vis,,MIT,zarr;visualization;web;multidimensional-data
195,EDA-Parsers,Parsers for EDA standard file formats,"A collection of C++ parsers for standard Electronic Design Automation (EDA) file formats such as Verilog, Liberty, SPEF, VCD, SDF, and SDC.",D1;D1-02;Electronic Engineering,parsing;io,library,C++,https://github.com/OSCC-Project/EDA-Parsers,,NOASSERTION,eda;verilog;parser;vcd
196,GDAL,Geospatial Data Abstraction Library,"The industry-standard translator library for raster and vector geospatial data formats, providing a single abstract data model for a multitude of formats.",D1;D1-02;Earth Science,io;format_conversion;data_processing,library,C++,https://github.com/OSGeo/gdal,https://gdal.org/,NOASSERTION,geospatial;gis;raster;vector;conversion
197,echopype,Interoperable ocean sonar data analysis in Python,"A Python library built on xarray and zarr to standardize and analyze ocean sonar data, converting proprietary formats into open standards.",D1;D1-02;Oceanography,data_conversion;analysis;standardization,library,Python,https://github.com/OSOceanAcoustics/echopype,https://echopype.readthedocs.io/,Apache-2.0,sonar;oceanography;netcdf;zarr;conversion
198,PVGeo-HDF5,HDF5 and NetCDF4 support for PVGeo,An extension of the PVGeo library to support reading and visualizing HDF5 and NetCDF4 data formats within the PyVista/ParaView ecosystem.,D1;D1-02;Geophysics,visualization;io,library,Python,https://github.com/OpenGeoVis/PVGeo-HDF5,,BSD-3-Clause,hdf5;netcdf;visualization;paraview;geophysics
199,mesogeos,Dataset and models for wildfire modeling in the Mediterranean,A repository containing a dataset and Deep Learning models for wildfire danger forecasting and burned area prediction in the Mediterranean region.,Earth Science;Environmental Science,modeling;prediction,solver,Jupyter Notebook,https://github.com/Orion-AI-Lab/mesogeos,,None,wildfire;deep-learning;dataset;modeling
200,xclim,Library of derived climate variables and indicators,A Python library based on xarray for calculating climate indicators and derived variables from climate model output and observational data.,Atmospheric Science;Climate Science,data_analysis;calculation,library,Python,https://github.com/Ouranosinc/xclim,https://xclim.readthedocs.io/,Apache-2.0,climate-indicators;xarray;climate-change;analysis
201,PDAL,Point Data Abstraction Library,"A C++ library for translating and manipulating point cloud data, functioning as a counterpart to GDAL but for point data (LiDAR, etc.).",D1;D1-02;Earth Science,io;processing;format_conversion,library,C++,https://github.com/PDAL/PDAL,https://pdal.io/,NOASSERTION,point-cloud;lidar;geospatial;processing
202,E3SM-IO,I/O Kernel Benchmark for E3SM,"A benchmark suite designed to evaluate the I/O performance of the Energy Exascale Earth System Model (E3SM), specifically targeting Parallel NetCDF and HDF5 usage.",D1;Computer Science;Earth Science,benchmarking;io_optimization,solver,C++,https://github.com/Parallel-NetCDF/E3SM-IO,,NOASSERTION,hpc;benchmark;io;e3sm;parallel-netcdf
203,Kaplan,Conformer searching package,"A package for searching molecular conformers, useful in computational chemistry and molecular modeling.",Chemistry,molecular_modeling;conformer_search,solver,TeX,https://github.com/PeaWagon/Kaplan,,MIT,chemistry;conformer-search;molecular-modeling
204,vcf-parser,Strict streaming parser for VCF 4.1/4.2,"A Java library for strictly parsing Variant Call Format (VCF) files in a streaming manner, ensuring adherence to format specifications.",D1;D1-02;Bioinformatics,parsing;io,library,Java,https://github.com/PharmGKB/vcf-parser,,MPL-2.0,vcf;bioinformatics;parser;genomics
205,PACKMAN,Python package for protein structure and dynamics,"A Python package for structural biology analysis, providing tools for handling protein structures and analyzing their dynamics.",Biology;Structural Biology,structure_analysis;dynamics,library,Python,https://github.com/Pranavkhade/PACKMAN,https://py-packman.readthedocs.io/,NOASSERTION,protein-structure;bioinformatics;dynamics;structural-biology
206,medio,Medical images I/O python package,"A Python package for reading and writing medical images, likely wrapping lower-level libraries like ITK or pydicom for easier access.",D1;D1-02;Medical Physics,io;data_loading,library,Python,https://github.com/RSIP-Vision/medio,,Apache-2.0,medical-imaging;io;python
207,UAVProduct,UAV image processing and point cloud generation tool,"A C++ tool for processing UAV imagery, implementing geometric correction, image stitching, and point cloud generation using OpenMVG, OpenMVS, and GDAL.",Remote Sensing;Photogrammetry,image_processing;3d_reconstruction,application,C++,https://github.com/RemoteSensingFrank/UAVProduct,,None,uav;photogrammetry;point-cloud;gdal
208,ESIO,ExaScale IO library for turbulence simulations,"A library providing simple, high-throughput input and output of structured datasets using parallel HDF5, designed for turbulence simulation restart files.",D1;Physics;Fluid Dynamics,io;hpc,library,C,https://github.com/RhysU/ESIO,,LGPL-2.1,hdf5;parallel-io;turbulence;cfd
209,swiftsimio,Python library for reading SWIFT simulation data,"A Python library for reading and visualizing data produced by the SWIFT astrophysical simulation code, utilizing unyt for unit handling.",D1;Astronomy;Astrophysics,io;visualization,library,Python,https://github.com/SWIFTSIM/swiftsimio,https://swiftsimio.readthedocs.io/,LGPL-3.0,astrophysics;simulation-data;swift;io
210,variantconvert,Customizable genetic variants file format converter,"A Python tool for converting between different genetic variant file formats, facilitating interoperability in bioinformatics workflows.",D1;D1-02;Bioinformatics,format_conversion;data_processing,solver,Python,https://github.com/SamuelNicaise/variantconvert,,AGPL-3.0,bioinformatics;variants;converter;genomics
211,Sen2Agri-System,Sentinel-2 for Agriculture processing system,A software system for processing high-resolution satellite images (Sentinel-2) for agricultural monitoring and analysis.,Remote Sensing;Agriculture,image_processing;monitoring,platform,HTML,https://github.com/Sen2Agri/Sen2Agri-System,http://www.sen2agri.org/,NOASSERTION,sentinel-2;agriculture;remote-sensing;processing
212,fastDFE,Inference of distribution of fitness effects,"A Python package for fast and flexible inference of the distribution of fitness effects (DFE) from genomic data, including VCF parsing.",Biology;Population Genetics,inference;analysis,library,Python,https://github.com/Sendrowski/fastDFE,,GPL-3.0,population-genetics;inference;vcf;dfe
213,vcflib,Python library for parsing and manipulation of VCF,An open-source Python library designed for parsing and manipulating Variant Call Format (VCF) files used in bioinformatics.,D1;D1-02;Bioinformatics,parsing;data_manipulation,library,Python,https://github.com/Sentieon/vcflib,,BSD-2-Clause,vcf;bioinformatics;parser;python
214,hdfdict,Dump and load Python dictionaries to HDF5,A utility library that simplifies the process of saving and loading Python dictionaries to/from HDF5 files using h5py.,D1;D1-02;Computer Science,io;serialization,library,Python,https://github.com/SiggiGue/hdfdict,,MIT,hdf5;python;dictionary;serialization
215,Solcast/netcdf-tiff,Utility library for converting NetCDF files to GeoTIFF format,"A Python library designed to convert scientific data stored in NetCDF format into GeoTIFF, facilitating integration with GIS workflows.",D1;D1-02,format_conversion;gis_interoperability,library,Python,https://github.com/Solcast/netcdf-tiff,,MIT,netcdf;geotiff;converter;gis
216,cheminformatics-microservice,Microservices for cheminformatics data processing and analysis,"A set of microservices accessible via API to support cheminformatics tasks, providing modular tools for chemical data handling.",D1;D1-02,cheminformatics;data_processing,service,JavaScript,https://github.com/Steinbeck-Lab/cheminformatics-microservice,,MIT,cheminformatics;microservice;api
217,AstroBinUploader,Parser for astronomical image headers to generate acquisition summaries,A Python script that parses FITS or XISF file headers to extract acquisition session information and formats it for AstroBin uploads.,D1;D1-02,metadata_extraction;data_formatting,solver,Python,https://github.com/SteveGreaves/AstroBinUploader,,GPL-3.0,astronomy;fits;xisf;metadata
218,mdio-python,Python interface for MDIO scalable energy data storage engine,"A cloud-native, scalable storage engine library designed for handling large-scale energy and seismic data in the MDIO format.",D1;D1-02,data_storage;io_library,library,Python,https://github.com/TGSAI/mdio-python,,Apache-2.0,seismic-data;energy-data;storage;mdio
219,zarrdataset,PyTorch dataset loader for Zarr files in ML pipelines,"A utility library to load data from Zarr files directly into machine learning training pipelines, facilitating the use of large scientific arrays in deep learning.",D1;D1-02,data_loading;machine_learning_io,library,Python,https://github.com/TheJacksonLaboratory/zarrdataset,,MIT,zarr;pytorch;data-loader;bioinformatics
220,OpenAthena-Legacy-Python,Geodetic location spotting tool for drones,A software tool that allows common drones to spot precise geodetic locations using digital elevation models and telemetry data.,D1;D1-02,geodesy;spatial_analysis,solver,Python,https://github.com/Theta-Limited/OpenAthena-Legacy-Python,,NOASSERTION,drones;geodesy;gis;location-spotting
221,Fiona,Python library for reading and writing geographic data files,"Fiona is a Python wrapper around OGR, providing a clean and Pythonic interface for reading and writing vector data formats (GIS).",D1;D1-02,data_io;gis_processing,library,Python,https://github.com/Toblerity/Fiona,https://fiona.readthedocs.io/,BSD-3-Clause,gis;vector-data;ogr;geospatial
222,cftime,Time-handling library for NetCDF and climate data,A library providing time-handling functionality for non-standard calendars commonly used in climate modeling and NetCDF files.,D1;D1-02,time_processing;climate_modeling,library,Python,https://github.com/Unidata/cftime,,MIT,netcdf;climate;calendars;time-series
223,GEMPAK,Meteorological data analysis and product generation package,"A comprehensive analysis and product generation package for meteorological data, widely used for weather forecasting and research.",D1;D1-02,meteorology;data_analysis;visualization,platform,C,https://github.com/Unidata/gempak,https://github.com/Unidata/gempak,BSD-3-Clause,meteorology;weather-analysis;gempak
224,netcdf4-python,Python interface to the netCDF C library,"The standard Python interface for the netCDF C library, allowing creation, access, and sharing of array-oriented scientific data.",D1;D1-02,data_io;array_processing,library,Cython,https://github.com/Unidata/netcdf4-python,http://unidata.github.io/netcdf4-python/,MIT,netcdf;hdf5;climate-data;oceanography
225,hyfo,Hydrology and Climate Forecasting R package,"An R package designed for hydrology and climate forecasting, focusing on data processing and visualization of NetCDF and other formats.",D1;D1-02,hydrology;climate_forecasting;data_processing,library,R,https://github.com/Yuanchao-Xu/hyfo,,None,hydrology;climate;netcdf;forecasting
226,vcfpp,C++ API wrapper for htslib VCF parsing,A C++ API for htslib designed to be easily integrated and safely used for parsing VCF (Variant Call Format) files in bioinformatics.,D1;D1-02,genomics;variant_calling;data_io,library,C++,https://github.com/Zilong-Li/vcfpp,,MIT,vcf;bioinformatics;htslib;cpp
227,vcfppR,High-performance VCF/BCF parser for R,"An R package providing a fast interface for parsing VCF and BCF files, leveraging the vcfpp C++ library.",D1;D1-02,genomics;data_io,library,C,https://github.com/Zilong-Li/vcfppR,,NOASSERTION,vcf;r-package;bioinformatics;genomics
228,pdf2dcm,Python package for converting PDF to DICOM,"A utility library to convert PDF documents into DICOM format, facilitating the integration of reports into medical imaging systems.",D1;D1-02,format_conversion;medical_imaging,library,Python,https://github.com/a-parida12/pdf2dcm,,MIT,dicom;pdf;medical-imaging;converter
229,bboxfinder.com,Web tool for generating bounding box coordinates for GIS,A web-based utility that helps users find and generate bounding box (bbox) values from a map for use with geospatial tools like GDAL and Leaflet.,D1;D1-02,spatial_analysis;utility,solver,JavaScript,https://github.com/aaronr/bboxfinder.com,http://bboxfinder.com/,None,gis;bounding-box;coordinates;utility
230,actinia-core,REST API for distributed GRASS GIS processing,"An open-source REST API for scalable, distributed, and high-performance processing of geographical data, primarily using GRASS GIS.",D1;D1-02,gis_processing;remote_sensing,platform,Python,https://github.com/actinia-org/actinia-core,https://actinia-org.github.io/actinia-core/,GPL-3.0,grass-gis;rest-api;geospatial;cloud-processing
231,lunarsky,Astropy extension for lunar surface observations,An extension to the Astropy library that provides functionality to describe and calculate astronomical observations from the surface of the Moon.,D1;D1-02,astronomy;coordinate_systems,library,Python,https://github.com/aelanman/lunarsky,,BSD-3-Clause,astronomy;moon;astropy;coordinates
232,gmshparser,Parser for Gmsh ASCII file format (.msh),"A lightweight Python package to parse the Gmsh ASCII file format (.msh), useful for finite element analysis (FEM) workflows.",D1;D1-02,mesh_processing;fem,library,Python,https://github.com/ahojukka5/gmshparser,,MIT,gmsh;fem;mesh;parser
233,aignostics-python-sdk,SDK for Aignostics pathology AI platform,"A Python SDK providing access to the Aignostics Platform for computational pathology, including tools for data interaction and analysis.",D1;D1-02,pathology;medical_ai;data_access,library,Python,https://github.com/aignostics/python-sdk,,MIT,pathology;ai;sdk;medical-imaging
234,godal,Golang wrapper for GDAL,"A Go programming language wrapper for the GDAL library, enabling geospatial data abstraction and manipulation in Go applications.",D1;D1-02,gis_io;data_processing,library,Go,https://github.com/airbusgeo/godal,,Apache-2.0,gdal;go;gis;geospatial
235,LinaQA,Medical physics toolkit for radiotherapy QA,"A toolkit for medical physics tasks in radiotherapy, diagnostic radiology, and nuclear medicine, built on top of pylinac and pydicom.",D1;D1-02,medical_physics;quality_assurance;radiotherapy,library,Python,https://github.com/alanphys/LinaQA,,NOASSERTION,medical-physics;radiotherapy;dicom;qa
236,broh5,Browser-based GUI HDF5 Viewer,"A browser-based graphical user interface for viewing and inspecting HDF5 files, facilitating data exploration without writing code.",D1;D1-02,visualization;data_inspection,solver,Python,https://github.com/algotom/broh5,https://broh5.readthedocs.io,Apache-2.0,hdf5;viewer;gui;visualization
237,s2orc-doc2json,Parsers for converting scientific papers to structured JSON,"A set of parsers (PDF2JSON, TEX2JSON, JATS2JSON) to convert scientific documents into structured JSON format for text mining and analysis.",D1;D1-02,text_mining;document_parsing,library,Python,https://github.com/allenai/s2orc-doc2json,,Apache-2.0,pdf-parsing;scientific-literature;nlp;json
238,science-parse,Parser for extracting structured data from scientific PDFs,"A Java-based tool that parses scientific papers in PDF format and extracts structured information such as titles, authors, and references.",D1;D1-02,text_mining;document_parsing,solver,Java,https://github.com/allenai/science-parse,,Apache-2.0,pdf-parsing;scientific-literature;metadata-extraction
239,go-eccodes,Go wrapper for ecCodes (GRIB/BUFR decoding),"A Go wrapper for the ecCodes library, enabling the decoding and encoding of meteorological data formats like GRIB and BUFR in Go applications.",D1;D1-02,meteorology;data_io,library,C,https://github.com/amsokol/go-eccodes,,Apache-2.0,grib;bufr;meteorology;eccodes
240,gdalcubes,Tool for creating and analyzing Earth observation data cubes,"A library and tool for processing collections of Earth observation images as regular data cubes, facilitating temporal and spatial analysis.",D1;D1-02,remote_sensing;spatiotemporal_analysis,library,C++,https://github.com/appelmar/gdalcubes,,NOASSERTION,earth-observation;data-cubes;remote-sensing;gdal
241,picovcf,Fast single-header C++ library for VCF parsing,"A lightweight, high-performance C++ library for parsing VCF (Variant Call Format) files with low memory overhead.",D1;D1-02,genomics;data_io,library,C++,https://github.com/aprilweilab/picovcf,,MIT,vcf;bioinformatics;cpp;parsing
242,ASDF,Advanced Scientific Data Format library,"The reference implementation for ASDF (Advanced Scientific Data Format), a next-generation interchange format for scientific data.",D1;D1-02,data_io;format_specification,library,Python,https://github.com/asdf-format/asdf,https://asdf.readthedocs.io/,BSD-3-Clause,asdf;file-format;scientific-data;io
243,fit-decoder,JavaScript library for parsing ANT/Garmin .FIT files,"A JavaScript library designed to parse .FIT files generated by Garmin and ANT+ devices, commonly used in sports science and physiology.",D1;D1-02,sports_science;data_io,library,JavaScript,https://github.com/ask77nl/fit-decoder,,MIT,fit-format;garmin;sports-data;parsing
244,fitsjs,JavaScript library for reading FITS astronomical files,"A JavaScript library for reading FITS (Flexible Image Transport System) files in the browser or Node.js, supporting images, data cubes, and tables.",D1;D1-02,astronomy;data_io;web_visualization,library,JavaScript,https://github.com/astrojs/fitsjs,,MIT,fits;astronomy;javascript;visualization
245,galfit-python-parser,Parser for GALFIT output FITS files,A Python utility to parse the output FITS files generated by GALFIT (galaxy fitting software) and extract fit information.,D1;D1-02,astronomy;data_parsing;galaxy_fitting,library,Python,https://github.com/astronomeralex/galfit-python-parser,,MIT,galfit;astronomy;fits;parser
246,asdf-astropy,ASDF extension for Astropy data structures,An extension library that provides support for serializing and deserializing Astropy data structures using the ASDF standard.,D1;D1-02,astronomy;data_io;serialization,library,Python,https://github.com/astropy/asdf-astropy,,BSD-3-Clause,asdf;astropy;serialization;astronomy
247,Astropy,Core library for Astronomy and Astrophysics,"The core Python package for Astronomy, providing common tools such as unit conversions, coordinate systems, and FITS file handling.",D1;D1-02,astronomy;data_analysis;data_io,library,Python,https://github.com/astropy/astropy,https://www.astropy.org/,BSD-3-Clause,astronomy;fits;coordinates;units
248,astropy-healpix,HEALPix implementation for Astropy,A BSD-licensed implementation of HEALPix (Hierarchical Equal Area isoLatitude Pixelization) for use with the Astropy ecosystem.,D1;D1-02,astronomy;spatial_indexing;pixelization,library,C,https://github.com/astropy/astropy-healpix,https://astropy-healpix.readthedocs.io/,BSD-3-Clause,healpix;astronomy;sky-map;pixelization
249,astroquery,Functions and classes to access online astronomical data resources,"A package that provides a set of tools for querying online astronomical forms and databases such as SIMBAD, VizieR, and others.",D1;D1-02,data_acquisition;database_query,library,Python,https://github.com/astropy/astroquery,https://astroquery.readthedocs.io,BSD-3-Clause,astronomy;data-access;query
250,astrowidgets,Jupyter widgets leveraging the Astropy ecosystem for visualization,"A set of Jupyter widgets for interactive visualization and analysis of astronomical data, designed to work with the Astropy ecosystem.",D1;D1-02,visualization;interactive_analysis,library,Python,https://github.com/astropy/astrowidgets,https://astrowidgets.readthedocs.io,BSD-3-Clause,astronomy;visualization;jupyter-widgets
251,ccdproc,Astropy affiliated package for reducing optical/IR CCD data,"A library for basic data reduction of CCD images, providing tools for bias subtraction, flat fielding, and cosmic ray rejection.",D1;D1-02,data_processing;image_reduction,library,Python,https://github.com/astropy/ccdproc,https://ccdproc.readthedocs.io,BSD-3-Clause,astronomy;ccd;image-processing
252,photutils,Astropy package for source detection and photometry,"A package for performing photometry of astronomical sources, including aperture photometry and PSF-fitting photometry.",D1;D1-02,data_analysis;photometry,library,Python,https://github.com/astropy/photutils,https://photutils.readthedocs.io,BSD-3-Clause,astronomy;photometry;source-detection
253,pyregion,DS9 region parser for Python,"A python module to parse ds9 region files, allowing users to read and visualize region files used in astronomical image analysis.",D1;D1-02,data_parsing;visualization,library,Python,https://github.com/astropy/pyregion,https://pyregion.readthedocs.io,MIT,astronomy;ds9;region-files
254,pyvo,Access to remote data and services of the Virtual Observatory (VO),"A package providing access to remote data and services of the Virtual Observatory (VO) using Python, enabling discovery and retrieval of astronomical data.",D1;D1-02,data_acquisition;vo_services,library,Python,https://github.com/astropy/pyvo,https://pyvo.readthedocs.io,BSD-3-Clause,astronomy;virtual-observatory;data-access
255,regions,Astropy package for region handling,"A package for handling regions in astronomical images, providing tools to define, manipulate, and visualize regions.",D1;D1-02,data_processing;region_handling,library,Python,https://github.com/astropy/regions,https://astropy-regions.readthedocs.io,BSD-3-Clause,astronomy;regions;spatial
256,specreduce,Tools for the reduction of spectroscopic observations,A package providing tools for the reduction of spectroscopic observations from optical and NIR instruments.,D1;D1-02,data_processing;spectroscopy_reduction,library,Jupyter Notebook,https://github.com/astropy/specreduce,https://specreduce.readthedocs.io,None,astronomy;spectroscopy;reduction
257,specutils,An Astropy coordinated package for astronomical spectroscopy,"A package for representing, manipulating, and analyzing astronomical spectroscopic data.",D1;D1-02,data_analysis;spectroscopy,library,Python,https://github.com/astropy/specutils,https://specutils.readthedocs.io,None,astronomy;spectroscopy;analysis
258,loam,Javascript wrapper for GDAL in the browser,"A Javascript wrapper for GDAL (Geospatial Data Abstraction Library) running in the browser via Emscripten, enabling geospatial data processing on the client side.",D1;D1-02,data_processing;format_conversion,library,JavaScript,https://github.com/azavea/loam,,Apache-2.0,geospatial;gdal;javascript
259,go-native-netcdf,A native Go implementation of NetCDF4,"A library providing a native Go implementation for reading and writing NetCDF4 files, a common format in atmospheric and oceanographic science.",D1;D1-02,data_io;format_parsing,library,Go,https://github.com/batchatco/go-native-netcdf,,MIT,netcdf;go;io
260,jzarr,Java implementation of the Zarr API,"A Java implementation of the Zarr chunked, compressed, N-dimensional array storage format, compatible with the Python zarr package.",D1;D1-02,data_io;format_parsing,library,Java,https://github.com/bcdev/jzarr,,MIT,zarr;java;io
261,zappend,Robustly creating and updating Zarr data cubes,"A tool for creating and updating Zarr data cubes from smaller subsets, useful for processing large scientific datasets.",D1;D1-02,data_processing;data_management,library,Python,https://github.com/bcdev/zappend,https://zappend.readthedocs.io,MIT,zarr;data-cubes;python
262,bioconvert,Facilitate the interconversion of life science data formats,"A collaborative project providing tools to convert between various life science data formats, streamlining bioinformatics workflows.",D1;D1-02,format_conversion;data_processing,solver,Python,https://github.com/bioconvert/bioconvert,http://bioconvert.readthedocs.io,GPL-3.0,bioinformatics;format-conversion;data-processing
263,geodot-plugin,Godot plugin for loading geospatial data,"A plugin for the Godot game engine that allows loading and visualizing geospatial data, useful for scientific visualization and simulation.",D1;D1-02,visualization;simulation,library,C++,https://github.com/boku-ilen/geodot-plugin,,GPL-3.0,geospatial;godot;visualization
264,cyvcf2,Fast VCF and BCF processing with Cython and htslib,A high-performance Python wrapper around htslib for parsing and manipulating VCF (Variant Call Format) and BCF files.,D1;D1-02,data_parsing;variant_processing,library,Cython,https://github.com/brentp/cyvcf2,https://brentp.github.io/cyvcf2/,MIT,bioinformatics;vcf;cython
265,hts-nim,Nim wrapper for htslib for parsing genomics data files,"A Nim language wrapper for htslib, enabling high-performance parsing of genomics data formats like BAM, VCF, and BCF.",D1;D1-02,data_parsing;genomics,library,Nim,https://github.com/brentp/hts-nim,,MIT,bioinformatics;nim;htslib
266,hts-zig,Zig bindings for htslib,"Zig language bindings for htslib, allowing the processing of high-throughput sequencing data in Zig.",D1;D1-02,data_parsing;genomics,library,Zig,https://github.com/brentp/hts-zig,,MIT,bioinformatics;zig;htslib
267,gdal3.js,Convert raster and vector geospatial data in the browser,A library to convert raster and vector geospatial data to various formats and coordinate systems entirely in the browser using GDAL.,D1;D1-02,format_conversion;geospatial_processing,library,JavaScript,https://github.com/bugra9/gdal3.js,,LGPL-2.1,geospatial;gdal;javascript
268,CaVEMan,SNV expectation maximisation based mutation calling algorithm,"A somatic mutation caller for detecting single nucleotide variants (SNVs) in paired tumour/normal cancer samples, supporting BAM and CRAM formats.",D1;D1-02,variant_calling;cancer_genomics,solver,C,https://github.com/cancerit/CaVEMan,,AGPL-3.0,bioinformatics;mutation-calling;cancer
269,cgpBigWig,BigWig manipulation tools using libBigWig and htslib,"A set of tools for manipulating BigWig files, including conversion and processing, utilizing libBigWig and htslib.",D1;D1-02,data_processing;genomics,solver,C,https://github.com/cancerit/cgpBigWig,,AGPL-3.0,bioinformatics;bigwig;genomics
270,ndpyramid,Utility for generating ND array pyramids using Xarray and Zarr,"A tool for creating multiscale pyramids of N-dimensional arrays, facilitating efficient visualization and analysis of large scientific datasets.",D1;D1-02,data_processing;visualization_prep,library,Python,https://github.com/carbonplan/ndpyramid,https://ndpyramid.readthedocs.io,MIT,zarr;xarray;pyramids
271,zarr-gl,Custom WebGL Zarr layer for Mapbox and Maplibre,"A WebGL layer for rendering Zarr data on Mapbox and Maplibre maps, enabling interactive visualization of large geospatial datasets.",D1;D1-02,visualization;geospatial,library,TypeScript,https://github.com/carderne/zarr-gl,,MIT,zarr;webgl;geospatial
272,vawk,Awk-like VCF parser for bioinformatics data,"A command-line tool designed to parse and process VCF (Variant Call Format) files using an awk-like syntax, facilitating filtering and data extraction in bioinformatics workflows.",D1;D1-02,parsing;filtering,library,Python,https://github.com/cc2qe/vawk,,MIT,vcf;bioinformatics;genomics;parser
273,fitsrs,Pure Rust FITS file reader library,"A library implemented in Rust for reading FITS (Flexible Image Transport System) files, commonly used in astronomy for data storage and transmission.",D1;D1-02,parsing;io,library,Rust,https://github.com/cds-astro/fitsrs,,Apache-2.0,fits;astronomy;rust;io
274,imagecodecs,Image transformation and compression codecs for scientific imaging,"A Python library providing block-oriented, in-memory buffer transformation, compression, and decompression functions for use with tifffile and other scientific imaging tools.",D1;D1-02,compression;decompression;io,library,Cython,https://github.com/cgohlke/imagecodecs,https://pypi.org/project/imagecodecs/,BSD-3-Clause,imaging;compression;codecs;tiff
275,tifffile,Reader and writer for scientific TIFF files,"A Python library to read and write TIFF files, specifically designed to handle the complex and multidimensional TIFF formats used in bioimaging and microscopy.",D1;D1-02,io;parsing,library,Python,https://github.com/cgohlke/tifffile,https://pypi.org/project/tifffile/,BSD-3-Clause,tiff;microscopy;bioimaging;io
276,cod-tools,Tools for handling Crystallographic Information Framework (CIF) files,"A collection of tools and parsers for handling CIF files, developed for and used by the Crystallography Open Database (COD) for data validation and management.",D1;D1-02,parsing;validation;io,library,Perl,https://github.com/cod-developers/cod-tools,https://wiki.crystallography.net/cod-tools/,LGPL-3.0,cif;crystallography;parsing;cod
277,rio-tiler,Rasterio plugin to read and tile raster datasets,"A Python library designed to read and process raster datasets (like Cloud Optimized GeoTIFFs) and create map tiles for web visualization, widely used in geospatial workflows.",D1;D1-02,io;tiling;visualization_prep,library,Python,https://github.com/cogeotiff/rio-tiler,https://cogeotiff.github.io/rio-tiler/,BSD-3-Clause,geospatial;raster;cog;tiling
278,gdal2tiles-leaflet,Generate raster image tiles for Leaflet maps,"A tool to generate raster image tiles from geospatial data compatible with Leaflet, facilitating the visualization of scientific raster data on the web.",D1;D1-02,visualization_prep;tiling,workflow,Python,https://github.com/commenthol/gdal2tiles-leaflet,,MIT,gdal;leaflet;tiles;geospatial
279,z5,C++ and Python interface for Zarr and N5 formats,"A lightweight C++ library with Python bindings for reading and writing multi-dimensional datasets in Zarr and N5 formats, commonly used in connectomics and bioimaging.",D1;D1-02,io;parsing,library,C++,https://github.com/constantinpape/z5,https://constantinpape.github.io/z5/,MIT,zarr;n5;bioimaging;io
280,dicomParser,JavaScript parser for DICOM Part 10 data,"A lightweight JavaScript library for parsing DICOM P10 byte streams in web browsers, enabling web-based medical imaging visualization and analysis applications.",D1;D1-02,parsing;io,library,JavaScript,https://github.com/cornerstonejs/dicomParser,,MIT,dicom;medical-imaging;javascript;parser
281,geocube,Tool to convert vector data into rasterized xarray data,"A Python tool that simplifies the conversion of geospatial vector data (GeoDataFrame) into rasterized xarray objects, facilitating integration between vector and raster workflows.",D1;D1-02,conversion;rasterization,workflow,Python,https://github.com/corteva/geocube,https://corteva.github.io/geocube/,BSD-3-Clause,geospatial;rasterization;xarray;geopandas
282,rioxarray,Geospatial xarray extension powered by rasterio,"An extension for xarray that provides geospatial capabilities using rasterio, allowing for easy manipulation, projection, and I/O of raster data in scientific workflows.",D1;D1-02,io;processing,library,Python,https://github.com/corteva/rioxarray,https://corteva.github.io/rioxarray/,NOASSERTION,xarray;rasterio;geospatial;io
283,agnpy,Modelling jetted Active Galactic Nuclei radiative processes,"A Python package for modelling the radiative processes of jetted Active Galactic Nuclei (AGN), enabling numerical calculation of photon spectra for astrophysics research.",D1,modeling;simulation,solver,Jupyter Notebook,https://github.com/cosimoNigro/agnpy,https://agnpy.readthedocs.io/,BSD-3-Clause,astrophysics;agn;radiative-processes;modeling
284,cubed,Scalable array processing with bounded memory,"A library for scalable array processing that operates with bounded memory usage, designed to handle large scientific datasets (like Zarr arrays) in distributed environments.",D1,computation;processing,library,Python,https://github.com/cubed-dev/cubed,,Apache-2.0,array-processing;distributed-computing;zarr;serverless
285,DVH-Analytics,DICOM Database Application for Radiation Oncology,"A software application for building a local database of DICOM Radiation Therapy (RT) data, enabling statistical analysis and visualization of Dose-Volume Histograms (DVH) for clinical research.",D1;D1-02,analysis;database_management;visualization,platform,Python,https://github.com/cutright/DVH-Analytics,http://dvh-analytics.com,NOASSERTION,dicom-rt;radiation-oncology;dvh;medical-physics
286,arrow-zarr,Rust implementation of Zarr file format for Arrow,"A Rust library providing an implementation of the Zarr storage format, designed to integrate with the Apache Arrow ecosystem for efficient data processing.",D1;D1-02,io;parsing,library,Rust,https://github.com/datafusion-contrib/arrow-zarr,,Apache-2.0,zarr;rust;arrow;io
287,NetCDF4-variable-streamer,Streamer for chunked reading/writing of NetCDF4 variables,"A Python utility that extends the netCDF4 package to support streaming read/write operations on variables using chunking, facilitating the handling of large datasets that exceed memory limits.",D1;D1-02,io;chunking,workflow,Python,https://github.com/david-salac/NetCDF4-variable-streamer,,MIT,netcdf;streaming;io;python
288,versioned-hdf5,Versioned abstraction on top of HDF5,"A Python library that implements a versioning system on top of HDF5 files, allowing for git-like tracking of data changes within HDF5 containers.",D1;D1-02,io;versioning;data_management,library,Python,https://github.com/deshaw/versioned-hdf5,https://versioned-hdf5.readthedocs.io/,NOASSERTION,hdf5;versioning;data-management;python
289,titiler,Dynamic map tile services for raster data,"A modern dynamic tile server built on top of FastAPI and Rasterio, allowing users to create map tile services from Cloud Optimized GeoTIFF (COG) and other raster sources for geospatial analysis and visualization.",D1;D1-02,visualization_service;processing,service,Python,https://github.com/developmentseed/titiler,https://developmentseed.org/titiler/,MIT,geospatial;raster;cog;tile-server
290,titiler-multidim,TiTiler application for NetCDF/Zarr datasets,"An extension of TiTiler specifically designed for serving and visualizing multi-dimensional datasets like NetCDF and Zarr, common in climate and meteorological sciences.",D1;D1-02,visualization_service;io,service,Python,https://github.com/developmentseed/titiler-multidim,,MIT,netcdf;zarr;multidimensional;geospatial
291,OnkoDICOM,Research platform for DICOM-RT and medical imaging,"An open-source software platform for Radiation Oncology research, enabling the viewing and analysis of DICOM standard image sets (CT, MRI, PET, RT) using Python-based technologies.",D1;D1-02,analysis;visualization;medical_imaging,platform,Python,https://github.com/didymo/OnkoDICOM,https://onkodicom.com,LGPL-2.1,dicom;radiation-oncology;medical-imaging;research-platform
292,hagelslag,Object-based severe weather forecast verification and tracking,"A Python package for object-based tracking and verification of weather fields (like storms), supporting segmentation, tracking, and performance diagram generation for meteorological research.",D1,tracking;segmentation;verification,solver,Jupyter Notebook,https://github.com/djgagne/hagelslag,,MIT,meteorology;weather-tracking;verification;machine-learning
293,python-fitparse,Parser for ANT/Garmin .FIT files,"A Python library for parsing .FIT files, a format commonly used by Garmin devices and ANT+ sensors, enabling access to sports science and physiological data.",D1;D1-02,parsing;io,library,Python,https://github.com/dtcooper/python-fitparse,,MIT,fit-format;sports-science;parsing;garmin
294,dask-rasterio,Parallel raster I/O using Rasterio and Dask,"A library that integrates Rasterio with Dask to enable parallel reading and writing of raster data, facilitating scalable geospatial data processing.",D1;D1-02,io;parallel_processing,library,Python,https://github.com/dymaxionlabs/dask-rasterio,https://dask-rasterio.readthedocs.io/,BSD-3-Clause,dask;rasterio;geospatial;parallel-computing
295,icechunk,Cloud-native transactional tensor storage engine,"A high-performance, transactional storage engine for tensor data (like Zarr), designed for cloud-native scientific computing and managing large-scale multi-dimensional arrays.",D1;D1-02,storage;io;data_management,library,Rust,https://github.com/earth-mover/icechunk,https://icechunk.io,Apache-2.0,zarr;tensor-storage;cloud-native;rust
296,lisflood-utilities,Utilities for LISFLOOD hydrological model,"A collection of Python utilities for pre-processing and post-processing data for the LISFLOOD hydrological model, maintained by the EC Joint Research Centre.",D1,preprocessing;postprocessing;hydrology,workflow,Python,https://github.com/ec-jrc/lisflood-utilities,https://ec-jrc.github.io/lisflood-utilities/,EUPL-1.2,hydrology;lisflood;environmental-science;utilities
297,climetlab-s2s-ai-challenge,Climetlab plugin for S2S AI Challenge data,"A plugin for Climetlab that provides access to the Sub-seasonal to Seasonal (S2S) forecast datasets used in the S2S AI Challenge, facilitating data loading for climate research.",D1,data_access;io,dataset,Jupyter Notebook,https://github.com/ecmwf-lab/climetlab-s2s-ai-challenge,,Apache-2.0,climate;s2s;climetlab;data-access
298,ecCodes,ECMWF's library for decoding and encoding GRIB and BUFR meteorological formats,"A package developed by ECMWF which provides an application programming interface and a set of tools for decoding and encoding messages in the following formats: WMO FM-92 GRIB edition 1 and edition 2, WMO FM-94 BUFR edition 3 and edition 4, WMO FM-95 CREX edition 1.",D1;D1-02;Meteorology,parsing;encoding;conversion,library,C++,https://github.com/ecmwf/eccodes,https://confluence.ecmwf.int/display/ECC,Apache-2.0,grib;bufr;meteorology;weather-data
299,eccodes-python,Python interface to the ecCodes GRIB and BUFR decoding/encoding library,"Python 3 interface to the ecCodes library, allowing Python programs to read and write GRIB and BUFR files used in meteorological data.",D1;D1-02;Meteorology,parsing;encoding,library,Python,https://github.com/ecmwf/eccodes-python,https://confluence.ecmwf.int/display/ECC/Python+bindings,Apache-2.0,python;grib;bufr;meteorology
300,pyeccodes,Experimental pure Python GRIB decoder,"An experimental, pure Python implementation for decoding GRIB files, serving as a potential alternative to C-binding based parsers for specific use cases.",D1;D1-02;Meteorology,parsing,library,Python,https://github.com/ecmwf/pyeccodes,,Apache-2.0,grib;python;experimental
301,gdal2mbtiles,Converter from GDAL-readable datasets to MBTiles format,"A command-line tool and Python library to convert any GDAL-supported geospatial dataset into the MBTiles format, primarily for generating web map tiles.",D1;D1-02;Geospatial,conversion;tiling,solver,Python,https://github.com/ecometrica/gdal2mbtiles,,Apache-2.0,gdal;mbtiles;gis;mapping
302,DicomBrowser,Lightweight portable DICOM browser application,"A portable application for viewing and inspecting DICOM medical imaging files, allowing users to browse tags and pixel data.",D1;D1-02;Medical Imaging,visualization;inspection,solver,Python,https://github.com/ericspod/DicomBrowser,,GPL-3.0,dicom;viewer;medical-imaging
303,pandasVCF,VCF parser using the Python pandas library,"A tool to parse Variant Call Format (VCF) files into pandas DataFrames, facilitating data analysis and manipulation of genomic variants.",D1;D1-02;Bioinformatics,parsing;data_loading,library,Jupyter Notebook,https://github.com/erscott/pandasVCF,,BSD-3-Clause,vcf;pandas;genomics
304,fitsio,Python package for FITS input/output wrapping cfitsio,"A Python wrapper around the cfitsio library, providing a full-featured interface for reading and writing FITS (Flexible Image Transport System) files used in astronomy.",D1;D1-02;Astronomy,parsing;io,library,Python,https://github.com/esheldon/fitsio,,GPL-2.0,fits;astronomy;cfitsio
305,astropysics,Astrophysics utilities and libraries for Python,"A library containing a variety of utilities for astrophysics, including coordinate transformations, cosmological calculations, and FITS file handling.",D1;D1-02;Astronomy,data_processing;calculation,library,Python,https://github.com/eteq/astropysics,http://pythonhosted.org/Astropysics/,None,astrophysics;fits;photometry
306,grid_map_geo,Geolocalization for grid maps using GDAL,"A C++ library that provides geolocalization capabilities for grid maps by interfacing with GDAL, allowing conversion between grid coordinates and geo-referenced coordinates.",D1;D1-02;Robotics;Geospatial,georeferencing;conversion,library,C++,https://github.com/ethz-asl/grid_map_geo,,BSD-3-Clause,gdal;grid-map;robotics;gis
307,VCF-Simplify,Python parser to simplify and build VCF files,"A tool designed to simplify the parsing and construction of VCF (Variant Call Format) files, making it easier to handle genomic variant data programmatically.",D1;D1-02;Bioinformatics,parsing;simplification,library,Python,https://github.com/everestial/VCF-Simplify,,MIT,vcf;genomics;parser
308,GeoDataFrames.jl,Geographical vector interaction for Julia built on ArchGDAL,"A Julia package that provides functionality for working with geospatial vector data, leveraging ArchGDAL for I/O and operations.",D1;D1-02;Geospatial,io;data_manipulation,library,Julia,https://github.com/evetion/GeoDataFrames.jl,,MIT,julia;gis;gdal;vector-data
309,SGS,Browser for visualizing single-cell and spatial multiomics data,"A user-friendly, collaborative browser tool for visualizing and exploring single-cell and spatial multiomics datasets.",D1;D1-02;Bioinformatics,visualization;exploration,solver,JavaScript,https://github.com/fanglu0411/sgs,,None,single-cell;spatial-omics;visualization
310,ngff-zarr,OME Next Generation File Format (NGFF) Zarr implementation,"A lightweight Python implementation of the Open Microscopy Environment (OME) Next Generation File Format (NGFF) based on Zarr, for bioimaging data.",D1;D1-02;Bioimaging,io;format_implementation,library,Python,https://github.com/fideus-labs/ngff-zarr,,MIT,ome-zarr;ngff;microscopy;bioimaging
311,vcf-reformatter,High-performance VCF file parser and reformatter,"A Rust-based tool to parse VCF files and reformat them into analyzable TSV formats, with support for VEP annotations and transcript handling.",D1;D1-02;Bioinformatics,conversion;parsing;formatting,solver,Rust,https://github.com/flalom/vcf-reformatter,,MIT,vcf;rust;genomics;bioinformatics
312,Gammapy,Python package for gamma-ray astronomy,"A community-developed, open-source Python package for gamma-ray astronomy, providing tools for data analysis, modeling, and format handling.",D1;D1-02;Astronomy,data_analysis;modeling;io,library,Python,https://github.com/gammapy/gammapy,https://gammapy.org/,BSD-3-Clause,gamma-ray;astronomy;fits;data-analysis
313,h5pyViewer,Viewer for HDF5 files,"A graphical user interface tool for viewing and inspecting the contents of HDF5 files, built using Python and h5py.",D1;D1-02;General Science,visualization;inspection,solver,Python,https://github.com/ganymede42/h5pyViewer,,BSD-2-Clause,hdf5;viewer;gui
314,hidefix,Concurrent HDF5 and NetCDF4 reader,"A Rust library for concurrent reading of HDF5 and NetCDF4 files, optimized for performance in scientific data pipelines.",D1;D1-02;General Science,io;parsing,library,Rust,https://github.com/gauteh/hidefix,,MIT,hdf5;netcdf;rust;concurrency
315,SDFormat,Simulation Description Format (SDFormat) parser,"The official parser and description files for SDFormat (SDF), an XML format that describes objects and environments for robot simulators, visualization, and control.",D1;D1-02;Robotics,parsing;simulation_description,library,C++,https://github.com/gazebosim/sdformat,http://sdformat.org,Apache-2.0,robotics;simulation;sdf;xml
316,Geofileops,Toolbox to process large geospatial vector files,"A Python toolbox designed to process large geospatial vector files efficiently, utilizing multiprocessing and spatial indexing.",D1;D1-02;Geospatial,data_processing;optimization,library,Python,https://github.com/geofileops/geofileops,https://geofileops.readthedocs.io/,BSD-3-Clause,gis;vector-data;geospatial;processing
317,gdal-rust,Rust bindings for GDAL,"Idiomatic Rust bindings for the GDAL (Geospatial Data Abstraction Library), enabling Rust applications to read and write geospatial raster and vector data.",D1;D1-02;Geospatial,io;bindings,library,Rust,https://github.com/georust/gdal,https://docs.rs/gdal/,MIT,rust;gdal;gis;geospatial
318,nc4fortran,Object-oriented Fortran NetCDF4 interface,"A lightweight, object-oriented Fortran interface for reading and writing NetCDF4 files, simplifying scientific I/O in Fortran applications.",D1;D1-02;General Science,io;interface,library,CMake,https://github.com/geospace-code/nc4fortran,,MIT,fortran;netcdf;io
319,LabCD,Remote sensing change detection annotation tool,"A specialized annotation tool for remote sensing change detection tasks, facilitating the creation of ground truth datasets for scientific research.",D1;D1-02;Remote Sensing,annotation;data_generation,solver,C++,https://github.com/geoyee/LabCD,,GPL-3.0,remote-sensing;annotation;change-detection
320,DINCAE,Data-Interpolating Convolutional Auto-Encoder for satellite data reconstruction,"A neural network-based tool (DINCAE) designed to reconstruct missing data (e.g., due to clouds) in satellite observations, particularly for oceanographic data.",D1;D1-02;Oceanography;Remote Sensing,reconstruction;interpolation;modeling,solver,Python,https://github.com/gher-uliege/DINCAE,,GPL-3.0,satellite;reconstruction;neural-network;oceanography
321,dmrpp-generator,Generator for DMR++ files from NetCDF4 and HDF5,"A tool developed by NASA GHRC DAAC to generate DMR++ (OPeNDAP Hyrax) files from NetCDF4 and HDF5 data, enabling efficient cloud-based data access.",D1;D1-02;Earth Science,conversion;metadata_generation,solver,Python,https://github.com/ghrcdaac/dmrpp-generator,,Apache-2.0,opendap;netcdf;hdf5;nasa
322,geoserver-rest,Python library for managing geospatial data in GeoServer,"A Python client library for interacting with the GeoServer REST API, allowing programmatic management of geospatial data layers, styles, and workspaces.",D1;D1-02;Geospatial,data_management;api_client,library,Python,https://github.com/gicait/geoserver-rest,,MIT,geoserver;gis;python
323,go-dicom,DICOM Medical Image Parser in Go,"A Go library for parsing and processing DICOM medical imaging files, supporting reading and writing of DICOM elements.",D1;D1-02;Medical Imaging,parsing;io,library,Go,https://github.com/gillesdemey/go-dicom,,MIT,dicom;go;medical-imaging
324,dans-gdal-scripts,Utilities for use in conjunction with GDAL,A collection of command-line utilities and scripts that extend or complement GDAL for geospatial data processing tasks.,D1;D1-02;Geospatial,data_processing;utilities,solver,C++,https://github.com/gina-alaska/dans-gdal-scripts,,NOASSERTION,gdal;gis;utilities
325,gdal2cesium,Python+GDAL Cesium heightmap/terrain generator,A tool to generate Cesium-compatible heightmaps and terrain tiles from GDAL-supported raster data sources.,D1;D1-02;Geospatial,conversion;terrain_generation,solver,Python,https://github.com/giohappy/gdal2cesium,,GPL-2.0,cesium;gdal;terrain;heightmap
326,ChemmineOB,OpenBabel wrapper package for R,"An R package that provides an interface to the OpenBabel chemistry library, enabling chemical file format conversion and molecular processing within R.",D1;D1-02;Cheminformatics,conversion;processing,library,C++,https://github.com/girke-lab/ChemmineOB,https://bioconductor.org/packages/ChemmineOB/,NOASSERTION,r;openbabel;chemistry;cheminformatics
327,gnparser,Scientific name parser and normalizer,"A high-performance tool written in Go to parse, normalize, and extract semantic elements from scientific names of organisms.",D1;D1-02;Biodiversity,parsing;normalization,solver,Go,https://github.com/gnames/gnparser,https://parser.globalnames.org/,MIT,taxonomy;biodiversity;parser;scientific-names
328,arco-era5,Recipes for reproducing Analysis-Ready & Cloud Optimized (ARCO) ERA5 datasets,"A collection of pipelines and tools to process ERA5 climate data into Analysis-Ready, Cloud Optimized (ARCO) formats like Zarr, facilitating large-scale climate research.",D1;D1-02;Climate Science,data_processing;workflow,workflow,Python,https://github.com/google-research/arco-era5,,Apache-2.0,era5;climate;zarr;cloud-optimized
329,Google Earth Enterprise,Open Source version of Google Earth Enterprise,A geospatial application platform that allows organizations to build and host their own private globes and maps using their own geospatial data.,D1;D1-02;Geospatial,visualization;platform,platform,C++,https://github.com/google/earthenterprise,http://www.opengee.org/,Apache-2.0,gis;earth;mapping;platform
330,xarray-beam,Distributed Xarray with Apache Beam,"A Python library that adapts Xarray data structures for distributed processing using Apache Beam, enabling scalable analysis of large scientific datasets.",D1;D1-02;General Science,data_processing;distributed_computing,library,Python,https://github.com/google/xarray-beam,https://xarray-beam.readthedocs.io/,Apache-2.0,xarray;apache-beam;distributed-computing;big-data
331,gradienthealth/dicom,High Performance DICOM Medical Image Parser in Go,"A high-performance Go library for parsing and processing DICOM files, designed for efficiency in medical imaging applications.",D1;D1-02;Medical Imaging,parsing;io,library,Go,https://github.com/gradienthealth/dicom,,MIT,dicom;go;medical-imaging
332,grailbio/go-dicom,DICOM parser for Golang,"A Go library for parsing DICOM files, providing functionality to read and extract information from medical images.",D1;D1-02;Medical Imaging,parsing;io,library,Go,https://github.com/grailbio/go-dicom,,MIT,dicom;go;medical-imaging
333,embedded-pydicom-react-viewer,Web-based DICOM viewer component using Pydicom and WebAssembly,A medical DICOM file viewer that runs in the browser by using Pyodide to run Pydicom (Python) within a React application. It allows for parsing and viewing medical imaging data directly in web interfaces.,D1;D1-02,visualization;parsing,platform,Python,https://github.com/grimmerk/embedded-pydicom-react-viewer,,NOASSERTION,dicom;medical-imaging;visualization;webassembly
334,node-dicom,DICOM parser and utility library for Node.js,A JavaScript/CoffeeScript library for parsing and handling DICOM medical imaging files in Node.js environments. It provides utilities to read tags and extract data from DICOM files.,D1;D1-02,parsing;data_extraction,library,CoffeeScript,https://github.com/grmble/node-dicom,,MIT,dicom;medical-imaging;parser;nodejs
335,zarr.js,JavaScript implementation of the Zarr storage format,"A JavaScript library for reading and writing Zarr arrays, a format widely used for chunked, compressed, N-dimensional arrays in scientific computing (e.g., genomics, bioimaging).",D1;D1-02,io;data_access,library,TypeScript,https://github.com/gzuidhof/zarr.js,,Apache-2.0,zarr;array-storage;io;javascript
336,h5netcdf,Pythonic interface to netCDF4 via h5py,A Python library that provides a netCDF4-compatible interface using h5py as the backend. It allows reading and writing netCDF4 files (which are based on HDF5) without relying on the official netCDF4-python C bindings.,D1;D1-02,io;data_access,library,Python,https://github.com/h5netcdf/h5netcdf,,BSD-3-Clause,netcdf;hdf5;geoscience;io
337,h5py,Pythonic interface to the HDF5 binary data format,"The standard Python package for interacting with HDF5 binary data format. It lets you store huge amounts of numerical data, and easily manipulate that data from NumPy.",D1;D1-02,io;data_storage,library,Python,https://github.com/h5py/h5py,https://www.h5py.org,BSD-3-Clause,hdf5;io;data-storage;numpy
338,IOH5Write,Library to write OpenFOAM cases as HDF5 archives,"A C++ library designed to convert and write OpenFOAM (Computational Fluid Dynamics) simulation cases into HDF5 archives, facilitating data management and analysis.",D1;D1-02,conversion;io,library,C++,https://github.com/hakostra/IOH5Write,,GPL-3.0,openfoam;cfd;hdf5;conversion
339,vcf.js,VCF parser and variant record model in JavaScript,"A JavaScript library for parsing Variant Call Format (VCF) files, commonly used in bioinformatics for storing gene sequence variations.",D1;D1-02,parsing;genomics,library,JavaScript,https://github.com/hammerlab/vcf.js,,Apache-2.0,vcf;bioinformatics;genomics;parser
340,clusttraj,Trajectory clustering tool for molecular dynamics,A Python script that performs agglomerative clustering on molecular dynamics or Monte Carlo trajectories to classify similar molecular structures.,D1;D1-02,clustering;structure_analysis,solver,Python,https://github.com/hmcezar/clusttraj,,GPL-3.0,molecular-dynamics;clustering;trajectory-analysis
341,viv,Multiscale visualization library for bioimaging data,A JavaScript library for high-resolution multiplexed bioimaging data visualization on the web. It supports direct rendering of Zarr and OME-TIFF formats.,D1;D1-02,visualization;bioimaging,library,JavaScript,https://github.com/hms-dbmi/viv,http://viv.gehlenborglab.org/,MIT,bioimaging;visualization;zarr;ome-tiff
342,vizarr,Minimal Zarr image viewer,"A lightweight viewer for Zarr images based on the Viv library, enabling quick visualization of OME-Zarr data.",D1;D1-02,visualization;bioimaging,platform,TypeScript,https://github.com/hms-dbmi/vizarr,,MIT,zarr;viewer;bioimaging;ome-zarr
343,ceramic,R tool for loading map tiles using GDAL,"An R package to obtain web map tiles directly as raster objects using GDAL, facilitating the integration of geospatial imagery into R workflows.",D1;D1-02,data_access;geospatial,library,R,https://github.com/hypertidy/ceramic,,None,gdal;geospatial;mapping;r
344,vcf-rs,Rust implementation of VCF parser,"A Rust library for parsing Variant Call Format (VCF) files, providing high-performance handling of genomic variation data.",D1;D1-02,parsing;genomics,library,Rust,https://github.com/informationsea/vcf-rs,,Apache-2.0,vcf;rust;bioinformatics;parser
345,POAP,Parallelized Open Babel & Autodock suite Pipeline,A pipeline tool that parallelizes ligand preparation (using Open Babel) and molecular docking (using Autodock suite) for virtual screening and drug discovery.,D1;D1-02,molecular_docking;virtual_screening,workflow,Shell,https://github.com/inpacdb/POAP,,GPL-3.0,molecular-docking;drug-discovery;pipeline;autodock
346,cellmap-segmentation-challenge,Workflows for CellMap segmentation challenge,"A collection of scripts and workflows from Janelia CellMap for training 2D/3D models, prediction, and post-processing of large-scale EM segmentation data.",D1;D1-02,segmentation;workflow,workflow,Python,https://github.com/janelia-cellmap/cellmap-segmentation-challenge,,BSD-3-Clause,segmentation;em;deep-learning;janelia
347,wasm-dicom-parser,WebAssembly DICOM parser,"A C-based DICOM parser compiled to WebAssembly, enabling high-performance parsing of medical images directly in web browsers.",D1;D1-02,parsing;webassembly,library,C,https://github.com/jodogne/wasm-dicom-parser,,AGPL-3.0,dicom;webassembly;parser;medical-imaging
348,pyroSAR,Framework for large-scale SAR satellite data processing,"A Python framework for processing Synthetic Aperture Radar (SAR) satellite data, providing workflows for data retrieval, organization, and processing using tools like SNAP and GAMMA.",D1;D1-02,remote_sensing;processing,framework,Python,https://github.com/johntruckenbrodt/pyroSAR,https://pyrosar.readthedocs.io,MIT,sar;remote-sensing;satellite;processing
349,thorsky,Astronomy time-and-sky calculation tools,"A Python package built on Astropy for astronomical calculations related to time and sky positions, useful for observational planning.",D1;D1-02,astronomy;calculation,library,Python,https://github.com/jrthorstensen/thorsky,,BSD-2-Clause,astronomy;astropy;observational-planning
350,dust_extinction,Astronomical dust extinction models,"A Python package that provides various models for interstellar dust extinction, used in astronomy to correct observations for dust effects.",D1;D1-02,modeling;correction,library,Python,https://github.com/karllark/dust_extinction,https://dust-extinction.readthedocs.io,BSD-3-Clause,astronomy;dust-extinction;modeling
351,pizzarr,Zarr array slicing for R,"An R library that provides functionality to slice and access Zarr arrays, enabling R users to work with this cloud-native scientific data format.",D1;D1-02,io;data_access,library,R,https://github.com/keller-mark/pizzarr,,NOASSERTION,zarr;r;io;array-slicing
352,fit,ANT+ FIT file parser for R,"An R package for parsing ANT+ FIT files, which are commonly used in sports science and health monitoring devices (e.g., Garmin).",D1;D1-02,parsing;sports_science,library,C++,https://github.com/kuperov/fit,,MIT,fit;ant+;r;sports-science
353,CuteVCF,Simple viewer for VCF files,"A C++ based viewer for Variant Call Format (VCF) files using htslib, providing a graphical interface to inspect genomic variants.",D1;D1-02,visualization;genomics,platform,C++,https://github.com/labsquare/CuteVCF,,GPL-3.0,vcf;viewer;bioinformatics;gui
354,3d-data-precrocessing,Preprocessing toolkit for 3D medical images (NIfTI/DICOM),"A Python library for 3D medical image preprocessing, supporting conversion between NIfTI and HDF5, DICOM to NIfTI conversion, and 3D patch extraction/ROI cropping.",D1;D1-02,image_preprocessing;format_conversion,library,Python,https://github.com/li-pengcheng/3d-data-precrocessing,,None,medical-imaging;nifti;dicom;preprocessing
355,mesh-data-synthesizer,Synthetic dataset generator from 3D meshes for ML,"A tool using Unreal Engine and Cesium to generate large synthetic datasets from 3D meshes, enabling machine learning tasks like Visual Place Recognition.",D1;D1-02,data_generation;simulation,solver,C++,https://github.com/lolleko/mesh-data-synthesizer,https://meshvpr.github.io,NOASSERTION,synthetic-data;3d-mesh;machine-learning;simulation
356,go-gdal,Go wrapper for the Geospatial Data Abstraction Library (GDAL),"A Go programming language wrapper for GDAL, providing access to geospatial data translation and processing capabilities for raster and vector formats.",D1;D1-02,data_io;format_conversion,library,Go,https://github.com/lukeroth/gdal,,MIT,gdal;geospatial;gis;go
357,zarrita.js,JavaScript toolkit for Zarr array storage,"A JavaScript toolkit for working with chunked, compressed, n-dimensional arrays in the Zarr format, enabling web-based scientific data visualization and processing.",D1;D1-02,data_io;web_visualization,library,TypeScript,https://github.com/manzt/zarrita.js,,MIT,zarr;javascript;web-science;array-storage
358,ncvue,Minimal GUI for viewing NetCDF files,"A Python-based GUI tool for quick visualization and inspection of NetCDF files, designed as a modern replacement for ncview.",D1;D1-02,visualization;data_inspection,solver,Python,https://github.com/mcuntz/ncvue,,NOASSERTION,netcdf;visualization;gui;climate-data
359,vcf-go,Variant Call Format (VCF) parser for Go,"A Go library for parsing Variant Call Format (VCF) files, used in bioinformatics for storing gene sequence variations.",D1;D1-02,data_io;genomics,library,Go,https://github.com/mendelics/vcf,,BSD-3-Clause,vcf;bioinformatics;genomics;go
360,openbabel-node,Node.js bindings for OpenBabel chemistry library,"Node.js bindings for OpenBabel, enabling chemical file format conversion and chemical data processing within JavaScript environments.",D1;D1-02,format_conversion;cheminformatics,library,C++,https://github.com/mohebifar/openbabel-node,,None,cheminformatics;openbabel;chemistry;node
361,vcf_parser,Simple VCF parser for Python,"A Python library for parsing VCF (Variant Call Format) files, providing a simple interface for accessing genomic variant data.",D1;D1-02,data_io;genomics,library,Python,https://github.com/moonso/vcf_parser,,MIT,vcf;bioinformatics;python;genomics
362,reducer,Astronomical data reduction and calibration tool,"A Python package for reducing and calibrating astronomical images (CCD/CMOS), handling bias, dark, and flat field corrections.",D1;D1-02,image_processing;calibration,library,Python,https://github.com/mwcraig/reducer,https://reducer.readthedocs.io/,BSD-3-Clause,astronomy;image-reduction;calibration;fits
363,harmony-netcdf-to-zarr,NASA Harmony service for NetCDF to Zarr conversion,"A service module for NASA's Harmony platform that transforms NetCDF4 files into Zarr format, facilitating cloud-native access to Earth observation data.",D1;D1-02,format_conversion;cloud_data,service,Python,https://github.com/nasa/harmony-netcdf-to-zarr,https://github.com/nasa/harmony,NOASSERTION,nasa;netcdf;zarr;earth-science
364,radbelt,Wrapper for AE-8/AP-8 Van Allen radiation belt models,"A Python wrapper for the AE-8 and AP-8 models of the Van Allen radiation belts, allowing calculation of trapped particle fluxes.",D1;D1-02,modeling;space_physics,library,Python,https://github.com/nasa/radbelt,,NOASSERTION,space-weather;radiation-belts;nasa;physics
365,stitchee,NetCDF4 file concatenation service,"A NASA Harmony service that concatenates multiple NetCDF4 data files along an existing dimension, useful for merging time-series or spatial data chunks.",D1;D1-02,data_processing;concatenation,service,Python,https://github.com/nasa/stitchee,,Apache-2.0,netcdf;nasa;data-processing;earth-science
366,node-gdal,Node.js bindings for GDAL,"Node.js bindings for the Geospatial Data Abstraction Library (GDAL), enabling reading and writing of raster and vector geospatial data formats in JavaScript applications.",D1;D1-02,data_io;format_conversion,library,C++,https://github.com/naturalatlas/node-gdal,,Apache-2.0,gdal;gis;node;geospatial
367,pygdal,Virtualenv-friendly GDAL Python bindings,"A packaging of the standard GDAL Python bindings designed to install easily into virtual environments via pip, solving common version matching issues.",D1;D1-02,data_io;environment_management,library,C++,https://github.com/nextgis/pygdal,,NOASSERTION,gdal;python;gis;bindings
368,nibabel,Neuroimaging file format access library,"A comprehensive Python library for reading and writing neuroimaging file formats, including NIfTI, GIFTI, MINC, and ANALYZE.",D1;D1-02,data_io;neuroimaging,library,Python,https://github.com/nipy/nibabel,https://nipy.org/nibabel/,NOASSERTION,neuroimaging;nifti;mri;medical-imaging
369,nitransforms,Geometric transformations for neuroimaging,"A library for applying and manipulating geometric transformations (affine, non-linear) on neuroimaging data, facilitating spatial normalization and alignment.",D1;D1-02,image_registration;spatial_transformation,library,Python,https://github.com/nipy/nitransforms,https://nitransforms.readthedocs.io/,MIT,neuroimaging;registration;transformation;mri
370,neuropythy,Neuroscience library for cortical surface analysis,"A Python library for neuroscience research, providing tools for cortical surface analysis, retinotopy, and integration with FreeSurfer and Human Connectome Project data.",D1;D1-02,neuroscience_analysis;cortical_mapping,library,Python,https://github.com/noahbenson/neuropythy,https://github.com/noahbenson/neuropythy/wiki,AGPL-3.0,neuroscience;cortex;retinotopy;freesurfer
371,ODDT,Open Drug Discovery Toolkit,"A modular and comprehensive toolkit for cheminformatics and drug discovery, providing unified interfaces for various toolkits (OpenBabel, RDKit) and implementing scoring functions for molecular docking.",D1;D1-02,drug_discovery;molecular_docking,library,Python,https://github.com/oddt/oddt,http://oddt.readthedocs.org,BSD-3-Clause,cheminformatics;drug-discovery;docking;molecular-modeling
372,go2com,DICOM file parser for Go,"A Go library for parsing DICOM files, enabling the reading and processing of medical imaging data within Go applications.",D1;D1-02,data_io;medical_imaging,library,Go,https://github.com/okieraised/go2com,,GPL-3.0,dicom;medical-imaging;go;parser
373,ome-zarr-models-py,OME-Zarr metadata models for Python,"A Python package for reading, writing, and validating OME-Zarr metadata models, supporting the Next Generation File Format (NGFF) for bioimaging.",D1;D1-02,metadata_management;validation,library,Python,https://github.com/ome-zarr-models/ome-zarr-models-py,,MIT,ome-zarr;bioimaging;metadata;ngff
374,napari-ome-zarr,Napari plugin for OME-Zarr images,A plugin for the napari image viewer that enables reading and visualization of OME-Zarr (NGFF) bioimaging data directly from local or remote sources.,D1;D1-02,visualization;plugin,library,Python,https://github.com/ome/napari-ome-zarr,,BSD-3-Clause,napari;ome-zarr;bioimaging;visualization
375,ome-zarr-py,Python implementation of OME-NGFF for bioimaging,A Python library implementing the OME-NGFF (Next Generation File Format) specification for storing and accessing bioimaging data in the cloud using Zarr.,D1;D1-02,data_io;cloud_storage,library,Python,https://github.com/ome/ome-zarr-py,https://ome-zarr.readthedocs.io/,NOASSERTION,bioimaging;ome-zarr;ngff;microscopy
376,dicom_parser,Python library for parsing and accessing DICOM medical imaging data,"A Python library designed to facilitate access to DICOM data, providing parsing capabilities for medical imaging files.",D1;D1-02,parsing;data_access,library,Python,https://github.com/open-dicom/dicom_parser,,MIT,dicom;medical-imaging;parsing
377,Open Babel,Chemical toolbox for converting and processing chemical data formats,"A chemical toolbox designed to speak the many languages of chemical data. It allows searching, converting, analyzing, and storing data from molecular modeling, chemistry, solid-state materials, biochemistry, or related areas.",D1;D1-02,format_conversion;molecular_modeling,library,C++,https://github.com/openbabel/openbabel,http://openbabel.org/,GPL-2.0,chemistry;cheminformatics;file-conversion;molecular-data
378,Open Data Cube Core,Framework for analysing continental scale Earth Observation data,Open Data Cube (ODC) is an open source geospatial data management and analysis software project that helps you harness the power of Satellite data. It provides a Python API for high-performance access and analysis of geospatial data.,D1;D1-02,data_management;geospatial_analysis,platform,Python,https://github.com/opendatacube/datacube-core,https://www.opendatacube.org/,Apache-2.0,earth-observation;geospatial;satellite-data;datacube
379,pangeo-forge-recipes,ETL framework for building analysis-ready cloud-optimized scientific datasets,"A Python library for building Pangeo Forge recipes, which are used to transform archival data into cloud-optimized formats (like Zarr) for scientific analysis.",D1;D1-02,etl;data_processing,workflow,Python,https://github.com/pangeo-forge/pangeo-forge-recipes,https://pangeo-forge.readthedocs.io/,Apache-2.0,geoscience;etl;zarr;pangeo
380,node-netcdf4,NodeJS addon to read and write NetCDF4 files,"A Node.js addon that provides bindings to the NetCDF C library, allowing reading and writing of NetCDF4 files, commonly used in atmospheric and oceanographic science.",D1;D1-02,io;parsing,library,C++,https://github.com/parro-it/netcdf4,,ISC,netcdf;nodejs;geoscience;io
381,PLIP,Protein-Ligand Interaction Profiler for PDB files,"A tool to analyze and visualize non-covalent protein-ligand interactions in PDB files. It detects interactions such as hydrogen bonds, hydrophobic contacts, and pi-stacking.",D1;D1-02,interaction_analysis;structural_biology,solver,Python,https://github.com/pharmai/plip,https://plip-tool.biotec.tu-dresden.de/,GPL-2.0,protein-ligand;bioinformatics;pdb;interaction-profiling
382,easy-fit,JavaScript library to parse FIT files,"A library to parse .FIT files (Flexible and Interoperable Data Transfer), commonly used in sports science and fitness tracking devices, directly in JavaScript.",D1;D1-02,parsing;data_processing,library,JavaScript,https://github.com/pierremtb/easy-fit,,NOASSERTION,fit-file;sports-science;parsing;javascript
383,radseq,Scripts for parsing and analyzing RAD-seq data,A collection of Python scripts designed for the parsing and analysis of Restriction site Associated DNA sequencing (RAD-seq) data.,D1;D1-02,genomics_analysis;parsing,library,Python,https://github.com/pimbongaerts/radseq,,None,rad-seq;genomics;bioinformatics;scripts
384,fitdecode,FIT file parsing and decoding library,"A Python library for parsing and decoding FIT (Flexible and Interoperable Data Transfer) files, used in sports science and device data logging.",D1;D1-02,parsing;decoding,library,Python,https://github.com/polyvertex/fitdecode,https://fitdecode.readthedocs.io/,MIT,fit-file;parsing;python;sports-data
385,simple-tiles,Library for generating map tiles from geospatial data,"A C library for generating map tiles from shapefiles and other geospatial data sources, useful for scientific visualization in GIS.",D1;D1-02,visualization;gis,library,C,https://github.com/propublica/simple-tiles,,MIT,gis;mapping;visualization;shapefile
386,pydicom-deid,Best effort anonymization for medical images,"A Python library for anonymizing DICOM medical images, essential for data privacy in medical research and dataset sharing.",D1;D1-02,anonymization;data_processing,library,Python,https://github.com/pydicom/deid,https://pydicom.github.io/deid/,MIT,dicom;anonymization;medical-imaging;privacy
387,pydicom,Standard Python library for DICOM medical image file IO,"A pure Python package for reading, modifying, and writing DICOM files. It is the de facto standard library for handling medical imaging data in Python.",D1;D1-02,io;parsing,library,Python,https://github.com/pydicom/pydicom,https://pydicom.github.io/,NOASSERTION,dicom;medical-imaging;io;python
388,pylibjpeg,Framework for decoding JPEG images in DICOM,"A Python framework for decoding JPEG images, specifically designed to support pydicom and the various JPEG transfer syntaxes used in medical imaging.",D1;D1-02,decoding;image_processing,library,Python,https://github.com/pydicom/pylibjpeg,https://github.com/pydicom/pylibjpeg,MIT,jpeg;dicom;decoding;medical-imaging
389,pylibjpeg-openjpeg,JPEG 2000 decoder plugin for pylibjpeg,"A plugin for pylibjpeg that provides JPEG 2000 (J2K, JP2, HTJ2K) decoding support using OpenJPEG, critical for handling compressed DICOM medical images.",D1;D1-02,decoding;image_processing,library,Python,https://github.com/pydicom/pylibjpeg-openjpeg,,NOASSERTION,jpeg2000;dicom;decoding;plugin
390,pynetdicom,Python implementation of the DICOM networking protocol,"A Python implementation of the DICOM networking protocol (Service Class User and Service Class Provider), allowing Python applications to communicate with medical imaging devices and PACS.",D1;D1-02,networking;data_transfer,library,Python,https://github.com/pydicom/pynetdicom,https://pydicom.github.io/pynetdicom/,MIT,dicom;networking;pacs;medical-imaging
391,pysam,Python library for reading and manipulating genomics data (SAM/BAM/VCF),"A Python module for reading, manipulating, and writing genomic data sets. It is a lightweight wrapper of the HTSlib C-API, supporting SAM, BAM, CRAM, VCF, and BCF formats.",D1;D1-02,io;genomics_processing,library,Cython,https://github.com/pysam-developers/pysam,https://pysam.readthedocs.io/,MIT,genomics;bioinformatics;sam;bam;vcf
392,feets,Feature extractor for time series data in astronomy,"A library for extracting features from time series data, primarily designed for astronomical light curves.",D1;D1-02,feature_extraction;time_series_analysis,library,Python,https://github.com/quatrope/feets,https://feets.readthedocs.io/,MIT,astronomy;time-series;feature-extraction;light-curves
393,rt-utils,Library for creating and manipulating DICOM RTStructs,"A minimal Python library to facilitate the creation and manipulation of DICOM RTStruct (Radiotherapy Structure Set) files, used in medical physics and radiation therapy.",D1;D1-02,data_manipulation;radiotherapy,library,Python,https://github.com/qurit/rt-utils,https://rt-utils.readthedocs.io/,MIT,dicom;rtstruct;radiotherapy;medical-physics
394,sf,Simple Features for R - Spatial data analysis,"An R package that provides support for simple features, a standardized way to encode spatial vector data. It allows for manipulation, analysis, and visualization of spatial data.",D1;D1-02,spatial_analysis;gis,library,R,https://github.com/r-spatial/sf,https://r-spatial.github.io/sf/,NOASSERTION,gis;spatial-analysis;r-stats;simple-features
395,RADTorch,Medical Imaging Machine Learning Framework,"A framework designed for medical imaging machine learning tasks, facilitating data loading, processing, and model training for radiology applications.",D1;D1-02,machine_learning;medical_imaging,framework,Python,https://github.com/radtorch/radtorch,,NOASSERTION,medical-imaging;machine-learning;radiology;pytorch
396,Rasters.jl,Raster data manipulation for Julia,"A Julia package for manipulating and analyzing raster data, supporting various file formats and geospatial operations.",D1;D1-02,raster_analysis;geospatial,library,Julia,https://github.com/rafaqz/Rasters.jl,https://rafaqz.github.io/Rasters.jl/,MIT,julia;raster;geospatial;gis
397,rasterio,Python library for reading and writing geospatial raster datasets,"Rasterio reads and writes geospatial raster datasets (like GeoTIFF) using GDAL, providing a Pythonic API for raster data processing.",D1;D1-02,io;geospatial_processing,library,Python,https://github.com/rasterio/rasterio,https://rasterio.readthedocs.io/,NOASSERTION,geospatial;raster;gdal;python
398,pydicom-seg,Library for DICOM-SEG medical segmentation file IO,"A Python package for reading and writing DICOM-SEG (Segmentation) objects, facilitating the handling of medical image segmentation results.",D1;D1-02,io;segmentation,library,Python,https://github.com/razorx89/pydicom-seg,,MIT,dicom;segmentation;medical-imaging;io
399,NIFTI-Reader-JS,JavaScript NIfTI file format reader,"A JavaScript library for reading NIfTI (Neuroimaging Informatics Technology Initiative) file formats, enabling web-based visualization and processing of neuroimaging data.",D1;D1-02,parsing;visualization,library,TypeScript,https://github.com/rii-mango/NIFTI-Reader-JS,,MIT,nifti;neuroimaging;javascript;parsing
400,segmentation-eval,Radiomics evaluation for liver cancer tumors from DICOM,"A tool to extract and evaluate radiomics features for liver cancer tumors using DICOM segmentation masks, integrating SimpleITK and PyRadiomics.",D1;D1-02,radiomics;evaluation,solver,Python,https://github.com/rmsandu/segmentation-eval,,NOASSERTION,radiomics;medical-imaging;liver-cancer;evaluation
401,clisops,"Library for subsetting, averaging and regridding climate simulation data","A python library for running data-reduction operations on climate simulation data (NetCDF), typically used in the ROOCS (Remote Operations On Climate Simulations) framework.",D1;D1-02,data_processing;subsetting,library,Python,https://github.com/roocs/clisops,https://clisops.readthedocs.io/,BSD-3-Clause,climate-science;netcdf;roocs
402,MODIStsp,Automated download and preprocessing of MODIS Land Products,"An R package that automates the creation of time series of rasters derived from MODIS Land Products data, performing download, mosaicking, reprojection and resizing.",D1;D1-02,data_acquisition;preprocessing,workflow,R,https://github.com/ropensci/MODIStsp,https://docs.ropensci.org/MODIStsp/,GPL-3.0,modis;remote-sensing;time-series
403,dcm2niix,Robust DICOM to NIfTI converter for medical imaging,"A popular tool to convert DICOM images from medical scanners (MRI, CT) to the NIfTI format used by scientific analysis tools like FSL, SPM, and AFNI.",D1;D1-02,format_conversion;medical_imaging,solver,C++,https://github.com/rordenlab/dcm2niix,https://www.nitrc.org/plugins/mwiki/index.php/dcm2nii:MainPage,NOASSERTION,dicom;nifti;neuroimaging
404,FitFileParser,Swift library for parsing Garmin FIT files,"A Swift package that provides functionality to parse FIT (Flexible and Interoperable Data Transfer) files, commonly used in sports science and physiological data logging.",D1;D1-02,data_parsing,library,Swift,https://github.com/roznet/FitFileParser,,MIT,fit-file;garmin;sports-science
405,terra,Spatial data analysis and manipulation in R,"A comprehensive R package for spatial data analysis, replacing the 'raster' package. It supports raster and vector data manipulation, including reading/writing various geospatial formats.",D1;D1-02,spatial_analysis;data_io,library,C++,https://github.com/rspatial/terra,https://rspatial.github.io/terra/,GPL-3.0,geospatial;raster;gis
406,rust-htslib,High-level Rust bindings for HTSlib,"Provides a high-level Rust API for reading and writing high-throughput sequencing data formats (BAM, BCF, VCF, etc.) via HTSlib.",D1;D1-02,data_io;bioinformatics_core,library,Rust,https://github.com/rust-bio/rust-htslib,https://docs.rs/rust-htslib,MIT,bioinformatics;bam;vcf
407,htslib,C library for high-throughput sequencing data formats,"The core C library for parsing and manipulating high-throughput sequencing data formats such as SAM, BAM, CRAM, and VCF. It is the foundation for samtools and bcftools.",D1;D1-02,data_io;format_parsing,library,C,https://github.com/samtools/htslib,http://www.htslib.org/,NOASSERTION,bioinformatics;ngs;sam
408,samtools,Utilities for manipulating NGS data (SAM/BAM/CRAM),"A suite of programs for interacting with high-throughput sequencing data. It provides tools for converting, sorting, indexing, and viewing data in SAM/BAM/CRAM formats.",D1;D1-02,data_processing;format_conversion,solver,C,https://github.com/samtools/samtools,http://www.htslib.org/,NOASSERTION,bioinformatics;ngs;alignment
409,mo_netcdf,Modern Fortran wrapper for NetCDF,"A library providing an object-oriented, modern Fortran interface to the NetCDF C library, simplifying IO operations in climate and weather models.",D1;D1-02,data_io,library,Fortran,https://github.com/schaefed/mo_netcdf,,None,fortran;netcdf;climate-modeling
410,zarr-rust,Rust implementation of the Zarr storage format,"A pure Rust implementation of the Zarr V3 specification, enabling high-performance N-dimensional array storage and retrieval, critical for cloud-native scientific data.",D1;D1-02,data_io;storage,library,Rust,https://github.com/sci-rs/zarr,https://docs.rs/zarrs/,Apache-2.0,zarr;rust;cloud-native
411,scippnexus,NeXus file handling with Scipp integration,A Python library that provides an h5py-like interface for reading NeXus files (common in neutron/X-ray scattering) directly into Scipp data structures.,D1;D1-02,data_io;format_parsing,library,Python,https://github.com/scipp/scippnexus,https://scipp.github.io/scippnexus/,BSD-3-Clause,nexus;neutron-scattering;scipp
412,astrolibpy,Python port of IDL astronomy library,"A collection of astronomical utility codes ported from the classic IDL astrolib, providing various calculations and data handling functions for astronomers.",D1;D1-02,data_analysis;utility,library,Python,https://github.com/segasai/astrolibpy,,GPL-3.0,astronomy;idl;utility
413,SeqAn,C++ template library for sequence analysis,"A high-performance C++ library for the analysis of biological sequences, providing algorithms and data structures for string matching, alignment, and IO.",D1;D1-02,sequence_analysis;data_io,library,C++,https://github.com/seqan/seqan,http://www.seqan.de,NOASSERTION,bioinformatics;sequence-alignment;cpp
414,bio2zarr,Converter for bioinformatics formats to Zarr,"A tool to convert standard bioinformatics file formats (like VCF and PLINK) into Zarr archives, facilitating cloud-based analysis and efficient storage.",D1;D1-02,format_conversion,solver,Python,https://github.com/sgkit-dev/bio2zarr,,Apache-2.0,bioinformatics;zarr;vcf
415,h5grove,Utilities for serving HDF5 file content,"A Python package providing utilities to design backends for serving HDF5 file content (attributes, metadata, data) efficiently, often used for web-based visualization.",D1;D1-02,data_service;visualization_backend,library,Python,https://github.com/silx-kit/h5grove,https://silx-kit.github.io/h5grove/,MIT,hdf5;web-service;visualization
416,hdf5plugin,HDF5 compression filters for h5py,"Provides a set of HDF5 compression filters (Blosc, LZ4, Zstandard, etc.) for use with h5py, enabling reading and writing of compressed HDF5 data.",D1;D1-02,data_compression;data_io,library,C,https://github.com/silx-kit/hdf5plugin,http://www.silx.org/doc/hdf5plugin/latest/,NOASSERTION,hdf5;compression;h5py
417,rust-fitsio,Rust bindings for CFITSIO,"A Rust library providing a wrapper around the CFITSIO C library, allowing Rust programs to read and write FITS files used in astronomy.",D1;D1-02,data_io,library,C,https://github.com/simonrw/rust-fitsio,https://docs.rs/fitsio,Apache-2.0,astronomy;fits;rust
418,garmin_wrapped,Analysis and visualization scripts for Garmin FIT data,"A collection of scripts to parse, analyze, and visualize running data from Garmin .fit and .txt files, enabling fine-grained performance analysis.",D1;D1-02,data_analysis;visualization,workflow,Python,https://github.com/sivaprakasaman/garmin_wrapped,,GPL-3.0,fit-file;sports-analytics;visualization
419,astroimtools,Astronomical image convenience tools,"A Python package providing convenience tools for processing astronomical images, including cutouts and simple arithmetic, developed by STScI.",D1;D1-02,image_processing,library,Python,https://github.com/spacetelescope/astroimtools,https://astroimtools.readthedocs.io/,BSD-3-Clause,astronomy;image-processing;stsci
420,gwcs,Generalized World Coordinate System,"A library for managing the Generalized World Coordinate System (GWCS), providing a flexible way to map pixel coordinates to world coordinates in astronomy.",D1;D1-02,coordinate_transformation,library,Python,https://github.com/spacetelescope/gwcs,https://gwcs.readthedocs.io/,None,astronomy;wcs;coordinates
421,imexam,Interactive image examination and plotting,"A Python tool for simple interactive image examination and plotting, providing functionality similar to IRAF's imexamine task.",D1;D1-02,image_analysis;visualization,library,Python,https://github.com/spacetelescope/imexam,https://imexam.readthedocs.io/,BSD-3-Clause,astronomy;visualization;iraf
422,jwql,James Webb Space Telescope Quicklook Application,"A software suite for monitoring the health and stability of the JWST instruments and data products, providing quicklook visualization and analysis.",D1;D1-02,quality_control;data_visualization,platform,Python,https://github.com/spacetelescope/jwql,https://jwql.readthedocs.io/,BSD-3-Clause,jwst;astronomy;quality-control
423,stsynphot,Synthetic photometry for HST and JWST,An extension of synphot providing synthetic photometry utilities specifically for Hubble Space Telescope (HST) and James Webb Space Telescope (JWST).,D1;D1-02,simulation;photometry,library,Python,https://github.com/spacetelescope/stsynphot_refactor,https://stsynphot.readthedocs.io/,BSD-3-Clause,astronomy;photometry;hst
424,synphot,Synthetic photometry using Astropy,"A general-purpose package for synthetic photometry in astronomy, allowing users to simulate observations and calculate photometric properties.",D1;D1-02,simulation;photometry,library,Python,https://github.com/spacetelescope/synphot_refactor,https://synphot.readthedocs.io/,BSD-3-Clause,astronomy;photometry;simulation
425,JGribX,Java GRIB-1/GRIB-2 decoder,"A Java library for decoding GRIB-1 and GRIB-2 files, which are standard formats for meteorological data.",D1;D1-02,data_parsing,library,Java,https://github.com/spidru/JGribX,,MIT,meteorology;grib;java
426,fitparse-rs,Rust library to parse FIT formatted files,"A Rust library for parsing FIT (Flexible and Interoperable Data Transfer) files, providing access to data records and definitions.",D1;D1-02,data_parsing,library,Rust,https://github.com/stadelmanma/fitparse-rs,https://docs.rs/fitparse,MIT,fit-file;rust;parser
427,Optika,Python library for simulating and designing optical systems,"A Python library for simulating optical systems, offering functionality similar to Zemax for ray tracing and optical design analysis.",D1;D1-02,simulation;optical_design,library,Python,https://github.com/sun-data/optika,,None,optics;simulation;ray-tracing
428,ndcube,Library for handling multi-dimensional coordinate-aware arrays in solar physics,"A base package for multi-dimensional contiguous and non-contiguous coordinate-aware arrays, primarily designed for solar physics data analysis.",D1;D1-02,data_processing;coordinate_handling,library,Python,https://github.com/sunpy/ndcube,https://docs.sunpy.org/projects/ndcube/,BSD-2-Clause,solar-physics;coordinates;data-cubes
429,SunPy,Core library for Solar Physics data analysis,"An open-source software library for solar physics data analysis, providing tools for querying, downloading, and analyzing solar data.",D1;D1-02,data_analysis;data_acquisition,library,Python,https://github.com/sunpy/sunpy,https://sunpy.org/,BSD-2-Clause,solar-physics;astronomy;data-analysis
430,sunraster,Tools to analyze solar spectral data,A SunPy-affiliated package providing tools to analyze spectral data from various solar missions.,D1;D1-02,data_analysis;spectroscopy,library,Python,https://github.com/sunpy/sunraster,,BSD-2-Clause,solar-physics;spectroscopy;raster-data
431,dicom (Go),High-performance DICOM medical image parser in Go,A high-performance library written in Go for parsing and processing DICOM medical image files.,D1;D1-02,data_parsing;medical_imaging,library,Go,https://github.com/suyashkumar/dicom,,MIT,dicom;medical-imaging;go
432,AGStoShapefile,Tool to convert ArcGIS Server Map Services to GeoJSON/Shapefile,A utility to query ArcGIS Server Dynamic Map Services and convert the output into standard geospatial formats like GeoJSON and Shapefile.,D1;D1-02,format_conversion;data_acquisition,solver,JavaScript,https://github.com/tannerjt/AGStoShapefile,,MIT,gis;arcgis;geojson;shapefile
433,gdal2tiles,Library for generating map tiles from GDAL-supported rasters,"A Python library for generating map tiles (TMS) based on the gdal2tiles.py utility from the GDAL project, facilitating geospatial data visualization.",D1;D1-02,data_processing;visualization_prep,library,Python,https://github.com/tehamalab/gdal2tiles,,MIT,gdal;gis;map-tiles
434,scipdf_parser,Parser for extracting content and figures from scientific PDF publications,"A Python tool to parse scientific PDF articles, extracting metadata, text content, and figures, useful for scientific text mining and analysis.",D1;D1-02,data_mining;text_extraction,library,Python,https://github.com/titipata/scipdf_parser,,MIT,pdf-parsing;scientific-literature;nlp
435,Argos,"GUI viewer for HDF5, NetCDF4, and other scientific data formats","A data viewer application capable of reading and inspecting HDF5, NetCDF4, and other common scientific file formats.",D1;D1-02,visualization;data_inspection,solver,Python,https://github.com/titusjan/argos,,GPL-3.0,hdf5;netcdf;data-viewer
436,nii2dcm,Tool for converting NIfTI medical images to DICOM format,A Python tool designed to convert NIfTI (Neuroimaging Informatics Technology Initiative) files into DICOM series.,D1;D1-02,format_conversion;medical_imaging,solver,Python,https://github.com/tomaroberts/nii2dcm,,NOASSERTION,nifti;dicom;medical-imaging
437,bio-vcf,DSL and parser for filtering and processing VCF files,"A smart parser and Domain Specific Language (DSL) for processing, filtering, and rewriting VCF (Variant Call Format) files in bioinformatics.",D1;D1-02,data_processing;variant_filtering,solver,Ruby,https://github.com/vcflib/bio-vcf,,MIT,vcf;bioinformatics;dsl
438,virtual-tiff,Tool to create virtual Zarr stores from TIFF files,"A utility to produce and explore virtual Zarr stores backed by TIFF files, enabling cloud-optimized access patterns without data duplication.",D1;D1-02,data_io;format_interoperability,library,Python,https://github.com/virtual-zarr/virtual-tiff,,MIT,zarr;tiff;cloud-native
439,Vitessce,Visual integration tool for spatial single-cell experiments,"A visual integration tool for exploration of spatial single-cell experiment data, supporting various bio-imaging formats.",D1;D1-02,visualization;single_cell_analysis,solver,JavaScript,https://github.com/vitessce/vitessce,http://vitessce.io/,MIT,single-cell;visualization;spatial-biology
440,SeqLib,C++ interface for querying and manipulating sequence data,"A C++ library providing an interface to htslib, bwa-mem, and fermi for efficient interrogation and manipulation of sequencing data (BAM/CRAM/FASTQ).",D1;D1-02,data_analysis;sequence_alignment,library,C++,https://github.com/walaj/SeqLib,,NOASSERTION,bioinformatics;htslib;sequencing
441,ogr2ogr-wrapper,Wrapper library for the ogr2ogr geospatial conversion tool,"A TypeScript/JavaScript wrapper around the ogr2ogr command-line tool, facilitating geospatial data format conversion within Node.js applications.",D1;D1-02,format_conversion;geospatial_processing,library,TypeScript,https://github.com/wavded/ogr2ogr,,MIT,gis;gdal;ogr2ogr
442,pydl,Library of IDL astronomy routines converted to Python,"A Python library implementing common astronomy routines originally written in IDL, facilitating migration and data analysis in Python.",D1;D1-02,data_analysis;migration_tools,library,Python,https://github.com/weaverba137/pydl,http://pydl.readthedocs.org/,BSD-3-Clause,astronomy;idl;python
443,zen3geo,Library for geospatial data IO and processing,A Python library designed to simplify geospatial data input/output and processing tasks.,D1;D1-02,data_io;geospatial_processing,library,Python,https://github.com/weiji14/zen3geo,,LGPL-3.0,geospatial;gis;data-science
444,wradlib,Library for weather radar data processing,"A Python library designed for processing weather radar data, including reading, correcting, and visualizing radar data formats.",D1;D1-02,data_processing;meteorology,library,Python,https://github.com/wradlib/wradlib,https://wradlib.org/,NOASSERTION,weather-radar;meteorology;remote-sensing
445,xcube,Toolkit for generating and exploiting Earth observation data cubes,"A Python package for generating, manipulating, and analyzing data cubes from Earth observation data, leveraging xarray, dask, and zarr.",D1;D1-02,data_generation;data_analysis,library,Python,https://github.com/xcube-dev/xcube,https://xcube.readthedocs.io/,MIT,earth-observation;data-cubes;xarray
446,xtensor-zarr,C++ implementation of the Zarr core protocol,"A C++ library implementing the Zarr core protocol (v2 and v3) based on the xtensor library, enabling efficient multidimensional array storage.",D1;D1-02,data_io;storage,library,C++,https://github.com/xtensor-stack/xtensor-zarr,,BSD-3-Clause,zarr;c++;xtensor
447,ArchGDAL.jl,High-level Julia API for GDAL,A Julia package providing a high-level interface to the GDAL (Geospatial Data Abstraction Library) for reading and writing geospatial data formats.,D1;D1-02,data_io;geospatial_processing,library,Julia,https://github.com/yeesian/ArchGDAL.jl,https://yeesian.com/ArchGDAL.jl/,NOASSERTION,julia;gdal;gis
448,OvertureMapsDownloader,Tool for downloading and processing Overture Maps data,"A tool that simplifies the acquisition and manipulation of geospatial data from Overture Maps using DuckDB, Dask, and GDAL.",D1;D1-02,data_acquisition;geospatial_processing,solver,Python,https://github.com/yharby/OvertureMapsDownloader,,NOASSERTION,gis;overture-maps;data-download
449,VirtualiZarr,Tool to cloud-optimize scientific data as Virtual Zarr stores,"A Python library to create virtual Zarr stores from existing data files, enabling cloud-optimized access via xarray syntax without data duplication.",D1;D1-02,data_optimization;data_io,library,Python,https://github.com/zarr-developers/VirtualiZarr,,Apache-2.0,zarr;cloud-native;xarray
450,pydantic-zarr,Pydantic models for Zarr data structures,A Python library providing Pydantic models for validating and defining Zarr data structures and metadata.,D1;D1-02,data_validation;metadata_management,library,Python,https://github.com/zarr-developers/pydantic-zarr,,BSD-3-Clause,zarr;pydantic;validation
451,zarr-java,Java implementation of the Zarr Specification for N-dimensional arrays,"A Java library providing an implementation of the Zarr specification, enabling storage and retrieval of chunked, compressed, N-dimensional arrays. It serves as a core IO library for Java-based scientific applications requiring Zarr format support.",D1;D1-02,data_io;format_parsing,library,Java,https://github.com/zarr-developers/zarr-java,https://github.com/zarr-developers/zarr-java,MIT,zarr;java;multidimensional-arrays;data-storage
452,zarr-python,"Reference Python implementation of chunked, compressed, N-dimensional arrays","The official Python implementation of the Zarr format, providing an interface for chunked, compressed, N-dimensional arrays. It is widely used in genomics, bioimaging, and geospatial sciences for handling large-scale scientific datasets.",D1;D1-02,data_io;array_manipulation,library,Python,https://github.com/zarr-developers/zarr-python,https://zarr.readthedocs.io/,MIT,zarr;python;numpy;scientific-data;io
453,zarrs,Rust library for the Zarr storage format,"A high-performance Rust library for creating, reading, and manipulating Zarr V3 and V2 data. It provides core IO capabilities for multidimensional arrays and metadata in the Rust ecosystem.",D1;D1-02,data_io;format_parsing,library,Rust,https://github.com/zarrs/zarrs,https://docs.rs/zarrs/,Apache-2.0,rust;zarr;data-storage;multidimensional-arrays
454,zarrs-python,Python bindings for the zarrs Rust crate,"Provides a high-performance CodecPipeline for zarr-python, backed by the zarrs Rust library. It accelerates Zarr data processing in Python environments by leveraging Rust's performance.",D1;D1-02,data_io;performance_optimization,library,Python,https://github.com/zarrs/zarrs-python,https://github.com/zarrs/zarrs-python,MIT,python;rust;zarr;optimization
455,ZnH5MD,High Performance Interface for H5MD Trajectories,A Python interface designed for high-performance reading and writing of H5MD (HDF5 for Molecular Dynamics) files. It facilitates the handling of large-scale molecular dynamics trajectory data.,D1;D1-02,data_io;trajectory_analysis,library,Python,https://github.com/zincware/ZnH5MD,https://znh5md.readthedocs.io/,Apache-2.0,molecular-dynamics;hdf5;h5md;trajectory
456,zarr-ml,OCaml implementation of the Zarr storage format,"An OCaml library implementing the Zarr specification for chunked and compressed multidimensional arrays, enabling scientific data IO in the OCaml ecosystem.",D1;D1-02,data_io;format_parsing,library,OCaml,https://github.com/zoj613/zarr-ml,https://zoj613.github.io/zarr-ml/,BSD-3-Clause,ocaml;zarr;data-storage;io
457,MungeSumstats,Rapid standardisation and quality control of GWAS or QTL summary statistics,"A Bioconductor package designed to facilitate the standardization and quality control of Genome-Wide Association Study (GWAS) summary statistics. It handles formatting, filtering, and correcting inconsistencies to ensure data integrity for downstream analysis.",D1;D1-03,quality_control;standardization;gwas_analysis,library,R,https://github.com/Al-Murphy/MungeSumstats,,None,gwas;bioinformatics;quality-control;statistics
458,SOAPnuke,Integrated Quality Control and Preprocessing tool for FASTQ or BAM/CRAM sequencing data,"A software tool developed by BGI for integrated quality control and preprocessing of high-throughput sequencing data. It supports filtering low-quality reads, trimming adapters, and generating statistics for FASTQ, BAM, and CRAM files.",D1;D1-03,quality_control;preprocessing;filtering,solver,C++,https://github.com/BGI-flexlab/SOAPnuke,,GPL-3.0,bioinformatics;ngs;quality-control;fastq
459,SQANTI3,Tool for the Quality Control of Long-Read Defined Transcriptomes,"A pipeline for the structural classification and quality control of isoforms defined by long-read sequencing technologies (PacBio, Oxford Nanopore). It characterizes transcripts based on their splice junctions and compares them to a reference annotation.",D1;D1-03,quality_control;isoform_classification;transcriptomics,solver,Python,https://github.com/ConesaLab/SQANTI3,,GPL-3.0,transcriptomics;long-read-sequencing;quality-control;isoforms
460,blobtools,"Modular command-line solution for visualisation, quality control and taxonomic partitioning of genome datasets","A toolset for the visualization, quality control, and taxonomic partitioning of genome assemblies. It allows researchers to identify contamination and assess the quality of genomic datasets using GC content, coverage, and taxonomy.",D1;D1-03,quality_control;visualization;taxonomic_partitioning,solver,Python,https://github.com/DRL/blobtools,,GPL-3.0,genomics;visualization;quality-control;taxonomy
461,CheckM,"Assess the quality of microbial genomes recovered from isolates, single cells, and metagenomes","A tool for assessing the quality of microbial genomes recovered from isolates, single cells, and metagenomes. It provides robust estimates of genome completeness and contamination by using collocated sets of genes that are ubiquitous and single-copy within a phylogenetic lineage.",D1;D1-03,quality_assessment;genome_recovery;metagenomics,solver,Python,https://github.com/Ecogenomics/CheckM,,GPL-3.0,microbiology;genomics;quality-assessment;metagenomics
462,TrimGalore,A wrapper around Cutadapt and FastQC for consistent adapter and quality trimming of FastQ files,"Trim Galore is a wrapper script to automate quality and adapter trimming as well as quality control, with some added functionality to remove Galore-specific RRBS sequence diversity bias when processing RRBS libraries.",D1;D1-03,quality_control;adapter_trimming;preprocessing,workflow,Perl,https://github.com/FelixKrueger/TrimGalore,https://github.com/FelixKrueger/TrimGalore/blob/master/Docs/Trim_Galore_User_Guide.md,GPL-3.0,bioinformatics;fastq;quality-control;ngs
463,dropSeqPipe,A Snakemake workflow for SingleCell RNASeq pre-processing,"dropSeqPipe is a comprehensive pipeline for processing Drop-Seq data, handling steps from raw reads to expression matrices, including quality control and alignment.",D1;D1-01,preprocessing;quality_control;alignment,workflow,Python,https://github.com/Hoohm/dropSeqPipe,https://github.com/Hoohm/dropSeqPipe,CC-BY-SA-4.0,bioinformatics;rnaseq;single-cell;snakemake
464,kgcl,Data model library for the Knowledge Graph Change Language (KGCL),"Provides the data model and implementation for KGCL, a language designed for defining and executing changes in ontologies and knowledge graphs, widely used in biomedical informatics.",D1;D1-03,ontology_management;data_modeling,library,Python,https://github.com/INCATools/kgcl,https://github.com/INCATools/kgcl,MIT,ontology;knowledge-graph;bioinformatics;metadata
465,kgcl-rdflib,RDFLib-based tools for manipulating ontologies using KGCL,"A Python library that provides functionality to apply Knowledge Graph Change Language (KGCL) operations on RDF graphs using RDFLib, facilitating ontology curation and evolution.",D1;D1-03,ontology_manipulation;graph_processing,library,Python,https://github.com/INCATools/kgcl-rdflib,https://github.com/INCATools/kgcl-rdflib,MIT,rdflib;ontology;kgcl;bioinformatics
466,semantic-sql,Library to create SQL and SQLite builds from OWL ontologies,"A tool designed to convert OWL ontologies into SQL/SQLite formats, enabling efficient querying and integration of semantic data within relational database systems, commonly used in biomedical ontology pipelines.",D1;D1-03,format_conversion;ontology_querying,library,Python,https://github.com/INCATools/semantic-sql,https://github.com/INCATools/semantic-sql,BSD-3-Clause,ontology;sql;owl;bioinformatics
467,bombcell,Automated quality control and curation tool for spike-sorted electrophysiology data,"A toolbox for automated quality control and curation of spike-sorted data, allowing researchers to classify neurons and assess recording quality in electrophysiology experiments.",D1;D1-03,quality_control;spike_sorting_curation;classification,solver,MATLAB,https://github.com/Julie-Fabre/bombcell,https://github.com/Julie-Fabre/bombcell/wiki,GPL-3.0,neuroscience;electrophysiology;quality-control;spike-sorting
468,MegaQC,Longitudinal quality control monitoring platform for MultiQC reports,"MegaQC is a web application designed to aggregate, store, and visualize data from multiple MultiQC runs over time. It enables sequencing facilities and bioinformatics cores to track quality metrics across projects and monitor trends in sequencing performance.",D1;D1-03;Bioinformatics,quality_control;qc_reporting;longitudinal_analysis,platform,Python,https://github.com/MultiQC/MegaQC,https://megaqc.info/,GPL-3.0,bioinformatics;quality-control;visualization;dashboard
469,MultiQC,Aggregate bioinformatics analysis reports across many samples,"MultiQC searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarizing the output from numerous bioinformatics tools.",D1;D1-03;Bioinformatics,quality_control;qc_reporting;data_aggregation,solver,Python,https://github.com/MultiQC/MultiQC,https://multiqc.info/,GPL-3.0,bioinformatics;ngs;quality-control;reporting
470,MultiQC_SAV,MultiQC plugin for Illumina Sequencing Analysis Viewer (SAV) data,"A plugin for MultiQC that parses and visualizes InterOp data from Illumina sequencers, replicating plots found in the Illumina Sequencing Analysis Viewer (SAV) for quality control purposes.",D1;D1-03;Bioinformatics,quality_control;sequencing_qc,solver,Python,https://github.com/MultiQC/MultiQC_SAV,https://github.com/MultiQC/MultiQC_SAV,MIT,illumina;sequencing;quality-control;multiqc-plugin
471,MultiQC_bcbio,MultiQC plugin for bcbio-nextgen pipeline metrics,A plugin for MultiQC that incorporates metrics and logs specifically generated by the bcbio-nextgen bioinformatics analysis pipeline into the aggregate QC report.,D1;D1-03;Bioinformatics,quality_control;pipeline_reporting,solver,Python,https://github.com/MultiQC/MultiQC_bcbio,https://github.com/MultiQC/MultiQC_bcbio,MIT,bcbio;bioinformatics;quality-control;multiqc-plugin
472,AfterQC,"Automatic filtering, trimming, error removing and quality control for FASTQ data","AfterQC is a tool for automatic quality control of NGS data. It performs filtering, trimming, error correction, and quality visualization for FASTQ files, designed to be faster and more automated than traditional tools.",D1;D1-03;Bioinformatics,quality_control;read_trimming;error_correction,solver,Python,https://github.com/OpenGene/AfterQC,https://github.com/OpenGene/AfterQC,MIT,fastq;ngs;quality-control;trimming
473,fastplong,Ultra-fast preprocessing and quality control for long-read sequencing data,"fastplong is a high-performance tool designed for the preprocessing and quality control of long-read sequencing data (e.g., Nanopore, PacBio). It offers functions for filtering, trimming, and generating QC statistics.",D1;D1-03;Bioinformatics,quality_control;read_preprocessing;long_read_sequencing,solver,C++,https://github.com/OpenGene/fastplong,https://github.com/OpenGene/fastplong,MIT,long-read;nanopore;pacbio;quality-control
474,rnaseq-pipeline,RNA-seq pipeline for raw sequence alignment and quantification,"A bioinformatics pipeline for processing RNA-seq data, handling steps from raw sequence alignment to transcript and gene quantification. Developed by the Pavlidis Lab.",D1;Bioinformatics,workflow;alignment;quantification,workflow,Python,https://github.com/PavlidisLab/rnaseq-pipeline,https://github.com/PavlidisLab/rnaseq-pipeline,Unlicense,rna-seq;bioinformatics;pipeline;quantification
475,Qoala-T,Supervised-learning tool for quality control of FreeSurfer segmented MRI data,Qoala-T is a supervised learning tool designed to assess the quality of FreeSurfer-segmented MRI data. It helps in automatically identifying poor quality segmentations in neuroimaging datasets.,D1;D1-03;Neuroscience,quality_control;image_segmentation_qc;neuroimaging,solver,R,https://github.com/Qoala-T/QC,https://qoala-t.shinyapps.io/qoala-t_app/,NOASSERTION,mri;freesurfer;quality-control;neuroscience
476,Schematic,Biomedical data model and metadata management ingress tool,"A package developed by Sage Bionetworks for managing biomedical data models and metadata ingress. It facilitates the validation and submission of data according to defined schemas, supporting data curation workflows in biomedical research.",D1;D1-03,metadata_management;schema_validation;data_curation,library,Python,https://github.com/Sage-Bionetworks/schematic,https://schematic.readthedocs.io/,MIT,biomedical;metadata;schema;validation;data-model
477,Ketupa,Deep learning framework for RF signal integrity analysis and simulation,"A deep learning project applied to signal integrity and RF analysis. It automates modeling, simulation, and data storage of HFSS for patch antennas, transmission lines, vias, and connectors, training S-parameter models on simulation data.",Physics;Engineering,simulation;modeling;rf_analysis,solver,Python,https://github.com/Shallot-2009/Ketupa,,BSD-2-Clause,deep-learning;rf-engineering;electromagnetics;simulation
478,3D-MedDiffusion,3D medical diffusion model for controllable image generation,A 3D Medical Diffusion Model designed for controllable and high-quality medical image generation. It addresses the challenges of generating realistic 3D volumetric medical data for research and analysis.,Medical Imaging;AI4S,image_generation;generative_modeling,solver,Python,https://github.com/ShanghaiTech-IMPACT/3D-MedDiffusion,,None,medical-imaging;diffusion-models;3d-generation;deep-learning
479,Cerberus,Visual-Inertial-Leg Odometry (VILO) for legged robots,"A state estimation framework for legged robots that fuses visual, inertial, and leg kinematics data to provide precise odometry. It is used in robotics research for localization and mapping.",Robotics;Control Systems,odometry;state_estimation;localization,solver,C++,https://github.com/ShuoYangRobotics/Cerberus,,GPL-3.0,robotics;odometry;slam;visual-inertial
480,Cerberus2.0,Low-drift Visual-Inertial-Leg Odometry for legged robots,"The second version of the Cerberus VILO framework, offering improved precision and low-drift performance for state estimation in legged robotics research.",Robotics;Control Systems,odometry;state_estimation;localization,solver,C++,https://github.com/ShuoYangRobotics/Cerberus2.0,,AGPL-3.0,robotics;odometry;slam;visual-inertial
481,Cerberus (Histology),Multi-task learning model for histology image segmentation and classification,A deep learning model that enables simultaneous histology image segmentation and classification. It uses multi-task learning to improve performance on pathology image analysis tasks.,Bioinformatics;Medical Imaging,image_segmentation;classification;histology_analysis,solver,Python,https://github.com/TissueImageAnalytics/cerberus,,GPL-3.0,histology;pathology;deep-learning;segmentation
482,Crowd-Kit,Quality control and aggregation for crowdsourced data labeling,"A Python library for computational quality control and aggregation of crowdsourced data. It provides efficient implementations of aggregation algorithms (like Dawid-Skene, GLAD) to ensure high-quality labeled datasets for machine learning research.",D1;D1-03;Machine Learning,quality_control;data_aggregation;annotation_processing,library,Python,https://github.com/Toloka/crowd-kit,https://crowd-kit.readthedocs.io/,Apache-2.0,crowdsourcing;data-labeling;quality-control;aggregation
483,FluLINE,Comprehensive pipeline for influenza virus sequencing analysis,"A bioinformatics pipeline for analyzing influenza sequencing data. It performs filtering, species identification, consensus genome generation, mapping, and SNV identification.",Bioinformatics;Genomics,pipeline;variant_calling;genome_assembly,workflow,Python,https://github.com/UmaSangumathi/FluLINE,,None,influenza;ngs;pipeline;genomics
484,openclean,Data cleaning and profiling library for scientific data workflows,"A Python library for data cleaning and profiling, developed by VIDA-NYU. It provides a declarative framework for detecting and fixing data quality issues, suitable for preparing scientific datasets.",D1;D1-03,data_cleaning;data_profiling;quality_control,library,Python,https://github.com/VIDA-NYU/openclean,https://github.com/VIDA-NYU/openclean/tree/master/docs,BSD-3-Clause,data-cleaning;profiling;quality-control;python
485,ModelDB,Open source ML model versioning and metadata management,"A system for managing machine learning models, including versioning, metadata, and experiment tracking. Originally developed at MIT CSAIL, it supports scientific reproducibility in ML workflows.",D1;Machine Learning,experiment_tracking;metadata_management;reproducibility,platform,Java,https://github.com/VertaAI/modeldb,https://modeldb.ai/,Apache-2.0,mlops;metadata;experiment-tracking;reproducibility
486,cfDNApipe,Quality control and analysis pipeline for cell-free DNA sequencing data,A comprehensive pipeline for the quality control and analysis of cell-free DNA (cfDNA) high-throughput sequencing data. It handles tasks specific to liquid biopsy data analysis.,Bioinformatics;Genomics,pipeline;quality_control;data_analysis,workflow,Python,https://github.com/XWangLabTHU/cfDNApipe,,NOASSERTION,cfdna;ngs;pipeline;quality-control
487,QuickNAT,Fast brain MRI segmentation framework with uncertainty-based quality control,A PyTorch implementation of QuickNAT and Bayesian QuickNAT for fast and accurate segmentation of neuroanatomy from brain MRI scans. It features a structure-wise uncertainty estimation mechanism that serves as a quality control measure for the segmentation results.,D3;D1-03,segmentation;quality_control,solver,Python,https://github.com/ai-med/quickNAT_pytorch,,MIT,mri;neuroimaging;segmentation;quality-control;uncertainty-estimation
488,AGR Curation Schema,Data schema and validation specifications for the Alliance of Genome Resources,"The official schema repository for the Alliance of Genome Resources (AGR), defining the data models and validation rules for persistent data storage and curation of genomic data across multiple model organisms.",D1-03,schema_definition;data_validation,library,Makefile,https://github.com/alliance-genome/agr_curation_schema,https://www.alliancegenome.org/,MIT,genomics;schema;data-curation;model-organisms
489,faster,High-performance FASTQ file statistics and quality metrics calculator,"A fast, Rust-based command-line tool for calculating statistics and quality metrics from FASTQ files, designed to provide rapid insights into sequencing data quality.",D1-03,quality_control;statistics,solver,Rust,https://github.com/angelovangel/faster,,MIT,fastq;bioinformatics;quality-control;rust
490,partialsmiles,Validating SMILES parser with support for incomplete strings,"A Python library for parsing and validating SMILES strings (Simplified Molecular Input Line Entry System), specifically designed to handle and validate incomplete or partial SMILES strings, useful for interactive chemistry applications and data cleaning.",D1-03,parsing;data_validation,library,Python,https://github.com/baoilleach/partialsmiles,,MIT,cheminformatics;smiles;validation;chemistry
491,fastqc-viz,Enhanced visualization for FastQC reports,"A tool to generate improved, modernized visualizations from FastQC reports, aiding in the interpretation of quality control metrics for high-throughput sequencing data.",D1-03,quality_control;visualization,library,R,https://github.com/barreiro-r/fastqc-viz,,NOASSERTION,fastqc;visualization;ngs;bioinformatics
492,pmultiqc,Proteomics quality control reporting library based on MultiQC,"A library designed to generate quality control reports for proteomics data by extending the MultiQC framework, enabling aggregated visualization of metrics from various proteomics analysis tools.",D1-03,quality_control;qc_report,library,Python,https://github.com/bigbio/pmultiqc,,MIT,proteomics;quality-control;multiqc;bioinformatics
493,KneadData,Quality control and decontamination tool for metagenomic data,A tool designed to perform quality control on metagenomic and metatranscriptomic sequencing data. It separates host reads from bacterial reads and performs trimming/filtering to ensure high-quality data for downstream analysis.,D1-03,quality_control;filtering,solver,Python,https://github.com/biobakery/kneaddata,http://huttenhower.sph.harvard.edu/kneaddata,NOASSERTION,metagenomics;quality-control;decontamination;bioinformatics
494,bioio,Standardized image reading and metadata management for microscopy,"A Python library providing a standardized interface for reading, writing, and managing metadata of microscopy images, supporting various bioimaging formats and facilitating seamless integration into analysis workflows.",D1;D1-03,parsing;metadata_extraction,library,Python,https://github.com/bioio-devs/bioio,https://github.com/bioio-devs/bioio,BSD-3-Clause,microscopy;bioimaging;metadata;io
495,Biolink Model,Data model and schema for biological entities and relationships,"The Biolink Model is a high-level data model that defines a set of classes, slots, and relationships for representing biological knowledge. It serves as a schema for standardizing data exchange in knowledge graphs and translational science.",D1-03,schema_definition;data_modeling,library,Python,https://github.com/biolink/biolink-model,https://biolink.github.io/biolink-model/,NOASSERTION,knowledge-graph;schema;biology;standardization
496,biolinkml,Modeling language and framework for biological entities (predecessor to LinkML),"A framework for defining data models and schemas for biological entities, facilitating the generation of JSON-Schema, SHACL, and other artifacts. It has been largely superseded by LinkML but remains relevant for legacy biological data models.",D1;D1-03,schema_definition;metadata_management,library,Python,https://github.com/biolink/biolinkml,https://biolink.github.io/biolinkml/,CC0-1.0,biolink;schema;metadata;biology
497,ccdhmodel,LinkML schema definitions for Cancer Data Harmonization,"Contains the LinkML model definitions for the Center for Cancer Data Harmonization (CCDH), used to harmonize and validate data across various cancer research programs.",D1;D1-03,schema_definition;data_harmonization,dataset,Python,https://github.com/cancerDHC/ccdhmodel,https://cancerdhc.github.io/ccdhmodel/,BSD-3-Clause,cancer;data-harmonization;linkml;schema
498,chemrof,Schema definitions for chemistry ontology classes,"Provides schema definitions and structures for chemistry ontology classes, facilitating the organization and validation of chemical knowledge graph data.",D1;D1-03,schema_definition;ontology_management,dataset,Python,https://github.com/chemkg/chemrof,,CC0-1.0,chemistry;ontology;schema;knowledge-graph
499,CheckM2,Machine learning tool for assessing metagenome bin quality,"A tool that uses machine learning to assess the quality (completeness and contamination) of metagenome-derived genome bins, improving upon previous lineage-specific marker set methods.",D1;D1-03,quality_control;metagenomics,solver,Scilab,https://github.com/chklovski/CheckM2,https://github.com/chklovski/CheckM2,GPL-3.0,metagenomics;quality-control;genome-binning;machine-learning
500,HistoQC,Quality control tool for digital pathology slides,An open-source quality control tool designed for digital pathology slides. It automatically identifies artifacts and assesses the suitability of slides for computational analysis.,D1;D1-03,quality_control;image_processing,solver,JavaScript,https://github.com/choosehappy/HistoQC,https://github.com/choosehappy/HistoQC,BSD-3-Clause-Clear,pathology;quality-control;histology;medical-imaging
501,DataHarmonizer,Standardized spreadsheet editor and validator for public health data,"A browser-based spreadsheet editor and validator that facilitates the harmonization of data according to defined schemas (e.g., LinkML). It includes templates for SARS-CoV-2 and Monkeypox sampling data.",D1;D1-03,data_harmonization;data_validation;data_entry,platform,JavaScript,https://github.com/cidgoh/DataHarmonizer,https://github.com/cidgoh/DataHarmonizer,MIT,epidemiology;data-harmonization;validation;genomics
502,Epsilon,GPS data integrity verification algorithm suite,"A suite of algorithms designed to verify the integrity of received GPS data and ranging signals, improving resiliency against signal loss and spoofing for navigation and timing applications.",D1;D1-03,quality_control;signal_processing,library,Python,https://github.com/cisagov/Epsilon,,CC0-1.0,gps;signal-integrity;pnt;navigation
503,PNT-Integrity,Library for verifying GPS/PNT signal integrity,"Provides methods to verify the integrity of received GPS data and ranging signals, serving as a reference implementation for detecting anomalies in Positioning, Navigation, and Timing (PNT) data.",D1;D1-03,quality_control;signal_processing,library,C++,https://github.com/cisagov/PNT-Integrity,,NOASSERTION,gps;pnt;integrity-check;signal-processing
504,Clowder,Research data management and analysis platform,"A data management system that enables users to share, annotate, organize, and analyze large collections of datasets. It supports extensible metadata annotation (JSON-LD) and automated extraction pipelines.",D1;D1-03,data_management;metadata_management;workflow_automation,platform,JavaScript,https://github.com/clowder-framework/clowder,https://clowderframework.org/,NCSA,data-management;metadata;curation;research-data
505,json-flattener,Utility for denormalizing nested JSON objects to tables,A Python library used in bioinformatics pipelines to denormalize nested dictionaries or JSON objects (such as ontology terms) into tabular formats and vice versa.,D1;D1-03,data_conversion;data_wrangling,library,Python,https://github.com/cmungall/json-flattener,,BSD-3-Clause,json;conversion;bioinformatics;flattening
506,linkml-phenopackets,LinkML rendering and tools for Phenopackets,"Provides tools and schema definitions for working with the Phenopackets standard using the LinkML modeling framework, facilitating phenotypic data exchange.",D1;D1-03,schema_definition;data_conversion,library,Python,https://github.com/cmungall/linkml-phenopackets,,None,phenopackets;linkml;phenotype;schema
507,semantic-llama,LLM-based scientific knowledge extraction tool,"A tool that leverages Large Language Models (LLMs) to extract structured semantic information and knowledge from unstructured text, tailored for scientific curation tasks.",D1;D1-03,knowledge_extraction;nlp,solver,Python,https://github.com/cmungall/semantic-llama,,BSD-3-Clause,llm;knowledge-extraction;semantics;curation
508,GrandQC,Quality control and tissue detection tool for digital pathology slides,"GrandQC is a tool designed for the quality control of digital pathology images. It performs tissue detection and identifies artifacts or quality issues in whole slide images (WSIs), facilitating the preprocessing steps required for computational pathology and AI model training in medical research.",D1;D1-03,quality_control;image_processing;tissue_detection,solver,Python,https://github.com/cpath-ukk/grandqc,,NOASSERTION,pathology;quality-control;wsi;tissue-detection
509,FastQC (CSF Fork),Quality control tool for high throughput sequence data (CSF fork),"This is a fork of the standard FastQC tool, adapted for usage on selected reads of unaligned BAM files. It provides a modular set of analyses which can be used to give a quick impression of whether your data has any problems of which you should be aware before doing any further analysis.",D1;D1-03,quality_control;ngs_analysis,solver,Java,https://github.com/csf-ngs/fastqc,http://www.bioinformatics.babraham.ac.uk/projects/fastqc/,GPL-3.0,fastqc;ngs;quality-control;bam
510,PLUTON,Automated shell pipeline for NIPT data preprocessing and aneuploidy prediction,"An automated pipeline wrapping tools like FastQC, SAMtools, and WisecondorX to execute pre-processing of aligned reads and predict fetal gender and chromosomal aneuploidies.",D1-03;D2,quality_control;variant_calling;workflow,workflow,Shell,https://github.com/epigen-bioinfolab/PLUTON,,None,nipt;bioinformatics;pipeline;aneuploidy
511,nanoq,Ultra-fast quality control and filtering for Nanopore sequencing reads,"A minimal but speedy quality control tool for nanopore reads written in Rust, providing read filtering and summary statistics.",D1-03,quality_control;filtering,solver,Rust,https://github.com/esteinig/nanoq,,MIT,nanopore;quality-control;bioinformatics;fastq
512,FAIR4Health Data Curation Tool,"Desktop tool for cleaning, validating and harmonizing health datasets for FAIR compliance",A tool developed by the FAIR4Health project to assist researchers in curating and validating health data to ensure it meets FAIR principles.,D1-03,data_curation;validation;harmonization,solver,TypeScript,https://github.com/fair4health/data-curation-tool,,Apache-2.0,fair-data;health-informatics;data-curation
513,fastqc-rs,High-performance Rust implementation of the FastQC quality control tool,"A quality control tool for FASTQ files written in Rust, offering a faster alternative to the original Java-based FastQC.",D1-03,quality_control,solver,Rust,https://github.com/fastqc-rs/fastqc-rs,,MIT,fastq;quality-control;bioinformatics;rust
514,frictionless-ci,Continuous integration service for validating tabular data packages in repositories,"A data management service that brings continuous data validation to tabular data in your repository via Github Action, ensuring data quality in scientific workflows.",D1-03,validation;quality_control,service,JavaScript,https://github.com/frictionlessdata/frictionless-ci,https://frictionlessdata.io,MIT,data-validation;continuous-integration;frictionless-data
515,frictionless-darwin-core,Converter and validator for Darwin Core Archive biodiversity data using Frictionless standards,"A tool to handle DarwinCore Archives as Frictionless Data Packages, facilitating the validation and management of biodiversity data.",D1-03;D1,data_conversion;validation,library,Python,https://github.com/frictionlessdata/frictionless-darwin-core,,MIT,biodiversity;darwin-core;frictionless-data;metadata
516,Frictionless Framework (Python),"Data management framework to describe, extract, validate, and transform tabular data","A comprehensive framework for Python that provides functionality to describe, extract, validate, and transform tabular data, widely used in research data management.",D1-03;D1,validation;metadata_management;data_cleaning,library,Python,https://github.com/frictionlessdata/frictionless-py,https://framework.frictionlessdata.io,MIT,data-validation;metadata;tabular-data;frictionless-data
517,frictionless-r,"R interface for reading, writing, and validating Frictionless Data Packages","An R package to read and write Frictionless Data Packages, allowing R users to integrate Frictionless validation and metadata standards into their analysis pipelines.",D1-03;D1,validation;data_io,library,R,https://github.com/frictionlessdata/frictionless-r,,NOASSERTION,r-package;data-validation;frictionless-data
518,RNA-SeQC,Efficient tool for computing quality control metrics for RNA-seq data,"Fast, efficient RNA-Seq metrics for quality control and process optimization, providing essential metrics for transcriptomics data analysis.",D1-03,quality_control,solver,C++,https://github.com/getzlab/rnaseqc,,NOASSERTION,rna-seq;quality-control;bioinformatics;genomics
519,tableschema-to-template,Tool to generate Excel data entry templates from Frictionless Table Schemas for HuBMAP data submission,"Developed by the HuBMAP Consortium, this tool converts Frictionless Table Schema definitions into Excel spreadsheets with built-in validation, facilitating standardized metadata collection and data submission in biomedical research.",D1;D1-03,metadata_management;schema_validation,solver,Python,https://github.com/hubmapconsortium/tableschema-to-template,,MIT,metadata;hubmap;frictionless-data;biomedical-data
520,compliance-checker,Tool to check oceanographic datasets against metadata compliance standards,"A Python tool developed by IOOS to check local or remote datasets (NetCDF, OPeNDAP) against various compliance standards such as CF (Climate and Forecast), ACDD, and ISO metadata standards, ensuring data interoperability in earth sciences.",D1;D1-03,quality_control;metadata_validation;standard_compliance,solver,Python,https://github.com/ioos/compliance-checker,https://ioos.github.io/compliance-checker/,Apache-2.0,oceanography;netcdf;metadata-validation;cf-conventions
521,iRODS,Open source data management software for data virtualization and workflow automation,"The Integrated Rule-Oriented Data System (iRODS) is a data management software used in high-performance computing and scientific research (genomics, physics, etc.) to manage data lifecycle, metadata, and provenance across distributed storage resources.",D1;D1-03,data_management;workflow_automation;metadata_management,platform,C++,https://github.com/irods/irods,https://irods.org/,BSD-3-Clause,data-management;hpc;metadata;workflow
522,TaxTriage,Nextflow workflow for taxonomic classification and triage of metagenomic NGS data,"A comprehensive bioinformatics workflow designed to identify and classify microbial organisms within short- or long-read metagenomic Next-Generation Sequencing (NGS) data. It performs quality control, host removal, and taxonomic classification to triage samples for further analysis.",D1;D6,taxonomic_classification,workflow,Java,https://github.com/jhuapl-bio/taxtriage,,MIT,metagenomics;ngs;microbiome;nextflow;bioinformatics
523,fastqcr,Quality control and reporting for sequencing data,"An R package designed for quality control (QC) of high-throughput sequencing data. It facilitates running FastQC from R, aggregating reports, and generating summaries to assess the quality of raw sequencing reads (FASTQ files).",D1;D1-03,quality_control,library,R,https://github.com/kassambara/fastqcr,http://www.sthda.com/english/wiki/fastqcr-an-r-package-facilitating-quality-controls-of-sequencing-data,GPL-3.0,fastq;quality-control;ngs;bioinformatics;r-package
524,FastQt,Qt5 port of FastQC for high throughput sequence data quality control,"A quality control tool for high throughput sequence data, serving as a C++/Qt5 port of the popular FastQC tool. It provides interactive visualization and analysis of FASTQ files to ensure data quality before downstream analysis.",D1;D1-03,quality_control;sequence_analysis,solver,C++,https://github.com/labsquare/FastQt,,GPL-3.0,fastqc;ngs;quality-control;bioinformatics
525,FastqCleaner,Shiny application for FASTQ quality control and filtering,"A Shiny application and R package designed for quality control, filtering, and trimming of FASTQ files, enabling interactive data cleaning for NGS workflows.",D1;D1-03,quality_control;data_filtering,solver,HTML,https://github.com/leandroroser/FastqCleaner,,NOASSERTION,fastq;quality-control;shiny;bioinformatics
526,LinkML,Linked Open Data Modeling Language and toolkit,"A general-purpose modeling language and toolkit for defining data schemas (ontologies, data models) that can be compiled into various artifacts (JSON-Schema, SHACL, SQL DDL, Python dataclasses), widely used in scientific data standardization.",D1;D1-03,schema_definition;data_modeling;validation,workflow,Python,https://github.com/linkml/linkml,https://linkml.io,Apache-2.0,schema;metadata;linked-data;modeling
527,linkml-arrays,N-dimensional array support for LinkML,"An extension for LinkML to support loading, dumping, and validating N-dimensional arrays, facilitating the integration of complex scientific data structures into LinkML models.",D1;D1-03,data_modeling;serialization,library,Python,https://github.com/linkml/linkml-arrays,,BSD-3-Clause,arrays;linkml;scientific-data
528,linkml-datalog,Datalog translation and inference for LinkML schemas,"A tool that translates LinkML schemas into Datalog programs and executes them using Souffle, enabling advanced validation and logical inference over scientific instance data.",D1;D1-03,validation;inference,solver,Python,https://github.com/linkml/linkml-datalog,,None,datalog;inference;validation;linkml
529,linkml-dataops,Data manipulation API for LinkML instances,"A library providing a data API for manipulating, querying, and validating LinkML instance data, supporting operations like patching and diffing.",D1;D1-03,data_processing;data_manipulation,library,Python,https://github.com/linkml/linkml-dataops,,None,data-ops;linkml;api
530,linkml-map,Schema mapping tool for LinkML,"A tool for defining and executing mappings between different LinkML schemas, facilitating data transformation and interoperability between scientific data standards.",D1;D1-03,data_transformation;schema_mapping,solver,Python,https://github.com/linkml/linkml-map,,NOASSERTION,mapping;transformation;linkml
531,linkml-owl,LinkML to OWL converter,"An extension of the LinkML runtime for converting instances of LinkML classes to OWL (Web Ontology Language) classes or instances, bridging data modeling with semantic web ontologies.",D1;D1-03,data_conversion;ontology_mapping,library,Python,https://github.com/linkml/linkml-owl,,None,owl;ontology;semantic-web;linkml
532,linkml-reference-validator,Validator for text quotes in scientific data,"A tool to validate that supporting text quotes in data actually appear in their cited references, useful for data curation and quality control in scientific databases.",D1;D1-03,validation;quality_control,solver,Python,https://github.com/linkml/linkml-reference-validator,,Apache-2.0,validation;curation;text-mining
533,linkml-renderer,Renderer for LinkML instance data,"A library and tool for rendering LinkML instance data into various formats such as HTML, Markdown, and Mermaid diagrams, aiding in data visualization and documentation.",D1;D1-03,visualization;reporting,library,Python,https://github.com/linkml/linkml-renderer,,Apache-2.0,rendering;visualization;documentation
534,linkml-runtime,Runtime library for LinkML models,"The core runtime support library for working with LinkML generated models in Python, providing utilities for data loading, dumping, and manipulation.",D1;D1-03,data_processing;serialization,library,Python,https://github.com/linkml/linkml-runtime,,CC0-1.0,runtime;linkml;serialization
535,linkml-runtime.js,JavaScript runtime for LinkML,"The JavaScript implementation of the LinkML runtime, enabling the use of LinkML models and validation in web and Node.js environments.",D1;D1-03,data_processing;validation,library,TypeScript,https://github.com/linkml/linkml-runtime.js,,None,javascript;linkml;runtime
536,linkml-solr,Solr integration for LinkML,"A wrapper and utility for using Apache Solr with LinkML schemas, facilitating the indexing and querying of scientific data modeled with LinkML.",D1;D1-03,data_indexing;data_storage,library,Python,https://github.com/linkml/linkml-solr,,None,solr;search;indexing;linkml
537,linkml-sparql,LinkML to SPARQL mapper,"A library that maps LinkML queries to SPARQL and back, enabling semantic queries over LinkML-compliant data stored in RDF stores.",D1;D1-03,data_querying;semantic_web,library,Python,https://github.com/linkml/linkml-sparql,,None,sparql;rdf;querying
538,linkml-store,Storage abstraction for LinkML,"A wrapper library providing a unified interface for multiple storage engines (e.g., SQL, MongoDB, Solr) for LinkML data.",D1;D1-03,data_storage;database_interface,library,Python,https://github.com/linkml/linkml-store,,MIT,storage;database;abstraction
539,prefixmaps,Semantic prefix map registry and library,"A Python library and registry for managing semantic prefix maps (CURIEs), essential for resolving identifiers in scientific data and semantic web applications.",D1;D1-03,identifier_resolution;metadata_management,library,Python,https://github.com/linkml/prefixmaps,,Apache-2.0,curie;prefixes;semantic-web
540,schema-automator,Automated schema induction tool,"A toolkit for automating the schema development lifecycle, including inducing LinkML schemas from structured data sources like TSV, JSON, or other schema formats.",D1;D1-03,schema_induction;data_modeling,solver,Python,https://github.com/linkml/schema-automator,,BSD-3-Clause,automation;schema-inference;modeling
541,schemasheets,Schema management via spreadsheets,"A tool that allows users to structure and define data schemas using Google Sheets or TSVs, which are then converted to LinkML and other formats, promoting FAIR data practices.",D1;D1-03,schema_definition;data_curation,solver,Python,https://github.com/linkml/schemasheets,,None,spreadsheets;fair-data;schema-conversion
542,semantic-dsl,Domain Specific Language creator for schemas,"A library for creating easy-to-use Domain Specific Languages (DSLs) for scientific schemas, simplifying the process of defining complex data models.",D1;D1-03,schema_definition;dsl,library,Python,https://github.com/linkml/semantic-dsl,,BSD-3-Clause,dsl;modeling;semantics
543,sparqlfun,SPARQL templating library,"A library for managing and executing SPARQL templates, providing a Python wrapper to simplify querying RDF data in scientific workflows.",D1;D1-03,data_querying;sparql,library,Python,https://github.com/linkml/sparqlfun,,CC0-1.0,sparql;templates;rdf
544,sssom-py,Python toolkit for working with SSSOM (Simple Standard for Sharing Ontology Mappings) metadata,"A Python library and command-line toolkit for manipulating, validating, and converting ontology mapping sets in the SSSOM format, facilitating interoperability between scientific ontologies.",D1;D1-03,metadata_management;ontology_mapping;data_conversion,library,Python,https://github.com/mapping-commons/sssom-py,https://mapping-commons.github.io/sssom-py/,MIT,ontology;metadata;mapping;sssom;bioinformatics
545,nmdc-schema,Unified data model and validation schema for the National Microbiome Data Collaborative,"Provides the schema definitions and generated Python libraries (Pydantic models) for validating and structuring microbiome data within the NMDC ecosystem, ensuring data interoperability and quality.",D1;D1-03,metadata_schema;data_validation;data_modeling,library,Python,https://github.com/microbiomedata/nmdc-schema,https://microbiomedata.github.io/nmdc-schema/,CC0-1.0,microbiome;schema;metadata;linkml;validation
546,NMDC Sample Annotator,Tool for annotating microbiome samples with NMDC-compliant metadata,A tool designed to assist researchers in annotating biosamples with standardized metadata according to the National Microbiome Data Collaborative (NMDC) schema.,D1;D1-03,metadata_curation;sample_annotation,solver,Python,https://github.com/microbiomedata/sample-annotator,,None,microbiome;metadata;annotation;nmdc
547,Koza,Data transformation framework for ingesting data into LinkML-compliant knowledge graphs,"A data transformation framework used to transform source data (CSV, JSON, etc.) into a target data model (LinkML), primarily used for building biological knowledge graphs.",D1;D1-03,data_transformation;knowledge_graph_construction;etl,workflow,Python,https://github.com/monarch-initiative/koza,https://koza.monarchinitiative.org/,BSD-3-Clause,etl;knowledge-graph;linkml;data-transformation
548,OntoGPT,LLM-based tool for extracting structured ontological information from unstructured text,"A Python package that uses Large Language Models (LLMs) to extract structured information from text, conforming to LinkML schemas, useful for knowledge base curation and ontology population.",D1;D1-03,knowledge_extraction;ontology_population;text_mining,solver,Python,https://github.com/monarch-initiative/ontogpt,https://monarch-initiative.github.io/ontogpt/,BSD-3-Clause,llm;ontology;knowledge-extraction;nlp;bioinformatics
549,TidyMultiqc,R package to convert MultiQC reports into tidy data frames for downstream analysis,"Provides functions to parse the output of MultiQC (a common bioinformatics QC tool) into tidy data frames, enabling easy statistical analysis and visualization in R.",D1;D1-03,qc_reporting;data_parsing;data_conversion,library,R,https://github.com/multimeric/TidyMultiqc,https://multimeric.github.io/TidyMultiqc/,GPL-3.0,multiqc;bioinformatics;r;tidy-data;quality-control
550,NASA MMT,Web-based tool for managing metadata in the NASA Common Metadata Repository (CMR),"The Metadata Management Tool (MMT) allows users to create, update, and manage metadata records within NASA's Common Metadata Repository, supporting Earth Science data stewardship.",D1;D1-03,metadata_management;data_curation,platform,JavaScript,https://github.com/nasa/mmt,,Apache-2.0,nasa;metadata;cmr;earth-science;data-management
551,nf-core/hgtseq,Bioinformatics pipeline for investigating horizontal gene transfer from NGS data,"A Nextflow pipeline designed to detect and analyze horizontal gene transfer events using Next Generation Sequencing data, facilitating evolutionary biology research.",D1;Bioinformatics,sequence_analysis;horizontal_gene_transfer_detection,workflow,Nextflow,https://github.com/nf-core/hgtseq,https://nf-co.re/hgtseq,MIT,bioinformatics;ngs;hgt;nextflow
552,nf-core/rnaseq,Comprehensive RNA sequencing analysis pipeline,"A standard bioinformatics pipeline for RNA-seq data analysis, integrating aligners (STAR, HISAT2) and quantification tools (Salmon) with extensive quality control reporting.",D1;Bioinformatics,rna_seq_analysis;quality_control;quantification,workflow,Nextflow,https://github.com/nf-core/rnaseq,https://nf-co.re/rnaseq,MIT,bioinformatics;rna-seq;gene-expression;nextflow
553,nf-core/seqinspector,Dedicated quality control pipeline for sequencing data,"A pipeline focused solely on generating comprehensive quality control reports for large-scale sequencing datasets, suitable for core facilities and high-throughput research.",D1;D1-03;Bioinformatics,quality_control;qc_report,workflow,Nextflow,https://github.com/nf-core/seqinspector,https://nf-co.re/seqinspector,MIT,bioinformatics;qc;ngs;multiqc
554,datapackage-m,Power Query M functions for Frictionless Data Packages,"A library enabling Power BI and Excel to directly ingest and parse Tabular Data Packages, a standard format in Open Science and research data management.",D1;D1-01,data_parsing;data_import,library,R,https://github.com/nimblelearn/datapackage-m,,MIT,frictionless-data;power-bi;data-package;open-data
555,MRIQC,Automated Quality Control for structural and functional MRI,"A tool for extracting quality measures from structural (T1w, T2w) and functional MRI data, generating visual reports to assess data integrity in neuroimaging studies.",D1;D1-03;Neuroscience,quality_control;image_analysis,solver,Python,https://github.com/nipreps/mriqc,https://mriqc.readthedocs.io/,Apache-2.0,neuroimaging;mri;quality-control;bids
556,Cosmos-Transfer2.5,World simulation model for physical AI applications,"A foundation model for generating high-quality physical world simulations conditioned on spatial inputs, used for robotics and physical AI research.",Physics;Robotics;Simulation,simulation;generative_modeling,solver,Python,https://github.com/nvidia-cosmos/cosmos-transfer2.5,,Apache-2.0,simulation;physical-ai;world-model;generative-ai
557,Open Data Editor,No-code application to explore and validate tabular research data,"A desktop application powered by the Frictionless Framework for validating, cleaning, and exploring tabular data, designed to support Open Data standards in research.",D1;D1-03,data_validation;data_cleaning,platform,Python,https://github.com/okfn/opendataeditor,https://opendataeditor.okfn.org/,MIT,frictionless-data;data-validation;open-science;csv
558,Onedata,Distributed scientific data management platform,"A high-performance, distributed global data management system that provides transparent data access and POSIX-compliant virtual filesystems for research infrastructures.",D1;Data_Infrastructure,data_management;storage_virtualization,platform,C++,https://github.com/onedata/onedata,https://onedata.org/,Apache-2.0,distributed-storage;research-data-management;posix;grid-computing
559,Open Semantic Search,Research tool for analyzing and searching large document collections,"An integrated search and analysis platform for research document collections, featuring text mining, named entity recognition, and metadata management.",D1;Text_Mining,text_mining;information_retrieval;document_analysis,platform,Shell,https://github.com/opensemanticsearch/open-semantic-search,https://www.opensemanticsearch.org/,GPL-3.0,semantic-search;text-mining;ner;research-tool
560,Atlas Checks,Integrity checks for geospatial data (OpenStreetMap),"A framework for running data integrity checks on geospatial map data, utilizing the Atlas library to identify quality issues in OpenStreetMap datasets.",D1;D1-03;Geospatial,data_validation;quality_control,library,Java,https://github.com/osmlab/atlas-checks,,BSD-3-Clause,geospatial;osm;quality-control;map-data
561,pytest-pandera,Data testing plugin for scientific dataframes,"A pytest plugin for Pandera, enabling statistical data validation and schema enforcement for pandas dataframes, widely used in scientific data processing pipelines.",D1;D1-03;Data_Science,data_validation;schema_enforcement,library,Python,https://github.com/pandera-dev/pytest-pandera,https://pandera.readthedocs.io/,MIT,data-validation;pandas;testing;quality-control
562,Nabu,Digital media management system for ethnographic research,"A catalog and workflow management system for audio/video items and metadata, developed by PARADISEC for archiving endangered cultures' linguistic data.",D1;Humanities,data_management;archiving;metadata_management,platform,Ruby,https://github.com/paradisec-archive/nabu,,GPL-3.0,archival-science;linguistics;metadata;workflow
563,pointblank,Data validation toolkit for R,"A comprehensive toolkit for data validation and quality monitoring in R, allowing scientists to define and verify data quality rules within analysis pipelines.",D1;D1-03;Statistics,data_validation;quality_assessment,library,Python,https://github.com/posit-dev/pointblank,https://pointblank.posit.co/,MIT,r-stats;data-validation;quality-control;data-science
564,pvanalytics,Quality control and feature labeling tools for photovoltaic system data,"A Python library providing functions for quality control, filtering, and feature labeling of data from photovoltaic energy systems. It supports tasks like clipping detection, daytime identification, and sensor data validation.",D1;D1-03,quality_control;data_filtering;feature_labeling,library,Python,https://github.com/pvlib/pvanalytics,https://pvanalytics.readthedocs.io/,MIT,photovoltaic;energy;quality-control;time-series
565,geoflow,Orchestrator for geospatial metadata management and FAIR services,"An R package to orchestrate geospatial metadata management workflows. It facilitates the management of FAIR services and metadata for geospatial data, supporting various standards and formats.",D1;D1-03,metadata_management;workflow_orchestration,workflow,R,https://github.com/r-geoflow/geoflow,https://github.com/r-geoflow/geoflow,NOASSERTION,geospatial;metadata;fair-data;workflow
566,MetaCerberus,Functional ontology assignments for metagenomes using HMM,"A Python tool for versatile functional ontology assignments for metagenomes via Hidden Markov Models (HMM), focusing on environmental shotgun metaomics data.",D1;D1-03,annotation;ontology_mapping;metagenomics_analysis,solver,Python,https://github.com/raw-lab/MetaCerberus,,BSD-3-Clause,metagenomics;hmm;ontology;bioinformatics
567,Refinery Platform,"Data management, analysis, and visualization system for bioinformatics","A platform for bioinformatics and computational biology applications consisting of a data repository with rich metadata capabilities, a Galaxy-based workflow engine, and visualization tools.",D1;D1-03,data_management;workflow_orchestration;visualization,platform,Python,https://github.com/refinery-platform/refinery-platform,http://refinery-platform.org/,NOASSERTION,bioinformatics;data-management;galaxy;metadata
568,fastq.bio,Interactive web tool for quality control of DNA sequencing data,"A web-based interactive tool designed for performing quality control on DNA sequencing data (FASTQ files), running entirely in the browser.",D1;D1-03,quality_control;visualization,solver,JavaScript,https://github.com/robertaboukhalil/fastq.bio,http://fastq.bio/,MIT,fastq;quality-control;dna-sequencing;web-tool
569,minion_multiQC,Multi-tool quality control wrapper for MinION sequencing data,A shell-based wrapper tool to perform quality control on MinION sequencing data using multiple underlying QC tools.,D1;D1-03,quality_control,workflow,Shell,https://github.com/roblanf/minion_multiQC,,None,minion;nanopore;quality-control
570,minion_qc,Quality control tool for MinION sequencing data,An R script/tool for generating quality control plots and statistics from MinION sequencing data.,D1;D1-03,quality_control;visualization,solver,R,https://github.com/roblanf/minion_qc,,MIT,minion;nanopore;quality-control;r
571,skimr,Compact and flexible summary statistics for data analysis,"An R package from rOpenSci that provides a frictionless approach to dealing with summary statistics, commonly used for data profiling and initial quality assessment in scientific workflows.",D1;D1-03,data_profiling;statistics,library,R,https://github.com/ropensci/skimr,https://docs.ropensci.org/skimr/,None,statistics;data-summary;r-package;ropensci
572,FastQC,Standard quality control analysis tool for high throughput sequencing data,A quality control tool for high throughput sequence data. It provides a modular set of analyses which you can use to give a quick impression of whether your data has any problems of which you should be aware before doing any further analysis.,D1;D1-03,quality_control;qc_report,solver,Java,https://github.com/s-andrews/FastQC,http://www.bioinformatics.babraham.ac.uk/projects/fastqc/,GPL-3.0,ngs;quality-control;fastq;bioinformatics
573,sequana_fastqc,Sequana pipeline wrapper for parallel FastQC execution,"A pipeline based on Sequana to perform FastQC analysis in parallel and summarize results using MultiQC, designed for efficient quality control of sequencing data.",D1;D1-03,quality_control;workflow,workflow,Python,https://github.com/sequana/fastqc,https://sequana.readthedocs.io,BSD-3-Clause,pipeline;fastqc;sequana;bioinformatics
574,Falco,"High-performance C++ quality control tool for sequencing data, compatible with FastQC","Falco is a C++ implementation of FastQC, designed to assess the quality of high-throughput sequencing data (NGS). It provides faster processing speeds while maintaining compatibility with FastQC reports, enabling efficient quality control in large-scale bioinformatics pipelines.",D1;D1-03,quality_control;qc_report,solver,C++,https://github.com/smithlabcode/falco,,GPL-3.0,bioinformatics;ngs;quality-control;fastq
575,iterative-stratification,Cross-validators for iterative stratification of multilabel data in scikit-learn,"A Python library providing scikit-learn compatible cross-validators for multilabel data, ensuring balanced label distribution across splits, which is essential for rigorous scientific machine learning experiments.",D1,data_splitting;model_validation,library,Python,https://github.com/trent-b/iterative-stratification,,BSD-3-Clause,scikit-learn;cross-validation;multilabel;machine-learning
576,Tropy,Research photo and metadata management tool for scientists and archivists,"A desktop application designed for researchers to organize, describe, and annotate photos of research material (e.g., from archives), managing metadata and facilitating the research workflow.",D1;D1-03,metadata_management;data_organization,platform,JavaScript,https://github.com/tropy/tropy,https://tropy.org,NOASSERTION,metadata;research-data-management;archival-science
577,SVI-Quality-Checker,Quality control tool for Street View Imagery datasets,"A tool developed by the Urban Analytics Lab to examine and validate the quality of street view imagery (SVI) datasets, supporting urban science and geospatial research.",D1;D1-03,quality_control;image_validation,solver,Jupyter Notebook,https://github.com/ualsg/SVI-Quality-Checker,,None,urban-science;geospatial;quality-control;street-view
578,Checkmate,Checkpoint management tool for TensorFlow models,"A lightweight utility for managing and saving the best TensorFlow checkpoints during model training, ensuring model integrity and preventing data loss in scientific ML workflows.",D1,workflow_management;artifact_management,library,Python,https://github.com/vonclites/checkmate,,MIT,tensorflow;checkpointing;ml-ops
579,nanoQC,Quality control tool for nanopore sequencing data,"A bioinformatics tool specifically designed for quality control of Oxford Nanopore sequencing data, generating plots and statistics to assess read quality.",D1;D1-03,quality_control;sequencing_analysis,solver,Python,https://github.com/wdecoster/nanoQC,,GPL-3.0,nanopore;bioinformatics;quality-control;long-read
580,ydata-quality,Data quality assessment library for data science,"A Python library for comprehensive data quality assessment, providing metrics and visualizations to identify issues in datasets prior to analysis or modeling.",D1;D1-03,quality_assessment;data_profiling,library,Jupyter Notebook,https://github.com/ydataai/ydata-quality,https://github.com/ydataai/ydata-quality,MIT,data-quality;data-science;profiling
581,ZotaData,Metadata management plugin for Zotero,"A tool (likely a plugin or extension) for Zotero that enhances metadata management capabilities, facilitating the organization of scientific literature and citations.",D1;D1-03,metadata_management;literature_management,solver,TypeScript,https://github.com/ydeng11/zotero-zotadata,,MIT,zotero;metadata;bibliography
582,LongQC,Quality control tool for PacBio and ONT long read data,"A tool designed for the quality control of long-read sequencing data (PacBio and Oxford Nanopore), addressing specific error profiles and artifacts associated with these technologies.",D1;D1-03,quality_control;sequencing_analysis,solver,C,https://github.com/yfukasawa/LongQC,,MIT,long-read;pacbio;ont;bioinformatics;quality-control
583,Tibanna,Workflow execution manager for running genomic pipelines on AWS,"Tibanna is a software tool designed to execute genomic pipelines on the Amazon Web Services (AWS) cloud. It supports Common Workflow Language (CWL), Workflow Description Language (WDL), and Snakemake, integrating with Docker for containerization. It is specifically used by the 4D Nucleome Data Coordination and Integration Center (4DN DCIC) for processing large-scale genomic data.",D1;D1-04,workflow_orchestration;genomic_pipeline_execution,workflow,Python,https://github.com/4dn-dcic/tibanna,https://tibanna.readthedocs.io/,MIT,genomics;aws;pipeline;cwl;wdl
584,Covalent,Workflow orchestration tool for HPC and quantum computing,"Covalent is a Pythonic workflow orchestration tool designed for research scientists and engineers to manage and execute complex workflows on heterogeneous compute environments, including High Performance Computing (HPC) clusters and quantum computers. It simplifies the deployment of machine learning and experimental simulations across diverse hardware backends.",D1;D1-04,workflow_orchestration;hpc_job_management;quantum_computing,workflow,Python,https://github.com/AgnostiqHQ/covalent,https://covalent.readthedocs.io/,Apache-2.0,hpc;quantum-computing;workflow;orchestration
585,Cromwell Frontend,Web interface for managing Cromwell workflows,"A web-based frontend application for the Cromwell Workflow Management System, which is widely used in bioinformatics for scientific workflow execution. It provides capabilities for job monitoring, authentication, and management of workflow definitions, facilitating the operation of genomic pipelines.",D1;D1-04,workflow_management;job_monitoring,platform,Python,https://github.com/BiRG/cromwell-frontend,,MIT,bioinformatics;cromwell;workflow-management;gui
586,AiiDA-GROMACS,AiiDA plugin for GROMACS molecular dynamics simulations,A plugin for the AiiDA workflow engine that enables the automation and provenance tracking of GROMACS molecular dynamics simulations. It allows researchers to integrate GROMACS calculations into complex scientific workflows for computational chemistry and materials science.,D1;D1-04,molecular_dynamics;workflow_automation,connector,Python,https://github.com/CCPBioSim/aiida-gromacs,https://aiida-gromacs.readthedocs.io/,MIT,molecular-dynamics;aiida;gromacs;workflow;chemistry
587,CalliNGS-NF,Nextflow pipeline for GATK RNA-Seq variant calling,"CalliNGS-NF is a bioinformatics pipeline implemented in Nextflow for performing variant calling on RNA-Seq data using the GATK Best Practices. It automates the process of read alignment, processing, and variant discovery, ensuring reproducibility and scalability in genomic research.",D1;D1-04,variant_calling;rna_seq_analysis;pipeline_execution,workflow,Nextflow,https://github.com/CRG-CNAG/CalliNGS-NF,,MPL-2.0,bioinformatics;nextflow;variant-calling;rna-seq;gatk
588,ClarityNLP,NLP framework for clinical phenotyping and medical data extraction,ClarityNLP is a Natural Language Processing (NLP) framework specifically designed for clinical phenotyping and extracting information from unstructured medical notes. It integrates with OMOP Common Data Model and Solr to enable researchers to build queries and pipelines for identifying patient cohorts and clinical features.,D1;D1-04,clinical_nlp;phenotyping;information_extraction,platform,Jupyter Notebook,https://github.com/ClarityNLP/ClarityNLP,http://claritynlp.readthedocs.io/en/latest/,MPL-2.0,clinical-nlp;phenotyping;omop;healthcare;text-mining
589,Toil,"Scalable, efficient, cross-platform workflow engine for scientific pipelines","Toil is a workflow engine written in pure Python that supports WDL, CWL, and Python workflows. It is designed for scalability and is widely used in genomics and bioinformatics for orchestrating complex analysis pipelines across cloud and local environments.",D1;D1-04,workflow_orchestration;pipeline_management,workflow,Python,https://github.com/DataBiosphere/toil,https://toil.readthedocs.io/,Apache-2.0,workflow-engine;wdl;cwl;bioinformatics;genomics
590,ETL-Connector-for-ODK,QGIS plugin to connect and retrieve data from ODK instances,"A QGIS plugin that serves as a connector to Open Data Kit (ODK) instances, allowing researchers to retrieve field survey forms and load them directly into QGIS as shapefiles, geopackages, or CSVs for geospatial analysis.",D1;D1-04,data_ingestion;geospatial_analysis,library,Python,https://github.com/DemevengDerrick/ETL-Connector-for-ODK,https://plugins.qgis.org/plugins/odkconnector2/,GPL-3.0,qgis-plugin;odk;field-data;gis;etl
591,fold_tree,Snakemake pipeline for creating phylogenetic trees from sequences,"A bioinformatics pipeline implemented in Snakemake that automates the process of creating phylogenetic trees from sets of biological sequences, facilitating evolutionary biology research.",D1;D1-04,phylogenetics;sequence_analysis,workflow,Jupyter Notebook,https://github.com/DessimozLab/fold_tree,,MIT,snakemake;phylogeny;bioinformatics;pipeline
592,VIRify,Pipeline for detection of phages and eukaryotic viruses,A bioinformatics pipeline designed for the detection and classification of bacteriophages and eukaryotic viruses from metagenomic and metatranscriptomic assembly data.,D1;D1-04,viral_detection;metagenomics,workflow,Python,https://github.com/EBI-Metagenomics/emg-viral-pipeline,,Apache-2.0,metagenomics;virology;bioinformatics;pipeline
593,REAT,Robust Eukaryotic Annotation Toolkit,"A toolkit designed for the robust annotation of eukaryotic genomes, providing workflows and utilities to improve the quality and consistency of genomic feature annotation.",D1;D1-04,genome_annotation;genomics,solver,Python,https://github.com/EI-CoreBioinformatics/reat,,MIT,genome-annotation;eukaryotes;bioinformatics
594,caper,Python wrapper and manager for Cromwell workflow engine,"A Python wrapper for the Cromwell workflow engine, developed by the ENCODE DCC. It simplifies the running of WDL workflows on various backends (Cloud, HPC) and manages workflow configurations.",D1;D1-04,workflow_management;pipeline_execution,workflow,Python,https://github.com/ENCODE-DCC/caper,,MIT,cromwell;wdl;encode;workflow-manager
595,croo,Output organizer for Cromwell workflows,"A utility tool designed to organize and structure the outputs generated by Cromwell workflows, making it easier to manage and interpret results from large-scale genomic analyses.",D1;D1-04,data_organization;workflow_utility,library,Python,https://github.com/ENCODE-DCC/croo,,MIT,cromwell;wdl;encode;data-management
596,precisionFDA,Platform for benchmarking and validating NGS analysis pipelines,"A cloud-based platform and environment that enables the community to test, pilot, and benchmark new approaches for validating next-generation sequencing (NGS) analysis pipelines and bioinformatics tools.",D1;D1-04,benchmarking;ngs_analysis,platform,TypeScript,https://github.com/FDA/precisionFDA,https://precision.fda.gov/,CC0-1.0,ngs;benchmarking;bioinformatics;fda
597,MAG_Snakemake_wf,Workflow for recovery of prokaryotic genomes from metagenomes,"A Snakemake workflow designed for the recovery of prokaryotic genomes (Metagenome-Assembled Genomes, MAGs) from shotgun metagenomic sequencing data.",D1;D1-04,genome_assembly;metagenomics,workflow,HTML,https://github.com/Finn-Lab/MAG_Snakemake_wf,,NOASSERTION,snakemake;metagenomics;mag;bioinformatics
598,redundans,Pipeline for assembly of heterozygous/polymorphic genomes,"A pipeline that assists in the assembly of heterozygous or polymorphic genomes by reducing redundancy and scaffolding contigs, particularly useful for complex eukaryotic genomes.",D1;D1-04,genome_assembly;genomics,workflow,C++,https://github.com/Gabaldonlab/redundans,,GPL-3.0,genome-assembly;heterozygosity;bioinformatics
599,sv-callers,Snakemake workflow for detecting structural variants,"A Snakemake-based workflow that integrates multiple tools for detecting structural variants in genomic data, developed by the GooglingTheCancerGenome project.",D1;D1-04,variant_calling;genomics,workflow,Python,https://github.com/GooglingTheCancerGenome/sv-callers,,Apache-2.0,structural-variants;snakemake;cancer-genomics;bioinformatics
600,aiida-fleur,AiiDA plugin for the FLEUR DFT code,"A plugin for the AiiDA workflow engine that interfaces with the FLEUR code, enabling high-throughput density functional theory (DFT) calculations and electronic structure analysis.",D1;D1-04,material_science;dft_calculation,library,Python,https://github.com/JuDFTteam/aiida-fleur,https://aiida-fleur.readthedocs.io/,NOASSERTION,aiida;dft;material-science;fleur;workflow-plugin
601,aiida-kkr,AiiDA plugin for the JuKKR KKR code,"A plugin for the AiiDA workflow engine that interfaces with the JuKKR (Korringa-Kohn-Rostoker) code, facilitating high-throughput electronic structure calculations in materials science.",D1;D1-04,material_science;dft_calculation,library,Python,https://github.com/JuDFTteam/aiida-kkr,https://aiida-kkr.readthedocs.io/,MIT,aiida;kkr;material-science;dft;workflow-plugin
602,pytest-workflow,Test framework for bioinformatics workflows and pipelines,"A pytest plugin designed to test computational pipelines (e.g., Nextflow, Snakemake, WDL) by running them and verifying their outputs, widely used in bioinformatics engineering.",D1;D1-04,pipeline_testing;workflow_verification,library,Python,https://github.com/LUMC/pytest-workflow,https://pytest-workflow.readthedocs.io/,AGPL-3.0,testing;bioinformatics;workflow;pipeline
603,BioJupies,Automated generation of bioinformatics Jupyter Notebooks,"A web-based tool and framework that automatically generates tailored Jupyter Notebooks for RNA-seq data analysis, facilitating reproducible bioinformatics research.",D1;D1-04,workflow_generation;rna_seq_analysis,platform,HTML,https://github.com/MaayanLab/biojupies,https://biojupies.cloud/,NOASSERTION,bioinformatics;jupyter-notebook;rna-seq;automation
604,MetONTIIME,Meta-barcoding pipeline for ONT data analysis,A bioinformatics pipeline built with Nextflow for analyzing Oxford Nanopore Technologies (ONT) meta-barcoding data within the QIIME2 framework.,D1;D1-04,metabarcoding;sequence_analysis,workflow,Nextflow,https://github.com/MaestSi/MetONTIIME,,GPL-3.0,bioinformatics;nextflow;qiime2;nanopore
605,MapGIS Client for JavaScript,Web client SDK for MapGIS geospatial platform,"A JavaScript development platform for Cloud GIS, integrating visualization libraries like Echarts and D3 for efficient visual expression and analysis of geospatial big data.",D1;D1-04,geospatial_visualization;gis_analysis,library,HTML,https://github.com/MapGIS/WebClient-JavaScript,http://develop.smaryun.com/,Apache-2.0,gis;visualization;geospatial;web-client
606,Express.jl,Workflow framework for ab initio materials science calculations,"A high-level, extensible workflow framework written in Julia for automating and accelerating ab initio calculations in materials science, specifically designed for Quantum ESPRESSO.",D1;D1-04,ab_initio_calculation;workflow_automation,workflow,Julia,https://github.com/MineralsCloud/Express.jl,https://mineralscloud.github.io/Express.jl/dev/,GPL-3.0,materials-science;workflow;julia;quantum-espresso
607,pgsc_calc,Polygenic Score Catalog Calculator pipeline,"A Nextflow pipeline for calculating polygenic scores (PGS) using the PGS Catalog, handling data download, harmonization, and scoring.",D1;D1-04,polygenic_scoring;genomics_pipeline,workflow,Nextflow,https://github.com/PGScatalog/pgsc_calc,https://pgsc-calc.readthedocs.io/,Apache-2.0,bioinformatics;genomics;polygenic-scores;nextflow
608,HiFi-16S-workflow,PacBio HiFi 16S rRNA analysis pipeline,"A Nextflow pipeline specifically designed for analyzing PacBio HiFi full-length 16S rRNA sequencing data, including quality control and taxonomy assignment.",D1;D1-04,16s_rrna_analysis;metagenomics,workflow,Nextflow,https://github.com/PacificBiosciences/HiFi-16S-workflow,,BSD-3-Clause-Clear,bioinformatics;pacbio;16s;microbiome
609,bionix,Reproducible bioinformatics pipelines using Nix,"A library for building functional, highly reproducible bioinformatics pipelines using the Nix package manager, ensuring consistent environments and execution.",D1;D1-04,workflow_management;reproducibility,workflow,Nix,https://github.com/PapenfussLab/bionix,https://bionix.readthedocs.io/,BSD-3-Clause,bioinformatics;nix;reproducibility;pipeline
610,ReAdW,Thermo Raw to mzXML converter,"A command-line tool for converting Thermo Finnigan RAW mass spectrometry data files into the open mzXML format, facilitating downstream proteomics analysis.",D1;D1-04,format_conversion;mass_spectrometry,solver,C,https://github.com/PedrioliLab/ReAdW,,LGPL-3.0,mass-spectrometry;proteomics;file-conversion;mzxml
611,PyPSA-Eur,Sector-coupled open optimisation model of the European energy system,PyPSA-Eur is an open model dataset and workflow of the European power system at the transmission network level. It covers the full ENTSO-E area and is designed for energy system optimization and modeling.,D1-04,energy_system_modeling;optimization,workflow,Python,https://github.com/PyPSA/pypsa-eur,https://pypsa-eur.readthedocs.io,None,energy-systems;optimization;snakemake;power-grid
612,VesselExpress,Automated blood vasculature analysis of 3D light-sheet image volumes,"A pipeline for the automated analysis of blood vasculature in 3D Light-Sheet Microscopy image volumes, facilitating the study of vascular structures in biological samples.",D1-04,image_analysis;vasculature_segmentation,solver,Python,https://github.com/RUB-Bioinf/VesselExpress,,GPL-3.0,bioimaging;light-sheet-microscopy;vasculature;3d-imaging
613,TlseHypDataSet,Data loader for the Toulouse Hyperspectral Data Set,"A Python library designed to flexibly load PyTorch datasets and facilitate machine learning experiments specifically on the Toulouse Hyperspectral Data Set, aiding in remote sensing research.",D1,data_loading;hyperspectral_imaging,library,Python,https://github.com/Romain3Ch216/TlseHypDataSet,,NOASSERTION,hyperspectral;remote-sensing;pytorch;data-loader
614,inphared,Phage genome databases and bioinformatics pipeline utilities,"Provides up-to-date phage genome databases, metrics, and input files to support various bioinformatic pipelines focused on bacteriophage research.",D1;D1-04,genome_analysis;database_construction,workflow,Perl,https://github.com/RyanCook94/inphared,,AGPL-3.0,bacteriophage;genomics;bioinformatics;database
615,reticulatus,Pipeline for assembling and polishing long genomes from nanopore reads,"A Snakemake-based pipeline designed for the assembly and polishing of long genomes using long nanopore sequencing reads, streamlining the genomic assembly workflow.",D1-04,genome_assembly;nanopore_sequencing,workflow,Python,https://github.com/SamStudio8/reticulatus,,MIT,genome-assembly;nanopore;snakemake;bioinformatics
616,tf-WSI-dataset-utils,Pipeline for Whole Slide Image (WSI) data in Tensorflow,"An optimized pipeline and utility set for working with Whole Slide Image (WSI) data within the Tensorflow framework, facilitating digital pathology and bioimaging analysis.",D1-04,image_processing;whole_slide_imaging,library,Python,https://github.com/SarderLab/tf-WSI-dataset-utils,,GPL-3.0,digital-pathology;wsi;tensorflow;bioimaging
617,ilus,Variant calling pipeline generator for WGS/WES data,"A lightweight pipeline generator for Whole Genome Sequencing (WGS) and Whole Exome Sequencing (WES) data analysis, utilizing GATK and Sentieon for variant calling.",D1-04,variant_calling;pipeline_generation,workflow,Python,https://github.com/ShujiaHuang/ilus,,GPL-3.0,variant-calling;gatk;wgs;wes;bioinformatics
618,SingleRust,High-throughput single-cell analysis pipeline in Rust,"A tool for single-cell analysis leveraging Rust's concurrency for scalable, high-throughput pipelines, aiming to improve performance in single-cell genomics workflows.",D1-04,single_cell_analysis;clustering,solver,Rust,https://github.com/SingleRust/SingleRust,,BSD-3-Clause,single-cell;rust;bioinformatics;high-throughput
619,ACES,Workflow for querying small sequences in large genome sets with phylogenetic analysis,"ACES is a bioinformatics workflow designed to query small sequences against a large set of genomes. It automates the process of BLAST searching, multiple sequence alignment, fragment assembly, and phylogenetic tree construction.",D1;D1-04,sequence_alignment;phylogenetic_analysis;workflow_orchestration,workflow,Python,https://github.com/TNTurnerLab/ACES,,MIT,bioinformatics;genomics;phylogenetics;blast
620,aiida-champ,AiiDA plugin for the CHAMP Quantum Monte Carlo code,"A plugin for the AiiDA workflow engine that interfaces with CHAMP (Cornell-Holland Ab-initio Materials Package), enabling the automation and provenance tracking of Quantum Monte Carlo simulations.",D1;D1-04,simulation_interface;workflow_orchestration;quantum_monte_carlo,library,Python,https://github.com/TREX-CoE/aiida-champ,,MIT,aiida;materials-science;qmc;workflow
621,aiida-qp2,AiiDA plugin for Quantum Package 2.0,"An AiiDA plugin designed to interface with Quantum Package 2.0, facilitating the orchestration of quantum chemistry calculations and managing data provenance within the AiiDA ecosystem.",D1;D1-04,simulation_interface;workflow_orchestration;quantum_chemistry,library,Python,https://github.com/TREX-CoE/aiida-qp2,,MIT,aiida;quantum-chemistry;workflow
622,Earl Grey,Fully automated transposable element curation and annotation pipeline,"Earl Grey is a comprehensive pipeline for the automated curation and annotation of transposable elements (TEs) in eukaryotic genomes, streamlining the identification and classification process.",D1;D1-04,genome_annotation;transposable_elements;pipeline,workflow,Python,https://github.com/TobyBaril/EarlGrey,https://github.com/TobyBaril/EarlGrey,NOASSERTION,bioinformatics;genomics;transposable-elements;annotation
623,snk,CLI generation tool for Snakemake workflows,"Snk is a utility that automatically generates Command Line Interfaces (CLIs) for Snakemake workflows, making scientific pipelines easier to distribute, install, and run as standalone applications.",D1;D1-04,workflow_management;pipeline_deployment,tool,Python,https://github.com/Wytamma/snk,,MIT,snakemake;workflow;cli;reproducibility
624,cLoops,Accurate and flexible loops calling tool for 3D genomic data,"cLoops is a tool designed for calling loops in 3D genomic data (such as ChIA-PET, Hi-C, and HiChIP). It uses a clustering-based approach to identify significant interactions in chromatin structure.",D1;D1-04,3d_genomics;loop_calling;data_analysis,solver,Python,https://github.com/YaqiangCao/cLoops,,MIT,bioinformatics;hi-c;chromatin-loops;genomics
625,HemTools,Collection of NGS pipelines and bioinformatic analyses,"HemTools provides a suite of pipelines and tools for Next-Generation Sequencing (NGS) data analysis, specifically tailored for hematology and general bioinformatics tasks, including ChIP-seq, RNA-seq, and CRISPR screening analysis.",D1;D1-04,ngs_analysis;pipeline;data_processing,workflow,Python,https://github.com/YichaoOU/HemTools,https://hemtools.readthedocs.io/,None,bioinformatics;ngs;pipeline;crispr
626,veridical-flow,Framework for building trustworthy data-science pipelines based on PCS,"Veridical Flow is a Python tool that implements the PCS (Predictability, Computability, Stability) framework to help researchers build stable and trustworthy data science pipelines, facilitating rigorous data analysis and validation.",D1;D1-04,data_validation;pipeline_stability;reproducibility,library,Jupyter Notebook,https://github.com/Yu-Group/veridical-flow,,MIT,data-science;pcs-framework;pipeline;statistics
627,ProteinFlow,Pipeline for processing protein structure data for deep learning,"ProteinFlow is a versatile computational pipeline designed to process protein structure data (e.g., from PDB) into formats suitable for deep learning applications. It handles filtering, clustering, and feature extraction for protein modeling.",D1;D1-04,data_preprocessing;protein_structure;deep_learning_prep,workflow,Python,https://github.com/adaptyvbio/ProteinFlow,https://proteinflow.readthedocs.io/,BSD-3-Clause,protein-structure;deep-learning;bioinformatics;dataset
628,aiida-cusp,Custodian based VASP Plugin for AiiDA,"AiiDA-CUSP is a plugin for the AiiDA workflow engine that integrates VASP calculations with Custodian-based error handling and recovery, designed for high-throughput materials science simulations.",D1;D1-04,simulation_interface;error_correction;workflow_orchestration,library,Python,https://github.com/aiida-cusp/aiida-cusp,https://aiida-cusp.readthedocs.io/,MIT,aiida;vasp;materials-science;custodian
629,aiida-phonopy,AiiDA plugin for phonon calculations using Phonopy,A plugin for AiiDA that interfaces with Phonopy to automate phonon calculations. It enables the calculation of vibrational properties of materials within a reproducible workflow environment.,D1;D1-04,simulation_interface;phonon_calculation;workflow_orchestration,library,Python,https://github.com/aiida-phonopy/aiida-phonopy,,MIT,aiida;phonopy;materials-science;phonons
630,aiida-trains-pot,AiiDA workflow for training neural network interatomic potentials,"An AiiDA workflow that implements an automated active learning scheme to train neural network interatomic potentials, facilitating the development of machine learning force fields for materials simulations.",D1;D1-04,ml_potential_training;active_learning;workflow_orchestration,workflow,Python,https://github.com/aiida-trieste-developers/aiida-trains-pot,,NOASSERTION,aiida;machine-learning;interatomic-potentials;materials-science
631,aiida-vasp,AiiDA plugin for running VASP simulations,"The official AiiDA plugin for the Vienna Ab initio Simulation Package (VASP). It provides a robust interface for setting up, running, and parsing VASP calculations within the AiiDA provenance graph.",D1;D1-04,simulation_interface;workflow_orchestration;dft,library,Python,https://github.com/aiida-vasp/aiida-vasp,https://aiida-vasp.readthedocs.io/,NOASSERTION,aiida;vasp;dft;materials-science
632,AiiDAlab,Web platform for AiiDA workflows and applications,AiiDAlab is a web-based platform that provides a user-friendly environment for running AiiDA workflows. It allows users to access computational science tools through a graphical interface in Jupyter notebooks.,D1;D1-04,workflow_platform;gui;scientific_computing,platform,Python,https://github.com/aiidalab/aiidalab,https://aiidalab.readthedocs.io/,MIT,aiida;jupyter;workflow-platform;materials-science
633,aiidalab-qe,AiiDAlab application for Quantum ESPRESSO,"An application for the AiiDAlab platform that provides a graphical user interface for running Quantum ESPRESSO calculations, making DFT simulations accessible to non-experts.",D1;D1-04,simulation_gui;dft;workflow_interface,solver,Python,https://github.com/aiidalab/aiidalab-qe,,MIT,aiidalab;quantum-espresso;dft;gui
634,aiida-ase,AiiDA plugin for the Atomic Simulation Environment (ASE),"A plugin that integrates the Atomic Simulation Environment (ASE) with AiiDA, allowing users to use ASE calculators and structures within AiiDA workflows for materials science simulations.",D1;D1-04,simulation_interface;structure_manipulation;workflow_orchestration,library,Python,https://github.com/aiidaplugins/aiida-ase,,MIT,aiida;ase;materials-science;interoperability
635,aiida-lammps,AiiDA plugin for LAMMPS molecular dynamics,"A plugin for AiiDA to interface with LAMMPS, enabling the automation of Molecular Dynamics simulations and the management of force fields and trajectories within AiiDA.",D1;D1-04,simulation_interface;molecular_dynamics;workflow_orchestration,library,Python,https://github.com/aiidaplugins/aiida-lammps,https://aiida-lammps.readthedocs.io/,MIT,aiida;lammps;molecular-dynamics;materials-science
636,aiida-common-workflows,Common workflow interfaces for materials science codes in AiiDA,"A library that defines and implements common interfaces for workflows across different quantum engines (like VASP, QE, Siesta) in AiiDA, enabling code-agnostic simulation protocols.",D1;D1-04,workflow_standardization;interoperability;simulation_interface,library,Python,https://github.com/aiidateam/aiida-common-workflows,https://aiida-common-workflows.readthedocs.io/,MIT,aiida;workflows;standardization;materials-science
637,AiiDA,Automated Interactive Infrastructure and Database for Computational Science,"AiiDA is a flexible and scalable informatics infrastructure to manage, preserve, and disseminate computational data and workflows. It provides a workflow engine with provenance tracking for high-throughput computational science.",D1;D1-04,workflow_management;provenance_tracking;high_throughput_computing,platform,Python,https://github.com/aiidateam/aiida-core,https://www.aiida.net/,MIT,workflow-engine;materials-science;provenance;hpc
638,AiiDA-CP2K,AiiDA plugin for the CP2K quantum chemistry and solid state physics software,"A plugin connecting the AiiDA workflow engine with CP2K, enabling automated atomistic simulations and electronic structure calculations with provenance tracking.",D1;D1-04,simulation_connector;electronic_structure,library,Python,https://github.com/aiidateam/aiida-cp2k,https://aiida-cp2k.readthedocs.io/,MIT,cp2k;dft;molecular-dynamics;aiida-plugin
639,AiiDA-Hubbard,Workflows for self-consistent Hubbard parameters from first-principles,"A plugin for AiiDA that provides workflows to calculate onsite and intersite Hubbard U and V parameters using linear response theory (DFPT), primarily for Quantum ESPRESSO.",D1;D1-04,parameter_estimation;electronic_structure,workflow,Python,https://github.com/aiidateam/aiida-hubbard,,NOASSERTION,dft+u;hubbard-parameters;quantum-espresso;materials-science
640,AiiDA-HyperQueue,AiiDA plugin for the HyperQueue metascheduler,"A scheduler plugin for AiiDA that interfaces with HyperQueue, allowing for efficient task scheduling on HPC clusters within scientific workflows.",D1;D1-04,job_scheduling;hpc_connector,library,Python,https://github.com/aiidateam/aiida-hyperqueue,,MIT,hpc;scheduling;hyperqueue;aiida-plugin
641,AiiDA-Project,Project management utility for AiiDA,"A command-line tool to manage AiiDA projects, facilitating the organization and switching between different scientific research contexts and datasets.",D1;D1-04,project_management;workflow_utility,solver,Python,https://github.com/aiidateam/aiida-project,,NOASSERTION,project-management;cli;aiida-utility
642,AiiDA-QuantumESPRESSO,Official AiiDA plugin for Quantum ESPRESSO,"The official plugin to interface AiiDA with the Quantum ESPRESSO suite, enabling automated, reproducible density functional theory (DFT) calculations and workflows.",D1;D1-04,simulation_connector;electronic_structure,library,Python,https://github.com/aiidateam/aiida-quantumespresso,https://aiida-quantumespresso.readthedocs.io/,NOASSERTION,quantum-espresso;dft;materials-science;aiida-plugin
643,AiiDA-Shell,Plugin to run arbitrary shell commands within AiiDA workflows,"A utility plugin that allows users to run any shell command or executable as an AiiDA process, automatically capturing provenance and outputs without writing a full plugin.",D1;D1-04,workflow_utility;provenance_tracking,library,Python,https://github.com/aiidateam/aiida-shell,,MIT,shell;provenance;automation;aiida-plugin
644,AiiDA-Submission-Controller,Utility for managing large-scale AiiDA process submissions,"A library providing classes to manage and throttle the submission of large numbers of processes in AiiDA, useful for high-throughput screening studies.",D1;D1-04,high_throughput_computing;workflow_control,library,Python,https://github.com/aiidateam/aiida-submission-controller,,MIT,high-throughput;batch-processing;aiida-utility
645,AiiDA-Wannier90,AiiDA plugin for the Wannier90 code,"A plugin connecting AiiDA with Wannier90, enabling the calculation of Maximally Localized Wannier Functions (MLWFs) within automated workflows.",D1;D1-04,simulation_connector;electronic_structure,library,Python,https://github.com/aiidateam/aiida-wannier90,https://aiida-wannier90.readthedocs.io/,NOASSERTION,wannier90;wannier-functions;materials-science;aiida-plugin
646,AiiDA-Wannier90-Workflows,Automated workflows for Wannier90 calculations,"A collection of advanced, automated workflows for computing Wannier functions and related properties using AiiDA and Wannier90, designed to minimize user intervention.",D1;D1-04,workflow_automation;electronic_structure,workflow,Python,https://github.com/aiidateam/aiida-wannier90-workflows,,NOASSERTION,wannier90;automation;workflows;materials-science
647,AiiDA-WorkGraph,Interactive GUI and workflow manager for AiiDA,"A tool to design and manage flexible AiiDA workflows efficiently, featuring an interactive GUI, checkpoints, and remote execution capabilities.",D1;D1-04,workflow_design;gui,workflow,Python,https://github.com/aiidateam/aiida-workgraph,https://aiida-workgraph.readthedocs.io/,MIT,gui;workflow-management;visual-programming;aiida-plugin
648,BindFlow,Snakemake workflow for FEP and MM(PB/GB)SA calculations,A Snakemake-based automated workflow for performing Free Energy Perturbation (FEP) and MM/PBSA or MM/GBSA calculations using GROMACS.,D1;D1-04,molecular_dynamics;free_energy_calculation,workflow,Python,https://github.com/ale94mleon/BindFlow,,GPL-3.0,gromacs;snakemake;free-energy;molecular-dynamics
649,scispacy,spaCy pipeline and models for scientific/biomedical documents,"A Python package containing spaCy pipelines and models specifically designed for processing biomedical, scientific, and clinical text, enabling entity recognition and linking in scientific literature.",D1;D1-04,natural_language_processing;text_mining,library,Python,https://github.com/allenai/scispacy,https://allenai.github.io/scispacy/,Apache-2.0,nlp;biomedical;spacy;text-mining
650,FlowCraft,Component-based pipeline composer for omics analysis using Nextflow,FlowCraft is a tool for building Nextflow pipelines specifically for omics data analysis. It allows researchers to assemble various bioinformatics components into a coherent workflow for processing biological data.,D1;D1-04,pipeline_composition;omics_analysis,workflow,Python,https://github.com/assemblerflow/flowcraft,,GPL-3.0,nextflow;omics;bioinformatics;pipeline-builder
651,Bactopia,A flexible pipeline for complete analysis of bacterial genomes,"Bactopia is an extensive workflow for processing bacterial genome data. It integrates numerous bioinformatics tools to perform quality control, assembly, annotation, and variant calling, specifically tailored for bacterial genomics.",D1;D1-04,genome_assembly;variant_calling;bacterial_genomics,workflow,Nextflow,https://github.com/bactopia/bactopia,https://bactopia.github.io/,MIT,bacteria;genomics;nextflow;bioinformatics-pipeline
652,BEDOPS,High-performance genomic feature operations and set statistics,"A highly scalable and fast toolkit for performing set operations (intersection, union, difference) on genomic interval data (BED files), essential for genomic analysis pipelines.",D1;D1-04,genomic_interval_manipulation;data_processing,solver,C,https://github.com/bedops/bedops,https://bedops.readthedocs.io/,NOASSERTION,genomics;bioinformatics;bed-files;set-operations
653,TOmicsVis,Transcriptomics visualization and analysis R package,"An R package designed for the visualization and analysis of transcriptomics data, providing ready-to-use plotting functions for scientific publications.",D1;D1-04,visualization;transcriptomics_analysis,library,R,https://github.com/benben-miao/TOmicsVis,,GPL-2.0,transcriptomics;visualization;r-package;bioinformatics
654,kraken2_classification,Snakemake workflow for metagenomic classification using Kraken2,A reproducible Snakemake workflow designed to perform taxonomic classification of metagenomic sequences using the Kraken2 engine.,D1;D1-04,metagenomics;taxonomic_classification,workflow,Python,https://github.com/bhattlab/kraken2_classification,,None,metagenomics;snakemake;kraken2;bioinformatics
655,ABFE_workflow,High-throughput Absolute Binding Free Energy calculation workflow,"A Snakemake-based workflow for automating Absolute Binding Free Energy (ABFE) calculations, designed for scalability on HPC clusters.",D1;D1-04,molecular_dynamics;free_energy_calculation,workflow,Python,https://github.com/bigginlab/ABFE_workflow,,GPL-3.0,computational-chemistry;molecular-dynamics;snakemake;drug-discovery
656,Master of Pores,Nextflow pipeline for direct RNA Nanopore sequencing analysis,"A comprehensive Nextflow pipeline for processing and analyzing direct RNA sequencing data from Oxford Nanopore Technologies, including preprocessing, mapping, and modification detection.",D1;D1-04,rna_sequencing_analysis;nanopore_processing,workflow,Nextflow,https://github.com/biocorecrg/master_of_pores,https://biocorecrg.github.io/master_of_pores/,MIT,nanopore;rna-seq;nextflow;bioinformatics
657,Taska,Workflow management system for biomedical exploration,A workflow management tool specifically designed to support biomedical research and exploration tasks.,D1;D1-04,workflow_management;biomedical_research,platform,JavaScript,https://github.com/bioinformatics-ua/taska,,GPL-3.0,workflow-manager;biomedical;bioinformatics
658,Cromshell,CLI for interacting with Cromwell scientific workflow servers,"A command-line interface tool for submitting workflows, checking status, and retrieving metadata from a Cromwell server, facilitating scientific workflow management.",D1;D1-04,workflow_management;job_submission,solver,Python,https://github.com/broadinstitute/cromshell,,BSD-3-Clause,cromwell;wdl;bioinformatics;workflow-cli
659,Cromwell,Scientific workflow engine for WDL and CWL,"A workflow management system geared towards scientific workflows, supporting WDL (Workflow Description Language) and CWL (Common Workflow Language), widely used in genomics and bioinformatics.",D1;D1-04,workflow_execution;pipeline_orchestration,platform,Scala,https://github.com/broadinstitute/cromwell,https://cromwell.readthedocs.io/,BSD-3-Clause,workflow-engine;wdl;cwl;bioinformatics;genomics
660,Cromwell-tools,Python clients and utilities for Cromwell workflow engine,"A collection of Python libraries and scripts to interact with the Cromwell workflow engine, enabling programmatic submission and monitoring of scientific workflows.",D1;D1-04,workflow_management;api_client,library,Python,https://github.com/broadinstitute/cromwell-tools,https://cromwell-tools.readthedocs.io/,BSD-3-Clause,cromwell;python-client;bioinformatics;workflow
661,GATK-SV,Structural variation discovery pipeline for short-read sequencing,"A comprehensive pipeline for detecting structural variations (SV) from short-read sequencing data, developed by the Broad Institute.",D1;D1-04,structural_variation_calling;genomics_pipeline,workflow,Python,https://github.com/broadinstitute/gatk-sv,,BSD-3-Clause,genomics;structural-variation;gatk;bioinformatics
662,Widdler,CLI for managing WDL workflows on Cromwell,"A command-line tool for executing, validating, and querying WDL workflows on Cromwell servers, providing an alternative interface for workflow management.",D1;D1-04,workflow_management;wdl_execution,solver,Python,https://github.com/broadinstitute/widdler,,None,wdl;cromwell;bioinformatics;cli
663,V-pipe,Bioinformatics pipeline for viral genome analysis,"A bioinformatics pipeline integrating various tools for the analysis of next-generation sequencing (NGS) data from short viral genomes, used for variant calling and haplotype reconstruction.",D1;D1-04,viral_genomics;variant_calling;haplotype_reconstruction,workflow,Jupyter Notebook,https://github.com/cbg-ethz/V-pipe,https://cbg-ethz.github.io/V-pipe/,Apache-2.0,virology;ngs;bioinformatics;pipeline
664,GraffiTE,Pipeline for detecting polymorphic transposable elements in genome assemblies,"GraffiTE is a computational pipeline designed to identify polymorphic transposable elements (TEs) in genome assemblies and long reads. It genotypes discovered polymorphisms using genome-graphs, facilitating the study of structural variations in genomics.",D1;D1-04,variant_calling;genome_assembly_analysis,workflow,R,https://github.com/cgroza/GraffiTE,,NOASSERTION,genomics;transposable-elements;structural-variation;pipeline
665,wdl-cell-ranger,WDL workflows for running Cell Ranger single-cell analysis pipelines,A collection of Workflow Description Language (WDL) tasks and workflows for running 10x Genomics Cell Ranger pipelines. It enables scalable execution of single-cell RNA-seq data processing on Cromwell-compatible infrastructure.,D1;D1-04,scRNA-seq_processing;pipeline_orchestration,workflow,Python,https://github.com/chanzuckerberg/wdl-cell-ranger,,MIT,single-cell;wdl;cell-ranger;bioinformatics-workflow
666,CompareM2,Microbial genomes-to-report pipeline for comparative genomics,"A comprehensive pipeline for processing microbial genomes to generate comparative reports. It automates steps likely including quality control, taxonomic classification, and functional annotation for microbial research.",D1;D1-04,comparative_genomics;microbial_analysis,workflow,Python,https://github.com/cmkobel/CompareM2,,GPL-3.0,microbiology;genomics;pipeline;comparative-analysis
667,ncov2019-artic-nf,Nextflow pipeline for SARS-CoV-2 ARTIC field bioinformatics,"A Nextflow pipeline implementing the ARTIC network's field bioinformatics protocol for SARS-CoV-2 sequencing data. It handles alignment, variant calling, and consensus sequence generation for viral genomics.",D1;D1-04,viral_genomics;variant_calling;consensus_generation,workflow,Nextflow,https://github.com/connor-lab/ncov2019-artic-nf,,AGPL-3.0,covid-19;nextflow;bioinformatics;artic-network
668,pyflow-ATACseq,Snakemake pipeline for ATAC-seq data analysis,"A Snakemake-based bioinformatics pipeline for processing ATAC-seq data. It automates steps from raw reads to peak calling and quality control, facilitating chromatin accessibility studies.",D1;D1-04,atac-seq_analysis;pipeline_orchestration,workflow,Python,https://github.com/crazyhottommy/pyflow-ATACseq,,MIT,atac-seq;snakemake;bioinformatics;epigenetics
669,pyflow-ChIPseq,Snakemake pipeline for ChIP-seq data analysis,"A Snakemake workflow for analyzing ChIP-seq data, handling alignment, peak calling, and QC. Designed to process data from GEO or local sources for epigenomic research.",D1;D1-04,chip-seq_analysis;pipeline_orchestration,workflow,Python,https://github.com/crazyhottommy/pyflow-ChIPseq,,MIT,chip-seq;snakemake;bioinformatics;epigenetics
670,WISC_MVPA,Workflow for Whole-brain Imaging with Sparse Correlations (MVPA),A High Throughput Computing (HTC) workflow for performing Multi-Voxel Pattern Analysis (MVPA) on whole-brain imaging data. It is designed for neuroscience research involving fMRI data analysis.,D1;D1-04,neuroimaging_analysis;mvpa,workflow,MATLAB,https://github.com/crcox/WISC_MVPA,,None,neuroscience;fmri;mvpa;matlab
671,ARMOR,Automated Reproducible MOdular RNA-seq workflow,"A light-weight Snakemake workflow for preprocessing and statistical analysis of RNA-seq data. It integrates tools like Salmon, edgeR, and DRIMSeq to provide a complete analysis pipeline from reads to results.",D1;D1-04,rna-seq_analysis;differential_expression,workflow,R,https://github.com/csoneson/ARMOR,,MIT,rna-seq;snakemake;bioinformatics;transcriptomics
672,Cylc,Workflow engine for cycling systems in meteorology and climate science,"Cylc is a workflow engine designed specifically for cycling systems, widely used in operational weather forecasting and climate modeling (e.g., by the Met Office). It handles complex dependencies in infinite cycling workflows.",D1;D1-04,workflow_orchestration;climate_modeling,platform,Python,https://github.com/cylc/cylc-flow,https://cylc.org/,GPL-3.0,meteorology;workflow-engine;climate-science;hpc
673,DeepChem,"Deep learning library for drug discovery, materials science, and quantum chemistry","DeepChem provides a high-quality open-source toolchain that democratizes the use of deep learning in drug discovery, materials science, quantum chemistry, and biology. It includes molecular featurizers (ETL), data loaders, and specialized model architectures.",D4;D1,drug_discovery;molecular_modeling;property_prediction,library,Python,https://github.com/deepchem/deepchem,https://deepchem.io,MIT,drug-discovery;cheminformatics;deep-learning;molecular-modeling
674,Dockstore,Platform for sharing scientific tools and workflows,"Dockstore is an open platform used by the GA4GH for sharing Docker-based scientific tools and workflows (CWL, WDL, Nextflow). It enables reproducibility and discovery of bioinformatics pipelines.",D1-04,workflow_sharing;reproducibility;tool_discovery,platform,Java,https://github.com/dockstore/dockstore,https://dockstore.org,Apache-2.0,bioinformatics;workflow;cwl;wdl;reproducibility
675,WDL Workspace,Web-based UI for running WDL bioinformatics workflows via Cromwell,A web interface designed to facilitate the execution and management of WDL-based bioinformatics workflows using the Cromwell server backend.,D1;D1-04,workflow_execution;bioinformatics_pipeline,platform,JavaScript,https://github.com/epam/wdl-workspace,,MIT,wdl;bioinformatics;cromwell;workflow-ui
676,aiida-defects,AiiDA plugin for point defect calculations in materials science,A plugin for the AiiDA workflow engine that provides automated workflows for calculating properties of point defects in materials.,D1;D1-04,defect_calculation;materials_modeling,workflow,Python,https://github.com/epfl-theos/aiida-defects,,MIT,aiida;materials-science;defects;workflow
677,MrBiomics,Modular bioinformatics pipeline framework for multi-omics analysis,"A framework providing composable modules and recipes to automate bioinformatics analyses for multi-omics data, built on top of Snakemake.",D1;D1-04,multi_omics_analysis;pipeline_framework,workflow,R,https://github.com/epigen/MrBiomics,,MIT,bioinformatics;multi-omics;snakemake;pipeline
678,atacseq_pipeline,Snakemake workflow for ATAC-seq data processing and quantification,"A comprehensive bioinformatics pipeline for processing, quantifying, and annotating ATAC-seq data, implemented as a MrBiomics module.",D1;D1-04,atac_seq_analysis;genomics_pipeline,workflow,Python,https://github.com/epigen/atacseq_pipeline,,MIT,atac-seq;snakemake;bioinformatics;ngs
679,dea_limma,Differential expression analysis workflow using Limma,A Snakemake workflow and MrBiomics module for performing differential expression analyses on NGS data using the R package limma.,D1;D1-04,differential_expression;transcriptomics,workflow,R,https://github.com/epigen/dea_limma,,MIT,limma;rna-seq;differential-expression;snakemake
680,enrichment_analysis,Genomic region and gene set enrichment analysis workflow,"A Snakemake workflow for performing enrichment analyses on genomic regions and gene sets using tools like LOLA, GREAT, and GSEApy.",D1;D1-04,enrichment_analysis;genomics,workflow,Python,https://github.com/epigen/enrichment_analysis,,MIT,gsea;enrichment;bioinformatics;snakemake
681,genome_tracks,Workflow for visualization of genome browser tracks,"A Snakemake workflow for generating and visualizing genome browser tracks from aligned BAM files (RNA-seq, ATAC-seq, etc.) using pyGenomeTracks and IGV.",D1;D1-04,genome_visualization;track_generation,workflow,Python,https://github.com/epigen/genome_tracks,,MIT,visualization;genome-browser;bam;snakemake
682,scrnaseq_processing_seurat,Single-cell RNA-seq processing workflow using Seurat,A Snakemake workflow for processing and visualizing single-cell/nuclei RNA-seq data (10X or MTX format) using the Seurat R package.,D1;D1-04,single_cell_analysis;scrnaseq,workflow,R,https://github.com/epigen/scrnaseq_processing_seurat,,MIT,scRNA-seq;seurat;bioinformatics;snakemake
683,unsupervised_analysis,Workflow for unsupervised dimensionality reduction and clustering,A general purpose Snakemake workflow for performing unsupervised analyses such as dimensionality reduction and cluster analysis on high-dimensional biological data.,D1;D1-04,dimensionality_reduction;clustering,workflow,Python,https://github.com/epigen/unsupervised_analysis,,MIT,clustering;pca;bioinformatics;snakemake
684,ClusterFlow,Pipeline tool for bioinformatics analyses on cluster environments,"A command-line tool designed to automate and standardize bioinformatics analyses on cluster environments, managing job submissions and dependencies.",D1;D1-04,workflow_management;bioinformatics_pipeline,workflow,Perl,https://github.com/ewels/clusterflow,http://clusterflow.io/,GPL-3.0,bioinformatics;pipeline;hpc;cluster
685,aiida-orca,AiiDA plugin for the ORCA quantum chemistry package,A plugin for the AiiDA workflow engine that interfaces with the ORCA software for quantum chemistry calculations.,D1;D1-04,quantum_chemistry;workflow_connector,solver,Python,https://github.com/ezpzbz/aiida-orca,,MIT,aiida;orca;quantum-chemistry;plugin
686,flowr,R-based workflow system for bioinformatics,"A robust and efficient workflow management system implemented in R, designed to streamline complex bioinformatics pipelines.",D1;D1-04,workflow_management;bioinformatics_pipeline,workflow,R,https://github.com/flow-r/flowr,http://docs.flowr.space,NOASSERTION,r;bioinformatics;workflow;pipeline
687,bacannot,Pipeline for prokaryotic genome annotation,"A comprehensive Nextflow pipeline for prokaryotic genome annotation and interrogation, including interactive reports.",D1;D1-04,genome_annotation;prokaryotic_genomics,workflow,Nextflow,https://github.com/fmalmeida/bacannot,,GPL-3.0,genome-annotation;nextflow;bacteria;bioinformatics
688,metaGEM,Workflow for generating genome-scale metabolic models from metagenomes,A pipeline for generating context-specific genome-scale metabolic models and predicting metabolic interactions within microbial communities directly from metagenomic data.,D1;D1-04,metabolic_modeling;metagenomics,workflow,Python,https://github.com/franciscozorrilla/metaGEM,,MIT,metagenomics;metabolic-modeling;systems-biology;workflow
689,dagr,Scala DSL for bioinformatics pipelines,A Scala-based DSL and framework for writing and executing bioinformatics pipelines as Directed Acyclic Graphs (DAGs).,D1;D1-04,workflow_definition;bioinformatics_pipeline,library,Scala,https://github.com/fulcrumgenomics/dagr,,MIT,scala;bioinformatics;pipeline;dsl
690,Galaxy,Open web-based platform for data intensive biomedical research,"A scientific workflow, data integration, and data and analysis persistence and publishing platform that aims to make computational biology accessible to research scientists that do not have computer programming experience.",D1;D1-04,workflow_platform;bioinformatics_analysis,platform,Python,https://github.com/galaxyproject/galaxy,https://galaxyproject.org/,NOASSERTION,bioinformatics;workflow;platform;reproducibility
691,hybracter,Automated long-read bacterial genome assembly pipeline,"A Snakemake pipeline for automated long-read first bacterial genome assembly, utilizing Snaketool for workflow management.",D1;D1-04,genome_assembly;bacterial_genomics,workflow,Python,https://github.com/gbouras13/hybracter,,MIT,genome-assembly;bacteria;snakemake;long-read
692,Cloudgene,Framework for building SaaS platforms for bioinformatics pipelines,"A framework to build Software As A Service (SaaS) platforms for data analysis pipelines, widely used for genetic imputation servers.",D1;D1-04,platform_building;genetics_pipeline,platform,Java,https://github.com/genepi/cloudgene,http://cloudgene.uibk.ac.at/,AGPL-3.0,saas;bioinformatics;pipeline;genetics
693,nanopype,Snakemake pipelines for nanopore sequencing data archiving and processing,"A collection of Snakemake pipelines designed for the processing and archiving of Oxford Nanopore Technologies (ONT) sequencing data, facilitating reproducible bioinformatics analysis.",D1;D1-04,sequencing_processing;bioinformatics_pipeline,workflow,Python,https://github.com/giesselmann/nanopype,,MIT,snakemake;nanopore;bioinformatics
694,dataset_grouper,Libraries for efficient and scalable group-structured dataset pipelines,"A Python library for creating efficient and scalable data pipelines for group-structured datasets, commonly used in machine learning research such as Federated Learning.",D1;D1-04,data_loading;ml_pipeline,library,Python,https://github.com/google-parfait/dataset_grouper,,Apache-2.0,data-pipeline;machine-learning;federated-learning
695,DeepSomatic,Deep learning-based somatic variant caller,"An analysis pipeline that uses a deep neural network to call somatic variants from tumor-normal and tumor-only sequencing data, developed by Google.",D1;D1-04,variant_calling;genomics,solver,Python,https://github.com/google/deepsomatic,,BSD-3-Clause,genomics;deep-learning;variant-calling
696,DeepVariant,Deep learning-based genetic variant caller,An analysis pipeline that uses a deep neural network to call genetic variants from next-generation DNA sequencing data with high accuracy.,D1;D1-04,variant_calling;genomics,solver,Python,https://github.com/google/deepvariant,https://github.com/google/deepvariant,BSD-3-Clause,genomics;deep-learning;variant-calling
697,kedro-dagster,Kedro plugin to support running pipelines on Dagster,"A plugin that integrates Kedro data science pipelines with the Dagster orchestration engine, facilitating the deployment and management of scientific data workflows.",D1;D1-04,workflow_orchestration;pipeline_integration,library,Python,https://github.com/gtauzin/kedro-dagster,,Apache-2.0,kedro;dagster;data-science-pipeline
698,atomate,Pre-built workflows for computational materials science,"A Python library containing pre-built workflows for computational materials science, designed to run with the FireWorks workflow software.",D1;D1-04,materials_science_workflow;computational_chemistry,library,Python,https://github.com/hackingmaterials/atomate,https://atomate.org,NOASSERTION,materials-science;workflows;fireworks
699,snpArcher,Snakemake workflow for variant calling in non-model organisms,"A reproducible and scalable Snakemake workflow for variant calling, specifically designed for ease-of-use in non-model organisms.",D1;D1-04,variant_calling;bioinformatics_pipeline,workflow,Python,https://github.com/harvardinformatics/snpArcher,https://snparcher.readthedocs.io,MIT,snakemake;variant-calling;genomics
700,rnaflow,RNA-Seq differential gene expression pipeline using Nextflow,A simple and reproducible RNA-Seq differential gene expression analysis pipeline implemented in Nextflow.,D1;D1-04,rna-seq;differential_expression,workflow,HTML,https://github.com/hoelzer-lab/rnaflow,,GPL-3.0,nextflow;rna-seq;bioinformatics
701,htmap,High-Throughput Computing in Python powered by HTCondor,"A library that enables high-throughput computing in Python by wrapping HTCondor, allowing users to map Python functions over inputs and run them on a cluster.",D1;D1-04,high_throughput_computing;job_scheduling,library,Python,https://github.com/htcondor/htmap,https://htmap.readthedocs.io,Apache-2.0,htcondor;distributed-computing;python
702,httk,High-Throughput Toolkit for materials science calculations,"A toolkit for preparing and running calculations, analyzing results, and storing outcomes in databases, primarily for computational materials science.",D1;D1-04,materials_science;workflow_management,library,Python,https://github.com/httk/httk,http://httk.openmaterialsdb.se/,AGPL-3.0,materials-science;high-throughput;simulation
703,IQA-Dataset,Interface for downloading and loading Image Quality Assessment datasets,"A unified interface for downloading and loading popular Image Quality Assessment (IQA) datasets, facilitating research in computer vision and image processing.",D1;D1-04,dataset_loading;image_processing,library,Python,https://github.com/icbcbicc/IQA-Dataset,,NOASSERTION,iqa;dataset-loader;computer-vision
704,nextNEOpi,Comprehensive pipeline for computational neoantigen prediction,"A Nextflow pipeline for computational neoantigen prediction from sequencing data, used in cancer immunology research.",D1;D1-04,neoantigen_prediction;immunoinformatics,workflow,Nextflow,https://github.com/icbi-lab/nextNEOpi,,NOASSERTION,nextflow;cancer-immunology;neoantigen
705,sns,Analysis pipelines for genomic sequencing data,"A collection of analysis pipelines for processing genomic sequencing data, including RNA-seq, ChIP-seq, and others.",D1;D1-04,genomics_pipeline;sequencing_analysis,workflow,Shell,https://github.com/igordot/sns,,MIT,genomics;pipeline;ngs
706,redun,Scientific workflow engine by Insitro,"A workflow engine developed by Insitro, designed to handle complex scientific workflows with features like caching, provenance tracking, and execution on various backends.",D1;D1-04,workflow_engine;scientific_computing,platform,Python,https://github.com/insitro/redun,https://insitro.github.io/redun/,Apache-2.0,workflow-engine;bioinformatics;reproducibility
707,apple-health-ingester,Ingestion tool for Apple Health export data to time-series databases,"A server and utility to ingest Apple Health XML export data and store it into databases like InfluxDB for analysis, enabling personal health data research and quantification.",D1;D1-04,data_ingestion;format_conversion,service,Go,https://github.com/irvinlim/apple-health-ingester,,MIT,apple-health;etl;quantified-self;health-data
708,ATMOSPEC (aiidalab-ispg),AiiDA lab application for ab initio UV/vis spectroscopy,"An application for the AiiDA lab platform that provides workflows for computing UV/vis spectroscopy properties using ab initio methods, developed by the Interdisciplinary Surface Physics Group.",D1;D1-04,spectroscopy;workflow_automation,workflow,Python,https://github.com/ispg-group/aiidalab-ispg,,MIT,aiida;spectroscopy;computational-chemistry;materials-science
709,smk-simple-slurm,Snakemake profile for Slurm job scheduling,"A configuration profile to enable Snakemake scientific workflows to run on Slurm-managed High Performance Computing (HPC) clusters, acting as a connector between the workflow engine and the scheduler.",D1;D1-04,workflow_scheduling;hpc_connector,workflow,Shell,https://github.com/jdblischak/smk-simple-slurm,,CC0-1.0,snakemake;slurm;hpc;bioinformatics-workflow
710,scDataLoader,DataLoader for large single-cell datasets from LaminDB,A specialized data loader designed to efficiently fetch and process large-scale single-cell biological datasets stored in LaminDB for machine learning workflows.,D1;D1-04,data_loading;single_cell_analysis,library,Jupyter Notebook,https://github.com/jkobject/scDataLoader,,MIT,single-cell;lamindb;dataloader;biology
711,multiPrime,Mismatch-tolerant minimal primer set design tool,"A tool for designing minimal primer sets that are tolerant to mismatches, specifically optimized for large and diverse viral sequences.",D1;D1-04,primer_design;sequence_analysis,solver,Python,https://github.com/joybio/multiPrime,http://multiPrime.cn,MIT,bioinformatics;primer-design;virology;genomics
712,era5_in_gee,Ingestion tools for ERA5 climate data into Google Earth Engine,A collection of Python scripts and functions designed to facilitate the ingestion of ERA5 climate reanalysis data into Google Earth Engine (GEE) for geospatial analysis.,D1;D1-04,data_ingestion;climate_data_processing,library,Python,https://github.com/jwagemann/era5_in_gee,,None,era5;google-earth-engine;climate-data;etl
713,landsat_ingestor,Ingestion scripts for Landsat satellite data,A set of tools and scripts for processing and ingesting Landsat satellite imagery data into Amazon S3 for public hosting and analysis.,D1;D1-04,data_ingestion;remote_sensing,library,Python,https://github.com/landsat-pds/landsat_ingestor,,Apache-2.0,landsat;satellite-imagery;aws;ingestion
714,tempo,Self-hosted weather API and processing pipeline,A self-hosted weather data processing tool that ingests ECMWF data and serves it as colorized WebP maps and GeoJSON contours for GIS integration.,D1;D1-04,meteorological_data_processing;visualization_service,service,Python,https://github.com/leoneljdias/tempo,,MIT,weather-api;ecmwf;gis;meteorology
715,fermikit,De novo assembly based variant calling pipeline,"A bioinformatics pipeline for Illumina short reads that performs de novo assembly-based variant calling, integrating assembly, mapping, and calling steps.",D1;D1-04,variant_calling;sequence_assembly,workflow,C,https://github.com/lh3/fermikit,,NOASSERTION,bioinformatics;genomics;variant-calling;assembly
716,LncPipe,Nextflow pipeline for lncRNA analysis,"A comprehensive Nextflow-based pipeline for the analysis of long non-coding RNAs (lncRNAs) from RNA-seq datasets, including identification and differential expression analysis.",D1;D1-04,rna_seq_analysis;lncrna_identification,workflow,Groovy,https://github.com/likelet/LncPipe,,LGPL-3.0,bioinformatics;nextflow;lncrna;rna-seq
717,altocumulus,CLI for submitting WDL jobs to Terra/Cromwell,A command-line tool designed to facilitate the submission and management of WDL-based scientific workflows on Terra or Cromwell servers.,D1;D1-04,workflow_submission;cloud_computing,solver,Python,https://github.com/lilab-bcb/altocumulus,,BSD-3-Clause,bioinformatics;wdl;terra;cromwell
718,aiida-lsmo,AiiDA workflows for materials science at LSMO,"A collection of AiiDA workflows and calculation plugins tailored for computational materials science research, specifically developed for the LSMO laboratory.",D1;D1-04,materials_modeling;workflow_orchestration,workflow,Python,https://github.com/lsmo-epfl/aiida-lsmo,,NOASSERTION,aiida;materials-science;workflow;epfl
719,aiida-raspa,AiiDA plugin for RASPA molecular simulations,"An AiiDA plugin that interfaces with the RASPA software, enabling the orchestration of molecular simulations for adsorption and diffusion in nanoporous materials.",D1;D1-04,molecular_simulation;materials_modeling,solver,Python,https://github.com/lsmo-epfl/aiida-raspa,http://www.aiida.net,NOASSERTION,aiida;raspa;molecular-simulation;materials-science
720,aiida-zeopp,AiiDA plugin for Zeo++ porous materials analysis,"An AiiDA plugin for Zeo++, facilitating high-throughput geometric analysis and characterization of porous materials within the AiiDA workflow engine.",D1;D1-04,materials_analysis;geometric_characterization,solver,Python,https://github.com/lsmo-epfl/aiida-zeopp,,NOASSERTION,aiida;zeopp;porous-materials;materials-science
721,aiida-graph-render,Visualization tool for AiiDA provenance graphs using GePhi,A utility to export and render complex provenance graphs from the AiiDA materials science workflow engine into GePhi format for visualization and analysis.,D1;D1-04,visualization;provenance_tracking,library,Python,https://github.com/ltalirz/aiida-graph-render,,None,aiida;visualization;materials-science;graph
722,AiiDA Explorer,Interactive provenance browser for AiiDA databases,"A web-based application to explore and visualize the provenance graph and data stored in AiiDA databases, facilitating the analysis of computational materials science workflows.",D1;D1-04,visualization;data_exploration,platform,JavaScript,https://github.com/materialscloud-org/aiida-explorer,https://aiida-explorer.materialscloud.org,MIT,aiida;materials-science;provenance;visualization
723,atomate2,Library of computational materials science workflows,"A library of computational materials science workflows for the Materials Project stack, designed to run complex simulations using engines like VASP and CP2K.",D1;D1-04,workflow_management;simulation,workflow,Python,https://github.com/materialsproject/atomate2,https://materialsproject.github.io/atomate2/,NOASSERTION,materials-science;workflow;vasp;cp2k
724,FireWorks,Workflow management system for high-throughput computing,"A workflow management system designed for running high-throughput calculations at supercomputing centers, widely used in the Materials Project for managing computational materials science tasks.",D1;D1-04,workflow_management;high_throughput_computing,workflow,Python,https://github.com/materialsproject/fireworks,https://materialsproject.github.io/fireworks/,NOASSERTION,workflow;hpc;materials-science;high-throughput
725,MPmorph,Tools for ab-initio molecular dynamics (AIMD) analysis,"A collection of tools to run and analyze ab-initio molecular dynamics (AIMD) calculations, integrating with the Materials Project stack (pymatgen, fireworks).",D1;D1-04,simulation_analysis;molecular_dynamics,library,Python,https://github.com/materialsproject/mpmorph,,NOASSERTION,aimd;molecular-dynamics;materials-science;vasp
726,voxceleb-luigi,Pipeline for processing VoxCeleb audio datasets,"A Luigi-based workflow pipeline to download, extract, and process the VoxCeleb audio dataset for speaker recognition research.",D1;D1-04,data_preparation;audio_processing,workflow,Python,https://github.com/maxhollmann/voxceleb-luigi,,MIT,audio;dataset-pipeline;luigi;speaker-recognition
727,snakePipes,Snakemake workflows for NGS data analysis,"A set of flexible and customizable workflows based on Snakemake for the analysis of Next-Generation Sequencing (NGS) data, including DNA-seq, RNA-seq, and ChIP-seq.",D1;D1-04,bioinformatics_pipeline;ngs_analysis,workflow,Python,https://github.com/maxplanck-ie/snakepipes,https://snakepipes.readthedocs.io,None,bioinformatics;ngs;snakemake;workflow
728,ATLAS,Metagenome data analysis pipeline,"A workflow pipeline for the assembly, annotation, and quantification of metagenomic data, designed to be easy to use and reproducible.",D1;D1-04,metagenomics;sequence_analysis,workflow,Python,https://github.com/metagenome-atlas/atlas,https://metagenome-atlas.readthedocs.io,BSD-3-Clause,metagenomics;bioinformatics;snakemake;assembly
729,CromwellOnAzure,Cromwell workflow engine deployment for Azure,"Microsoft Genomics implementation of the Broad Institute's Cromwell workflow engine, enabling large-scale bioinformatics workflows on Azure cloud infrastructure.",D1;D1-04,workflow_orchestration;cloud_computing,platform,C#,https://github.com/microsoft/CromwellOnAzure,,MIT,bioinformatics;cromwell;azure;workflow
730,aiida-autocas,AiiDA plugin for automatic active space selection,An AiiDA plugin that automates the selection of active spaces for multireference quantum chemistry calculations.,D1;D1-04,computational_chemistry;workflow_automation,library,Python,https://github.com/microsoft/aiida-autocas,,MIT,aiida;quantum-chemistry;active-space;automation
731,aiida-dynamic-workflows,Dynamic workflow definition for AiiDA,"An AiiDA plugin allowing the definition of dynamic workflows using Python functions, enhancing flexibility for computational science simulations.",D1;D1-04,workflow_management;computational_science,library,Python,https://github.com/microsoft/aiida-dynamic-workflows,,MIT,aiida;workflow;dynamic-execution
732,aiida-pyscf,AiiDA plugin for PySCF,"An AiiDA plugin to interface with the PySCF (Python-based Simulations of Chemistry Framework) code, enabling automated quantum chemistry calculations.",D1;D1-04,computational_chemistry;workflow_connector,library,Python,https://github.com/microsoft/aiida-pyscf,,MIT,aiida;pyscf;quantum-chemistry;plugin
733,biomedica-etl,ETL pipeline for BIOMEDICA image-caption dataset,"Data processing pipeline used to create the BIOMEDICA dataset (Biomedical Image-Caption Archive) from scientific literature, supporting vision-language model research.",D1;D1-04,data_generation;biomedical_mining,workflow,Python,https://github.com/minwoosun/biomedica-etl,,MIT,etl;biomedical;dataset-creation;vision-language
734,MToolBox,Bioinformatics pipeline for mtDNA analysis from NGS data,"A highly automated pipeline for the reconstruction and analysis of human mitochondrial DNA from High Throughput Sequencing data, including variant calling, haplogroup classification, and heteroplasmy assessment.",D1;D1-04,variant_calling;haplogroup_classification;mtDNA_analysis,workflow,Python,https://github.com/mitoNGS/MToolBox,https://github.com/mitoNGS/MToolBox/wiki,GPL-3.0,bioinformatics;mtDNA;ngs;pipeline
735,grenepipe,Automated variant calling pipeline for raw sequence reads,"A flexible, scalable, and reproducible Snakemake pipeline to automate variant calling from raw sequence reads, supporting both sampled individuals and pool sequencing.",D1;D1-04,variant_calling;sequence_processing,workflow,Python,https://github.com/moiexpositoalonsolab/grenepipe,https://github.com/moiexpositoalonsolab/grenepipe,GPL-3.0,bioinformatics;variant-calling;snakemake;genomics
736,pipeliner,Nextflow-based framework for sequencing data processing,"A flexible Nextflow-based framework for the definition and execution of sequencing data processing pipelines, facilitating reproducible bioinformatics workflows.",D1;D1-04,workflow_management;sequencing_analysis,workflow,Nextflow,https://github.com/montilab/pipeliner,,GPL-3.0,bioinformatics;nextflow;pipeline;ngs
737,aiida-gaussian,AiiDA plugin for Gaussian quantum chemistry software,"A plugin to interface the Gaussian quantum chemistry software with the AiiDA workflow engine, enabling automated and reproducible computational chemistry simulations.",D1;D1-04,workflow_connector;quantum_chemistry,solver,Python,https://github.com/nanotech-empa/aiida-gaussian,https://aiida-gaussian.readthedocs.io/,MIT,aiida;computational-chemistry;gaussian;workflow
738,aiidalab-empa-surfaces,AiiDAlab app for on-surface chemistry simulations,"An AiiDAlab application designed for running and analyzing on-surface chemistry simulations, developed at Empa.",D1;D1-04,surface_chemistry;simulation_workflow,workflow,Jupyter Notebook,https://github.com/nanotech-empa/aiidalab-empa-surfaces,,MIT,aiidalab;surface-science;chemistry;simulation
739,GeneLab Data Processing,NASA GeneLab bioinformatics pipelines for spaceflight omics data,Standardized bioinformatics pipelines used by NASA GeneLab for processing and analyzing omics data from spaceflight and space-relevant experiments.,D1;D1-04,omics_processing;bioinformatics_pipeline,workflow,Jupyter Notebook,https://github.com/nasa/GeneLab_Data_Processing,https://genelab.nasa.gov/,None,nasa;genelab;omics;space-biology
740,MayomicsVC,Variant Calling Pipeline in Cromwell/WDL,"A variant calling pipeline implemented in WDL (Workflow Description Language) for execution with Cromwell, designed for genomic data analysis.",D1;D1-04,variant_calling;genomics_workflow,workflow,Shell,https://github.com/ncsa/MayomicsVC,,MIT,wdl;cromwell;variant-calling;genomics
741,paperetl,ETL processes for medical and scientific papers,"A library for processing medical and scientific papers, converting them into structured data for downstream analysis, indexing, and machine learning tasks.",D1;D1-04,scientific_literature_mining;etl,library,Python,https://github.com/neuml/paperetl,,Apache-2.0,etl;nlp;scientific-literature;cord-19
742,Nextflow,Data-driven computational pipeline framework,A workflow management system and DSL that enables scalable and reproducible scientific workflows using software containers. It is widely used in bioinformatics and other data-intensive scientific fields.,D1;D1-04,workflow_orchestration;pipeline_management,platform,Groovy,https://github.com/nextflow-io/nextflow,https://www.nextflow.io/,Apache-2.0,workflow-engine;bioinformatics;reproducibility;pipeline
743,rnaseq-nf,Proof of concept RNA-seq pipeline using Nextflow,"A basic RNA-seq analysis pipeline implemented in Nextflow, often used as a reference implementation or educational example for building scientific workflows.",D1;D1-04,rnaseq_analysis;workflow_example,workflow,Nextflow,https://github.com/nextflow-io/rnaseq-nf,,Apache-2.0,rnaseq;nextflow;bioinformatics;pipeline
744,nf-core/ampliseq,Amplicon sequencing analysis workflow,"A bioinformatics pipeline for amplicon sequencing analysis, utilizing DADA2 and QIIME2 for processing and analyzing microbial community data.",D1;D1-04,amplicon_sequencing;microbiome_analysis,workflow,Nextflow,https://github.com/nf-core/ampliseq,https://nf-co.re/ampliseq,MIT,nf-core;microbiome;16s;bioinformatics
745,nf-core/atacseq,ATAC-seq peak-calling and QC analysis pipeline,"A reproducible analysis pipeline for ATAC-seq data, including quality control, alignment, and peak calling steps.",D1;D1-04,atac_seq;peak_calling;epigenetics,workflow,Nextflow,https://github.com/nf-core/atacseq,https://nf-co.re/atacseq,MIT,nf-core;atac-seq;genomics;pipeline
746,nf-core/bacass,Bacterial assembly and annotation pipeline,A pipeline for the assembly and annotation of bacterial genomes from NGS data.,D1;D1-04,genome_assembly;genome_annotation;bacterial_genomics,workflow,Nextflow,https://github.com/nf-core/bacass,https://nf-co.re/bacass,MIT,nf-core;bacteria;assembly;annotation
747,nf-core/chipseq,ChIP-seq peak-calling and differential analysis pipeline,"A comprehensive pipeline for ChIP-seq data analysis, covering QC, alignment, peak calling, and differential binding analysis.",D1;D1-04,chip_seq;peak_calling;epigenetics,workflow,Nextflow,https://github.com/nf-core/chipseq,https://nf-co.re/chipseq,MIT,nf-core;chip-seq;genomics;pipeline
748,nf-core/cutandrun,Analysis pipeline for CUT&RUN and CUT&TAG experiments,"A pipeline designed for the analysis of CUT&RUN and CUT&TAG chromatin profiling data, including QC, spike-in normalization, and peak calling.",D1;D1-04,cut_and_run;epigenetics;chromatin_profiling,workflow,Nextflow,https://github.com/nf-core/cutandrun,https://nf-co.re/cutandrun,MIT,nf-core;cut-and-run;epigenetics;pipeline
749,nf-core/differentialabundance,Differential abundance analysis pipeline,"A pipeline for performing differential abundance analysis on feature matrices (e.g., from RNA-seq), generating plots and reports.",D1;D1-04,differential_expression;statistical_analysis,workflow,Nextflow,https://github.com/nf-core/differentialabundance,https://nf-co.re/differentialabundance,MIT,nf-core;rnaseq;statistics;visualization
750,nf-core/eager,Ancient DNA analysis pipeline,"A fully reproducible pipeline for the analysis of ancient DNA (aDNA) data, handling specific characteristics like damage patterns and contamination.",D1;D1-04,ancient_dna;paleogenomics;sequencing_analysis,workflow,Nextflow,https://github.com/nf-core/eager,https://nf-co.re/eager,MIT,nf-core;adna;paleogenomics;pipeline
751,nf-core/fetchngs,Pipeline to fetch metadata and raw FastQ files,"A utility pipeline to retrieve sequencing metadata and raw FastQ files from public databases like SRA, ENA, and DDBJ for downstream analysis.",D1;D1-04,data_retrieval;metadata_fetching,workflow,Nextflow,https://github.com/nf-core/fetchngs,https://nf-co.re/fetchngs,MIT,nf-core;sra;ena;data-download
752,nf-core/funcscan,Screening for functional and natural product gene sequences,"A pipeline for screening (meta-)genomes for functional genes and biosynthetic gene clusters (BGCs), aiding in natural product discovery.",D1;D1-04,functional_screening;biosynthetic_gene_clusters;metagenomics,workflow,Nextflow,https://github.com/nf-core/funcscan,https://nf-co.re/funcscan,MIT,nf-core;metagenomics;natural-products;pipeline
753,nf-core/hic,Analysis of Chromosome Conformation Capture data (Hi-C),"A pipeline for processing Hi-C data, including mapping, filtering, matrix generation, and quality control to study 3D genome organization.",D1;D1-04,hic_analysis;3d_genome;chromatin_structure,workflow,Nextflow,https://github.com/nf-core/hic,https://nf-co.re/hic,MIT,nf-core;hi-c;genomics;pipeline
754,nf-core/mag,Assembly and binning of metagenomes,"A pipeline for the assembly, binning, and taxonomic classification of metagenomic data to reconstruct Metagenome-Assembled Genomes (MAGs).",D1;D1-04,metagenomics;genome_assembly;binning,workflow,Nextflow,https://github.com/nf-core/mag,https://nf-co.re/mag,MIT,nf-core;metagenomics;mag;assembly
755,nf-core/methylseq,Methylation (Bisulfite-Sequencing) analysis pipeline,"A pipeline for the analysis of Bisulfite-Sequencing data to study DNA methylation, supporting various alignment and methylation calling tools.",D1;D1-04,methylation_analysis;epigenetics;bisulfite_sequencing,workflow,Nextflow,https://github.com/nf-core/methylseq,https://nf-co.re/methylseq,MIT,nf-core;methylation;epigenetics;pipeline
756,nf-core/nanoseq,"Nanopore demultiplexing, QC and alignment pipeline","A pipeline for analyzing Oxford Nanopore sequencing data, including demultiplexing, quality control, and alignment steps.",D1;D1-04,nanopore_sequencing;long_read_analysis,workflow,Nextflow,https://github.com/nf-core/nanoseq,https://nf-co.re/nanoseq,MIT,nf-core;nanopore;long-read;pipeline
757,nf-core/oncoanalyser,Comprehensive cancer DNA/RNA analysis and reporting pipeline,"A bioinformatics pipeline for the analysis of cancer DNA and RNA sequencing data, providing comprehensive reporting for oncology research.",D1;D1-04,cancer_genomics;variant_calling;rnaseq_analysis,workflow,Nextflow,https://github.com/nf-core/oncoanalyser,https://nf-co.re/oncoanalyser,MIT,cancer;genomics;pipeline;nextflow
758,nf-core/pangenome,Pipeline to render sequences into a pangenome graph,"A bioinformatics pipeline that constructs pangenome graphs from a collection of genomic sequences, facilitating comparative genomics analysis.",D1;D1-04,pangenome_construction;graph_generation,workflow,Nextflow,https://github.com/nf-core/pangenome,https://nf-co.re/pangenome,MIT,pangenome;graph;genomics;nextflow
759,nf-core/proteinfold,Protein 3D structure prediction pipeline,"A pipeline for predicting protein 3D structures from amino acid sequences, integrating tools like AlphaFold2 and ColabFold for structural biology research.",D1;D1-04,structure_prediction;protein_folding,workflow,Nextflow,https://github.com/nf-core/proteinfold,https://nf-co.re/proteinfold,MIT,protein-structure;alphafold;colabfold;nextflow
760,nf-core/raredisease,Variant calling pipeline for rare disease analysis,A pipeline designed to call and score variants from Whole Genome Sequencing (WGS) or Whole Exome Sequencing (WES) data specifically for rare disease patients.,D1;D1-04,variant_calling;rare_disease_analysis,workflow,Nextflow,https://github.com/nf-core/raredisease,https://nf-co.re/raredisease,MIT,rare-disease;variant-calling;wgs;wes
761,nf-core/rnafusion,RNA-seq analysis pipeline for gene fusion detection,"A specialized RNA-seq analysis pipeline focused on the detection of gene fusions, utilizing multiple fusion callers for robust identification.",D1;D1-04,gene_fusion_detection;rnaseq_analysis,workflow,Nextflow,https://github.com/nf-core/rnafusion,https://nf-co.re/rnafusion,MIT,rna-seq;gene-fusion;genomics;nextflow
762,nf-core/sarek,Variant calling pipeline for germline and somatic variants,"A comprehensive pipeline for detecting germline or somatic variants from Whole Genome Sequencing (WGS) or targeted sequencing data, including preprocessing and annotation.",D1;D1-04,variant_calling;germline_analysis;somatic_analysis,workflow,Nextflow,https://github.com/nf-core/sarek,https://nf-co.re/sarek,MIT,variant-calling;wgs;cancer;genomics
763,nf-core/scdownstream,Single-cell transcriptomics downstream analysis pipeline,"A pipeline for the downstream analysis of single-cell transcriptomics data, handling quality control, data integration, and visualization.",D1;D1-04,single_cell_analysis;transcriptomics;data_integration,workflow,Nextflow,https://github.com/nf-core/scdownstream,https://nf-co.re/scdownstream,MIT,single-cell;rna-seq;downstream-analysis;nextflow
764,nf-core/scrnaseq,Single-cell RNA-Seq processing pipeline,"A pipeline for processing single-cell RNA-Seq data from barcode-based protocols (10x, DropSeq, SmartSeq), supporting alignment and empty-droplet detection.",D1;D1-04,single_cell_analysis;expression_quantification,workflow,Nextflow,https://github.com/nf-core/scrnaseq,https://nf-co.re/scrnaseq,MIT,single-cell;rna-seq;10x-genomics;nextflow
765,nf-core/smrnaseq,Small-RNA sequencing analysis pipeline,"A bioinformatics pipeline dedicated to the analysis of small-RNA sequencing data, including miRNA identification and quantification.",D1;D1-04,small_rna_analysis;mirna_profiling,workflow,Nextflow,https://github.com/nf-core/smrnaseq,https://nf-co.re/smrnaseq,MIT,small-rna;mirna;sequencing;nextflow
766,nf-core/spatialvi,Spatial transcriptomics processing pipeline,"A pipeline for processing spatially-resolved gene counts alongside image data, specifically designed for 10x Genomics Visium transcriptomics.",D1;D1-04,spatial_transcriptomics;image_processing,workflow,Nextflow,https://github.com/nf-core/spatialvi,https://nf-co.re/spatialvi,MIT,spatial-transcriptomics;visium;10x;nextflow
767,nf-core/taxprofiler,Multi-taxonomic profiling pipeline for metagenomic data,A highly parallelized pipeline for taxonomic profiling of shotgun short- and long-read metagenomic data using multiple profiling tools.,D1;D1-04,metagenomic_profiling;taxonomic_classification,workflow,Nextflow,https://github.com/nf-core/taxprofiler,https://nf-co.re/taxprofiler,MIT,metagenomics;taxonomy;profiling;nextflow
768,nf-core/viralrecon,Viral assembly and variant calling pipeline,"A bioinformatics pipeline for the assembly of viral genomes and intrahost/low-frequency variant calling, useful for viral surveillance.",D1;D1-04,viral_genomics;assembly;variant_calling,workflow,Nextflow,https://github.com/nf-core/viralrecon,https://nf-co.re/viralrecon,MIT,viral-genomics;covid-19;assembly;nextflow
769,b2luigi,Workflow scheduling library for Belle II analysis (basf2),A Python library extending Luigi to handle task scheduling and batch job execution specifically for the Belle II Analysis Software Framework (basf2) in high-energy physics.,D1;D1-04,workflow_scheduling;hep_analysis,library,Python,https://github.com/nils-braun/b2luigi,https://b2luigi.readthedocs.io/,GPL-3.0,high-energy-physics;workflow;luigi;basf2
770,distiller-nf,Modular Hi-C mapping pipeline,A Nextflow-based data processing pipeline for mapping and processing Hi-C (chromosome conformation capture) data.,D1;D1-04,hic_mapping;genome_structure_analysis,workflow,Groovy,https://github.com/open2c/distiller-nf,https://github.com/open2c/distiller-nf,MIT,hi-c;genomics;mapping;nextflow
771,OpenMOLE,Workflow engine for exploration of simulation models,"A platform designed for the exploration, calibration, and sensitivity analysis of scientific simulation models using high-throughput computing.",D1;D1-04,simulation_exploration;model_calibration;sensitivity_analysis,platform,Scala,https://github.com/openmole/openmole,https://openmole.org/,AGPL-3.0,simulation;workflow;hpc;model-exploration
772,neoantigen-vaccine-pipeline,Pipeline for patient-specific cancer neoantigen vaccine selection,A bioinformatics pipeline that processes sequencing data to identify and select patient-specific cancer neoantigens for vaccine development.,D1;D1-04,neoantigen_prediction;vaccine_design;immunotherapy,workflow,Python,https://github.com/openvax/neoantigen-vaccine-pipeline,,Apache-2.0,cancer-immunotherapy;neoantigen;bioinformatics;pipeline
773,ASAP,Automated bacterial genome assembly and analysis pipeline,"A scalable pipeline for the assembly, annotation, and analysis of bacterial genomes, integrating multiple bioinformatics tools.",D1;D1-04,genome_assembly;genome_annotation;bacterial_genomics,workflow,Groovy,https://github.com/oschwengers/asap,https://github.com/oschwengers/asap,GPL-3.0,bacteria;assembly;annotation;pipeline
774,widget-bandsplot,Jupyter widget for plotting electronic band structures,A Jupyter widget designed for the visualization of electronic band structures and density of states (DOS) in materials science and physics.,D1;D1-04,electronic_structure_visualization;band_structure_analysis,library,Jupyter Notebook,https://github.com/osscar-org/widget-bandsplot,https://osscar-org.github.io/widget-bandsplot/,NOASSERTION,materials-science;physics;visualization;jupyter-widget
775,SciLuigi,Helper library for writing scientific workflows in Luigi,"A lightweight wrapper around Spotify's Luigi workflow library, designed to make writing scientific workflows more fluent, flexible, and modular. It addresses specific needs in bioinformatics and computational science pipelines.",D1;D1-04,workflow_management;pipeline_orchestration,library,Python,https://github.com/pharmbio/sciluigi,,MIT,luigi;workflow;bioinformatics;pipeline
776,Python Workflow Definition,Interoperability layer for materials science workflows,"A project defining common python interfaces for workflows in materials science, enabling interoperability between different workflow engines like AiiDA, Jobflow, and PyIron.",D1;D1-04,workflow_interoperability;materials_informatics,library,Jupyter Notebook,https://github.com/pythonworkflow/python-workflow-definition,,BSD-3-Clause,materials-science;workflow;interoperability;aiida;pyiron
777,What the Phage,Phage identification and annotation pipeline,A Nextflow-based bioinformatics pipeline for the identification and annotation of bacteriophage sequences from metagenomic data. It integrates multiple phage detection tools into a reproducible workflow.,D1;D1-04,phage_identification;metagenomics;pipeline,workflow,Nextflow,https://github.com/replikation/What_the_Phage,,GPL-3.0,bioinformatics;nextflow;phage;metagenomics
778,Aviary,Metagenomics hybrid assembly and binning pipeline,A comprehensive pipeline for hybrid assembly (using long and short reads) and recovery of Metagenome-Assembled Genomes (MAGs). It automates the workflow from raw reads to high-quality bins.,D1;D1-04,genome_assembly;metagenomics;pipeline,workflow,Python,https://github.com/rhysnewell/aviary,,GPL-3.0,metagenomics;assembly;mag-recovery;bioinformatics
779,law,Luigi Analysis Workflow for High Energy Physics,"A python package to build complex and large-scale task workflows. It extends Luigi with features specifically useful for High Energy Physics (HEP) analyses, such as remote job submission (HTCondor, Slurm) and environment sandboxing.",D1;D1-04,workflow_management;physics_analysis,library,Python,https://github.com/riga/law,https://law.readthedocs.io,BSD-3-Clause,high-energy-physics;luigi;workflow;batch-processing
780,NetworkCommons,Platform for inferring context-specific protein interaction networks,A community-driven platform designed to simplify access to tools and resources for inferring context-specific protein interaction networks by integrating context-agnostic prior knowledge with omics data.,D1;D4,network_inference;omics_integration,platform,Python,https://github.com/saezlab/networkcommons,,GPL-3.0,protein-interaction;network-inference;omics;bioinformatics
781,scDataset,Scalable data loading library for large-scale single-cell omics,"A Python library designed for efficient and scalable data loading of large-scale single-cell omics data, facilitating deep learning applications in bioinformatics.",D1;D1-04,data_loading;single_cell_analysis,library,Python,https://github.com/scDataset/scDataset,,MIT,single-cell;omics;data-loader;deep-learning
782,SciPipe,Workflow library for building complex scientific pipelines in Go,"A robust and flexible workflow library written in Go, designed for building complex, resource-efficient scientific pipelines with support for provenance tracking and command-line execution.",D1;D1-04,workflow_orchestration;pipeline_management,workflow,Go,https://github.com/scipipe/scipipe,http://scipipe.org,MIT,workflow;pipeline;go;reproducibility;bioinformatics
783,PyDESeq2,Python implementation of the DESeq2 pipeline for bulk RNA-seq analysis,"A Python library implementing the DESeq2 statistical method for differential expression analysis of bulk RNA-seq data, enabling integration with Python-based data science workflows.",D4;D1-04,differential_expression_analysis;rna_seq_analysis,library,Python,https://github.com/scverse/PyDESeq2,https://pydeseq2.readthedocs.io,MIT,rna-seq;deseq2;differential-expression;bioinformatics
784,wdlRunR,R interface for running WDL workflows for genomic data science,"A tool enabling the execution and management of WDL (Workflow Description Language) workflows directly from R, facilitating reproducible genomic data science backed by cloud resources.",D1;D1-04,workflow_execution;genomics_pipeline,library,R,https://github.com/seandavi/wdlRunR,,None,wdl;r;genomics;workflow;reproducibility
785,Nextflow Tower,Monitoring and management platform for Nextflow pipelines,"A centralized platform for monitoring, logging, and managing Nextflow data analysis pipelines, providing visibility and control over distributed scientific workflows.",D1;D1-04,workflow_management;pipeline_monitoring,platform,Groovy,https://github.com/seqeralabs/nf-tower,https://tower.nf,MPL-2.0,nextflow;workflow-management;bioinformatics;cloud-computing
786,Sequana,Collection of Snakemake pipelines for NGS analysis,"A set of Snakemake pipelines and Python tools dedicated to the analysis of Next Generation Sequencing (NGS) data, covering various tasks such as quality control, variant calling, and coverage analysis.",D1;D1-04,ngs_pipeline;quality_control,workflow,Python,https://github.com/sequana/sequana,http://sequana.readthedocs.io,BSD-3-Clause,snakemake;ngs;pipeline;bioinformatics
787,hecatomb,Virome analysis pipeline for Illumina sequence data,"A bioinformatics pipeline designed for the analysis of viral metagenomes (viromes) from Illumina sequencing data, handling processing, assembly, and taxonomic assignment.",D1;D1-04,virome_analysis;metagenomics,workflow,Python,https://github.com/shandley/hecatomb,https://hecatomb.readthedocs.io,MIT,virome;metagenomics;snakemake;bioinformatics
788,AiiDA-Siesta,AiiDA plugin and workflows for the SIESTA DFT code,"A plugin for the AiiDA workflow engine that interfaces with the SIESTA Density Functional Theory (DFT) code, enabling automated and reproducible materials science simulations.",D1;D1-04;D4,material_simulation;workflow_automation,workflow,Python,https://github.com/siesta-project/aiida_siesta_plugin,https://aiida-siesta-plugin.readthedocs.io,None,aiida;siesta;dft;materials-science;workflow
789,CeleScope,Single-cell analysis pipelines for Singleron data,"A suite of bioinformatics pipelines for processing single-cell sequencing data generated by Singleron platforms, covering various assays like RNA-seq and VDJ.",D1;D1-04,single_cell_analysis;pipeline_processing,workflow,Python,https://github.com/singleron-RD/CeleScope,,MIT,single-cell;pipeline;bioinformatics;rna-seq
790,snakefiles,Collection of Snakemake workflows for RNA-seq analysis,"A repository of reusable Snakemake workflow definitions (Snakefiles) for common RNA-seq data analysis tasks, including alignment with STAR and quantification with Kallisto.",D1;D1-04,rna_seq_workflow;alignment,workflow,Python,https://github.com/slowkow/snakefiles,,MIT,snakemake;rna-seq;workflow;bioinformatics
791,cookiecutter-snakemake-workflow,Standard template for creating Snakemake workflows,"A Cookiecutter template designed to standardize the structure of Snakemake workflows, promoting best practices and reproducibility in scientific data analysis pipelines.",D1;D1-04,workflow_development;reproducibility,solver,Python,https://github.com/snakemake-workflows/cookiecutter-snakemake-workflow,,MIT,snakemake;cookiecutter;template;workflow
792,dna-seq-gatk-variant-calling,Snakemake pipeline implementing GATK best-practices for DNA-seq,"A standardized Snakemake workflow that implements the GATK best-practices for DNA-seq variant calling, ensuring reproducible and scalable genomic analysis.",D1;D1-04,variant_calling;genomics_pipeline,workflow,Python,https://github.com/snakemake-workflows/dna-seq-gatk-variant-calling,,MIT,gatk;snakemake;variant-calling;dna-seq;bioinformatics
793,dna-seq-varlociraptor,Snakemake workflow for small and structural variant calling using Varlociraptor,"A comprehensive Snakemake workflow designed for calling small and structural variants across various scenarios (tumor/normal, germline, pedigree, etc.) using the unified statistical model of Varlociraptor.",D1;D1-04,variant_calling;genomic_analysis,workflow,Python,https://github.com/snakemake-workflows/dna-seq-varlociraptor,https://snakemake.github.io/snakemake-workflow-catalog/,MIT,snakemake;bioinformatics;variant-calling;dna-seq
794,rna-seq-kallisto-sleuth,Snakemake workflow for RNA-seq differential expression analysis,A Snakemake workflow that performs differential expression analysis of RNA-seq data utilizing Kallisto for pseudo-alignment and Sleuth for statistical analysis.,D1;D1-04,differential_expression_analysis;rna_seq,workflow,Python,https://github.com/snakemake-workflows/rna-seq-kallisto-sleuth,https://snakemake.github.io/snakemake-workflow-catalog/,MIT,snakemake;rna-seq;kallisto;sleuth
795,rna-seq-star-deseq2,RNA-seq analysis workflow using STAR and DESeq2,A standard Snakemake workflow for RNA-sequencing analysis that employs STAR for alignment and DESeq2 for differential expression analysis.,D1;D1-04,rna_seq;alignment;differential_expression,workflow,Python,https://github.com/snakemake-workflows/rna-seq-star-deseq2,https://snakemake.github.io/snakemake-workflow-catalog/,MIT,snakemake;star;deseq2;bioinformatics
796,Snakemake,Workflow management system for reproducible data analysis,A workflow management system that aims to reduce the complexity of creating facsimiles of data analysis to create reproducible and scalable data analyses. It is widely used in bioinformatics and scientific computing.,D1;D1-04,workflow_orchestration;reproducibility,platform,Python,https://github.com/snakemake/snakemake,https://snakemake.readthedocs.io,MIT,workflow-engine;pipeline;reproducibility;bioinformatics
797,Bpipe,Platform for running and managing bioinformatics pipelines,"Bpipe is a tool for running and managing bioinformatics pipelines. It provides a domain specific language for defining pipelines and handles task execution, parallelism, and reporting.",D1;D1-04,workflow_orchestration;bioinformatics_pipeline,platform,Groovy,https://github.com/ssadedin/bpipe,http://docs.bpipe.org/,MIT,bioinformatics;pipeline;workflow
798,aiida-mlip,AiiDA plugin for machine learning interatomic potentials,"A plugin for the AiiDA workflow platform that interfaces with Machine Learning Interatomic Potentials (MLIP), enabling automated calculations and simulations in materials science.",D1;D1-04,molecular_dynamics;materials_modeling,library,Python,https://github.com/stfc/aiida-mlip,https://aiida-mlip.readthedocs.io/,BSD-3-Clause,aiida;materials-science;mlip;interatomic-potentials
799,St. Jude Cloud Workflows,Bioinformatics workflows for St. Jude Cloud,"A collection of bioinformatics workflows written in WDL, developed for and used on the St. Jude Cloud project for genomic analysis.",D1;D1-04,genomic_analysis;bioinformatics_pipeline,workflow,WDL,https://github.com/stjudecloud/workflows,https://stjude.cloud,MIT,wdl;genomics;bioinformatics;workflow
800,Sunbeam,Extensible metagenomics pipeline,"A robust and extensible pipeline for metagenomics analysis, handling quality control, assembly, and classification of sequencing data.",D1;D1-04,metagenomics_analysis;sequence_processing,workflow,Python,https://github.com/sunbeam-labs/sunbeam,https://sunbeam.readthedocs.io/,GPL-3.0,metagenomics;pipeline;bioinformatics;snakemake
801,bio-pipeline,Collection of bioinformatics analysis pipelines,"A collection of lightweight bioinformatics analysis pipelines and scripts for specific tasks such as assembly, mapping, and annotation, developed by Tang Haibao.",D1;D1-04,bioinformatics_analysis;sequence_processing,library,Python,https://github.com/tanghaibao/bio-pipeline,,MIT,bioinformatics;pipeline;scripts
802,scib-pipeline,Snakemake pipeline for benchmarking single-cell data integration methods,A reproducible pipeline built with Snakemake to benchmark various single-cell data integration methods using the scIB (Single-Cell Integration Benchmarking) package. It automates the execution of integration tasks and metric evaluation.,D1;D1-04,benchmarking;data_integration;single_cell_analysis,workflow,Python,https://github.com/theislab/scib-pipeline,,MIT,single-cell;benchmarking;snakemake;bioinformatics
803,UGENE,Integrated bioinformatics software for sequence analysis and visualization,"A free open-source cross-platform bioinformatics software suite. It integrates dozens of popular bioinformatics tools and algorithms for sequence alignment, assembly, and analysis into a single graphical interface, facilitating complex workflows.",D1;D1-04,sequence_analysis;visualization;alignment;workflow_management,platform,C++,https://github.com/ugeneunipro/ugene,http://ugene.net,GPL-2.0,bioinformatics;gui;sequence-analysis;ngs
804,pyrpipe,Python framework for creating reproducible bioinformatics pipelines,A Python package that enables the creation of reproducible bioinformatics pipelines by providing a wrapper around Unix tools and commands. It facilitates the integration of various bioinformatics tools into Python scripts with logging and report generation.,D1;D1-04,workflow_management;pipeline_creation,library,Python,https://github.com/urmi-21/pyrpipe,https://pyrpipe.readthedocs.io,MIT,bioinformatics;pipeline;reproducibility;python
805,seq2science,Automated preprocessing and analysis workflows for NGS data,"A collection of automated and customizable workflows for preprocessing Next-Generation Sequencing (NGS) data, including ATAC-seq, ChIP-seq, and RNA-seq. It handles downloading, alignment, and quality control.",D1;D1-04,preprocessing;alignment;quality_control;rna_seq,workflow,Python,https://github.com/vanheeringen-lab/seq2science,https://vanheeringen-lab.github.io/seq2science/,MIT,ngs;rna-seq;chip-seq;atac-seq;snakemake
806,vsn-pipelines,Collection of Nextflow pipelines for single-cell data analysis,"A repository of Nextflow DSL2 pipelines specifically designed for processing and analyzing single-cell sequencing data, maintained by the VIB Single Cell Core.",D1;D1-04,single_cell_analysis;pipeline;workflow_management,workflow,Nextflow,https://github.com/vib-singlecell-nf/vsn-pipelines,https://vib-singlecell-nf.github.io/vsn-pipelines,GPL-3.0,single-cell;nextflow;bioinformatics;vib
807,UAVS,Intelligent UAV path planning and simulation platform,"A comprehensive simulation system for Unmanned Aerial Vehicles (UAVs) focusing on path planning, formation control, and mission simulation in complex environments. It integrates model building, automated control, and route verification.",Robotics;Simulation,path_planning;simulation;control_system,platform,JavaScript,https://github.com/wangwei39120157028/UAVS,,BSD-3-Clause,uav;path-planning;simulation;robotics
808,scATAC-pro,Comprehensive workflow for single-cell ATAC-seq data analysis,"A tool for processing, analyzing, and visualizing single-cell chromatin accessibility sequencing (scATAC-seq) data. It provides a complete workflow from raw data processing to downstream analysis like clustering and motif enrichment.",Bioinformatics;Genomics,scatac-seq;data_analysis;visualization,workflow,R,https://github.com/wbaopaul/scATAC-pro,https://github.com/wbaopaul/scATAC-pro,MIT,single-cell;atac-seq;chromatin-accessibility;bioinformatics
809,nano-snakemake,Snakemake pipeline for structural variant analysis from Nanopore data,A bioinformatics pipeline built with Snakemake for analyzing structural variants (SV) using data from Oxford Nanopore sequencing. It automates the workflow for long-read genomic analysis.,Bioinformatics;Genomics;D1-04,structural_variant_calling;pipeline;nanopore_sequencing,workflow,Python,https://github.com/wdecoster/nano-snakemake,,MIT,snakemake;nanopore;structural-variants;genomics
810,flo,Pipeline for lifting over genome annotations within the same species,"A Ruby-based pipeline designed to lift over genome annotations from one assembly to another within the same species, facilitating genomic data migration and comparison.",Bioinformatics;Genomics;D1-04,annotation_liftover;genome_assembly;pipeline,workflow,Ruby,https://github.com/wurmlab/flo,,None,genomics;annotation;liftover;pipeline
811,aiida-yambo,AiiDA plugin for Yambo many-body perturbation theory code,A plugin for the AiiDA workflow engine that interfaces with the Yambo code. It enables automated high-throughput calculations for many-body perturbation theory (MBPT) in materials science.,Materials Science;Physics;D1-04,workflow_connector;electronic_structure;mbpt,library,Python,https://github.com/yambo-code/aiida-yambo,https://aiida-yambo.readthedocs.io/,NOASSERTION,aiida;yambo;materials-science;workflow
812,aiida-castep,AiiDA plugin for CASTEP DFT code,"A plugin for the AiiDA workflow engine that provides an interface to CASTEP, a leading code for calculating the properties of materials from first principles. It facilitates automated DFT calculations and provenance tracking.",Materials Science;Physics;D1-04,workflow_connector;dft;electronic_structure,library,Python,https://github.com/zhubonan/aiida-castep,https://aiida-castep.readthedocs.io/,MIT,aiida;castep;dft;materials-science
813,rgbd360,Omnidirectional RGB-D sensor data acquisition and SLAM tool,"A tool for image acquisition, localization, and mapping using an omnidirectional RGB-D sensor. It supports data serialization, frame registration, loop closure detection, and PbMap-based hybrid SLAM (Simultaneous Localization and Mapping).",D1,data_acquisition;slam;localization,solver,C++,https://github.com/EduFdez/rgbd360,,None,slam;rgb-d;robotics;computer-vision
814,open-parse,Improved file parsing library for LLM data preparation,"A library designed to parse complex documents (PDFs, etc.) into structured chunks suitable for Large Language Models (LLMs), facilitating RAG (Retrieval-Augmented Generation) workflows in scientific literature analysis.",D1;D1-05,document_parsing;data_chunking,library,Python,https://github.com/Filimoa/open-parse,,MIT,pdf-parsing;llm;rag;document-processing
815,ArUCo-Markers-Pose-Estimation-Generation-Python,Pose estimation tool using ArUCo markers,"A Python tool for generating ArUCo markers and estimating pose, commonly used in robotics, computer vision research, and laboratory automation for object tracking.",D1,pose_estimation;computer_vision,solver,Python,https://github.com/GSNCodes/ArUCo-Markers-Pose-Estimation-Generation-Python,,MIT,aruco;pose-estimation;computer-vision;robotics
816,detectron2-publaynet,Document layout analysis models trained on PubLayNet,"Provides trained Detectron2 models for document layout analysis, specifically optimized for scientific publications (PubLayNet dataset). Essential for extracting structure from scientific PDFs.",D1;D1-05,layout_analysis;document_parsing,dataset,Python,https://github.com/JPLeoRX/detectron2-publaynet,,NOASSERTION,layout-analysis;publaynet;detectron2;pdf-parsing
817,YuzuMarker.FontDetection,CJK font recognition and style extraction model,"A deep learning model and tool for recognizing Chinese, Japanese, and Korean (CJK) fonts and extracting styles from document images, aiding in detailed document layout analysis and OCR.",D1;D1-05,font_recognition;document_analysis,solver,Python,https://github.com/JeffersonQin/YuzuMarker.FontDetection,,MIT,font-recognition;ocr;document-analysis;cjk
818,TopOpt.jl,Topology optimization library for Julia,A Julia package for binary and continuous topology optimization on unstructured meshes using automatic differentiation. Used for structural design and physics simulations.,D1,topology_optimization;simulation,library,Julia,https://github.com/JuliaTopOpt/TopOpt.jl,,NOASSERTION,topology-optimization;julia;fem;automatic-differentiation
819,parsetron,Natural language semantic parsing library,"A library for semantic parsing of natural language, capable of mapping text to structured representations, applicable in scientific text mining and command parsing.",D1;D1-05,semantic_parsing;nlp,library,Python,https://github.com/Kitt-AI/parsetron,,Apache-2.0,semantic-parsing;nlp;grammar
820,markify,File to Markdown converter for RAG/LLM,"A tool to convert various file formats (PDF, etc.) into Markdown, specifically optimized to help RAG systems and LLMs understand document structure and content.",D1;D1-05,document_conversion;rag_preparation,solver,Python,https://github.com/KylinMountain/markify,,NOASSERTION,markdown;pdf-conversion;rag;llm
821,layout-model-training,Training scripts for LayoutParser models,"Scripts and utilities for training Detectron2-based document layout analysis models, supporting the LayoutParser ecosystem for custom scientific document parsing.",D1;D1-05,model_training;layout_analysis,workflow,Python,https://github.com/Layout-Parser/layout-model-training,,None,layout-analysis;training-scripts;detectron2;document-parsing
822,layout-parser,Unified toolkit for deep learning based document image analysis,"A comprehensive toolkit for document image analysis, providing pre-trained models and tools for layout detection, character recognition, and structural analysis of scientific documents.",D1;D1-05,layout_analysis;ocr;document_parsing,library,Python,https://github.com/Layout-Parser/layout-parser,https://layout-parser.readthedocs.io/,Apache-2.0,document-analysis;deep-learning;ocr;layout-parsing
823,MetaConfigurator,A schema editor and form generator for JSON schemas and research data,"MetaConfigurator is a web-based tool designed to facilitate the creation and editing of JSON schemas and configuration files. It is particularly useful for managing metadata and structured research data, allowing researchers to define and validate data formats visually.",D1;D1-05,schema_management;data_formatting,solver,TypeScript,https://github.com/MetaConfigurator/meta-configurator,,MIT,json-schema;metadata;configuration-management
824,Arabic Nougat,Fine-tuned Nougat model for parsing Arabic scientific documents,"This tool provides an implementation of the Nougat (Neural Optical Understanding for Academic Documents) model, specifically fine-tuned for Arabic text. It converts PDF documents into Markdown, enabling the extraction of structured text and layout information from Arabic scientific literature.",D1;D1-05,document_parsing;ocr,solver,Python,https://github.com/MohamedAliRashad/arabic-nougat,,None,pdf-parsing;ocr;arabic-nlp;nougat
825,NanoNets docext,Toolkit for OCR-free unstructured data extraction and benchmarking,"docext is a toolkit designed for extracting structured data from unstructured documents without relying on traditional OCR pipelines. It supports converting documents to Markdown and includes benchmarking tools to evaluate extraction performance, suitable for processing scientific literature and reports.",D1;D1-05,document_parsing;layout_analysis;benchmarking,solver,Python,https://github.com/NanoNets/docext,https://idp-leaderboard.org/,Apache-2.0,document-extraction;pdf-to-markdown;unstructured-data
826,NeurboParser,Neural TurboSemanticParser for semantic dependency parsing,"NeurboParser is a C++ implementation of a neural semantic dependency parser. It is used in Natural Language Processing (NLP) to extract semantic structures from text, which is a critical step in mining structured information from scientific literature.",D1;D1-05,semantic_parsing;nlp,solver,C++,https://github.com/Noahs-ARK/NeurboParser,,LGPL-3.0,semantic-parsing;dependency-parsing;nlp
827,Layout2Graph,GNN-based framework for document layout analysis,"Layout2Graph is an implementation of the Paragraph2Graph framework, which uses Graph Neural Networks (GNNs) to perform language-independent layout analysis. This tool is essential for understanding the structure of scientific documents and extracting logical sections.",D1;D1-05,layout_analysis;document_parsing,solver,Python,https://github.com/NormXU/Layout2Graph,,Apache-2.0,layout-analysis;gnn;document-structure
828,nougat-latex-ocr,Nougat-based image to LaTeX generation tool,"This repository provides code for fine-tuning and evaluating Nougat-based models specifically for the task of converting images (such as mathematical formulas and scientific text) into LaTeX code, facilitating the digitization of scientific content.",D1;D1-05,ocr;latex_generation,solver,Python,https://github.com/NormXU/nougat-latex-ocr,,Apache-2.0,image-to-latex;nougat;ocr;scientific-notation
829,LAREX,Layout Analysis and Region Extraction tool for early printed books,LAREX is a semi-automatic tool designed for the layout analysis and region extraction of early printed books and historical documents. It helps researchers in digital humanities and history of science to digitize and structure complex historical layouts.,D1;D1-05,layout_analysis;document_parsing,solver,Java,https://github.com/OCR4all/LAREX,,MIT,layout-analysis;historical-documents;ocr
830,General-Documents-Layout-parser,General document layout analysis and parsing tool,"A tool for general document layout analysis, capable of parsing the structure of documents (including Chinese documents). It aids in extracting content from diverse document formats, supporting downstream scientific data mining tasks.",D1;D1-05,layout_analysis;document_parsing,solver,Python,https://github.com/OKC13/General-Documents-Layout-parser,,NOASSERTION,layout-analysis;document-parsing;chinese-nlp
831,Oxen,Data version control system for machine learning datasets,"Oxen is a fast data version control system optimized for structured and unstructured machine learning datasets. It enables researchers to version control large scientific datasets (images, text, audio) similarly to how code is versioned, ensuring reproducibility in AI4S workflows.",D1,data_versioning;workflow_management,solver,Rust,https://github.com/Oxen-AI/Oxen,,Apache-2.0,data-version-control;machine-learning;dataset-management
832,MegaParse,File parser optimized for LLM ingestion of documents,"MegaParse is a robust file parsing tool designed to convert unstructured documents (PDF, Docx, PPTx) into clean, structured formats ideal for Large Language Model (LLM) ingestion. It is highly relevant for processing scientific literature and reports in AI4S pipelines.",D1;D1-05,document_parsing;data_conversion,solver,Python,https://github.com/QuivrHQ/MegaParse,,Apache-2.0,pdf-parsing;llm-ingestion;unstructured-data
833,RapidLayout,Layout analysis tool for Chinese and English documents,"A tool for analyzing document layouts, specifically optimized for Chinese and English, capable of identifying regions like text, headers, and figures, which is essential for parsing unstructured scientific documents.",D1;D1-05,layout_analysis;document_parsing,library,Python,https://github.com/RapidAI/RapidLayout,,Apache-2.0,layout-analysis;ocr;document-parsing
834,TableStructureRec,Table structure recognition and extraction tool,"A collection of optimized models for table structure recognition, including pre- and post-processing pipelines and ONNX conversion, facilitating the extraction of structured data from scientific papers and reports.",D1;D1-05,table_extraction;structure_recognition,library,Python,https://github.com/RapidAI/TableStructureRec,,Apache-2.0,table-recognition;ocr;onnx
835,Spotlight,Interactive visualization and curation tool for unstructured data,"A tool for interactively exploring and curating unstructured datasets (images, audio, text) directly from dataframes, supporting data-centric AI workflows in scientific research.",D1,data_visualization;data_curation;exploratory_analysis,platform,TypeScript,https://github.com/Renumics/spotlight,https://renumics.com/,MIT,data-curation;visualization;unstructured-data
836,SCOREC Core,Parallel unstructured mesh management library,"A set of C++ libraries for managing parallel unstructured meshes, supporting adaptive mesh refinement and partition, essential for finite element simulations in physics and engineering.",D1,mesh_generation;simulation;finite_element_analysis,library,C++,https://github.com/SCOREC/core,,NOASSERTION,mesh;fem;hpc
837,SPECFEM3D Cartesian,Seismic wave propagation simulation software,"Simulates acoustic, elastic, coupled acoustic/elastic, or poroelastic seismic wave propagation in any type of conforming mesh of hexahedra, widely used in geophysics and seismology.",D1,simulation;seismic_modeling;wave_propagation,solver,Fortran,https://github.com/SPECFEM/specfem3d,https://specfem3d.readthedocs.io/,GPL-3.0,seismology;geophysics;simulation
838,GravitasML,XML parser optimized for LLM data ingestion,"A lightweight XML parsing library designed to simplify the processing of XML data for Large Language Models, facilitating the ingestion of structured scientific data into AI workflows.",D1;D1-05,xml_parsing;data_ingestion;llm_preprocessing,library,Python,https://github.com/Significant-Gravitas/gravitasml,,MIT,xml;llm;parsing
839,Merlin,3D Vision-Language Model for medical imaging,"A 3D Vision-Language Model (VLM) specifically designed for computed tomography (CT) scans, leveraging structured EHR and unstructured radiology reports for pretraining to assist in medical diagnosis and analysis.",D1;D1-05,medical_imaging;structure_prediction;multimodal_learning,solver,Python,https://github.com/StanfordMIMI/Merlin,,MIT,medical-ai;ct-scan;vlm
840,Table Transformer,OCR and vision-based table extraction tool,"An open-source tool combining OCR and computer vision to extract structured tabular data from images, suitable for preprocessing scientific documents for LLMs and data analysis.",D1;D1-05,table_extraction;ocr;document_parsing,library,Python,https://github.com/Sudhanshu1304/table-transformer,,MIT,table-extraction;ocr;computer-vision
841,OCR Correction,Seq2seq model for post-processing OCR errors,"A tool using sequence-to-sequence models to correct errors in Optical Character Recognition (OCR) output, improving the quality of digitized scientific texts and historical documents.",D1;D1-05,ocr_correction;text_processing;data_cleaning,library,Python,https://github.com/TurkuNLP/ocr-correction,,None,ocr;nlp;seq2seq
842,UXarray,Xarray extension for unstructured climate data,"An extension to Xarray that provides analysis and visualization capabilities for unstructured grid data, specifically designed for climate and global weather datasets.",D1,climate_analysis;data_visualization;unstructured_grid,library,Python,https://github.com/UXARRAY/uxarray,https://uxarray.readthedocs.io/,Apache-2.0,climate;weather;xarray
843,Fiducials,Simultaneous localization and mapping using fiducial markers,"A system for simultaneous localization and mapping (SLAM) using fiducial markers, enabling robots to determine their position and orientation in an environment, widely used in robotics research.",D1,slam;localization;robotics,solver,C,https://github.com/UbiquityRobotics/fiducials,http://wiki.ros.org/fiducials,BSD-3-Clause,slam;robotics;localization
844,Unstructured,Open-source ETL library for ingesting and processing unstructured documents for LLMs,"A library that provides components for ingesting and processing unstructured documents (PDF, HTML, Word, etc.) into structured formats suitable for Large Language Models (LLMs). It handles partitioning, cleaning, and extracting text/metadata from complex document layouts.",D1;D1-05,document_parsing;etl;data_cleaning,library,HTML,https://github.com/Unstructured-IO/unstructured,https://unstructured.io,Apache-2.0,etl;pdf-parsing;llm-preprocessing;unstructured-data
845,ViTLP,Visually Guided Generative Text-Layout Pre-training for Document Intelligence,An implementation of a visually guided generative text-layout pre-training framework for document intelligence. It is designed to handle document understanding tasks by leveraging both visual and layout information.,D1;D1-05,document_intelligence;layout_analysis;pretraining,solver,Python,https://github.com/Veason-silverbullet/ViTLP,,MIT,document-understanding;layout-analysis;generative-model
846,Document-Layout-Analysis,"Tools for extracting figures, tables, and text from PDF documents","A collection of tools designed to analyze the layout of PDF documents and extract structured components such as figures, tables, and text blocks, facilitating downstream data processing.",D1;D1-05,pdf_extraction;layout_analysis,library,Python,https://github.com/Wild-Rift/Document-Layout-Analysis,,None,pdf-extraction;layout-analysis;data-mining
847,csv-schema-inference,Automatic schema and data type inference for CSV files,"A tool that automatically infers column data types and generates schemas for CSV files, aiding in the preprocessing and validation of tabular data.",D1;D1-05,schema_inference;data_profiling,library,Jupyter Notebook,https://github.com/Wittline/csv-schema-inference,,MIT,csv;schema-inference;data-preprocessing
848,GEM,Online globally consistent dense elevation mapping for unstructured terrain,"A system for creating globally consistent dense elevation maps of unstructured terrain in real-time, useful for robotics navigation and geological surface analysis.",D1;D1-05,mapping;slam;terrain_analysis,solver,C++,https://github.com/ZJU-Robotics-Lab/GEM,,None,robotics;elevation-mapping;slam;unstructured-terrain
849,llmwhisperer-table-extraction,PDF table extraction pipeline using LLMWhisperer and Langchain,"A workflow for extracting tabular data from PDFs using LLMWhisperer and structuring the information using Langchain, specifically targeting the conversion of unstructured document tables into structured formats.",D1;D1-05,table_extraction;pdf_parsing,workflow,Python,https://github.com/Zipstack/llmwhisperer-table-extraction,,MIT,table-extraction;pdf;llm;structured-data
850,Unstract,No-code LLM platform for structuring unstructured documents via ETL pipelines,"A platform that enables the creation of ETL pipelines to extract structured data from unstructured documents using Large Language Models, providing APIs and a no-code interface for document processing workflows.",D1;D1-05,etl;document_structuring;pipeline_orchestration,platform,Python,https://github.com/Zipstack/unstract,https://unstract.com,AGPL-3.0,etl;llm;document-processing;no-code
851,OmniParse,Universal data ingestion and parsing tool for GenAI compatibility,"A tool designed to ingest, parse, and optimize various unstructured data formats (documents, multimedia) into structured formats optimized for Generative AI frameworks.",D1;D1-05,data_ingestion;parsing;multimodal_processing,platform,Python,https://github.com/adithya-s-k/omniparse,,GPL-3.0,data-ingestion;parsing;genai;unstructured-data
852,CCTag,Library for detecting concentric circle markers for photogrammetry,"A computer vision library for the detection and identification of CCTag markers, which are used for reliable tracking and calibration in photogrammetry and 3D reconstruction workflows.",D1;D1-05,marker_detection;photogrammetry;calibration,library,C++,https://github.com/alicevision/CCTag,https://alicevision.org,MPL-2.0,computer-vision;photogrammetry;fiducial-markers
853,AllenNLP Semparse,Framework for building semantic parsers with AllenNLP,"A library built on AllenNLP for developing semantic parsers, which convert natural language into logical forms or executable code, facilitating the extraction of structured meaning from text.",D1;D1-05,semantic_parsing;nlp,library,Python,https://github.com/allenai/allennlp-semparse,,Apache-2.0,semantic-parsing;nlp;allennlp
854,ROSGPT,Interface for controlling robots using natural language via ChatGPT,"A tool that integrates ChatGPT with ROS (Robot Operating System) to convert unstructured human language commands into actionable robotic instructions, enabling natural language interaction with robots.",D1;D1-05,human_robot_interaction;instruction_parsing;robot_control,solver,Python,https://github.com/aniskoubaa/rosgpt,,None,ros;robotics;llm;natural-language-control
855,Marker,High-accuracy PDF to Markdown/JSON converter for scientific documents,"A powerful pipeline that converts PDF documents (including scientific papers) into Markdown and JSON formats. It handles equations, tables, and layout analysis with high accuracy, making it essential for ingesting scientific literature into LLMs or data workflows.",D1;D1-05,parsing;layout_analysis;ocr,solver,Python,https://github.com/datalab-to/marker,,GPL-3.0,pdf-parsing;ocr;scientific-literature;markdown
856,Surya,Multilingual OCR and layout analysis toolkit,"A comprehensive OCR and document layout analysis tool that supports over 90 languages. It performs text detection, reading order determination, and table recognition, serving as a foundational tool for digitizing and structuring scientific documents.",D1;D1-05,ocr;layout_analysis;table_extraction,solver,Python,https://github.com/datalab-to/surya,,GPL-3.0,ocr;layout-analysis;document-understanding
857,Probable People,Parser for unstructured western names into structured components,"A library using conditional random fields to parse unstructured name strings into structured components (e.g., given name, surname, title). It is widely used in bibliometrics and scientific data cleaning to normalize author names from citation data.",D1;D1-05,data_cleaning;normalization;parsing,library,Python,https://github.com/datamade/probablepeople,,MIT,name-parsing;bibliometrics;data-cleaning
858,usaddress,Parser for unstructured US address strings,"A probabilistic parser that converts unstructured US address strings into structured components. It is valuable for geospatial scientific data processing, epidemiology, and social science research where location data normalization is required.",D1;D1-05,data_cleaning;normalization;parsing,library,Python,https://github.com/datamade/usaddress,,MIT,address-parsing;geospatial;data-cleaning
859,deepdoctection,Document AI package for analyzing and extracting data from documents,"A comprehensive Document AI library that orchestrates OCR, layout analysis, and table extraction. It is specifically designed to handle complex document structures like scientific papers, enabling the extraction of structured data from PDFs.",D1;D1-05,parsing;layout_analysis;table_extraction,solver,Python,https://github.com/deepdoctection/deepdoctection,https://deepdoctection.readthedocs.io/,Apache-2.0,document-ai;pdf-parsing;ocr
860,ExtractThinker,Document Intelligence library for LLM-based extraction,"A library that provides an ORM-style interaction for document workflows using LLMs. It facilitates the extraction of structured data from unstructured documents, enabling flexible and powerful document intelligence applications in scientific research.",D1;D1-05,parsing;information_extraction;llm_workflow,library,Python,https://github.com/enoch3712/ExtractThinker,,Apache-2.0,llm;document-intelligence;extraction
861,TaBERT,Pre-trained language model for learning joint representations of natural language and structured tables,"A pre-trained language model designed to learn joint representations of natural language utterances and semi-structured tables. It is trained on a massive corpus of web tables and can be used for semantic parsing tasks, enabling the conversion of natural language into structured queries or representations by understanding tabular data context.",D1;D1-05,semantic_parsing;table_understanding,model,Python,https://github.com/facebookresearch/TaBERT,,NOASSERTION,nlp;semantic-parsing;table-understanding;representation-learning
862,Nougat,Neural Optical Understanding for Academic Documents,"A Visual Transformer model that understands academic documents and converts them into markup language (Markdown). It is specifically designed to handle the complex layout and formatting of scientific papers, enabling the extraction of structured text, equations, and tables from PDF documents for downstream scientific data processing.",D1;D1-05,document_parsing;ocr;layout_analysis,solver,Python,https://github.com/facebookresearch/nougat,https://facebookresearch.github.io/nougat/,MIT,ocr;pdf-parsing;academic-documents;transformer
863,Gretel Synthetics,Synthetic data generators for structured and unstructured text with differential privacy,"A library for generating synthetic data for structured and unstructured text, incorporating differentially private learning techniques. It is used in data science and research to create privacy-preserving datasets for training models, simulating scientific data, or sharing sensitive information safely.",D1;D1-05,data_generation;synthetic_data;privacy_preserving,library,Python,https://github.com/gretelai/gretel-synthetics,https://gretel-synthetics.readthedocs.io/,NOASSERTION,synthetic-data;differential-privacy;data-generation;nlp
864,HanLP,Multilingual Natural Language Processing library,"A comprehensive Natural Language Processing (NLP) library supporting multiple languages. It provides functionalities such as tokenization, part-of-speech tagging, named entity recognition, and syntactic/semantic dependency parsing. It is widely used as a foundational tool for text mining and information extraction in scientific literature analysis.",D1;D1-05,nlp;text_mining;parsing;ner,library,Python,https://github.com/hankcs/HanLP,https://hanlp.hankcs.com/,Apache-2.0,nlp;tokenization;ner;dependency-parsing
865,fAIr,AI-assisted mapping tool for humanitarian and geographic data,"An open-source AI-assisted mapping tool developed by the Humanitarian OpenStreetMap Team (HOT). It leverages AI models to detect features (like buildings and roads) from satellite imagery, assisting researchers and mappers in generating structured geographic data for humanitarian and scientific analysis.",D1;D1-05,mapping;feature_extraction;geospatial_analysis,platform,TypeScript,https://github.com/hotosm/fAIr,,AGPL-3.0,mapping;gis;ai-assisted;satellite-imagery
866,pdf-document-layout-analysis,Docker-powered service for PDF document layout analysis and segmentation,"A service designed to perform layout analysis on PDF documents. It segments and classifies different parts of PDF pages, identifying elements such as text blocks, titles, images, and tables. This tool is essential for preprocessing scientific literature and reports to extract structured data.",D1;D1-05,document_analysis;layout_segmentation;pdf_parsing,service,Python,https://github.com/huridocs/pdf-document-layout-analysis,,Apache-2.0,pdf-analysis;layout-analysis;document-processing;docker
867,pdf-text-extraction,Tool for extracting text from PDFs using layout analysis outputs,"A utility that leverages the outputs of the pdf-document-layout-analysis service to extract text from PDF files. It uses the segmentation and classification information to accurately extract and structure text content from complex documents, facilitating downstream text mining and analysis.",D1;D1-05,text_extraction;pdf_processing,workflow,Makefile,https://github.com/huridocs/pdf-text-extraction,,Apache-2.0,pdf;text-extraction;document-processing
868,vision-parse,PDF to Markdown converter using Vision LLMs for document parsing,"A tool that leverages Vision Language Models (VLMs) to parse PDF documents (including scientific papers) into structured Markdown format, preserving layout and content structure.",D1;D1-05,document_parsing;ocr;unstructured_data_extraction,solver,Python,https://github.com/iamarunbrahma/vision-parse,,MIT,pdf-parsing;vision-llm;markdown;document-intelligence
869,schemer,"Schema registry and inference tool for CSV, JSON, Avro, and Parquet","A schema registry service that supports schema inference for common data formats (CSV, JSON, etc.), facilitating data management and validation in data workflows.",D1;D1-05,schema_inference;data_validation,service,Scala,https://github.com/indix/schemer,,Apache-2.0,schema-inference;csv;parquet;data-management
870,layout_analysis,Document layout analysis tool using YOLOv8,"A tool for detecting and analyzing the layout of documents (specifically Chinese documents, but applicable to others) using YOLOv8, essential for extracting structured information from scientific literature.",D1;D1-05,layout_analysis;document_parsing,solver,Python,https://github.com/jiangnanboy/layout_analysis,,None,yolov8;layout-analysis;document-understanding
871,layout_analysis4j,Java implementation of document layout analysis using YOLOv8,"The Java version of the layout_analysis tool, enabling document layout detection and analysis in Java-based scientific workflows.",D1;D1-05,layout_analysis;document_parsing,library,Java,https://github.com/jiangnanboy/layout_analysis4j,,None,java;yolov8;layout-analysis
872,json-typedef-infer,CLI tool for inferring JSON Typedef schemas from data,"A command-line tool that generates JSON Typedef schemas from example data, aiding in schema inference and data structure discovery for JSON-based scientific datasets.",D1;D1-05,schema_inference;data_modeling,solver,Rust,https://github.com/jsontypedef/json-typedef-infer,,MIT,schema-inference;json-typedef;cli
873,genson-rs,High-performance JSON Schema inference engine,"A Rust-based engine for inferring JSON Schemas from data, providing fast schema discovery for large JSON datasets in scientific data pipelines.",D1;D1-05,schema_inference;data_profiling,library,Rust,https://github.com/junyu-w/genson-rs,,Apache-2.0,rust;json-schema;inference
874,byte-vision,Privacy-first document intelligence platform with RAG,"A platform for transforming static documents into an interactive knowledge base using OCR, parsing, and RAG (Retrieval-Augmented Generation), suitable for scientific literature management.",D1;D1-05,document_parsing;ocr;rag,platform,JavaScript,https://github.com/kbrisso/byte-vision,,None,document-intelligence;ocr;rag;elasticsearch
875,GROBID,Machine learning software for extracting information from scholarly documents,"A leading library for extracting, parsing, and restructuring raw documents (PDF) such as scientific publications into structured XML/TEI encoded data, focusing on bibliographic data and full text.",D1;D1-05,document_parsing;information_extraction;bibliographic_analysis,solver,Java,https://github.com/kermitt2/grobid,https://grobid.readthedocs.io/,Apache-2.0,pdf-parsing;scientific-literature;tei;crf;deep-learning
876,grobid-astro,GROBID module for extracting astronomical entities,A specialized module for GROBID designed to recognize and extract astronomical entities (such as celestial objects) from scientific papers.,D1;D1-05,entity_extraction;document_parsing,solver,JavaScript,https://github.com/kermitt2/grobid-astro,,None,astronomy;ner;grobid-module
877,grobid-client-java,Java client for GROBID REST services,"The official Java client library for interacting with the GROBID service, facilitating the integration of scientific document parsing into Java applications.",D1;D1-05,document_parsing,library,Java,https://github.com/kermitt2/grobid-client-java,,Apache-2.0,client;java;grobid
878,grobid-client-node,Node.js client for GROBID REST services,"The official Node.js client library for interacting with the GROBID service, enabling scientific document parsing in JavaScript/Node.js environments.",D1;D1-05,document_parsing,library,JavaScript,https://github.com/kermitt2/grobid-client-node,,Apache-2.0,client;node.js;grobid
879,grobid-client-python,Python client for GROBID Web services,"The official Python client library for interacting with the GROBID service, widely used in Python-based scientific data pipelines for literature mining.",D1;D1-05,document_parsing,library,Python,https://github.com/kermitt2/grobid-client-python,,Apache-2.0,client;python;grobid
880,grobid-ner,Named-Entity Recognition module based on Grobid for scientific text,"A Named-Entity Recogniser (NER) built on top of Grobid, designed to extract entities from scientific documents. It leverages Grobid's cascading CRF models to identify and classify entities within the structure of academic papers.",D1;D1-05,named_entity_recognition;text_mining,library,Java,https://github.com/kermitt2/grobid-ner,,Apache-2.0,ner;grobid;scientific-text-mining
881,grobid-quantities,Grobid extension for extracting physical quantities from scientific text,"A module for Grobid that identifies, parses, and normalizes physical quantities and measurements in scientific and technical documents. It handles values, units, and their normalization.",D1;D1-05,entity_extraction;normalization,library,JavaScript,https://github.com/lfoppiano/grobid-quantities,,Apache-2.0,grobid;physical-quantities;measurement-extraction
882,grobid-superconductors,Grobid module for superconductor material and property extraction,"A specialized Grobid module designed to extract information about superconductor materials, their properties (like critical temperature), and related experimental conditions from scientific literature.",D1;D1-05,material_extraction;property_extraction,library,HTML,https://github.com/lfoppiano/grobid-superconductors,,Apache-2.0,materials-science;superconductors;text-mining
883,material-parsers,Parsers and utilities for materials science data extraction,"A collection of parsers and scripts developed to support the extraction of materials science data, particularly in the context of the Grobid Superconductors project. It includes utilities for handling material names and properties.",D1;D1-05,parsing;data_processing,library,Python,https://github.com/lfoppiano/material-parsers,,Apache-2.0,materials-science;parsing;grobid-utils
884,structure-vision,Visualizer for Grobid-extracted document structure,A viewer tool designed to visualize the structured data extracted by Grobid from PDF documents. It helps researchers and developers inspect and validate the parsing results of scientific publications.,D1;D1-05,visualization;validation,tool,Python,https://github.com/lfoppiano/structure-vision,,Apache-2.0,visualization;grobid;pdf-structure
885,P2PaLA,Layout analysis tool for historical documents (PAGE format),"Page to PAGE Layout Analysis Tool. A software for analyzing the layout of documents, particularly historical ones, and generating output in the PAGE XML format, which is a standard in document analysis research.",D1;D1-05,layout_analysis;document_processing,tool,Python,https://github.com/lquirosd/P2PaLA,,GPL-3.0,layout-analysis;page-xml;historical-documents
886,iFEM,MATLAB package for adaptive finite element methods,A MATLAB software package containing robust and efficient codes for adaptive finite element methods (FEM) on unstructured simplicial grids. It is used for scientific simulation and modeling in 2D and 3D.,Scientific Computing;Simulation,simulation;finite_element_method,library,MATLAB,https://github.com/lyc102/ifem,,GPL-3.0,fem;simulation;matlab
887,tesseract-recognize,Layout analysis and OCR tool exporting to Page XML format,"A C++ tool that performs layout analysis and text recognition using Tesseract, specifically designed to output results in Page XML format, which is a standard for document image analysis and digital archiving workflows.",D1;D1-05,ocr;layout_analysis;document_parsing,solver,C++,https://github.com/mauvilsa/tesseract-recognize,,MIT,ocr;page-xml;layout-analysis;tesseract
888,llm-document-ocr,LLM-based OCR and document parsing library,"A TypeScript library that leverages Large Language Models (LLMs) to perform OCR and parse unstructured documents into structured formats, facilitating data extraction from scientific or technical documents.",D1;D1-05,ocr;document_parsing;information_extraction,library,TypeScript,https://github.com/mercoa-finance/llm-document-ocr,,MIT,llm;ocr;document-parsing;typescript
889,semantic-csv,Higher-level semantic tools for CSV data manipulation,"A Clojure library providing higher-level abstractions for working with CSV data, enabling semantic mapping and processing of tabular data commonly used in scientific research.",D1;D1-05,data_processing;csv_parsing;data_normalization,library,Clojure,https://github.com/metasoarous/semantic-csv,,EPL-1.0,csv;clojure;data-processing
890,AIDocIntelligence,Client for AI Document Intelligence service,"A Python tool/client for interacting with AI Document Intelligence services, enabling the extraction of text, key-value pairs, tables, and structures from unstructured scientific or technical documents.",D1;D1-05,document_parsing;information_extraction;table_extraction,library,Python,https://github.com/microsoft/AIDocIntelligence,,MIT,document-intelligence;extraction;parsing
891,Document-Knowledge-Mining-Solution-Accelerator,Workflow for mining knowledge from unstructured documents,"A solution accelerator that integrates Azure OpenAI and Document Intelligence to process, summarize, and extract entities/metadata from unstructured multi-modal documents, facilitating knowledge discovery in research.",D1;D1-05,knowledge_mining;document_summarization;entity_extraction,workflow,C#,https://github.com/microsoft/Document-Knowledge-Mining-Solution-Accelerator,,MIT,knowledge-mining;rag;document-processing
892,OmniParser,Screen parsing tool for vision-based GUI agents,"A pure vision-based screen parsing tool designed to convert GUI screenshots into structured elements. While primarily for agents, its capability to parse visual information into structured data is relevant for AI-assisted data extraction and automation in research workflows.",D1;D1-05,visual_parsing;gui_automation;screen_parsing,solver,Jupyter Notebook,https://github.com/microsoft/OmniParser,,CC-BY-4.0,vision-parsing;gui-agent;screen-parsing
893,data-formulator,AI-powered data visualization creation tool,"A tool that uses AI to transform data and create rich visualizations, assisting researchers in exploring and presenting scientific data effectively.",D1;D1-05,data_visualization;data_transformation;exploratory_analysis,tool,TypeScript,https://github.com/microsoft/data-formulator,https://microsoft.github.io/data-formulator,MIT,visualization;ai-assisted;data-analysis
894,dstoolkit-text2sql-and-imageprocessing,"Toolkit for RAG, Text2SQL, and document processing","A development toolkit accelerating RAG applications by integrating SQL Warehouses and document analysis via Azure Document Intelligence, facilitating complex data querying and extraction for research.",D1;D1-05,text2sql;rag;document_processing,workflow,Python,https://github.com/microsoft/dstoolkit-text2sql-and-imageprocessing,,MIT,rag;text2sql;document-intelligence
895,openscraping-lib-csharp,Library for structured data extraction from HTML,"A C# library designed to turn unstructured HTML pages into structured data using JSON configuration and XPath rules, capable of handling complex objects like tables, useful for scientific data collection from web sources.",D1;D1-05,web_scraping;data_extraction;html_parsing,library,C#,https://github.com/microsoft/openscraping-lib-csharp,,NOASSERTION,scraping;structured-data;xpath
896,rat-sql,Relation-aware semantic parsing model (Text-to-SQL),"A relation-aware semantic parsing model that translates natural language questions into SQL queries, facilitating natural language interfaces for scientific databases.",D1;D1-05,semantic_parsing;text2sql;natural_language_interface,solver,Python,https://github.com/microsoft/rat-sql,,MIT,semantic-parsing;text2sql;nlp
897,table-transformer,Deep learning model for table extraction from documents,"Table Transformer (TATR) is a deep learning model specifically designed to extract and structure tables from unstructured documents like PDFs and images, a critical task in scientific literature mining.",D1;D1-05,table_extraction;document_parsing;structure_recognition,solver,Python,https://github.com/microsoft/table-transformer,,MIT,table-extraction;deep-learning;pdf-parsing
898,YOLOv10-Document-Layout-Analysis,YOLOv10 model for document layout analysis,"A YOLOv10 model trained on the DocLayNet dataset for performing document layout analysis, enabling the segmentation and classification of document elements (text, tables, figures) in scientific papers.",D1;D1-05,layout_analysis;document_parsing;computer_vision,solver,Jupyter Notebook,https://github.com/moured/YOLOv10-Document-Layout-Analysis,,AGPL-3.0,yolo;layout-analysis;doclaynet
899,YOLOv11-Document-Layout-Analysis,YOLOv11 model for document layout analysis,"A YOLOv11 model trained on the DocLayNet dataset for performing document layout analysis, providing updated performance for segmenting scientific document structures.",D1;D1-05,layout_analysis;document_parsing;computer_vision,solver,Jupyter Notebook,https://github.com/moured/YOLOv11-Document-Layout-Analysis,,AGPL-3.0,yolo;layout-analysis;doclaynet
900,ccg2lambda,Semantic parsing tool for natural language inference,"A tool for semantic parsing that converts Combinatory Categorial Grammar (CCG) derivations into lambda calculus expressions, supporting natural language inference and logic-based semantics research.",D1;D1-05,semantic_parsing;natural_language_inference;logic_representation,library,Python,https://github.com/mynlp/ccg2lambda,,Apache-2.0,semantic-parsing;nlp;logic
901,LLM Graph Builder,Neo4j graph construction from unstructured data using LLMs,"A tool that utilizes Large Language Models (LLMs) to extract nodes and relationships from unstructured text data and construct knowledge graphs in Neo4j. It supports schema inference and automated mapping, facilitating the conversion of scientific literature or reports into structured knowledge bases.",D1;D1-05,knowledge_extraction;graph_construction;schema_inference,workflow,Jupyter Notebook,https://github.com/neo4j-labs/llm-graph-builder,,Apache-2.0,knowledge-graph;llm;unstructured-data;neo4j
902,SPARQA,Skeleton-based Semantic Parsing for Complex Questions over Knowledge Bases,"A semantic parsing framework designed to handle complex questions over knowledge bases (KBQA). It uses a skeleton-based approach to map natural language queries into SPARQL or logical forms, facilitating the interrogation of structured scientific data.",D1;D1-05,semantic_parsing;kbqa;query_mapping,solver,Python,https://github.com/nju-websoft/SPARQA,,MIT,semantic-parsing;knowledge-base;nlp;sparql
903,arucogen,Online ArUco markers generator for computer vision,"A utility tool for generating ArUco markers, which are essential for camera pose estimation, robotics navigation, and augmented reality experiments in computer vision research.",D1;D1-01,data_generation;computer_vision_setup,solver,JavaScript,https://github.com/okalachev/arucogen,http://chev.me/arucogen/,MIT,aruco;computer-vision;robotics;marker-generation
904,Open Politics HQ,OSINT infrastructure for structured insights from unstructured data,"A platform for Open Source Intelligence (OSINT) that ingests content, defines analytical frameworks, and visualizes patterns. It is designed for researchers in social and political sciences to turn domain expertise into structured insights from large volumes of documents.",D1;D1-05,osint;text_analysis;pattern_recognition,platform,TypeScript,https://github.com/open-politics/open-politics-hq,,NOASSERTION,osint;social-science;data-analysis;visualization
905,DocLayout-YOLO,Document Layout Analysis using YOLO,"A deep learning model based on YOLO designed for document layout analysis. It detects and segments different components of a document (e.g., text blocks, tables, figures), which is a critical step in parsing scientific literature and technical documents.",D1;D1-05,document_layout_analysis;parsing;segmentation,solver,Python,https://github.com/opendatalab/DocLayout-YOLO,,AGPL-3.0,document-analysis;yolo;layout-analysis;pdf-parsing
906,PDF-Extract-Kit,Comprehensive Toolkit for High-Quality PDF Content Extraction,"A toolkit focused on extracting high-quality content from PDFs, including text, tables, and formulas. It serves as a preprocessing engine for scientific document analysis and knowledge base construction.",D1;D1-05,pdf_extraction;ocr;layout_analysis,library,Python,https://github.com/opendatalab/PDF-Extract-Kit,,AGPL-3.0,pdf-extraction;ocr;document-parsing
907,semantic-bot,Semi-Automatic Tool to generate RDF mappings,"A tool designed to assist in generating RDF mappings for datasets. It helps in the semantic enrichment of data, facilitating the integration of datasets into the Semantic Web or knowledge graphs.",D1;D1-05,rdf_mapping;semantic_enrichment;schema_mapping,solver,Python,https://github.com/opendatasoft/semantic-bot,,MIT,rdf;semantic-web;data-mapping
908,GeoAI,Artificial Intelligence for Geospatial Data,"A Python library for applying artificial intelligence and machine learning techniques to geospatial data. It supports tasks such as image segmentation, object detection, and data analysis in the context of geography and earth sciences.",D1;D1-05,geospatial_analysis;image_segmentation;remote_sensing,library,Python,https://github.com/opengeos/geoai,,MIT,geospatial;ai;gis;remote-sensing
909,openalex-pdf-parser,PDF parser powered by grobid for OpenAlex,"A specialized PDF parsing tool used within the OpenAlex ecosystem, leveraging Grobid to extract structured metadata and full text from scientific publications.",D1;D1-05,pdf_parsing;metadata_extraction;bibliometrics,solver,Python,https://github.com/ourresearch/openalex-pdf-parser,,MIT,grobid;openalex;pdf-parsing;scientific-literature
910,aruco_ros,ROS wrappers for Aruco Augmented Reality marker detector,"A ROS package that provides wrappers for the Aruco library, enabling the detection of augmented reality markers. This is widely used in robotics research for localization, calibration, and object tracking.",D1;D1-01,marker_detection;robotics_perception;localization,library,C++,https://github.com/pal-robotics/aruco_ros,,MIT,ros;robotics;computer-vision;aruco
911,papercast,"Pipeline tool for processing technical documents (arXiv, PDF)",A pipeline tool designed to process technical documents from sources like arXiv and SemanticScholar. It uses GROBID and LangChain to parse papers and can convert them into audio (podcast format) or other structured representations for analysis.,D1;D1-05,literature_processing;pdf_parsing;audio_synthesis,workflow,Python,https://github.com/papercast-dev/papercast,,MIT,arxiv;pdf-processing;grobid;langchain
912,View-Parsing-Network,Cross-view Semantic Segmentation for Sensing Surroundings,Implementation of the View Parsing Network (VPN) for cross-view semantic segmentation. This tool is used in robotics and autonomous driving research to transform first-person view images into top-down semantic maps.,D1;D1-05,semantic_segmentation;view_transformation;robotics_perception,solver,Python,https://github.com/pbw-Berwin/View-Parsing-Network,,None,computer-vision;semantic-segmentation;robotics;view-parsing
913,tranX,Neural semantic parser for mapping natural language to code,A general-purpose neural semantic parser that maps natural language queries into machine-executable code or logical forms. It is widely used in NLP research for tasks like code generation and semantic parsing of complex queries.,D1;D1-05,semantic_parsing;code_generation;nlp,library,Python,https://github.com/pcyin/tranX,,Apache-2.0,semantic-parsing;nlp;code-generation
914,pdfix-autotag-deepdoctection,Autotag PDF documents using deepdoctection,A tool that uses the deepdoctection AI model to automatically analyze and tag the structure of PDF documents. This aids in making PDFs accessible and machine-readable for further data extraction.,D1;D1-05,pdf_tagging;document_structure_analysis;accessibility,solver,Python,https://github.com/pdfix/pdfix-autotag-deepdoctection,,None,pdf;deepdoctection;autotagging
915,OCRIntegrator,"Integrated solution for OCR, layout analysis, and table parsing","A unified interface combining multiple open-source OCR models, layout analysis tools, and table parsers. It streamlines the process of extracting structured information from various document types.",D1;D1-05,ocr;layout_analysis;table_extraction,workflow,Python,https://github.com/peakhell/OCRIntegrator,,Apache-2.0,ocr;document-processing;layout-analysis
916,SEMPRE,Semantic Parser with Execution,A toolkit for training semantic parsers that map natural language to logical forms. It is a foundational tool in NLP research for building systems that can understand and execute natural language commands against knowledge bases.,D1;D1-05,semantic_parsing;nlp;logical_form_generation,library,Java,https://github.com/percyliang/sempre,,NOASSERTION,semantic-parsing;nlp;stanford
917,geodict,Library for pulling location information from unstructured text,"A simple Python library for geoparsing, allowing the extraction of location names and coordinates from unstructured text. Useful for geospatial analysis and social science research.",D1;D1-05,geoparsing;text_mining;location_extraction,library,Python,https://github.com/petewarden/geodict,,None,geoparsing;nlp;location-extraction
918,yolo-doclaynet,YOLO models trained on DocLayNet for document layout analysis,"Provides YOLO models trained on the DocLayNet dataset specifically for document layout analysis. This tool enables the segmentation and classification of document elements (headers, paragraphs, tables) in scientific and technical documents.",D1;D1-05,layout_analysis;document_segmentation;computer_vision,solver,Python,https://github.com/ppaanngggg/yolo-doclaynet,,AGPL-3.0,yolo;doclaynet;document-analysis
919,Advanced Deep Research,Automated Deep Research agent with paper parsing,"An AI agent designed to conduct deep research by performing web searches, parsing scientific papers, and generating didactic summaries. It automates the literature review and information synthesis process.",D1;D1-05,literature_review;paper_parsing;automated_research,workflow,Python,https://github.com/prodesk98/advanced-deep-research,,MIT,ai-agent;research-automation;paper-parsing
920,gds2Para,GDSII layout file parsing and parameter extraction tool,"A tool for parsing GDSII files (standard format for IC layout data), performing layout analysis, and extracting parameters for semiconductor engineering and physics simulations.",D1;D1-01,layout_analysis;parameter_extraction,solver,C++,https://github.com/purdue-onchip/gds2Para,,GPL-2.0,gdsii;eda;semiconductor;layout-analysis
921,QMiner,Real-time large-scale data analytics platform,"An analytics platform for processing real-time large-scale streams containing structured and unstructured data, suitable for data mining, sensor data analysis, and text mining tasks.",D1;D1-04,data_mining;stream_analytics;statistics,platform,C++,https://github.com/qminer/qminer,http://qminer.github.io/,NOASSERTION,data-mining;stream-processing;analytics;cpp
922,eynollah,Document layout analysis and segmentation tool,"A tool for document layout analysis, capable of segmenting pages into regions (text, images, tables) and extracting structure, often used in OCR pipelines for scientific literature or historical documents.",D1;D1-05,document_layout_analysis;ocr_post_processing;structure_extraction,library,Python,https://github.com/qurator-spk/eynollah,,Apache-2.0,layout-analysis;ocr;document-processing;deep-learning
923,document-layout-analysis,Simple document layout analysis using OpenCV,"A Python-OpenCV based tool for analyzing document layouts, identifying blocks of text and images, useful for preprocessing scientific documents for data extraction.",D1;D1-05,document_layout_analysis;image_processing,library,Python,https://github.com/rbaguila/document-layout-analysis,,None,opencv;layout-analysis;document-processing
924,llm_data_parser,LLM-based web data extraction tool,"A proof-of-concept tool leveraging LLMs to identify and extract meaningful structured data from HTML content without heavy parsing, facilitating data collection for analysis.",D1;D1-05,data_extraction;html_parsing;llm_inference,library,Python,https://github.com/repollo/llm_data_parser,,None,llm;web-scraping;data-extraction
925,BotanicGarden,Dataset for robot navigation in unstructured natural environments,"A high-quality dataset designed for training and evaluating robot navigation algorithms in unstructured natural environments (botanic gardens), supporting robotics research.",D4;D1,robot_navigation;dataset_access,dataset,Jupyter Notebook,https://github.com/robot-pesg/BotanicGarden,,None,robotics;dataset;navigation;unstructured-environment
926,semtools,Command line tools for semantic search and document parsing,"A collection of CLI tools for semantic search, RAG (Retrieval-Augmented Generation), and document parsing, facilitating the processing of unstructured text for AI applications.",D1;D1-05,semantic_search;document_parsing;rag,workflow,Rust,https://github.com/run-llama/semtools,,MIT,semantic-search;rag;document-parsing;rust
927,TabularSemanticParsing,Natural language to SQL semantic parsing model,"Research code for translating natural language questions into structured query language (SQL), supporting semantic parsing tasks on tabular data.",D1;D1-05,semantic_parsing;text_to_sql;nlp,solver,Jupyter Notebook,https://github.com/salesforce/TabularSemanticParsing,,BSD-3-Clause,nlp;semantic-parsing;sql;deep-learning
928,WikiSQL,Large annotated semantic parsing corpus for Text-to-SQL,"A large-scale dataset for developing natural language interfaces for relational databases, specifically for the task of semantic parsing (Text-to-SQL).",D4;D1,dataset_access;semantic_parsing,dataset,HTML,https://github.com/salesforce/WikiSQL,,BSD-3-Clause,dataset;nlp;text-to-sql;semantic-parsing
929,ingest,CLI tool to parse files and websites for LLM ingestion,"A command-line tool designed to parse code repositories and websites into a format suitable for ingestion by Large Language Models (LLMs), streamlining the data preparation workflow for AI.",D1;D1-05,data_ingestion;preprocessing;llm_context_preparation,workflow,Go,https://github.com/sammcj/ingest,,MIT,llm;data-ingestion;cli;parsing
930,HybridRAG,Hybrid retrieval system combining vector and graph search,A Retrieval-Augmented Generation (RAG) system that integrates vector search with knowledge graph search to handle both structured and unstructured data for accurate LLM response generation.,D1;D1-05,information_retrieval;rag;knowledge_graph,solver,Jupyter Notebook,https://github.com/sarabesh/HybridRAG,,None,rag;knowledge-graph;llm;hybrid-search
931,ACL-anthology-corpus,ACL Anthology corpus data and extraction scripts,"A repository providing the ACL Anthology corpus (computational linguistics research papers), including metadata, PDFs, and Grobid extractions, serving as a dataset for NLP research.",D4;D1,dataset_access;nlp_corpus_processing,dataset,Jupyter Notebook,https://github.com/shauryr/ACL-anthology-corpus,,None,nlp;dataset;acl-anthology;corpus
932,graph-parser,Semantic parser for converting natural language to logical forms,"A semantic parsing tool capable of converting natural language sentences into logical forms and graphs, supporting research in computational linguistics and knowledge representation.",D1;D1-05,semantic_parsing;knowledge_representation;nlp,library,Java,https://github.com/sivareddyg/graph-parser,,NOASSERTION,semantic-parsing;nlp;logical-forms;graphs
933,SUQL,Conversational search interface over hybrid structured and unstructured data,"A formal language and framework for building conversational interfaces that can query both structured databases (SQL) and unstructured text corpora, useful for scientific knowledge retrieval.",D1;D1-05,semantic_parsing;text_to_sql;information_retrieval,solver,Python,https://github.com/stanford-oval/suql,,Apache-2.0,semantic-parsing;nlp;hybrid-retrieval
934,TOUGH2Viewer,3D visualization tool for TOUGH2 simulation grids,A Java-based visualization tool specifically designed for displaying structured and unstructured Voronoi grids used in TOUGH2 groundwater and heat flow simulations.,D1;D1-05,scientific_visualization;mesh_processing,solver,Java,https://github.com/stebond/TOUGH2Viewer,,None,visualization;geoscience;tough2;voronoi-grid
935,Stencila,Platform for executable and reproducible scientific documents,"A platform and set of tools for creating, converting, and executing scientific documents, supporting conversion between formats like JATS XML, JSON-LD, Markdown, and Jupyter Notebooks.",D1;D1-05,format_conversion;reproducible_research;document_parsing,platform,Rust,https://github.com/stencila/stencila,https://stencila.io,Apache-2.0,reproducible-research;document-conversion;jats-xml;scientific-publishing
936,Galactic,Data cleaning and curation tool for massive unstructured text datasets,"A library designed for processing, cleaning, and curating large-scale unstructured text data, commonly used for preparing scientific literature datasets for LLM training.",D1;D1-05,data_cleaning;text_normalization;dataset_curation,library,Python,https://github.com/taylorai/galactic,,Apache-2.0,data-cleaning;nlp;llm-training;unstructured-data
937,UCNS3D,Unstructured Compressible Navier-Stokes 3D CFD solver,"A high-order accurate Computational Fluid Dynamics (CFD) code for solving unstructured compressible Navier-Stokes equations, used for scientific simulations in aerodynamics and fluid mechanics.",Physics;Fluid Dynamics,cfd_simulation;fluid_dynamics_modeling,solver,Fortran,https://github.com/ucns3d-team/UCNS3D,,GPL-3.0,cfd;navier-stokes;simulation
938,GraphGPT,Tool for extrapolating knowledge graphs from unstructured text using LLMs,"A tool that leverages GPT models to convert unstructured text into structured knowledge graphs, facilitating the extraction of relationships and entities for scientific knowledge management.",D1;D1-05,knowledge_graph_construction;information_extraction,workflow,JavaScript,https://github.com/varunshenoy/GraphGPT,,MIT,knowledge-graph;llm;unstructured-data
939,ocrsegment,Deep learning model for page layout analysis and segmentation,"A deep learning based model specifically designed for document layout analysis and page segmentation, enabling the structural parsing of document images.",D1;D1-05,layout_analysis;document_segmentation,solver,Python,https://github.com/watersink/ocrsegment,,None,layout-analysis;ocr;segmentation
940,knowledge-table,Library for extracting structured data from unstructured documents,"An open-source package designed to simplify the process of extracting structured data (tables, entities) from unstructured documents, facilitating data harmonization in scientific workflows.",D1;D1-05,information_extraction;structured_data_generation,library,Python,https://github.com/whyhow-ai/knowledge-table,,MIT,extraction;unstructured-data;parsing
941,e2m,Universal document to Markdown converter for LLM processing,"A comprehensive tool to convert various file formats (PDF, DOCX, EPUB, etc.) into Markdown, specifically optimized for feeding unstructured data into LLMs for analysis and parsing.",D1;D1-05,document_conversion;text_extraction,library,Jupyter Notebook,https://github.com/wisupai/e2m,,Apache-2.0,markdown-converter;document-parsing;llm-preprocessing
942,extractous,High-performance unstructured data extraction library,"A fast and efficient library written in Rust for extracting text and metadata from various unstructured data formats, serving as a foundational tool for scientific data ingestion pipelines.",D1;D1-05,data_extraction;etl,library,Rust,https://github.com/yobix-ai/extractous,,Apache-2.0,data-extraction;rust;unstructured-data
943,RoDLA,Benchmark toolkit for Document Layout Analysis robustness,"A benchmarking toolkit and dataset designed to evaluate the robustness of Document Layout Analysis (DLA) models, essential for validating tools used in scientific document parsing.",D1;D1-05,benchmarking;layout_analysis,workflow,Python,https://github.com/yufanchen96/RoDLA,,Apache-2.0,benchmark;document-layout-analysis;robustness
944,faster-nougat,Optimized local implementation of the Nougat model for parsing academic PDFs,"An efficient, local implementation of the Nougat (Neural Optical Understanding for Academic Documents) model. It utilizes Transformer-based architecture to parse unstructured scientific documents (PDFs) and convert them into structured Markdown or LaTeX formats, specifically handling mathematical formulas and tables found in academic literature.",D1;D1-05,document_parsing;optical_character_recognition;formula_extraction,solver,Python,https://github.com/zhuzilin/faster-nougat,,MIT,pdf-parsing;scientific-literature;ocr;academic-documents;nougat
