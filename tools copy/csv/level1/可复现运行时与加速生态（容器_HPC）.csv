id,name,one_line_profile,detailed_description,domains,subtask_category,application_level,primary_language,repo_url,help_website,license,tags
1,omnipkg,Python package and interpreter version manager wrapper for conda-forge,"A tool that simplifies the management of Python environments and packages using conda-forge, allowing for conflict-free installation of infinite package and interpreter versions.",AI6;AI6-01,environment_management;dependency_resolution,tool,Python,https://github.com/1minds3t/omnipkg,,NOASSERTION,conda;python;package-management
2,distrobox,Container wrapper to run any Linux distribution inside the terminal,"A tool that uses Podman or Docker to create containers using the Linux distribution of choice, enabling reproducible environments and backward/forward compatibility for scientific software on HPC or personal workstations.",AI6;AI6-01,environment_management;containerization,tool,Shell,https://github.com/89luca89/distrobox,https://distrobox.it,GPL-3.0,linux;container;podman;docker;hpc
3,lilipod,Simple container manager for OCI images,"A lightweight container manager capable of downloading, unpacking, and using OCI images, serving as a minimal runtime for containerized scientific workflows.",AI6;AI6-01,container_management;runtime,tool,Go,https://github.com/89luca89/lilipod,,GPL-3.0,container;oci;sandbox
4,ACCESS-OM2,Global coupled ocean-sea ice model,"The ACCESS Ocean-Sea Ice Model (ACCESS-OM2), a global coupled model used for climate research and oceanography simulations.",AI4S;Earth Science,simulation;climate_modeling,solver,Fortran,https://github.com/ACCESS-NRI/ACCESS-OM2,https://access-om2.readthedocs.io/,Apache-2.0,oceanography;climate-model;simulation
5,mSSA,Multivariate Singular Spectrum Analysis for time series,An implementation of Multivariate Singular Spectrum Analysis (mSSA) for forecasting and imputation of multivariate time series data.,AI4S;Data Analysis,time_series_analysis;forecasting;imputation,library,Jupyter Notebook,https://github.com/AbdullahO/mSSA,,Apache-2.0,time-series;forecasting;statistics
6,Covalent,Workflow orchestration tool for HPC and quantum computing,"A Pythonic tool for orchestrating machine learning, high-performance computing (HPC), and quantum computing workflows across heterogeneous compute environments.",AI6;AI6-01,workflow_orchestration;distributed_computing,platform,Python,https://github.com/AgnostiqHQ/covalent,https://covalent.readthedocs.io/,Apache-2.0,workflow;hpc;quantum-computing;orchestration
7,Batch Shipyard,HPC and Batch workload management on Azure,"A tool to simplify deploying and managing High Performance Computing (HPC) and Batch workloads on Azure, supporting Docker and Singularity containers.",AI6;AI6-01,job_scheduling;cloud_hpc,platform,Python,https://github.com/Azure/batch-shipyard,https://batch-shipyard.readthedocs.io/,MIT,azure;hpc;batch-processing;docker
8,cyclecloud-singularity,Singularity container support for Azure CycleCloud,"A project enabling the use of Singularity containers within HPC clusters managed by Azure CycleCloud, facilitating reproducible scientific workflows in the cloud.",AI6;AI6-01,environment_management;cloud_hpc,tool,Ruby,https://github.com/Azure/cyclecloud-singularity,,MIT,azure;singularity;hpc
9,HPK,Kubernetes to Slurm/Singularity translator for HPC,A tool that allows running Kubernetes applications within HPC environments by translating deployments to Slurm jobs and Singularity/Apptainer containers.,AI6;AI6-01,workload_management;container_orchestration,tool,Go,https://github.com/CARV-ICS-FORTH/HPK,,Apache-2.0,kubernetes;slurm;hpc;singularity
10,KNoC,Kubernetes Virtual Kubelet for HPC clusters,"A Kubernetes Virtual Kubelet implementation that uses an HPC cluster as the container execution environment, bridging cloud-native and HPC workflows.",AI6;AI6-01,workload_management;resource_scheduling,tool,Go,https://github.com/CARV-ICS-FORTH/knoc,,Apache-2.0,kubernetes;hpc;virtual-kubelet
11,hpc-container-wrapper,Wrapper for HPC container installations,"A tool designed to wrap software installations into containers specifically for use on HPC systems, simplifying deployment and execution.",AI6;AI6-01,containerization;deployment,tool,Shell,https://github.com/CSCfi/hpc-container-wrapper,,MIT,hpc;container;wrapper
12,jupyter_environment_kernels,Jupyter plugin for Conda/Virtualenv kernel detection,"A Jupyter plugin that enables automatic detection and management of Conda and virtualenv environments as kernels, facilitating reproducible scientific computing in notebooks.",AI6;AI6-01,environment_management;interactive_computing,tool,Python,https://github.com/Cadair/jupyter_environment_kernels,,BSD-2-Clause,jupyter;conda;virtualenv;python
13,VR-Caps,Virtual environment for capsule endoscopy simulation,"A virtual reality environment for simulating active capsule endoscopy, used for training and testing control algorithms and medical analysis.",AI4S;Medical Physics,simulation;medical_imaging,platform,C#,https://github.com/CapsuleEndoscope/VirtualCapsuleEndoscopy,,NOASSERTION,simulation;medical;virtual-reality;endoscopy
14,ChangeMamba,Remote sensing change detection model,A Spatio-Temporal State Space Model (Mamba) based approach for change detection in remote sensing imagery.,AI4S;Remote Sensing,image_analysis;change_detection,solver,Python,https://github.com/ChenHongruixuan/ChangeMamba,,Apache-2.0,remote-sensing;deep-learning;mamba;change-detection
15,ZigMa,Mamba-based diffusion model,"Implementation of 'ZigMa: A DiT-Style Mamba-based Diffusion Model', a generative model architecture for scientific or general image synthesis.",AI4S;Deep Learning,generative_modeling;image_synthesis,solver,Python,https://github.com/CompVis/zigma,,Apache-2.0,diffusion-model;mamba;deep-learning
16,COVIDStrategyCalculator,Epidemiological strategy assessment tool,"A standalone software tool to assess testing and quarantine strategies for COVID-19 management, supporting contact tracing and isolation logic.",AI4S;Epidemiology,simulation;policy_analysis,tool,C++,https://github.com/CovidStrategyCalculator/COVIDStrategyCalculator,https://covidstrategycalculator.github.io/,LGPL-3.0,epidemiology;simulation;covid-19
17,mach-nix,Tool to create highly reproducible Python environments using Nix,"A tool that simplifies the creation of reproducible Python environments by leveraging the Nix package manager, solving complex dependency management issues in scientific computing.",AI6;AI6-01,environment_management;reproducibility,solver,Python,https://github.com/DavHau/mach-nix,,MIT,python;nix;reproducibility;environment-manager
18,cotainr,User-space Apptainer/Singularity container builder for HPC,A tool designed for High Performance Computing (HPC) users to build Apptainer/Singularity containers in user space without requiring privileged access.,AI6;AI6-01,container_build;hpc_deployment,workflow,Python,https://github.com/DeiC-HPC/cotainr,,EUPL-1.2,hpc;apptainer;singularity;container-builder
19,e4s-alc,Tool for customizing E4S container images,"E4S à la carte (e4s-alc) is a tool that enables users to customize container images by adding system packages and Spack packages, facilitating the creation of tailored HPC environments.",AI6;AI6-01,container_customization;image_generation,workflow,Python,https://github.com/E4S-Project/e4s-alc,,MIT,hpc;e4s;container;spack
20,e4s-cl,Container launcher and manager for E4S HPC applications,"A tool designed to simplify the launch of MPI applications inside containers on HPC systems, handling library injection and inter-node communication transparently.",AI6;AI6-01,job_launching;mpi_runtime,platform,Python,https://github.com/E4S-Project/e4s-cl,,MIT,hpc;mpi;container-runtime;e4s
21,LvArray,C++ template library for portable HPC array data structures,A C++ library providing performance-portable array data structures and utilities designed for scientific simulations on HPC architectures (developed by GEOS-DEV).,AI6;HPC,data_structure;scientific_computing,library,C++,https://github.com/GEOS-DEV/LvArray,,BSD-3-Clause,hpc;c++;array-manipulation;scientific-simulation
22,nd-Mamba2-torch,N-dimensional Mamba2 implementation in PyTorch,"A PyTorch library implementing the Mamba2 state space model with support for multi-dimensional data (1D/2D/3D), enabling the application of SSMs to scientific modeling tasks like vision or volumetric analysis.",AI-Model;Scientific-Modeling,modeling;deep_learning,library,Python,https://github.com/Human9000/nd-Mamba2-torch,,None,pytorch;mamba;state-space-models;scientific-ml
23,kube-mpi,MPI operator and runtime for HPC workloads on Kubernetes,"A prototype enabling High Performance Computing (HPC) developers to deploy stateful MPI-based applications (simulation, distributed deep learning) on container orchestration platforms like Kubernetes.",AI6;AI6-01,hpc_scheduling;distributed_computing,platform,Python,https://github.com/IBM/kube-mpi,,None,mpi;kubernetes;hpc;distributed-training
24,VM-UNet,Vision Mamba UNet model for medical image segmentation,"Implementation of VM-UNet, a medical image segmentation model integrating Vision Mamba blocks into a UNet architecture to capture long-range dependencies.",AI4-01;AI4,medical_image_segmentation;image_segmentation,solver,Python,https://github.com/JCruan519/VM-UNet,,Apache-2.0,medical-imaging;segmentation;mamba;deep-learning
25,Computer-Generated-Hologram,Simulation framework for computer-generated holography,"A framework for calculating and simulating computer-generated holograms (CGH), supporting recording and reproduction processes using MATLAB and Python.",AI6;AI4-05,holography_simulation;optical_simulation,library,Python,https://github.com/JackHCC/Computer-Generated-Hologram,,None,holography;optics;simulation;matlab
26,maru,CLI for containerizing scientific applications,An opinionated command-line interface designed to simplify the process of containerizing scientific applications for reproducibility and deployment.,AI6;AI6-01,containerization;reproducibility,workflow,Go,https://github.com/JaneliaSciComp/maru,,BSD-3-Clause,containers;science;reproducibility;cli
27,Swin-UMamba,Mamba-based UNet model for biomedical image analysis,"A deep learning model combining Swin Transformer and Mamba architectures for medical image segmentation tasks, with ImageNet-based pretraining.",AI4-01;AI4,medical_image_segmentation;biomedical_imaging,solver,Python,https://github.com/JiarunLiu/Swin-UMamba,,Apache-2.0,medical-imaging;mamba;swin-transformer;segmentation
28,IterativeSolvers.jl,Iterative algorithms for solving linear systems in Julia,"A Julia library providing iterative algorithms for solving linear systems, eigensystems, and singular value problems, essential for scientific computing.",AI1;AI6,linear_algebra;numerical_methods,library,Julia,https://github.com/JuliaLinearAlgebra/IterativeSolvers.jl,,MIT,julia;linear-algebra;iterative-solvers;math
29,Conda.jl,Conda environment manager integration for Julia,"A Julia package that allows managing binary dependencies using Conda, facilitating the integration of Python-based scientific tools within the Julia ecosystem.",AI6;AI6-01,package_management;environment_management,workflow,Julia,https://github.com/JuliaPy/Conda.jl,,NOASSERTION,julia;conda;package-manager;dependencies
30,KrylovKit.jl,Krylov methods for linear problems and matrix functions,"A Julia library implementing Krylov subspace methods for solving linear problems, eigenvalues, singular values, and matrix functions in scientific computing.",AI1;AI6,linear_algebra;numerical_methods,library,Julia,https://github.com/Jutho/KrylovKit.jl,,NOASSERTION,julia;krylov-methods;linear-algebra;eigenvalues
31,SCALE-MAMBA,Framework for Secure Multi-Party Computation (MPC),"A research system for Secure Multi-Party Computation, enabling privacy-preserving computation on data, often used in secure scientific data analysis.",AI6;AI6-02,secure_computation;cryptography,platform,Verilog,https://github.com/KULeuven-COSIC/SCALE-MAMBA,,NOASSERTION,mpc;cryptography;privacy;secure-computation
32,pytorch-aarch64,PyTorch binaries for ARM64/AArch64 architectures,"A repository providing PyTorch wheels and Conda packages for ARMv8/AArch64, enabling AI/ML workloads on Edge devices and ARM-based HPC systems.",AI6;AI6-01,runtime_environment;infrastructure,service,HTML,https://github.com/KumaTea/pytorch-aarch64,,MIT,pytorch;arm64;aarch64;wheels
33,uberenv,Automated Spack package deployment for HPC,A tool developed by LLNL to automate the use of Spack for building and deploying complex scientific software stacks and dependencies.,AI6;AI6-01,package_management;deployment,workflow,Shell,https://github.com/LLNL/uberenv,,NOASSERTION,spack;hpc;deployment;automation
34,PointMamba,State Space Model for 3D point cloud analysis,"A deep learning framework applying State Space Models (Mamba) to 3D point cloud analysis, applicable in geospatial and structural scientific data processing.",AI4-01;AI4,point_cloud_analysis;3d_vision,solver,Python,https://github.com/LMD0311/PointMamba,,Apache-2.0,point-cloud;mamba;3d-analysis;deep-learning
35,PSCondaEnvs,PowerShell scripts for Conda environment management,"A set of scripts enabling native Conda environment activation and deactivation within PowerShell, facilitating scientific workflows on Windows.",AI6;AI6-01,environment_management;shell_integration,workflow,PowerShell,https://github.com/Liquidmantis/PSCondaEnvs,,MIT,conda;powershell;windows;environment-manager
36,sumo-rl,Reinforcement Learning environments for traffic simulation,"A library providing Reinforcement Learning environments for traffic signal control using the SUMO simulator, supporting scientific research in transportation systems.",AI6;AI4-06,traffic_simulation;reinforcement_learning,library,Python,https://github.com/LucasAlegre/sumo-rl,,MIT,simulation;reinforcement-learning;traffic-control;sumo
37,LUMI-EasyBuild-contrib,EasyBuild configurations for LUMI supercomputer,"A repository of EasyConfig files for building scientific software stacks on the LUMI supercomputer, enabling reproducible HPC environments.",AI6;AI6-01,hpc_configuration;build_automation,dataset,Shell,https://github.com/Lumi-supercomputer/LUMI-EasyBuild-contrib,,GPL-3.0,hpc;easybuild;lumi;configuration
38,LUMI-SoftwareStack,Software stack setup for LUMI supercomputer,Scripts and configurations for setting up the LMOD-based module system and EasyBuild environment on the LUMI supercomputer.,AI6;AI6-01,hpc_environment;module_management,workflow,Python,https://github.com/Lumi-supercomputer/LUMI-SoftwareStack,,GPL-3.0,hpc;lmod;easybuild;lumi
39,dsatools,Digital signal analysis library for Python,"A library for digital signal analysis and parameter estimation, including ARMA, SSA, EMD, and other techniques for processing scientific signal data.",AI1;AI4,signal_processing;time_series_analysis,library,Jupyter Notebook,https://github.com/MVRonkin/dsatools,,MIT,signal-processing;spectral-analysis;python;decomposition
40,VRQuestionnaireToolkit,Toolkit for data collection in virtual environments,"A toolkit enabling the collection of subjective measures and questionnaire data within virtual environments, used for research in psychology and HCI.",AI4-06,data_collection;behavioral_research,library,C#,https://github.com/MartinFk/VRQuestionnaireToolkit,,MIT,vr;research-tools;data-collection;unity
41,MathInspector,Visual programming environment for scientific computing,A visual programming environment designed for scientific computing and mathematics visualization using Python.,AI1;AI6,scientific_visualization;visual_programming,platform,Python,https://github.com/MathInspector/MathInspector,,GPL-3.0,visualization;scientific-computing;python;math
42,ngmo-environments,Environment configurations for Met Office Momentum models,"Configuration repository for setting up Next Generation Environments for Momentum, supporting meteorological and climate modeling workflows.",AI6;AI6-01,environment_configuration;climate_modeling,workflow,Python,https://github.com/MetOffice/ngmo-environments,,BSD-3-Clause,meteorology;environment;configuration;met-office
43,AlphaFold3-Conda-Install,Installation scripts for AlphaFold 3 via Conda,"A repository providing scripts and guides to automate the installation and environment configuration of AlphaFold 3 using Conda, facilitating structural biology research.",AI6;AI6-01,environment_setup;software_deployment,workflow,Shell,https://github.com/Model3DBio/AlphaFold3-Conda-Install,,None,alphafold;conda;installation;structural-biology
44,molssi-hub,Container Hub for Computational Molecular Science,"A central hub and registry for containers specifically designed for computational molecular science applications, maintained by MolSSI.",AI6;AI6-01,container_registry;molecular_science,service,Python,https://github.com/MolSSI/molssi-hub,,NOASSERTION,containers;molecular-science;hub;molssi
45,facemap,Neural activity prediction from orofacial movements,"A framework for analyzing behavioral videos to predict neural activity from mouse orofacial movements, including SVD analysis of video data.",AI4-01;AI4,behavioral_analysis;neural_decoding,solver,Python,https://github.com/MouseLand/facemap,,GPL-3.0,neuroscience;behavior-analysis;svd;neural-activity
46,LightM-UNet,Lightweight Mamba-based UNet for medical segmentation,"A PyTorch implementation of LightM-UNet, a lightweight medical image segmentation model leveraging Mamba architecture for efficiency.",AI4-01;AI4,medical_image_segmentation;deep_learning,solver,Python,https://github.com/MrBlankness/LightM-UNet,,Apache-2.0,medical-imaging;mamba;segmentation;lightweight-model
47,Inception,Lightweight container runtime designed for HPC environments,"Inception is a lightweight container runtime primarily targeting HPC environments. It allows unprivileged users to run containers on HPC systems, focusing on security and performance.",AI6;AI6-01,container_runtime;hpc_execution,platform,C,https://github.com/NCAR/Inception,,BSD-3-Clause,hpc;container-runtime;linux-containers
48,Shifter,Container runtime for HPC environments enabling user-defined images,"Shifter is a container runtime designed for High Performance Computing (HPC) environments. It allows users to run custom Docker images on supercomputers, addressing security and performance requirements specific to shared HPC resources.",AI6;AI6-01,container_runtime;image_conversion,platform,C,https://github.com/NERSC/shifter,https://docs.nersc.gov/development/shifter/,NOASSERTION,hpc;docker;containers;nersc
49,Remote Sensing Mamba,State Space Model architecture tailored for remote sensing image analysis,"Official implementation of Remote Sensing Mamba, a deep learning model based on the Mamba architecture, specifically optimized for processing and analyzing remote sensing imagery data.",AI4S-EarthScience,image_analysis;feature_extraction,library,Python,https://github.com/NJU-LHRS/Official_Remote_Sensing_Mamba,,None,remote-sensing;mamba;deep-learning;earth-observation
50,NVFlare,Federated learning runtime environment for collaborative AI model training,"NVIDIA Federated Learning Application Runtime Environment (NVFlare) is a platform that enables federated learning, allowing multiple parties to collaborate on training AI models (often used in medical imaging and scientific collaboration) without sharing raw data.",AI6;AI6-01,federated_learning;distributed_training,platform,Python,https://github.com/NVIDIA/NVFlare,https://nvflare.readthedocs.io/,Apache-2.0,federated-learning;privacy-preserving;distributed-computing
51,container-canary,CLI tool for validating container images against defined requirements,Container Canary is a tool for testing and validating container requirements against versioned manifests. It is useful in scientific workflows to ensure container images meet specific environment specifications before deployment.,AI6;AI6-01,container_validation;quality_control,tool,Go,https://github.com/NVIDIA/container-canary,,Apache-2.0,container-testing;validation;devops-for-science
52,enroot,"Simple, powerful tool to turn container images into unprivileged sandboxes for HPC",Enroot is a tool designed to turn traditional container/OS images into unprivileged sandboxes. It is widely used in HPC environments (often with PyTorch/NVIDIA stacks) to provide a lightweight and performant container runtime.,AI6;AI6-01,container_runtime;sandbox_environment,platform,Shell,https://github.com/NVIDIA/enroot,https://github.com/NVIDIA/enroot/blob/master/doc/README.md,Apache-2.0,hpc;containers;sandbox;nvidia
53,HPC Container Maker,Tool to generate Dockerfiles and Singularity definition files for HPC,HPC Container Maker (HPCCM) is a Python tool that generates Dockerfiles and Singularity definition files. It simplifies the creation of container specifications for High Performance Computing (HPC) applications by providing high-level primitives.,AI6;AI6-01,image_generation;environment_definition,tool,Python,https://github.com/NVIDIA/hpc-container-maker,https://github.com/NVIDIA/hpc-container-maker/tree/master/docs,Apache-2.0,hpc;dockerfile-generator;singularity;reproducibility
54,libnvidia-container,Library for NVIDIA GPU container runtime support,The NVIDIA container runtime library (libnvidia-container) provides a C API to configure containers with NVIDIA GPU support. It is a foundational component for running GPU-accelerated scientific applications in containers.,AI6;AI6-01,gpu_acceleration;container_runtime,library,C,https://github.com/NVIDIA/libnvidia-container,,Apache-2.0,gpu;containers;nvidia;cuda
55,nvidia-container-runtime,Container runtime hook to enable NVIDIA GPU support in containers,NVIDIA Container Runtime is a modified version of runc that adds a custom pre-start hook to enable NVIDIA GPU support. It is essential for running AI and scientific simulation workloads in Docker/Kubernetes environments.,AI6;AI6-01,container_runtime;gpu_acceleration,platform,Go,https://github.com/NVIDIA/nvidia-container-runtime,,Apache-2.0,gpu;docker;runc;hpc
56,envkernel,"Jupyter kernel manager for Conda, Docker, Singularity, and Lmod environments","Envkernel allows users to run Jupyter kernels inside different environments such as Conda, Virtualenv, Docker, Singularity, and Lmod. It bridges interactive scientific computing (Jupyter) with HPC environment management systems.",AI6;AI6-01,environment_management;jupyter_integration,tool,Python,https://github.com/NordicHPC/envkernel,,BSD-3-Clause,jupyter;hpc;singularity;conda
57,hatch-conda,Hatch plugin to manage Conda environments,"Hatch-conda is a plugin for the Hatch project manager that enables the use of Conda environments. Since Conda is the de facto standard for scientific software packaging, this tool facilitates scientific Python development workflows.",AI6;AI6-01,package_management;environment_management,tool,Python,https://github.com/OldGrumpyViking/hatch-conda,,MIT,conda;hatch;python-packaging
58,pixi-pack,Tool to pack and unpack Conda environments created with pixi,Pixi-pack is a utility for packing and unpacking Conda environments created with the 'pixi' package manager. It aids in the reproducibility and distribution of scientific computing environments.,AI6;AI6-01,environment_packaging;reproducibility,tool,Rust,https://github.com/Quantco/pixi-pack,,BSD-3-Clause,conda;pixi;environment-management
59,neurodocker,Generator for custom Docker and Singularity images for neuroimaging,"Neurodocker is a command-line tool that generates custom Dockerfiles and Singularity definition files for neuroimaging and scientific computing. It simplifies the creation of reproducible environments containing common neuroscience software (FSL, SPM, etc.).",AI6;AI6-01;AI4S-Neuroscience,image_generation;reproducibility,tool,Python,https://github.com/ReproNim/neurodocker,https://github.com/ReproNim/neurodocker,Apache-2.0,neuroimaging;docker;singularity;reproducibility
60,Spackenv,Environment management wrapper for Spack in HPC clusters,"A tool developed by SJTU HPC to manage and switch between Spack environments, facilitating software management for sysadmins, users, and developers in high-performance computing contexts.",AI6;AI6-01,environment_management;package_management,platform,Python,https://github.com/SJTU-HPC/spackenv,,None,hpc;spack;environment-management
61,Create-A-Container,Builder for custom Singularity/Apptainer HPC containers,"A repository and toolset for building custom Singularity/Apptainer containers tailored for specific HPC environments (RAP Workstation, CREATE HPC), supporting reproducible scientific workflows.",AI6;AI6-01,container_building;environment_reproducibility,workflow,Python,https://github.com/Sensible-Robots/Create-A-Container,,None,singularity;apptainer;hpc;container
62,Singular,Computer algebra system for polynomial computations,"A computer algebra system for polynomial computations, with special emphasis on commutative and non-commutative algebra, algebraic geometry, and singularity theory.",Math;Algebra,algebraic_computation;polynomial_solving,solver,C++,https://github.com/Singular/Singular,https://www.singular.uni-kl.de/,GPL-2.0,computer-algebra-system;algebraic-geometry;polynomials
63,SkyText-Chinese-GPT3,Chinese GPT-3 pre-trained large language model,"A Chinese GPT-3 pre-trained large model capable of text generation, dialogue, translation, and reasoning, serving as a foundation model for NLP research.",AI;NLP,text_generation;translation;reasoning,model,Python,https://github.com/SkyWorkAIGC/SkyText-Chinese-GPT3,,MIT,gpt-3;llm;nlp;chinese
64,StaPH-B Docker Builds,Container recipes for public health bioinformatics,A collection of Dockerfiles and documentation providing reproducible container environments for public health bioinformatics tools and workflows.,AI6;AI6-01;Bioinformatics,environment_provisioning;bioinformatics_workflow,library,Dockerfile,https://github.com/StaPH-B/docker-builds,https://staphb.org,GPL-3.0,bioinformatics;docker;public-health;containers
65,BeeGFS CSI Driver,Kubernetes CSI driver for BeeGFS parallel file system,"A Container Storage Interface (CSI) driver that enables Kubernetes clusters to utilize BeeGFS, a high-performance parallel file system commonly used in HPC environments.",AI6;HPC,storage_management;hpc_infrastructure,platform,Go,https://github.com/ThinkParQ/beegfs-csi-driver,,Apache-2.0,beegfs;csi;kubernetes;hpc
66,skrl,Modular Reinforcement Learning library for robotics and physics simulations,"A modular Reinforcement Learning library built on PyTorch, JAX, and NVIDIA Warp, designed to support scientific environments like Isaac Lab, Brax, and Gymnasium for robotics and physics control tasks.",AI;Robotics;Physics,reinforcement_learning;robotics_control;physics_simulation,library,Python,https://github.com/Toni-SM/skrl,https://skrl.readthedocs.io,MIT,reinforcement-learning;robotics;isaac-lab;physics-simulation
67,AkôFlow,Middleware for container-based scientific workflows,"An open-source middleware for orchestrating and executing container-based scientific workflows across heterogeneous environments, developed for e-Science applications.",AI6;HPC,workflow_orchestration;scientific_workflow,workflow,Go,https://github.com/UFFeScience/akoflow,,None,scientific-workflow;middleware;containers;hpc
68,E4S Spack Environments,Spack environments and container recipes for E4S,"Configuration files and recipes for creating Spack environments and containers for the Extreme-scale Scientific Software Stack (E4S), facilitating reproducible HPC software deployment.",AI6;AI6-01;HPC,environment_provisioning;software_stack_management,library,Dockerfile,https://github.com/UO-OACISS/e4s,https://e4s-project.github.io/,None,e4s;spack;hpc;containers
69,MogaNet,Efficient Multi-order Gated Aggregation Network for vision tasks,"Implementation of MogaNet, a neural network architecture for efficient computer vision tasks, serving as a tool for image analysis and feature extraction.",AI;Computer Vision,image_classification;feature_extraction,model,Jupyter Notebook,https://github.com/Westlake-AI/MogaNet,,Apache-2.0,computer-vision;deep-learning;moganet
70,MedMamba,Vision Mamba model for medical image classification,"A deep learning model applying the Mamba architecture to medical image classification tasks, providing a tool for medical image analysis.",AI;Medical Imaging,medical_image_classification;image_analysis,model,Python,https://github.com/YubiaoYue/MedMamba,,None,medical-imaging;mamba;deep-learning
71,NavRL,Reinforcement learning framework for safe flight navigation,"A reinforcement learning framework and library for training safe flight navigation agents in dynamic environments, integrating with ROS and NVIDIA Isaac.",AI;Robotics,navigation;robotics_control;reinforcement_learning,solver,C++,https://github.com/Zhefan-Xu/NavRL,,MIT,robotics;navigation;reinforcement-learning;ros
72,BlackMamba,Implementation of the BlackMamba state-space model,"Code repository for the BlackMamba architecture, a state-space model for sequence modeling, serving as a tool for AI research.",AI;Deep Learning,sequence_modeling;model_architecture,model,Python,https://github.com/Zyphra/BlackMamba,,None,mamba;ssm;deep-learning
73,PSSA,Singular Spectrum Analysis library for time series forecasting,"A Python implementation of Singular Spectrum Analysis (SSA) for time series decomposition and forecasting, useful in scientific data analysis.",Math;Statistics;Time Series Analysis,forecasting;time_series_analysis;decomposition,library,Jupyter Notebook,https://github.com/aj-cloete/pssa,,None,ssa;time-series;forecasting
74,ScienceWorld,Text-based virtual environment for scientific discovery agents,A simulation environment centered around elementary science curriculum tasks to test and evaluate AI agents' reasoning and scientific problem-solving capabilities.,AI Research;General Science,simulation;agent_training;reasoning,platform,Scala,https://github.com/allenai/ScienceWorld,https://sciworld.apps.allenai.org/,Apache-2.0,rl-environment;science-simulation;nlp
75,DiscoveryWorld,Virtual environment for automated scientific discovery agents,A virtual environment designed for developing and evaluating automated agents capable of performing scientific discovery tasks.,AI Research;Scientific Discovery,simulation;agent_training;discovery,platform,Python,https://github.com/allenai/discoveryworld,,Apache-2.0,rl-environment;scientific-discovery;agent
76,conda-merge,Utility to merge Conda environment files,"A tool to merge multiple Conda environment specification files into a single file, facilitating complex scientific environment management.",AI6-01;Scientific Computing,environment_management,solver,Python,https://github.com/amitbeka/conda-merge,,MIT,conda;environment-management;reproducibility
77,nb_conda,Conda environment management extension for Jupyter,An extension that allows management of Conda environments and packages directly from within the Jupyter Notebook interface.,AI6-01;Scientific Computing,environment_management;interactive_computing,platform,Python,https://github.com/anaconda/nb_conda,,BSD-3-Clause,jupyter;conda;notebook
78,nb_conda_kernels,Jupyter extension for Conda environment kernels,"A package that automatically creates Jupyter kernels for all environments found in the Conda installation, enabling easy switching between scientific environments.",AI6-01;Scientific Computing,environment_management;kernel_management,platform,Python,https://github.com/anaconda/nb_conda_kernels,,BSD-3-Clause,jupyter;conda;kernels
79,Apptainer,Container system for High Performance Computing (HPC),"The open-source container system (formerly Singularity) designed for HPC environments, allowing researchers to package and run applications reproducibly.",AI6;AI6-01;HPC,containerization;reproducibility;runtime_management,platform,Go,https://github.com/apptainer/apptainer,https://apptainer.org/,NOASSERTION,hpc;containers;singularity
80,Singularity,Container platform for HPC (Legacy/Snapshot),"The legacy repository for Singularity (now Apptainer), a container platform optimized for High Performance Computing and scientific workflows.",AI6;AI6-01;HPC,containerization;reproducibility,platform,Go,https://github.com/apptainer/singularity,https://apptainer.org/,NOASSERTION,hpc;containers;legacy
81,uv,Extremely fast Python package and project manager,"A modern, high-performance Python package manager that serves as a drop-in replacement for pip and pip-tools, increasingly used in scientific Python ecosystems for environment reproducibility.",AI6-01;Scientific Computing,package_management;environment_management,platform,Rust,https://github.com/astral-sh/uv,https://docs.astral.sh/uv/,Apache-2.0,python;package-manager;rust
82,uvify,Tool to convert Python repos to uv environments,"A utility to automatically generate `uv` environment configurations from existing Python repositories, facilitating reproducible scientific environments.",AI6-01;Scientific Computing,environment_management;reproducibility,solver,Python,https://github.com/avilum/uvify,,MIT,uv;python;environment
83,DockerMake,Reproducible Docker image build system for complex stacks,"A command-line tool to build and manage Docker images for complex software stacks, designed to support reproducible research and scientific workflows.",AI6-01;Scientific Computing,container_build;reproducibility,workflow,Python,https://github.com/avirshup/DockerMake,,Apache-2.0,docker;reproducibility;build-tool
84,TwinGraph,Distributed container orchestration framework for simulations,"A Python framework for orchestrating distributed containerized applications, specifically targeting high-throughput simulations, digital twins, and scientific optimization tasks on AWS/K8s.",AI6;HPC;Simulation,orchestration;simulation;digital_twin,platform,Python,https://github.com/aws-samples/twingraph,,MIT-0,orchestration;simulation;kubernetes
85,Bactopia,Pipeline for complete analysis of bacterial genomes,"A flexible and comprehensive Nextflow pipeline for the analysis of bacterial genomes, including QC, assembly, and annotation.",Bioinformatics;Genomics,genome_analysis;pipeline;assembly,workflow,Nextflow,https://github.com/bactopia/bactopia,https://bactopia.github.io/,MIT,bioinformatics;bacteria;nextflow
86,unidep,Unified dependency management for pip and conda,"A tool that provides a single source of truth for Python requirements, handling both pip and conda dependencies to simplify scientific environment setup.",AI6-01;Scientific Computing,dependency_management;environment_setup,solver,Python,https://github.com/basnijholt/unidep,,BSD-3-Clause,conda;pip;dependencies
87,pybullet-gym,Open-source OpenAI Gym MuJoCo environments using PyBullet,"A reimplementation of OpenAI Gym MuJoCo environments using the open-source PyBullet physics engine, enabling reinforcement learning research without proprietary licenses.",AI Research;Robotics;Reinforcement Learning,simulation,platform,Python,https://github.com/benelot/pybullet-gym,,NOASSERTION,reinforcement-learning;pybullet;physics-simulation;gym-environments
88,Master of Pores,Nextflow pipeline for direct RNA Nanopore sequencing analysis,"A bioinformatics pipeline built with Nextflow for processing and analyzing direct RNA sequencing data from Oxford Nanopore technologies, handling preprocessing, alignment, and modification detection.",Bioinformatics;Genomics,pipeline_processing,workflow,Nextflow,https://github.com/biocorecrg/master_of_pores,https://biocorecrg.github.io/master_of_pores/,MIT,nanopore;rna-seq;nextflow;bioinformatics
89,Graph-Mamba,Long-range graph sequence modelling with selective state spaces,"A deep learning model integrating Mamba's selective state space models with graph neural networks to capture long-range dependencies in graph sequences, applicable to molecular and structural analysis.",AI for Science;Graph Learning,modeling,solver,Python,https://github.com/bowang-lab/Graph-Mamba,,NOASSERTION,graph-neural-networks;mamba;deep-learning;sequence-modeling
90,U-Mamba,CNN-Mamba hybrid network for biomedical image segmentation,A general-purpose biomedical image segmentation tool that enhances long-range dependency modeling by combining State Space Models (Mamba) with CNN-based U-Net architectures.,Biomedical Imaging;AI for Science,image_segmentation,solver,Python,https://github.com/bowang-lab/U-Mamba,,Apache-2.0,medical-imaging;segmentation;mamba;deep-learning
91,irlba,Fast truncated singular value decomposition (SVD) library,"An R library for implicitly restarted Lanczos bidiagonalization algorithms, providing fast truncated SVD and PCA for large sparse or dense matrices common in scientific data analysis.",Statistics;Scientific Computing,statistical_analysis,library,R,https://github.com/bwlewis/irlba,,NOASSERTION,svd;pca;matrix-factorization;sparse-matrices
92,calkit,Project management tool for reproducible research,"A command-line tool and Python library designed to simplify version control, environment management, and reproducible pipelines specifically for research projects.",AI6;AI6-01;Reproducible Research,workflow_management,workflow,Python,https://github.com/calkit/calkit,https://calkit.readthedocs.io/,MIT,reproducibility;git;pipeline;research-management
93,cmcrameri,Perceptually uniform colourmaps for geosciences,"A Python library providing Fabio Crameri's perceptually uniform colourmaps, designed to accurately represent scientific data in geosciences and prevent visual distortion.",Geoscience;Scientific Visualization,visualization,library,Python,https://github.com/callumrollo/cmcrameri,,NOASSERTION,colormaps;visualization;geoscience;matplotlib
94,conda-auto-env,Automatic Conda environment activator,"A shell utility that automatically activates the appropriate Conda environment when entering a directory containing an environment.yml file, streamlining scientific workflows.",AI6;AI6-01,environment_management,solver,Shell,https://github.com/chdoig/conda-auto-env,,BSD-3-Clause,conda;environment-management;productivity;shell-script
95,vim-conda,Vim plugin for Conda environment switching,"A Vim plugin that allows users to change Conda environments directly within the editor, facilitating development in scientific Python environments.",AI6;AI6-01,environment_management,solver,Python,https://github.com/cjrh/vim-conda,,MIT,vim;conda;ide-plugin;python
96,CompareM2,Microbial genomes-to-report pipeline,"A comprehensive pipeline for comparative genomics of microbial isolates, automating the process from genomes to analytical reports.",Bioinformatics;Microbiology,genomic_analysis,workflow,Python,https://github.com/cmkobel/CompareM2,,GPL-3.0,genomics;pipeline;microbial-analysis;bioinformatics
97,detectron2-windows,Windows build of Detectron2,"A distribution of Facebook AI Research's Detectron2 library optimized for Windows, enabling object detection and segmentation research on Windows platforms.",Computer Vision;AI Research,image_analysis,library,Python,https://github.com/conansherry/detectron2,,Apache-2.0,detectron2;object-detection;segmentation;windows
98,conda-env,Interface for managing Conda environments,"A tool for managing Conda environments, allowing users to create, export, list, remove, and update environments, essential for reproducible scientific computing.",AI6;AI6-01,environment_management,solver,Python,https://github.com/conda-archive/conda-env,,NOASSERTION,conda;environment-management;reproducibility;python
99,conda-smithy,Tool for managing conda-forge feedstocks,"A tool used to manage the conda-forge scientific software distribution ecosystem, automating the linting, re-rendering, and updating of feedstock repositories.",AI6;AI6-01,package_management,solver,Python,https://github.com/conda-forge/conda-smithy,https://conda-forge.org/docs/,BSD-3-Clause,conda-forge;packaging;automation;scientific-software
100,Miniforge,Minimal installer for Conda specific to conda-forge,"A minimal installer for Conda that is pre-configured to use the conda-forge channel, widely used in the scientific community for setting up Python/R environments, especially on architectures like Apple Silicon (M1/M2) and AArch64.",AI6;AI6-01,environment_management;package_installation,platform,Shell,https://github.com/conda-forge/miniforge,https://github.com/conda-forge/miniforge,BSD-3-Clause,conda;installer;python-distribution;hpc
101,conda-docker,Tool to create minimal docker images from conda environments,"A tool that allows users to generate Docker images directly from Conda environments without requiring a Docker daemon, facilitating the containerization of scientific workflows.",AI6;AI6-01,containerization;reproducibility,workflow,Python,https://github.com/conda-incubator/conda-docker,https://github.com/conda-incubator/conda-docker,BSD-3-Clause,docker;conda;container-image;reproducibility
102,conda-env-builder,Builder for maintaining multiple custom conda environments,"A tool to build and maintain multiple custom Conda environments from a single configuration source, useful for managing complex scientific software stacks.",AI6;AI6-01,environment_management;dependency_management,workflow,Scala,https://github.com/conda-incubator/conda-env-builder,https://github.com/conda-incubator/conda-env-builder,MIT,conda;environment-manager;build-tool
103,conda-project,Tool for encapsulating and reproducing projects with Conda,"A tool designed to encapsulate, run, and reproduce data science projects by managing Conda environments and project-specific commands.",AI6;AI6-01,project_management;reproducibility,workflow,Python,https://github.com/conda-incubator/conda-project,https://conda-project.readthedocs.io,BSD-3-Clause,reproducible-research;conda;project-management
104,conda-store,Server for managing and serving Conda environments,"A tool that provides a way to build and serve Conda environments for data science teams, often integrated with JupyterHub to ensure consistent environments across users.",AI6;AI6-01,environment_management;collaboration,service,Python,https://github.com/conda-incubator/conda-store,https://conda-store.readthedocs.io,BSD-3-Clause,jupyterhub;conda;data-science;environment-serving
105,conda-tree,Dependency tree analyzer for Conda environments,"A utility to inspect the dependency tree of Conda environments, helping scientists debug package conflicts and understand environment structure.",AI6;AI6-01,dependency_analysis;debugging,solver,Python,https://github.com/conda-incubator/conda-tree,https://github.com/conda-incubator/conda-tree,MIT,dependency-tree;conda;visualization
106,condacolab,Tool to install Conda on Google Colab,"A Python package that enables the installation and use of Conda/Mamba on Google Colab, allowing researchers to use scientific packages not available in the default Colab runtime.",AI6;AI6-01,environment_setup;cloud_computing,library,Jupyter Notebook,https://github.com/conda-incubator/condacolab,https://github.com/conda-incubator/condacolab,MIT,google-colab;conda;python;research-environment
107,conda-execute,Execute scripts in temporary Conda environments,"A tool to execute scripts in their own temporary, reproducible Conda environments defined within the script itself, ensuring consistent execution contexts.",AI6;AI6-01,reproducibility;script_execution,workflow,Python,https://github.com/conda-tools/conda-execute,https://github.com/conda-tools/conda-execute,BSD-3-Clause,reproducibility;conda;scripting
108,Conda,"Package, dependency and environment management for any language","The de facto standard package and environment manager for scientific computing (Python, R, etc.), enabling users to install, run, and update packages and their dependencies.",AI6;AI6-01,package_management;environment_management,platform,Python,https://github.com/conda/conda,https://docs.conda.io,BSD-3-Clause,package-manager;virtual-environment;scientific-computing
109,conda-build,Tools for building conda packages,"The build system for creating Conda packages, essential for packaging scientific software for distribution via channels like conda-forge.",AI6;AI6-01,package_building;distribution,workflow,Python,https://github.com/conda/conda-build,https://docs.conda.io/projects/conda-build,BSD-3-Clause,build-tool;packaging;conda
110,conda-libmamba-solver,Fast libmamba-based solver for Conda,A plugin for Conda that uses the libmamba solver to significantly speed up dependency resolution in complex scientific environments.,AI6;AI6-01,dependency_resolution;optimization,library,Python,https://github.com/conda/conda-libmamba-solver,https://conda.github.io/conda-libmamba-solver/,BSD-3-Clause,solver;performance;conda;mamba
111,conda-lock,Lightweight lockfile generator for Conda,"A tool to generate fully reproducible lockfiles for Conda environments across multiple platforms, ensuring identical environments for scientific collaboration.",AI6;AI6-01,reproducibility;dependency_locking,workflow,Python,https://github.com/conda/conda-lock,https://conda-incubator.github.io/conda-lock/,MIT,lockfile;reproducibility;conda
112,conda-pack,Tool to package conda environments for redistribution,"A tool for creating relocatable archives of Conda environments, widely used to deploy scientific environments to Spark/Hadoop clusters or HPC nodes where Conda is not installed.",AI6;AI6-01,deployment;environment_archiving,workflow,Python,https://github.com/conda/conda-pack,https://conda.github.io/conda-pack/,BSD-3-Clause,deployment;hpc;archive;conda
113,constructor,Tool for creating installers from conda packages,"A tool that allows users to create custom installers (like Miniconda or Anaconda) from a collection of Conda packages, used for distributing scientific software stacks.",AI6;AI6-01,distribution;installer_generation,workflow,Python,https://github.com/conda/constructor,https://github.com/conda/constructor,BSD-3-Clause,installer;packaging;distribution
114,Grayskull,Recipe generator for Conda packages,"An automatic recipe generator for Conda that creates recipes for PyPI packages, simplifying the process of adding scientific Python libraries to conda-forge.",AI6;AI6-01,package_building;automation,workflow,Python,https://github.com/conda/grayskull,https://github.com/conda/grayskull,Apache-2.0,recipe-generator;pypi;conda-forge
115,rattler,Rust crates for the Conda ecosystem,"A high-performance Rust library and toolkit for working with the Conda ecosystem, providing the foundation for next-generation Conda tools (like pixi).",AI6;AI6-01,package_management;infrastructure,library,Rust,https://github.com/conda/rattler,https://docs.rs/rattler/latest/rattler/,BSD-3-Clause,rust;conda;performance;library
116,Buildah,"Tool for building OCI images, often used in HPC",A tool that facilitates building OCI container images. It is particularly important in scientific HPC environments for its ability to build containers without root privileges (rootless).,AI6;AI6-01,container_building;hpc_infrastructure,workflow,Go,https://github.com/containers/buildah,https://buildah.io,Apache-2.0,containers;hpc;oci;rootless
117,Podman,Daemonless container engine for OCI containers,"A daemonless container engine for developing, managing, and running OCI containers. It is the standard for running containers in HPC environments due to its rootless capabilities and compatibility with Docker CLI.",AI6;AI6-01,container_runtime;hpc_infrastructure,platform,Go,https://github.com/containers/podman,https://podman.io,Apache-2.0,containers;hpc;rootless;docker-alternative
118,podman-compose,Run docker-compose.yml using Podman,"A script that allows users to run docker-compose.yml files using Podman, enabling the orchestration of multi-container scientific workflows in rootless environments.",AI6;AI6-01,orchestration;workflow_management,workflow,Python,https://github.com/containers/podman-compose,https://github.com/containers/podman-compose,GPL-2.0,orchestration;compose;podman
119,podman-py,Python bindings for Podman,"A Python library for interacting with the Podman REST API, allowing scientific applications to programmatically manage containers.",AI6;AI6-01,automation;container_management,library,Python,https://github.com/containers/podman-py,https://github.com/containers/podman-py,Apache-2.0,python-api;podman;automation
120,podman-tui,Terminal UI for Podman,"A terminal user interface for Podman, facilitating the management of containers and pods in terminal-only environments common in HPC and remote servers.",AI6;AI6-01,container_management;visualization,workflow,Go,https://github.com/containers/podman-tui,https://github.com/containers/podman-tui,Apache-2.0,tui;podman;management
121,RamaLama,Tool for local serving of AI models via containers,"An open-source tool that simplifies the local serving and inference of AI models using containers, abstracting the complexity of hardware acceleration and container runtimes.",AI6;AI6-01,model_inference;ai_serving,platform,Python,https://github.com/containers/ramalama,https://github.com/containers/ramalama,MIT,ai-inference;containers;llm;model-serving
122,mrs_apptainer,Apptainer wrappers and resources for the MRS UAV System,"Provides Apptainer (Singularity) wrappers, definitions, and scripts specifically designed for the MRS UAV System, facilitating reproducible robotics research environments and workflows.",AI6;AI6-01;Robotics,environment_management;robotics_simulation,workflow,Shell,https://github.com/ctu-mrs/mrs_apptainer,,None,apptainer;robotics;uav;reproducible-research
123,ck-docker,Collective Knowledge extension for Docker automation,"Extension for the Collective Knowledge (CK) framework to automate Docker build, run, and push functions, enabling collaborative and reproducible research workflows and artifact management.",AI6;AI6-01,reproducible_research;artifact_management,workflow,Dockerfile,https://github.com/ctuning/ck-docker,,BSD-3-Clause,collective-knowledge;reproducible-research;docker;artifact-evaluation
124,Omnia Artifactory,HPC cluster container management and automation tools,"Part of the Omnia framework, providing tools to build, manage, and deploy containerized services for HPC clusters, including Ansible-based provisioning and automated image creation.",AI6;AI6-01;HPC,hpc_provisioning;cluster_management,platform,Shell,https://github.com/dell/omnia-artifactory,,Apache-2.0,hpc;ansible;container-deployment;dell-omnia
125,Phobos,Blender add-on for robot model creation (URDF/SDF),"An add-on for Blender that enables the creation and editing of URDF, SDF, and SMURF robot models in a WYSIWYG environment for robotics simulation and research.",Robotics;Modeling,robot_modeling;simulation_setup,solver,Python,https://github.com/dfki-ric/phobos,,BSD-3-Clause,blender;urdf;robotics;simulation
126,wfl,Simple job workflow library for Go supporting HPC/Containers,"A Go library for creating job workflows that can run in processes, containers, pods, or HPC jobs (supporting DRMAA), facilitating scientific workflow management.",AI6;AI6-01;HPC,workflow_management;job_scheduling,library,Go,https://github.com/dgruber/wfl,,BSD-2-Clause,workflow;hpc;drmaa;go
127,neuron_poker,Texas Hold'em RL environment,"A reinforcement learning environment for Texas Hold'em poker, based on keras-rl, used for AI research in game theory and decision making.",AI_Research;Reinforcement_Learning,reinforcement_learning;game_simulation,library,Python,https://github.com/dickreuter/neuron_poker,,MIT,reinforcement-learning;poker;openai-gym;ai-research
128,poetry2conda,Tool to convert Poetry projects to Conda environments,"A utility that converts Python pyproject.toml configuration files into Conda environment.yaml files, bridging standard Python packaging with the scientific Conda ecosystem.",AI6;AI6-01,dependency_management;environment_conversion,solver,Python,https://github.com/dojeda/poetry2conda,,MIT,poetry;conda;python;dependency-management
129,earth-analytics-python-env,Conda environment and Docker container for Earth and environmental science,A pre-configured Conda environment and Docker container designed to support Python-based workflows in earth and environmental data science. It ensures reproducibility by providing a consistent set of libraries for geospatial analysis and data processing.,AI6;AI6-01;Earth Science,environment_management;reproducibility,platform,Shell,https://github.com/earthlab/earth-analytics-python-env,https://www.earthdatascience.org/,BSD-3-Clause,conda;docker;earth-science;reproducibility
130,JSC EasyBuild Repository,Jülich Supercomputing Centre's EasyBuild configuration repository,The public repository of EasyBuild configuration files (easyconfigs) and custom blocks used by the Jülich Supercomputing Centre (JSC). It enables the reproduction of the scientific software stack deployed on JSC's HPC systems.,AI6;AI6-01;HPC,package_management;environment_deployment,dataset,Python,https://github.com/easybuilders/JSC,https://easybuild.io/,GPL-3.0,hpc;easybuild;configuration;jsc
131,EasyBuild,Software build and installation framework for HPC systems,"A software installation framework written in Python that allows for the structured, robust, and reproducible building of scientific software stacks on High Performance Computing (HPC) systems. It automates the compilation and management of dependencies.",AI6;AI6-01;HPC,package_management;compilation;environment_management,platform,Shell,https://github.com/easybuilders/easybuild,https://easybuild.io/,GPL-2.0,hpc;build-automation;scientific-software;python
132,easybuild-easyblocks,Collection of Python modules for EasyBuild software installation logic,"A collection of 'easyblocks' that implement the specific build and installation logic for various scientific software packages within the EasyBuild framework. These blocks define how to configure, build, and install complex scientific applications.",AI6;AI6-01;HPC,package_management;build_automation,library,Python,https://github.com/easybuilders/easybuild-easyblocks,https://docs.easybuild.io/en/latest/Writing_easyblocks.html,GPL-2.0,easybuild;hpc;build-recipes
133,easybuild-easyconfigs,Collection of build configuration files for EasyBuild,"A comprehensive collection of 'easyconfig' files that describe which scientific software versions to build, using which toolchains and dependencies. It serves as the central database of recipes for the EasyBuild ecosystem.",AI6;AI6-01;HPC,package_management;reproducibility,dataset,Python,https://github.com/easybuilders/easybuild-easyconfigs,https://easybuild.io/,GPL-2.0,easybuild;configuration;hpc;recipes
134,easybuild-framework,Core framework for the EasyBuild software installation system,"The core Python framework of EasyBuild that provides the functionality to parse easyconfigs, load easyblocks, and execute the build and installation process for scientific software on HPC infrastructure.",AI6;AI6-01;HPC,package_management;framework,platform,Python,https://github.com/easybuilders/easybuild-framework,https://easybuild.io/,GPL-2.0,hpc;python;installation-framework
135,eb-singularity,Integration tools for EasyBuild and Singularity containers,"A set of tools and scripts to integrate EasyBuild with Singularity (Apptainer), enabling the generation of scientific containers directly from EasyBuild recipes for reproducible HPC workflows.",AI6;AI6-01;HPC,containerization;image_generation,workflow,Roff,https://github.com/easybuilders/eb-singularity,https://easybuild.io/,None,singularity;easybuild;containers;hpc
136,OpenArm,Open-source humanoid arm for physical AI research,"A low-cost, open-source robotic arm platform designed for research in physical AI, teleoperation, and contact-rich manipulation. It provides the hardware design and software interfaces necessary for training and testing embodied AI agents.",Robotics;Embodied AI,scientific_modeling;data_generation,platform,MDX,https://github.com/enactic/openarm,https://open-arm.com/,Apache-2.0,robotics;physical-ai;hardware;research-platform
137,EPFL-SCITAS Spack Config,Spack configuration for EPFL SCITAS HPC deployment,"A repository containing site-specific configurations, package lists, and helper scripts for deploying the Spack package manager at the EPFL SCITAS supercomputing facility. It facilitates the reproducible deployment of scientific software in that specific HPC environment.",AI6;AI6-01;HPC,environment_management;package_deployment,dataset,Jinja,https://github.com/epfl-scitas/spack-packagelist,https://spack.io,None,spack;hpc;epfl;configuration
138,svd3,Fast 3x3 singular value decomposition library,"A specialized library for performing fast singular value decomposition (SVD), diagonalization, and QR decomposition of 3x3 matrices. This is a critical low-level kernel for many physics simulations, computer graphics, and mechanics problems.",Scientific Computing;Physics,scientific_data_analysis;linear_algebra,library,Mathematica,https://github.com/ericjang/svd3,,MIT,svd;linear-algebra;mathematica;physics-simulation
139,CSCS Production Scripts,User scripts and tools for CSCS HPC environment,"A collection of utility scripts and tools for users of the Swiss National Supercomputing Centre (CSCS). It includes helpers for job submission, environment setup, and data management specific to CSCS scientific infrastructure.",AI6;AI6-01;HPC,job_management;environment_setup,workflow,Python,https://github.com/eth-cscs/production,https://www.cscs.ch/,GPL-3.0,hpc;cscs;scripts;utility
140,py2spack,Converter from Python packages to Spack recipes,A tool that automates the conversion of standard Python packages (from PyPI) into Spack package recipes. It simplifies the process of adding new Python scientific libraries to the Spack ecosystem.,AI6;AI6-01;HPC,package_management;automation,workflow,Python,https://github.com/eth-cscs/py2spack,https://spack.io,None,spack;python;pypi;packaging
141,Sarus,OCI-compatible container engine for HPC environments,"A container engine designed specifically for High Performance Computing (HPC) environments. It provides OCI compliance while addressing the unique security and performance requirements of HPC, such as support for MPI, GPU, and high-speed interconnects.",AI6;AI6-01;HPC,containerization;runtime,platform,C++,https://github.com/eth-cscs/sarus,https://sarus.readthedocs.io/,BSD-3-Clause,hpc;containers;oci;mpi
142,spack-batteries-included,Standalone Spack installer,"A project aimed at installing the Spack package manager without relying on system dependencies, ensuring a self-contained and portable package management setup for scientific computing environments.",AI6;AI6-01;HPC,package_management;deployment,workflow,C,https://github.com/eth-cscs/spack-batteries-included,https://spack.io,GPL-3.0,spack;installation;portability
143,Habitat-Lab,Modular library for training embodied AI agents,A modular high-level library designed to train embodied AI agents across a variety of tasks (like navigation and instruction following) and 3D environments. It serves as a standard platform for simulation-based AI research.,AI6;Embodied AI,scientific_modeling;simulation,platform,Python,https://github.com/facebookresearch/habitat-lab,https://aihabitat.org/,MIT,embodied-ai;simulation;reinforcement-learning;robotics
144,fastai-docker-containers,Docker images for the fastai deep learning library,"Official Docker containers for the fastai library, providing a reproducible and pre-configured environment for deep learning research and development. It simplifies the setup of GPU-accelerated AI workflows.",AI6;AI6-01;Deep Learning,environment_management;reproducibility,platform,Shell,https://github.com/fastai/docker-containers,https://github.com/fastai/docker-containers,Apache-2.0,fastai;docker;deep-learning;gpu
145,easybuild.experimental,Experimental contributions for EasyBuild,A repository for experimental or community-contributed EasyBuild configurations and blocks that are not yet part of the main stable release. It serves as a staging ground for new scientific software recipes.,AI6;AI6-01;HPC,package_management;experimentation,dataset,Python,https://github.com/fgeorgatos/easybuild.experimental,https://easybuild.io/,None,easybuild;experimental;hpc;recipes
146,easy_update,Tool to update EasyBuild configuration files,"A utility script to automate the updating of EasyBuild easyconfig files, specifically for R and Python bundles. It helps maintainers keep scientific software stacks up to date with minimal manual effort.",AI6;AI6-01;HPC,package_management;maintenance,workflow,Python,https://github.com/fizwit/easy_update,,None,easybuild;automation;maintenance;python;r
147,nixpack,Integration of Nix and Spack package managers,An experimental tool from the Flatiron Institute that aims to combine the strengths of the Nix package manager (reproducibility) and Spack (HPC optimization) for scientific software deployment.,AI6;AI6-01;HPC,package_management;reproducibility,workflow,Nix,https://github.com/flatironinstitute/nixpack,,MIT,nix;spack;hpc;package-management
148,copip,Environment development overlays for Conda to facilitate reproducible scientific workflows,"A tool designed to manage development overlays for Conda environments, allowing users to install packages in 'development mode' (editable installs) on top of existing Conda environments. This is particularly useful in scientific computing workflows where researchers need to modify libraries without breaking the base reproducible environment.",AI6;AI6-01,environment_management;reproducibility,tool,Python,https://github.com/fperez/copip,,BSD-3-Clause,conda;environment-management;reproducibility;python
149,SegMamba,Long-range sequential modeling Mamba for 3D medical image segmentation,"A deep learning model based on the Mamba architecture designed for 3D medical image segmentation. It addresses the challenge of modeling long-range dependencies in volumetric medical data, providing a tool for scientific analysis of medical imaging datasets.",AI4S;Medical Imaging,image_segmentation;medical_analysis,model,Python,https://github.com/ge-xing/SegMamba,,None,medical-imaging;segmentation;mamba;deep-learning
150,Popper,Container-native task automation engine for scientific reproducibility,"A tool for defining and executing container-native workflows, specifically designed to implement the 'Popper Convention' for scientific reproducibility. It allows researchers to automate experiments and validate results in a portable way using containers (Docker, Singularity).",AI6;AI6-01,workflow_automation;reproducibility,workflow,Python,https://github.com/getpopper/popper,https://popper.readthedocs.io,MIT,reproducibility;workflow;containers;scientific-computing
151,GitLab HPC CI/CB,GitLab runner scripts for HPC systems using Enroot and Slurm,"A set of tools and scripts to enable Continuous Integration (CI) and Continuous Benchmarking (CB) on High Performance Computing (HPC) systems. It leverages Slurm for job scheduling and Enroot for containerization, facilitating automated testing of scientific software in HPC environments.",AI6;AI6-01,hpc_workflow;ci_cd,tool,Shell,https://github.com/ginkgo-project/gitlab-hpc-ci-cb,,BSD-3-Clause,hpc;slurm;enroot;ci-cd;gitlab
152,docker-centos7-slurm,Slurm Docker container for simulating HPC clusters,"A Docker container setup that runs Slurm on CentOS 7, providing a simulated HPC environment. This tool is used by researchers and developers to develop and test HPC workflows and job submission scripts locally before deploying to actual supercomputers.",AI6;AI6-01,hpc_simulation;environment_simulation,tool,Python,https://github.com/giovtorres/docker-centos7-slurm,,MIT,slurm;hpc;docker;simulation
153,HOOMD-blue,Molecular dynamics and Monte Carlo soft matter simulation on GPUs,"A general-purpose particle simulation toolkit optimized for GPUs. It performs molecular dynamics (MD) and Monte Carlo (MC) simulations of soft matter systems, widely used in physics, chemistry, and materials science research.",AI4S;Physics;Chemistry,molecular_dynamics;monte_carlo_simulation,solver,C++,https://github.com/glotzerlab/hoomd-blue,https://hoomd-blue.readthedocs.io,BSD-3-Clause,molecular-dynamics;gpu-acceleration;simulation;soft-matter
154,PyBOMBS,Package management system for GNU Radio and scientific signal processing,"The GNU Radio install management system (Python Build Overlay Managed Bundle System). It resolves dependencies and installs out-of-tree projects for GNU Radio, a key framework in scientific signal processing and radio astronomy.",AI6;AI6-01,package_management;environment_management,tool,Python,https://github.com/gnuradio/pybombs,https://github.com/gnuradio/pybombs,GPL-3.0,gnu-radio;package-manager;signal-processing;sdr
155,OpenSpiel,Framework for reinforcement learning and search in games,"A collection of environments and algorithms for research in general reinforcement learning and search/planning in games. It serves as a platform for scientific research in AI, game theory, and multi-agent systems.",AI4S;AI Research,reinforcement_learning;game_theory;simulation,platform,C++,https://github.com/google-deepmind/open_spiel,,Apache-2.0,reinforcement-learning;game-theory;ai-research;deepmind
156,containerize-conda,Tool to convert Conda environments into Singularity containers,"A utility that packages an existing Conda environment into a Singularity container (or a squashfs image). This bridges the gap between scientific package management (Conda) and HPC container runtimes (Singularity), ensuring reproducibility on supercomputers.",AI6;AI6-01,containerization;environment_management,tool,Python,https://github.com/grst/containerize-conda,,None,conda;singularity;hpc;reproducibility
157,rstudio-server-conda,Deployment tool for RStudio Server within Conda environments,"A wrapper script and configuration to run RStudio Server inside a Conda environment. This allows data scientists to manage R versions and dependencies via Conda while using the standard RStudio IDE interface, facilitating reproducible data analysis environments.",AI6;AI6-01,environment_management;data_analysis_environment,tool,Shell,https://github.com/grst/rstudio-server-conda,,MIT,rstudio;conda;data-science;reproducibility
158,MCC,Automated container cluster creation tool for scientific computing,My Container Cluster (MCC) is a tool developed by the GRyCAP research group to automate the creation of container-based computing clusters (using LXD). It is designed to support scientific computing workloads on cloud infrastructures.,AI6;AI6-01,cluster_management;cloud_computing,tool,Shell,https://github.com/grycap/mcc,,Apache-2.0,lxd;cluster-management;cloud-computing;hpc
159,Cobra,Multi-modal Large Language Model extending Mamba for efficient inference,"A Multi-modal Large Language Model (MLLM) that extends the Mamba architecture. It is designed for efficient inference in multi-modal tasks, serving as a scientific AI model for processing and analyzing multi-modal data.",AI4S;AI Models,inference;multi_modal_analysis,model,Python,https://github.com/h-zhao1997/cobra,,MIT,mamba;mllm;multi-modal;efficient-inference
160,PDC (Proactive Data Containers),Object-centric data management system for HPC environments,"Proactive Data Containers (PDC) is a runtime system and API designed for high-performance computing (HPC) environments. It provides object-centric data management services, allowing efficient data placement in memory/storage hierarchies, asynchronous data movement, and scalable metadata operations for scientific applications.",AI6;AI6-01,data_management;hpc_io,library,C,https://github.com/hpc-io/pdc,,NOASSERTION,hpc;data-management;object-storage;parallel-io
161,Project AirSim,High-fidelity simulation platform for autonomous systems,"Project AirSim is an advanced simulation platform designed for building, training, and testing autonomous systems (such as drones and robots) in realistic virtual environments. It supports physics-based simulation for generating synthetic scientific data for robotics and AI research.",AI6;AI6-01,simulation;synthetic_data_generation,platform,C++,https://github.com/iamaisim/ProjectAirSim,,MIT,simulation;robotics;autonomous-systems;synthetic-data
162,udocker,User-space container execution tool for HPC systems,"udocker is a basic user tool to execute simple Docker containers in batch or interactive systems without root privileges. It is specifically designed for High Performance Computing (HPC) environments where users lack administrative rights, enabling the use of containerized scientific applications.",AI6;AI6-01,container_runtime;environment_management,solver,Python,https://github.com/indigo-dc/udocker,https://indigo-dc.github.io/udocker/,Apache-2.0,hpc;docker;containers;user-space
163,NVIDIA Isaac Sim,Robotics simulation and synthetic data generation platform,"NVIDIA Isaac Sim is a simulation platform built on NVIDIA Omniverse for developing, testing, and managing AI-based robots. It provides photorealistic, physically accurate virtual environments for scientific simulation and synthetic data generation in robotics research.",AI6;AI6-01,simulation;robotics_modeling,platform,Python,https://github.com/isaac-sim/IsaacSim,https://developer.nvidia.com/isaac-sim,NOASSERTION,simulation;robotics;omniverse;synthetic-data
164,conda-minify,Tool for minifying Conda environment specifications,A library and tool to create minified or relaxed versions of Conda environment specifications. It facilitates the sharing and reproduction of scientific computing environments across different platforms by reducing strict dependency pinning issues.,AI6;AI6-01,environment_management;reproducibility,solver,Python,https://github.com/jamespreed/conda-minify,,MIT,conda;reproducibility;environment-management
165,Berryconda,Conda distribution for Raspberry Pi (ARM),"Berryconda is a Conda-based Python distribution specifically for the Raspberry Pi. It enables the management of scientific Python stacks (NumPy, SciPy, Pandas, etc.) on ARM-based edge devices, facilitating scientific computing and data collection in IoT/edge scenarios.",AI6;AI6-01,environment_management;edge_computing,platform,Shell,https://github.com/jjhelmus/berryconda,,BSD-3-Clause,conda;raspberry-pi;arm;scientific-computing
166,apptainer-in-docker,Utility to run Apptainer (Singularity) within Docker containers for CI/CD workflows,"A specialized container image and utility that enables running Apptainer (formerly Singularity), the standard container runtime for High Performance Computing (HPC), inside Docker environments. This is crucial for building and testing scientific containers in standard CI/CD pipelines.",AI6;AI6-01,container_management;reproducibility,service,Dockerfile,https://github.com/kaczmarj/apptainer-in-docker,,Apache-2.0,apptainer;singularity;hpc;ci-cd;docker
167,pymssa,Python implementation of Multivariate Singular Spectrum Analysis (MSSA),"A Python library implementing Multivariate Singular Spectrum Analysis (MSSA), a statistical technique used for time series analysis, decomposition, and forecasting in scientific domains such as geophysics and climate science.",Scientific Analysis,time_series_analysis;statistics,library,Python,https://github.com/kieferk/pymssa,,MIT,mssa;time-series;statistics;analysis
168,Mycodo,Environmental monitoring and regulation system for research and automation,"An open-source software system for environmental monitoring and regulation, designed to run on the Raspberry Pi. It is widely used in scientific research for lab automation, hydroponics, and biological experiments requiring precise control of environmental conditions.",Lab Automation;Scientific Data Generation,environmental_monitoring;lab_automation;data_acquisition,platform,Python,https://github.com/kizniche/Mycodo,https://kizniche.github.io/Mycodo/,GPL-3.0,environmental-monitoring;raspberry-pi;lab-automation;hydroponics;sensors
169,MultiModalMamba,Implementation of Multi-Modal Mamba model for AI research,A PyTorch implementation of a Multi-Modal Model fusing Vision Transformer (ViT) with Mamba (State Space Model). It serves as a research tool for exploring efficient multi-modal representation learning.,AI4S;Deep Learning,multimodal_modeling;deep_learning,library,Python,https://github.com/kyegomez/MultiModalMamba,,MIT,mamba;transformer;multimodal;deep-learning
170,VisionMamba,Implementation of Vision Mamba for efficient visual representation learning,"A PyTorch implementation of the Vision Mamba architecture, offering a more efficient alternative to Transformers for visual representation learning tasks in AI research.",AI4S;Computer Vision,computer_vision;deep_learning;modeling,library,Python,https://github.com/kyegomez/VisionMamba,,MIT,vision-mamba;computer-vision;deep-learning;ssm
171,Backend.AI,Container-based computing cluster platform for AI and HPC,"A streamlined, container-based computing cluster platform designed to host machine learning frameworks and support heterogeneous accelerators (CUDA, ROCm, TPU, IPU). It manages resources and environments for scientific computing and AI training/inference.",AI6;HPC,cluster_management;compute_orchestration;environment_management,platform,Python,https://github.com/lablup/backend.ai,https://docs.backend.ai/,LGPL-3.0,hpc;gpu-cluster;container-orchestration;machine-learning-platform
172,libigl-python-bindings,Python bindings for the libigl geometry processing library,"Provides Python access to libigl, a simple C++ geometry processing library. It is widely used in computer graphics and scientific modeling for tasks such as meshing, parameterization, and geometric analysis.",Scientific Computing;Geometry Processing,geometry_processing;modeling;mesh_analysis,library,C++,https://github.com/libigl/libigl-python-bindings,https://libigl.github.io/,GPL-3.0,geometry-processing;mesh;graphics;python-bindings
173,venvstacks,Tool for creating portable Python virtual environment stacks,"A utility to create layered, portable Python virtual environments. This is particularly useful for scientific workflows requiring reproducible environments that can be distributed across different machines or containers without full containerization overhead.",AI6;AI6-01,environment_management;reproducibility,workflow,Python,https://github.com/lmstudio-ai/venvstacks,,MIT,python;virtualenv;reproducibility;packaging
174,Crocoddyl,Optimal control library for robot control and physics simulation,Crocoddyl (Contact RObot COntrol by Differential DYnamic Library) is an optimal control library for robot control under contact sequence. It uses efficient Differential Dynamic Programming (DDP) algorithms for multi-body dynamics and physics simulations.,Robotics;Physics Simulation,optimal_control;simulation;trajectory_optimization,library,C++,https://github.com/loco-3d/crocoddyl,https://gepettoweb.laas.fr/cms/crocoddyl/,BSD-3-Clause,optimal-control;robotics;ddp;physics-simulation
175,Agent Studio,Environment and benchmark platform for general virtual agents,"A comprehensive platform providing environments, tools, and benchmarks for evaluating general virtual agents. It supports multimodal interactions and is used for AI research in agent behavior and task completion.",AI Research;Agent Evaluation,agent_evaluation;benchmark;simulation,platform,Python,https://github.com/ltzheng/agent-studio,https://skyworkai.github.io/agent-studio/,AGPL-3.0,ai-agents;benchmark;multimodal;virtual-environment
176,boa,Fast Conda package builder using Mamba,A package builder for the Conda ecosystem that utilizes Mamba for dependency resolution. It significantly speeds up the creation of scientific packages compared to traditional Conda build tools.,AI6;AI6-01,package_management;build_system,workflow,Python,https://github.com/mamba-org/boa,https://github.com/mamba-org/boa,BSD-3-Clause,conda;mamba;package-build;scientific-computing
177,gator,Conda environment management extension for Jupyter,A JupyterLab extension that provides a graphical interface for managing Conda/Mamba environments and packages directly within the scientific notebook interface.,AI6;AI6-01,environment_management;ide_integration,platform,TypeScript,https://github.com/mamba-org/gator,,NOASSERTION,jupyter;conda;mamba;environment-manager
178,Mamba,"Fast, cross-platform package manager for scientific computing","A reimplementation of the Conda package manager in C++. It offers parallel downloading of repository data and package files, and much faster dependency solving, serving as a critical infrastructure tool for scientific Python environments.",AI6;AI6-01,package_management;environment_management,platform,C++,https://github.com/mamba-org/mamba,https://mamba.readthedocs.io/,BSD-3-Clause,package-manager;conda;scientific-computing;dependency-solver
179,micromamba-docker,Docker utilities for Micromamba-based scientific containers,Provides base images and utilities for building lightweight Docker containers using Micromamba. It is essential for creating reproducible and efficient containerized scientific environments.,AI6;AI6-01,containerization;environment_management,workflow,Shell,https://github.com/mamba-org/micromamba-docker,https://github.com/mamba-org/micromamba-docker,Apache-2.0,docker;micromamba;containers;reproducibility
180,Quetz,Open-source server for Conda package repositories,"A server implementation for hosting Conda packages. It allows scientific organizations to manage their own package channels and artifacts, supporting the distribution of scientific software.",AI6;AI6-01,package_distribution;repository_management,service,Python,https://github.com/mamba-org/quetz,https://quetz.readthedocs.io/,BSD-3-Clause,conda-server;package-repository;scientific-software
181,vscode-micromamba,VS Code extension for Micromamba environments,"Integrates Micromamba into Visual Studio Code, allowing researchers and developers to easily create, activate, and manage scientific Python environments directly from their editor.",AI6;AI6-01,environment_management;ide_integration,platform,TypeScript,https://github.com/mamba-org/vscode-micromamba,,BSD-3-Clause,vscode;micromamba;environment-manager
182,Sublime Text Conda,Conda environment management for Sublime Text,"A plugin for Sublime Text 3 that enables users to work with Conda environments, including activation, deactivation, and package management, facilitating scientific development workflows.",AI6;AI6-01,environment_management;ide_integration,platform,Python,https://github.com/mandeep/sublime-text-conda,,BSD-3-Clause,sublime-text;conda;environment-manager
183,condax,Isolated execution of Conda-packaged applications,"A tool similar to pipx but for Conda. It allows users to install and run scientific applications packaged with Conda in isolated environments, preventing dependency conflicts.",AI6;AI6-01,environment_management;application_isolation,platform,Python,https://github.com/mariusvniekerk/condax,,MIT,conda;cli-tools;isolation;package-management
184,conda-move,Utility to relocate Conda environments,"A shell script utility to move Conda environments from one directory to another, handling the necessary path updates. Useful for reorganizing scientific computing environments.",AI6;AI6-01,environment_management;system_administration,workflow,Shell,https://github.com/matthuska/conda-move,,Apache-2.0,conda;environment-migration;shell-script
185,Syndeo,Tool for running massively parallel Ray jobs on SLURM with Apptainer,"Syndeo bridges modern AI frameworks (Ray) with traditional scientific HPC schedulers (SLURM) using secure containerization (Apptainer), enabling scalable AI4S workflows.",AI6;AI6-01,job_scheduling;distributed_computing;hpc_integration,workflow,Shell,https://github.com/mit-ll/Syndeo,,GPL-2.0,ray;slurm;apptainer;hpc
186,MLRun,Open source MLOps platform for managing continuous ML applications,"MLRun provides an open MLOps orchestration framework to manage the lifecycle of machine learning applications, including data preparation, training, and deployment, facilitating reproducibility in data science.",AI6;AI6-01,pipeline_orchestration;experiment_tracking;model_lifecycle,platform,Python,https://github.com/mlrun/mlrun,https://docs.mlrun.org,Apache-2.0,mlops;orchestration;reproducibility
187,repo2apptainer,Wrapper to convert repo2docker environments into Apptainer images for HPC,A tool developed by NCAR to facilitate reproducible science by converting Jupyter-ready repositories (repo2docker format) into Apptainer/Singularity images compatible with High Performance Computing environments.,AI6;AI6-01,reproducibility;environment_management;image_build,solver,Python,https://github.com/ncar-xdev/repo2apptainer,,BSD-3-Clause,hpc;apptainer;jupyter;reproducibility
188,Nextflow,Workflow orchestration engine for data-driven computational pipelines,"A domain-specific language and runtime environment for creating scalable, portable, and reproducible scientific workflows, widely adopted in bioinformatics and data-intensive science.",AI6;AI6-01,pipeline_orchestration;workflow_management,workflow,Groovy,https://github.com/nextflow-io/nextflow,https://www.nextflow.io/docs/latest/index.html,Apache-2.0,workflow;bioinformatics;pipeline;reproducibility
189,Nextstrain CLI,CLI tool for running and visualizing pathogen evolution analysis,"The command-line interface for Nextstrain, enabling consistent execution of pathogen build pipelines and visualization (Augur/Auspice) across different computing environments (Docker, Conda, AWS Batch).",AI6;AI6-01,epidemiology;phylogenetics;visualization,workflow,Python,https://github.com/nextstrain/cli,https://docs.nextstrain.org/en/latest/guides/install/cli.html,MIT,epidemiology;pathogen;visualization;cli
190,Sarek,Analysis pipeline for germline and somatic variant calling,"A comprehensive Nextflow pipeline for detecting germline or somatic variants from Whole Genome Sequencing (WGS) or targeted sequencing data, handling pre-processing, variant calling, and annotation.",AI6;AI6-01,variant_calling;genomics;bioinformatics,workflow,Nextflow,https://github.com/nf-core/sarek,https://nf-co.re/sarek,MIT,genomics;wgs;variant-calling;nf-core
191,PyGame Learning Environment (PLE),Reinforcement learning environment based on PyGame,"A framework that provides a learning environment for Reinforcement Learning agents using PyGame, allowing the simulation of games for AI training and evaluation.",AI4;AI4-01,reinforcement_learning;simulation_environment,platform,Python,https://github.com/ntasfi/PyGame-Learning-Environment,,MIT,reinforcement-learning;pygame;simulation;ai-training
192,conda-depgraph,Visualization tool for Conda environment dependencies,"A command-line utility designed to generate and plot the dependency graph of a Conda environment, aiding in the management and debugging of complex scientific software environments.",AI6;AI6-01,environment_management;dependency_visualization,solver,Python,https://github.com/omegacen/conda-depgraph,,LGPL-3.0,conda;dependency-graph;visualization;environment-management
193,Open-CE,Build recipes and environment definitions for AI/HPC packages,"A community-driven project providing recipes and tools to build and distribute Python and binary packages for the Open Cognitive Environment, focusing on AI, Machine Learning, and Deep Learning frameworks on HPC architectures.",AI6;AI6-01,package_management;build_system,platform,Python,https://github.com/open-ce/open-ce,https://open-ce.github.io/,Apache-2.0,hpc;conda;ai-infrastructure;build-system
194,leafmap,Interactive geospatial analysis and mapping library,"A Python package for interactive mapping and geospatial analysis with minimal coding in a Jupyter environment, supporting various mapping backends and data formats for scientific geospatial research.",AI4;AI4-03,geospatial_analysis;visualization,library,Python,https://github.com/opengeos/leafmap,https://leafmap.org,MIT,geospatial;mapping;gis;jupyter
195,poetry-kernel,Jupyter kernel for Poetry-managed environments,"A tool that creates a Jupyter kernel for Python projects managed by Poetry, facilitating reproducible scientific computing workflows within Jupyter notebooks.",AI6;AI6-01,environment_management;reproducibility,solver,Python,https://github.com/pathbird/poetry-kernel,,MIT,jupyter;poetry;reproducibility;python-environment
196,PLIP,Protein-Ligand Interaction Profiler,"A tool to analyze and visualize non-covalent protein-ligand interactions in PDB files, widely used in structural biology and drug discovery.",AI4;AI4-04,interaction_analysis;structure_analysis,solver,Python,https://github.com/pharmai/plip,https://plip-tool.biotec.tu-dresden.de/,GPL-2.0,protein-ligand;structural-biology;bioinformatics;interaction-profiling
197,Archiconda3,Conda distribution for ARM64 devices,"A lightweight Anaconda environment distribution specifically designed for ARM64 devices (like Raspberry Pi, Jetson), enabling scientific computing stacks on edge hardware.",AI6;AI6-01,environment_management;distribution,platform,Shell,https://github.com/piyoki/archiconda3,,None,conda;arm64;scientific-computing;environment-distribution
198,pixi,Package management tool for reproducible scientific environments based on the Conda ecosystem,"Pixi is a package manager built on top of the Conda ecosystem that focuses on project-local environments and reproducibility. It allows developers and scientists to manage dependencies and environments declaratively, ensuring consistent execution across different machines, which is critical for scientific reproducibility.",AI6;AI6-01,environment_management;reproducibility,platform,Rust,https://github.com/prefix-dev/pixi,https://pixi.sh/,BSD-3-Clause,conda;package-manager;reproducibility;environment-management
199,rattler-build,High-performance builder for Conda packages,"rattler-build is a universal and fast tool for building Conda packages. It serves as a modern replacement for conda-build, enabling the creation of binary artifacts for scientific software across multiple platforms, which is essential for the distribution of AI4S tools.",AI6;AI6-01,package_building;distribution,tool,Rust,https://github.com/prefix-dev/rattler-build,https://prefix.dev/docs/rattler-build,BSD-3-Clause,conda;build-tool;packaging
200,PRIMME,High-performance library for solving large sparse eigenvalue and singular value problems,"PRIMME (PReconditioned Iterative MultiMethod Eigensolver) is a high-performance library for computing a few eigenvalues/eigenvectors and singular values/vectors of large, sparse matrices. It is widely used in scientific computing applications such as quantum physics, chemistry, and structural mechanics.",Math;Physics,numerical_solver;eigenvalue_problem,library,C,https://github.com/primme/primme,https://www.cs.wm.edu/~andreas/software/,BSD-3-Clause,eigenvalues;sparse-matrices;numerical-linear-algebra;hpc
201,Bender,Dependency management tool for hardware design and verification projects,"Bender is a dependency management tool specifically designed for hardware description languages (SystemVerilog, VHDL). It manages IP cores and verification components, facilitating reproducible hardware design workflows in research and engineering (e.g., RISC-V research).",Electronic Engineering;AI6,dependency_management;hardware_design,tool,Rust,https://github.com/pulp-platform/bender,https://github.com/pulp-platform/bender,Apache-2.0,hardware-design;dependency-manager;eda;risc-v
202,PyAMG,Algebraic Multigrid (AMG) solvers for large sparse linear systems,"PyAMG is a library of Algebraic Multigrid (AMG) solvers for solving large sparse linear systems of equations. It provides implementations of Ruge-Stuben (RS) and Smoothed Aggregation (SA) AMG, commonly used in scientific simulations involving partial differential equations.",Math;Physics,numerical_solver;linear_algebra,library,Python,https://github.com/pyamg/pyamg,https://pyamg.readthedocs.io/,MIT,multigrid;solver;sparse-matrices;pde
203,PyMTL3,"Python-based framework for hardware generation, simulation, and verification","PyMTL3 is a framework for multi-level hardware modeling. It allows researchers to design, simulate, and verify hardware components using Python, bridging the gap between high-level modeling and low-level RTL implementation.",Electronic Engineering;Computer Science,hardware_simulation;modeling,framework,Python,https://github.com/pymtl/pymtl3,https://pymtl3.readthedocs.io/,BSD-3-Clause,hardware-simulation;verilog;modeling;eda
204,Prosodic,Metrical-phonological parser for linguistic analysis,"Prosodic is a scientific tool for the analysis of language prosody. It parses text to determine its metrical structure, useful in linguistics and digital humanities research for analyzing poetry, speech rhythm, and phonology.",Linguistics;Digital Humanities,text_analysis;phonological_parsing,tool,Python,https://github.com/quadrismegistus/prosodic,https://github.com/quadrismegistus/prosodic,GPL-3.0,linguistics;nlp;phonology;meter
205,FireHPC,Container-based HPC cluster emulator for workflow testing,"FireHPC is a tool designed to instantly emulate an HPC cluster using containers. It allows researchers and system administrators to test HPC workflows, schedulers, and configurations in a reproducible local environment without needing access to a physical supercomputer.",AI6;HPC,simulation;infrastructure_testing,tool,Python,https://github.com/rackslab/FireHPC,https://github.com/rackslab/FireHPC,GPL-3.0,hpc;emulation;containers;cluster
206,radioconda-installer,Software radio distribution and environment manager based on Conda,"Radioconda is a distribution of software-defined radio (SDR) tools packaged with Conda. This installer sets up a reproducible environment containing essential tools for radio science and signal processing research, such as GNU Radio and various hardware drivers.",Signal Processing;Physics,environment_management;signal_processing,platform,Python,https://github.com/radioconda/radioconda-installer,https://github.com/radioconda/radioconda-installer,NOASSERTION,sdr;conda;radio-astronomy;signal-processing
207,OpenRAVE,Environment for testing and developing robotics motion planning algorithms,"OpenRAVE (Open Robotics Automation Virtual Environment) is a platform for robotics research. It provides an environment for testing, developing, and deploying motion planning algorithms, focusing on simulation and analysis of kinematic and geometric constraints.",Robotics,simulation;motion_planning,platform,C++,https://github.com/rdiankov/openrave,http://openrave.org/,NOASSERTION,robotics;simulation;motion-planning;kinematics
208,poetry-conda,Poetry plugin for managing Conda environments,"This tool is a plugin for Poetry that enables the creation and management of Conda environments directly from Poetry workflows. It bridges the gap between the standard Python packaging ecosystem (Poetry) and the scientific computing ecosystem (Conda), facilitating reproducible research environments.",AI6;AI6-01,environment_management;interoperability,tool,Python,https://github.com/renan-r-santos/poetry-conda,https://github.com/renan-r-santos/poetry-conda,MIT,poetry;conda;environment-management;python
209,What the Phage,Reproducible pipeline for phage identification and annotation,What the Phage (WtP) is a bioinformatics pipeline for the identification and annotation of bacteriophages. It leverages Nextflow and containers (Docker/Singularity) to ensure reproducibility and scalability across different computing environments.,Bioinformatics;Genomics,sequence_analysis;identification,workflow,Nextflow,https://github.com/replikation/What_the_Phage,https://replikation.github.io/What_the_Phage/,GPL-3.0,phage;nextflow;bioinformatics;pipeline
210,allgebra,Base container environment for C++ and Fortran HPC application development,"A specialized Docker container image designed to provide a reproducible build and runtime environment for High Performance Computing (HPC) applications written in C++ and Fortran. It serves as a foundational layer for scientific software development, ensuring consistency across different computing clusters.",AI6;AI6-01,environment_management;containerization,platform,Dockerfile,https://github.com/ricosjp/allgebra,,Apache-2.0,hpc;docker;c++;fortran;reproducibility
211,law,Large-scale task workflow management system for High Energy Physics,"A workflow management system based on Luigi, designed for large-scale physics analysis (specifically High Energy Physics). It extends Luigi with features for remote job submission (HTCondor, Slurm, etc.), remote file targets, and environment sandboxing using Docker and Singularity, enabling reproducible scientific pipelines.",AI6;AI6-01,workflow_management;job_submission,workflow,Python,https://github.com/riga/law,https://law.readthedocs.io,BSD-3-Clause,workflow;hpc;physics;luigi;singularity
212,packrat,Dependency management system for reproducible R scientific analysis,"A dependency management tool for the R programming language, widely used in statistical computing and bioinformatics. It ensures that R projects are self-contained, portable, and reproducible by isolating package dependencies, which is critical for scientific research workflows.",AI6;AI6-01,environment_management;dependency_management,platform,R,https://github.com/rstudio/packrat,https://rstudio.github.io/packrat/,GPL-2.0,r;reproducibility;package-manager;science
213,spack-manager,Management tool for Spack deployments in HPC environments,A tool developed by Sandia National Laboratories to manage the deployment of software stacks using Spack (a package manager for supercomputers). It facilitates the creation and maintenance of reproducible software environments on High Performance Computing (HPC) systems.,AI6;AI6-01,environment_management;package_management,platform,Python,https://github.com/sandialabs/spack-manager,,BSD-3-Clause,hpc;spack;package-management;sandia
214,docker-selkies-egl-desktop,Containerized KDE desktop with EGL support for HPC visualization,"A specialized Docker container providing a KDE Plasma desktop environment optimized for Kubernetes and HPC clusters. It supports OpenGL EGL for NVIDIA GPUs, enabling low-latency remote visualization of scientific applications and simulations via WebRTC.",AI6;AI6-01,visualization;remote_desktop,platform,Dockerfile,https://github.com/selkies-project/docker-selkies-egl-desktop,,MPL-2.0,hpc;visualization;egl;kubernetes;remote-desktop
215,docker-selkies-glx-desktop,Containerized KDE desktop with GLX support for HPC visualization,"A specialized Docker container providing a KDE Plasma desktop environment optimized for Kubernetes and HPC clusters. It supports OpenGL GLX for NVIDIA GPUs, enabling low-latency remote visualization of scientific applications and simulations via WebRTC.",AI6;AI6-01,visualization;remote_desktop,platform,Dockerfile,https://github.com/selkies-project/docker-selkies-glx-desktop,,MPL-2.0,hpc;visualization;glx;kubernetes;remote-desktop
216,selkies,WebRTC-based remote desktop streaming platform for HPC and Cloud,"An open-source platform for low-latency, accelerated remote desktop streaming using WebRTC and HTML5. It is designed for self-hosting on Kubernetes or HPC clusters to provide remote access to graphical scientific applications and visualization workloads.",AI6;AI6-01,visualization;remote_access,platform,Python,https://github.com/selkies-project/selkies,,MPL-2.0,webrtc;hpc;visualization;streaming;kubernetes
217,wave-cli,CLI for Wave container provisioning service in scientific workflows,"The command-line interface for the Wave container provisioning service, developed by Seqera Labs (creators of Nextflow). It enables on-the-fly container creation and augmentation for scientific workflows, facilitating reproducible bioinformatics and data science pipelines.",AI6;AI6-01,containerization;workflow_management,platform,Java,https://github.com/seqeralabs/wave-cli,https://wave.seqera.io,Apache-2.0,nextflow;containers;bioinformatics;workflow;cli
218,docker2singularity,Converter for Docker images to Singularity format for HPC,A utility tool that converts Docker container images into Singularity images. This is essential for HPC workflows where Docker is used for development but Singularity (Apptainer) is required for runtime execution on shared clusters.,AI6;AI6-01,containerization;image_conversion,platform,Shell,https://github.com/singularityhub/docker2singularity,,MIT,hpc;singularity;docker;conversion;container
219,singularity-deploy,Deployment tool for Singularity containers to GitHub Releases,"A CI/CD utility designed to build and deploy Singularity container images directly to GitHub releases. It streamlines the distribution of scientific software containers, making them easily accessible for HPC users.",AI6;AI6-01,containerization;deployment,platform,Singularity,https://github.com/singularityhub/singularity-deploy,,MPL-2.0,hpc;singularity;ci-cd;deployment
220,singularity-hpc,Local container registry manager for HPC environments,"A tool for managing a local filesystem registry of Singularity containers, specifically designed for HPC environments. It integrates with Lmod or Environment Modules to allow users and admins to easily manage and load containerized scientific applications.",AI6;AI6-01,environment_management;container_registry,platform,Python,https://github.com/singularityhub/singularity-hpc,https://singularity-hpc.readthedocs.io,MPL-2.0,hpc;singularity;lmod;modules;registry
221,singularity-python,Python API and CLI for Singularity container management,"A Python library and command-line interface for interacting with Singularity containers and Singularity Hub. It allows researchers to automate the management, inspection, and execution of Singularity containers within Python-based scientific workflows.",AI6;AI6-01,containerization;automation,library,Python,https://github.com/singularityhub/singularity-python,https://singularityhub.github.io/singularity-python,AGPL-3.0,python;singularity;hpc;api
222,sregistry,Singularity Registry Server for scientific container storage,"An open-source registry server specifically designed for storing and managing Singularity images. It allows institutions and research groups to host their own private or public container registries, facilitating the sharing and reproducibility of scientific environments.",AI6;AI6-01,container_registry;data_management,service,JavaScript,https://github.com/singularityhub/sregistry,https://singularityhub.github.io/sregistry,MPL-2.0,registry;singularity;hpc;container-storage
223,Spack,"A flexible package manager for HPC supporting multiple versions, configurations, platforms, and compilers","Spack is a package manager designed for high-performance computing (HPC) environments. It enables reproducible scientific software stacks by handling complex dependency graphs, supporting multiple compiler versions, and allowing coexistence of different library configurations, which is critical for scientific simulations and data analysis.",AI6;AI6-01,package_management;environment_reproducibility;hpc_deployment,platform,Python,https://github.com/spack/spack,https://spack.io,Apache-2.0,hpc;package-manager;reproducibility;supercomputing
224,Spyder,The Scientific Python Development Environment,"Spyder is a powerful scientific environment written in Python, for Python, and designed by and for scientists, engineers and data analysts. It features a unique combination of the advanced editing, analysis, debugging, and profiling functionality of a comprehensive development tool with the data exploration, interactive execution, deep inspection, and beautiful visualization capabilities of a scientific package.",Scientific_Computing;Data_Analysis,scientific_programming;data_analysis;visualization,platform,Python,https://github.com/spyder-ide/spyder,https://www.spyder-ide.org/,MIT,ide;python;scientific-computing;data-science
225,SSRS,Semantic Segmentation for Remote Sensing imagery,A deep learning toolkit specifically designed for semantic segmentation tasks in remote sensing. It provides implementations of various segmentation models tailored for earth observation data analysis.,AI4S_Earth;Remote_Sensing,semantic_segmentation;image_analysis;earth_observation,library,Python,https://github.com/sstary/SSRS,,Apache-2.0,remote-sensing;deep-learning;segmentation;earth-science
226,Pinocchio,Rigid Body Dynamics algorithms and their analytical derivatives,"A fast and flexible C++ library for rigid body dynamics computations. It is widely used in robotics, biomechanics, and physics simulations to calculate kinematics and dynamics efficiently.",Physics;Robotics,dynamics_simulation;kinematics_solver;physics_modeling,library,C++,https://github.com/stack-of-tasks/pinocchio,https://stack-of-tasks.github.io/pinocchio,BSD-2-Clause,rigid-body-dynamics;physics-simulation;robotics;biomechanics
227,MedAgentBench,A Realistic Virtual EHR Environment to Benchmark Medical LLM Agents,A benchmark suite that provides a realistic virtual Electronic Health Record (EHR) environment to evaluate the performance and capabilities of Medical Large Language Model (LLM) agents in clinical scenarios.,AI4S_Medicine;AI_Evaluation,benchmarking;model_evaluation;clinical_simulation,dataset,Python,https://github.com/stanfordmlgroup/MedAgentBench,,MIT,medical-ai;benchmark;ehr;clinical-nlp
228,SingularityCE,Container platform optimized for HPC and scientific computing,"Singularity (now SingularityCE/Apptainer) is a container platform designed specifically for High Performance Computing (HPC). It allows researchers to package their scientific workflows, software, and data into a single image that can be run reproducibly on various HPC clusters without requiring root privileges.",AI6;AI6-01,container_runtime;reproducibility;hpc_execution,platform,Go,https://github.com/sylabs/singularity,https://sylabs.io/singularity/,BSD-3-Clause,hpc;containers;singularity;reproducibility
229,Konda,Lightweight utility for managing Conda environments within Google Colab sessions,"Konda is a Python utility designed to bridge the gap between Google Colab's default runtime and the Conda package management system. It allows researchers to easily install and persist Conda environments in Colab, enabling the use of scientific libraries and tools that are not available via standard pip installations or require complex dependency resolution.",AI6;AI6-01,environment_management;package_installation,library,Python,https://github.com/tamnguyenvan/konda,,MIT,conda;google-colab;environment-setup;data-science
230,Recipe Wizard,Dockerfile generator for hardware-accelerated scientific simulation environments,"Recipe Wizard is a tool that automates the creation of Dockerfiles for complex scientific simulation setups. It specifically targets headless server environments requiring OpenGL (GLX), nvidia-docker2 (CUDA), ROS (Robot Operating System), and Gazebo, streamlining the deployment of robotics and physics simulations.",AI6;AI6-01,container_generation;simulation_environment_setup,solver,Shell,https://github.com/trn84/recipe-wizard,,None,docker;ros;gazebo;cuda;opengl;simulation
231,Banpei,Anomaly detection library based on Singular Spectrum Transformation,"Banpei is a Python library dedicated to anomaly detection in time-series data using the Singular Spectrum Transformation (SST) method. It provides a simple interface for change-point detection, applicable to scientific monitoring and signal processing tasks.",AI3;AI3-03,anomaly_detection;time_series_analysis,library,Python,https://github.com/tsurubee/banpei,,MIT,anomaly-detection;singular-spectrum-transformation;time-series;statistics
232,Videoflow,Python framework for building multiprocessing video analysis pipelines,"Videoflow is a Python framework designed to facilitate the rapid development of complex video analysis applications. It handles multiprocessing and flow execution, allowing researchers to focus on implementing computer vision algorithms and processing logic for scientific video data.",AI3;AI3-01,video_processing;pipeline_orchestration,library,Python,https://github.com/videoflow/videoflow,https://videoflow.readthedocs.io/,MIT,computer-vision;video-processing;multiprocessing;pipeline
233,ipyvizzu,Animated data visualization library for Jupyter notebooks,"ipyvizzu is a tool that enables the creation of animated, interactive charts within Jupyter notebooks and other Python environments. It allows scientists to build data stories and visualize complex dataset transitions, enhancing the interpretability and presentation of research findings.",AI3;AI3-04,data_visualization;interactive_plotting,library,Jupyter Notebook,https://github.com/vizzuhq/ipyvizzu,https://ipyvizzu.vizzuhq.com/,Apache-2.0,visualization;jupyter;animation;data-storytelling
234,Warewulf,Stateless and diskless container operating system provisioning system for HPC clusters,"Warewulf is a scalable systems management and provisioning suite specifically designed for High Performance Computing (HPC) clusters. It facilitates the deployment of stateless and diskless container-based operating systems to bare metal hardware, essential for scientific computing infrastructure.",Infra/HPC;AI6;AI6-02,cluster_provisioning;system_management,platform,Go,https://github.com/warewulf/warewulf,https://warewulf.org/,BSD-3-Clause,hpc;provisioning;cluster-management;bare-metal
235,UltraLight VM-UNet,Parallel Vision Mamba network for skin lesion segmentation,"A lightweight medical image segmentation model that integrates Vision Mamba into a U-Net architecture. It is specifically designed for skin lesion segmentation tasks, offering reduced parameter count while maintaining performance.",Computer Vision;Medical Imaging,image_segmentation;medical_diagnosis,solver,Python,https://github.com/wurenkai/UltraLight-VM-UNet,,MIT,medical-imaging;segmentation;mamba;deep-learning
236,S-D-Mamba,Mamba-based model for time series forecasting,An implementation evaluating and utilizing the Mamba architecture for time series forecasting tasks. It serves as a solver for scientific data analysis involving temporal sequences.,Machine Learning;Time Series Analysis,time_series_forecasting;data_analysis,solver,Python,https://github.com/wzhwzhwzh0921/S-D-Mamba,,Unknown,time-series;forecasting;mamba;deep-learning
237,conda-envs (InSAR),Conda environment configurations for InSAR data processing,A collection of Conda environment setup scripts and configurations specifically tailored for Interferometric Synthetic Aperture Radar (InSAR) data processing workflows on Linux and macOS.,Earth Science;AI6-01,environment_setup;reproducibility,workflow,Shell,https://github.com/yunjunz/conda-envs,,MIT,insar;conda;environment-management;earth-science
238,MambaOut,Efficient vision backbone architecture analyzing Mamba's necessity,"An implementation of the MambaOut architecture, which empirically analyzes the necessity of Mamba blocks in vision tasks. It serves as a computer vision backbone for scientific image analysis.",Computer Vision;AI4S,image_classification;feature_extraction,solver,Python,https://github.com/yuweihao/MambaOut,,Apache-2.0,computer-vision;model-architecture;deep-learning
239,Sigma,Siamese Mamba Network for Multi-Modal Semantic Segmentation,"A deep learning model implementing a Siamese Mamba Network for multi-modal semantic segmentation (e.g., RGB-Thermal, RGB-Depth). Useful for scientific sensing and robotics perception tasks.",Computer Vision;Robotics,semantic_segmentation;multi_modal_fusion,solver,Python,https://github.com/zifuwan/Sigma,,MIT,segmentation;mamba;multi-modal;rgb-t
240,Mamba-UNet,Zoo of Mamba-UNet models for medical image segmentation,A collection (Zoo) of Mamba-integrated U-Net architectures designed for medical image segmentation tasks. It provides reusable model implementations for biomedical image analysis.,Medical Imaging;Computer Vision,medical_segmentation;image_analysis,solver,Python,https://github.com/ziyangwang007/Mamba-UNet,,Apache-2.0,medical-imaging;unet;mamba;segmentation
241,DAGEE,Directed Acyclic Graph Execution Engine for concurrent task scheduling on CPUs/GPUs,"A C++ library developed by AMD Research that enables programmers to express computation and data movement as task graphs, scheduled concurrently and asynchronously on heterogeneous architectures (CPUs and GPUs).",AI6;AI6-02,task_execution;runtime_optimization,library,C++,https://github.com/AMDResearch/DAGEE,,MIT,hpc;task-graph;gpu-scheduling;amd
242,lidar_IMU_calib,Targetless Calibration of LiDAR-IMU System Based on Continuous-time Batch Estimation,"A tool for calibrating LiDAR and IMU systems using continuous-time batch estimation, essential for sensor fusion in robotics and autonomous data collection systems.",AI6;Robotics,calibration;sensor_fusion,solver,C++,https://github.com/APRIL-ZJU/lidar_IMU_calib,,GPL-3.0,calibration;lidar;imu;sensor-fusion
243,gpushare-scheduler-extender,GPU Sharing Scheduler for Kubernetes Cluster,"A Kubernetes scheduler extender that enables fine-grained GPU sharing among pods, allowing multiple tasks to share a single GPU resource, optimizing utilization for AI/HPC workloads.",AI6;AI6-02,resource_scheduling;gpu_sharing,platform,Go,https://github.com/AliyunContainerService/gpushare-scheduler-extender,,Apache-2.0,kubernetes;gpu-scheduling;hpc;resource-management
244,aicsimageio,"Image Reading, Metadata Conversion, and Image Writing for Microscopy Images","A Python library developed by the Allen Institute for Cell Science for reading, writing, and converting microscopy image data and metadata, supporting various scientific file formats.",AI6;Bioinformatics,image_io;data_conversion,library,Python,https://github.com/AllenCellModeling/aicsimageio,https://allencellmodeling.github.io/aicsimageio/,NOASSERTION,microscopy;bioimage;image-io;metadata
245,daskqueue,Distributed persistent Task Queue running on Dask,"A distributed task queue built on top of Dask, providing a persistent queue mechanism for scheduling and executing tasks in scientific computing workflows.",AI6;AI6-02,task_scheduling;workflow_management,library,Python,https://github.com/AmineDiro/daskqueue,,MIT,dask;task-queue;distributed-computing;python
246,batch-shipyard,Simplify HPC and Batch workloads on Azure,"A tool to provision and execute batch-style and HPC workloads on Azure Batch using Docker containers, simplifying the deployment of scientific applications in the cloud.",AI6;AI6-02,batch_processing;cloud_hpc,platform,Python,https://github.com/Azure/batch-shipyard,https://batch-shipyard.readthedocs.io/,MIT,azure;hpc;batch-processing;docker
247,cyclecloud-lsf,Enable Spectrum LSF job scheduler in Azure CycleCloud HPC clusters,"An official Azure project providing the necessary configuration and scripts to integrate the IBM Spectrum LSF job scheduler with Azure CycleCloud, enabling hybrid or cloud-native HPC scheduling.",AI6;AI6-02,scheduler_integration;cluster_management,platform,HTML,https://github.com/Azure/cyclecloud-lsf,,MIT,lsf;hpc;azure;scheduler
248,ggVolcano,R package for creating volcano plots from differential expression data,"An R package designed to generate customizable volcano plots for visualizing differential gene expression analysis results, including gradient colors and GO term annotation.",Bioinformatics,visualization;differential_expression,library,R,https://github.com/BioSenior/ggVolcano,,GPL-3.0,bioinformatics;visualization;r;volcano-plot
249,cobamp,Constraint-based modeling framework for pathway analysis concepts,"A Python framework for constraint-based modeling of metabolic networks, specifically focused on the enumeration of pathway analysis concepts in systems biology.",Bioinformatics;Systems Biology,metabolic_modeling;pathway_analysis,library,Jupyter Notebook,https://github.com/BioSystemsUM/cobamp,,GPL-3.0,systems-biology;metabolic-networks;constraint-based-modeling
250,pyvolcans,Python tool to identify analogue volcanoes,"A Python tool developed by the British Geological Survey to identify analogue volcanoes based on various geological and physical parameters, aiding in volcanology research.",Geology,data_analysis;classification,solver,Python,https://github.com/BritishGeologicalSurvey/pyvolcans,,LGPL-3.0,volcanology;geology;analogue-identification
251,scrapi,Data processing pipeline for research metadata harvesting,A data processing pipeline developed by the Center for Open Science that schedules and runs content harvesters to normalize research metadata from various sources into a unified dataset.,AI6;Open Science,data_harvesting;metadata_normalization,platform,Python,https://github.com/CenterForOpenScience/scrapi,https://osf.io/share/,Apache-2.0,open-science;metadata;harvesting;pipeline
252,go-socker,Wrapper for secure running of Docker containers on Slurm,"A Go-based wrapper tool that enables the secure execution of Docker containers within a Slurm HPC environment, bridging the gap between containerized workflows and traditional batch schedulers.",AI6;AI6-02,container_runtime;job_submission,solver,Go,https://github.com/China-HPC/go-socker,,MIT,slurm;docker;hpc;container
253,Toil,"Scalable, efficient, cross-platform workflow engine for scientific pipelines","Toil is a workflow engine written in pure Python that supports widely used scientific workflow languages like WDL and CWL. It is designed to run scalable scientific pipelines on various platforms, including commercial clouds (AWS, Google, Azure) and high-performance computing (HPC) environments.",AI6;AI6-02;Bioinformatics,workflow_management;pipeline_orchestration,workflow,Python,https://github.com/DataBiosphere/toil,https://toil.readthedocs.io/,Apache-2.0,workflow-engine;wdl;cwl;hpc;cloud-computing
254,HyperGBM,Full pipeline AutoML tool for tabular data,"HyperGBM is an AutoML tool designed for tabular data that integrates data cleaning, preprocessing, feature generation, and model selection into a unified pipeline. It leverages gradient boosting models and hyperparameter optimization to automate the construction of machine learning models for scientific and industrial data analysis.",AI4S;Machine Learning,automl;model_training;tabular_data_analysis,solver,Python,https://github.com/DataCanvasIO/HyperGBM,https://hypergbm.readthedocs.io/,Apache-2.0,automl;tabular-data;gradient-boosting;hyperparameter-optimization
255,Bolt,Batch job submission script generator for HPC environments,Bolt is a tool developed by EPCC to automate the production of batch job submission scripts. It simplifies the process of configuring and submitting jobs to high-performance computing clusters by generating the necessary scheduler directives.,AI6;AI6-02,job_submission;hpc_utility,solver,Python,https://github.com/EPCCed/bolt,,GPL-3.0,hpc;batch-jobs;script-generation;epcc
256,cubo,On-Demand Earth System Data Cubes generation tool,cubo is a Python library for creating Earth System Data Cubes (ESDCs) on demand. It facilitates the access and processing of geospatial data from various sources (like Sentinel imagery) into structured data cubes suitable for scientific analysis and machine learning applications.,Earth Science;Geospatial,data_access;data_cube_generation,library,Python,https://github.com/ESDS-Leipzig/cubo,https://cubo.readthedocs.io/,MIT,earth-observation;data-cubes;geospatial;sentinel
257,VSM,Volcano and Seismic source Modeling tool,"VSM (Volcano and Seismic source Modeling) is a Python tool for modeling volcanic and seismic sources. It allows researchers to invert deformation data to estimate source parameters, supporting various source geometries used in geophysics.",Geophysics;Seismology,modeling;inversion;source_characterization,solver,Python,https://github.com/EliTras/VSM,,GPL-3.0,volcanology;seismology;geophysics;modeling
258,EngineCL,Heterogeneous computing scheduling and usability framework,"EngineCL is a framework designed to improve usability and performance in heterogeneous computing environments. It acts as a scheduler and wrapper for OpenCL, managing device selection and kernel execution across different hardware accelerators.",AI6;AI6-02,task_scheduling;heterogeneous_computing,library,C++,https://github.com/EngineCL/EngineCL,,MIT,opencl;hpc;scheduling;heterogeneous-computing
259,Daft,High-performance distributed data engine for multimodal AI workloads,"Daft is a distributed query engine written in Rust, designed for ETL, analytics, and data processing for multimodal AI datasets. It provides a Python DataFrame API and is optimized for handling large-scale scientific and AI data workloads.",AI Infra;Data Science,data_processing;etl;distributed_computing,platform,Rust,https://github.com/Eventual-Inc/Daft,https://www.getdaft.io/,Apache-2.0,dataframe;distributed-computing;etl;multimodal-ai
260,simple_gpu_scheduler,Lightweight scheduler for managing GPU jobs,A simple Python-based scheduler designed to manage and queue jobs on machines with multiple GPUs. It allows users to submit commands that require GPU resources and executes them as devices become available.,AI6;AI6-02,job_scheduling;resource_management,solver,Python,https://github.com/ExpectationMax/simple_gpu_scheduler,,GPL-3.0,gpu;scheduling;queue;python
261,FedML,Unified library for distributed training and federated learning,"FedML is a comprehensive library for federated learning and distributed training. It includes a cross-cloud scheduler (FedML Launch) that enables running AI jobs across diverse GPU clouds and on-premise clusters, facilitating large-scale scientific ML experiments.",AI6;AI6-02;Machine Learning,distributed_training;federated_learning;job_scheduling,platform,Python,https://github.com/FedML-AI/FedML,https://doc.fedml.ai/,Apache-2.0,federated-learning;distributed-systems;scheduler;edge-computing
262,GENIE Generator,Universal neutrino event generator and simulation tool,"The GENIE Generator is a large-scale physics simulation tool used by neutrino experiments. It simulates neutrino interactions across a wide energy range (MeV–PeV) and handles flux generation, detector geometry, and event reweighting.",Physics;High Energy Physics,simulation;event_generation,solver,C++,https://github.com/GENIE-MC/Generator,http://www.genie-mc.org/,None,neutrino;physics-simulation;monte-carlo;particle-physics
263,gpu-topo-aware,GPU topology-aware job scheduler,A scheduler designed to optimize job placement based on GPU topology. It aims to improve performance for distributed training or HPC tasks by considering the interconnect architecture of GPU resources.,AI6;AI6-02,job_scheduling;resource_optimization,solver,Python,https://github.com/HiEST/gpu-topo-aware,,Apache-2.0,gpu;topology;scheduling;hpc
264,lsf-slurm-wrappers,Wrappers to execute LSF commands using Slurm syntax,A set of wrapper scripts developed by IBM Spectrum Computing to assist users in migrating from Slurm to LSF. It allows users to run common Slurm commands which are then translated to execute LSF commands in the background.,AI6;AI6-02,job_management;migration_utility,solver,Perl,https://github.com/IBMSpectrumComputing/lsf-slurm-wrappers,,Apache-2.0,hpc;slurm;lsf;scheduler-migration
265,PaRSEC,Generic framework for architecture-aware micro-task scheduling,"PaRSEC is a runtime system for distributed, GPU-accelerated, heterogeneous architectures. It manages micro-tasks with a dynamic, fully-distributed scheduler that optimizes for data locality, communication overlap, and architectural features like NUMA nodes.",AI6;AI6-02,task_scheduling;runtime_system,platform,C,https://github.com/ICLDisco/parsec,http://icl.utk.edu/parsec/,NOASSERTION,hpc;distributed-computing;task-scheduling;heterogeneous-computing
266,Maui-Simulation,Simulation environment for HPC job scheduling,A simulation tool for modeling and analyzing the behavior of the Maui/PBS job scheduler in large-scale HPC clusters. It allows researchers and administrators to simulate job scheduling scenarios based on real cluster data.,AI6;AI6-02,simulation;scheduler_analysis,solver,Jupyter Notebook,https://github.com/It4innovations/Maui-Simulation,,BSD-2-Clause,hpc;scheduling-simulation;maui;pbs
267,Kartothek,Consistent table management library for datasets,Kartothek is a Python library for managing consistent tabular datasets backed by cloud object stores. It builds on Apache Arrow and Parquet to provide reliable data storage and retrieval for data-intensive scientific and analytical workflows.,Data Science;AI Infra,data_management;storage,library,Python,https://github.com/JDASoftwareGroup/kartothek,https://kartothek.readthedocs.io/,MIT,parquet;arrow;dataset-management;python
268,xESMF,Universal Regridder for Geospatial Data,"xESMF is a Python package for regridding geospatial data (e.g., climate model outputs). It wraps the ESMF (Earth System Modeling Framework) regridding algorithms and integrates with Xarray to handle complex grid transformations in Earth Science.",Earth Science;Climate Science,data_processing;regridding,library,Python,https://github.com/JiaweiZhuang/xESMF,https://xesmf.readthedocs.io/,MIT,geospatial;regridding;climate-data;xarray
269,VolcaNoseR,Web app for generating and annotating Volcano plots,"VolcaNoseR is an R Shiny application designed for the interactive creation and annotation of volcano plots, which are widely used in bioinformatics to visualize differential expression data.",Bioinformatics,visualization;data_plotting,solver,R,https://github.com/JoachimGoedhart/VolcaNoseR,https://huygens.science.uva.nl/VolcaNoseR/,GPL-3.0,volcano-plot;bioinformatics;shiny;visualization
270,ClusterManagers.jl,Julia interface for HPC job schedulers,"ClusterManagers.jl provides an interface for the Julia programming language to submit and manage jobs on various HPC schedulers, including Slurm, PBS, LSF, and SGE, enabling distributed scientific computing in Julia.",AI6;AI6-02,job_submission;distributed_computing,library,Julia,https://github.com/JuliaParallel/ClusterManagers.jl,,NOASSERTION,julia;hpc;slurm;pbs;distributed-computing
271,mass,Batch job management system for complex pipelines,"mass is a computer farm management system based on AWS SWF, designed to handle complex pipelines of batch jobs. It serves as a lightweight scheduler for managing computational workloads.",AI6;AI6-02,job_management;pipeline_orchestration,platform,Python,https://github.com/KKBOX/mass,,Apache-2.0,batch-jobs;workflow;aws-swf;scheduler
272,volcano3D,3D visualization tool for differential expression analysis,volcano3D is an R package that enables the plotting of interactive three-way differential expression analysis results. It extends standard 2D volcano plots to 3D to visualize gene expression changes across three groups simultaneously.,Bioinformatics,visualization;differential_expression,library,R,https://github.com/KatrionaGoldmann/volcano3D,https://katrionagoldmann.github.io/volcano3D/,None,bioinformatics;visualization;3d-plot;r-package
273,Magpie,Scripts for running Big Data software in HPC environments,"Magpie provides a set of scripts to deploy and run Big Data frameworks like Hadoop and Spark within traditional HPC environments (using schedulers like Slurm, Moab, LSF). It bridges the gap between HPC schedulers and big data analytics stacks.",AI6;AI6-02,job_management;framework_integration,solver,Shell,https://github.com/LLNL/magpie,,GPL-2.0,hpc;hadoop;spark;slurm;lustre
274,Yoda-Scheduler,GPU-metric based scheduler for Kubernetes clusters,"Yoda is a Kubernetes scheduler extension that optimizes pod placement based on GPU metrics, designed to improve resource utilization for AI and scientific workloads.",AI6;AI6-02,job_scheduling;resource_management,solver,Go,https://github.com/Mr-Linus/Yoda-Scheduler,,None,kubernetes;scheduler;gpu;hpc
275,qhist,Historical job query utility for PBS Pro,"A command-line utility developed by NCAR to query and analyze historical job data from the PBS Pro workload manager, facilitating HPC usage analysis.",AI6;AI6-02,job_management;hpc_analytics,solver,Python,https://github.com/NCAR/qhist,,MIT,pbs-pro;hpc;job-history;ncar
276,KAI-Scheduler,Kubernetes native scheduler for large-scale AI workloads,"An open-source Kubernetes scheduler optimized for large-scale AI and HPC workloads, providing advanced scheduling capabilities for GPU resources.",AI6;AI6-02,job_scheduling;orchestration,platform,Go,https://github.com/NVIDIA/KAI-Scheduler,,Apache-2.0,kubernetes;scheduler;ai-infrastructure;gpu
277,pyxis,Slurm container execution plugin,A SPANK plugin for Slurm that enables unprivileged users to execute containerized workloads (via Enroot) seamlessly within HPC environments.,AI6;AI6-02,container_runtime;job_execution,solver,C,https://github.com/NVIDIA/pyxis,,Apache-2.0,slurm;container;hpc;enroot
278,mlforecast,Scalable machine learning framework for time series forecasting,"A framework for performing scalable time series forecasting using machine learning models, applicable to scientific domains such as weather, climate, and energy load forecasting.",AI6,time_series_forecasting;data_analysis,library,Python,https://github.com/Nixtla/mlforecast,https://nixtla.github.io/mlforecast/,Apache-2.0,time-series;forecasting;machine-learning
279,Slurm_tools,Collection of administration and user tools for Slurm,"A set of scripts and utilities for managing and interacting with the Slurm HPC workload manager, aiding in job submission, monitoring, and accounting.",AI6;AI6-02,job_management;cluster_administration,solver,Shell,https://github.com/OleHolmNielsen/Slurm_tools,,GPL-3.0,slurm;hpc;administration
280,CSGHub,Open-source platform for managing LLMs and datasets,"A platform for managing the lifecycle of Large Language Models (LLMs), datasets, and agents, providing infrastructure for AI model hosting and deployment relevant to AI4S workflows.",AI6,model_management;dataset_management,platform,Vue,https://github.com/OpenCSGs/csghub,,Apache-2.0,llm;model-registry;ai-infrastructure
281,PipelineDP,Differential privacy framework for large dataset processing,"A Python framework for applying differentially private aggregations to large datasets using batch processing systems like Spark and Beam, enabling secure scientific data analysis.",AI6,data_processing;privacy_preservation,library,Python,https://github.com/OpenMined/PipelineDP,https://pipelinedp.io,Apache-2.0,differential-privacy;data-processing;spark;beam
282,OpenRLHF,High-performance RLHF framework based on Ray,"A scalable framework for Reinforcement Learning from Human Feedback (RLHF) built on Ray, facilitating the training and alignment of large models used in various AI applications including scientific domains.",AI6,model_training;reinforcement_learning,workflow,Python,https://github.com/OpenRLHF/OpenRLHF,,Apache-2.0,rlhf;ray;llm-training;distributed-training
283,xclim,Library for calculating climate indicators,A Python library based on xarray for calculating climate indices and indicators from climate model output and observational data.,AI6,climate_analysis;data_processing,library,Python,https://github.com/Ouranosinc/xclim,https://xclim.readthedocs.io/,Apache-2.0,climate-science;xarray;meteorology
284,HybriMoE,Hybrid CPU-GPU scheduling for MoE inference,A system for efficient Mixture-of-Experts (MoE) inference that utilizes hybrid CPU-GPU scheduling and cache management to optimize resource usage.,AI6;AI6-02,inference_scheduling;resource_optimization,solver,Python,https://github.com/PKU-SEC-Lab/HybriMoE,,Apache-2.0,moe;scheduling;inference;gpu
285,condor,R interface for HTCondor,"An R package that enables interaction with the HTCondor high-throughput computing system via SSH, allowing users to submit and manage jobs from R.",AI6;AI6-02,job_submission;workflow_management,library,R,https://github.com/PacificCommunity/condor,,None,htcondor;r;hpc;ssh
286,paddle-operator,Kubernetes operator for PaddlePaddle training jobs,A Kubernetes operator that facilitates elastic deep learning training for PaddlePaddle by leveraging Volcano for scheduling and resource management.,AI6;AI6-02,job_scheduling;distributed_training,platform,Go,https://github.com/PaddleFlow/paddle-operator,,Apache-2.0,kubernetes;paddlepaddle;operator;volcano
287,Liquid,Resource estimation and scheduling for DL jobs,"A system for intelligent resource requirement estimation and scheduling of deep learning jobs on distributed GPU clusters, developed by PasaLab.",AI6;AI6-02,job_scheduling;resource_estimation,solver,Python,https://github.com/PasaLab/Liquid,,Apache-2.0,scheduling;deep-learning;gpu-cluster;hpc
288,volcano-vgpu-device-plugin,Volcano vGPU device plugin for Kubernetes,A Kubernetes device plugin designed for the Volcano scheduler to support hard resource isolation and scheduling of virtual GPUs (vGPUs).,AI6;AI6-02,resource_management;scheduling,solver,Go,https://github.com/Project-HAMi/volcano-vgpu-device-plugin,,Apache-2.0,kubernetes;volcano;gpu;virtualization
289,pyslurm,Python interface to Slurm C API,"A Python extension that provides an interface to the Slurm Workload Manager's C API, allowing programmatic interaction with Slurm for job control and querying.",AI6;AI6-02,job_management;api_binding,library,Cython,https://github.com/PySlurm/pyslurm,https://pyslurm.github.io/,GPL-2.0,slurm;python;hpc;api
290,Embree,High-performance ray tracing kernels,"A collection of high-performance ray tracing kernels developed by Intel, widely used in scientific visualization and rendering engines to accelerate geometric calculations.",AI6,scientific_visualization;rendering,library,C++,https://github.com/RenderKit/embree,https://www.embree.org/,Apache-2.0,ray-tracing;visualization;rendering;hpc
291,REEF,GPU-accelerated DNN inference serving system,A high-performance DNN inference serving system that supports instant kernel preemption and biased concurrent execution for optimized GPU scheduling.,AI6;AI6-02,inference_serving;gpu_scheduling,platform,Cuda,https://github.com/SJTU-IPADS/reef,,Apache-2.0,inference;gpu;scheduling;preemption
292,Slurm,A highly scalable workload manager for HPC clusters,"Slurm is an open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters. It is the de facto standard for HPC job scheduling in scientific research.",AI6;AI6-02,job_scheduling;resource_management,platform,C,https://github.com/SchedMD/slurm,https://slurm.schedmd.com/,NOASSERTION,hpc;scheduler;workload-manager
293,Slurm on GCP,Deployment tools for running Slurm clusters on Google Cloud Platform,"A set of tools and scripts to deploy and manage Slurm clusters on Google Cloud Platform (GCP), enabling scalable HPC workloads in the cloud.",AI6;AI6-02,cloud_deployment;cluster_management,platform,HCL,https://github.com/SchedMD/slurm-gcp,https://github.com/SchedMD/slurm-gcp,Apache-2.0,gcp;slurm;cloud-hpc
294,Slurm in Docker,Dockerized Slurm environment for testing and development,"Provides Docker images and configurations to run Slurm clusters in containers, facilitating the development, testing, and reproducibility of HPC workflows.",AI6;AI6-02,environment_setup;reproducibility,platform,Shell,https://github.com/SciDAS/slurm-in-docker,https://github.com/SciDAS/slurm-in-docker,MIT,docker;slurm;containerization
295,TRTIS Kubernetes Scheduler,Custom Kubernetes scheduler for deploying ML models to TensorRT Inference Server,"A custom scheduler designed to optimize the deployment of machine learning models to NVIDIA's TensorRT Inference Server (TRTIS) on Kubernetes, specifically handling GPU sharing.",AI6;AI6-02,inference_scheduling;gpu_sharing,service,Go,https://github.com/SeldonIO/trtis-k8s-scheduler,https://github.com/SeldonIO/trtis-k8s-scheduler,Apache-2.0,kubernetes;inference;gpu
296,Slurm Operator,Kubernetes Operator for managing Slurm clusters,"An operator to deploy and manage Slurm clusters on Kubernetes, bridging traditional HPC scheduling with cloud-native infrastructure.",AI6;AI6-02,cluster_management;cloud_native_hpc,platform,Go,https://github.com/SlinkyProject/slurm-operator,https://github.com/SlinkyProject/slurm-operator,None,kubernetes;slurm;operator
297,spark.condor,Utilities to run Apache Spark on HTCondor clusters,"Scripts and tools to submit and manage Apache Spark jobs in standalone mode on HTCondor clusters, enabling big data processing in scientific HPC environments.",AI6;AI6-02,job_submission;big_data_processing,solver,Shell,https://github.com/SmartDataInnovationLab/spark.condor,https://github.com/SmartDataInnovationLab/spark.condor,BSD-3-Clause,spark;htcondor;hpc
298,Snakemake HTCondor Profile,Snakemake profile for executing workflows on HTCondor,"A configuration profile for Snakemake that allows scientific workflows to be executed on HTCondor clusters, managing job submission and resource allocation.",AI6;AI6-02,workflow_execution;job_submission,library,Python,https://github.com/Snakemake-Profiles/htcondor,https://github.com/Snakemake-Profiles/htcondor,MIT,snakemake;htcondor;workflow
299,watchmen,Toolkit for GPU scheduling and monitoring,"A simple toolkit designed to assist with GPU scheduling and monitoring, useful for managing resources in deep learning and scientific computing experiments.",AI6;AI6-02,gpu_scheduling;resource_monitoring,solver,Python,https://github.com/Spico197/watchmen,https://github.com/Spico197/watchmen,MIT,gpu;scheduling;monitoring
300,SEML,Slurm Experiment Management Library for machine learning,"SEML allows researchers to manage and track machine learning experiments on Slurm clusters, handling job submission, configuration management, and results collection.",AI6;AI6-02,experiment_management;job_scheduling,library,Python,https://github.com/TUM-DAML/seml,https://github.com/TUM-DAML/seml,NOASSERTION,slurm;experiment-tracking;machine-learning
301,Caelus,Kubernetes solution for reusing idle node resources for batch jobs,Caelus is a set of Kubernetes solutions designed to improve resource utilization by running extra batch jobs (often scientific or AI workloads) on idle node resources.,AI6;AI6-02,resource_optimization;batch_scheduling,platform,Go,https://github.com/Tencent/caelus,https://github.com/Tencent/caelus,NOASSERTION,kubernetes;batch-jobs;resource-management
302,TimeEval,Evaluation tool for time series anomaly detection algorithms,"TimeEval is a tool for evaluating and benchmarking anomaly detection algorithms on time series data, automating the execution and scoring of algorithms.",AI6;AI6-02,benchmarking;algorithm_evaluation,library,Jupyter Notebook,https://github.com/TimeEval/TimeEval,https://timeeval.readthedocs.io/,MIT,time-series;anomaly-detection;benchmarking
303,Orca,Task orchestration library for UrbanSim and data science,"Orca is a Python library for task orchestration, primarily used within the UrbanSim ecosystem for urban data science and modeling simulations.",AI6;AI6-02,task_orchestration;simulation_pipeline,library,Python,https://github.com/UDST/orca,https://udst.github.io/orca/,BSD-3-Clause,orchestration;urban-science;pipeline
304,slurmR,Lightweight R wrapper for Slurm,"slurmR provides a lightweight wrapper for Slurm, allowing R users to submit and manage jobs on Slurm clusters directly from their R environment.",AI6;AI6-02,job_submission;parallel_computing,library,R,https://github.com/USCbiostats/slurmR,https://github.com/USCbiostats/slurmR,NOASSERTION,r;slurm;hpc
305,pbsweb,Web interface for monitoring PBS Pro HPC clusters,"A web interface designed to display the status of nodes, queues, and jobs on High Performance Compute (HPC) clusters using the PBS Pro scheduler.",AI6;AI6-02,cluster_monitoring;job_visualization,service,Python,https://github.com/UTS-eResearch/pbsweb,https://github.com/UTS-eResearch/pbsweb,GPL-3.0,pbs-pro;hpc;monitoring
306,vector-inference,Efficient LLM inference on Slurm clusters,"A tool for running efficient Large Language Model (LLM) inference on Slurm-managed clusters using vLLM, facilitating AI research on HPC infrastructure.",AI6;AI6-02,inference_scheduling;llm_deployment,solver,Python,https://github.com/VectorInstitute/vector-inference,https://github.com/VectorInstitute/vector-inference,MIT,slurm;llm;inference
307,pyglidein,Scripts to launch HTCondor glideins,"Python scripts to launch HTCondor glideins, used for distributed computing in particle astrophysics research (e.g., IceCube).",AI6;AI6-02,distributed_computing;job_submission,utility,Python,https://github.com/WIPACrepo/pyglidein,https://github.com/WIPACrepo/pyglidein,MIT,htcondor;distributed-computing;physics
308,xsched,"Scheduling framework for diverse XPUs (GPUs, NPUs, FPGAs)","A scheduling framework designed for multitasking over heterogeneous computing units (XPUs) such as GPUs, NPUs, ASICs, and FPGAs, optimizing resource usage in accelerated computing.",AI6;AI6-02,heterogeneous_scheduling;resource_management,platform,C,https://github.com/XpuOS/xsched,https://github.com/XpuOS/xsched,Apache-2.0,scheduling;xpu;accelerators
309,Grove,Kubernetes scheduler extensions for gang scheduling and topology awareness,"Grove provides Kubernetes enhancements for Network Topology Aware Gang Scheduling and Autoscaling, which are critical for distributed AI training and HPC workloads to ensure efficient resource utilization and job coordination.",AI6;AI6-02,scheduling;resource_management,platform,Go,https://github.com/ai-dynamo/grove,,Apache-2.0,kubernetes;gang-scheduling;hpc;autoscaling
310,slurm_gpustat,Command line tool for monitoring GPU usage on Slurm clusters,"A simple command line utility designed to display GPU usage statistics specifically for jobs running on a SLURM cluster, aiding in resource monitoring and optimization for HPC workloads.",AI6;AI6-02,monitoring;resource_management,tool,Python,https://github.com/albanie/slurm_gpustat,,None,slurm;gpu;monitoring;hpc
311,GPU-scheduler-for-deep-learning,GPU scheduler designed for deep learning workloads,"A specialized scheduler for managing GPU resources in deep learning environments, optimizing the allocation and execution of training jobs.",AI6;AI6-02,scheduling;resource_management,solver,C++,https://github.com/alibaba/GPU-scheduler-for-deep-learning,,MIT,gpu;scheduling;deep-learning
312,simple_slurm,Python wrapper for Slurm Workload Manager,"A Python library that provides a simple wrapper around the Slurm Workload Manager, allowing users to submit and manage HPC jobs programmatically.",AI6;AI6-02,job_submission;workflow_management,library,Python,https://github.com/amq92/simple_slurm,,AGPL-3.0,slurm;python;hpc;job-management
313,Whippletree,Dynamic scheduling framework for irregular GPU workloads,"A novel approach and framework for scheduling dynamic, irregular workloads directly on the GPU, bypassing some of the limitations of traditional kernel launch overheads.",AI6;AI6-02,scheduling;gpu_acceleration,library,Cuda,https://github.com/apc-llc/whippletree,,None,cuda;gpu;scheduling;hpc
314,Spark on Kubernetes Batch Processing Gateway,Gateway for managing Spark batch jobs on Kubernetes,"A gateway component designed to simplify the submission and management of Spark batch processing jobs on Kubernetes clusters, facilitating large-scale data processing workflows.",AI6;AI6-02,job_submission;batch_processing,platform,Java,https://github.com/apple/batch-processing-gateway,,Apache-2.0,spark;kubernetes;batch-processing
315,Armada,Multi-cluster batch queuing system for Kubernetes,"A high-throughput batch queuing system for Kubernetes that spans multiple clusters, designed to handle massive scale scientific and AI workloads.",AI6;AI6-02,scheduling;queue_management,platform,Go,https://github.com/armadaproject/armada,https://armadaproject.io/,Apache-2.0,kubernetes;batch-processing;hpc;multi-cluster
316,Escalator,Batch-optimized horizontal autoscaler for Kubernetes,"A horizontal autoscaler for Kubernetes optimized for batch jobs and large-scale compute workloads, ensuring efficient resource scaling based on job demand.",AI6;AI6-02,autoscaling;resource_management,platform,Go,https://github.com/atlassian/escalator,,Apache-2.0,kubernetes;autoscaling;batch-jobs
317,Kolibri,Framework for concurrent batch processing and ranking evaluation,"A Scala-based framework for concurrent multi-node batch processing and evaluation of search systems, providing out-of-the-box functionality for IR metrics (NDCG, Precision, Recall).",AI6;AI6-02,batch_processing;evaluation,framework,Scala,https://github.com/awagen/kolibri,,Apache-2.0,batch-processing;evaluation;scala;distributed-computing
318,AWS SDK for pandas,Pandas integration for AWS data services,"An open-source Python library that extends pandas to easily integrate with AWS data services like Athena, Glue, Redshift, and S3, facilitating scientific data processing pipelines on AWS.",AI6,data_processing;data_integration,library,Python,https://github.com/aws/aws-sdk-pandas,https://aws-sdk-pandas.readthedocs.io/,Apache-2.0,pandas;aws;data-processing;etl
319,Floto,Task orchestration tool based on AWS SWF,"A task orchestration tool built on top of AWS Simple Workflow Service (SWF) and boto3, allowing for the definition and execution of distributed data processing workflows.",AI6;AI6-02,orchestration;workflow_management,tool,Python,https://github.com/babbel/floto,,MIT,orchestration;aws-swf;workflow
320,Bodywork,ML pipeline orchestration and model deployment on Kubernetes,"A tool for orchestrating machine learning pipelines and deploying models on Kubernetes, supporting continuous training and batch scoring workflows.",AI6;AI6-02,orchestration;mlops,platform,Python,https://github.com/bodywork-ml/bodywork-core,https://bodywork.readthedocs.io/,AGPL-3.0,kubernetes;mlops;orchestration;pipeline
321,slurmpy,Python wrapper for submitting jobs to the Slurm workload manager,"A lightweight Python library that simplifies the submission of jobs to the Slurm scheduler, allowing users to define job properties and scripts programmatically within Python code.",AI6;AI6-02,job_submission;workflow_management,library,Python,https://github.com/brentp/slurmpy,,MIT,slurm;hpc;python;job-scheduling
322,Uchuva,Scientific web portal for submitting workflows to HPC schedulers,"A web-based portal designed to facilitate the creation and submission of scientific workflows to various HPC schedulers including HTCondor, Slurm, OpenLava, and Torque.",AI6;AI6-02,job_submission;workflow_management,platform,JavaScript,https://github.com/carlochess/uchuva,,GPL-3.0,hpc;web-portal;htcondor;slurm;workflow
323,JobSchedulers.jl,Julia-based job scheduler and workload manager,"A pure Julia implementation of a job scheduler and workload manager, inspired by Slurm and PBS, designed to manage scientific computations and tasks within the Julia ecosystem.",AI6;AI6-02,job_scheduling;workload_management,library,Julia,https://github.com/cihga39871/JobSchedulers.jl,,MIT,julia;scheduler;hpc;parallel-computing
324,ClearML Agent,MLOps orchestration agent for experiment scheduling,"The agent component of the ClearML platform, responsible for pulling experiment execution tasks from the queue and running them on local or remote resources, facilitating reproducible AI research workflows.",AI6;AI6-02,experiment_orchestration;mlops,service,Python,https://github.com/clearml/clearml-agent,https://clear.ml/docs,Apache-2.0,mlops;orchestration;reproducibility;scheduler
325,GPUTasker,Lightweight GPU task scheduler for single-node clusters,"A lightweight and easy-to-use GPU task scheduling tool designed to manage and queue tasks on GPU servers, optimizing resource utilization for small-scale AI research environments.",AI6;AI6-02,gpu_scheduling;resource_management,solver,Python,https://github.com/cnstark/gputasker,,MIT,gpu;scheduler;python;deep-learning
326,vGPU Manager,Kubernetes device plugin for vGPU scheduling and allocation,"A Kubernetes device plugin that enables the scheduling and allocation of virtualized GPU resources, allowing for fine-grained sharing of GPUs in containerized scientific workloads.",AI6;AI6-02,resource_allocation;container_orchestration,service,C,https://github.com/coldzerofear/vgpu-manager,,Apache-2.0,kubernetes;gpu;virtualization;scheduler
327,MetaVolcanoR,Gene expression meta-analysis visualization tool,"An R package designed for the visualization of gene expression meta-analysis results, specifically creating volcano plots to identify differentially expressed genes across multiple studies.",Bioinformatics;Visualization,visualization;differential_expression_analysis,library,R,https://github.com/csbl-usp/MetaVolcanoR,,NOASSERTION,genomics;visualization;r;meta-analysis
328,DanteGPU Core,Core microservices for decentralized GPU computing network,"The core infrastructure for the DanteGPU network, enabling decentralized orchestration of AI job scheduling and management of distributed GPU providers.",AI6;AI6-02,distributed_computing;resource_orchestration,platform,Go,https://github.com/dante-gpu/dantegpu-core,,MIT,gpu;decentralized-computing;scheduler;go
329,FluxPrune.jl,Pruning framework for Flux machine learning models,"A Julia library providing methods and a framework for pruning neural networks built with Flux.jl, facilitating model compression and efficiency in scientific machine learning.",Scientific Machine Learning,model_optimization;pruning,library,Julia,https://github.com/darsnack/FluxPrune.jl,,MIT,julia;flux;machine-learning;model-compression
330,Dask SQL,Distributed SQL Engine for Dask DataFrames,"A distributed SQL engine that allows users to query Dask DataFrames using SQL, enabling scalable data analysis and processing on large scientific datasets using familiar SQL syntax.",AI6;Data Science,data_querying;data_analysis,library,Python,https://github.com/dask-contrib/dask-sql,https://dask-sql.readthedocs.io/,MIT,sql;dask;distributed-computing;python
331,Dask,Flexible library for parallel computing in Python,"A core library for parallel computing in Python that integrates with the scientific Python stack (NumPy, Pandas, Scikit-Learn) to enable scalable data analysis and task scheduling.",AI6;AI6-02,parallel_computing;task_scheduling,library,Python,https://github.com/dask/dask,https://dask.org/,BSD-3-Clause,parallel-computing;python;scheduler;big-data
332,Dask Cloudprovider,Cloud provider cluster managers for Dask,"A library for deploying and managing Dask clusters on various cloud providers (AWS, Azure, GCP), facilitating the scaling of scientific workloads in cloud environments.",AI6;AI6-02,cluster_management;cloud_computing,library,Python,https://github.com/dask/dask-cloudprovider,https://cloudprovider.dask.org/,BSD-3-Clause,dask;cloud;cluster-management;python
333,Dask Gateway,Multi-tenant server for securely deploying and managing Dask clusters,"A secure, multi-tenant server for managing Dask clusters, allowing users to launch and use Dask clusters in a shared environment with authentication and resource limits.",AI6;AI6-02,cluster_management;job_scheduling,service,Python,https://github.com/dask/dask-gateway,https://gateway.dask.org/,BSD-3-Clause,dask;cluster-management;distributed-computing
334,dask-image,Distributed image processing library using Dask,"A library for distributed image processing that integrates with Dask arrays, allowing for scalable analysis of large scientific image datasets.",AI6;AI4,image_processing;distributed_computing,library,Python,https://github.com/dask/dask-image,https://image.dask.org/,BSD-3-Clause,image-processing;dask;distributed
335,dask-jobqueue,"Integration of Dask with HPC job schedulers (PBS, Slurm, SGE)","A library that deploys Dask workers on common HPC job schedulers like PBS, Slurm, SGE, and LSF, enabling scalable scientific computing on existing cluster infrastructure.",AI6;AI6-02,job_scheduling;hpc_integration,library,Python,https://github.com/dask/dask-jobqueue,https://jobqueue.dask.org/,BSD-3-Clause,hpc;slurm;pbs;dask
336,dask-kubernetes,Native Kubernetes integration for deploying Dask clusters,"Provides utilities for deploying and managing Dask clusters on Kubernetes, including a native operator and a classic cluster manager.",AI6;AI6-02,cluster_management;container_orchestration,library,Python,https://github.com/dask/dask-kubernetes,https://kubernetes.dask.org/,BSD-3-Clause,kubernetes;dask;cloud-native
337,dask-labextension,JupyterLab extension for managing and monitoring Dask clusters,A JupyterLab extension that provides a dashboard for managing Dask clusters and visualizing task progress directly within the scientific research environment.,AI6;AI6-02,workflow_management;monitoring,plugin,TypeScript,https://github.com/dask/dask-labextension,https://github.com/dask/dask-labextension,BSD-3-Clause,jupyterlab;dask;visualization
338,dask-ml,Scalable machine learning library compatible with Scikit-Learn,"A library for scalable machine learning in Python, providing parallel implementations of common ML algorithms and integration with Dask for handling large datasets.",AI3;AI6,machine_learning;distributed_training,library,Python,https://github.com/dask/dask-ml,https://ml.dask.org/,BSD-3-Clause,machine-learning;distributed;scikit-learn
339,Dask Distributed,Distributed task scheduler for the Dask ecosystem,"The core distributed scheduling engine for Dask, managing task execution across clusters of machines with low latency and high throughput.",AI6;AI6-02,job_scheduling;distributed_computing,library,Python,https://github.com/dask/distributed,https://distributed.dask.org/,BSD-3-Clause,scheduler;distributed;python
340,Cube Studio,Cloud-native one-stop MLOps and LLM platform,"An open-source AI platform supporting the full lifecycle of machine learning and large model development, including distributed training, inference, and resource management on Kubernetes.",AI6;AI6-02,mlops;platform_orchestration;distributed_training,platform,Python,https://github.com/data-infra/cube-studio,https://github.com/data-infra/cube-studio,NOASSERTION,mlops;kubernetes;llm;distributed-training
341,ec2cluster,Tool for launching and managing MPI clusters on Amazon EC2,A Rails-based web service and dashboard for provisioning MPI-ready clusters on AWS EC2 and managing user-submitted HPC jobs.,AI6;AI6-02,cluster_provisioning;job_submission,tool,Ruby,https://github.com/datawrangling/ec2cluster,,None,aws;mpi;hpc;cluster-management
342,cwm-simulator,Simulator for Slurm-like cluster workload managers,"A simulation tool for modeling and analyzing the behavior of cluster workload managers (like Slurm), useful for research on scheduling algorithms.",AI6;AI6-02,scheduling_simulation;performance_modeling,solver,Python,https://github.com/dchasap/cwm-simulator,,None,slurm;simulator;scheduling
343,dpdispatcher,Job submission and management tool for DeepModeling ecosystem,"A Python tool to generate HPC scheduler scripts, submit jobs, and monitor their status, specifically designed for the DeepModeling scientific workflow.",AI6;AI6-02,job_submission;workflow_automation,tool,Python,https://github.com/deepmodeling/dpdispatcher,,LGPL-3.0,hpc;deepmodeling;scheduler
344,DeepSquare Grid,Decentralized HPC platform with Slurm-like interface,"A decentralized high-performance computing grid based on blockchain technology, offering an abstracted Slurm interface for job scheduling and meta-scheduling strategies.",AI6;AI6-02,distributed_computing;resource_allocation,platform,Go,https://github.com/deepsquare-io/grid,https://docs.deepsquare.io/,None,hpc;decentralized;blockchain;slurm
345,Omnia,Toolkit for deploying and managing HPC and AI clusters,"An open-source toolkit using Ansible and Kubernetes to deploy and manage high-performance clusters for HPC, AI, and data analytics workloads.",AI6;AI6-02,cluster_provisioning;infrastructure_management,tool,YAML,https://github.com/dell/omnia,https://omnia-doc.readthedocs.io/,Apache-2.0,hpc;ansible;kubernetes;cluster-deployment
346,High-Performance-Integer-Factorization-Suite,High-performance suite for integer factorization algorithms,"A suite implementing GNFS, MPQS, and QS algorithms with optimizations like GPU acceleration and NUMA-aware scheduling for computational number theory research.",AI4;AI6,integer_factorization;cryptanalysis,solver,Python,https://github.com/devatnull/High-Performance-Integer-Factorization-Suite-GNFS-MPQS-QS,,MIT,number-theory;factorization;gpu;hpc
347,opt_einsum,Optimizer for tensor contraction orders in scientific computing,"A library that optimizes the contraction order of einsum functions in NumPy, TensorFlow, and Dask, significantly speeding up tensor operations in quantum chemistry and physics.",AI4;AI6,numerical_optimization;tensor_contraction,library,Python,https://github.com/dgasmith/opt_einsum,https://optimized-einsum.readthedocs.io/,MIT,tensor;optimization;numpy;quantum-chemistry
348,qsub,Command line utility for submitting batch jobs to Kubernetes,"A Go-based utility that emulates the traditional 'qsub' command to submit batch jobs to Kubernetes clusters, bridging the gap between HPC and Cloud Native workflows.",AI6;AI6-02,job_submission;hpc_emulation,tool,Go,https://github.com/dgruber/qsub,,BSD-3-Clause,kubernetes;hpc;batch-jobs
349,XGBoost,Scalable and distributed gradient boosting library,"An optimized distributed gradient boosting library designed to be highly efficient, flexible and portable, widely used in scientific data analysis and machine learning competitions.",AI3;AI6,machine_learning;gradient_boosting,library,C++,https://github.com/dmlc/xgboost,https://xgboost.readthedocs.io/,Apache-2.0,gbdt;machine-learning;distributed
350,cms-htcondor-es,ElasticSearch integration for CMS HTCondor pool monitoring,"A tool for integrating the CMS experiment's HTCondor pool with ElasticSearch, enabling monitoring and analysis of high-throughput computing jobs in high-energy physics.",AI6;AI6-02,monitoring;hpc_infrastructure,service,Python,https://github.com/dmwm/cms-htcondor-es,,None,cms;cern;htcondor;monitoring
351,dstack,Control plane for running AI jobs on GPUs across clouds,"An open-source control plane that simplifies running development, training, and inference jobs on GPUs across various cloud providers and on-premise clusters.",AI6;AI6-02,mlops;resource_orchestration;job_scheduling,platform,Python,https://github.com/dstackai/dstack,https://dstack.ai/,MPL-2.0,mlops;gpu;cloud-computing
352,Metview Python,Python interface to Metview meteorological workstation,"A Python interface to Metview, enabling meteorological data processing, analysis, and visualization, as well as interaction with batch systems for weather forecasting workflows.",AI6;AI4,meteorology;data_visualization;workflow_automation,library,Python,https://github.com/ecmwf/metview-python,https://metview.readthedocs.io/,Apache-2.0,meteorology;ecmwf;visualization
353,elastic-gpu-scheduler,Kubernetes scheduler extender for GPU resources,"A Kubernetes scheduler extender designed to optimize GPU resource scheduling, supporting elastic scaling for AI and HPC workloads.",AI6;AI6-02,resource_scheduling;gpu_management,service,Go,https://github.com/elastic-ai/elastic-gpu-scheduler,,Apache-2.0,kubernetes;gpu;scheduler
354,ElastiCluster,Tool to create and configure compute clusters on cloud providers,"A command-line tool to create, manage, and setup computing clusters (with Slurm, GridEngine, etc.) on various cloud providers using Ansible.",AI6;AI6-02,cluster_provisioning;cloud_hpc,tool,Python,https://github.com/elasticluster/elasticluster,https://elasticluster.readthedocs.io/,GPL-3.0,cloud;hpc;ansible;cluster-management
355,TESK API,GA4GH Task Execution Service implementation for Kubernetes,"An implementation of the GA4GH Task Execution Service (TES) API that translates scientific task descriptions into Kubernetes Batch API calls, facilitating interoperable genomics workflows.",AI6;AI6-02,workflow_execution;genomics_infrastructure,service,Java,https://github.com/elixir-cloud-aai/tesk-api,,Apache-2.0,ga4gh;genomics;kubernetes;workflow
356,Paella,Low-latency model serving system with virtualized GPU scheduling,A research system for low-latency machine learning model serving that utilizes virtualized GPU scheduling to optimize resource usage and response times.,AI6;AI6-02,model_serving;gpu_scheduling,solver,C++,https://github.com/eniac/paella,,MIT,model-serving;gpu;scheduling
357,Proteus,Heterogeneous database engine with adaptive scheduling,"A research database engine designed for heterogeneous environments, featuring GPU acceleration and adaptive scheduling to handle variable scientific and analytical workloads.",AI6;AI6-02,data_management;adaptive_scheduling,solver,C++,https://github.com/epfl-dias/proteus,,NOASSERTION,database;gpu;heterogeneous-computing
358,Orion,Interference-aware scheduler for fine-grained GPU sharing,"A scheduler designed to manage fine-grained GPU sharing by being aware of interference between tasks, optimizing throughput for deep learning workloads.",AI6;AI6-02,gpu_scheduling;resource_optimization,solver,Python,https://github.com/eth-easl/orion,,MIT,gpu;scheduling;deep-learning
359,submitit,Python toolbox for submitting jobs to Slurm,"A lightweight Python library for submitting and managing jobs on Slurm clusters, enabling easy switching between local execution and cluster execution for research experiments.",AI6;AI6-02,job_submission;experiment_management,library,Python,https://github.com/facebookincubator/submitit,https://github.com/facebookincubator/submitit,MIT,slurm;python;hpc
360,GPUTaskScheduler,Lightweight Python library for scheduling tasks on available GPUs,"A simple Python-based scheduler designed to manage and distribute tasks across available GPU resources, useful for local scientific experiment management.",AI6;AI6-02,job_scheduling;resource_management,library,Python,https://github.com/fjxmlzn/GPUTaskScheduler,,MIT,gpu;scheduling;python
361,Flux Core,Next-generation resource manager and scheduler for HPC centers,"The core framework of the Flux project, providing a hierarchical resource management system and job scheduler designed for modern High Performance Computing (HPC) environments.",AI6;AI6-02,job_scheduling;resource_management,platform,C,https://github.com/flux-framework/flux-core,http://flux-framework.org,LGPL-3.0,hpc;scheduler;resource-manager;flux
362,Flux K8s,Integration components for running Flux resource manager on Kubernetes,"A project to manage Flux tasks and standardize Kubernetes HPC scheduling interfaces, enabling the use of the Flux scheduler within Cloud Native environments.",AI6;AI6-02,job_scheduling;orchestration,solver,Go,https://github.com/flux-framework/flux-k8s,,Apache-2.0,kubernetes;hpc;flux;scheduling
363,Fugue,"Unified interface for distributed computing on Spark, Dask, and Ray","An abstraction layer that allows users to write code in native Python or SQL and execute it on distributed computing engines like Spark, Dask, and Ray, facilitating scalable scientific data processing.",AI6;AI6-02,distributed_computing;data_processing,library,Python,https://github.com/fugue-project/fugue,https://fugue-tutorials.readthedocs.io,Apache-2.0,distributed-computing;spark;dask;ray;abstraction
364,Furiko,Kubernetes-native batch job platform for complex workflows,"A high-performance cron and batch job platform for Kubernetes, suitable for managing scientific batch workloads with advanced scheduling features.",AI6;AI6-02,job_scheduling;batch_processing,platform,Go,https://github.com/furiko-io/furiko,https://furiko.io,Apache-2.0,kubernetes;batch-jobs;cron;scheduling
365,Ansible Role for Slurm,Ansible role for deploying Slurm Workload Manager,"An Ansible role maintained by the Galaxy Project for installing and managing the Slurm Workload Manager, essential for setting up scientific HPC clusters.",AI6;AI6-02,cluster_management;deployment,service,Jinja,https://github.com/galaxyproject/ansible-slurm,,None,slurm;ansible;hpc;deployment
366,Hypertunity,Toolset for black-box hyperparameter optimisation,"A lightweight and modular Python library for black-box hyperparameter optimization, supporting various schedulers and optimization algorithms for scientific ML models.",AI6;AI6-02,hyperparameter_optimization;model_tuning,library,Python,https://github.com/gdikov/hypertunity,,Apache-2.0,hpo;optimization;machine-learning
367,GeodMod,Geodetic Modeling Software in Matlab,"A MATLAB-based software suite for geodetic modeling, used for analyzing deformation data and geophysical parameters.",AI6,scientific_modeling;geodesy,solver,MATLAB,https://github.com/geodesymiami/GeodMod,,BSD-2-Clause,geodesy;matlab;modeling;earth-science
368,Dask-GeoPandas,Parallel GeoPandas with Dask,"A library that enables parallel processing of geospatial data by integrating GeoPandas with Dask, facilitating large-scale spatial analysis.",AI6,data_processing;spatial_analysis,library,Python,https://github.com/geopandas/dask-geopandas,https://dask-geopandas.readthedocs.io,BSD-3-Clause,geospatial;dask;parallel-computing;gis
369,foamlib,Modern Python package for interacting with OpenFOAM,"A Python interface for OpenFOAM, allowing users to automate CFD simulations, manipulate cases, and interact with OpenFOAM utilities programmatically.",AI6,simulation_interface;cfd,library,Python,https://github.com/gerlero/foamlib,https://foamlib.readthedocs.io,GPL-3.0,openfoam;cfd;python;simulation
370,Docker CentOS7 Slurm,Slurm Docker Container on CentOS 7,"A Docker image providing a pre-configured Slurm Workload Manager environment on CentOS 7, useful for testing and developing HPC workflows locally.",AI6;AI6-02,environment_simulation;hpc_testing,platform,Python,https://github.com/giovtorres/docker-centos7-slurm,,MIT,slurm;docker;hpc;centos
371,Slurm Docker Cluster,A Slurm cluster using docker-compose,"A tool to deploy a multi-node Slurm cluster using Docker Compose, enabling reproducible local simulation of HPC environments for job scheduling development.",AI6;AI6-02,cluster_simulation;job_scheduling,platform,Shell,https://github.com/giovtorres/slurm-docker-cluster,,MIT,slurm;docker-compose;hpc;cluster
372,stackstac,Turn a STAC catalog into a dask-based xarray,"A library for converting SpatioTemporal Asset Catalogs (STAC) into Dask-backed Xarray objects, streamlining the analysis of large-scale satellite and earth science data.",AI6,data_loading;earth_observation,library,Python,https://github.com/gjoseph92/stackstac,https://stackstac.readthedocs.io,MIT,stac;xarray;dask;remote-sensing
373,SDSC ibrun,SDSC's implementation of the ibrun MPI launcher,A wrapper script used at the San Diego Supercomputer Center (SDSC) to simplify MPI job launching across different batch schedulers and MPI implementations.,AI6;AI6-02,job_launching;mpi_execution,solver,Perl,https://github.com/glennklockwood/sdsc-ibrun,,BSD-3-Clause,mpi;hpc;job-launcher;sdsc
374,PathwaysJob API,Kubernetes-native API to deploy ML training and batch inference using Pathways,An API and controller for deploying Machine Learning training and batch inference workloads on Google Kubernetes Engine (GKE) using the Pathways runtime.,AI6;AI6-02,ml_orchestration;batch_inference,platform,Go,https://github.com/google/pathways-job,,Apache-2.0,kubernetes;machine-learning;pathways;gke
375,Xarray-Beam,Distributed Xarray with Apache Beam,"A library that adapts Xarray data structures for use with Apache Beam, enabling distributed processing of massive multi-dimensional scientific datasets.",AI6,distributed_processing;data_analysis,library,Python,https://github.com/google/xarray-beam,https://xarray-beam.readthedocs.io,Apache-2.0,xarray;apache-beam;distributed-computing;big-data
376,grid-control,Versatile job submission and management tool for grid computing,"A job submission tool designed for High Energy Physics and other scientific domains, supporting parameterized jobs and automatic resubmission on Grid and local batch systems.",AI6;AI6-02,job_submission;grid_computing,solver,Python,https://github.com/grid-control/grid-control,https://grid-control.github.io,None,grid-computing;batch-jobs;hep;job-management
377,VodaScheduler,GPU scheduler for elastic and distributed deep learning workloads on Kubernetes,VodaScheduler is a GPU scheduler designed for Kubernetes clusters to optimize elastic and distributed deep learning workloads. It improves resource utilization and training efficiency by managing GPU allocation dynamically.,AI6;AI6-02,job_scheduling;resource_allocation,solver,Go,https://github.com/heyfey/vodascheduler,,Apache-2.0,kubernetes;gpu-scheduling;deep-learning;distributed-training
378,Kubernetes Scheduler Simulator,Simulator for evaluating Kubernetes schedulers,"A tool designed to simulate the behavior of Kubernetes schedulers, allowing researchers and developers to evaluate scheduling algorithms and cluster behavior without deploying a real cluster. Useful for optimizing HPC/AI workload placement.",AI6;AI6-02,simulation;scheduling_research,solver,Shell,https://github.com/hkust-adsl/kubernetes-scheduler-simulator,,Apache-2.0,kubernetes;simulator;scheduling;hpc
379,hvPlot,High-level plotting API for scientific data visualization,"A high-level plotting API built on HoloViews that provides a general and consistent interface for visualizing data from Pandas, Dask, XArray, and NetworkX. Widely used in geoscience and physics for interactive data exploration.",AI6;Scientific Visualization,visualization;data_exploration,library,Python,https://github.com/holoviz/hvplot,https://hvplot.holoviz.org/,BSD-3-Clause,visualization;pandas;xarray;dask;interactive-plots
380,Horovod,Distributed deep learning training framework,"A distributed deep learning training framework for TensorFlow, Keras, PyTorch, and Apache MXNet. It makes distributed training easy and efficient, often used in HPC environments (via MPI) for large-scale scientific AI models.",AI6;AI6-02,distributed_training;model_training,library,Python,https://github.com/horovod/horovod,https://horovod.ai/,Apache-2.0,deep-learning;distributed-training;mpi;hpc
381,HTCondor,High-Throughput Computing (HTC) workload management system,"A specialized workload management system for compute-intensive jobs. It provides a job queueing mechanism, scheduling policy, priority scheme, resource monitoring, and resource management, widely used in physics (e.g., CERN) and genomics.",AI6;AI6-02,job_scheduling;workload_management,platform,C++,https://github.com/htcondor/htcondor,https://htcondor.org/,Apache-2.0,htc;batch-system;scheduling;grid-computing
382,HTCondor-CE,Grid gatekeeper for HTCondor compute elements,"A site grid gatekeeper technology based on HTCondor components, used to authorize and route incoming grid jobs to the local batch system. Essential for federated scientific computing grids.",AI6;AI6-02,grid_computing;job_routing,service,Python,https://github.com/htcondor/htcondor-ce,https://htcondor-ce.readthedocs.io/,Apache-2.0,grid;gatekeeper;htcondor;compute-element
383,HTCondor-RESTD,REST API interface for HTCondor,"Provides a RESTful interface to the HTCondor High-Throughput Computing system, enabling remote job submission, query, and management via HTTP, facilitating integration with modern scientific web portals.",AI6;AI6-02,job_submission;api_interface,service,Python,https://github.com/htcondor/htcondor-restd,,Apache-2.0,rest-api;htcondor;job-management
384,HTMap,Pythonic high-throughput computing library powered by HTCondor,"A library that wraps HTCondor to provide a map-reduce style interface for Python, allowing researchers to easily scale out function calls across a cluster without managing job files directly.",AI6;AI6-02,high_throughput_computing;parallel_execution,library,Python,https://github.com/htcondor/htmap,https://htmap.readthedocs.io/,Apache-2.0,python;htcondor;map-reduce;parallel-computing
385,llm-swarm,Scalable LLM inference on Slurm clusters,A tool to manage and scale open LLM inference endpoints within Slurm-managed HPC clusters. It facilitates the deployment of large language models for scientific research using existing HPC infrastructure.,AI6;AI6-02,inference_serving;resource_management,solver,Python,https://github.com/huggingface/llm-swarm,,MIT,slurm;llm;inference;hpc
386,Opara,DNN Operator parallel scheduling framework,A lightweight and resource-aware DNN Operator parallel scheduling framework designed to accelerate the execution of DNN inference on GPUs by optimizing operator execution order.,AI6;AI6-02,inference_optimization;operator_scheduling,library,Python,https://github.com/icloud-ecnu/Opara,,None,dnn;scheduling;gpu;inference
387,Prophet,Communication scheduling strategy for distributed training,"A predictable communication scheduling strategy to schedule gradient transfers in an adequate order, aiming to maximize GPU and network resource utilization during distributed DNN training.",AI6;AI6-02,distributed_training;communication_scheduling,library,Python,https://github.com/icloud-ecnu/Prophet,,None,distributed-training;gradient-scheduling;network-optimization
388,Argo Volcano Executor Plugin,Argo Workflows plugin for executing Volcano Jobs,"A plugin that allows Argo Workflows to trigger and manage Volcano jobs. Volcano is a batch scheduling system for Kubernetes, widely used for AI and Big Data workloads.",AI6;AI6-02,workflow_orchestration;job_submission,solver,Go,https://github.com/iflytek/argo-volcano-executor-plugin,,Apache-2.0,argo;volcano;kubernetes;workflow
389,MintPy,Miami InSAR time-series software,An open-source software package for Interferometric Synthetic Aperture Radar (InSAR) time-series analysis. It reads stack of interferograms and estimates the ground displacement time-series.,Geoscience;Remote Sensing,time_series_analysis;image_processing,solver,Python,https://github.com/insarlab/MintPy,https://mintpy.readthedocs.io/,None,insar;geodesy;remote-sensing;deformation
390,BigDL,Distributed deep learning on Big Data platforms,"A distributed deep learning framework for Apache Spark and Ray. It allows users to write deep learning applications as standard Spark/Ray programs, facilitating the integration of AI models into big data pipelines.",AI6;AI6-02,distributed_training;big_data_analytics,platform,Python,https://github.com/intel/BigDL,https://bigdl.readthedocs.io/,Apache-2.0,spark;ray;deep-learning;distributed-computing
391,CRI Resource Manager,Hardware resource aware workload placement for Kubernetes,"A Kubernetes Container Runtime Interface (CRI) proxy service that applies hardware resource-aware policies (e.g., NUMA topology, cache allocation) to optimize workload placement, essential for high-performance AI/HPC jobs.",AI6;HPC,resource_management;workload_placement,service,Go,https://github.com/intel/cri-resource-manager,https://intel.github.io/cri-resource-manager/,Apache-2.0,kubernetes;numa;resource-management;hpc
392,cellxgene_VIP,Visualization in Plugin for cellxgene,"A plugin for cellxgene that provides advanced visualization capabilities (violin plots, heatmaps, volcano plots) and differential gene expression analysis for single-cell transcriptomics data.",Bioinformatics;Genomics,visualization;differential_expression_analysis,solver,Python,https://github.com/interactivereport/cellxgene_VIP,,MIT,single-cell;visualization;genomics;cellxgene
393,Slurm Bank,Resource accounting wrapper for Slurm,"A collection of wrapper scripts for Slurm to provide banking/accounting capabilities (similar to GOLD), allowing HPC centers to manage compute allocations and project budgets.",AI6;AI6-02,resource_accounting;allocation_management,solver,Shell,https://github.com/jcftang/slurm-bank,,GPL-2.0,slurm;accounting;hpc;resource-management
394,autoray,Abstract array operations for backend-agnostic scientific computing,"A lightweight library that abstracts array operations, allowing scientific code to run transparently on NumPy, PyTorch, JAX, TensorFlow, Dask, and CuPy. Heavily used in quantum physics simulations (e.g., tensor networks).",AI6;Scientific Computing,array_computing;backend_abstraction,library,Python,https://github.com/jcmgray/autoray,,Apache-2.0,numpy;pytorch;jax;tensor-networks
395,smk-simple-slurm,Simple Slurm profile for Snakemake,"A configuration profile for Snakemake that simplifies the execution of scientific workflows on Slurm clusters, handling job submission and resource specification without complex cluster configuration files.",AI6;AI6-02,workflow_execution;job_submission,solver,Shell,https://github.com/jdblischak/smk-simple-slurm,,CC0-1.0,snakemake;slurm;workflow;hpc
396,GeoWombat,Utilities for geospatial data processing,"A Python package for processing geospatial data at scale. It simplifies tasks like reading/writing rasters, tiling, and applying functions over large satellite imagery datasets, often used in earth science research.",Geoscience;Remote Sensing,geospatial_analysis;image_processing,library,Python,https://github.com/jgrss/geowombat,https://geowombat.readthedocs.io/,MIT,geospatial;remote-sensing;raster;satellite-imagery
397,Swifter,Efficiently applies any function to a pandas dataframe or series in the fastest available manner,"A library that accelerates pandas DataFrame operations by automatically vectorizing or parallelizing computations using Dask or multiprocessing, essential for processing large scientific datasets.",AI6;Data Science,data_processing;acceleration,library,Python,https://github.com/jmcarpenter2/swifter,,MIT,pandas;acceleration;parallel-computing;data-processing
398,BatchSpawner,Custom Spawner for Jupyterhub to start servers in batch scheduled systems,"A JupyterHub spawner that enables launching Jupyter notebook servers as batch jobs on HPC schedulers like Slurm, HTCondor, and Torque, bridging interactive computing with HPC infrastructure.",AI6;AI6-02,job_scheduling;interactive_computing,service,Python,https://github.com/jupyterhub/batchspawner,,BSD-3-Clause,jupyterhub;hpc;slurm;batch-scheduling
399,Task Spooler,A UNIX batch system where tasks submitted from a shell are run one after another,"A lightweight job scheduling tool for single machines that allows users to queue commands (tasks) for sequential execution, useful for managing scientific simulations or data processing jobs on workstations.",AI6;AI6-02,job_scheduling;task_queue,solver,C,https://github.com/justanhduc/task-spooler,,GPL-2.0,scheduler;batch-system;cli;queue
400,Turm,TUI for the Slurm Workload Manager,"A terminal user interface (TUI) for monitoring and managing jobs on the Slurm Workload Manager, providing a visual way to interact with HPC clusters.",AI6;AI6-02,job_management;monitoring,solver,Rust,https://github.com/kabouzeid/turm,,MIT,slurm;hpc;tui;monitoring
401,EnhancedVolcano,Publication-ready volcano plots with enhanced colouring and labeling,An R package for generating highly customizable volcano plots to visualize differential expression results in bioinformatics and genomics research.,Bioinformatics,visualization;differential_expression,library,R,https://github.com/kevinblighe/EnhancedVolcano,https://bioconductor.org/packages/release/bioc/html/EnhancedVolcano.html,GPL-3.0,volcano-plot;genomics;visualization;r-package
402,kube-batch,A batch scheduler of kubernetes for high performance workload,"A batch scheduler for Kubernetes designed for high-performance workloads such as AI/ML, Big Data, and HPC, supporting advanced scheduling policies like gang scheduling.",AI6;AI6-02,job_scheduling;workload_management,platform,Go,https://github.com/kubernetes-retired/kube-batch,,Apache-2.0,kubernetes;batch-scheduling;hpc;gang-scheduling
403,JobSet,A Kubernetes-native API for distributed ML training and HPC workloads,"A Kubernetes controller that manages groups of related jobs (JobSets) as a single unit, specifically designed to handle distributed machine learning training and HPC workloads with failure recovery policies.",AI6;AI6-02,workload_management;distributed_training,platform,Go,https://github.com/kubernetes-sigs/jobset,,Apache-2.0,kubernetes;hpc;machine-learning;distributed-training
404,Kueue,Kubernetes-native Job Queueing,"A job queueing controller for Kubernetes that manages quotas and job admission, enabling batch scheduling capabilities similar to traditional HPC schedulers within a cloud-native environment.",AI6;AI6-02,job_queueing;resource_management,platform,Go,https://github.com/kubernetes-sigs/kueue,https://kueue.sigs.k8s.io/,Apache-2.0,kubernetes;batch-queueing;job-management;hpc
405,ggvolc,Translates differential expression datasets into informative volcano plots,"An R package designed to simplify the creation of volcano plots for RNA-seq and differential expression data, allowing for easy visualization of genes of interest.",Bioinformatics,visualization;differential_expression,library,R,https://github.com/loukesio/ggvolc,,NOASSERTION,volcano-plot;visualization;rnaseq;r
406,Mars,"Tensor-based unified framework for scaling numpy, pandas, and scikit-learn","Mars is a tensor-based unified framework for large-scale data computation which scales Python scientific libraries like numpy, pandas, and scikit-learn. It allows researchers to run data-intensive scientific computing tasks on distributed clusters with minimal code changes.",AI6;AI6-02,distributed_computing;data_processing,library,Python,https://github.com/mars-project/mars,https://mars-project.readthedocs.io/,Apache-2.0,distributed-computing;tensor;numpy-compatible;parallel-computing
407,LiCSAlert,Volcano monitoring system using Sentinel-1 InSAR data,LiCSAlert is a tool for automatic volcano monitoring that processes Sentinel-1 InSAR data to detect ground deformation. It is designed to assist in the surveillance of volcanic activity through satellite remote sensing data analysis.,Earth Science;Geophysics,remote_sensing_analysis;anomaly_detection,solver,Python,https://github.com/matthew-gaddes/LiCSAlert,,GPL-3.0,volcanology;insar;remote-sensing;monitoring
408,ssubmit,CLI tool to submit Slurm jobs without writing sbatch scripts,"ssubmit is a command-line utility that simplifies the submission of jobs to the Slurm workload manager. It allows users to submit jobs directly without the need to create and manage temporary sbatch scripts, streamlining the HPC workflow.",AI6;AI6-02,job_submission;workflow_management,tool,Rust,https://github.com/mbhall88/ssubmit,,Unlicense,slurm;hpc;cli;productivity
409,TorchX,Universal job launcher for PyTorch applications on HPC and Cloud,"TorchX is a universal job launcher and workflow engine for PyTorch applications. It supports submitting distributed training and batch inference jobs to various schedulers including Slurm, Kubernetes, AWS Batch, and Ray, facilitating reproducible AI research.",AI6;AI6-02,job_scheduling;distributed_training,platform,Python,https://github.com/meta-pytorch/torchx,https://pytorch.org/torchx/,BSD-3-Clause,pytorch;job-launcher;slurm;kubernetes;mlops
410,CRA,Common Runtime for Applications for distributed dataflow,"Common Runtime for Applications (CRA) is a library designed to simplify the creation and deployment of distributed dataflow-style applications. It abstracts resource management on clusters like Kubernetes and YARN, useful for building custom scientific distributed computing systems.",AI6;AI6-01,distributed_computing;resource_management,library,C#,https://github.com/microsoft/CRA,,MIT,distributed-systems;dataflow;runtime;microsoft-research
411,OpenPAI,Resource scheduling and cluster management platform for AI,"OpenPAI is an open-source platform that provides complete AI model training and resource management capabilities. It supports job scheduling, cluster monitoring, and efficient resource utilization for large-scale AI for Science workloads.",AI6;AI6-02,cluster_management;job_scheduling,platform,JavaScript,https://github.com/microsoft/pai,https://openpai.readthedocs.io/,MIT,ai-platform;cluster-management;kubernetes;gpu-scheduling
412,stui,Terminal-based dashboard for monitoring Slurm jobs,"stui is a terminal user interface (TUI) for the Slurm workload manager. It allows researchers and administrators to monitor job status, node utilization, and cluster health directly from the command line in an interactive dashboard.",AI6;AI6-02,monitoring;job_management,tool,Python,https://github.com/mil-ad/stui,,MIT,slurm;tui;monitoring;hpc
413,batchtools,R package for high-performance computing on batch systems,"batchtools is an R package that provides a unified interface for parallel computing on batch systems like Slurm, LSF, SGE, and Torque. It handles job submission, status monitoring, and result collection, enabling scalable scientific data analysis in R.",AI6;AI6-02,job_submission;parallel_computing,library,R,https://github.com/mlr-org/batchtools,https://mllg.github.io/batchtools/,LGPL-3.0,r;hpc;slurm;parallel-computing
414,pbrt-v4,Physically based rendering system for light transport simulation,"pbrt-v4 is the source code for the fourth edition of 'Physically Based Rendering'. It is a comprehensive rendering system that simulates the physical behavior of light, widely used in computer graphics research and optical simulation.",Physics;Computer Graphics,simulation;rendering,solver,C++,https://github.com/mmp/pbrt-v4,https://pbrt.org/,Apache-2.0,rendering;ray-tracing;physics-simulation;optics
415,clustermq,Efficient parallelization of R function calls on HPC clusters,"clustermq is an R package that sends function calls as jobs to HPC schedulers (Slurm, LSF, SGE, etc.) or via SSH. It reduces the overhead of job submission and management compared to traditional batch scripts, optimizing high-throughput scientific computing in R.",AI6;AI6-02,job_submission;parallel_computing,library,R,https://github.com/mschubert/clustermq,https://mschubert.github.io/clustermq/,Apache-2.0,r;hpc;slurm;parallelization
416,Lexcube,Interactive 3D visualization for Earth system data cubes,"Lexcube is a tool for the interactive 3D visualization of large Earth system data cubes within Jupyter Notebooks. It enables scientists to explore and analyze massive spatiotemporal datasets (e.g., climate data) efficiently.",Earth Science;Climate Science,visualization;data_exploration,tool,TypeScript,https://github.com/msoechting/lexcube,,GPL-3.0,visualization;earth-science;data-cube;jupyter
417,Narwhals,Compatibility layer for scientific dataframe libraries,"Narwhals is a lightweight compatibility layer that allows library developers to write dataframe-agnostic code. It supports pandas, Polars, and other dataframe libraries, facilitating the development of interoperable scientific data analysis tools.",AI6;Data Science,data_processing;interoperability,library,Python,https://github.com/narwhals-dev/narwhals,https://narwhals-dev.github.io/narwhals/,MIT,dataframe;pandas;polars;compatibility
418,scores,Metrics for verification and evaluation of weather and climate forecasts,"scores is a Python package containing mathematical functions for the verification, evaluation, and optimization of forecasts, predictions, or models, specifically tailored for meteorology and climate science applications.",Earth Science;Meteorology,model_evaluation;verification,library,Jupyter Notebook,https://github.com/nci/scores,https://scores.readthedocs.io/,Apache-2.0,meteorology;verification;metrics;climate-science
419,NCSA Scheduler,Aggregate job launcher for HPC environments,The NCSA Scheduler is a tool designed to aggregate and launch single-core or single-node applications on HPC sites. It helps optimize job scheduling and resource usage on supercomputing clusters.,AI6;AI6-02,job_scheduling;workload_management,tool,Fortran,https://github.com/ncsa/Scheduler,,NOASSERTION,hpc;scheduler;ncsa;job-launcher
420,Nebari,Open source data science platform for scalable collaboration,"Nebari is an opinionated, open-source data science platform that integrates JupyterHub, Dask, and Conda. It provides a reproducible and scalable environment for scientific collaboration and data analysis on cloud or on-premise infrastructure.",AI6;AI6-01,environment_management;collaborative_science,platform,Python,https://github.com/nebari-dev/nebari,https://www.nebari.dev/,BSD-3-Clause,data-science;jupyterhub;dask;platform
421,soperator,Kubernetes operator for running Slurm clusters,soperator is a Kubernetes operator that manages the deployment and lifecycle of Slurm clusters on Kubernetes. It enables the convergence of HPC and cloud-native workflows by running Slurm workloads within a Kubernetes environment.,AI6;AI6-02,cluster_management;orchestration,tool,Go,https://github.com/nebius/soperator,https://nebius.ai/slurm-operator,Apache-2.0,kubernetes;slurm;operator;hpc-on-k8s
422,Slurm-Mail,Enhanced email notification system for Slurm jobs,"A drop-in replacement for standard Slurm email notifications that provides users with comprehensive job information, including resource usage and status details, improving observability for HPC workloads.",AI6;AI6-02,job_monitoring;hpc_utility,service,Python,https://github.com/neilmunday/slurm-mail,,GPL-3.0,slurm;hpc;monitoring;email-notifications
423,OAR,Versatile resource and task manager for HPC clusters,"A batch scheduler and resource manager for high-performance computing clusters. It provides a flexible architecture for managing jobs, resources, and scheduling policies, widely used in research infrastructures like Grid'5000.",AI6;AI6-02,job_scheduling;resource_management,platform,Perl,https://github.com/oar-team/oar,http://oar.imag.fr/,GPL-2.0,hpc;scheduler;batch-system;cluster-management
424,OAR3,Next-generation Python-based OAR scheduler,"The third generation of the OAR resource and job manager, rewritten in Python to provide a more modern, maintainable, and extensible architecture for cluster scheduling.",AI6;AI6-02,job_scheduling;resource_management,platform,Python,https://github.com/oar-team/oar3,,NOASSERTION,hpc;scheduler;python;cluster
425,Funnel,Distributed task execution toolkit implementing GA4GH TES,"A toolkit for distributed task execution that implements the GA4GH Task Execution Schema (TES), enabling standardized job submission and execution across various compute backends (HPC, Cloud) for genomics and bioinformatics workflows.",AI6;AI6-02,task_execution;genomics_workflow,service,Go,https://github.com/ohsu-comp-bio/funnel,https://ohsu-comp-bio.github.io/funnel/,MIT,ga4gh;tes;bioinformatics;distributed-computing;task-runner
426,CCQHub,Meta-scheduler for linking disparate HPC environments,"A meta-scheduler designed to connect different HPC environments, allowing jobs to be treated as payloads that can be routed and executed across disparate computing resources.",AI6;AI6-02,meta_scheduling;hpc_interoperability,service,Python,https://github.com/omnibond/CCQHub,,LGPL-3.0,hpc;meta-scheduler;cloud-bursting;job-management
427,CoexecutorRuntime,Runtime for heterogeneous computing scheduling in oneAPI,"A runtime environment associated with Intel's oneAPI ecosystem, designed to facilitate straightforward heterogeneous computing and scheduling across different accelerator architectures.",AI6;AI6-02,heterogeneous_scheduling;runtime_acceleration,library,C++,https://github.com/oneAPI-scheduling/CoexecutorRuntime,,MIT,oneapi;hpc;heterogeneous-computing;scheduling
428,Kubernetes EC2 Autoscaler,Batch-optimized scaling manager for Kubernetes on AWS,"A Kubernetes autoscaler optimized for batch workloads (like AI training and scientific simulations), managing EC2 ASGs to efficiently scale compute resources based on pending job requirements.",AI6;AI6-02,resource_scaling;cloud_hpc,service,Python,https://github.com/openai/kubernetes-ec2-autoscaler,,MIT,kubernetes;autoscaling;batch-processing;aws;ai-infra
429,Gridscale,Scala library for accessing grid and batch schedulers,"A library used by the OpenMOLE workflow engine to abstract interactions with various computing backends, including local execution, SSH, Slurm, PBS, and grid middlewares, facilitating distributed scientific computing.",AI6;AI6-02,job_submission;grid_computing,library,Scala,https://github.com/openmole/gridscale,,AGPL-3.0,scala;hpc;grid-computing;middleware;job-submission
430,OpenPBS,HPC workload manager and job scheduler,"An open-source version of the Portable Batch System (PBS), a widely used workload manager for HPC clusters, clouds, and supercomputers, responsible for scheduling and managing computational jobs.",AI6;AI6-02,job_scheduling;workload_management,platform,C,https://github.com/openpbs/openpbs,https://www.openpbs.org,NOASSERTION,hpc;scheduler;workload-manager;cluster
431,Kueue Operator,Operator for managing Kueue job queuing system on Kubernetes,"A Kubernetes operator to deploy and manage Kueue, a cloud-native job queueing system that manages batch jobs and resource quotas, essential for running AI/ML and scientific batch workloads on Kubernetes.",AI6;AI6-02,batch_scheduling;k8s_operator,service,Go,https://github.com/openshift/kueue-operator,,Apache-2.0,kubernetes;batch-jobs;operator;kueue;ai-infra
432,django-remote-submission,Django app for remote job submission to HPC clusters,"A Django application developed at ORNL that facilitates asynchronous task submission and monitoring on remote HPC resources (via Celery and Redis), typically used to build science gateways and web portals for research.",AI6;AI6-02,job_submission;science_gateway,library,Python,https://github.com/ornl-ndav/django-remote-submission,,ISC,hpc;django;celery;job-submission;science-gateway
433,ATOS,Multi-GPU dynamic scheduler with PGAS communication,A research scheduler for multi-GPU environments that utilizes PGAS-style cross-GPU communication to optimize dynamic task scheduling and execution efficiency in high-performance computing contexts.,AI6;AI6-02,gpu_scheduling;parallel_computing,solver,Cuda,https://github.com/owensgroup/ATOS,,None,gpu;cuda;scheduling;hpc;pgas
434,mgpuscheduler,Multi-GPU CUDA-based scheduler,"A scheduler designed for managing and executing tasks across multiple GPUs using CUDA, developed for research into efficient GPU utilization and parallel task management.",AI6;AI6-02,gpu_scheduling;parallel_computing,solver,C++,https://github.com/owensgroup/mgpuscheduler,,None,gpu;cuda;scheduler;hpc
435,Climpred,Verification tool for weather and climate forecasts,A python package for the verification and analysis of weather and climate forecasts. It provides statistical tools to assess the skill of prediction models against observations.,AI6;AI6-02,forecast_verification;climate_analysis,library,Python,https://github.com/pangeo-data/climpred,https://climpred.readthedocs.io/,MIT,climate-science;weather-forecasting;verification;geoscience;pangeo
436,mpify,MPI-like multiprocessing for Python in Jupyter,"A simple API to launch Python functions on multiple ranked processes, enabling interactive distributed data parallel experiments (e.g., for AI training) directly from Jupyter/IPython environments.",AI6;AI6-02,distributed_computing;interactive_hpc,library,Python,https://github.com/philtrade/mpify,,Apache-2.0,multiprocessing;jupyter;distributed-training;mpi;python
437,Pipefunc,Lightweight pipeline creation for scientific HPC workflows,"A Python library for creating lightweight, fast function pipelines (DAGs) specifically designed for scientific and HPC workflows, facilitating modular code structure and execution.",AI6;AI6-02,workflow_creation;pipeline_management,library,Python,https://github.com/pipefunc/pipefunc,https://pipefunc.readthedocs.io/,MIT,pipeline;dag;hpc;scientific-computing;workflow
438,slurm-rs,Rust bindings for Slurm workload manager,"Rust language bindings for interacting with the Slurm workload manager API, enabling the development of high-performance tools and utilities for HPC job management in Rust.",AI6;AI6-02,hpc_development;job_management_api,library,Rust,https://github.com/pkgw/slurm-rs,,MIT,rust;slurm;hpc;bindings
439,Soopervisor,Exporter for Ploomber pipelines to HPC and Cloud platforms,"A tool that exports Ploomber data science pipelines to various execution environments including Kubernetes (Argo), Airflow, AWS Batch, and SLURM, bridging local development and production/HPC execution.",AI6;AI6-02,pipeline_deployment;workflow_export,tool,Python,https://github.com/ploomber/soopervisor,https://soopervisor.readthedocs.io/,Apache-2.0,ploomber;pipeline;slurm;kubernetes;mlops
440,ScanTools,Genomic selection analysis tools and Slurm wrapper,"A collection of tools for analyzing selection in genomic data, including a wrapper for simplifying job submission to Slurm clusters, tailored for bioinformatics research.",AI6;AI6-02,genomics_analysis;job_submission,tool,Python,https://github.com/pmonnahan/ScanTools,,None,genomics;bioinformatics;slurm;selection-analysis
441,TraceML,ML/Data tracking and visualization engine for Polyaxon,"The tracking and visualization engine for the Polyaxon platform, providing capabilities for logging experiments, visualizing metrics, and detecting drift in machine learning workflows used in research and production.",AI6;AI6-02,experiment_tracking;mlops,library,Python,https://github.com/polyaxon/traceml,https://polyaxon.com/docs/experimentation/tracking/,Apache-2.0,mlops;tracking;visualization;polyaxon;experiment-management
442,AppWrapper,Kueue controller for managing AI/HPC applications on Kubernetes,"Part of the Project CodeFlare, AppWrapper is a Kubernetes controller that integrates with Kueue to provide advanced queuing, resource management, and lifecycle handling for complex AI and HPC applications.",AI6;AI6-02,application_management;batch_scheduling,service,Go,https://github.com/project-codeflare/appwrapper,,Apache-2.0,kubernetes;hpc;ai;controller;codeflare
443,MLBatch,Queuing and quota management for AI/ML batch jobs,"A system for managing queuing and resource quotas specifically for AI/ML batch jobs on Kubernetes, ensuring efficient utilization of cluster resources for training and inference workloads.",AI6;AI6-02,batch_management;resource_quota,service,JavaScript,https://github.com/project-codeflare/mlbatch,,Apache-2.0,kubernetes;ml;batch-jobs;quota-management
444,PyCondor,Python utility for HTCondor workflow submission,"A Python package that simplifies the process of building and submitting workflows to the HTCondor high-throughput computing system, allowing users to define jobs and DAGs using Python objects.",AI6;AI6-02,job_submission;workflow_management,library,Python,https://github.com/pycondor/pycondor,https://pycondor.readthedocs.io/,MIT,htcondor;hpc;workflow;python;high-throughput-computing
445,xarray,N-D labeled arrays and datasets in Python,"Xarray introduces labels in the form of dimensions, coordinates and attributes on top of raw NumPy-like arrays, which allows for a more intuitive, more concise, and less error-prone developer experience. It is widely used in physics, climate science, and oceanography for handling multi-dimensional scientific data.",AI6;AI6-02,data_processing;multidimensional_analysis,library,Python,https://github.com/pydata/xarray,https://docs.xarray.dev,Apache-2.0,scientific-computing;multi-dimensional-arrays;netcdf
446,pyresample,Geospatial image resampling in Python,A Python package for resampling geospatial image data. It is primarily designed for resampling earth observation satellite data and handling various map projections.,AI6,data_processing;resampling,library,Python,https://github.com/pytroll/pyresample,https://pyresample.readthedocs.io,LGPL-3.0,geospatial;remote-sensing;resampling
447,satpy,Python package for earth-observing satellite data processing,"Satpy is a python library for reading, manipulating, and writing meteorological remote sensing data. It supports various satellite instrument formats and provides functionality for compositing and resampling.",AI6,data_processing;satellite_imaging,library,Python,https://github.com/pytroll/satpy,https://satpy.readthedocs.io,GPL-3.0,remote-sensing;meteorology;satellite-data
448,Slurm-web,Open source web interface for Slurm HPC & AI clusters,"A web interface for the Slurm workload manager, providing a dashboard for monitoring cluster status and jobs, tailored for HPC and AI research environments.",AI6;AI6-02,job_management;cluster_monitoring,service,Python,https://github.com/rackslab/Slurm-web,https://rackslab.github.io/Slurm-web,MIT,hpc;slurm;web-interface
449,Crater,Cloud-native AI training & inference platform,"A platform designed to streamline AI training and inference workloads on cloud-native infrastructure, facilitating the execution of scientific machine learning models.",AI6;AI6-02,model_training;inference_serving,platform,TypeScript,https://github.com/raids-lab/crater,,Apache-2.0,ai-platform;training;inference
450,cuDF,GPU DataFrame Library,"A GPU DataFrame library for loading, joining, aggregating, filtering, and manipulating data, built on the Apache Arrow columnar memory format. It accelerates scientific data processing pipelines.",AI6,data_processing;acceleration,library,C++,https://github.com/rapidsai/cudf,https://docs.rapids.ai/api/cudf/stable/,Apache-2.0,gpu;dataframe;rapids
451,dask-cuda,Utilities for Dask and CUDA interactions,"Utilities for using Dask with CUDA-enabled GPUs, including cluster management and worker configuration, enabling distributed parallel computing for scientific workloads.",AI6;AI6-02,distributed_computing;gpu_acceleration,library,Python,https://github.com/rapidsai/dask-cuda,https://docs.rapids.ai/api/dask-cuda/stable/,Apache-2.0,dask;cuda;distributed-computing
452,dask-cudf,Dask support for distributed GDF object,"A library that connects Dask and cuDF to provide distributed GPU DataFrames, allowing for scaling of scientific data processing across multiple GPUs.",AI6,data_processing;distributed_computing,library,Python,https://github.com/rapidsai/dask-cudf,https://docs.rapids.ai/api/dask-cudf/stable/,Apache-2.0,dask;cudf;gpu
453,KubeRay,A toolkit to run Ray applications on Kubernetes,"KubeRay is a Kubernetes operator for managing Ray clusters, simplifying the deployment and management of distributed AI and scientific computing applications on K8s.",AI6;AI6-02,cluster_management;distributed_computing,platform,Go,https://github.com/ray-project/kuberay,https://ray-project.github.io/kuberay/,Apache-2.0,ray;kubernetes;operator
454,Ray,Unified framework for scaling AI and Python applications,"Ray provides a simple, universal API for building distributed applications. It is widely used for scaling scientific AI workloads like reinforcement learning, hyperparameter tuning, and model training.",AI6;AI6-02,distributed_computing;model_training,platform,Python,https://github.com/ray-project/ray,https://docs.ray.io,Apache-2.0,distributed-computing;machine-learning;scaling
455,XGBoost on Ray,Distributed XGBoost on Ray,"A library for training XGBoost models at scale using Ray clusters, enabling efficient processing of large-scale scientific datasets.",AI6,model_training;distributed_computing,library,Python,https://github.com/ray-project/xgboost_ray,https://docs.ray.io/en/latest/ray-air/examples/xgboost_example.html,Apache-2.0,xgboost;ray;distributed-ml
456,ezpz,Distributed training utility for PyTorch,"A lightweight wrapper to simplify distributed training across multiple devices and nodes, facilitating scientific machine learning experiments.",AI6;AI6-02,model_training;distributed_computing,library,Python,https://github.com/saforem2/ezpz,,MIT,pytorch;distributed-training;ddp
457,Kuscia,Kubernetes-based privacy-preserving computing task orchestration framework,"A lightweight, privacy-preserving computing task orchestration framework based on Kubernetes, designed for secure collaborative analysis of sensitive scientific or medical data.",AI6;AI6-02,task_orchestration;privacy_preserving_computing,platform,Go,https://github.com/secretflow/kuscia,https://www.secretflow.org.cn/docs/kuscia/,Apache-2.0,privacy-computing;kubernetes;orchestration
458,spark-gateway,REST API for interacting with batch Spark Applications on Kubernetes,"A gateway service that provides a REST API to submit and manage Spark batch applications on Kubernetes clusters, facilitating big data processing for scientific research.",AI6;AI6-02,job_submission;batch_processing,service,Go,https://github.com/slackhq/spark-gateway,,Apache-2.0,spark;kubernetes;batch-processing
459,snakemake-executor-plugin-kueue,Snakemake executor plugin for Kueue on Kubernetes,"A plugin for Snakemake that allows scientific workflow jobs to be executed via the Kueue job queueing system on Kubernetes, enabling scalable workflow execution.",AI6;AI6-02,workflow_execution;job_scheduling,library,Python,https://github.com/snakemake/snakemake-executor-plugin-kueue,https://snakemake.github.io/snakemake-plugin-catalog/plugins/executor/kueue.html,MIT,snakemake;kueue;kubernetes
460,STUMPY,Scalable Python library for modern time series analysis using Matrix Profiles,"STUMPY is a powerful and scalable Python library that efficiently computes the matrix profile for time series data. It is used for pattern discovery, anomaly detection, and semantic segmentation in scientific and industrial time series analysis.",AI1;AI1-01,time_series_analysis;motif_discovery;anomaly_detection,library,Python,https://github.com/stumpy-dev/stumpy,https://stumpy.readthedocs.io/,NOASSERTION,time-series;matrix-profile;data-analysis
461,wlm-operator,Kubernetes operator for interacting with Slurm workloads via Singularity,"A Kubernetes operator that serves as a bridge between Kubernetes and Slurm Workload Manager. It allows for the submission and management of Slurm jobs directly from a Kubernetes environment, utilizing Singularity containers for HPC compatibility.",AI6;AI6-02,job_submission;workload_management;hpc_integration,service,Go,https://github.com/sylabs/wlm-operator,,Apache-2.0,slurm;kubernetes;singularity;hpc
462,pbstools,Administration and management utilities for PBS/TORQUE HPC schedulers,"A collection of utilities designed to assist in the administration, use, and management of PBS (Portable Batch System) variants, including OpenPBS, PBS Pro, and TORQUE, facilitating HPC cluster operations.",AI6;AI6-02,cluster_administration;job_management,library,PHP,https://github.com/tabaer/pbstools,,GPL-2.0,pbs;torque;hpc;scheduler
463,Slurm4Azure,Deployment scripts for Slurm Workload Manager on Microsoft Azure,"A set of tools and scripts to deploy and configure the Slurm Workload Manager on Ubuntu instances within the Microsoft Azure cloud environment, enabling cloud-based HPC clusters.",AI6;AI6-02,cluster_deployment;cloud_hpc,workflow,Shell,https://github.com/tamhinsf/Slurm4Azure,,None,slurm;azure;hpc;cloud-computing
464,GooseSLURM,Command line wrappers and utilities for Slurm job submission,"A collection of Python-based command line tools and scripts that simplify the interaction with the Slurm Workload Manager, providing convenient wrappers for job submission and management tasks.",AI6;AI6-02,job_submission;cli_utility,library,Python,https://github.com/tdegeus/GooseSLURM,https://gooseslurm.readthedocs.io,MIT,slurm;cli;hpc;job-management
465,condorpy,Python interface for HTCondor high-throughput computing system,"A Python module that provides an interface to interact with HTCondor, allowing users to create, submit, and manage high-throughput computing jobs programmatically from Python scripts.",AI6;AI6-02,job_submission;htc_management,library,Python,https://github.com/tethysplatform/condorpy,,BSD-2-Clause,htcondor;htc;job-scheduling;python-wrapper
466,Paperboy,Web frontend for scheduling and executing Jupyter notebook reports,"A web-based application for scheduling and running Jupyter notebooks as reports. It allows users to parameterize notebooks and schedule their execution, facilitating reproducible scientific reporting and automated analysis workflows.",AI6;AI6-02,notebook_scheduling;workflow_automation;reporting,platform,Python,https://github.com/tkp-archive/paperboy,https://paperboy.readthedocs.io,Apache-2.0,jupyter;scheduling;reporting;reproducibility
467,Tuplex,Parallel big data processing framework for optimizing Python data science pipelines,"Tuplex is a parallel big data processing framework that compiles Python data science pipelines into optimized LLVM bytecode. It is designed to run Python code at the speed of compiled languages like C++, specifically targeting data cleaning and transformation tasks in scientific data analysis.",AI6;AI6-01,data_processing;pipeline_optimization;parallel_computing,framework,C++,https://github.com/tuplex/tuplex,https://tuplex.cs.brown.edu/,Apache-2.0,data-science;llvm;parallel-processing;python-optimization
468,Cook,Fair job scheduler for batch workloads and Spark on Kubernetes/Mesos,"Cook is a fair job scheduler designed for batch workloads and Spark jobs, running on Kubernetes and Mesos. It provides advanced scheduling features like preemption, fair sharing, and resource pooling, suitable for high-performance computing and quantitative research environments.",AI6;AI6-02,batch_scheduling;resource_management;spark_scheduling,platform,Clojure,https://github.com/twosigma/Cook,https://github.com/twosigma/Cook/wiki,Apache-2.0,scheduler;kubernetes;batch-processing;spark
469,socker,Wrapper for securely running Docker containers on Slurm clusters,A tool that wraps Docker execution to allow secure running of containers within a Slurm HPC environment. It addresses security concerns associated with running Docker in multi-user clusters by managing permissions and execution contexts.,AI6;AI6-01,container_runtime;hpc_security,solver,Python,https://github.com/unioslo/socker,,NOASSERTION,docker;slurm;hpc;container
470,HTGS,Hybrid Task Graph Scheduler API for high-performance computing,The Hybrid Task Graph Scheduler (HTGS) is an abstract execution model and API designed to facilitate the implementation of workflow systems for high-performance computing. It helps manage data dependencies and task scheduling across hybrid architectures.,AI6;AI6-02,task_scheduling;workflow_execution,library,C++,https://github.com/usnistgov/HTGS,,NOASSERTION,hpc;task-graph;scheduler;cpp
471,Tensor Fusion,GPU virtualization and pooling solution for optimizing AI cluster utilization,"Tensor Fusion is a GPU virtualization and pooling solution designed to maximize GPU cluster utilization. It supports dynamic resource allocation and sharing for AI inference and training workloads, integrating with tools like Karpenter and PyTorch.",AI6;AI6-01,gpu_virtualization;resource_optimization;ai_infrastructure,platform,Go,https://github.com/veneratedcoin/tensor-fusion,,Apache-2.0,gpu-virtualization;ai-infrastructure;resource-pooling;cuda
472,Volcano,Cloud Native Batch Scheduling System for Kubernetes,"Volcano is a batch system built on Kubernetes, designed for high-performance computing (HPC) and big data workloads. It provides powerful scheduling capabilities such as gang scheduling, fair share, and queue management, making it a critical component for running AI and scientific workloads in cloud-native environments.",AI6;AI6-02,batch_scheduling;workload_management;resource_scheduling,platform,Go,https://github.com/volcano-sh/volcano,https://volcano.sh/,Apache-2.0,kubernetes;batch-processing;scheduler;hpc;cncf
473,Volcano Global,Federation scheduler for multi-cluster management in Volcano ecosystem,"A federation scheduler component for the Volcano batch system, enabling cross-cluster job scheduling and resource management for cloud-native AI and HPC workloads.",Infra/HPC;AI6;AI6-02,scheduling;cluster_federation,service,Go,https://github.com/volcano-sh/volcano-global,https://volcano.sh,Apache-2.0,scheduler;kubernetes;hpc;federation;volcano
474,veTurboIO,High-performance I/O library for PyTorch model files,"A library developed by Volcano Engine to accelerate reading and writing of PyTorch model files, optimizing I/O performance for large-scale AI model training and inference.",Infra/HPC;AI6,io_optimization;model_loading,library,Python,https://github.com/volcengine/veTurboIO,,Apache-2.0,pytorch;io-optimization;hpc;ai-infrastructure
475,verl,Volcano Engine Reinforcement Learning library for LLMs,"A high-performance Reinforcement Learning (RL) library designed for Large Language Models (LLMs), supporting flexible and scalable RLHF (Reinforcement Learning from Human Feedback) training workflows.",Infra/HPC;AI6,model_training;reinforcement_learning,library,Python,https://github.com/volcengine/verl,,Apache-2.0,llm;rlhf;reinforcement-learning;training-framework
476,prometheus-slurm-exporter,Prometheus exporter for Slurm metrics,"A tool that collects performance and status metrics from the Slurm workload manager and exports them for monitoring via Prometheus, essential for HPC cluster observability.",Infra/HPC;AI6;AI6-02,monitoring;cluster_management,service,Go,https://github.com/vpenso/prometheus-slurm-exporter,,GPL-3.0,slurm;prometheus;monitoring;hpc;exporter
477,Slurmer,TUI application for Slurm job management,"A Terminal User Interface (TUI) tool for monitoring and managing jobs on Slurm-based HPC clusters, providing a user-friendly way to interact with the scheduler.",Infra/HPC;AI6;AI6-02,job_management;monitoring,solver,Rust,https://github.com/wjwei-handsome/Slurmer,,MIT,slurm;tui;hpc;job-management;rust
478,tmux-mpi,Tool for launching MPI processes in tmux,"A utility for launching and managing MPI (Message Passing Interface) processes within tmux windows, facilitating debugging and interactive monitoring of parallel HPC applications.",Infra/HPC;AI6;AI6-02,process_launching;debugging,solver,Python,https://github.com/wrs20/tmux-mpi,,MIT,mpi;tmux;hpc;parallel-computing;debugging
479,xcube,Python package for Earth observation data cubes,"A Python package for generating, manipulating, and analyzing Earth observation data cubes, leveraging xarray, dask, and zarr for scalable scientific data processing.",Earth Science;Scientific Data Analysis,data_cube_generation;geospatial_analysis,library,Python,https://github.com/xcube-dev/xcube,https://xcube.readthedocs.io,MIT,earth-observation;data-cubes;xarray;dask;geospatial
480,slurm-for-ml,Machine Learning workflow scripts for Slurm,"A collection of scripts and configurations designed to streamline running Machine Learning workflows on Slurm-managed HPC clusters, handling job submission and environment setup.",Infra/HPC;AI6;AI6-02,workflow_management;job_submission,workflow,Shell,https://github.com/y0ast/slurm-for-ml,,MIT,slurm;machine-learning;hpc;workflow
481,cuda_scheduling_examiner,Tool for examining GPU scheduling behavior,"A utility for analyzing and understanding CUDA GPU scheduling behavior, useful for performance optimization and debugging of GPU-accelerated scientific applications.",Infra/HPC;AI6,performance_analysis;scheduling_analysis,solver,Cuda,https://github.com/yalue/cuda_scheduling_examiner_mirror,,NOASSERTION,cuda;gpu;scheduling;performance-analysis;hpc
482,HPC-NOW,Cross-platform multi-cloud HPC platform manager,"A command-line tool to quickly deploy and manage High-Performance Computing (HPC) clusters across multiple cloud providers or local environments, simplifying scientific computing infrastructure setup.",Infra/HPC;AI6;AI6-02,cluster_deployment;resource_management,platform,C,https://github.com/zhenrong-wang/hpc-now,https://hpc-now.readthedocs.io,MIT,hpc;cloud-computing;cluster-management;infrastructure
483,Spline,Data lineage tracking and visualization solution for data processing engines like Spark,"Spline is a data lineage tracking and visualization tool that captures and stores lineage information from data processing pipelines (e.g., Apache Spark), enabling reproducibility and auditing in data-intensive scientific workflows.",AI6;AI6-03,data_lineage;provenance_tracking,service,Scala,https://github.com/AbsaOSS/spline,https://absaoss.github.io/spline/,Apache-2.0,data-lineage;spark;provenance;visualization
484,Alluxio,Data orchestration platform for analytics and machine learning in hybrid cloud environments,Alluxio is a data orchestration layer that brings data closer to compute for analytics and machine learning workloads. It provides a unified file system namespace and caching to accelerate data access across heterogeneous storage systems in HPC and AI pipelines.,AI6;AI6-03,data_orchestration;caching;storage_abstraction,platform,Java,https://github.com/Alluxio/alluxio,https://www.alluxio.io/,Apache-2.0,data-orchestration;distributed-cache;hpc;machine-learning
485,Alluxio Python Client,Python client library for interacting with the Alluxio data orchestration system,"The Alluxio Python client enables Python-based data science and machine learning applications to interact with the Alluxio file system, facilitating efficient data access and management within Python workflows.",AI6;AI6-03,data_access;client_library,library,Python,https://github.com/Alluxio/alluxio-py,https://docs.alluxio.io/os/user/stable/en/api/Python-API.html,Apache-2.0,python;alluxio;client;data-access
486,FedHeteroBench,Benchmark framework for handling data heterogeneity in federated learning,FedHeteroBench is a repository and framework designed to evaluate and handle data heterogeneity in federated learning (Non-IID settings). It provides unified implementations and reproducible experiments for researching federated learning algorithms.,AI6;AI6-03,federated_learning;benchmarking;reproducibility,library,Python,https://github.com/AntonioZC666/FedHeteroBench,,MIT,federated-learning;benchmark;non-iid;heterogeneity
487,Deep AutoViML,AutoML library for building TensorFlow Keras model pipelines with MLflow tracking,Deep AutoViML is an automated machine learning library that simplifies the process of building deep learning models using TensorFlow and Keras. It includes built-in integration with MLflow for experiment tracking and reproducibility.,AI6;AI6-03,automl;model_training;experiment_tracking,library,Python,https://github.com/AutoViML/deep_autoviml,,Apache-2.0,automl;tensorflow;keras;mlflow;deep-learning
488,RD-CDM,Ontology-based common data model for rare diseases,"RD-CDM (Rare Disease Common Data Model) is an ontology-based framework for harmonizing international registries, FHIR, and Phenopackets, facilitating data interoperability and standardization in rare disease research.",AI6;AI6-03,data_modeling;ontology_alignment;data_harmonization,dataset,Python,https://github.com/BIH-CEI/rd-cdm,,MIT,rare-disease;common-data-model;ontology;fhir
489,Lite Tracer,Lightweight experiment reproducibility toolset for ML,Lite Tracer is a lightweight toolset designed to facilitate experiment reproducibility in machine learning by tracking and managing experiment configurations and artifacts.,AI6;AI6-03,experiment_tracking;reproducibility,library,Python,https://github.com/BorealisAI/lite_tracer,,NOASSERTION,reproducibility;experiment-tracking;ml-ops
490,HPC DME APIs,APIs for NCI High Performance Computing Data Management Services,"This repository contains the Common APIs for the National Cancer Institute (NCI) High Performance Computing (HPC) Data Management Services (DME), enabling researchers to programmatically interact with scientific data archives.",AI6;AI6-03,data_management;archive_access;hpc_api,library,JavaScript,https://github.com/CBIIT/HPC_DME_APIs,,NOASSERTION,nci;hpc;data-management;api
491,Scratch Manager,Daemon for automating dataset caching in HPC environments,"Scratch Manager is a daemon designed to automate the caching of read-only datasets between slow (archive) and fast (scratch) storage locations, optimizing data access for HPC workloads.",AI6;AI6-03,caching;storage_management;hpc_io,service,Python,https://github.com/CEA-LIST/scratch_manager,,NOASSERTION,hpc;caching;storage-tiering;dataset-management
492,Stochastic Caching,Library for stochastic dataset caching in PyTorch,"A lightweight library for implementing stochastic caching strategies for datasets in PyTorch, helping to optimize data loading performance in machine learning training pipelines.",AI6;AI6-03,caching;data_loading;optimization,library,Python,https://github.com/Charl-AI/stochastic-caching,,MIT,pytorch;caching;data-loading;optimization
493,Oceananigans.jl,Fast and flexible fluid dynamics software for ocean modeling on CPUs and GPUs,"Oceananigans.jl is a Julia software package for fluid dynamics simulations, specifically tailored for oceanography and atmospheric science. It supports fast execution on CPUs and GPUs and provides a user-friendly interface for setting up complex simulations.",AI6;AI6-03,fluid_dynamics;ocean_modeling;simulation,solver,Julia,https://github.com/CliMA/Oceananigans.jl,https://clima.github.io/Oceananigans.jl/stable/,MIT,fluid-dynamics;oceanography;julia;gpu-acceleration
494,DagsHub Client,Client library for DagsHub data versioning and collaboration platform,"The DagsHub client library allows users to interact with the DagsHub platform, facilitating data versioning, experiment tracking, and collaboration for machine learning projects using Git and DVC.",AI6;AI6-03,data_versioning;collaboration;experiment_tracking,library,Python,https://github.com/DagsHub/client,https://dagshub.com/docs/,MIT,data-versioning;mlops;dagshub;client
495,Fast Data Science (fds),CLI tool wrapping Git and DVC for simplified data and code version control,"Fast Data Science (fds) is a command-line interface that simplifies the usage of Git and DVC (Data Version Control) for data scientists, streamlining the process of versioning both code and large datasets.",AI6;AI6-03,data_versioning;version_control;cli,tool,Python,https://github.com/DagsHub/fds,,MIT,dvc;git;data-versioning;cli
496,GeoMet Data Registry,Registry system for managing access to meteorological open data via OGC standards,"A system to manage access to the Environment and Climate Change Canada's Meteorological Service of Canada (MSC) open data, including raw numerical weather prediction (NWP) model data layers and weather radar mosaics, via Open Geospatial Consortium (OGC) standards.",AI6;AI6-03,data_management;data_access;meteorology,service,Python,https://github.com/ECCC-MSC/geomet-data-registry,,NOASSERTION,meteorology;ogc;data-registry;weather-data
497,FastTrackML,High-performance experiment tracking server compatible with MLflow,"An experiment tracking server focused on speed and scalability, designed to be a drop-in replacement for the MLflow tracking server, facilitating reproducible machine learning experiments.",AI6;AI6-03,experiment_tracking;reproducibility;artifact_management,service,Go,https://github.com/G-Research/fasttrackml,,Apache-2.0,mlflow;experiment-tracking;reproducibility;mlops
498,kedro-mlflow,Kedro plugin for MLflow integration enabling experiment tracking and model versioning,"A plugin for the Kedro framework that integrates MLflow capabilities, specifically focusing on machine learning model versioning, packaging, and experiment tracking within data pipelines.",AI6;AI6-03,experiment_tracking;model_versioning;pipeline_management,library,Python,https://github.com/Galileo-Galilei/kedro-mlflow,https://kedro-mlflow.readthedocs.io/,Apache-2.0,kedro;mlflow;pipeline;versioning
499,GiraffeTools,Graphical interface for reproducible analysis of workflow experiments,"A graphical interface designed to facilitate the reproducible analysis of workflow experiments, likely in a bioinformatics or scientific computing context, enabling users to manage and visualize analysis processes.",AI6;AI6-03,workflow_management;reproducibility;analysis_visualization,platform,JavaScript,https://github.com/GiraffeTools/GiraffeTools,,GPL-3.0,workflow;reproducibility;gui;scientific-analysis
500,jzfs,"Git-based version control file system for code, data, and models","A Git-based Version Control File System designed for the joint management of code, data, and models, facilitating reproducibility and artifact management in AI and scientific workflows.",AI6;AI6-03,data_versioning;artifact_management;reproducibility,system,TypeScript,https://github.com/GitDataAI/jzfs,,MIT,data-versioning;filesystem;git;model-management
501,CMF,Common Metadata Framework for tracking ML pipeline lineage and artifacts,"A library to collect and store information associated with ML pipelines, tracking lineages for artifacts and executions of distributed AI pipelines to ensure reproducibility and metadata management.",AI6;AI6-03,metadata_tracking;lineage_tracking;artifact_management,library,Python,https://github.com/HewlettPackard/cmf,,Apache-2.0,metadata;lineage;ml-pipeline;reproducibility
502,Sacred,"Tool to configure, organize, log, and reproduce computational experiments","A tool to help researchers configure, organize, log, and reproduce experiments, managing configuration injection and database logging of experiment runs.",AI6;AI6-03,experiment_tracking;reproducibility;configuration_management,library,Python,https://github.com/IDSIA/sacred,https://sacred.readthedocs.io/,MIT,experiment-tracking;reproducibility;machine-learning;logging
503,pycellin,Graph-based framework for analyzing cell lineages from tracking data,"A graph-based framework to manipulate and analyze cell lineages derived from cell tracking data, facilitating the study of cellular dynamics and genealogy.",AI6;AI6-03,cell_lineage_analysis;graph_analysis;biological_image_analysis,library,Jupyter Notebook,https://github.com/Image-Analysis-Hub/pycellin,,BSD-3-Clause,cell-lineage;bioinformatics;graph-theory;tracking
504,ArtiVC,Version control system for large files in data science projects,"A version control system designed to manage large files, similar to DVC, enabling data versioning and artifact management within scientific and AI workflows.",AI6;AI6-03,data_versioning;artifact_management;large_file_storage,solver,Go,https://github.com/InfuseAI/ArtiVC,https://artivc.io/,Apache-2.0,data-versioning;version-control;large-files;reproducibility
505,PositionBasedDynamics,"Library for physically-based simulation of rigid bodies, deformable solids, and fluids","A library implementing Position Based Dynamics (PBD) for the physically-based simulation of rigid bodies, deformable solids, and fluids, widely used in computer graphics and scientific simulation.",AI6,physics_simulation;fluid_dynamics;solid_mechanics,library,C++,https://github.com/InteractiveComputerGraphics/PositionBasedDynamics,https://interactivecomputergraphics.github.io/PositionBasedDynamics/,MIT,physics-simulation;pbd;fluid-dynamics;deformable-solids
506,SPlisHSPlasH,Open-source library for physically-based simulation of fluids,"An open-source library focused on the physically-based simulation of fluids, implementing various SPH (Smoothed Particle Hydrodynamics) methods for scientific modeling.",AI6,fluid_dynamics;sph_simulation;physics_modeling,library,C++,https://github.com/InteractiveComputerGraphics/SPlisHSPlasH,https://interactivecomputergraphics.github.io/SPlisHSPlasH/,MIT,fluid-simulation;sph;physics;cfd
507,MLJModels.jl,Model registry and loader for the MLJ machine learning framework,"The model registry and tools for model queries and code loading for MLJ, a machine learning framework in Julia, facilitating model management and reproducibility.",AI6;AI6-03,model_registry;model_management;machine_learning,library,Julia,https://github.com/JuliaAI/MLJModels.jl,,MIT,julia;machine-learning;model-registry;mlj
508,trixi,Modular experiment infrastructure optimized for PyTorch reproducibility,"A tool to manage machine learning experiments, ensuring reproducibility and modularity. It provides an experiment infrastructure optimized for PyTorch but flexible enough for other frameworks, facilitating artifact management and logging.",AI6;AI6-03,experiment_tracking;reproducibility;artifact_management,library,Python,https://github.com/MIC-DKFZ/trixi,,MIT,pytorch;experiment-management;reproducibility
509,ML4ITS-synthetic-data,GAN-based synthetic time-series generation system,"A functional end-to-end system for generating synthetic time-series data using generative adversarial networks (GANs). It includes modules for dataset generation, model registry, and an interface for evaluation, specifically targeted at Intelligent Transportation Systems (ITS) research.",AI4;AI6-03,data_generation;model_registry,workflow,Jupyter Notebook,https://github.com/ML4ITS/synthetic-data,,None,gan;synthetic-data;time-series
510,smilelogging,Python logging package for reproducible research experiments,A Python logging package designed to facilitate easy and reproducible experimenting in research. It helps in tracking experiment logs and configurations to ensure scientific reproducibility.,AI6;AI6-03,experiment_logging;reproducibility,library,Python,https://github.com/MingSun-Tse/smilelogging,,None,logging;reproducibility;research-tools
511,PipelineX,ML pipeline builder for experimentation with Kedro and MLflow,"A Python package to build machine learning pipelines for experimentation, integrating with Kedro and MLflow. It focuses on simplifying the ML lifecycle management and experiment tracking.",AI6;AI6-03,pipeline_orchestration;experiment_tracking,library,Python,https://github.com/Minyus/pipelinex,,NOASSERTION,ml-pipeline;kedro;mlflow;experimentation
512,CoolGraph,Graph Neural Network (GNN) library,"A library designed to make Graph Neural Networks (GNNs) easy to start with. GNNs are widely used in scientific modeling (e.g., molecular structures, physics simulations).",AI3;AI6,graph_learning;modeling,library,Jupyter Notebook,https://github.com/MobileTeleSystems/CoolGraph,,MIT,gnn;graph-neural-networks;deep-learning
513,Oxen,High-performance data version control system for ML datasets,"A lightning-fast data version control system designed for structured and unstructured machine learning datasets. It aims to make versioning datasets as easy as versioning code, serving as a faster alternative to DVC for large scientific artifacts.",AI6;AI6-03,data_versioning;artifact_management,platform,Rust,https://github.com/Oxen-AI/Oxen,https://oxen.ai,Apache-2.0,data-version-control;machine-learning;dvc-alternative;rust
514,Pachyderm Acoustic (Grasshopper),Acoustical simulation extension for Grasshopper,"The Grasshopper extension for Pachyderm Acoustic, enabling acoustical simulation and analysis within the Grasshopper parametric modeling environment. Used for scientific modeling of sound propagation.",AI6;Physics,acoustic_simulation;modeling,solver,C#,https://github.com/PachydermAcoustic/PachydermAcoustic_Grasshopper,,None,acoustics;simulation;grasshopper;parametric-modeling
515,Pachyderm Acoustic (Rhino),Acoustical simulation plugin for Rhinoceros,A popular acoustical simulation plugin for Rhinoceros 3D. It performs scientific simulation of room acoustics and sound analysis.,AI6;Physics,acoustic_simulation;modeling,solver,C#,https://github.com/PachydermAcoustic/PachydermAcoustic_Rhinoceros,,NOASSERTION,acoustics;simulation;rhinoceros
516,WebGL-Fluid-Simulation,Real-time fluid dynamics simulation solver in browser,"A WebGL-based implementation of fluid dynamics simulation (Navier-Stokes equations). While often used for visualization, it is a functional physics solver for fluid behavior.",AI6;Physics,fluid_simulation;visualization,solver,JavaScript,https://github.com/PavelDoGreat/WebGL-Fluid-Simulation,,MIT,cfd;fluid-dynamics;webgl;simulation
517,RL Reach,Platform for reproducible reinforcement learning experiments,"A platform designed for running reproducible reinforcement learning (RL) experiments, specifically focusing on reaching tasks in robotics/simulation environments.",AI6;AI6-03,reinforcement_learning;reproducibility,platform,Python,https://github.com/PierreExeter/rl_reach,,None,reinforcement-learning;reproducibility;robotics
518,FluidX3D,High-performance lattice Boltzmann CFD software,"A highly optimized Computational Fluid Dynamics (CFD) software based on the Lattice Boltzmann Method (LBM). It runs on GPUs and CPUs via OpenCL, designed for high-performance scientific simulation.",AI6;Physics,cfd_simulation;fluid_dynamics,solver,C++,https://github.com/ProjectPhysX/FluidX3D,,NOASSERTION,cfd;lattice-boltzmann;opencl;hpc
519,ReproZip,Tool for packing and reproducing experiments by tracing system calls,"ReproZip is a tool aimed at simplifying the process of creating reproducible experiments from command-line executions. It tracks operating system calls to identify and package all necessary files and dependencies, allowing the experiment to be replayed on different environments.",AI6;AI6-03,reproducibility;experiment_packing;provenance_tracking,workflow,Python,https://github.com/VIDA-NYU/reprozip,https://www.reprozip.org/,BSD-3-Clause,reproducibility;provenance;experiment-management
520,SoptSC,Single-cell RNA-seq data analysis tool for clustering and lineage inference,"SoptSC is a MATLAB-based tool for single-cell data analysis. It performs unsupervised inference of clustering, cell lineage, pseudotime, and cell-cell communication networks from scRNA-seq data using similarity matrix optimization.",AI4;AI4-06,clustering;lineage_inference;scrna_seq_analysis,solver,MATLAB,https://github.com/WangShuxiong/SoptSC,,MIT,single-cell;rna-seq;clustering;lineage-inference
521,WaterLily.jl,Fast and simple fluid simulator for solving Navier-Stokes equations,"WaterLily.jl is a Julia library for solving the incompressible Navier-Stokes equations on Cartesian grids. It is designed to be fast, simple, and backend-agnostic, suitable for fluid dynamics simulations.",AI6;AI4,fluid_simulation;cfd;navier_stokes,library,Julia,https://github.com/WaterLily-jl/WaterLily.jl,https://waterlily-jl.github.io/WaterLily.jl/dev/,NOASSERTION,fluid-dynamics;cfd;julia;simulation
522,Geochemistrypi,Automated machine learning framework for geochemistry data analysis,"Geochemistryπ is an open-sourced, highly automated machine learning Python framework designed specifically for data-driven geochemistry discovery. It simplifies the application of ML techniques to geochemical datasets.",AI4;AI4-01,geochemistry_analysis;data_mining;automated_ml,platform,Python,https://github.com/ZJUEarthData/Geochemistrypi,https://geochemistrypi.readthedocs.io/,MIT,geochemistry;machine-learning;earth-science;automl
523,Aim,An easy-to-use & supercharged open-source experiment tracker,"Aim is an open-source experiment tracking tool that logs AI metadata (hyperparameters, metrics, images, etc.) and provides a UI for comparison and visualization, facilitating reproducible research.",AI6;AI6-03,experiment_tracking;visualization,platform,Python,https://github.com/aimhubio/aim,https://aimstack.io/,Apache-2.0,experiment-tracking;mlops;visualization
524,AimLflow,Aim-MLflow integration for syncing experiments,"A tool that synchronizes MLflow runs with Aim, allowing users to leverage Aim's visualization and tracking capabilities on top of existing MLflow setups.",AI6;AI6-03,experiment_tracking;artifact_sync,library,Python,https://github.com/aimhubio/aimlflow,,Apache-2.0,mlflow;integration;experiment-tracking
525,FeatHub,Stream-batch unified feature store for real-time machine learning,"FeatHub is a feature store that simplifies feature engineering and management for machine learning, supporting both streaming and batch data processing with point-in-time correctness.",AI6;AI6-03,feature_store;data_versioning,platform,Python,https://github.com/alibaba/feathub,https://github.com/alibaba/feathub,Apache-2.0,feature-store;flink;machine-learning
526,MLflow Export-Import,"Tools to export and import MLflow experiments, runs, or models","A set of utilities to migrate MLflow objects (experiments, runs, registered models) between different MLflow tracking servers or for backup purposes.",AI6;AI6-03,artifact_management;migration,solver,Python,https://github.com/amesar/mlflow-export-import,,Apache-2.0,mlflow;migration;backup
527,Hamilton,Modular dataflow definition with lineage and metadata tracking,"Apache Hamilton is a framework for defining dataflows in Python that automatically tracks lineage and metadata, facilitating reproducible feature engineering and data processing pipelines.",AI6;AI6-03,pipeline_orchestration;lineage_tracking,library,Python,https://github.com/apache/hamilton,https://hamilton.dagworks.io/,Apache-2.0,dataflow;lineage;feature-engineering
528,AIOps Modules,Reusable IaC modules for ML and GenAI infrastructure on AWS,A collection of Infrastructure as Code (IaC) modules designed to accelerate the deployment and operation of Machine Learning and Generative AI workloads on AWS.,AI6;AI6-01,infrastructure_provisioning;mlops_deployment,library,Python,https://github.com/awslabs/aiops-modules,,Apache-2.0,iac;aws;mlops
529,Data on EKS,"Tool to build, deploy and scale Data Platforms on Amazon EKS","Data on EKS (DoEKS) provides blueprints and tools to deploy scalable data and machine learning platforms (like Spark, Ray, Kubeflow) on Amazon EKS, optimizing for performance and cost.",AI6;AI6-01,platform_engineering;cluster_management,platform,HCL,https://github.com/awslabs/data-on-eks,https://awslabs.github.io/data-on-eks/,Apache-2.0,kubernetes;eks;data-platform
530,Cloud Detection Model for Sentinel-2,Deep learning model for cloud detection in Sentinel-2 satellite imagery,"A semantic segmentation model based on U-Net/ResNet architectures specifically trained to detect clouds in Sentinel-2 satellite imagery, facilitating preprocessing for remote sensing and earth science analysis.",AI4-Earth;AI6,cloud_detection;image_segmentation;preprocessing,solver,Python,https://github.com/azavea/cloud-model,https://github.com/azavea/cloud-model,MIT,remote-sensing;sentinel-2;cloud-masking;earth-science
531,InfiniStore,High-performance KV cache store for distributed LLM inference,"A scalable key-value storage system designed specifically for managing KV caches in distributed Large Language Model (LLM) inference, optimizing memory usage and access latency for AI workloads.",AI6;AI6-03,kv_caching;inference_acceleration;memory_management,service,C++,https://github.com/bytedance/InfiniStore,,Apache-2.0,llm;kv-cache;distributed-systems;inference
532,Calkit,Lightweight research project management and reproducibility tool,"A command-line tool designed for researchers to manage project environments, version control data and code, and execute reproducible pipelines, simplifying the complexity of Git and DVC for scientific workflows.",AI6;AI6-03,reproducibility;data_versioning;environment_management,workflow,Python,https://github.com/calkit/calkit,https://calkit.readthedocs.io,MIT,reproducibility;git;research-management;pipeline
533,PARSEC Benchmark,Benchmark suite for shared-memory parallel systems,"A ported and maintained version of the PARSEC Benchmark suite, widely used in High Performance Computing (HPC) research to evaluate the performance of shared-memory parallel systems using diverse workloads.",AI6,benchmarking;performance_evaluation;hpc_analysis,solver,C,https://github.com/cirosantilli/parsec-benchmark,http://parsec.cs.princeton.edu,NOASSERTION,hpc;benchmark;parallel-computing
534,ClearML,Integrated MLOps platform for experiment tracking and orchestration,"A comprehensive open-source MLOps platform that provides tools for experiment management, data versioning, and pipeline orchestration, widely used in AI research to ensure reproducibility and manage scientific machine learning workflows.",AI6;AI6-03;AI6-01,experiment_tracking;artifact_management;pipeline_orchestration,platform,Python,https://github.com/clearml/clearml,https://clear.ml/docs,Apache-2.0,mlops;experiment-tracking;reproducibility;data-management
535,ClearML Server,Backend server for the ClearML MLOps platform,"The backend infrastructure for ClearML, handling data persistence, API requests, and coordination for experiment tracking and orchestration services.",AI6;AI6-03,experiment_tracking_backend;service_orchestration,service,Python,https://github.com/clearml/clearml-server,https://clear.ml/docs,NOASSERTION,mlops;backend;server
536,OMLMD,OCI Artifact specification and tool for ML models,"A tool and specification for packaging Machine Learning models and their metadata as OCI (Open Container Initiative) artifacts, facilitating the distribution and management of ML assets in container registries.",AI6;AI6-03,model_packaging;artifact_management;metadata_handling,library,Python,https://github.com/containers/omlmd,,Apache-2.0,oci;ml-models;containers;artifact-management
537,git-rdm,Research data management plugin for Git to track data provenance and publication,"A plugin for the Git version control system designed to facilitate research data management (RDM). It allows researchers to curate, version control, and share their research data alongside their code, bridging the gap between version control and data repositories.",AI6;AI6-03,data_versioning;artifact_management;reproducibility,solver,Python,https://github.com/ctjacobs/git-rdm,,MIT,git;research-data-management;reproducibility;provenance
538,DataTracer,Data lineage tracing library for data science workflows,"A library designed to trace data lineage and provenance in data science and machine learning workflows. It helps in understanding the origin and transformation of data, which is critical for reproducibility in scientific data processing.",AI6;AI6-03,data_provenance;lineage_tracing;reproducibility,library,Python,https://github.com/data-dev/DataTracer,,MIT,data-lineage;provenance;data-science;reproducibility
539,RaceID3_StemID2_package,Algorithm for cell type and lineage inference from single-cell RNA-seq data,An R package implementing the RaceID3 and StemID2 algorithms. It is used for the identification of rare cell types and the inference of lineage trees and differentiation trajectories from single-cell RNA-sequencing data.,Life Sciences;Bioinformatics,cell_type_inference;lineage_inference;single_cell_analysis,library,R,https://github.com/dgrun/RaceID3_StemID2_package,,None,scrna-seq;lineage-inference;cell-type-identification;bioinformatics
540,StemID,Algorithm for lineage tree inference from single-cell data,An algorithm for the inference of cell types and lineage trees from single-cell RNA-seq data. It focuses on identifying differentiation trajectories and stem cell populations.,Life Sciences;Bioinformatics,lineage_inference;trajectory_analysis,solver,R,https://github.com/dgrun/StemID,,None,scrna-seq;lineage-tree;differentiation;bioinformatics
541,Fluid Engine Dev,Fluid simulation engine for computer graphics and physics applications,"A C++ library for simulating fluid dynamics, often used in computer graphics but applicable to physics-based modeling. It provides solvers for grid-based and particle-based fluid simulations.",Physics;Computer_Graphics;Simulation,fluid_dynamics_simulation;physics_modeling,library,C++,https://github.com/doyubkim/fluid-engine-dev,http://doyubkim.github.io/fluid-engine-dev/,MIT,fluid-simulation;physics-engine;cfd
542,DuckDB Delta,DuckDB extension for reading and writing Delta Lake tables,"An extension for DuckDB that enables direct interaction with Delta Lake tables, facilitating data versioning and management in scientific data lakes and analytical workflows.",AI6-03;Data_Engineering,data_access;data_versioning,library,C++,https://github.com/duckdb/duckdb-delta,https://duckdb.org/docs/extensions/delta,MIT,duckdb;delta-lake;data-lake;versioning
543,paleotree,R library for analyzing and simulating phylogenies of extinct lineages,"A package for analyzing, time-scaling, and simulating phylogenies of extinct/fossil lineages, including plotting diversity curves for stratigraphic range data.",Biology;Paleontology,phylogenetic_analysis;evolutionary_modeling,library,R,https://github.com/dwbapst/paleotree,https://cran.r-project.org/web/packages/paleotree/index.html,CC0-1.0,phylogeny;fossils;evolution;time-scaling
544,Elementary,dbt-native data observability and quality monitoring solution,"An open-source data observability solution for data engineers using dbt. It provides monitoring for data pipelines, anomaly detection, and data quality reporting, ensuring the reliability of data artifacts.",AI6-03;Data_Engineering,data_quality_control;pipeline_monitoring,platform,HTML,https://github.com/elementary-data/elementary,https://docs.elementary-data.com/,Apache-2.0,data-observability;dbt;data-quality;monitoring
545,SCICHEM,Puff model with chemistry for simulating atmospheric plume transport,A version of the SCIPUFF puff model incorporating chemical transformations. It simulates the transport and chemical evolution of power plant plumes in the atmosphere.,Environmental_Science;Atmospheric_Physics,atmospheric_dispersion_modeling;chemical_transport_simulation,solver,Fortran,https://github.com/epri-dev/SCICHEM_archived,,Unknown,atmospheric-model;plume-simulation;chemistry
546,papermill-mlflow,Integration for tracking Papermill notebook executions in MLflow,"A utility that connects Papermill (parameterized notebooks) with MLflow, enabling automatic tracking of parameters, metrics, and artifacts from notebook-based experiments.",AI6-03;Data_Science,experiment_tracking;reproducibility,library,Jupyter Notebook,https://github.com/eugeneyan/papermill-mlflow,,Unknown,mlflow;papermill;experiment-tracking;jupyter
547,IEEE-118 Power Flow Data Pipeline,Data pipeline for generating IEEE-118 power system flow cases,"A data processing pipeline designed to build and structure power flow cases for the IEEE-118 bus power system, facilitating simulation and analysis in power engineering.",Power_Systems;Engineering,data_generation;power_flow_analysis,workflow,Jupyter Notebook,https://github.com/evgenytsydenov/ieee118_power_flow_data,,NOASSERTION,power-systems;ieee-118;data-pipeline
548,Expfactory,Framework for generating reproducible experiment containers,"Software to generate reproducible containers (Docker/Singularity) containing a battery of behavioral experiments, ensuring consistent runtime environments for scientific studies.",AI6;Psychology;Neuroscience,experiment_deployment;reproducibility,platform,Python,https://github.com/expfactory/expfactory,https://expfactory.github.io/,BSD-3-Clause,reproducibility;containers;behavioral-experiments
549,Data Lineage Doris,Data lineage tracking tool for Apache Doris,"A tool for parsing and tracking table and field-level lineage within Apache Doris, aiding in data provenance and impact analysis for data warehouses.",AI6-03;Data_Engineering,data_lineage;provenance_tracking,tool,Java,https://github.com/eyesmoons/data-lineage-doris,,GPL-3.0,data-lineage;apache-doris;provenance
550,dbt Feature Store,Feature store implementation using dbt macros,A lightweight feature store implementation that allows defining and managing machine learning features directly within dbt repositories using macros.,AI6-03;Machine_Learning,feature_management;feature_store,library,Python,https://github.com/fal-ai/dbt_feature_store,,Unknown,dbt;feature-store;mlops
551,Feast,Open source feature store for machine learning,"A leading open-source feature store that manages the serving of features for training and inference, ensuring consistency between offline and online environments.",AI6-03;Machine_Learning,feature_serving;feature_management,platform,Python,https://github.com/feast-dev/feast,https://feast.dev/,Apache-2.0,feature-store;mlops;feature-serving
552,Featureform,Virtual feature store for existing data infrastructure,"A virtual feature store that turns existing data infrastructure (like Spark, Redis, Snowflake) into a feature store, managing feature definitions, lineage, and serving.",AI6-03;Machine_Learning,feature_management;feature_store,platform,Go,https://github.com/featureform/featureform,https://www.featureform.com/,MPL-2.0,feature-store;mlops;virtual-feature-store
553,Featury,Machine learning feature store library,A feature store library designed to simplify feature engineering and serving for machine learning applications.,AI6-03;Machine_Learning,feature_store;feature_engineering,library,Scala,https://github.com/findify/featury,,Apache-2.0,feature-store;scala;ml
554,Fluid,Elastic data abstraction and acceleration for AI/BigData on Kubernetes,"A cloud-native data orchestration and acceleration system that abstracts data access for AI and Big Data applications, providing caching and data locality in Kubernetes environments.",AI6-03;Cloud_Native,data_orchestration;data_acceleration;caching,platform,Go,https://github.com/fluid-cloudnative/fluid,https://fluid-cloudnative.github.io/,Apache-2.0,kubernetes;data-acceleration;caching;cncf
555,Flyte Data Catalog,Service for indexing and managing parameterized data artifacts in Flyte workflows,Data Catalog is a core service within the Flyte ecosystem designed to index and manage strongly-typed data artifacts across revisions. It enables efficient caching (memoization) of task outputs and ensures reproducibility by tracking data lineage in scientific and ML workflows.,AI6;AI6-03,artifact_management;data_lineage;caching,service,Go,https://github.com/flyteorg/datacatalog,https://flyte.org,Apache-2.0,flyte;artifact-management;caching;mlops
556,alluxiofs,Fsspec implementation for Alluxio distributed caching,"Alluxiofs provides a Python filesystem interface (fsspec) for Alluxio, enabling scientific data processing tools (like Pandas, Dask, and Ray) to leverage Alluxio's distributed caching capabilities for accelerated data access.",AI6;AI6-03,data_access;caching,library,Python,https://github.com/fsspec/alluxiofs,https://github.com/fsspec/alluxiofs,Apache-2.0,fsspec;alluxio;distributed-caching;python
557,FuseML,Orchestration framework for MLOps and scientific workflows,FuseML is an MLOps framework designed to dynamically integrate various AI/ML tools. It provides a flexible orchestration layer for managing the lifecycle of machine learning models and scientific data processing pipelines.,AI6;AI6-03,workflow_orchestration;mlops,platform,Go,https://github.com/fuseml/fuseml,https://fuseml.github.io,Apache-2.0,mlops;orchestration;workflow;integration
558,git-lfs-fuse,FUSE filesystem for mounting Git LFS repositories,"Git LFS FUSE allows users to mount remote Git LFS repositories as a local filesystem. This enables instant access to large scientific models and datasets without downloading the entire repository, facilitating efficient data exploration and lazy loading.",AI6;AI6-03,data_access;dataset_management,tool,Go,https://github.com/git-lfs-fuse/git-lfs-fuse,,Apache-2.0,git-lfs;fuse;data-access;mounting
559,Git LFS,Git extension for versioning large files,"Git Large File Storage (LFS) replaces large files such as audio samples, videos, datasets, and graphics with text pointers inside Git, while storing the file contents on a remote server. It is the industry standard for versioning large scientific datasets and ML models.",AI6;AI6-03,data_versioning;artifact_management,tool,Go,https://github.com/git-lfs/git-lfs,https://git-lfs.github.com/,MIT,version-control;large-file-storage;data-versioning
560,lfs-test-server,Standalone Git LFS server implementation,"A simple, standalone implementation of the Git LFS server API. While originally designed for testing, it serves as a lightweight artifact store for hosting scientific datasets and models in self-managed environments.",AI6;AI6-03,artifact_store;data_hosting,service,Go,https://github.com/git-lfs/lfs-test-server,,MIT,git-lfs;server;artifact-store
561,FluidNet,Accelerating Eulerian Fluid Simulation With Convolutional Networks,"FluidNet is a deep learning framework for accelerating Eulerian fluid simulations. It uses Convolutional Neural Networks (ConvNets) to predict fluid dynamics, offering a data-driven approach to scientific simulation.",AI6,fluid_simulation;physics_informed_ml,solver,Lua,https://github.com/google/FluidNet,,NOASSERTION,cfd;deep-learning;fluid-simulation;physics
562,JAX-CFD,Computational Fluid Dynamics in JAX,"JAX-CFD is a library for computational fluid dynamics (CFD) written in JAX. It enables differentiable physics simulations, allowing for gradient-based optimization and integration with machine learning models for scientific research.",AI6,fluid_simulation;cfd;differentiable_physics,library,Python,https://github.com/google/jax-cfd,,Apache-2.0,jax;cfd;fluid-dynamics;simulation
563,Space,Unified storage framework for the machine learning lifecycle,"Space is a unified storage framework designed to manage data across the entire machine learning lifecycle. It provides abstractions for dataset management, versioning, and access, facilitating reproducible ML research.",AI6;AI6-03,data_storage;dataset_management,library,Python,https://github.com/google/space,,Apache-2.0,storage;ml-lifecycle;dataset-management
564,Ground,Open-source data context service for lineage and versioning,"Ground is a vendor-neutral data context service that manages the lineage, metadata, and versioning of data artifacts. It serves as a critical infrastructure component for ensuring reproducibility and traceability in scientific data workflows.",AI6;AI6-03,data_lineage;metadata_management;data_versioning,service,Java,https://github.com/ground-context/ground,http://www.ground-context.org/,Apache-2.0,data-lineage;metadata;versioning;reproducibility
565,carla_apollo_bridge,Bridge between Carla simulator and Apollo control stack,This tool provides a data and control bridge enabling communication between the Carla autonomous driving simulator and the Apollo open autonomous driving platform. It facilitates scientific research in robotics and autonomous systems by linking simulation with control logic.,AI6,simulation_bridge;robotics_simulation,tool,Python,https://github.com/guardstrikelab/carla_apollo_bridge,,Apache-2.0,carla;apollo;autonomous-driving;simulation
566,Spark Atlas Connector,Connector to track Spark data lineage in Apache Atlas for data governance,"A connector that enables tracking of data lineage and metadata from Apache Spark jobs into Apache Atlas. This is essential for scientific data governance, reproducibility, and provenance tracking in large-scale data processing pipelines.",AI6;AI6-03,data_lineage;provenance_tracking,library,Scala,https://github.com/hortonworks-spark/spark-atlas-connector,,Apache-2.0,data-lineage;spark;atlas;provenance
567,Superglue,Data lineage tracking and visualization tool for complex pipelines,"A lineage-tracking tool designed to visualize the propagation of data through complex pipelines composed of tables, jobs, and reports. It helps in understanding data dependencies and provenance, which is critical for reproducible scientific workflows.",AI6;AI6-03,data_lineage;visualization,platform,Scala,https://github.com/intuit/superglue,,Apache-2.0,lineage;data-visualization;pipeline-tracking
568,GPU-Jupyter,GPU-accelerated JupyterLab environment for reproducible deep learning,"A specialized JupyterLab environment stack pre-configured with GPU support (CUDA/cuDNN) and data science libraries (TensorFlow, PyTorch). It serves as a reproducible runtime platform for conducting deep learning experiments in scientific research.",AI6;AI6-03,reproducible_environment;interactive_computing,platform,Jupyter Notebook,https://github.com/iot-salzburg/gpu-jupyter,,Apache-2.0,jupyter;gpu;reproducibility;deep-learning
569,GTO,Git Tag Ops for artifact and model registry management,"A tool that turns a Git repository into an Artifact Registry or Model Registry using Git tags. It allows scientific teams to version, register, and manage the lifecycle of machine learning models and data artifacts directly within their version control system.",AI6;AI6-03,artifact_management;model_registry,solver,Python,https://github.com/iterative/gto,https://iterative.github.io/gto/,Apache-2.0,gitops;model-registry;artifact-management;mlops
570,pachypy,Python client library for Pachyderm data lineage and versioning,"A Python client library for Pachyderm, a data versioning and lineage platform for machine learning and scientific data processing. It simplifies the interaction with Pachyderm pipelines and data repositories.",AI6;AI6-03,data_versioning;pipeline_management,library,Python,https://github.com/itssimon/pachypy,,Apache-2.0,pachyderm;data-lineage;versioning;python-client
571,Rudolfs,High-performance caching Git LFS server,"A high-performance, caching Git LFS (Large File Storage) server with support for AWS S3 and local storage backends. It facilitates the management and efficient retrieval of large scientific artifacts (datasets, models) in version-controlled workflows.",AI6;AI6-03,artifact_storage;caching,service,Rust,https://github.com/jasonwhite/rudolfs,,MIT,git-lfs;caching;artifact-storage;rust
572,sci-pype,Machine Learning API and pipeline framework with caching,"A Machine Learning API framework featuring native Redis caching and S3 export/import capabilities. It is designed to build, train, test, and analyze entire datasets, providing a structured pipeline for scientific data analysis and reproducibility.",AI6;AI6-03,pipeline_management;caching;data_analysis,workflow,Python,https://github.com/jay-johnson/sci-pype,,Apache-2.0,pipeline;caching;machine-learning;reproducibility
573,DeltaLakeReader,Lightweight reader for Delta Lake tables without Spark,"A Python library to read Delta Lake tables directly without requiring a Spark engine. This enables lightweight access to versioned scientific datasets stored in Delta format, facilitating data analysis in non-Spark environments.",AI6;AI6-03,data_access;data_versioning,library,Python,https://github.com/jeppe742/DeltaLakeReader,,Apache-2.0,delta-lake;data-access;python
574,SharedDataset,Shared memory caching wrapper for PyTorch Datasets,"A PyTorch Dataset extension that caches samples in shared memory, making them accessible globally to all processes to reduce memory redundancy and accelerate data loading in machine learning pipelines.",AI6;AI6-03,caching;data_loading,library,Python,https://github.com/jotaf98/shareddataset,,BSD-3-Clause,pytorch;caching;shared-memory;data-loading
575,JuiceFS,Distributed POSIX file system for cloud-native AI and big data,"A distributed POSIX file system built on top of object storage (e.g., S3) and a metadata engine (e.g., Redis), widely used in AI/Science for high-performance data caching, artifact storage, and sharing across containerized environments.",AI6;AI6-03,artifact_storage;caching;distributed_storage,platform,Go,https://github.com/juicedata/juicefs,https://juicefs.com/docs/,Apache-2.0,distributed-filesystem;posix;caching;cloud-native;storage
576,K3ai,Lightweight AI infrastructure stack deployer,"A tool designed to rapidly deploy and configure AI infrastructure stacks (including Kubernetes and AI tools) for experimentation and development, facilitating reproducible runtime environments for scientific AI workflows.",AI6;AI6-03,infrastructure_deployment;environment_setup,tool,Go,https://github.com/k3ai/k3ai,https://docs.k3ai.in,BSD-3-Clause,mlops;kubernetes;infrastructure;deployment
577,Karamel,Orchestration tool for reproducible distributed experiments,"A tool for defining, provisioning, and deploying distributed systems and experiments on cloud infrastructure, ensuring reproducibility of runtime environments for data-intensive research.",AI6;AI6-03,experiment_orchestration;reproducibility,tool,Java,https://github.com/karamelchef/karamel,http://www.karamel.io,Apache-2.0,distributed-systems;reproducibility;orchestration;cloud
578,Klever Model Registry,Cloud-native machine learning model registry,"A cloud-native registry for managing machine learning models, providing versioning, storage, and metadata management for ML artifacts in scientific workflows.",AI6;AI6-03,model_management;artifact_versioning,service,Go,https://github.com/kleveross/klever-model-registry,,Apache-2.0,model-registry;mlops;artifact-management;cloud-native
579,ORMB,OCI-based artifact manager for ML/DL models,"A tool that manages machine learning and deep learning models as OCI (Open Container Initiative) artifacts, enabling versioning, distribution, and deployment of models similar to Docker images.",AI6;AI6-03,artifact_management;model_distribution;versioning,tool,Go,https://github.com/kleveross/ormb,https://ormb.io,Apache-2.0,oci-artifacts;model-management;mlops;docker
580,Kart,Distributed version control for geospatial and tabular data,"A distributed version control system specifically designed for geospatial and tabular datasets, enabling collaboration, history tracking, and branching for scientific data similar to Git for code.",AI6;AI6-03,data_versioning;geospatial_data_management,tool,Python,https://github.com/koordinates/kart,https://kartproject.org,NOASSERTION,data-versioning;geospatial;gis;version-control
581,Kubeflow Model Registry,Centralized management for ML models and artifacts,"A core component of the Kubeflow ecosystem that provides a centralized registry for indexing, versioning, and managing metadata of machine learning models and artifacts, facilitating collaboration in MLOps lifecycles.",AI6;AI6-03,model_registry;artifact_management;metadata_tracking,service,Go,https://github.com/kubeflow/model-registry,https://github.com/kubeflow/model-registry,Apache-2.0,kubeflow;model-registry;mlops;artifact-management
582,Mooncake,LLM serving platform with optimized KV caching,"A serving platform designed for Large Language Models (LLMs), featuring optimized KV cache management and scheduling to accelerate inference and improve throughput for AI science applications.",AI6;AI6-03,inference_acceleration;kv_caching;llm_serving,platform,C++,https://github.com/kvcache-ai/Mooncake,,Apache-2.0,llm;serving;kv-cache;inference
583,LaminDB,Data framework for biology with lineage and artifact tracking,"A data framework specifically designed for biology, providing capabilities for data querying, lineage tracking, reproducibility, and artifact management (lakehouse, feature store) to ensure FAIR data principles.",AI6;AI6-03,data_management;lineage_tracking;reproducibility;biology_data,framework,Python,https://github.com/laminlabs/lamindb,https://lamin.ai/docs/lamindb/,Apache-2.0,biology;data-lineage;reproducibility;feature-store
584,llm-d-kv-cache,Distributed KV cache coordinator for LLMs,"A distributed coordinator for managing Key-Value (KV) caches in Large Language Model (LLM) inference, enabling efficient cache sharing and management across distributed runtime environments.",AI6;AI6-03,kv_caching;inference_optimization;distributed_coordination,tool,Go,https://github.com/llm-d/llm-d-kv-cache,,Apache-2.0,llm;kv-cache;distributed-systems;inference
585,Hopsworks,Data-intensive AI platform with a Feature Store for managing ML artifacts,"Hopsworks is an open-source platform for developing and operating machine learning models at scale. It includes a Feature Store for managing features, a Model Registry for model versioning, and support for distributed training, directly addressing artifact management in scientific ML workflows.",AI6;AI6-03,artifact_management;feature_store;mlops,platform,Java,https://github.com/logicalclocks/hopsworks,https://www.hopsworks.ai/,AGPL-3.0,feature-store;mlops;model-registry
586,git-lfs-s3-server,"Git LFS server implementation using S3, developed for astronomical data management","A deployable Git LFS server that uses AWS S3 as the storage backend. Developed by the LSST (Legacy Survey of Space and Time) Data Management team, it is designed to handle large scientific artifacts and data files within a version-controlled environment.",AI6;AI6-03,artifact_management;data_versioning,service,Ruby,https://github.com/lsst-sqre/git-lfs-s3-server,,MIT,git-lfs;s3;astronomy;artifact-storage
587,marimo,Reactive Python notebook for reproducible scientific experiments,"A reactive notebook for Python that stores notebooks as pure Python scripts, enabling better version control and reproducibility for scientific experiments. It supports executing as a script, deploying as an app, and integrates with data analysis workflows.",AI6;AI6-01,reproducible_runtime;scientific_visualization,platform,Python,https://github.com/marimo-team/marimo,https://marimo.io,Apache-2.0,notebook;reproducibility;python;data-science
588,spark-sql-flow-plugin,Spark SQL plugin for visualizing column-level data lineage,A plugin for Apache Spark that extracts and visualizes column-level data lineage from Spark SQL queries. This is essential for tracking data provenance and transformations in large-scale scientific data processing pipelines.,AI6;AI6-03,data_lineage;provenance_tracking,library,Scala,https://github.com/maropu/spark-sql-flow-plugin,,Apache-2.0,spark;data-lineage;visualization;provenance
589,SingleCellLineage,Pipelines for processing GESTALT single-cell lineage tracing data,Scripts and pipelines for processing GESTALT (Genome Editing of Synthetic Target Arrays for Lineage Tracing) data at single-cell resolution. It facilitates the reconstruction of cell lineage trees in developmental biology research.,AI6;AI6-03,lineage_inference;bioinformatics;single_cell_analysis,workflow,Scala,https://github.com/mckennalab/SingleCellLineage,,None,single-cell;lineage-tracing;gestalt;bioinformatics
590,OpenTTDLab,Framework for running reproducible experiments using OpenTTD simulation,"A Python framework designed to run reproducible experiments using the OpenTTD game engine. It allows researchers (likely in RL or complex systems) to automate simulations, manage seeds, and collect data in a consistent manner.",AI6;AI6-01,simulation;reproducible_experiments;reinforcement_learning,workflow,Python,https://github.com/michalc/OpenTTDLab,,GPL-2.0,simulation;reproducibility;openttd;experimentation
591,DataLineage,Tool for extracting and visualizing data lineage from Spark and PowerBI,"A tool developed to extract data lineage information from Spark components and PowerBI/AAS and visualize it (e.g., in Azure Purview). It supports the management of data provenance in analytical workflows.",AI6;AI6-03,data_lineage;provenance_tracking,tool,Python,https://github.com/microsoft/DataLineage,,MIT,data-lineage;spark;azure;provenance
592,lst-bench,"Benchmark framework for Log-Structured Tables (Delta Lake, Hudi, Iceberg)","A framework for benchmarking Log-Structured Tables (LSTs) such as Delta Lake, Apache Hudi, and Apache Iceberg. It helps data engineers and scientists evaluate the performance of artifact stores used in data lakehouse architectures.",AI6;AI6-03,benchmarking;artifact_management;data_storage,tool,Java,https://github.com/microsoft/lst-bench,,Apache-2.0,benchmark;delta-lake;hudi;iceberg;data-lake
593,RSoptSC,Cell-cell communication and lineage inference for scRNA-seq data,An R package for inferring cell-cell communication networks and reconstructing cell lineage trajectories from single-cell RNA sequencing (scRNA-seq) data. It uses optimization techniques to model cellular interactions and developmental paths.,AI6;AI6-03,lineage_inference;bioinformatics;scRNA-seq,solver,R,https://github.com/mkarikom/RSoptSC,,NOASSERTION,bioinformatics;single-cell;lineage;inference
594,MLflow,Open source platform for the machine learning lifecycle,"A platform to streamline machine learning development, including tracking experiments, packaging code into reproducible runs, and sharing and deploying models. It provides a central registry for model management.",AI6;AI6-03,artifact_management;model_registry;experiment_tracking,platform,Python,https://github.com/mlflow/mlflow,https://mlflow.org/,Apache-2.0,mlops;experiment-tracking;model-registry
595,MCP Registry,Registry service for Model Context Protocol (MCP) servers,"A community-driven registry service designed to manage and discover Model Context Protocol (MCP) servers, facilitating the connection between AI models and data contexts.",AI6;AI6-03,artifact_management;service_registry,service,Go,https://github.com/modelcontextprotocol/registry,,MIT,mcp;registry;llm-infrastructure
596,CellTagR,R package for clone calling and lineage reconstruction,A computational tool for analyzing CellTag data to support clone calling and lineage reconstruction in single-cell biology experiments.,Bioinformatics,lineage_reconstruction;clone_calling,library,R,https://github.com/morris-lab/CellTagR,,None,single-cell;lineage-tracing;r-package
597,Jodie,Delta Lake and filesystem helper methods for Scala,"A utility library providing helper methods for managing Delta Lake tables and filesystem operations, facilitating data versioning and management in data science workflows.",AI6;AI6-03,data_management;data_versioning,library,Scala,https://github.com/mrpowers-io/jodie,,MIT,delta-lake;scala;data-engineering
598,Levi,Delta Lake helper methods for Python,"A Python library offering utility functions for interacting with Delta Lake, enabling efficient data management and versioning without a direct Spark dependency.",AI6;AI6-03,data_management;data_versioning,library,Python,https://github.com/mrpowers-io/levi,,MIT,delta-lake;python;data-management
599,Horcrux,Version controlled access to data for Docker containers,"A tool that provides on-demand, version-controlled access to data volumes for Docker containers, facilitating reproducible data environments for containerized applications.",AI6;AI6-03,data_versioning;container_storage,infrastructure,Go,https://github.com/muthu-r/horcrux,,BSD-3-Clause,docker;data-versioning;storage
600,Fast-LangGraph,High-performance Rust accelerators for LangGraph applications,"A library providing Rust-based accelerators for LangGraph, optimizing checkpoint operations and state management for LLM agent workflows.",AI6;AI6-03,state_management;artifact_acceleration,library,Python,https://github.com/neul-labs/fast-langgraph,,MIT,langgraph;rust;optimization
601,Reskit,Library for reproducible pipelines in scientific machine learning,"A Python library designed to assist in creating and curating reproducible machine learning pipelines, specifically targeting scientific and industrial applications.",AI6;AI6-03,pipeline_management;reproducibility,library,Jupyter Notebook,https://github.com/neuro-ml/reskit,,BSD-3-Clause,scientific-ml;reproducibility;pipelines
602,ONNX Registry,Web service for managing ONNX models,"An intelligent component registry web service for storing, managing, and retrieving SNN, DNN, and ML models in the ONNX format.",AI6;AI6-03,model_registry;artifact_management,service,Python,https://github.com/neurom-iot/onnx-registry,,MIT,onnx;model-registry;mlops
603,Kapsule,Tool for packaging LLM models into OCI images,"A utility for packaging Large Language Models (LLMs) into encrypted OCI (Open Container Initiative) images, enabling secure distribution via standard container registries.",AI6;AI6-03,artifact_packaging;model_distribution,tool,Go,https://github.com/nicholasjackson/kapsule,,None,llm;oci;packaging
604,Shelf,"Type-aware, fsspec-based artifact store client",A Python client for general artifact storage that leverages fsspec to provide a type-aware interface for managing data and model artifacts across various storage backends.,AI6;AI6-03,artifact_management;storage_client,library,Python,https://github.com/nicholasjng/shelf,,Apache-2.0,fsspec;artifact-store;python
605,lfs-s3,Git LFS custom transfer agent for S3,A custom transfer agent for Git LFS (Large File Storage) that enables using Amazon S3 (or compatible providers) as the storage backend for versioning large scientific datasets and models.,AI6;AI6-03,data_versioning;storage_backend,tool,Go,https://github.com/nicolas-graves/lfs-s3,,MIT,git-lfs;s3;data-versioning
606,Trustix,Distributed trust and reproducibility tracking for binary caches,"A tool for tracking reproducibility and establishing distributed trust for binary caches, particularly within the Nix ecosystem, ensuring artifact integrity in scientific computing workflows.",AI6;AI6-03,reproducibility;artifact_verification,infrastructure,Go,https://github.com/nix-community/trustix,,None,nix;reproducibility;binary-cache
607,OpenHPC Scale-up Automation,Automation scripts for scaling OpenHPC clusters,A set of tools and scripts to automate the process of scaling up OpenHPC clusters by leveraging IPMI and Redfish for hardware management and node discovery.,AI6,cluster_management;hpc_automation,workflow,Python,https://github.com/nsfcac/Automating-the-scale-up-process-in-OpenHPC,,None,openhpc;hpc;automation
608,StorageLayer,Content-addressable storage for files across S3 and local systems,"A library providing a content-addressable storage abstraction layer, allowing unified file management across local filesystems and S3, useful for data-intensive analysis.",AI6;AI6-03,storage_abstraction;artifact_management,library,Python,https://github.com/occrp-attic/storagelayer,,MIT,storage;content-addressable;s3
609,Ollama GGUF Downloader,CLI tool to download GGUF model files from Ollama registry,"A command-line tool designed to download GGUF model files directly from the Ollama registry, facilitating the acquisition and management of local AI models.",AI6;AI6-03,artifact_management;model_download,tool,Python,https://github.com/olamide226/ollama-gguf-downloader,,MIT,ollama;gguf;model-management
610,Onllama ModelScope2Registry,Ollama Model Registry Mirror/Accelerator for ModelScope,"A tool acting as a registry mirror and accelerator, enabling faster downloading of Ollama models from the ModelScope repository.",AI6;AI6-03,artifact_management;registry_mirror,tool,C#,https://github.com/onllama/Onllama.ModelScope2Registry,,MIT,ollama;modelscope;registry
611,GAM,Globally Addressable Memory management via RDMA,"A system for efficient distributed memory management using RDMA and caching, designed to support high-performance computing applications requiring shared memory abstractions.",AI6;AI6-03,memory_management;caching;hpc_acceleration,infrastructure,C++,https://github.com/ooibc88/gam,,None,rdma;distributed-memory;hpc
612,OomStore,Lightweight and fast Feature Store,"A feature store powered by Go and Rust, designed to manage and serve machine learning features consistently across training and inference environments.",AI6;AI6-03,feature_store;data_management,platform,Go,https://github.com/oom-ai/oomstore,,Apache-2.0,feature-store;mlops;go
613,OpenMetadata,Unified metadata platform for data discovery and observability,"A platform for metadata management, data discovery, and lineage tracking, essential for governing scientific data assets and ensuring data quality and traceability.",AI6;AI6-03,metadata_management;lineage_tracking;data_discovery,platform,TypeScript,https://github.com/open-metadata/OpenMetadata,https://open-metadata.org/,Apache-2.0,metadata;data-governance;lineage
614,ODD Platform,Open-source data discovery and observability platform,"A platform focused on data discovery and observability, helping data practitioners manage data lineage and quality in complex data ecosystems.",AI6;AI6-03,data_discovery;observability,platform,Java,https://github.com/opendatadiscovery/odd-platform,,Apache-2.0,observability;data-discovery;lineage
615,hcfsfuse,Hadoop compatible FUSE client,"A FUSE (Filesystem in Userspace) implementation that allows mounting Hadoop-compatible filesystems locally, facilitating access to distributed storage in HPC/Big Data environments.",AI6,storage_access;hpc_integration,tool,Java,https://github.com/opendataio/hcfsfuse,,Apache-2.0,hadoop;fuse;hpc
616,ModelStore,"Library to version, export, and save ML models","A Python library that simplifies the process of versioning, exporting, and saving machine learning models to various storage providers, supporting reproducible ML workflows.",AI6;AI6-03,model_versioning;artifact_management,library,Python,https://github.com/operatorai/modelstore,,Apache-2.0,model-versioning;mlops;python
617,Pachyderm,Data-centric pipeline and data versioning platform for reproducible data science,"Pachyderm is a data versioning and data lineage platform that allows users to create reproducible data science pipelines. It provides a Git-like file system for data (PFS) and a pipeline system (PPS) that automatically triggers processing when data changes, ensuring full reproducibility and provenance tracking for scientific workflows.",AI6;AI6-03,data_versioning;lineage_tracking;pipeline_orchestration,platform,Go,https://github.com/pachyderm/pachyderm,https://www.pachyderm.com/docs,Apache-2.0,data-versioning;mlops;reproducibility;pipeline
618,python-pachyderm,Python client library for Pachyderm data versioning platform,"The official Python client for Pachyderm, enabling scientists and developers to interact with Pachyderm's data versioning and pipeline features programmatically. It facilitates the integration of data lineage and version control into Python-based scientific workflows.",AI6;AI6-03,data_versioning;api_client,library,Python,https://github.com/pachyderm/python-pachyderm,https://pachyderm-python.readthedocs.io/,Apache-2.0,python;client;pachyderm;data-science
619,duckdb-diskcache,Disk caching extension for DuckDB to accelerate access to remote data lakes,"A C++ extension for DuckDB that provides a disk cache for accessing remote data lakes (such as Iceberg or Delta Lake). Developed by researchers at CWI, it optimizes data access patterns for analytical workloads common in scientific data processing.",AI6;AI6-03,caching;data_access_acceleration,library,C++,https://github.com/peterboncz/duckdb-diskcache,,MIT,duckdb;caching;data-lake;performance
620,STREAM,"Single-cell Trajectories Reconstruction, Exploration And Mapping tool",STREAM is an interactive pipeline for reconstructing complex cellular differentiation trajectories from single-cell RNA-sequencing data. It can accurately disentangle complex trajectories and provides visualization tools for exploring developmental branches.,AI3;Bioinformatics,trajectory_inference;single_cell_analysis;visualization,library,Jupyter Notebook,https://github.com/pinellolab/STREAM,https://stream.pinellolab.partners.org/,AGPL-3.0,single-cell;trajectory-inference;rna-seq;bioinformatics
621,PLynx,Domain-agnostic platform for managing reproducible experiments and data-oriented workflows,"PLynx is a modular platform designed to manage reproducible experiments and data-oriented workflows. It provides a graphical interface for building pipelines, tracking experiment history, and managing artifacts, suitable for machine learning and scientific computing tasks.",AI6;AI6-03,workflow_management;reproducibility;experiment_tracking,platform,JavaScript,https://github.com/plynx-team/plynx,https://plynx.com/,Apache-2.0,workflow;reproducibility;experiment-tracking;pipeline
622,GENDIS,Genetic Discovery of Shapelets algorithm for time series classification,"GENDIS (GEnetic DIscovery of Shapelets) is a Python implementation of a genetic algorithm-based shapelet discovery method for time series classification. It provides a scikit-learn compatible API for analyzing time-series data, which is common in scientific experiments.",AI1;DataScience,time_series_analysis;shapelet_discovery;classification,library,Jupyter Notebook,https://github.com/predict-idlab/GENDIS,,NOASSERTION,time-series;genetic-algorithm;shapelets;sklearn
623,GridFluidSim3D,PIC/FLIP fluid simulation solver based on physical methods,"A C++ implementation of a fluid simulation solver using Particle-In-Cell (PIC) and Fluid-Implicit-Particle (FLIP) methods, capable of generating fluid dynamics data.",AI6;AI6-03,simulation;fluid_dynamics,solver,C++,https://github.com/rlguy/GridFluidSim3D,,Zlib,fluid-simulation;physics;solver;cpp
624,BPref,Benchmark suite for preference-based reinforcement learning,"A benchmarking framework for preference-based reinforcement learning (PbRL), providing environments and baselines to evaluate RL algorithms.",AI6;AI6-03,benchmarking;reinforcement_learning,dataset,Python,https://github.com/rll-research/BPref,,MIT,reinforcement-learning;benchmark;preference-learning
625,gittargets,Data version control for R analysis pipelines,"A tool that integrates data version control with the 'targets' workflow package in R, enabling reproducible analysis pipelines by tracking data snapshots.",AI6;AI6-03,data_versioning;workflow_management,tool,R,https://github.com/ropensci/gittargets,https://docs.ropensci.org/gittargets/,NOASSERTION,r;data-version-control;reproducibility;pipeline
626,s3git,Distributed version control for data on cloud storage,"A CLI tool that brings git-like versioning to data stored in S3 and other cloud storage, enabling distributed version control for large datasets.",AI6;AI6-03,data_versioning;artifact_management,tool,Go,https://github.com/s3git/s3git,http://s3git.org,Apache-2.0,data-versioning;s3;cloud-storage;git-like
627,git-lfs-ipfs,IPFS storage backend for Git LFS,A custom transfer agent for Git LFS that allows using IPFS (InterPlanetary File System) as the storage backend for large scientific artifacts.,AI6;AI6-03,artifact_management;data_storage,tool,Rust,https://github.com/sameer/git-lfs-ipfs,,NOASSERTION,git-lfs;ipfs;decentralized-storage;artifact-management
628,lambo,Bayesian optimization solver for protein design,"Implementation of 'Latent MBO', a method for accelerating Bayesian Optimization for protein design using denoising autoencoders.",AI6;AI6-03,protein_design;optimization,solver,Jupyter Notebook,https://github.com/samuelstanton/lambo,,Apache-2.0,protein-design;bayesian-optimization;machine-learning;bioinformatics
629,lfscache,Caching proxy for Git LFS,"A caching proxy server for Git LFS, designed to accelerate the retrieval of large artifacts in distributed workflows.",AI6;AI6-03,caching;artifact_management,service,Go,https://github.com/saracen/lfscache,,MIT,git-lfs;caching;proxy;performance
630,llm-data-annotation,Data annotation framework using LLMs,A framework that leverages Large Language Models (LLMs) and active learning to automate and enhance data annotation processes for machine learning datasets.,AI6;AI6-03,data_annotation;data_processing,workflow,Python,https://github.com/saran9991/llm-data-annotation,,MIT,data-annotation;llm;active-learning;cleanlab
631,DVCP-TE,Simulation model of the Tennessee Eastman chemical process,"A simulation environment for the Tennessee Eastman chemical process, used as a benchmark for process control and security research (Damn Vulnerable Chemical Process).",AI6;AI6-03,simulation;process_control,dataset,HTML,https://github.com/satejnik/DVCP-TE,,BSD-3-Clause,chemical-process;simulation;benchmark;security
632,lfs-folderstore,Local folder storage adapter for Git LFS,"A custom transfer adapter for Git LFS that allows using a local folder (or shared network drive) as the remote storage backend, facilitating artifact management in restricted environments.",AI6;AI6-03,artifact_management;data_storage,tool,Go,https://github.com/sinbad/lfs-folderstore,,None,git-lfs;storage-adapter;artifact-management
633,Spine Toolbox,Workflow and data management for modelling and simulation,"An open-source platform to manage data, scenarios, and workflows for complex modelling and simulation tasks, supporting version control and team collaboration.",AI6;AI6-03,workflow_management;simulation_management,platform,Python,https://github.com/spine-tools/Spine-Toolbox,https://spine-toolbox.readthedocs.io/,LGPL-3.0,workflow;simulation;data-management;modelling
634,stac-geoparquet,Conversion library between STAC items and GeoParquet format,"A Python library to convert SpatioTemporal Asset Catalog (STAC) items between JSON, GeoParquet, pgstac, and Delta Lake formats, facilitating efficient storage and querying of geospatial data.",Earth Science;Geospatial;AI6-03,data_conversion;data_management,library,Python,https://github.com/stac-utils/stac-geoparquet,,MIT,stac;geoparquet;geospatial;gis;data-conversion
635,SU2,Open-Source Suite for Multiphysics Simulation and Design,"SU2 is an open-source suite of software tools written in C++ for the numerical solution of partial differential equations (PDE) and performing PDE-constrained optimization, primarily for CFD and aerodynamics.",Physics;CFD;HPC;AI6,simulation;modeling;optimization,solver,C++,https://github.com/su2code/SU2,https://su2code.github.io/,NOASSERTION,cfd;multiphysics;simulation;aerodynamics;optimization
636,torchdatasets,Extended PyTorch Dataset with caching and mapping capabilities,"A library that extends PyTorch Dataset with features like caching, mapping, and other functional transformations, similar to tensorflow.data, to optimize data loading pipelines in scientific machine learning.",AI6-03;Machine Learning,data_loading;caching;data_processing,library,Python,https://github.com/szymonmaszke/torchdatasets,,MIT,pytorch;dataset;caching;data-loading
637,Hangar,Version control system for tensor data,"Hangar is a version control system specifically designed for tensor data. It allows users to commit, branch, merge, revert, and collaborate on numerical data, ensuring reproducibility in machine learning and scientific research.",AI6-03;Machine Learning,data_versioning;artifact_management,platform,Python,https://github.com/tensorwerk/hangar-py,https://hangar-py.readthedocs.io/,Apache-2.0,data-versioning;tensors;reproducibility;git-for-data
638,LineageExplorer,Tool for estimating SARS-CoV-2 variant growth advantages,An R package/tool to estimate the growth rate advantage of SARS-CoV-2 variants of concern based on international genomic surveillance data and multinomial spline fits.,Biology;Epidemiology;Genomics,inference;statistical_analysis;modeling,solver,R,https://github.com/tomwenseleers/LineageExplorer,,None,covid-19;epidemiology;genomics;statistical-modeling
639,DVC,Data Version Control for Machine Learning Projects,"DVC is a data version control system built for machine learning projects. It handles large files, datasets, and machine learning models, making them shareable and reproducible. It integrates with Git to version control data and pipelines.",AI6-03;Machine Learning;Data Science,data_versioning;reproducibility;pipeline_management,platform,Python,https://github.com/treeverse/dvc,https://dvc.org/,Apache-2.0,data-version-control;mlops;reproducibility;git-for-data
640,DVCLive,Library for logging and tracking ML metrics,"DVCLive is a Python library for logging machine learning metrics, parameters, and model artifacts. It integrates with DVC to track experiments and visualize results, facilitating scientific experiment management.",AI6-03;Machine Learning,experiment_tracking;metrics_logging,library,Python,https://github.com/treeverse/dvclive,https://dvc.org/doc/dvclive,Apache-2.0,experiment-tracking;mlops;metrics;logging
641,lakeFS,Git-like version control for data lakes,"lakeFS provides a Git-like version control interface for object storage (S3, Azure Blob, GCS). It allows managing data lakes with commits, branches, and merges, enabling reproducible data science and data engineering workflows.",AI6-03;Data Science;Big Data,data_versioning;artifact_management;reproducibility,platform,Go,https://github.com/treeverse/lakeFS,https://lakefs.io/,Apache-2.0,data-lake;version-control;object-storage;reproducibility
642,ATOM,Python package for fast exploration and optimization of machine learning pipelines,"ATOM is an AutoML tool designed to accelerate the data science pipeline. It provides features for data cleaning, feature engineering, and model selection/optimization, specifically catering to scientific modeling and analysis tasks.",AI4;AI6,automl;model_optimization;pipeline_automation,library,Python,https://github.com/tvdboom/ATOM,https://atom-ml.readthedocs.io/,MIT,automl;machine-learning;data-science
643,tvault,Lightweight local model registry for PyTorch,"tvault is a tool for managing machine learning model artifacts. It allows researchers to track, compare, and register PyTorch models locally, facilitating reproducibility and experiment management in scientific workflows.",AI6-03,model_registry;artifact_management;experiment_tracking,tool,Python,https://github.com/vessl-ai/tvault,,MIT,model-registry;pytorch;mlops
644,OpenCorr,Digital Image Correlation (DIC) and Digital Volume Correlation (DVC) library,"OpenCorr is an open-source C++ library for Digital Image Correlation (DIC) and Digital Volume Correlation (DVC), widely used in experimental mechanics and materials science for strain and deformation analysis.",Physics;Materials Science,digital_image_correlation;strain_analysis;deformation_measurement,library,C++,https://github.com/vincentjzy/OpenCorr,,MPL-2.0,dic;dvc;experimental-mechanics
645,vLLM,High-throughput and memory-efficient inference engine for LLMs,"vLLM is a high-performance library for LLM inference and serving. It utilizes PagedAttention to manage attention key and value memory efficiently, making it a critical tool for deploying large-scale scientific language models.",AI6;AI6-01,llm_inference;model_serving;memory_optimization,solver,Python,https://github.com/vllm-project/vllm,https://docs.vllm.ai/,Apache-2.0,inference-engine;llm;hpc
646,GPTCache,Semantic caching library for Large Language Models to reduce latency and costs,"A semantic cache for LLMs that stores and retrieves responses based on semantic similarity. It integrates with LangChain and llama_index to optimize inference efficiency, reducing API costs and latency in AI-driven scientific workflows.",AI6;AI6-03,caching;inference_optimization,library,Python,https://github.com/zilliztech/GPTCache,,MIT,llm;caching;semantic-search;optimization
647,ZnTrack,Python interface for DVC to manage scientific workflows and data versioning,"A lightweight Python package that acts as a wrapper for DVC (Data Version Control). It enables researchers to define, run, visualize, and benchmark DVC pipelines directly within Python scripts or Jupyter notebooks, facilitating reproducible scientific experiments.",AI6;AI6-03,data_versioning;workflow_management,workflow,Python,https://github.com/zincware/ZnTrack,https://zntrack.readthedocs.io,Apache-2.0,dvc;reproducibility;pipeline;jupyter
648,tensorscript,Shape-checking neural network DSL compiling to PyTorch,"A domain-specific language (DSL) for defining neural networks with a Hindley-Milner type system for shape checking, compiling to PyTorch for execution.",AI6;AI6-04,compiler;model_definition,solver,Rust,https://github.com/0b01/tensorscript,,None,dsl;compiler;pytorch;shape-checking
649,YOLO_RKNN_Acceleration_Program,Multi-threaded hardware-accelerated inference framework for YOLO on RKNN,"A framework for accelerating YOLO object detection models using Rockchip NPU (RKNN), featuring multi-threading support for efficient inference.",AI6;AI6-04,inference_acceleration;edge_computing,solver,C,https://github.com/1125962926/YOLO_RKNN_Acceleration_Program,,Apache-2.0,yolo;rknn;npu;inference
650,PTQ4DM,Post-training quantization framework for diffusion models,Implementation of post-training quantization (PTQ) techniques specifically optimized for diffusion models to reduce model size and accelerate inference.,AI6;AI6-04,quantization;model_compression,library,Python,https://github.com/42Shawn/PTQ4DM,,None,diffusion-models;ptq;quantization
651,OpenEmbedding,Distributed training acceleration framework for TensorFlow embedding layers,An open-source framework designed to accelerate distributed training of large-scale embedding layers in TensorFlow models.,AI6;AI6-04,training_acceleration;distributed_training,library,C++,https://github.com/4paradigm/OpenEmbedding,,Apache-2.0,tensorflow;embedding;distributed-training
652,micronet,Comprehensive model compression and deployment library,"A library for neural network compression and deployment, supporting quantization (QAT, PTQ), pruning, and TensorRT deployment integration.",AI6;AI6-04,model_compression;quantization;pruning,library,Python,https://github.com/666DZY666/micronet,,MIT,model-compression;quantization;pruning;tensorrt
653,JetStream,High-throughput LLM inference engine for XLA devices,A throughput and memory optimized inference engine for Large Language Models (LLMs) designed for XLA devices like TPUs.,AI6;AI6-04,inference_acceleration;llm_serving,solver,Python,https://github.com/AI-Hypercomputer/JetStream,,Apache-2.0,llm;inference;tpu;xla
654,jetstream-pytorch,PyTorch/XLA integration for JetStream inference engine,Provides PyTorch/XLA integration with the JetStream engine to enable high-performance LLM inference using PyTorch models on XLA devices.,AI6;AI6-04,inference_acceleration;framework_integration,library,Python,https://github.com/AI-Hypercomputer/jetstream-pytorch,,Apache-2.0,pytorch;xla;jetstream;inference
655,BiLLM,Ultra-low bit post-training quantization for LLMs,"Implementation of BiLLM, a method for pushing the limits of post-training quantization for Large Language Models to extremely low bit-widths.",AI6;AI6-04,quantization;model_compression,library,Python,https://github.com/Aaronhuang-778/BiLLM,,MIT,llm;quantization;ptq
656,Hash3D,Training-free acceleration tool for 3D generation,"A tool providing training-free acceleration techniques for 3D generative models, optimizing the generation process.",AI6;AI6-04,inference_acceleration;3d_generation,library,Python,https://github.com/Adamdad/hash3D,,None,3d-generation;acceleration;training-free
657,Adlik,End-to-end deep learning inference acceleration toolkit,"A toolkit for accelerating deep learning inference, providing model optimization and deployment capabilities across various hardware platforms.",AI6;AI6-04,inference_acceleration;model_optimization,platform,C++,https://github.com/Adlik/Adlik,,Apache-2.0,inference;acceleration;deep-learning
658,LLM-distributed-finetune,Distributed fine-tuning workflow for LLMs using DeepSpeed and Ray,A workflow tool for efficiently fine-tuning Large Language Models (LLMs) using distributed training techniques with DeepSpeed and Ray orchestration.,AI6;AI6-04,distributed_training;fine_tuning,workflow,Python,https://github.com/AdrianBZG/LLM-distributed-finetune,,MIT,llm;distributed-training;deepspeed;ray
659,optimum-transformers,Accelerated NLP pipelines using ONNX Runtime,"A library providing accelerated NLP pipelines for fast inference on CPU and GPU, integrating Transformers with Optimum and ONNX Runtime.",AI6;AI6-04,inference_acceleration;nlp_pipeline,library,Python,https://github.com/AlekseyKorshuk/optimum-transformers,,GPL-3.0,nlp;onnx;inference;acceleration
660,torchacc,PyTorch distributed training acceleration framework,"A framework designed to accelerate distributed training workloads in PyTorch, optimizing performance for large-scale models.",AI6;AI6-04,training_acceleration;distributed_training,library,Python,https://github.com/AlibabaPAI/torchacc,,Apache-2.0,pytorch;distributed-training;acceleration
661,Compass_Apache_TVM,Enhanced Apache TVM compiler for heterogeneous execution,"An enhanced version of the Apache TVM compiler stack, optimized for wide neural network support and heterogeneous execution on specific hardware.",AI6;AI6-04,compiler;inference_optimization,solver,Python,https://github.com/Arm-China/Compass_Apache_TVM,,Apache-2.0,tvm;compiler;heterogeneous-computing
662,AutoGPTQ,Easy-to-use LLM quantization package based on GPTQ,"A user-friendly library for quantizing Large Language Models (LLMs) using the GPTQ algorithm, facilitating efficient inference.",AI6;AI6-04,quantization;model_compression,library,Python,https://github.com/AutoGPTQ/AutoGPTQ,,MIT,gptq;quantization;llm
663,distribuuuu,Lightweight PyTorch distributed training framework,"A minimalist and clear framework for PyTorch distributed training, designed to simplify the setup and execution of distributed experiments.",AI6;AI6-04,distributed_training;training_acceleration,library,Python,https://github.com/BIGBALLON/distribuuuu,,MIT,pytorch;distributed-training
664,BitNet-Transformers,1-bit Transformer implementation for LLMs,A PyTorch implementation of BitNet (Scaling 1-bit Transformers for Large Language Models) integrated with Huggingface Transformers.,AI6;AI6-04,quantization;model_architecture,library,Python,https://github.com/Beomi/BitNet-Transformers,,None,bitnet;1-bit;quantization;llm
665,bluefog,Decentralized distributed training framework for PyTorch,"A distributed and decentralized training framework for PyTorch that operates over graphs, optimizing communication for large-scale training.",AI6;AI6-04,distributed_training;decentralized_learning,library,Python,https://github.com/Bluefog-Lib/bluefog,,Apache-2.0,distributed-training;decentralized;pytorch
666,attorch,PyTorch modules accelerated with OpenAI Triton,A collection of PyTorch neural network modules re-implemented using OpenAI's Triton language for high-performance GPU acceleration.,AI6;AI6-04,acceleration;kernel_optimization,library,Python,https://github.com/BobMcDear/attorch,,MIT,triton;pytorch;acceleration
667,metalQwen3,Metal GPU accelerated inference for Qwen3 on macOS,A C++ implementation of the Qwen3 transformer model optimized for Apple Silicon using Metal compute shaders for acceleration.,AI6;AI6-04,inference_acceleration;edge_computing,solver,C++,https://github.com/BoltzmannEntropy/metalQwen3,,MIT,metal;apple-silicon;qwen;inference
668,Triton-distributed,Distributed compiler based on Triton,"A distributed compiler infrastructure built on top of Triton, designed to optimize parallel execution across distributed systems.",AI6;AI6-04,compiler;distributed_computing,solver,Python,https://github.com/ByteDance-Seed/Triton-distributed,,MIT,triton;compiler;distributed-systems
669,Super-Fast-Adversarial-Training,High-performance adversarial training framework,"A PyTorch implementation for super fast adversarial training, incorporating distributed data parallel, mixed precision, and efficient data loading techniques.",AI6;AI6-04,training_acceleration;adversarial_training,library,Python,https://github.com/ByungKwanLee/Super-Fast-Adversarial-Training,,MIT,adversarial-training;acceleration;pytorch
670,XB-Sim,Simulation framework for ReRAM-based CNN acceleration,"A unified framework for training, mapping, and simulating Convolutional Neural Networks (CNNs) on ReRAM-based hardware accelerators.",AI6;AI6-04,hardware_simulation;neuromorphic_computing,solver,C++,https://github.com/CRAFT-THU/XB-Sim,,MIT,reram;simulation;hardware-acceleration
671,ChatGLM_mutli_gpu_tuning,Multi-GPU fine-tuning tool for ChatGLM,A streamlined implementation for multi-GPU fine-tuning of ChatGLM models using DeepSpeed and HuggingFace Trainer.,AI6;AI6-04,fine_tuning;distributed_training,workflow,Python,https://github.com/CSHaitao/ChatGLM_mutli_gpu_tuning,,MIT,chatglm;fine-tuning;deepspeed
672,triton-linalg,Triton to Linalg dialect conversion tool,"A development repository for converting Triton IR to MLIR Linalg dialect, facilitating compiler interoperability and optimization.",AI6;AI6-04,compiler;ir_conversion,library,C++,https://github.com/Cambricon/triton-linalg,,Apache-2.0,triton;mlir;linalg;compiler
673,APQ-DM,Accurate post-training quantization for diffusion models,"Implementation of APQ-DM, a method for accurate post-training quantization of diffusion models, preserving generation quality.",AI6;AI6-04,quantization;model_compression,library,Python,https://github.com/ChangyuanWang17/APQ-DM,,Apache-2.0,diffusion-models;quantization;ptq
674,vllm-cli,CLI tool for serving LLMs with vLLM,"A command-line interface wrapper for vLLM, simplifying the deployment and serving of Large Language Models.",AI6;AI6-04,inference_serving;deployment,service,Python,https://github.com/Chen-zexi/vllm-cli,,MIT,vllm;cli;serving;llm
675,ncnnqat,Quantization-aware training package for NCNN on PyTorch,"A Python package designed to facilitate quantization-aware training (QAT) for models intended to be deployed with the NCNN inference framework, helping to maintain accuracy while optimizing for edge devices.",AI6;AI6-04,quantization;model_optimization,library,Python,https://github.com/ChenShisen/ncnnqat,,MIT,ncnn;quantization-aware-training;pytorch
676,llm-rk3588,GPU-accelerated LLM inference on Rockchip RK3588,"A deployment tool enabling the execution of Large Language Models on Rockchip RK3588 hardware with GPU acceleration, optimizing inference for edge computing scenarios.",AI6;AI6-04,inference_acceleration;edge_computing,solver,C++,https://github.com/Chrisz236/llm-rk3588,,Apache-2.0,rk3588;llm;edge-inference
677,BiSeNet,Implementation of BiSeNet V1 and V2 for real-time semantic segmentation,"A PyTorch implementation of the BiSeNet (Bilateral Segmentation Network) architecture, designed for efficient real-time semantic segmentation tasks in computer vision.",AI6;AI6-04,image_segmentation;model_implementation,library,Python,https://github.com/CoinCheung/BiSeNet,,MIT,semantic-segmentation;bisenet;computer-vision
678,gdGPT,Accelerated LLM training using DeepSpeed pipeline mode,"A training framework for Large Language Models (Bloom, Llama, Baichuan, ChatGLM) utilizing DeepSpeed's pipeline parallelism to achieve faster training speeds compared to standard Zero/FSDP methods.",AI6;AI6-04,training_acceleration;distributed_training,workflow,Python,https://github.com/CoinCheung/gdGPT,,Apache-2.0,llm-training;deepspeed;pipeline-parallelism
679,MPP-LLaVA,Multimodal Pipeline Parallel training for LLaVA-like models,"A project enabling the training of large multimodal models (like Qwen-VL) on consumer-grade hardware (e.g., RTX3090/4090) using pipeline parallelism techniques.",AI6;AI6-04,training_acceleration;multimodal_learning,workflow,Jupyter Notebook,https://github.com/Coobiw/MPP-LLaVA,,None,mllm;pipeline-parallelism;consumer-gpu
680,QuIP,2-Bit Quantization of Large Language Models with guarantees,"Implementation of the QuIP algorithm for extreme quantization (2-bit) of Large Language Models, providing theoretical guarantees and practical code for model compression.",AI6;AI6-04,quantization;model_compression,library,Python,https://github.com/Cornell-RelaxML/QuIP,,None,llm-quantization;2-bit;model-compression
681,dfq-toolkit,Task-Specific Zero-shot Quantization-Aware Training toolkit,"A toolkit for performing zero-shot quantization-aware training specifically optimized for object detection tasks, as presented at ICCV 2025.",AI6;AI6-04,quantization;object_detection,library,Python,https://github.com/DFQ-Dojo/dfq-toolkit,,AGPL-3.0,quantization-aware-training;zero-shot;object-detection
682,BerryNet,Deep learning gateway for Raspberry Pi and edge devices,"An open-source deep learning gateway designed to turn edge devices like Raspberry Pi into intelligent AI nodes, managing inference tasks and data flow.",AI6;AI6-04,edge_inference;iot_gateway,platform,Python,https://github.com/DT42/BerryNet,,GPL-3.0,edge-ai;raspberry-pi;inference-gateway
683,Audio-Denoiser-ONNX,Audio denoising using ONNX Runtime,"A tool leveraging ONNX Runtime to perform efficient audio denoising, suitable for cleaning up audio data in scientific or media processing pipelines.",AI6;AI6-04,audio_processing;denoising,solver,Python,https://github.com/DakeQQ/Audio-Denoiser-ONNX,,Apache-2.0,audio-denoising;onnx;signal-processing
684,F5-TTS-ONNX,F5-TTS implementation using ONNX Runtime,"A runtime implementation for the F5 Text-to-Speech model using ONNX, enabling efficient speech synthesis inference.",AI6;AI6-04,speech_synthesis;inference_acceleration,solver,Python,https://github.com/DakeQQ/F5-TTS-ONNX,,Apache-2.0,tts;onnx;inference
685,HiPrune,Training-free visual token pruning for VLM acceleration,"Implementation of a method for pruning visual tokens in Vision-Language Models (VLMs) without retraining, aiming to accelerate inference.",AI6;AI6-04,model_pruning;vlm_acceleration,library,Jupyter Notebook,https://github.com/Danielement321/HiPrune,,MIT,pruning;vlm;acceleration
686,CVFusion,Deep learning compiler to fuse OpenCV operators,"An open-source deep learning compiler designed to optimize computer vision pipelines by fusing OpenCV operators, improving execution efficiency.",AI6;AI6-04,compiler;operator_fusion,library,C++,https://github.com/DeepLink-org/CVFusion,,Apache-2.0,compiler;opencv;optimization
687,jaxDecomp,JAX bindings for NVIDIA cuDecomp library,"Provides JAX bindings for the NVIDIA cuDecomp library, enabling efficient domain decomposition for high-performance scientific computing and simulations on GPUs.",AI6;AI6-04,hpc;domain_decomposition,library,Python,https://github.com/DifferentiableUniverseInitiative/jaxDecomp,,MIT,jax;hpc;cudecomp
688,keras_compressor,Model Compression CLI Tool for Keras,"A command-line interface tool for compressing Keras models, facilitating optimization for deployment.",AI6;AI6-04,model_compression;optimization,solver,Python,https://github.com/DwangoMediaVillage/keras_compressor,,None,keras;compression;cli
689,EduChat,Open-source educational chat model,"A large language model specifically tuned for educational contexts, including tools for data cleaning and GPU deployment.",AI6;AI6-04,llm;education_domain,platform,Jupyter Notebook,https://github.com/ECNU-ICALK/EduChat,,None,llm;education;deployment
690,kernl,Accelerated PyTorch transformer inference on GPU,"A library that optimizes PyTorch transformer models for faster GPU inference using custom kernels, designed to be easily integrated and modified.",AI6;AI6-04,inference_acceleration;kernel_optimization,library,Jupyter Notebook,https://github.com/ELS-RD/kernl,,Apache-2.0,pytorch;transformer;gpu-acceleration
691,evogp,GPU-accelerated library for Tree-based Genetic Programming,"A library leveraging PyTorch and CUDA for high-performance evolutionary computation, specifically tree-based genetic programming for symbolic regression and classification.",AI6;AI6-04,genetic_programming;symbolic_regression,library,Python,https://github.com/EMI-Group/evogp,,GPL-3.0,genetic-programming;gpu;symbolic-regression
692,Stable-Diffusion-NCNN,Stable Diffusion implementation in NCNN with C++,"A C++ implementation of Stable Diffusion using the NCNN framework, enabling image generation on edge devices and mobile platforms.",AI6;AI6-04,generative_ai;edge_inference,solver,C++,https://github.com/EdVince/Stable-Diffusion-NCNN,,BSD-3-Clause,stable-diffusion;ncnn;edge-ai
693,mera,Heterogeneous Platform Deep Learning Compiler Framework,A compiler framework from EdgeCortix designed to optimize deep learning models for heterogeneous computing platforms.,AI6;AI6-04,compiler;heterogeneous_computing,library,Python,https://github.com/Edgecortix-Inc/mera,,Apache-2.0,compiler;edge-ai;optimization
694,Einsums,Compile-time tensor contraction analysis and optimization,A C++ library that performs compile-time analysis of tensor contraction patterns to determine and execute optimal tensor operations.,AI6;AI6-04,tensor_computation;optimization,library,C++,https://github.com/Einsums/Einsums,,MIT,tensor;c++;optimization
695,gpt-neox,Model parallel autoregressive transformer implementation on GPUs,"A library for training large-scale language models on GPUs using model parallelism, built on top of Megatron-LM and DeepSpeed.",AI6;AI6-04,llm_training;distributed_computing,workflow,Python,https://github.com/EleutherAI/gpt-neox,,Apache-2.0,llm;distributed-training;gpu
696,Reactant.jl,Optimize Julia functions with MLIR and XLA,"A tool to optimize Julia code execution on high-performance hardware (CPU, GPU, TPU) by leveraging MLIR and XLA compilation stacks.",AI6;AI6-04,compiler;hpc,library,Julia,https://github.com/EnzymeAD/Reactant.jl,,MIT,julia;xla;mlir
697,candle-vllm,Efficient inference and serving platform for local LLMs,"A Rust-based platform for efficient inference and serving of Large Language Models, compatible with OpenAI API standards.",AI6;AI6-04,inference_serving;llm,service,Rust,https://github.com/EricLBuehler/candle-vllm,,MIT,llm-serving;rust;inference
698,FaceONNX,Face recognition library based on ONNX Runtime,A C# library for face recognition and analytics utilizing deep neural networks and the ONNX Runtime for inference.,AI6;AI6-04,face_recognition;biometrics,library,C#,https://github.com/FaceONNX/FaceONNX,,MIT,face-recognition;onnx;c#
699,fasterai,Model pruning and distillation library for FastAI/PyTorch,A library designed to facilitate neural network compression techniques such as pruning and knowledge distillation within the FastAI and PyTorch ecosystems.,AI6;AI6-04,model_compression;pruning,library,Jupyter Notebook,https://github.com/FasterAI-Labs/fasterai,,Apache-2.0,pruning;distillation;fastai
700,TensorRT-Alpha,TensorRT implementations for YOLO series and other models,A comprehensive collection of TensorRT implementations for accelerating various YOLO models (v5-v8) and other architectures on NVIDIA GPUs.,AI6;AI6-04,inference_acceleration;tensorrt,library,C++,https://github.com/FeiYull/TensorRT-Alpha,,GPL-2.0,tensorrt;yolo;inference
701,QDLM,Post-training quantization for Diffusion LLMs,A tool for applying post-training quantization techniques specifically to Diffusion Large Language Models (dLLMs) to improve efficiency.,AI6;AI6-04,quantization;diffusion_models,library,Python,https://github.com/FelixMessi/QDLM,,MIT,quantization;diffusion-llm;ptq
702,CMUNeXt,Efficient Medical Image Segmentation Network,"An efficient deep learning network architecture designed for medical image segmentation, featuring large kernels and skip fusion mechanisms.",AI6;AI6-04,medical_image_segmentation;model_architecture,solver,Python,https://github.com/FengheTan9/CMUNeXt,,MIT,medical-imaging;segmentation;efficient-network
703,RoboBrain,Unified Brain Model for Robotic Manipulation,"A unified foundation model for robotic manipulation tasks, bridging abstract reasoning with concrete control actions.",AI6;AI6-04,robotics;foundation_model,solver,Python,https://github.com/FlagOpen/RoboBrain,,Apache-2.0,robotics;manipulation;foundation-model
704,XLA.jl,XLA compiler bindings for Julia,"A package providing bindings to the XLA (Accelerated Linear Algebra) compiler for the Julia language, enabling hardware acceleration for machine learning workloads.",AI6;AI6-04,compiler;acceleration,library,Julia,https://github.com/FluxML/XLA.jl,,MIT,julia;xla;compiler
705,compressonator,Texture and 3D Model Compression Tool Suite,"A suite of tools for compressing, optimizing, and analyzing textures and 3D models, supporting various hardware accelerations (CPU, GPU, APU).",AI6;AI6-04,data_compression;3d_visualization,workflow,C++,https://github.com/GPUOpen-Tools/compressonator,,None,compression;texture;3d-model
706,nano-vllm,Lightweight implementation of vLLM,"A simplified and lightweight version of the vLLM library, designed for efficient LLM inference with lower overhead.",AI6;AI6-04,inference_acceleration;llm,library,Python,https://github.com/GeeeekExplorer/nano-vllm,,MIT,vllm;inference;lightweight
707,FastMOT,High-performance multiple object tracking,"A high-performance multiple object tracking library integrating YOLO, Deep SORT, and KLT optical flow for efficient video analysis.",AI6;AI6-04,object_tracking;video_analysis,solver,Python,https://github.com/GeekAlexis/FastMOT,,MIT,tracking;yolo;computer-vision
708,Depths-CPP,High-performance C++ depth estimation using ONNX Runtime,"A C++ application and header library for real-time metric depth estimation using Depth-Anything-V2 models, optimized with ONNX Runtime and OpenCV.",AI6;AI6-04,depth_estimation;computer_vision,solver,C++,https://github.com/Geekgineer/Depths-CPP,,None,depth-estimation;onnx;c++
709,YOLOs-CPP,High-performance C++ YOLO inference library,"A C++ library for real-time object detection and segmentation using various YOLO models (v5-v12), leveraging ONNX Runtime for optimized CPU/GPU inference.",AI6;AI6-04,object_detection;inference_acceleration,library,C++,https://github.com/Geekgineer/YOLOs-CPP,,None,yolo;onnx;c++
710,PiSSA,Parameter-efficient fine-tuning method for Large Language Models,"A library implementing Principal Singular Values and Singular Vectors Adaptation (PiSSA) for efficient fine-tuning of LLMs, optimizing parameter adaptation compared to LoRA.",AI6-04;AI6,model_adaptation;fine_tuning,library,Jupyter Notebook,https://github.com/GraphPKU/PiSSA,,None,peft;llm-finetuning;parameter-efficiency
711,YOLOv5-Multibackbone-Compression,Comprehensive compression toolbox for YOLOv5 models,"A toolbox integrating multi-backbone support, pruning (EagleEye, Network Slimming), quantization (MQBench), and deployment (TensorRT, ncnn) for YOLOv5 series models.",AI6-04;AI6,model_compression;quantization;pruning,workflow,Python,https://github.com/Gumpest/YOLOv5-Multibackbone-Compression,,None,yolov5;model-compression;pruning;quantization
712,EasyCache,Training-free acceleration for video diffusion models,"A library for accelerating video diffusion models using runtime-adaptive caching mechanisms, enabling faster inference without retraining.",AI6-04;AI6,inference_acceleration;caching,library,Python,https://github.com/H-EmbodVis/EasyCache,,Apache-2.0,diffusion-models;video-generation;acceleration
713,TTC,High-performance compiler for tensor transpositions,"A specialized compiler designed to generate high-performance code for tensor transpositions, optimizing data layout transformations in scientific computing and deep learning.",AI6-04;AI6,compilation;tensor_optimization,solver,Python,https://github.com/HPAC/TTC,,GPL-3.0,compiler;tensor-transposition;hpc
714,tpc_llvm,LLVM-based compiler for HabanaLabs TPC accelerators,"The TPC-CLANG compiler based on LLVM, designed to compile TPC C programming language for HabanaLabs Deep-Learning Accelerators.",AI6-04;AI6,compilation;hardware_acceleration,solver,C++,https://github.com/HabanaAI/tpc_llvm,,None,llvm;compiler;habana;accelerator
715,YOLO-Multi-Backbones-Attention,Model compression toolkit for YOLOv3,"A model compression toolkit for YOLOv3 incorporating lightweight backbones (ShuffleNet, GhostNet), attention mechanisms, pruning, and quantization.",AI6-04;AI6,model_compression;pruning;quantization,workflow,Python,https://github.com/HaloTrouvaille/YOLO-Multi-Backbones-Attention,,None,yolo;model-compression;pruning
716,revlib,Memory-efficient Reversible Network library for PyTorch,"A library implementing Reversible Networks (RevNet) for PyTorch, supporting XLA and DeepSpeed to significantly reduce memory usage during training.",AI6-04;AI6,training_optimization;memory_management,library,Python,https://github.com/HomebrewML/revlib,,BSD-2-Clause,memory-optimization;reversible-networks;pytorch
717,transpeeder,Tool for training Llama on single A100 using Pipeline Parallelism,A utility enabling the training of large language models (like Llama) on limited hardware (single A100 node) by leveraging DeepSpeed Pipeline Parallelism.,AI6-04;AI6,distributed_training;pipeline_parallelism,workflow,Python,https://github.com/HuangLK/transpeeder,,Apache-2.0,llm-training;deepspeed;pipeline-parallelism
718,tfbert,TensorFlow 1.x based BERT pre-training framework,"A pre-training framework for BERT models based on TensorFlow 1.x, supporting multi-GPU training, gradient accumulation, XLA acceleration, and mixed precision.",AI6-04;AI6,model_training;pretraining,library,Python,https://github.com/HuiResearch/tfbert,,None,bert;pretraining;tensorflow;xla
719,zDLC,Deep Learning Compiler for IBM Z systems,"A deep learning compiler specifically optimized for IBM Z mainframes, enabling efficient execution of neural networks on this architecture.",AI6-04;AI6,compilation;hardware_optimization,solver,Python,https://github.com/IBM/zDLC,,Apache-2.0,compiler;ibm-z;deep-learning
720,OBC,Optimal Brain Compression framework for quantization and pruning,"A framework for accurate post-training quantization and pruning of neural networks, implementing the Optimal Brain Compression method.",AI6-04;AI6,model_compression;quantization;pruning,library,Python,https://github.com/IST-DASLab/OBC,,None,quantization;pruning;model-compression
721,GPTQ,Accurate post-training quantization for GPT models,"A widely used library for post-training quantization of generative pretrained transformers (GPT), enabling efficient inference on consumer hardware.",AI6-04;AI6,quantization;model_compression,library,Python,https://github.com/IST-DASLab/gptq,,Apache-2.0,quantization;llm;gpt;inference-acceleration
722,QMoE,Sub-1-bit compression tool for Mixture-of-Experts models,A library for compressing trillion-parameter Mixture-of-Experts (MoE) models to sub-1-bit precision while maintaining accuracy.,AI6-04;AI6,quantization;model_compression,library,Python,https://github.com/IST-DASLab/qmoe,,Apache-2.0,moe;quantization;model-compression
723,InferenceMAX,Continuous inference benchmarking tool for LLM hardware,"A benchmarking tool for evaluating large language model inference performance across various hardware accelerators (NVIDIA, AMD, TPU).",AI6-04;AI6,benchmarking;performance_analysis,workflow,Python,https://github.com/InferenceMAX/InferenceMAX,,Apache-2.0,benchmarking;llm-inference;hardware-evaluation
724,TriForce,Lossless acceleration for long sequence generation,"A system for accelerating long sequence generation in LLMs using Hierarchical Speculative Decoding, maintaining lossless quality.",AI6-04;AI6,inference_acceleration;speculative_decoding,library,Python,https://github.com/Infini-AI-Lab/TriForce,,None,llm-acceleration;speculative-decoding;long-sequence
725,NLP Architect,Intel's library for NLP model optimization and exploration,A library by Intel Labs for exploring state-of-the-art deep learning topologies and optimization techniques specifically for Natural Language Processing.,AI6-04;AI6,model_optimization;nlp_modeling,library,Python,https://github.com/IntelLabs/nlp-architect,http://nlp_architect.nervanasys.com/,Apache-2.0,nlp;optimization;intel;deep-learning
726,LMDeploy,"Toolkit for compressing, deploying, and serving LLMs","A comprehensive toolkit for the efficient compression, deployment, and serving of Large Language Models, supporting high-throughput inference.",AI6-04;AI6,model_deployment;inference_serving;compression,platform,Python,https://github.com/InternLM/lmdeploy,,Apache-2.0,llm-serving;deployment;compression;inference
727,Neural-Net-LabView-DLL,Deep Learning library for LabView integration,"A C++-based library enabling the execution of feed-forward neural networks within the LabView environment, facilitating deep learning integration in experimental setups.",AI6-04;AI6,inference_integration;data_acquisition,library,C++,https://github.com/JamesGlare/Neural-Net-LabView-DLL,,MIT,labview;neural-network;integration;experimental-physics
728,Jittor,High-performance JIT-based deep learning framework,"A deep learning framework based on JIT compiling and meta-operators, designed for high performance and easy optimization.",AI6-04;AI6,deep_learning_framework;jit_compilation,platform,Python,https://github.com/Jittor/jittor,https://jittor.org/,Apache-2.0,deep-learning-framework;jit;compiler
729,Kernel Tuner,Auto-tuning tool for GPU kernels,"A tool for automatically tuning and optimizing CUDA, OpenCL, and C code kernels for GPUs, essential for high-performance scientific computing.",AI6-04;AI6,kernel_tuning;performance_optimization,solver,Python,https://github.com/KernelTuner/kernel_tuner,http://kerneltuner.github.io/kernel_tuner/,Apache-2.0,auto-tuning;gpu;cuda;opencl
730,fastT5,Inference acceleration library for T5 models,"A library to boost the inference speed of T5 models by converting them to ONNX Runtime and quantizing them, reducing model size and latency.",AI6-04;AI6,inference_acceleration;model_optimization,library,Python,https://github.com/Ki6an/fastT5,,Apache-2.0,t5;onnx;quantization;inference
731,LMCache,High-performance KV cache storage backend for LLM inference acceleration,"LMCache is a specialized cache layer designed to accelerate Large Language Model (LLM) inference by optimizing Key-Value (KV) cache management. It supports sharing KV caches across different inference engines and instances, significantly reducing latency and improving throughput for distributed LLM serving.",AI6;AI6-04,inference_acceleration;memory_optimization,library,Python,https://github.com/LMCache/LMCache,,Apache-2.0,llm;kv-cache;inference-optimization
732,ocaml-xla,OCaml bindings for the XLA (Accelerated Linear Algebra) compiler,"This library provides OCaml bindings for Google's XLA (Accelerated Linear Algebra) compiler, enabling OCaml developers to leverage high-performance machine learning compilation and hardware acceleration (GPU/TPU).",AI6;AI6-04,compiler_binding;model_compilation,library,OCaml,https://github.com/LaurentMazare/ocaml-xla,,MIT,xla;ocaml;compiler;acceleration
733,ug,Experimental deep learning compiler written in Rust,"ug is an experimental compiler for deep learning models, written in Rust. It aims to provide a testbed for exploring compilation techniques and optimizations for neural network inference and training.",AI6;AI6-04,model_compilation,solver,Rust,https://github.com/LaurentMazare/ug,,Apache-2.0,compiler;rust;deep-learning
734,xla-rs,Rust bindings for the XLA compiler,"xla-rs provides Rust bindings for the XLA compiler, allowing Rust programs to construct and execute XLA computations for accelerated linear algebra and machine learning tasks.",AI6;AI6-04,compiler_binding;model_compilation,library,Rust,https://github.com/LaurentMazare/xla-rs,,Apache-2.0,rust;xla;compiler
735,AutoGPTQ.tvm,TVM kernel implementation for GPTQ quantization inference,"This project provides a TVM (Tensor Virtual Machine) kernel implementation for GPTQ (Generative Pre-trained Transformer Quantization), enabling efficient inference of quantized LLMs using the TVM compiler stack.",AI6;AI6-04,quantization_inference;kernel_optimization,library,Cuda,https://github.com/LeiWang1999/AutoGPTQ.tvm,,None,tvm;gptq;quantization;cuda
736,FusedKernelLibrary,Library for user-defined GPU kernel fusion,"FusedKernelLibrary implements a methodology allowing users to define and execute fused GPU kernels without writing raw CUDA code, optimizing memory bandwidth and execution speed for custom operations.",AI6;AI6-04,kernel_optimization;gpu_acceleration,library,C++,https://github.com/Libraries-Openly-Fused/FusedKernelLibrary,,Apache-2.0,kernel-fusion;gpu;cuda;optimization
737,lit-llama,Optimized implementation of LLaMA for training and fine-tuning,"lit-llama is a clean, optimized implementation of the LLaMA language model based on nanoGPT. It supports advanced features like Flash Attention, Int8/GPTQ quantization, LoRA, and LLaMA-Adapter for efficient pre-training and fine-tuning.",AI6;AI6-04,model_training;model_finetuning;quantization,library,Python,https://github.com/Lightning-AI/lit-llama,,Apache-2.0,llama;finetuning;quantization;lora
738,TensorRT-For-YOLO-Series,TensorRT deployment toolkit for YOLO object detection models,"A comprehensive toolkit for deploying various versions of YOLO (v5-v11, X) using NVIDIA TensorRT. It includes C++ and Python implementations for efficient inference acceleration and NMS plugin support.",AI6;AI6-04,inference_acceleration;object_detection,library,Python,https://github.com/Linaom1214/TensorRT-For-YOLO-Series,,None,tensorrt;yolo;inference;object-detection
739,Lux.jl,Explicit parameter deep learning framework for Julia,"Lux.jl is a Julia deep learning framework that emphasizes explicit parameter handling and functional design, making it highly suitable for scientific machine learning (SciML) and integration with differential equation solvers.",AI6;AI6-04,deep_learning_framework;scientific_modeling,library,Julia,https://github.com/LuxDL/Lux.jl,https://lux.csail.mit.edu/,MIT,julia;deep-learning;sciml
740,mpeg-pcc-tmc13,Reference software for Geometry-based Point Cloud Compression (G-PCC),"The official reference software implementation for the MPEG Geometry-based Point Cloud Compression (G-PCC) standard, providing encoder and decoder tools for scientific and industrial point cloud data.",AI6;AI6-04,data_compression;point_cloud_processing,solver,C++,https://github.com/MPEGGroup/mpeg-pcc-tmc13,,NOASSERTION,point-cloud;compression;mpeg;g-pcc
741,mpeg-pcc-tmc2,Reference software for Video-based Point Cloud Compression (V-PCC),"The official reference software implementation for the MPEG Video-based Point Cloud Compression (V-PCC) standard, enabling compression of dynamic point clouds by projecting them onto 2D video frames.",AI6;AI6-04,data_compression;point_cloud_processing,solver,C++,https://github.com/MPEGGroup/mpeg-pcc-tmc2,,NOASSERTION,point-cloud;compression;mpeg;v-pcc
742,NNPACK,High-performance neural network inference acceleration package for multi-core CPUs,"NNPACK is an acceleration package for neural network computations, optimized for multi-core CPUs. It provides high-performance implementations of convolution, pooling, and matrix multiplication operations.",AI6;AI6-04,inference_acceleration;cpu_optimization,library,C,https://github.com/Maratyszcza/NNPACK,,BSD-2-Clause,acceleration;cpu;neural-network;optimization
743,volksdep,Toolbox for deploying and accelerating models with TensorRT,"volksdep is an open-source toolbox designed to simplify the deployment and acceleration of PyTorch, ONNX, and TensorFlow models using TensorRT, providing a unified interface for inference optimization.",AI6;AI6-04,inference_deployment;model_conversion,library,Python,https://github.com/Media-Smart/volksdep,,Apache-2.0,tensorrt;deployment;inference;acceleration
744,YOLOX,High-performance anchor-free YOLO object detection library,"YOLOX is a high-performance, anchor-free object detection model family. It supports multiple deployment backends including ONNX, TensorRT, ncnn, and OpenVINO, making it suitable for scientific image analysis and real-time detection tasks.",AI6;AI6-04,object_detection;inference_acceleration,library,Python,https://github.com/Megvii-BaseDetection/YOLOX,https://yolox.readthedocs.io/,Apache-2.0,object-detection;yolo;computer-vision
745,TensorFrost,Static optimizing tensor compiler with Python frontend,TensorFrost is a static optimizing tensor compiler that provides a Python frontend and autodifferentiation capabilities. It aims to offer a shader-like syntax for high-performance tensor computations.,AI6;AI6-04,tensor_compiler;autodifferentiation,library,C++,https://github.com/MichaelMoroz/TensorFrost,,MIT,compiler;tensor;optimization
746,modalities,PyTorch-native framework for distributed foundation model training,Modalities is a framework designed for the distributed and reproducible training of foundation models. It leverages PyTorch native components to provide a modular and scalable training infrastructure.,AI6;AI6-04,distributed_training;model_training,framework,Python,https://github.com/Modalities/modalities,,MIT,distributed-training;pytorch;foundation-models
747,GPTQModel,LLM quantization toolkit with multi-backend hardware acceleration,"GPTQModel is a toolkit for quantizing Large Language Models (LLMs) using GPTQ. It supports hardware acceleration for NVIDIA CUDA, AMD ROCm, Intel XPU, and CPUs, integrating with HF, vLLM, and SGLang.",AI6;AI6-04,model_quantization;inference_acceleration,library,Python,https://github.com/ModelCloud/GPTQModel,,NOASSERTION,quantization;gptq;llm;acceleration
748,EasyLLM,Usability-focused LLM training framework based on Megatron-Deepspeed,EasyLLM is a training framework built upon Megatron-Deepspeed and HuggingFace Trainer. It simplifies the complexity of distributed training for Large Language Models while maintaining high efficiency.,AI6;AI6-04,model_training;distributed_training,framework,Python,https://github.com/ModelTC/EasyLLM,,Apache-2.0,llm;training;megatron-deepspeed
749,LightCompress,Toolkit for compressing large language and vision models,"LightCompress is a toolkit dedicated to the compression of large models, including LLMs, VLMs, and video generation models. It implements techniques to reduce model size and improve inference efficiency.",AI6;AI6-04,model_compression;quantization,library,Python,https://github.com/ModelTC/LightCompress,,Apache-2.0,compression;llm;vlm
750,MQBench,Benchmark framework for model quantization algorithms,MQBench is a comprehensive benchmark framework for evaluating model quantization techniques. It allows researchers to assess the performance and accuracy of different quantization algorithms on various models.,AI6;AI6-04,quantization_benchmark;model_evaluation,library,Python,https://github.com/ModelTC/MQBench,,Apache-2.0,quantization;benchmark;deep-learning
751,LARS-ImageNet-PyTorch,LARS optimizer implementation for large batch training,"This repository provides a PyTorch implementation of the LARS (Layer-wise Adaptive Rate Scaling) optimizer, designed for large batch training of deep learning models (e.g., ResNet on ImageNet) in distributed environments.",AI6;AI6-04,optimization_algorithm;distributed_training,library,Python,https://github.com/NUS-HPC-AI-Lab/LARS-ImageNet-PyTorch,,MIT,optimizer;lars;distributed-training
752,torch2trt,Easy-to-use PyTorch to TensorRT converter,"torch2trt is a Python library that simplifies the conversion of PyTorch models to NVIDIA TensorRT engines, enabling easy acceleration of inference on NVIDIA GPUs.",AI6;AI6-04,model_conversion;inference_acceleration,library,Python,https://github.com/NVIDIA-AI-IOT/torch2trt,,MIT,pytorch;tensorrt;converter
753,trt_pose,Real-time pose estimation accelerated with TensorRT,"trt_pose provides tools for training and deploying real-time human pose estimation models accelerated by NVIDIA TensorRT, suitable for computer vision and behavioral analysis tasks.",AI6;AI6-04,pose_estimation;inference_acceleration,library,Python,https://github.com/NVIDIA-AI-IOT/trt_pose,,MIT,pose-estimation;tensorrt;computer-vision
754,isaac_ros_object_detection,NVIDIA-accelerated object detection package for ROS,"This package provides NVIDIA-accelerated deep learning model support for object detection within the ROS (Robot Operating System) ecosystem, enabling high-performance vision for robotics applications.",AI6;AI6-04,object_detection;robotics_inference,library,C++,https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_object_detection,,Apache-2.0,ros;object-detection;isaac;robotics
755,Model-Optimizer,Unified library for SOTA model optimization techniques,"NVIDIA Model-Optimizer is a library containing state-of-the-art techniques for model optimization, including quantization, pruning, distillation, and speculative decoding, to compress models for efficient deployment.",AI6;AI6-04,model_optimization;quantization;pruning,library,Python,https://github.com/NVIDIA/Model-Optimizer,,Apache-2.0,optimization;quantization;pruning;distillation
756,Stable-Diffusion-WebUI-TensorRT,TensorRT acceleration extension for Stable Diffusion Web UI,"This extension integrates NVIDIA TensorRT into the Stable Diffusion Web UI, providing significant inference speedups for generative AI image synthesis tasks.",AI6;AI6-04,inference_acceleration;image_synthesis,plugin,Python,https://github.com/NVIDIA/Stable-Diffusion-WebUI-TensorRT,,MIT,stable-diffusion;tensorrt;acceleration;generative-ai
757,TensorRT,SDK for high-performance deep learning inference on NVIDIA GPUs,NVIDIA TensorRT is a high-performance deep learning inference SDK. It includes a deep learning inference optimizer and runtime that delivers low latency and high throughput for deep learning inference applications.,AI6;AI6-04,inference_acceleration;model_optimization,platform,C++,https://github.com/NVIDIA/TensorRT,https://developer.nvidia.com/tensorrt,Apache-2.0,inference;gpu;optimization;sdk
758,TensorRT-LLM,Library for optimizing and executing Large Language Models on NVIDIA GPUs,"TensorRT-LLM provides a comprehensive Python API and C++ runtime for defining, optimizing, and executing Large Language Models (LLMs) on NVIDIA GPUs, incorporating state-of-the-art techniques for efficient inference.",AI6;AI6-04,inference_acceleration;llm_optimization,library,Python,https://github.com/NVIDIA/TensorRT-LLM,,NOASSERTION,llm;tensorrt;inference;gpu
759,apex,PyTorch extension for mixed precision and distributed training,"A PyTorch extension that provides tools for easy mixed precision and distributed training, enabling faster training times and lower memory usage for deep learning models.",AI6;AI6-04,training_acceleration;mixed_precision,library,Python,https://github.com/NVIDIA/apex,https://nvidia.github.io/apex/,BSD-3-Clause,pytorch;mixed-precision;distributed-training
760,nvvl,Hardware-accelerated video loading library for ML training,"A library that leverages hardware acceleration to load sequences of video frames, facilitating efficient machine learning training by offloading video decoding to the GPU.",AI6;AI6-04,data_loading;video_processing,library,C++,https://github.com/NVIDIA/nvvl,,NOASSERTION,video-loading;gpu-acceleration;machine-learning
761,Fast-dLLM,Training-free acceleration framework for Diffusion LLMs,"An acceleration framework for Diffusion Language Models that enables KV Cache and Parallel Decoding without the need for retraining, improving inference speed.",AI6;AI6-04,inference_acceleration;diffusion_models,library,Python,https://github.com/NVlabs/Fast-dLLM,,Apache-2.0,diffusion-llm;acceleration;kv-cache
762,he-transformer,Homomorphic Encryption backend for Intel nGraph,"A tool enabling deep learning with Homomorphic Encryption (HE) through the Intel nGraph compiler, allowing computation on encrypted data.",AI6;AI6-04,privacy_preserving_computation;compiler_backend,library,C++,https://github.com/NervanaSystems/he-transformer,,Apache-2.0,homomorphic-encryption;ngraph;privacy
763,Tengine,"Lite, high-performance modular inference engine for embedded devices","A modular and high-performance inference engine designed for embedded devices, supporting various AI models and hardware backends.",AI6;AI6-04,inference_engine;embedded_ai,solver,C++,https://github.com/OAID/Tengine,http://tengine.openailab.com/,Apache-2.0,inference-engine;embedded;edge-ai
764,GRAT,Training-free acceleration for Diffusion Transformers,"A tool implementing 'Grouping First, Attending Smartly' to accelerate Diffusion Transformers without retraining, optimizing the attention mechanism.",AI6;AI6-04,inference_acceleration;diffusion_transformers,library,Python,https://github.com/OliverRensu/GRAT,,None,acceleration;diffusion-models;transformer
765,BMCook,Model compression toolkit for large language models,"A toolkit designed for compressing big models through techniques like quantization, pruning, and distillation to reduce resource consumption.",AI6;AI6-04,model_compression;quantization,library,Python,https://github.com/OpenBMB/BMCook,,Apache-2.0,model-compression;llm;quantization
766,UltraRAG,Low-code framework for building RAG pipelines,"A framework for constructing complex Retrieval-Augmented Generation (RAG) pipelines, facilitating the integration of external knowledge into LLMs.",AI6,rag_pipeline;knowledge_retrieval,framework,Python,https://github.com/OpenBMB/UltraRAG,,Apache-2.0,rag;llm;pipeline
767,llm-inference,Platform for managing and deploying LLM inference,"A platform providing out-of-the-box features for LLM model deployment, auto-scaling, and computing resource management.",AI6;AI6-04,inference_serving;resource_management,platform,Python,https://github.com/OpenCSGs/llm-inference,,Apache-2.0,llm-serving;inference;deployment
768,EfficientQAT,Efficient Quantization-Aware Training for LLMs,"A tool for performing efficient Quantization-Aware Training (QAT) on Large Language Models, enabling high-performance low-bit inference.",AI6;AI6-04,quantization;model_training,library,Python,https://github.com/OpenGVLab/EfficientQAT,,None,qat;quantization;llm
769,VideoChat-Flash,Hierarchical compression tool for long-context video modeling,A tool implementing hierarchical compression techniques to enable efficient modeling of long-context videos.,AI6;AI6-04,video_modeling;data_compression,library,Python,https://github.com/OpenGVLab/VideoChat-Flash,,MIT,video-understanding;compression;long-context
770,CoLLiE,Framework for collaborative training of Large Language Models,"A library designed to facilitate efficient and collaborative training of Large Language Models, optimizing resource usage and training speed.",AI6;AI6-04,distributed_training;llm_training,framework,Python,https://github.com/OpenMOSS/CoLLiE,,Apache-2.0,llm;distributed-training;optimization
771,CTranslate2,Fast inference engine for Transformer models,"A C++ and Python library for efficient inference with Transformer models, supporting weights quantization and hardware acceleration.",AI6;AI6-04,inference_engine;transformer_acceleration,solver,C++,https://github.com/OpenNMT/CTranslate2,https://opennmt.net/CTranslate2/,MIT,inference;transformer;quantization
772,simple-onnx-processing-tools,Tools for ONNX model manipulation and optimization,"A collection of utilities for splitting, merging, compressing, and modifying ONNX models to facilitate deployment and inference optimization.",AI6;AI6-04,model_optimization;onnx_manipulation,library,Python,https://github.com/PINTO0309/simple-onnx-processing-tools,,MIT,onnx;model-optimization;tools
773,tflite2tensorflow,Model converter for TFLite to various formats,"A tool to generate saved_model, ONNX, OpenVINO, and other formats from .tflite files, supporting quantization and inverse quantization.",AI6;AI6-04,model_conversion;interoperability,library,Python,https://github.com/PINTO0309/tflite2tensorflow,,MIT,model-conversion;tflite;onnx
774,safe-rlhf,Framework for constrained value alignment via Safe RLHF,A framework implementing Safe Reinforcement Learning from Human Feedback to ensure AI model alignment with safety constraints.,AI6,safety_alignment;rlhf,framework,Python,https://github.com/PKU-Alignment/safe-rlhf,https://safe-rlhf.readthedocs.io/,Apache-2.0,safety;alignment;rlhf
775,LLM-boost-recognition,OCR and Voice Recognition module with LLM correction,"A module for converting documents and audio into text using OCR and voice recognition, enhanced by LLM-based correction and GPU acceleration.",AI6;AI6-04,data_ingestion;ocr;speech_recognition,library,Python,https://github.com/PStarH/LLM-boost-recognition,,GPL-3.0,ocr;voice-recognition;data-processing
776,FastDeploy,High-performance inference and deployment toolkit,"A toolkit for the inference and deployment of Large Language Models (LLMs) and Vision-Language Models (VLMs), supporting multiple backends and hardware.",AI6;AI6-04,inference_deployment;model_serving,library,Python,https://github.com/PaddlePaddle/FastDeploy,https://github.com/PaddlePaddle/FastDeploy,Apache-2.0,deployment;inference;paddlepaddle
777,PARL,High-performance distributed reinforcement learning framework,"A flexible and high-performance framework for distributed Reinforcement Learning, built on PaddlePaddle.",AI6,reinforcement_learning;distributed_training,framework,Python,https://github.com/PaddlePaddle/PARL,https://parl.readthedocs.io/,Apache-2.0,reinforcement-learning;distributed-system;paddlepaddle
778,PaddleNLP,NLP library for LLMs and SLMs,A comprehensive Natural Language Processing library providing easy-to-use interfaces for Large Language Models and Small Language Models.,AI6,nlp_modeling;text_processing,library,Python,https://github.com/PaddlePaddle/PaddleNLP,https://paddlenlp.readthedocs.io/,Apache-2.0,nlp;llm;paddlepaddle
779,PaddleSlim,Deep model compression and architecture search library,"A library for deep learning model compression, including quantization, pruning, distillation, and neural architecture search.",AI6;AI6-04,model_compression;nas,library,Python,https://github.com/PaddlePaddle/PaddleSlim,https://paddleslim.readthedocs.io/,Apache-2.0,compression;quantization;pruning
780,PERSIA,Distributed framework for training recommendation models,"A high-performance distributed training framework specifically optimized for deep learning recommendation models, based on PyTorch.",AI6,recommendation_systems;distributed_training,framework,Rust,https://github.com/PersiaML/PERSIA,https://persiaml-tutorials.readthedocs.io/,MIT,recommendation;distributed-training;pytorch
781,NeuralSolvers,Neural network based solvers for PDEs,A library implementing physics-informed neural networks (PINNs) and other neural solvers for partial differential equations and inverse problems.,AI6,pde_solver;scientific_modeling,solver,Python,https://github.com/Photon-AI-Research/NeuralSolvers,,MIT,pinn;pde;scientific-computing
782,OpenDiloco,Framework for globally distributed low-communication training,"An open-source framework enabling efficient, globally distributed training of AI models with low communication overhead.",AI6;AI6-04,distributed_training;communication_optimization,framework,Python,https://github.com/PrimeIntellect-ai/OpenDiloco,,Apache-2.0,distributed-training;decentralized-ai;optimization
783,prime-diloco,Framework for globally distributed AI model training,A framework designed for efficient training of AI models across globally distributed compute resources over the internet.,AI6;AI6-04,distributed_training;decentralized_computing,framework,Python,https://github.com/PrimeIntellect-ai/prime-diloco,,Apache-2.0,distributed-training;infrastructure;ai
784,tensornet,Distributed training framework for sparse data,"A TensorFlow-based distributed training framework optimized for large-scale sparse data, often used in recommendation and search ranking.",AI6,distributed_training;sparse_data_processing,framework,C++,https://github.com/Qihoo360/tensornet,,Apache-2.0,distributed-training;tensorflow;sparse-data
785,QizNLP,Tensorflow-based NLP task framework,"A framework for quickly running various NLP tasks such as classification, sequence labeling, and matching, with support for distributed training.",AI6,nlp_workflow;model_training,framework,Python,https://github.com/Qznan/QizNLP,,MPL-2.0,nlp;tensorflow;distributed-training
786,TritonForge,LLM-powered GPU kernel synthesis tool,"A tool that uses LLMs to synthesize optimized Triton kernels from PyTorch operations, facilitating custom operator acceleration.",AI6;AI6-04,kernel_synthesis;code_generation,tool,Python,https://github.com/RLsys-Foundation/TritonForge,,None,triton;gpu-kernel;compiler
787,rwkv.cpp,CPU inference engine for RWKV models,"A high-performance CPU inference implementation for RWKV language models, supporting various quantization formats (INT4/INT5/INT8).",AI6;AI6-04,inference_engine;cpu_acceleration,solver,C++,https://github.com/RWKV/rwkv.cpp,,MIT,inference;rwkv;quantization
788,Model Compression Toolkit (MCT),Advanced quantization and compression tools for neural network optimization on constrained hardware,"An open-source project by Sony Semiconductor Solutions providing researchers and developers with tools for neural network model optimization, specifically focusing on quantization and compression to enable efficient deployment on hardware with constraints.",AI6;AI6-04,quantization;model_compression,library,Python,https://github.com/SonySemiconductorSolutions/mct-model-optimization,,Apache-2.0,quantization;model-compression;neural-network;optimization
789,YOLO-ModelCompression,"Framework for YOLO model compression, multi-dataset training, and multi-backbone support","A comprehensive framework designed for compressing YOLO series models (v3/v4), supporting advanced features like multi-dataset training, pruning, and quantization to optimize models for deployment.",AI6;AI6-04,model_compression;training_optimization,workflow,Python,https://github.com/SpursLipu/YOLOv3v4-ModelCompression-MultidatasetTraining-Multibackbone,,GPL-3.0,yolo;model-compression;pruning;quantization
790,Mobile-YOLOv5-Pruning-Distillation,Toolkit for pruning and distilling YOLOv5 models for efficient mobile deployment,"A specialized toolkit for optimizing YOLOv5 models through pruning and knowledge distillation, specifically targeting mobile deployment with support for NCNN and TensorRT export.",AI6;AI6-04,model_compression;pruning;distillation,workflow,Jupyter Notebook,https://github.com/Syencil/mobile-yolov5-pruning-distillation,,MIT,yolov5;pruning;knowledge-distillation;ncnn;tensorrt
791,Oobleck,Resilient distributed training framework for large models,"A distributed training framework designed to be resilient to faults, enabling robust and efficient training of large language models by handling node failures and topology changes dynamically.",AI6,distributed_training;fault_tolerance,platform,Python,https://github.com/SymbioticLab/Oobleck,,Apache-2.0,distributed-training;fault-tolerance;llm;hpc
792,Torch-Model-Compression,Automated toolset for analyzing and compressing PyTorch models,"A toolset developed by THU-MIG for automated model structure analysis and modification, providing a library of compression algorithms to optimize PyTorch models for efficiency.",AI6;AI6-04,model_compression;model_analysis,library,Python,https://github.com/THU-MIG/torch-model-compression,,MIT,pytorch;model-compression;automation;optimization
793,lyraDiff,Inference acceleration engine for Diffusion and DiT models,"An out-of-the-box inference acceleration engine specifically optimized for Diffusion and Diffusion Transformer (DiT) models, aiming to speed up generative AI tasks.",AI6;AI6-04,inference_acceleration;generative_ai,solver,C++,https://github.com/TMElyralab/lyraDiff,,Apache-2.0,diffusion-models;inference-acceleration;dit;generative-ai
794,AngelSlim,Comprehensive model compression toolkit for enhanced usability and efficiency,"A model compression toolkit from Tencent designed to improve the usability and efficiency of deploying AI models, offering a range of compression techniques.",AI6;AI6-04,model_compression;deployment,library,Python,https://github.com/Tencent/AngelSlim,,NOASSERTION,model-compression;tencent;optimization;deployment
795,PocketFlow,Automatic Model Compression (AutoMC) framework,"An open-source framework for Automatic Model Compression (AutoMC) developed by Tencent, enabling developers to create smaller and faster AI applications with minimal human effort.",AI6;AI6-04,model_compression;automl,framework,Python,https://github.com/Tencent/PocketFlow,,NOASSERTION,automc;model-compression;automl;optimization
796,TNN,High-performance deep learning inference framework for mobile and edge,"A uniform deep learning inference framework developed by Tencent Youtu Lab, optimized for mobile, desktop, and server platforms, featuring high performance, cross-platform support, and model compression capabilities.",AI6;AI6-04,inference_engine;edge_computing,platform,C++,https://github.com/Tencent/TNN,,NOASSERTION,inference-framework;mobile-ai;edge-computing;ncnn
797,OnnxStack,.NET library for running Stable Diffusion and AI models via ONNX Runtime,"A library that enables the execution of Stable Diffusion and other deep learning models within the .NET ecosystem using ONNX Runtime, facilitating inference integration in Windows applications.",AI6;AI6-04,inference_runtime;generative_ai,library,C#,https://github.com/TensorStack-AI/OnnxStack,,Apache-2.0,onnx;stable-diffusion;dotnet;inference
798,PyTorch-YOLOv4,PyTorch implementation of YOLOv4 with ONNX and TensorRT support,"A widely used PyTorch implementation of the YOLOv4 object detection model, including tools for training, inference, and conversion to ONNX and TensorRT for accelerated deployment.",AI6;AI6-04,object_detection;model_implementation,library,Python,https://github.com/Tianxiaomo/pytorch-YOLOv4,,Apache-2.0,yolov4;pytorch;tensorrt;onnx;object-detection
799,Frame_Extractor,Automated video scene detection and frame extraction tool for datasets,"A utility tool that automatically detects scenes in videos and extracts the sharpest frames, optimized for preparing high-quality image datasets for training AI models (e.g., LoRA fine-tuning).",AI6,data_preparation;dataset_creation,solver,Python,https://github.com/Tranchillo/Frame_Extractor,,MIT,dataset-preparation;video-processing;frame-extraction;lora
800,AQLM,Extreme compression of Large Language Models via Additive Quantization,"AQLM (Additive Quantization for Language Models) is a library and method for extreme compression of LLMs, enabling efficient inference on consumer hardware while maintaining high accuracy.",AI6;AI6-04,quantization;model_compression,library,Python,https://github.com/Vahe1994/AQLM,https://arxiv.org/pdf/2401.06118.pdf,Apache-2.0,quantization;llm;compression;inference-acceleration
801,FasterCache,Training-free acceleration for video diffusion models,FasterCache is a training-free acceleration tool for video diffusion models that utilizes caching mechanisms to speed up inference while maintaining high generation quality.,AI6;AI6-04,inference_acceleration;generative_model_optimization,library,Python,https://github.com/Vchitect/FasterCache,,None,diffusion-models;video-generation;acceleration;caching
802,voltaML,Lightweight library for accelerating ML/DL models on high-performance runtimes,"VoltaML is a library designed to convert and run machine learning and deep learning models on high-performance inference runtimes such as TensorRT, TorchScript, ONNX, and TVM, optimizing them for speed.",AI6;AI6-04,inference_acceleration;model_conversion,library,Python,https://github.com/VoltaML/voltaML,,Apache-2.0,tensorrt;onnx;inference;acceleration
803,Fast3Dcache,Training-free acceleration for 3D geometry synthesis,"Fast3Dcache provides a training-free method to accelerate 3D geometry synthesis, optimizing the inference process for 3D generative models.",AI6;AI6-04,inference_acceleration;3d_synthesis,library,Jupyter Notebook,https://github.com/Westlake-AGI-Lab/Fast3Dcache,,MIT,3d-generation;acceleration;geometry-synthesis
804,Q-Diffusion,Quantization framework for diffusion models,Q-Diffusion is a tool for quantizing diffusion models to reduce their memory footprint and accelerate inference without significant loss in generation quality.,AI6;AI6-04,quantization;model_compression,library,Python,https://github.com/Xiuyu-Li/q-diffusion,,MIT,diffusion-models;quantization;compression
805,native-sparse-attention-triton,Efficient Triton implementation of Native Sparse Attention,"This repository provides an optimized implementation of Native Sparse Attention using OpenAI Triton, serving as a kernel-level acceleration tool for transformer models.",AI6;AI6-04,kernel_optimization;inference_acceleration,library,Python,https://github.com/XunhaoLai/native-sparse-attention-triton,,Apache-2.0,triton;sparse-attention;cuda;optimization
806,DashGaussian,Acceleration method for 3D Gaussian Splatting training,"DashGaussian implements a powerful acceleration method for training 3D Gaussian Splatting (3DGS) models, significantly reducing training time for 3D scene reconstruction.",AI6;AI6-04,training_acceleration;3d_reconstruction,solver,C++,https://github.com/YouyuChen0207/DashGaussian,,NOASSERTION,3d-gaussian-splatting;acceleration;rendering
807,KVCache-Factory,Unified KV Cache compression methods for auto-regressive models,KVCache-Factory is a unified framework providing various KV cache compression methods to accelerate inference and reduce memory usage for large language models.,AI6;AI6-04,inference_acceleration;memory_optimization,library,Python,https://github.com/Zefan-Cai/KVCache-Factory,,MIT,kv-cache;llm;compression;inference
808,R-KV,Redundancy-aware KV Cache compression for reasoning models,"R-KV implements a redundancy-aware KV cache compression technique specifically designed for reasoning models, optimizing memory efficiency during long-context inference.",AI6;AI6-04,inference_acceleration;memory_optimization,library,Python,https://github.com/Zefan-Cai/R-KV,,None,kv-cache;llm;reasoning;compression
809,deepC,Vendor-independent TinyML deep learning compiler and inference framework,"deepC is a deep learning compiler and inference framework designed for microcomputers and microcontrollers, enabling vendor-independent TinyML model deployment.",AI6;AI6-04,compiler;inference_deployment,library,C++,https://github.com/ai-techsystems/deepC,https://deepc.ai,Apache-2.0,tinyml;compiler;embedded-ai;inference
810,AidLearning-FrameWork,AIoT development platform for Linux on Android,"AidLearning is a mobile AI development platform that provides a Linux environment on Android with support for GUI, deep learning inference acceleration (CPU/GPU/NPU), and visual IDEs.",AI6;AI6-04,inference_platform;edge_computing,platform,Python,https://github.com/aidlearning/AidLearning-FrameWork,http://www.aidlearning.net,NOASSERTION,android;linux;aiot;inference
811,EasyParallelLibrary,General and efficient deep learning framework for distributed model training,"Easy Parallel Library (EPL) is a framework designed to simplify and accelerate distributed model training for deep learning, providing efficient parallelization strategies.",AI6;AI6-04,distributed_training;parallel_computing,library,Python,https://github.com/alibaba/EasyParallelLibrary,,Apache-2.0,distributed-training;parallelism;deep-learning
812,TePDist,HLO-level automatic distributed system for DL models,TePDist (TEnsor Program DISTributed) is an automatic distributed system that operates at the HLO (High Level Optimizer) level to optimize deep learning models for distributed execution.,AI6;AI6-04,distributed_training;compiler_optimization,library,C++,https://github.com/alibaba/TePDist,,Apache-2.0,distributed-systems;compiler;hlo;deep-learning
813,TinyNeuralNetwork,Efficient deep learning model compression framework,"TinyNeuralNetwork is a framework focused on deep learning model compression, offering tools for quantization, pruning, and optimization to enable efficient deployment on resource-constrained devices.",AI6;AI6-04,model_compression;quantization,library,Python,https://github.com/alibaba/TinyNeuralNetwork,,MIT,model-compression;quantization;tinyml;optimization
814,PainlessInferenceAcceleration,Tool for simplified inference acceleration,"PainlessInferenceAcceleration provides a streamlined workflow and tools to accelerate deep learning model inference with minimal user effort, supporting various backends.",AI6;AI6-04,inference_acceleration;model_optimization,library,Python,https://github.com/alipay/PainlessInferenceAcceleration,,MIT,inference;acceleration;optimization
815,cONNXr,Pure C ONNX runtime for embedded devices,"cONNXr is a lightweight, zero-dependency ONNX runtime written in pure C, specifically designed for running inference on embedded devices.",AI6;AI6-04,inference_runtime;embedded_ai,library,C,https://github.com/alrevuelta/cONNXr,,MIT,onnx;embedded;inference;c
816,GLake,GPU memory management and IO transmission optimization,"GLake is a system tool for optimizing GPU memory management and I/O transmission efficiency, aiming to improve the performance of large-scale model training and inference.",AI6;AI6-04,memory_optimization;io_optimization,library,Python,https://github.com/antgroup/glake,,Apache-2.0,gpu-memory;optimization;io-acceleration
817,nnieqat-pytorch,Quantization aware training tool for NNIE on PyTorch,"nnieqat-pytorch is a quantization-aware training (QAT) tool designed for the HiSilicon NNIE (Neural Network Inference Engine), enabling users to train models compatible with NNIE quantization requirements.",AI6;AI6-04,quantization;model_training,library,Python,https://github.com/aovoc/nnieqat-pytorch,,MIT,quantization;nnie;pytorch;qat
818,TVM,"Open deep learning compiler stack for cpu, gpu and specialized accelerators","Apache TVM is an open source machine learning compiler framework for CPUs, GPUs, and machine learning accelerators. It aims to enable machine learning engineers to optimize and run computations efficiently on any hardware backend.",AI6;AI6-04,compiler;optimization;inference_acceleration,framework,Python,https://github.com/apache/tvm,https://tvm.apache.org/,Apache-2.0,compiler;deep-learning;optimization;inference
819,flux-fp8-api,Flux diffusion model implementation with quantized FP8 acceleration,A specialized implementation of the Flux diffusion model utilizing quantized FP8 matrix multiplication and half-precision accumulation to achieve acceleration on consumer devices.,AI6;AI6-04,quantization;inference_acceleration;image_generation,library,Python,https://github.com/aredden/flux-fp8-api,,Apache-2.0,quantization;fp8;diffusion-model;acceleration
820,torch-bnb-fp4,Accelerated 4-bit FP4 linear operations for PyTorch,"A library providing faster PyTorch bitsandbytes 4-bit FP4 nn.Linear operations, enabling efficient low-bit quantization for neural networks.",AI6;AI6-04,quantization;inference_acceleration,library,Python,https://github.com/aredden/torch-bnb-fp4,,MIT,quantization;fp4;pytorch;acceleration
821,LLM-Inference-Bench,Benchmark suite for Large Language Model inference performance,A benchmarking tool developed by Argonne National Laboratory to evaluate and analyze the inference performance of Large Language Models on various hardware configurations.,AI6;AI6-04,benchmarking;performance_analysis,solver,Jupyter Notebook,https://github.com/argonne-lcf/LLM-Inference-Bench,,BSD-3-Clause,benchmarking;llm;inference;hpc
822,DeepX,Unified framework for large-scale auto-distributed training and inference,A large-scale auto-distributed training and inference unified framework featuring a memory-compute-control decoupled architecture and support for heterogeneous hardware.,AI6;AI6-04,distributed_training;inference;hpc,framework,C++,https://github.com/array2d/deepx,,Apache-2.0,distributed-training;inference;framework;hpc
823,Fine-Tune Codebase,Tool for fine-tuning LLMs on codebases with LoRA and quantization support,"A scalable and efficient tool designed for fine-tuning large language models on codebases, supporting LoRA, mixed precision training, and quantization.",AI6;AI6-04,model_finetuning;training,workflow,Python,https://github.com/ayminovitch/fine-tune-codebase,,MIT,finetuning;llm;lora;quantization
824,TokenSwift,Lossless acceleration method for ultra-long sequence generation,"Implementation of TokenSwift, a method for accelerating ultra-long sequence generation in large language models without loss of quality.",AI6;AI6-04,inference_acceleration;sequence_generation,library,Python,https://github.com/bigai-nlco/TokenSwift,,MIT,acceleration;llm;inference;long-sequence
825,Megatron-DeepSpeed,Large-scale distributed training framework for transformer models,A deep learning library that combines Megatron-LM and DeepSpeed to enable efficient large-scale distributed training of transformer language models.,AI6;AI6-04,distributed_training;hpc;model_training,framework,Python,https://github.com/bigscience-workshop/Megatron-DeepSpeed,,NOASSERTION,distributed-training;transformer;hpc;deepspeed
826,bitsandbytes,"Lightweight wrapper around CUDA custom functions, in particular 8-bit optimizers and quantization","A library that provides accessible large language models via k-bit quantization for PyTorch, including 8-bit optimizers and matrix multiplication routines.",AI6;AI6-04,quantization;optimization;inference_acceleration,library,Python,https://github.com/bitsandbytes-foundation/bitsandbytes,,MIT,quantization;cuda;optimization;pytorch
827,X-LLM,Library for cutting-edge and easy LLM fine-tuning,"A library designed to simplify and accelerate the fine-tuning process of Large Language Models (LLMs), providing cutting-edge techniques.",AI6;AI6-04,model_finetuning;training,library,Python,https://github.com/bobazooba/xllm,,Apache-2.0,finetuning;llm;training
828,QuantVSR,Low-bit post-training quantization for video super-resolution,"PyTorch implementation of QuantVSR, a method for low-bit post-training quantization specifically designed for real-world video super-resolution tasks.",AI6;AI6-04,quantization;super_resolution;image_processing,solver,Python,https://github.com/bowenchai/QuantVSR,,None,quantization;super-resolution;video-processing
829,fastai_xla_extensions,Extensions to run fastai on TPUs using PyTorch-XLA,A Python package that enables the fastai library to utilize TPUs for accelerated training and inference via PyTorch-XLA.,AI6;AI6-04,hardware_acceleration;training;tpu_support,library,Jupyter Notebook,https://github.com/butchland/fastai_xla_extensions,,Apache-2.0,fastai;tpu;xla;acceleration
830,ABQ-LLM,Acceleration library for arbitrary bit-width combinatorial quantization,An acceleration library that supports arbitrary bit-width combinatorial quantization operations for Large Language Models.,AI6;AI6-04,quantization;inference_acceleration,library,C++,https://github.com/bytedance/ABQ-LLM,,Apache-2.0,quantization;acceleration;llm
831,BytePS,High performance and generic framework for distributed DNN training,"A high-performance, generic framework for distributed Deep Neural Network (DNN) training, designed to run on heterogeneous hardware clusters.",AI6;AI6-04,distributed_training;hpc,framework,Python,https://github.com/bytedance/byteps,,NOASSERTION,distributed-training;hpc;deep-learning
832,exprgrad,Differentiable array programming language and DL framework for Nim,"An experimental deep learning framework for the Nim programming language, based on a differentiable array programming approach.",AI6;AI6-04,modeling;training,framework,Nim,https://github.com/can-lehmann/exprgrad,,Apache-2.0,deep-learning;nim;differentiable-programming
833,JEDI,Jetson embedded platform deep learning inference acceleration framework,A deep learning inference acceleration framework specifically targeted for Jetson embedded platforms using TensorRT.,AI6;AI6-04,inference_acceleration;embedded_ai,framework,C++,https://github.com/cap-lab/jedi,,GPL-2.0,jetson;tensorrt;inference;embedded
834,NeuPIMs,NPU-PIM heterogeneous acceleration simulator for batched LLM inferencing,"A framework/simulator for NPU-PIM (Processing-in-Memory) heterogeneous acceleration, specifically optimized for batched Large Language Model inferencing.",AI6;AI6-04,inference_acceleration;hardware_simulation,solver,Jupyter Notebook,https://github.com/casys-kaist/NeuPIMs,,None,pim;acceleration;llm;simulation
835,petit-kernel,Optimized FP16/BF16 x FP4 GPU kernels for AMD GPUs,"A library of optimized GPU kernels for AMD GPUs, supporting FP16/BF16 and FP4 precisions, useful for accelerating low-precision inference.",AI6;AI6-04,kernel_optimization;inference_acceleration,library,C++,https://github.com/causalflow-ai/petit-kernel,,BSD-3-Clause,amd-gpu;kernels;quantization;acceleration
836,flex-nano-vllm,Minimal FlexAttention-based inference engine for Gemma 2,"A minimal, vLLM-style inference engine optimized for fast Gemma 2 inference using FlexAttention.",AI6;AI6-04,inference_engine;acceleration,solver,Python,https://github.com/changjonathanc/flex-nano-vllm,,MIT,inference;vllm;gemma;acceleration
837,llama-dfdx,Rust implementation of LLaMa 7b with CUDA acceleration,A Rust implementation of the LLaMa 7b model featuring CUDA acceleration and optimized for minimal GPU memory usage.,AI6;AI6-04,inference;model_implementation,solver,Rust,https://github.com/chelsea0x3b/llama-dfdx,,MIT,rust;llama;cuda;inference
838,model_compression,Model compression implementation using knowledge distillation,"A repository implementing model compression techniques, specifically focusing on knowledge distillation methods.",AI6;AI6-04,model_compression;knowledge_distillation,library,Python,https://github.com/chengshengchan/model_compression,,None,model-compression;knowledge-distillation
839,PTQ4SAM,Post-Training Quantization for Segment Anything Model,"Implementation of Post-Training Quantization (PTQ) specifically tailored for the Segment Anything Model (SAM), enabling efficient inference.",AI6;AI6-04,quantization;inference_acceleration;computer_vision,solver,Jupyter Notebook,https://github.com/chengtao-lv/PTQ4SAM,,None,quantization;sam;segmentation
840,DDRNet.pytorch,Deep Dual-resolution Networks for real-time semantic segmentation,Implementation of Deep Dual-resolution Networks (DDRNet) for real-time and accurate semantic segmentation of road scenes.,AI6;AI6-04,image_segmentation;model_implementation,solver,Python,https://github.com/chenjun2hao/DDRNet.pytorch,,NOASSERTION,semantic-segmentation;real-time;computer-vision
841,topicGPT,Prompt-based framework for topic modeling,A framework utilizing Large Language Models (LLMs) and prompting techniques to perform topic modeling on text data.,AI6;AI6-04,topic_modeling;text_analysis,framework,Python,https://github.com/chtmp223/topicGPT,,None,topic-modeling;llm;nlp
842,EasyQuant,Efficient post-training quantization method optimizing weights and activations,An efficient and simple post-training quantization (PTQ) tool that optimizes the scales of weights and activations to reduce quantization error. It is designed to facilitate the deployment of deep learning models on low-precision hardware.,AI6-04;Computer Vision,quantization;model_compression,library,Python,https://github.com/deepglint/EasyQuant,,NOASSERTION,quantization;post-training-quantization;cnn;optimization
843,DeepSpeed,Deep learning optimization library for distributed training and inference,"A deep learning optimization library that enables massive-scale distributed training and inference. It provides system innovations like ZeRO (Zero Redundancy Optimizer), 3D parallelism, and sparse attention to improve speed, memory efficiency, and scalability of large models.",AI6;AI6-04,distributed_training;inference_acceleration;memory_optimization,library,Python,https://github.com/deepspeedai/DeepSpeed,https://www.deepspeed.ai,Apache-2.0,distributed-training;optimization;zero-redundancy-optimizer;hpc
844,DeepSpeed-MII,High-throughput and low-latency inference library powered by DeepSpeed,DeepSpeed Model Implementations for Inference (MII) is a library designed to accelerate low-latency and high-throughput inference of large models. It leverages DeepSpeed's inference engine to provide optimized serving solutions.,AI6-04,inference_acceleration;model_serving,library,Python,https://github.com/deepspeedai/DeepSpeed-MII,,Apache-2.0,inference;latency-optimization;throughput;serving
845,tensorRTIntegrate,C++ integration tool for TensorRT inference and ONNX plugin management,"A C++ repository providing tools and examples for integrating TensorRT inference, managing ONNX plugins, and compiling models. It facilitates the deployment of deep learning models using NVIDIA's TensorRT engine.",AI6-04,inference_deployment;model_conversion,library,C++,https://github.com/dlunion/tensorRTIntegrate,,None,tensorrt;onnx;inference;cpp
846,nnvm-fusion,Kernel fusion and runtime compilation module based on NNVM,A library implementing kernel fusion and runtime compilation techniques based on the NNVM (Neural Network Virtual Machine) intermediate representation. It aims to optimize deep learning graph execution.,AI6-04,compiler_optimization;kernel_fusion,library,C++,https://github.com/dmlc/nnvm-fusion,,Apache-2.0,nnvm;compiler;optimization;kernel-fusion
847,Paracel,Distributed training framework implementing the parameter server architecture,A distributed training framework designed to solve large-scale machine learning problems using the parameter server architecture. It supports various ML algorithms and provides a mechanism for efficient data and parameter synchronization.,AI6;HPC,distributed_training,library,C++,https://github.com/douban/paracel,,NOASSERTION,parameter-server;distributed-systems;machine-learning
848,VisDrone-dataset-python-toolkit,Toolkit for processing and using the VisDrone aerial object detection dataset,"A Python toolkit designed to facilitate the use of the VisDrone dataset for aerial object detection. It includes pipelines for training, inference, and format conversion, supporting models like Faster R-CNN and RetinaNet.",Computer Vision;Data Processing,data_processing;object_detection,library,Python,https://github.com/dronefreak/VisDrone-dataset-python-toolkit,,Apache-2.0,visdrone;aerial-imagery;dataset-tools;pytorch
849,gemlite,Library for fast low-bit matrix multiplication kernels using Triton,A library providing optimized low-bit matrix multiplication (matmul) kernels implemented in Triton. It focuses on accelerating quantized neural network operations on GPUs.,AI6-04,quantization;kernel_optimization,library,Python,https://github.com/dropbox/gemlite,,Apache-2.0,triton;matmul;quantization;gpu-acceleration
850,XLand-MiniGrid,JAX-accelerated meta-reinforcement learning environments,"A library of JAX-accelerated reinforcement learning environments inspired by XLand and MiniGrid. It is designed for meta-reinforcement learning research, enabling fast and scalable simulation on hardware accelerators.",Reinforcement Learning;AI6,reinforcement_learning;simulation,library,Python,https://github.com/dunnolab/xland-minigrid,,Apache-2.0,jax;reinforcement-learning;environment;simulation
851,XLand-MiniGrid Datasets,Large-scale multi-task dataset for in-context reinforcement learning,"A large-scale dataset (XLand-100B) designed for multi-task and in-context reinforcement learning research, generated using the XLand-MiniGrid environments.",Reinforcement Learning,reinforcement_learning,dataset,Python,https://github.com/dunnolab/xland-minigrid-datasets,,Apache-2.0,dataset;reinforcement-learning;jax
852,NanoLLM,Optimized local inference library for LLMs and multimodal models on NVIDIA Jetson/Edge,"A lightweight and efficient library for running Large Language Models (LLMs), Vision-Language Models (VLMs), and multimodal agents locally on NVIDIA Jetson and edge devices. It supports quantization (AWQ, GPTQ), multimodal pipelines, and integrates with vector databases for RAG applications.",AI6;AI6-04,inference_acceleration;quantization;edge_computing,library,Python,https://github.com/dusty-nv/NanoLLM,,MIT,llm;edge-ai;quantization;nvidia-jetson
853,jetson-inference,High-performance deep learning inference library for NVIDIA Jetson devices,"A C++ library and collection of utilities for deploying deep learning inference networks (image classification, detection, segmentation, pose estimation) on NVIDIA Jetson devices using TensorRT. It provides optimized primitives for vision tasks and streamlined deployment workflows.",AI6;AI6-04,inference_acceleration;computer_vision;edge_computing,library,C++,https://github.com/dusty-nv/jetson-inference,https://github.com/dusty-nv/jetson-inference/blob/master/docs/html/index.md,MIT,tensorrt;edge-ai;inference;computer-vision
854,ros_deep_learning,Deep learning inference nodes for ROS/ROS2 integration,"Provides ROS and ROS2 nodes that wrap deep learning inference capabilities (using TensorRT and NVIDIA Jetson), enabling robotic systems to perform real-time object detection, classification, and segmentation within the ROS ecosystem.",AI6;AI6-04,robotics_integration;inference_acceleration,library,C++,https://github.com/dusty-nv/ros_deep_learning,,None,ros;ros2;robotics;tensorrt
855,Q-LLM,Query-aware inference acceleration library for Large Language Models,"Implementation of the QuickLLaMA method, focusing on query-aware inference acceleration for LLMs. It provides techniques to optimize the inference process by leveraging query information to reduce computational redundancy.",AI6;AI6-04,inference_acceleration;model_optimization,solver,Python,https://github.com/dvlab-research/Q-LLM,,None,llm;inference;acceleration
856,mixtral-offloading,Efficient offloading inference engine for Mixtral-8x7B models,"A specialized inference tool enabling the execution of large Mixture-of-Experts (MoE) models like Mixtral-8x7B on consumer-grade hardware or limited memory environments (e.g., Colab) through efficient CPU/GPU offloading strategies.",AI6;AI6-04,inference_acceleration;memory_optimization,solver,Python,https://github.com/dvmazur/mixtral-offloading,,MIT,moe;offloading;inference;mixtral
857,Nx,Numerical computing and tensor library for Elixir,"A foundational library for numerical computing in Elixir, providing multi-dimensional arrays (tensors) and automatic differentiation. It serves as the core infrastructure for machine learning and scientific computing within the Elixir ecosystem.",AI6,numerical_computing;tensor_operations,library,Elixir,https://github.com/elixir-nx/nx,https://hexdocs.pm/nx/Nx.html,None,elixir;tensors;numerical-computing
858,Ortex,ONNX Runtime bindings for Elixir,"Provides Elixir bindings for ONNX Runtime, enabling the execution of machine learning models trained in other frameworks (PyTorch, TensorFlow) within Elixir applications for high-performance inference.",AI6;AI6-04,inference_runtime;interoperability,library,Elixir,https://github.com/elixir-nx/ortex,https://hexdocs.pm/ortex,MIT,onnx;elixir;inference
859,XLA (Elixir),XLA (Accelerated Linear Algebra) compiler extension for Elixir Nx,"Integrates Google's XLA compiler with Elixir Nx, allowing tensor operations to be just-in-time compiled to optimized machine code for CPUs, GPUs, and TPUs, significantly accelerating numerical computations.",AI6;AI6-04,compilation;acceleration,library,Elixir,https://github.com/elixir-nx/xla,https://hexdocs.pm/xla,Apache-2.0,xla;compiler;acceleration;elixir
860,tensorflow-serving-arm,Cross-compilation toolkit for TensorFlow Serving on ARM architecture,"A utility project providing scripts and configurations to cross-compile TensorFlow Serving for ARM-based devices (e.g., Raspberry Pi, edge devices), facilitating the deployment of ML models on edge infrastructure.",AI6;AI6-04,deployment;cross_compilation,utility,C++,https://github.com/emacski/tensorflow-serving-arm,,Apache-2.0,tensorflow-serving;arm;cross-compile
861,yolo-tensorrt,TensorRT implementation and conversion tool for YOLO object detection models,"A C++ library and toolset for converting and running YOLO series models (v3, v4, v5) using NVIDIA TensorRT. It optimizes inference speed for real-time object detection applications.",AI6;AI6-04,inference_acceleration;model_conversion,library,C++,https://github.com/enazoe/yolo-tensorrt,,MIT,tensorrt;yolo;inference;acceleration
862,imgcomp-cvpr,Deep image compression model implementation based on Conditional Probability Models,"A TensorFlow implementation of deep image compression techniques using conditional probability models. While a paper implementation, it serves as a baseline solver for image compression research and data processing.",AI6,image_compression;data_processing,solver,Python,https://github.com/fab-jul/imgcomp-cvpr,,GPL-3.0,image-compression;deep-learning;tensorflow
863,FBTT-Embedding,Tensor Train compression library for sparse embedding tables,A library for compressing sparse embedding tables in large-scale recommendation and NLP models using Tensor Train decomposition. It significantly reduces memory footprint and enables efficient runtime decompression.,AI6;AI6-04,model_compression;memory_optimization,library,Cuda,https://github.com/facebookresearch/FBTT-Embedding,,MIT,embedding-compression;tensor-train;dlrm
864,LLM-QAT,Data-Free Quantization Aware Training framework for LLMs,A research tool enabling Quantization Aware Training (QAT) for Large Language Models without requiring original training data (data-free). It facilitates the production of quantized models with preserved accuracy.,AI6;AI6-04,quantization;model_training,library,Python,https://github.com/facebookresearch/LLM-QAT,,NOASSERTION,qat;quantization;llm
865,diffq,Differentiable quantization library for model compression,A library for differentiable quantization using pseudo quantization noise. It allows automatic tuning of bit-width per weight or group to achieve optimal trade-offs between model size and accuracy.,AI6;AI6-04,quantization;model_compression,library,Python,https://github.com/facebookresearch/diffq,,NOASSERTION,quantization;differentiable-programming;compression
866,flashy,Lightweight framework for deep learning training loops,"A flexible framework for constructing deep learning training loops, handling checkpointing, logging, and distributed training (Dora compatibility), designed to streamline research experimentation.",AI6,training_framework;experiment_management,library,Python,https://github.com/facebookresearch/flashy,,MIT,training-loop;distributed-training;pytorch
867,Felafax,Infrastructure platform for AI workloads on non-NVIDIA GPUs,"A platform and toolkit designed to facilitate the running and fine-tuning of AI models on diverse hardware backends, specifically targeting non-NVIDIA GPUs (e.g., AMD, TPUs) to democratize AI compute access.",AI6,hardware_abstraction;distributed_training,platform,Jupyter Notebook,https://github.com/felafax/felafax,https://felafax.ai,Apache-2.0,amd-gpu;tpu;infrastructure;fine-tuning
868,fhelipe,Tensor compiler for Fully Homomorphic Encryption (FHE),"A compiler designed to transform high-level tensor operations into Fully Homomorphic Encryption (FHE) compatible circuits, enabling privacy-preserving computation on encrypted data.",AI6,compilation;privacy_preserving_computing,solver,C++,https://github.com/fhelipe-compiler/fhelipe,,GPL-3.0,fhe;compiler;privacy;tensor
869,Finch.jl,Sparse and structured tensor compiler for Julia,"A compiler for sparse and structured tensor operations in Julia. It optimizes tensor loops to generate high-performance code for complex sparse array computations, essential for scientific computing and graph analysis.",AI6,compilation;sparse_computing,library,Julia,https://github.com/finch-tensor/Finch.jl,https://willow-ahrens.io/Finch.jl/stable/,MIT,julia;sparse-tensors;compiler;hpc
870,native-sparse-attention,Hardware-aligned sparse attention kernels in Triton,A library of efficient Triton implementations for native sparse attention mechanisms. It provides optimized kernels that align with hardware characteristics to accelerate training and inference of sparse transformers.,AI6;AI6-04,kernel_optimization;sparse_attention,library,Python,https://github.com/fla-org/native-sparse-attention,,MIT,triton;sparse-attention;acceleration
871,FlagAttention,Memory-efficient attention operators library,"A collection of high-performance, memory-efficient attention operators implemented in Triton. It aims to optimize the core attention mechanism in Large Language Models for better throughput and lower memory usage.",AI6;AI6-04,kernel_optimization;attention_mechanism,library,Python,https://github.com/flagos-ai/FlagAttention,,NOASSERTION,triton;attention;optimization
872,FlagGems,Triton-based operator library for Large Language Models,"A library of general-purpose and specialized operators for deep learning, implemented in Triton. It serves as a high-performance backend for LLM inference and training, offering alternatives to standard CUDA kernels.",AI6;AI6-04,kernel_optimization;operator_library,library,Python,https://github.com/flagos-ai/FlagGems,,Apache-2.0,triton;operators;llm
873,FlagTree,Unified compiler for custom DL operations on multiple AI chips,"A fork of the Triton compiler designed to support multiple AI chip backends. It provides a unified compilation framework for custom deep learning operations, facilitating portability across different hardware architectures.",AI6,compilation;hardware_abstraction,solver,C++,https://github.com/flagos-ai/flagtree,,MIT,compiler;triton;multi-backend
874,SAX,S-parameter based frequency domain circuit simulation with JAX,"A circuit simulation and optimization tool based on S-parameters, built on top of JAX. It leverages JAX's autograd and XLA capabilities for efficient frequency domain analysis and optimization of photonic and electrical circuits.",AI6,scientific_modeling;simulation,solver,Python,https://github.com/flaport/sax,https://flaport.github.io/sax/,Apache-2.0,jax;circuit-simulation;photonics;autograd
875,Deep Learning on Flink,Distributed deep learning framework on Apache Flink,"Integrates deep learning frameworks (TensorFlow, PyTorch) with Apache Flink, enabling distributed training and inference workflows on Flink clusters for large-scale data processing pipelines.",AI6,distributed_computing;workflow_orchestration,platform,Java,https://github.com/flink-extended/dl-on-flink,,Apache-2.0,flink;distributed-training;tensorflow;pytorch
876,fms-acceleration,Acceleration libraries for foundation model fine-tuning,A collection of libraries and plugins designed to accelerate the fine-tuning and training of foundation models within the Foundation Model Stack ecosystem. It provides optimizations for training loops and hardware utilization.,AI6;AI6-04,training_acceleration;fine_tuning,library,Python,https://github.com/foundation-model-stack/fms-acceleration,,Apache-2.0,foundation-models;acceleration;fine-tuning
877,GPTQ-triton,Triton kernel implementation for GPTQ inference,A specialized implementation of the GPTQ (Generative Pre-trained Transformer Quantization) inference kernel using OpenAI's Triton language. It enables high-performance inference of quantized models on GPUs.,AI6;AI6-04,inference_acceleration;quantization,library,Jupyter Notebook,https://github.com/fpgaminer/GPTQ-triton,,Apache-2.0,gptq;triton;quantization;inference
878,Galois,Tensor computing compiler based on tile programming for GPU/CPU/TPU,"A tensor computing compiler that utilizes tile programming to optimize execution on various hardware backends including GPUs, CPUs, and TPUs.",AI6;AI6-04,compiler;tensor_computing,solver,C++,https://github.com/galois-stack/galois,,None,compiler;tensor;gpu;tpu
879,CLAMP-ViT,Contrastive data-free learning for adaptive post-training quantization of ViTs,A tool implementing contrastive data-free learning techniques for adaptive post-training quantization specifically designed for Vision Transformers (ViTs).,AI6;AI6-04,quantization;model_compression,solver,Python,https://github.com/georgia-tech-synergy-lab/CLAMP-ViT,,MIT,quantization;vit;post-training-quantization
880,SparQ,Post-training sparsity-aware quantization framework,A framework for post-training quantization that takes sparsity into account to optimize model performance and size.,AI6;AI6-04,quantization;model_compression,solver,Python,https://github.com/gilshm/sparq,,None,quantization;sparsity;post-training
881,GoMLX,Accelerated Machine Learning Framework for Go,"A machine learning framework for the Go programming language that provides acceleration capabilities, likely via XLA or similar backends.",AI6;AI6-04,ml_framework;training;inference,platform,Go,https://github.com/gomlx/gomlx,,Apache-2.0,go;machine-learning;framework
882,AI Edge Quantizer,Flexible post-training quantization for LiteRT models,A tool provided by Google AI Edge for performing flexible post-training quantization on LiteRT (formerly TensorFlow Lite) models.,AI6;AI6-04,quantization;edge_computing,solver,Python,https://github.com/google-ai-edge/ai-edge-quantizer,,Apache-2.0,quantization;litert;tensorflow-lite
883,GPUStack,GPU cluster manager for optimized AI model deployment,A cluster management tool designed to orchestrate and optimize the deployment of AI models across GPU clusters.,AI6;AI6-04,cluster_management;deployment;orchestration,platform,Python,https://github.com/gpustack/gpustack,,Apache-2.0,gpu;cluster-manager;deployment
884,Horovod Ansible,Ansible roles for deploying Horovod clusters,Infrastructure-as-Code tool using Ansible to automate the deployment and configuration of Horovod distributed training clusters.,AI6;AI6-04,deployment;infrastructure_provisioning,workflow,HCL,https://github.com/graykode/horovod-ansible,,None,ansible;horovod;distributed-training
885,Inference (C#),"C# deployment wrapper for OpenVINO, TensorRT, and ONNX Runtime","A library providing C# interfaces for deploying models using various high-performance inference engines like OpenVINO, TensorRT, and ONNX Runtime.",AI6;AI6-04,inference_wrapper;deployment,library,C#,https://github.com/guojin-yan/Inference,,None,csharp;openvino;tensorrt;onnx
886,BERT-pre-training,Multi-GPU pre-training implementation for BERT without Horovod,A specialized implementation for pre-training BERT models using multi-GPU data parallelism on a single machine without requiring Horovod.,AI6;AI6-04,model_training;parallelism,solver,Python,https://github.com/guotong1988/BERT-pre-training,,Apache-2.0,bert;pre-training;multi-gpu
887,APPy,Annotated Parallelism for Python to GPU compiler,A compiler tool that allows users to annotate Python loops and tensor expressions for automatic compilation into efficient GPU kernels.,AI6;AI6-04,compiler;parallelization,solver,Python,https://github.com/habanero-lab/APPy,,MIT,compiler;gpu;python;parallelism
888,docker-tensorflow-builder,Docker environment for compiling TensorFlow from source,"A set of Docker configurations and scripts to facilitate the compilation of TensorFlow from source, enabling custom builds.",AI6;AI6-04,build_tool;compilation,workflow,Shell,https://github.com/hadim/docker-tensorflow-builder,,MIT,docker;tensorflow;compilation
889,PTQ4ViT,Post-Training Quantization for Vision Transformers,A tool implementing post-training quantization techniques specifically optimized for Vision Transformer (ViT) architectures.,AI6;AI6-04,quantization;model_compression,solver,Python,https://github.com/hahnyuan/PTQ4ViT,,None,quantization;vit;vision-transformer
890,RPTQ4LLM,Reorder-based post-training quantization for LLMs,A quantization tool for Large Language Models that uses a reorder-based approach to maintain accuracy after post-training quantization.,AI6;AI6-04,quantization;llm_optimization,solver,Python,https://github.com/hahnyuan/RPTQ4LLM,,MIT,quantization;llm;post-training
891,Hailo Model Zoo,Pre-trained models and build environment for Hailo hardware,A collection of pre-trained models along with a build and evaluation environment optimized for deployment on Hailo AI processors.,AI6;AI6-04,model_deployment;benchmarking,platform,Python,https://github.com/hailo-ai/hailo_model_zoo,,MIT,model-zoo;hailo;deployment
892,Catgrad,Categorical deep learning compiler,"A deep learning compiler built using principles from category theory, written in Rust.",AI6;AI6-04,compiler;deep_learning,solver,Rust,https://github.com/hellas-ai/catgrad,,MIT,compiler;rust;category-theory
893,SWIFT,On-the-Fly Self-Speculative Decoding for LLM Inference Acceleration,A tool implementing self-speculative decoding to accelerate the inference of Large Language Models.,AI6;AI6-04,inference_acceleration;decoding,solver,Python,https://github.com/hemingkx/SWIFT,,Apache-2.0,inference;acceleration;llm;speculative-decoding
894,Quantization.MXNet,Quantization simulation for MXNet-Gluon models,A tool to simulate quantization and perform quantization-aware training for models built with MXNet-Gluon.,AI6;AI6-04,quantization;simulation,solver,Python,https://github.com/hey-yahei/Quantization.MXNet,,MIT,mxnet;quantization;gluon
895,tensorflow-cpp,TensorFlow C++ library compilation for CMake projects,A utility to compile TensorFlow into a C++ library suitable for integration into CMake-based projects.,AI6;AI6-04,build_tool;integration,library,C++,https://github.com/hhzrz/tensorflow-cpp,,Apache-2.0,tensorflow;cpp;cmake
896,Hidet,Efficient deep learning framework and compiler,"An open-source deep learning framework and compiler written in Python, designed for high efficiency.",AI6;AI6-04,compiler;dl_framework,platform,Python,https://github.com/hidet-org/hidet,https://hidet.org,Apache-2.0,compiler;deep-learning;python
897,Higgsfield,Fault-tolerant GPU orchestration and training framework,A scalable GPU orchestration platform and machine learning framework designed for training large-scale models with fault tolerance.,AI6;AI6-04,orchestration;training_framework,platform,Jupyter Notebook,https://github.com/higgsfield-ai/higgsfield,,Apache-2.0,orchestration;gpu;training
898,Caten,Polyhedral-based Deep Learning Compiler,"A deep learning compiler leveraging polyhedral compilation techniques, lightweight IRs, and pattern matching for optimization.",AI6;AI6-04,compiler;optimization,solver,Common Lisp,https://github.com/hikettei/Caten,,NOASSERTION,compiler;polyhedral;lisp
899,Parallel Prompt Decoding,Efficient LLM Inference Acceleration using Prompting,A tool implementing parallel prompt decoding techniques to accelerate the inference process of Large Language Models.,AI6;AI6-04,inference_acceleration;decoding,solver,Python,https://github.com/hmarkc/parallel-prompt-decoding,,Apache-2.0,inference;acceleration;llm
900,LLM-Pruner,Structural Pruning tool for Large Language Models,"A tool for structural pruning of Large Language Models (LLMs) such as Llama, BLOOM, and Vicuna to reduce model size and improve efficiency.",AI6;AI6-04,model_compression;pruning,solver,Python,https://github.com/horseee/LLM-Pruner,,Apache-2.0,pruning;llm;compression
901,SINQ,Fast and high-quality quantization method for LLMs,"A quantization tool designed to compress Large Language Models while preserving accuracy, implementing the SINQ method.",AI6;AI6-04,quantization;model_compression,solver,Python,https://github.com/huawei-csl/SINQ,,Apache-2.0,quantization;llm;compression
902,Huawei Noah PLM,Pretrained language models and optimization techniques,A repository containing pretrained language models and implementations of optimization techniques (like PanGu-Alpha) developed by Huawei Noah's Ark Lab.,AI6;AI6-04,model_optimization;pretraining,library,Python,https://github.com/huawei-noah/Pretrained-Language-Model,,None,pretrained-models;optimization;huawei
903,Accelerate,Library for easy distributed training and mixed precision in PyTorch,"A library by Hugging Face that abstracts the boilerplate code for distributed training and mixed precision, making it easy to run PyTorch scripts on various hardware configurations.",AI6;AI6-04,distributed_training;acceleration,library,Python,https://github.com/huggingface/accelerate,https://huggingface.co/docs/accelerate,Apache-2.0,pytorch;distributed-training;mixed-precision
904,Optimum ONNX,Export and inference tool for ONNX Runtime via Hugging Face,"A tool to export Hugging Face models to ONNX format and run inference using ONNX Runtime, optimizing performance.",AI6;AI6-04,inference_optimization;model_export,library,Python,https://github.com/huggingface/optimum-onnx,https://huggingface.co/docs/optimum,Apache-2.0,onnx;inference;optimization
905,Picotron,Minimalistic 4D-parallelism distributed training framework,"A distributed training framework implementing 4D-parallelism, designed for educational purposes but functional as a reference implementation for advanced parallelism techniques.",AI6;AI6-04,distributed_training;parallelism,platform,Python,https://github.com/huggingface/picotron,,Apache-2.0,distributed-training;parallelism;educational
906,tensorflow-yolov4-tflite,YOLOv4 implementation with conversion tools for TFLite and TensorRT,"A comprehensive repository providing implementations of YOLOv4, YOLOv4-tiny, YOLOv3, and YOLOv3-tiny in TensorFlow 2.0, along with utilities to convert these models to TensorFlow Lite (.tflite) and TensorRT formats for accelerated inference on edge devices.",AI6;AI6-04,model_conversion;inference_acceleration,solver,Python,https://github.com/hunglc007/tensorflow-yolov4-tflite,,MIT,yolov4;tflite;tensorrt;conversion
907,PD-Quant,Post-training quantization method based on prediction difference metric,"Implementation of the PD-Quant method (CVPR 2023), a post-training quantization technique that uses a prediction difference metric to optimize quantization parameters without requiring retraining.",AI6;AI6-04,quantization;model_compression,solver,Python,https://github.com/hustvl/PD-Quant,,Apache-2.0,post-training-quantization;cvpr-2023;model-compression
908,yzma,Go bindings for llama.cpp enabling local LLM inference,A Go library that integrates with llama.cpp to provide hardware-accelerated local inference for Large Language Models (LLMs) within Go applications.,AI6;AI6-04,inference_acceleration;llm_inference,library,Go,https://github.com/hybridgroup/yzma,,NOASSERTION,llama.cpp;go;llm;inference
909,AutoRound,Advanced quantization toolkit for LLMs and VLMs,"An advanced quantization toolkit designed for Large Language Models (LLMs) and Vision-Language Models (VLMs), supporting various schemes like WOQ, MXFP4, and NVFP4. It integrates with major frameworks like Transformers and vLLM to facilitate low-bit model deployment.",AI6;AI6-04,quantization;model_compression,library,Python,https://github.com/intel/auto-round,,Apache-2.0,quantization;llm;vlm;intel
910,Intel Extension for DeepSpeed,DeepSpeed extension for Intel XPU acceleration,"An extension for the DeepSpeed optimization library that enables support for Intel GPU (XPU) devices using SYCL kernels, facilitating accelerated distributed training on Intel hardware.",AI6;AI6-04,training_acceleration;distributed_training,library,C++,https://github.com/intel/intel-extension-for-deepspeed,,MIT,deepspeed;intel-xpu;sycl;distributed-training
911,Intel XPU Backend for Triton,OpenAI Triton compiler backend for Intel GPUs,"A backend implementation for the OpenAI Triton compiler, enabling Triton kernels to run efficiently on Intel GPUs (XPU), supporting high-performance deep learning primitives.",AI6;AI6-04,compiler_backend;inference_acceleration,library,MLIR,https://github.com/intel/intel-xpu-backend-for-triton,,MIT,triton;intel-gpu;compiler;acceleration
912,IPEX-LLM,LLM inference and finetuning acceleration library for Intel XPU,"A library for accelerating local inference and fine-tuning of Large Language Models (LLMs) on Intel hardware (CPUs, iGPUs, discrete GPUs). It integrates with popular frameworks like HuggingFace, LangChain, and vLLM.",AI6;AI6-04,inference_acceleration;finetuning,library,Python,https://github.com/intel/ipex-llm,https://ipex-llm.readthedocs.io/,Apache-2.0,llm;intel;inference;finetuning
913,Intel Neural Compressor,Model compression tool for quantization and sparsity,"A model compression tool that provides state-of-the-art quantization (INT8, FP8, INT4, etc.) and sparsity techniques for PyTorch, TensorFlow, and ONNX Runtime, aiming to accelerate inference with minimal accuracy loss.",AI6;AI6-04,quantization;model_compression;sparsity,library,Python,https://github.com/intel/neural-compressor,https://intel.github.io/neural-compressor/,Apache-2.0,quantization;compression;intel;optimization
914,NeuroVectorizer,RL-based framework for optimal compiler vectorization,"A framework that utilizes deep reinforcement learning to predict optimal vectorization compiler pragmas for loops in C and C++ code, automating the tuning of compiler optimizations.",AI6;AI6-04,compiler_optimization;vectorization,solver,C,https://github.com/intel/neuro-vectorizer,,BSD-3-Clause,compiler;reinforcement-learning;vectorization;optimization
915,PKD-for-BERT,Patient Knowledge Distillation for BERT model compression,"PyTorch implementation of Patient Knowledge Distillation (PKD), a method for compressing BERT models by distilling knowledge from intermediate layers, enabling efficient inference.",AI6;AI6-04,knowledge_distillation;model_compression,solver,Python,https://github.com/intersun/PKD-for-BERT-Model-Compression,,NOASSERTION,bert;knowledge-distillation;compression
916,IREE,Retargetable MLIR-based machine learning compiler and runtime,"A compiler and runtime toolkit based on MLIR that lowers machine learning models to a unified intermediate representation, enabling execution on diverse hardware targets including mobile, edge, and datacenter devices.",AI6;AI6-04,compiler;runtime;inference_acceleration,platform,C++,https://github.com/iree-org/iree,https://iree.dev/,Apache-2.0,mlir;compiler;runtime;cross-platform
917,yolov4-triton-tensorrt,Deployment workflow for YOLOv4 on Triton Inference Server via TensorRT,A repository providing the necessary configurations and scripts to deploy YOLOv4 models as optimized TensorRT engines within the Triton Inference Server environment.,AI6;AI6-04,model_deployment;inference_serving,workflow,C++,https://github.com/isarsoft/yolov4-triton-tensorrt,,NOASSERTION,yolov4;triton-inference-server;tensorrt;deployment
918,Tzer,Coverage-guided tensor compiler fuzzer for TVM,A fuzzing tool designed for tensor compilers (specifically TVM) that uses coverage guidance and joint IR-pass mutation to detect bugs and correctness issues in the compilation process.,AI6;AI6-04,compiler_testing;fuzzing,solver,Python,https://github.com/ise-uiuc/tzer,,Apache-2.0,tvm;fuzzing;compiler-testing
919,CalibTIP,Layer-wise calibration for post-training neural quantization,Implementation of a post-training quantization method that utilizes layer-wise calibration and integer programming to improve the accuracy of quantized neural networks.,AI6;AI6-04,quantization;calibration,solver,Python,https://github.com/itayhubara/CalibTIP,,MIT,quantization;calibration;optimization
920,dl-benchmark,Multi-framework deep learning inference benchmark tool,"A benchmarking tool for evaluating deep learning inference performance across multiple frameworks including OpenVINO, TensorFlow, ONNX Runtime, PyTorch, and TVM.",AI6;AI6-04,benchmarking;performance_analysis,solver,HTML,https://github.com/itlab-vision/dl-benchmark,,Apache-2.0,benchmark;inference;deep-learning
921,yolov5-onnxruntime,C++ inference implementation for YOLOv5 using ONNX Runtime,"A C++ implementation for running inference on YOLOv5 models using the ONNX Runtime, providing a lightweight solution for deploying object detection models.",AI6;AI6-04,inference_acceleration;model_deployment,solver,C++,https://github.com/itsnine/yolov5-onnxruntime,,NOASSERTION,yolov5;onnx-runtime;cpp;inference
922,InferenceHelper,C++ helper library for multiple deep learning inference frameworks,"A C++ wrapper library that provides a unified interface for various deep learning inference frameworks such as TensorFlow Lite, TensorRT, OpenVINO, ONNX Runtime, and ncnn, simplifying application development.",AI6;AI6-04,inference_abstraction;deployment,library,C++,https://github.com/iwatake2222/InferenceHelper,,Apache-2.0,inference;wrapper;cpp;multi-framework
923,Alpaca-LoRA-RLHF-PyTorch,Pipeline for finetuning Alpaca LLM with LoRA and RLHF,A complete pipeline for fine-tuning the Alpaca Large Language Model using Low-Rank Adaptation (LoRA) and Reinforcement Learning with Human Feedback (RLHF) on consumer hardware.,AI6;AI6-04,finetuning;rlhf;training_pipeline,workflow,Python,https://github.com/jackaduma/Alpaca-LoRA-RLHF-PyTorch,,MIT,alpaca;lora;rlhf;finetuning
924,ChatGLM-LoRA-RLHF-PyTorch,Pipeline for finetuning ChatGLM with LoRA and RLHF,"A pipeline designed to fine-tune the ChatGLM model using LoRA and RLHF techniques, enabling efficient customization of the model on consumer-grade hardware.",AI6;AI6-04,finetuning;rlhf;training_pipeline,workflow,Python,https://github.com/jackaduma/ChatGLM-LoRA-RLHF-PyTorch,,MIT,chatglm;lora;rlhf;finetuning
925,YOLOv8-qat,Quantization Aware Training implementation for YOLOv8,"A tool implementing Quantization Aware Training (QAT) specifically for YOLOv8 models, allowing for the creation of quantized models that retain high accuracy.",AI6;AI6-04,quantization_aware_training;model_optimization,solver,Python,https://github.com/jahongir7174/YOLOv8-qat,,NOASSERTION,yolov8;qat;quantization
926,jax-triton,Integration library between JAX and OpenAI Triton,"A library that provides integrations between JAX and OpenAI Triton, allowing users to write custom Triton kernels and use them within JAX computations for accelerated machine learning.",AI6;AI6-04,compiler_integration;acceleration,library,Python,https://github.com/jax-ml/jax-triton,,Apache-2.0,jax;triton;kernel;acceleration
927,xllm,High-performance inference engine for LLMs on diverse accelerators,"A high-performance inference engine designed for Large Language Models (LLMs), optimized to run efficiently on various AI accelerators and hardware platforms.",AI6;AI6-04,inference_engine;llm_acceleration,solver,C++,https://github.com/jd-opensource/xllm,,NOASSERTION,llm;inference-engine;acceleration
928,QSNNs,Quantization-aware training for spiking neural networks,"A library/tool for performing quantization-aware training specifically tailored for Spiking Neural Networks (SNNs), enabling the deployment of efficient neuromorphic models.",AI6;AI6-04,quantization;neuromorphic_computing,library,Python,https://github.com/jeshraghian/QSNNs,,NOASSERTION,snn;quantization;spiking-neural-networks
929,tensorrt_demos,Collection of TensorRT implementation examples and utilities,"A widely used collection of examples and utility scripts for deploying various deep learning models (YOLO, SSD, etc.) using TensorRT on NVIDIA Jetson and x86 platforms.",AI6;AI6-04,inference_deployment;tensorrt_optimization,library,Python,https://github.com/jkjung-avt/tensorrt_demos,,MIT,tensorrt;jetson;inference;demo
930,DeepDetect,Open source deep learning API and server,"A deep learning API and server written in C++14 that supports multiple backends (PyTorch, TensorRT, NCNN, etc.), providing a unified platform for training and inference integration.",AI6;AI6-04,inference_server;model_serving,platform,C++,https://github.com/jolibrain/deepdetect,https://www.deepdetect.com/,NOASSERTION,inference-server;api;deep-learning
931,pykaldi2,Speech recognition toolkit based on Kaldi and PyTorch,"A Python wrapper and toolkit for the Kaldi speech recognition system, integrating it with PyTorch for flexible model training and inference.",AI6;AI4,speech_recognition;model_training,library,Python,https://github.com/jzlianglu/pykaldi2,,MIT,kaldi;speech-recognition;pytorch-wrapper
932,trident,Performance library for machine learning applications,"A library designed to accelerate machine learning applications, providing optimized kernels and utilities for performance enhancement.",AI6;AI6-04,inference_acceleration;training_acceleration,library,Python,https://github.com/kakaobrain/trident,,Apache-2.0,acceleration;performance;machine-learning
933,ps-dnn,Distributed deep learning training and prediction framework,"A lightweight distributed deep learning framework based on Parameter Server (PS-Lite), supporting feature extraction and distributed training.",AI6;AI6-04,distributed_training;inference,platform,C++,https://github.com/kangshantong/ps-dnn,,None,parameter-server;distributed-training;c++
934,sparrow,Structured data extraction tool using ML and LLMs,"A tool for extracting structured data from documents and images using machine learning and Large Language Models, useful for scientific data processing.",AI1;AI6,data_extraction;document_processing,solver,Python,https://github.com/katanaml/sparrow,,GPL-3.0,data-extraction;llm;ocr
935,nncase,Deep learning compiler stack for AI accelerators,An open compiler stack designed to optimize and deploy deep learning models onto Kendryte AI accelerators.,AI6;AI6-04,model_compilation;inference_acceleration,solver,C#,https://github.com/kendryte/nncase,,Apache-2.0,compiler;ai-accelerator;kendryte
936,onnxruntime-server,Server for ONNX inference via REST APIs,A server application that provides TCP and HTTP/HTTPS REST APIs for performing inference using ONNX Runtime.,AI6;AI6-04,model_serving;inference,service,C++,https://github.com/kibae/onnxruntime-server,,MIT,onnx;serving;rest-api
937,kserve,Standardized distributed AI inference platform on Kubernetes,"A platform for serving machine learning models on Kubernetes, supporting serverless inference, canary rollouts, and multi-framework deployment.",AI6;AI6-04,model_serving;inference_management,platform,Shell,https://github.com/kserve/kserve,https://kserve.github.io/website/,Apache-2.0,kubernetes;inference-serving;mlops
938,kubeai,AI Inference Operator for Kubernetes,"A Kubernetes operator designed to simplify the deployment and serving of AI models, including LLMs and VLMs, in production environments.",AI6;AI6-04,model_serving;deployment_automation,platform,Go,https://github.com/kubeai-project/kubeai,,Apache-2.0,kubernetes-operator;inference;llm-serving
939,mpi-operator,Kubernetes Operator for MPI-based applications,"A Kubernetes operator that manages the lifecycle of MPI jobs, facilitating distributed training and HPC workloads on Kubernetes clusters.",AI6;AI6-04,distributed_training;hpc_job_management,platform,Go,https://github.com/kubeflow/mpi-operator,,Apache-2.0,mpi;kubernetes;hpc
940,pytorch2c,Compiler for converting PyTorch graphs to C,"A tool that compiles PyTorch computational graphs into C code, enabling standalone execution of models without the Python runtime.",AI6;AI6-04,model_compilation;inference_acceleration,solver,Python,https://github.com/lantiga/pytorch2c,,MIT,pytorch;compiler;c-generation
941,TensorRT-YOLO,Deployment toolkit for YOLO models using TensorRT,A toolkit designed to facilitate the deployment of YOLO object detection models on NVIDIA GPUs using TensorRT for acceleration.,AI6;AI6-04,inference_acceleration;model_deployment,solver,C++,https://github.com/laugh12321/TensorRT-YOLO,,GPL-3.0,tensorrt;yolo;deployment
942,Liger-Kernel,Efficient Triton kernels for LLM training,A library of highly optimized Triton kernels designed to accelerate the training of Large Language Models.,AI6;AI6-04,training_acceleration;kernel_optimization,library,Python,https://github.com/linkedin/Liger-Kernel,,BSD-2-Clause,triton;kernels;llm-training
943,Tempo,Declarative compiled dynamic deep learning system,"A system for end-to-end compiled dynamic deep learning, offering declarative interfaces and efficient execution.",AI6;AI6-04,model_compilation;deep_learning_system,platform,Python,https://github.com/lsds/Tempo,,MIT,compiler;deep-learning;system
944,pytorch-quantity,Automated 8-bit quantization conversion tool for PyTorch,"A tool for performing post-training quantization on PyTorch models, specifically using KL divergence for calibration.",AI6;AI6-04,quantization;model_compression,solver,Python,https://github.com/lswzjuer/pytorch-quantity,,None,quantization;pytorch;post-training-quantization
945,SOBER,Fast Bayesian optimization with GPU acceleration,"A tool for performing fast Bayesian optimization, quadrature, and inference over arbitrary domains, leveraging GPU acceleration.",AI6;AI6-04,optimization;scientific_modeling,library,Jupyter Notebook,https://github.com/ma921/SOBER,,BSD-3-Clause,bayesian-optimization;gpu-acceleration;inference
946,altius,Small ONNX inference runtime written in Rust,"A lightweight inference runtime for ONNX models, implemented in Rust, focusing on portability and performance.",AI6;AI6-04,inference_runtime;model_execution,solver,Rust,https://github.com/maekawatoshiki/altius,,MIT,onnx;runtime;rust
947,DeepStream-Yolo,NVIDIA DeepStream implementation for YOLO models,A widely used integration tool that enables running YOLO object detection models within the NVIDIA DeepStream SDK pipeline.,AI6;AI6-04,inference_acceleration;pipeline_integration,solver,C++,https://github.com/marcoslucianops/DeepStream-Yolo,,MIT,deepstream;yolo;nvidia
948,ONN-QAT-SQL,Simulation scripts for Optical Neural Networks under photon shot noise,"A set of scripts for training neural networks resistant to photon shot noise using quantization-aware training, including simulation of neural network performance under shot noise conditions.",AI6-04;Physics,simulation;quantization_aware_training,solver,Jupyter Notebook,https://github.com/mcmahon-lab/ONN-QAT-SQL,,CC-BY-4.0,optical-neural-networks;simulation;quantization
949,FQ-ViT,Post-Training Quantization for Fully Quantized Vision Transformers,"Implementation of FQ-ViT, a method for post-training quantization specifically designed for Vision Transformers to achieve full quantization.",AI6-04;CV,quantization;model_compression,solver,Python,https://github.com/megvii-research/FQ-ViT,,Apache-2.0,vision-transformer;post-training-quantization;ptq
950,Sparsebit,Model compression and acceleration toolbox for PyTorch,"A comprehensive toolbox for model compression and acceleration based on PyTorch, facilitating quantization and pruning tasks.",AI6-04,model_compression;acceleration,library,Python,https://github.com/megvii-research/Sparsebit,,Apache-2.0,compression;acceleration;pytorch
951,MSLK,Meta Superintelligence Labs Kernels for GenAI optimization,"A collection of PyTorch GPU operator libraries designed and optimized for GenAI training and inference, including FP8 row-wise quantization and collective communications.",AI6-04;HPC,kernel_optimization;quantization,library,Python,https://github.com/meta-pytorch/MSLK,,NOASSERTION,gpu-kernels;fp8;genai
952,Tritonbench,Benchmarking framework for PyTorch operators and Triton kernels,"A collection of PyTorch custom operators with example inputs designed to measure their performance, serving as a benchmarking tool for Triton kernels.",AI6-04,benchmarking;performance_profiling,solver,Python,https://github.com/meta-pytorch/tritonbench,,BSD-3-Clause,triton;benchmarking;pytorch
953,TritonParse,Compiler Tracer and Visualizer for Triton Kernels,"A tool for tracing, visualizing, and reproducing Triton compiler behavior, aiding in the debugging and optimization of Triton kernels.",AI6-04,compiler_debugging;visualization,solver,Python,https://github.com/meta-pytorch/tritonparse,,BSD-3-Clause,triton;compiler;visualization
954,Olive,Model optimization toolchain for hardware acceleration,"A tool to simplify ML model finetuning, conversion, quantization, and optimization for deployment on CPUs, GPUs, and NPUs.",AI6-04,model_optimization;quantization,workflow,Python,https://github.com/microsoft/Olive,https://microsoft.github.io/Olive/,MIT,onnx;optimization;quantization
955,SwitchML,Switch-based training acceleration for machine learning,"A project implementing switch-based training acceleration for machine learning workloads, optimizing communication in distributed training.",AI6;HPC,distributed_training;acceleration,library,Python,https://github.com/microsoft/SwitchML,,MIT,distributed-training;networking;acceleration
956,TileFusion,C++ macro kernel template library for CUDA tile processing,An experimental C++ macro kernel template library that elevates the abstraction level in CUDA C for efficient tile processing.,AI6-04;HPC,kernel_optimization;cuda_programming,library,Cuda,https://github.com/microsoft/TileFusion,,MIT,cuda;kernel-templates;optimization
957,Antares,Automatic engine for multi-platform kernel generation,"An automatic engine for multi-platform kernel generation and optimization, supporting various backends like CPU, CUDA, ROCm, and OpenCL.",AI6-04,kernel_generation;compiler,solver,C++,https://github.com/microsoft/antares,,NOASSERTION,kernel-generation;compiler;multi-platform
958,Hummingbird,Compiles traditional ML models into tensor computation,A library that compiles trained traditional ML models (like decision trees) into tensor computation for faster inference on deep learning frameworks.,AI6-04,model_compilation;inference_acceleration,solver,Python,https://github.com/microsoft/hummingbird,,MIT,ml-compilation;tensor-computation;inference
959,NNI,AutoML toolkit for model compression and NAS,"An open source AutoML toolkit for automating machine learning lifecycle, including feature engineering, neural architecture search (NAS), model compression, and hyper-parameter tuning.",AI6-04,automl;model_compression;nas,platform,Python,https://github.com/microsoft/nni,https://nni.readthedocs.io/,MIT,automl;nas;hyperparameter-tuning
960,ONNX Runtime,High performance ML inferencing and training accelerator,"A cross-platform, high performance machine learning inferencing and training accelerator that supports models from PyTorch, TensorFlow/Keras, TFLite, scikit-learn, and other frameworks.",AI6-04,inference_acceleration;runtime,solver,C++,https://github.com/microsoft/onnxruntime,https://onnxruntime.ai/,MIT,inference;onnx;acceleration
961,onnxruntime-extensions,Pre- and post-processing library for ONNX Runtime,"A specialized library providing custom operators for pre- and post-processing to support ONNX Runtime, enabling end-to-end model execution.",AI6-04,data_processing;custom_operators,library,C++,https://github.com/microsoft/onnxruntime-extensions,,MIT,onnx;preprocessing;extensions
962,triton-shared,Shared Middle-Layer for Triton Compilation,"A shared middle-layer infrastructure for Triton compilation, facilitating the development of Triton backends and compiler optimizations.",AI6-04,compiler_infrastructure,library,MLIR,https://github.com/microsoft/triton-shared,,MIT,triton;compiler;mlir
963,Vidur,Large-scale simulation framework for LLM inference,A large-scale simulation framework designed to model and analyze the performance of Large Language Model (LLM) inference systems.,AI6-04,performance_simulation;profiling,solver,Python,https://github.com/microsoft/vidur,,MIT,llm;simulation;inference
964,BoxMOT,Pluggable multi-object tracking modules,"A collection of state-of-the-art multi-object tracking modules pluggable into segmentation, object detection, and pose estimation models.",AI6;CV,object_tracking;image_analysis,library,Python,https://github.com/mikel-brostrom/boxmot,,AGPL-3.0,tracking;computer-vision;mot
965,MindNLP,NLP library for MindSpore with Huggingface compatibility,An NLP library that enables running Transformers/Diffusers models on MindSpore with seamless compatibility and acceleration.,AI6-04;NLP,natural_language_processing;model_training,library,Jupyter Notebook,https://github.com/mindspore-lab/mindnlp,,Apache-2.0,mindspore;nlp;transformers
966,AMC,AutoML for Model Compression on Mobile Devices,"A tool implementing AutoML for Model Compression (AMC), leveraging reinforcement learning to automate the compression of deep neural networks for mobile devices.",AI6-04,model_compression;automl,solver,Python,https://github.com/mit-han-lab/amc,,MIT,compression;automl;mobile-ai
967,DistriFusion,Distributed Parallel Inference for Diffusion Models,A framework for distributed parallel inference enabling high-resolution diffusion model generation by splitting computation across devices.,AI6-04,distributed_inference;image_generation,solver,Python,https://github.com/mit-han-lab/distrifuser,,MIT,diffusion-models;distributed-inference;parallel-computing
968,AWQ,Activation-aware Weight Quantization for LLMs,"A tool for Activation-aware Weight Quantization (AWQ), enabling efficient compression and acceleration of Large Language Models.",AI6-04,quantization;model_compression,solver,Python,https://github.com/mit-han-lab/llm-awq,,MIT,llm;quantization;awq
969,SmoothQuant,Post-Training Quantization for Large Language Models,"A framework for accurate and efficient post-training quantization of Large Language Models, enabling 8-bit weight and activation quantization.",AI6-04,quantization;model_compression,solver,Python,https://github.com/mit-han-lab/smoothquant,,MIT,llm;quantization;post-training
970,TorchSparse,Efficient Sparse Convolution Framework on GPUs,A high-performance computing framework for efficient training and inference of sparse convolutions on GPUs.,AI6-04;HPC,sparse_computation;acceleration,library,Cuda,https://github.com/mit-han-lab/torchsparse,,MIT,sparse-convolution;gpu;acceleration
971,WebLLM,High-performance in-browser LLM inference engine,"A high-performance in-browser inference engine for Large Language Models, bringing hardware-accelerated AI to web browsers.",AI6-04,inference_engine;web_ai,solver,TypeScript,https://github.com/mlc-ai/web-llm,https://webllm.mlc.ai/,Apache-2.0,llm;webgpu;inference
972,mpi4jax,Zero-copy MPI communication for JAX,"A library enabling zero-copy MPI communication of JAX arrays, facilitating the development of turbo-charged HPC applications in Python.",AI6;HPC,distributed_computing;hpc,library,Python,https://github.com/mpi4jax/mpi4jax,https://mpi4jax.readthedocs.io/,MIT,jax;mpi;hpc
973,FastVGGT,Training-free acceleration library for Visual Geometry Transformers,"A library implementing training-free acceleration techniques for Visual Geometry Transformers (VGGT), optimizing inference speed without retraining.",AI6;AI6-04,inference_acceleration;model_optimization,library,Python,https://github.com/mystorm16/FastVGGT,,NOASSERTION,transformer;acceleration;vision
974,onnxruntime-rs,Rust bindings for ONNX Runtime inference engine,"A Rust wrapper for Microsoft's ONNX Runtime, enabling high-performance machine learning inference within Rust applications.",AI6;AI6-04,inference_runtime;model_deployment,library,Rust,https://github.com/nbigaouette/onnxruntime-rs,,Apache-2.0,rust;onnx;inference
975,DeepSparse,Sparsity-aware deep learning inference runtime for CPUs,"An inference runtime engine optimized for sparse neural networks, delivering GPU-class performance on commodity CPUs by leveraging sparsity.",AI6;AI6-04,inference_acceleration;inference_runtime,solver,Python,https://github.com/neuralmagic/deepsparse,https://docs.neuralmagic.com/deepsparse/,NOASSERTION,sparsity;inference;cpu-optimization
976,SparseZoo,Repository of sparse models and recipes for inference optimization,A repository and library providing pre-sparsified models and optimization recipes to facilitate the deployment of high-performance sparse neural networks.,AI6;AI6-04,model_optimization;model_repository,dataset,Python,https://github.com/neuralmagic/sparsezoo,https://docs.neuralmagic.com/sparsezoo/,Apache-2.0,sparse-models;optimization-recipes;neural-networks
977,Sparsify,Tool for model sparsification and pruning to accelerate inference,A tool enabling users to apply sparsification technologies (pruning and quantization) to neural networks to accelerate inference performance.,AI6;AI6-04,model_compression;quantization;pruning,solver,Python,https://github.com/neuralmagic/sparsify,https://docs.neuralmagic.com/sparsify/,Apache-2.0,pruning;quantization;optimization
978,vLLM-gfx906,Port of vLLM inference engine for AMD gfx906 GPUs,"A specialized fork of the vLLM library optimized for AMD gfx906 GPUs (e.g., Radeon VII, MI50, MI60), enabling high-throughput LLM inference on this hardware.",AI6;AI6-04,inference_runtime;llm_serving,solver,Python,https://github.com/nlzy/vllm-gfx906,,Apache-2.0,amd;rocm;vllm;llm
979,nndeploy,Cross-platform high-performance AI model deployment framework,"A comprehensive framework for AI model deployment that supports multiple inference backends (TensorRT, ONNX Runtime, OpenVINO, etc.) and provides a unified C++ interface.",AI6;AI6-04,model_deployment;inference_runtime,library,C++,https://github.com/nndeploy/nndeploy,,Apache-2.0,deployment;inference;cross-platform
980,NNTile,Task-based parallel neural network training framework for HPC,"A neural network training framework built on a task-based parallel programming paradigm, designed for high-performance computing environments.",AI6;AI6-04,distributed_training;hpc_acceleration,library,C++,https://github.com/nntile/nntile,,MIT,hpc;parallel-computing;training
981,tf-to-xla-to-wasm,Toolchain to compile TensorFlow graphs to WebAssembly via XLA,"A utility that compiles TensorFlow graphs into WebAssembly modules using XLA, enabling model execution in web environments.",AI6;AI6-04,model_compilation;webassembly_export,solver,Shell,https://github.com/nuchi/tf-to-xla-to-wasm,,MIT,tensorflow;xla;webassembly;compiler
982,DeepCompressor,Compression toolbox for LLMs and diffusion models,"A model compression toolbox specifically designed for Large Language Models and Diffusion Models, offering quantization and optimization techniques.",AI6;AI6-04,model_compression;quantization,library,Python,https://github.com/nunchaku-tech/deepcompressor,,Apache-2.0,llm;diffusion;compression
983,Nunchaku,Inference engine and quantization library for 4-bit diffusion models,"A library implementing SVDQuant for 4-bit quantization of diffusion models, enabling efficient inference by absorbing outliers into low-rank components.",AI6;AI6-04,quantization;inference_acceleration,library,Python,https://github.com/nunchaku-tech/nunchaku,,Apache-2.0,diffusion-models;quantization;svdquant
984,ComfyUI-FSampler,Acceleration layer for diffusion sampling in ComfyUI,"A training-free, sampler-agnostic acceleration layer integrated into ComfyUI to speed up diffusion model sampling.",AI6;AI6-04,inference_acceleration;image_generation,solver,Python,https://github.com/obisin/ComfyUI-FSampler,,NOASSERTION,comfyui;diffusion;acceleration
985,ONNX-TensorRT,TensorRT backend for parsing and executing ONNX models,"A library that parses ONNX models and executes them using the NVIDIA TensorRT inference engine, serving as a critical bridge for deploying ONNX models on NVIDIA GPUs.",AI6;AI6-04,model_compilation;inference_acceleration,library,C++,https://github.com/onnx/onnx-tensorrt,,Apache-2.0,onnx;tensorrt;nvidia
986,OpenVINO Training Extensions,"Framework for training, optimizing, and deploying CV models with OpenVINO","A framework that provides workflows for training, evaluating, optimizing, and deploying computer vision models, specifically tailored for the OpenVINO toolkit.",AI6;AI6-04,model_optimization;deployment_workflow,workflow,Python,https://github.com/open-edge-platform/training_extensions,,Apache-2.0,openvino;computer-vision;optimization
987,MMDeploy,Model deployment framework supporting export to multiple inference backends,"A comprehensive model deployment toolbox that provides a unified pipeline to export OpenMMLab models to various inference backends like ONNX Runtime, TensorRT, and ncnn.",AI6;AI6-04,model_deployment;model_conversion,workflow,Python,https://github.com/open-mmlab/mmdeploy,https://mmdeploy.readthedocs.io/,Apache-2.0,deployment;openmmlab;conversion
988,MMRazor,"Model compression toolbox for pruning, quantization, and distillation","A model compression toolbox that includes algorithms for neural network pruning, quantization, knowledge distillation, and architecture search.",AI6;AI6-04,model_compression;quantization;pruning,library,Python,https://github.com/open-mmlab/mmrazor,https://mmrazor.readthedocs.io/,Apache-2.0,compression;distillation;nas
989,DI-hpc,High-performance operator library for Reinforcement Learning,A library of optimized CUDA and Triton kernels specifically designed to accelerate Reinforcement Learning operations.,AI6;AI6-04,kernel_optimization;hpc_acceleration,library,Python,https://github.com/opendilab/DI-hpc,,Apache-2.0,reinforcement-learning;cuda;triton
990,ReaLHF,Efficient RLHF training system for LLMs,"A system for efficient Reinforcement Learning from Human Feedback (RLHF) training of Large Language Models, utilizing parameter reallocation techniques.",AI6;AI6-04,distributed_training;llm_optimization,platform,Python,https://github.com/openpsi-project/ReaLHF,,Apache-2.0,rlhf;llm;training-system
991,XLA,Domain-specific compiler for linear algebra and machine learning models,"A machine learning compiler that optimizes linear algebra computations for execution on GPUs, CPUs, and ML accelerators.",AI6;AI6-04,model_compilation;hardware_acceleration,solver,C++,https://github.com/openxla/xla,https://openxla.org/xla,Apache-2.0,compiler;linear-algebra;optimization
992,sd4j,Java implementation of Stable Diffusion pipeline using ONNX Runtime,"A library that provides a Stable Diffusion inference pipeline in Java, leveraging ONNX Runtime for execution.",AI6;AI6-04,inference_runtime;image_generation,library,Java,https://github.com/oracle/sd4j,,UPL-1.0,java;stable-diffusion;onnx
993,kvcached,Virtualized elastic KV cache system for dynamic GPU sharing,"A system that provides a virtualized, elastic Key-Value (KV) cache to enable efficient dynamic GPU sharing for Large Language Model inference.",AI6;AI6-04,inference_optimization;resource_management,platform,Python,https://github.com/ovg-project/kvcached,,Apache-2.0,kv-cache;llm;gpu-sharing
994,onnx_transformers,Library for accelerated NLP inference using ONNX Runtime,A library that provides accelerated NLP pipelines by integrating Hugging Face Transformers with ONNX Runtime for faster CPU inference.,AI6;AI6-04,inference_acceleration;nlp_pipeline,library,Python,https://github.com/patil-suraj/onnx_transformers,,Apache-2.0,nlp;onnx;transformers
995,BambooAI,Library for conversational data analysis using LLMs,"A Python library that leverages Large Language Models to perform conversational data discovery, analysis, and visualization.",AI6;AI6-04,data_analysis;scientific_visualization,library,Python,https://github.com/pgalko/BambooAI,,MIT,data-analysis;llm;visualization
996,neural-imaging,Toolbox for modeling and optimizing photo acquisition pipelines,"A Python toolbox for modeling, simulating, and optimizing various stages of photo acquisition and distribution pipelines, including ISP and compression.",AI6;AI6-04,image_processing;pipeline_optimization,library,Python,https://github.com/pkorus/neural-imaging,,None,imaging;isp;optimization
997,FastV,Inference acceleration library for Large Vision-Language Models,A plug-and-play inference acceleration library for Large Vision-Language Models (LVLMs) that reduces computational cost via token pruning.,AI6;AI6-04,inference_acceleration;token_pruning,library,Python,https://github.com/pkunlp-icler/FastV,,None,lvlm;acceleration;pruning
998,PlaidML,Tensor compiler and runtime for deep learning on diverse hardware,A tensor compiler and runtime framework that enables deep learning on a wide range of hardware devices by using OpenCL and other backends.,AI6;AI6-04,model_compilation;inference_runtime,solver,C++,https://github.com/plaidml/plaidml,,Apache-2.0,compiler;opencl;deep-learning
999,YOLOv5-Lite,Lightweight YOLOv5 implementation optimized for edge devices with NPU/GPU support,"A lightweight version of YOLOv5 designed for edge computing devices like Raspberry Pi. It features model pruning and quantization (int8/fp16) to achieve high inference speeds (e.g., 15 FPS on RPi 4B) while maintaining reasonable accuracy, suitable for real-time object detection in resource-constrained scientific or field environments.",AI6-04;Computer Vision,inference_optimization;quantization;edge_computing,library,C++,https://github.com/ppogg/YOLOv5-Lite,,GPL-3.0,yolo;quantization;edge-ai;ncnn;mnn
1000,DinkyTrain,Lightweight pre-training library with DeepSpeed integration,"A pre-training library from Princeton NLP based on fairseq, integrated with DeepSpeed kernels. It is designed to facilitate efficient training of language models, providing a streamlined interface for research into model pre-training and optimization.",AI6-04;NLP,training_acceleration;model_pretraining,library,Python,https://github.com/princeton-nlp/DinkyTrain,,MIT,deepspeed;training;nlp;fairseq
1001,Prometheus-Eval,LLM evaluation toolkit using Prometheus and GPT-4,"A toolkit for evaluating Large Language Models (LLMs) by leveraging Prometheus (an open-source evaluator LLM) and GPT-4. It provides a framework for assessing model responses, enabling researchers to perform quality control and comparative analysis of generative models.",AI11;NLP,model_evaluation;quality_control,library,Python,https://github.com/prometheus-eval/prometheus-eval,,Apache-2.0,llm-evaluation;benchmark;prometheus
1002,Torch-TensorRT,PyTorch compiler for NVIDIA GPUs using TensorRT,A compiler for PyTorch/TorchScript/FX that targets NVIDIA GPUs using NVIDIA's TensorRT deep learning optimizer and runtime. It accelerates inference for PyTorch models by leveraging TensorRT's optimizations while maintaining the ease of use of the PyTorch ecosystem.,AI6-04;AI Infra,compiler;inference_acceleration,library,Python,https://github.com/pytorch/TensorRT,https://pytorch.org/TensorRT/,BSD-3-Clause,pytorch;tensorrt;inference;compiler;gpu
1003,PyTorch-ORT,PyTorch acceleration via ONNX Runtime,A library that accelerates PyTorch model training and inference by integrating with ONNX Runtime. It allows users to run PyTorch models with the performance benefits of ONNX Runtime's optimizations without leaving the PyTorch environment.,AI6-04;AI Infra,inference_acceleration;training_acceleration,library,Python,https://github.com/pytorch/ort,https://onnxruntime.ai/,MIT,onnx-runtime;pytorch;acceleration
1004,PyTorch XLA,PyTorch support for XLA devices (TPU/GPU),"A Python package that connects PyTorch to the XLA (Accelerated Linear Algebra) compiler, enabling PyTorch models to run on high-performance XLA devices such as Google TPUs and GPUs. It provides the necessary runtime and compiler integration for scaling PyTorch workloads.",AI6-04;AI Infra,compiler;training_acceleration;inference_acceleration,library,C++,https://github.com/pytorch/xla,https://github.com/pytorch/xla,NOASSERTION,xla;tpu;pytorch;compiler
1005,async_cosyvoice,Accelerated inference for CosyVoice2 using vLLM,A tool designed to accelerate the inference of the CosyVoice2 text-to-speech model by leveraging vLLM (a high-throughput and memory-efficient LLM serving engine). It optimizes the runtime performance for audio generation tasks.,AI6-04;Audio,inference_acceleration;audio_generation,library,Jupyter Notebook,https://github.com/qi-hua/async_cosyvoice,,Apache-2.0,vllm;cosyvoice;inference;tts
1006,AIMET,AI Model Efficiency Toolkit for quantization and compression,"A library that provides advanced model quantization and compression techniques for trained neural networks. It helps in reducing model size and improving inference latency on edge devices while maintaining accuracy, supporting both post-training quantization and quantization-aware training.",AI6-04;AI Infra,quantization;model_compression,library,Python,https://github.com/quic/aimet,https://quic.github.io/aimet-pages/index.html,NOASSERTION,quantization;compression;neural-networks
1007,Chatterbox-vLLM,vLLM port of the Chatterbox TTS model,"A port of the Chatterbox Text-to-Speech model to the vLLM inference engine. This tool enables high-performance serving of the Chatterbox model, leveraging vLLM's memory management and batching capabilities for efficient audio synthesis.",AI6-04;Audio,inference_acceleration;inference_serving,library,Python,https://github.com/randombk/chatterbox-vllm,,MIT,vllm;tts;inference
1008,ComfyUI_Step1X-Edit,TeaCache acceleration plugin for ComfyUI,"A plugin for ComfyUI that implements TeaCache acceleration, enabling up to 2x faster inference for generative models with minimal quality loss. It serves as an optimization tool for image generation workflows.",AI6-04;Generative AI,inference_acceleration;caching,library,Python,https://github.com/raykindle/ComfyUI_Step1X-Edit,,MIT,comfyui;acceleration;teacache
1009,RZV DRP-AI TVM,Apache TVM extension for Renesas DRP-AI accelerators,"An extension package for the Apache TVM machine learning compiler, specifically designed to support Renesas DRP-AI accelerators. It enables the compilation and optimization of deep learning models for deployment on Renesas hardware.",AI6-04;Embedded AI,compiler;hardware_acceleration,library,C++,https://github.com/renesas-rz/rzv_drp-ai_tvm,,Apache-2.0,tvm;compiler;drp-ai;renesas
1010,FreeTensor,Language and compiler for irregular tensor programs,A domain-specific language and compiler designed for optimizing irregular tensor programs. It targets high-performance computing scenarios where standard tensor compilers may struggle with irregular data structures or access patterns.,AI6-04;HPC,compiler;tensor_computation,library,C++,https://github.com/roastduck/FreeTensor,,Apache-2.0,compiler;tensor;hpc;irregular-computation
1011,Roboflow Inference,High-performance inference server for computer vision,"A comprehensive inference server and library for running computer vision models on various devices (edge to cloud). It provides a unified interface for deploying models, managing inference pipelines, and optimizing runtime performance.",AI6-04;Computer Vision,inference_serving;deployment,platform,Python,https://github.com/roboflow/inference,https://inference.roboflow.com/,NOASSERTION,inference-server;computer-vision;deployment
1012,l2hmc-qcd,L2HMC algorithm implementation for Lattice QCD simulations,"An implementation of the L2HMC (Learning to Hamiltonian Monte Carlo) algorithm specifically applied to simulations in Lattice Quantum Chromodynamics (QCD). It serves as a computational tool for physics research, enabling more efficient sampling in high-dimensional spaces.",AI4S;Physics,simulation;lattice_qcd;sampling,solver,Jupyter Notebook,https://github.com/saforem2/l2hmc-qcd,,Apache-2.0,l2hmc;lattice-qcd;physics-simulation;mcmc
1013,HLOEnv,RL environment for XLA compiler optimization research,A research environment based on XLA (Accelerated Linear Algebra) designed for deep learning compiler optimization. It allows researchers to apply reinforcement learning techniques to optimize HLO (High Level Optimizer) passes and graph transformations.,AI6-04;Compiler Research,compiler_optimization;reinforcement_learning,library,C++,https://github.com/sail-sg/hloenv,,Apache-2.0,xla;compiler;reinforcement-learning;optimization
1014,Sbnb Linux,Linux distribution optimized for AI workloads,"A specialized Linux distribution designed for AI computers, automating the setup and execution of AI workloads like vLLM, SGLang, and RAG pipelines. It serves as an infrastructure platform to facilitate reproducible AI research and deployment.",AI6;AI Infra,environment_management;infrastructure,platform,Shell,https://github.com/sbnb-io/sbnb,https://sbnb.io,MIT,linux-distro;ai-infrastructure;vllm
1015,Red Candle,Ruby interface for local LLM inference via Candle,"A Ruby gem that provides an interface to run state-of-the-art language models locally, powered by the Rust-based Candle framework. It supports Metal/CUDA acceleration, enabling Ruby-based scientific workflows to leverage efficient local LLM inference.",AI6-04;NLP,inference_acceleration;inference_serving,library,Rust,https://github.com/scientist-labs/red-candle,,MIT,ruby;candle;llm;inference
1016,ScatterMoE,Triton-based Sparse Mixture of Experts implementation,"A high-performance implementation of Sparse Mixture of Experts (MoE) using OpenAI's Triton language. It provides efficient kernels for training and inference of MoE models, serving as a building block for large-scale model acceleration.",AI6-04;AI Infra,training_acceleration;inference_acceleration,library,Python,https://github.com/shawntan/scattermoe,,Apache-2.0,triton;moe;mixture-of-experts;acceleration
1017,TensorRT_Pro,C++ library for easy TensorRT integration,"A C++ library that simplifies the integration and usage of NVIDIA TensorRT. It provides a high-level API for loading models, managing memory, and executing inference, aiming to streamline the deployment of accelerated deep learning models.",AI6-04;AI Infra,inference_acceleration;deployment,library,C++,https://github.com/shouxieai/tensorRT_Pro,,MIT,tensorrt;c++;inference;wrapper
1018,chatGLM-6B-QLoRA,Efficient fine-tuning and quantization implementation for ChatGLM models,"A specific implementation for 4-bit QLoRA fine-tuning of ChatGLM-6B/ChatGLM2-6B models, including LoRA model merging and 4-bit quantization capabilities.",AI6-04,model_quantization;fine_tuning,solver,Python,https://github.com/shuxueslpi/chatGLM-6B-QLoRA,,None,qlora;quantization;llm;chatglm
1019,Tacker,Tensor-CUDA Core Kernel Fusion for Improving GPU Utilization,"A kernel fusion tool that leverages Tensor Cores and CUDA Cores to improve GPU utilization while ensuring QoS, specifically designed for optimizing deep learning workloads.",AI6-04,kernel_optimization;gpu_acceleration,solver,C++,https://github.com/sjtu-epcc/Tacker,,Apache-2.0,kernel-fusion;cuda;gpu-optimization
1020,ArcticInference,"vLLM plugin for high-throughput, low-latency inference","A plugin for vLLM designed to enable high-throughput and low-latency inference, specifically optimized for Snowflake's Arctic models and enterprise-grade workloads.",AI6-04,inference_acceleration;model_serving,library,Python,https://github.com/snowflakedb/ArcticInference,,Apache-2.0,vllm;inference;llm
1021,llms_tool,"Toolkit for LLM training, testing, quantization and deployment","A comprehensive tool based on HuggingFace for Large Language Model training (Pre-training, SFT, RM, PPO, DPO), testing, quantization, and model fusion.",AI6-04,model_training;model_quantization;fine_tuning,workflow,Python,https://github.com/stanleylsx/llms_tool,,Apache-2.0,llm;quantization;fine-tuning;rlhf
1022,catgrad,A categorical deep learning compiler,"A compiler for deep learning that leverages categorical concepts, providing a framework for compiling and optimizing neural network models.",AI6-04,compiler;model_optimization,solver,Python,https://github.com/statusfailed/catgrad,,MIT,compiler;deep-learning;category-theory
1023,llm_finetuning,Wrapper for LLM fine-tuning and inference with quantization,"A convenient wrapper tool for fine-tuning and running inference on Large Language Models, supporting quantization techniques like GPTQ and bitsandbytes.",AI6-04,fine_tuning;model_quantization;inference,workflow,Python,https://github.com/taprosoft/llm_finetuning,,Apache-2.0,llm;gptq;bitsandbytes;fine-tuning
1024,Tensara,Competitive GPU kernel optimization platform,"A platform designed for optimizing GPU kernels, likely providing tools or frameworks to benchmark and improve kernel performance for deep learning or scientific computing.",AI6-04,kernel_optimization;gpu_acceleration,platform,TypeScript,https://github.com/tensara/tensara,,GPL-3.0,gpu;optimization;kernel
1025,taco,The Tensor Algebra Compiler,"A compiler that computes sparse tensor expressions on CPUs and GPUs, automatically generating efficient code for complex tensor algebra operations used in scientific computing and machine learning.",AI6-04,compiler;tensor_algebra;sparse_computation,solver,C++,https://github.com/tensor-compiler/taco,http://tensor-compiler.org,NOASSERTION,compiler;tensor-algebra;sparse-tensors
1026,TensorFlow Model Optimization Toolkit,Toolkit to optimize ML models for deployment,"A suite of tools for optimizing machine learning models for deployment and execution, including techniques like quantization and pruning to reduce model size and improve latency.",AI6-04,model_quantization;model_pruning;optimization,library,Python,https://github.com/tensorflow/model-optimization,https://www.tensorflow.org/model_optimization,Apache-2.0,tensorflow;quantization;pruning;optimization
1027,HyperPose,Library for Fast and Flexible Human Pose Estimation,"A library built on TensorLayer for high-performance human pose estimation, focusing on acceleration and flexibility for real-time applications and research.",AI6-04,pose_estimation;inference_acceleration,library,Python,https://github.com/tensorlayer/HyperPose,,None,pose-estimation;tensorlayer;acceleration
1028,tt-forge-fe,Graph compiler for Tenstorrent hardware,"A graph compiler frontend designed to optimize and transform computational graphs for deep learning models, specifically targeting Tenstorrent's AI hardware accelerators.",AI6-04,compiler;graph_optimization,solver,Python,https://github.com/tenstorrent/tt-forge-fe,,Apache-2.0,compiler;tenstorrent;graph-optimization
1029,tt-xla,PJRT device implementation for Tenstorrent AI Compiler,"Implementation of a PJRT (Pretty Just-In-Time Runtime) device for Tenstorrent's AI compiler stack, enabling XLA (Accelerated Linear Algebra) compatibility.",AI6-04,compiler;backend_integration,library,Python,https://github.com/tenstorrent/tt-xla,,Apache-2.0,xla;compiler;tenstorrent
1030,SageAttention,Quantized Attention acceleration library,"A library implementing Quantized Attention that achieves significant speedups compared to FlashAttention without losing accuracy, applicable to language, image, and video models.",AI6-04,attention_acceleration;quantization,library,Cuda,https://github.com/thu-ml/SageAttention,,Apache-2.0,attention;quantization;acceleration;cuda
1031,SpargeAttn,Training-free sparse attention for inference acceleration,"A library implementing SpargeAttention, a training-free sparse attention mechanism designed to accelerate model inference across various architectures.",AI6-04,attention_acceleration;sparse_computation,library,Cuda,https://github.com/thu-ml/SpargeAttn,,Apache-2.0,sparse-attention;inference-acceleration;cuda
1032,DAMO-YOLO,Fast and accurate object detection method with NAS and distillation,"A high-performance object detection framework incorporating Neural Architecture Search (NAS) backbones, efficient RepGFPN, and distillation enhancement for accelerated inference.",AI6-04,object_detection;model_distillation;nas,solver,Python,https://github.com/tinyvision/DAMO-YOLO,,Apache-2.0,object-detection;yolo;nas;distillation
1033,TonY,Framework to natively run deep learning on Apache Hadoop,"TonY (TensorFlow on YARN) is a framework for running distributed deep learning jobs (TensorFlow, PyTorch, etc.) on Apache Hadoop clusters, enabling scalable scientific computing.",AI6,distributed_training;job_scheduling,platform,Java,https://github.com/tony-framework/TonY,,NOASSERTION,hadoop;distributed-training;yarn
1034,llama.onnx,ONNX export and quantization tools for LLaMa/RWKV,A set of tools and scripts for converting LLaMa and RWKV models to ONNX format and performing quantization to enable efficient inference.,AI6-04,model_quantization;model_conversion,solver,Python,https://github.com/tpoisonooo/llama.onnx,,GPL-3.0,onnx;quantization;llama;rwkv
1035,GDS3D,3D hardware accelerated viewer for GDSII IC layouts,"An application that interprets IC layouts (GDSII files) and renders them in 3D, allowing real-time control over camera position and angle for inspecting chip designs.",AI6;AI6-04,scientific_visualization;chip_design,application,C++,https://github.com/trilomix/GDS3D,,GPL-2.0,gdsii;3d-rendering;ic-layout;visualization
1036,YOLOv8-TensorRT,TensorRT implementation for YOLOv8 acceleration,"A C++ and Python implementation for accelerating YOLOv8 object detection models using NVIDIA TensorRT, optimized for high-performance inference.",AI6;AI6-04,inference_acceleration;computer_vision,solver,C++,https://github.com/triple-Mu/YOLOv8-TensorRT,,MIT,tensorrt;yolov8;inference;acceleration
1037,Triton Backend,Utilities for creating custom Triton Inference Server backends,"Common source code, scripts, and utilities designed to facilitate the creation and maintenance of backends for the Triton Inference Server.",AI6;AI6-04,inference_serving;backend_development,library,C++,https://github.com/triton-inference-server/backend,https://github.com/triton-inference-server/server,BSD-3-Clause,triton;inference-server;backend
1038,Triton Client,Client libraries for Triton Inference Server,"Provides Python, C++, and Java client libraries, along with GRPC-generated examples, to interact with the Triton Inference Server for sending inference requests.",AI6;AI6-04,inference_serving;client_interface,library,Python,https://github.com/triton-inference-server/client,https://github.com/triton-inference-server/server,BSD-3-Clause,triton;client;grpc;http
1039,Triton Model Analyzer,Profiling tool for Triton model compute and memory requirements,"A CLI tool that helps users understand the compute and memory requirements of models served by Triton Inference Server, enabling configuration optimization.",AI6;AI6-04,profiling;optimization,application,Python,https://github.com/triton-inference-server/model_analyzer,https://github.com/triton-inference-server/server,Apache-2.0,profiling;optimization;triton;inference
1040,Triton Model Navigator,Toolkit for optimizing and deploying DL models on NVIDIA GPUs,"An inference toolkit designed to automate the process of moving deep learning models from training to deployment, focusing on optimization for NVIDIA GPUs within the Triton ecosystem.",AI6;AI6-04,model_optimization;deployment,workflow,Python,https://github.com/triton-inference-server/model_navigator,https://github.com/triton-inference-server/server,Apache-2.0,deployment;optimization;nvidia;triton
1041,Triton ONNX Runtime Backend,ONNX Runtime integration for Triton Inference Server,The backend implementation that allows Triton Inference Server to execute models using the ONNX Runtime engine.,AI6;AI6-04,inference_serving;runtime_integration,library,C++,https://github.com/triton-inference-server/onnxruntime_backend,https://github.com/triton-inference-server/server,BSD-3-Clause,onnx;triton;backend
1042,Triton Python Backend,Python execution backend for Triton Inference Server,"Enables pre-processing, post-processing, and other custom logic to be implemented in Python and executed within the Triton Inference Server pipeline.",AI6;AI6-04,inference_serving;custom_logic,library,C++,https://github.com/triton-inference-server/python_backend,https://github.com/triton-inference-server/server,BSD-3-Clause,python;triton;backend
1043,PyTriton,Python interface for deploying models with Triton,"A Flask/FastAPI-like interface that simplifies the deployment of Python models and functions using Triton Inference Server, allowing developers to bind Python functions to Triton endpoints.",AI6;AI6-04,inference_serving;deployment,library,Python,https://github.com/triton-inference-server/pytriton,https://triton-inference-server.github.io/pytriton,Apache-2.0,python;serving;triton;deployment
1044,Triton Inference Server,High-performance inference serving platform,"An open-source inference serving software that streamlines AI inference by enabling teams to deploy, run, and scale trained AI models from any framework on any GPU- or CPU-based infrastructure.",AI6;AI6-04,inference_serving;platform,platform,Python,https://github.com/triton-inference-server/server,https://developer.nvidia.com/nvidia-triton-inference-server,BSD-3-Clause,inference;server;gpu;cloud;edge
1045,Triton TensorRT-LLM Backend,TensorRT-LLM integration for Triton Inference Server,A backend for Triton Inference Server that enables the execution of Large Language Models (LLMs) optimized with NVIDIA TensorRT-LLM.,AI6;AI6-04,inference_serving;llm_acceleration,library,C++,https://github.com/triton-inference-server/tensorrtllm_backend,https://github.com/triton-inference-server/server,Apache-2.0,llm;tensorrt;triton;backend
1046,Triton,Language and compiler for custom Deep Learning primitives,A language and compiler for writing highly efficient custom Deep Learning primitives. It aims to provide an open-source environment to write fast code at higher productivity than CUDA.,AI6;AI6-04,compiler;kernel_optimization,library,MLIR,https://github.com/triton-lang/triton,https://triton-lang.org/,MIT,compiler;gpu;cuda;optimization;deep-learning
1047,TrustGraph,Graph-based tool to reduce AI hallucinations,A tool designed to eliminate hallucinations from AI agents by leveraging knowledge graphs and trusted data sources to ground the generation process.,AI6;AI6-04,knowledge_graph;ai_reliability,library,Python,https://github.com/trustgraph-ai/trustgraph,,Apache-2.0,hallucination;knowledge-graph;ai-agent;reliability
1048,Petastorm,Data access library for deep learning from Parquet,"A library that enables single machine or distributed training and evaluation of deep learning models directly from datasets in Apache Parquet format, supporting TensorFlow, PyTorch, and PySpark.",AI6;AI6-04,data_loading;distributed_training,library,Python,https://github.com/uber/petastorm,,Apache-2.0,parquet;data-loading;deep-learning;distributed-training
1049,Telamon,Optimization framework for GPU computational kernels,"A framework designed to explore and find optimal combinations of optimizations for computational kernels running on GPUs, acting as an auto-tuning tool.",AI6;AI6-04,kernel_optimization;auto_tuning,solver,Rust,https://github.com/ulysseB/telamon,,Apache-2.0,gpu;optimization;kernel;auto-tuning
1050,SparseTIR,Sparse tensor compiler for deep learning,"A compiler infrastructure for sparse tensor algebra in deep learning, enabling efficient execution of sparse operations on hardware accelerators.",AI6;AI6-04,compiler;sparse_computation,library,Python,https://github.com/uwsampl/SparseTIR,,Apache-2.0,compiler;sparse-tensor;deep-learning;optimization
1051,Cache-DiT,Inference engine with cache acceleration for Diffusion Transformers,A PyTorch-native inference engine that utilizes hybrid cache acceleration and parallelism to speed up Diffusion Transformer (DiT) models like Z-Image and FLUX2.,AI6;AI6-04,inference_acceleration;diffusion_models,solver,Python,https://github.com/vipshop/cache-dit,,Apache-2.0,diffusion-transformer;inference;cache;acceleration
1052,LLM Compressor,Library for compressing LLMs for vLLM deployment,"A library compatible with Transformers for applying various compression algorithms (quantization, sparsification) to Large Language Models to optimize them for deployment with vLLM.",AI6;AI6-04,model_compression;quantization,library,Python,https://github.com/vllm-project/llm-compressor,,Apache-2.0,llm;compression;quantization;vllm
1053,Semantic Router,Routing layer for Mixture-of-Models and LLM agents,"An intelligent routing tool for AI systems that directs queries to the most appropriate model or agent based on semantic meaning, optimizing resource usage and response quality.",AI6;AI6-04,inference_routing;model_orchestration,library,Go,https://github.com/vllm-project/semantic-router,,Apache-2.0,routing;llm;mixture-of-models;agent
1054,vLLM Ascend,Ascend NPU hardware plugin for vLLM,"A community-maintained plugin that enables vLLM to run on Huawei Ascend hardware, providing hardware-specific optimizations for LLM inference.",AI6;AI6-04,hardware_acceleration;inference_serving,library,Python,https://github.com/vllm-project/vllm-ascend,,Apache-2.0,ascend;npu;vllm;hardware-support
1055,vLLM Omni,Inference framework for omni-modality models,"An extension of the vLLM framework designed to support efficient inference for omni-modality models (processing text, image, audio, etc. simultaneously).",AI6;AI6-04,multimodal_inference;serving,library,Python,https://github.com/vllm-project/vllm-omni,,Apache-2.0,multimodal;inference;vllm;omni-modality
1056,PytorchAutoDrive,Toolkit for segmentation and lane detection in autonomous driving,"A PyTorch-based toolkit providing implementations of various segmentation and lane detection models (ERFNet, SCNN, etc.) along with tools for training, visualization, benchmarking, and deployment.",AI6;AI6-04,computer_vision;autonomous_driving,library,Python,https://github.com/voldemortX/pytorch-auto-drive,,BSD-3-Clause,autonomous-driving;segmentation;lane-detection;pytorch
1057,TensorRTx,TensorRT implementations of popular deep learning networks,"A comprehensive collection of TensorRT network definition API implementations for popular deep learning models, serving as a reference and library for accelerating these models.",AI6;AI6-04,inference_acceleration;model_implementation,library,C++,https://github.com/wang-xinyu/tensorrtx,,MIT,tensorrt;deep-learning;acceleration;inference
1058,3d-model-convert-to-gltf,Converter for 3D models to glTF format,"A utility tool to convert various 3D model formats (STL, IGES, STEP, OBJ, FBX) into the glTF format, often used for efficient transmission and loading of 3D scenes.",AI6;AI6-04,data_conversion;scientific_visualization,application,Python,https://github.com/wangerzi/3d-model-convert-to-gltf,,Apache-2.0,3d-model;converter;gltf;visualization
1059,QLLM,Quantization toolbox for Large Language Models,"A general quantization toolbox supporting 2-8 bit quantization methods like GPTQ, AWQ, HQQ, and VPTQ, with capabilities to export models to ONNX/ONNX Runtime.",AI6;AI6-04,quantization;model_compression,library,Python,https://github.com/wejoncy/QLLM,,Apache-2.0,quantization;llm;onnx;compression
1060,QDrop,Post-training quantization method implementation,The official implementation of the QDrop method for randomly dropping quantization during post-training quantization to achieve better performance with low-bit models.,AI6;AI6-04,quantization;model_optimization,library,Python,https://github.com/wimh966/QDrop,,MIT,quantization;ptq;deep-learning;optimization
1061,QwT,Post-training quantization library with lightweight linear compensation,A PyTorch implementation of 'Quantization without Tears' (QwT) that provides fast and accurate post-training network quantization using lightweight linear compensation layers to minimize accuracy loss.,AI6;AI6-04,quantization;model_compression,library,Python,https://github.com/wujx2001/QwT,,Apache-2.0,quantization;pytorch;post-training-quantization
1062,rknn-3588-npu-yolo-accelerate,YOLOv5 inference acceleration on RK3588 NPU,"A C++ implementation for deploying and accelerating YOLOv5 object detection models on Rockchip RK3588 NPUs, utilizing thread pools for efficient inference.",AI6;AI6-04,inference_acceleration;edge_computing,solver,C++,https://github.com/wzxzhuxi/rknn-3588-npu-yolo-accelerate,,Apache-2.0,rknn;npu;yolov5;inference
1063,libonnx,Lightweight pure C99 ONNX inference engine,"A portable and lightweight ONNX inference engine written in pure C99, designed for embedded devices with support for hardware acceleration.",AI6;AI6-04,inference_engine;embedded_ai,library,C,https://github.com/xboot/libonnx,,MIT,onnx;inference;embedded;c99
1064,xlang,High-performance dynamic language for AI and IoT,"A next-generation dynamic programming language designed for AI and IoT applications, featuring built-in distributed computing capabilities and high performance.",AI6;AI6-04,compiler;programming_language,platform,C,https://github.com/xlang-foundation/xlang,,Apache-2.0,language;compiler;distributed-computing
1065,lite.ai.toolkit,"C++ AI toolkit wrapping MNN, ONNXRuntime, and TensorRT","A lightweight C++ toolkit that integrates multiple inference backends (MNN, ONNXRuntime, TensorRT) to support over 100 models for tasks like detection, segmentation, and generation.",AI6;AI6-04,inference_acceleration;model_deployment,library,C++,https://github.com/xlite-dev/lite.ai.toolkit,,GPL-3.0,inference;mnn;tensorrt;onnxruntime
1066,onnx_runtime_cpp,Simplified C++ wrapper for ONNX Runtime,"A small C++ library designed to facilitate the quick deployment of machine learning models using ONNX Runtime, providing a simplified interface for inference.",AI6;AI6-04,inference_deployment;model_serving,library,C++,https://github.com/xmba15/onnx_runtime_cpp,,MIT,onnx-runtime;cpp;inference
1067,Xinference,Unified inference platform for LLMs and multimodal models,"A production-ready inference platform that allows running open-source LLMs, speech, and multimodal models on cloud or on-premise infrastructure with a unified API compatible with GPT.",AI6;AI6-04,inference_serving;llm_inference,platform,Python,https://github.com/xorbitsai/inference,https://inference.readthedocs.io,Apache-2.0,llm;inference-server;distributed-inference
1068,local-dream,Stable Diffusion inference on Android with NPU acceleration,"An application and toolkit for running Stable Diffusion models on Android devices, leveraging Snapdragon NPU acceleration as well as CPU/GPU support.",AI6;AI6-04,mobile_inference;generative_ai,solver,Kotlin,https://github.com/xororz/local-dream,,NOASSERTION,android;stable-diffusion;npu;inference
1069,GlobalCom2,Plug-and-play inference acceleration for LVLMs,A tool implementing 'Global Compression Commander' for accelerating high-resolution Large Vision-Language Models (LVLMs) inference through token compression.,AI6;AI6-04,inference_acceleration;model_compression,library,Python,https://github.com/xuyang-liu16/GlobalCom2,,Apache-2.0,lvlm;compression;acceleration
1070,VidCom2,Inference acceleration for Video LLMs,"A plug-and-play tool for accelerating Video Large Language Models inference via video compression techniques, as presented at EMNLP 2025.",AI6;AI6-04,inference_acceleration;video_processing,library,Python,https://github.com/xuyang-liu16/VidCom2,,Apache-2.0,video-llm;compression;inference
1071,LOPQ,Locally Optimized Product Quantization for ANN search,A library for training Locally Optimized Product Quantization (LOPQ) models to enable efficient approximate nearest neighbor search for high-dimensional data.,AI6;AI6-04,quantization;ann_search,library,Python,https://github.com/yahoo/lopq,,Apache-2.0,quantization;ann;search;spark
1072,face-parsing,Real-time face parsing inference with ONNX Runtime,"A tool for real-time face parsing using BiSeNet, providing a pipeline from PyTorch training to ONNX Runtime inference.",AI6;AI6-04,image_segmentation;inference_deployment,solver,Python,https://github.com/yakhyo/face-parsing,,MIT,face-parsing;onnx;segmentation
1073,face-reidentification,Face re-identification pipeline with FAISS and ONNX,"A complete pipeline for face re-identification integrating SCRFD for detection, ArcFace for recognition, and FAISS for vector search, optimized for ONNX Runtime inference.",AI6;AI6-04,face_recognition;inference_pipeline,solver,Python,https://github.com/yakhyo/face-reidentification,,None,face-reid;faiss;onnx
1074,gaze-estimation,Real-time gaze estimation inference models,"A collection of real-time gaze estimation models (ResNet, MobileNet, etc.) optimized for inference using ONNX Runtime.",AI6;AI6-04,gaze_estimation;inference_deployment,solver,Python,https://github.com/yakhyo/gaze-estimation,,MIT,gaze-estimation;onnx;real-time
1075,Monocular_Depth_Estimation_TRT,TensorRT optimization for monocular depth estimation,"A toolkit for optimizing monocular depth estimation models using TensorRT, including model conversion and inference acceleration for 3D reconstruction tasks.",AI6;AI6-04,inference_acceleration;depth_estimation,solver,Python,https://github.com/yester31/Monocular_Depth_Estimation_TRT,,MIT,tensorrt;depth-estimation;acceleration
1076,LLM-SFT,Framework for Chinese LLM supervised fine-tuning,"A comprehensive framework for Supervised Fine-Tuning (SFT) of Large Language Models (LLMs), supporting multiple base models (ChatGLM, LLaMA, etc.) and acceleration techniques like LoRA, QLoRA, and DeepSpeed.",AI6;AI6-04,model_training;fine_tuning,workflow,Python,https://github.com/yongzhuo/LLM-SFT,,Apache-2.0,llm;sft;fine-tuning;deepspeed
1077,SimVQ,Vector quantization method to address representation collapse,"An implementation of SimVQ, a method to improve vector quantized models by addressing representation collapse using a linear layer approach, as presented at ICCV 2025.",AI6;AI6-04,quantization;representation_learning,library,Python,https://github.com/youngsheen/SimVQ,,MIT,vector-quantization;iccv;computer-vision
1078,rknn-cpp-yolo,Optimized YOLOv11 inference on RK3588,A C++ project for efficient real-time inference of YOLOv11 on RK3588 platforms using RKNN and RGA hardware acceleration.,AI6;AI6-04,inference_acceleration;edge_computing,solver,C++,https://github.com/yuunnn-w/rknn-cpp-yolo,,GPL-3.0,rknn;yolo;rk3588;inference
1079,Optimizing-SGEMM-on-NVIDIA-Turing-GPUs,High-performance SGEMM kernels for NVIDIA GPUs,"A collection of highly optimized SGEMM (Single-Precision General Matrix Multiply) kernel functions for NVIDIA Turing GPUs, achieving performance close to cuBLAS.",AI6;AI6-04,hpc_kernels;matrix_multiplication,library,Cuda,https://github.com/yzhaiustc/Optimizing-SGEMM-on-NVIDIA-Turing-GPUs,,GPL-3.0,cuda;sgemm;optimization;hpc
1080,AI-research-SKILLs,Library of AI research skills for agents,A comprehensive library of AI research and engineering skills designed to be packaged into AI agents (like Claude or Gemini) to enhance their capabilities in conducting AI research.,AI6;AI6-04,agent_tools;research_automation,library,Python,https://github.com/zechenzhangAGI/AI-research-SKILLs,,MIT,ai-agent;research-tools;skills-library
1081,ZhiLight,High-performance LLM inference engine,"A highly optimized inference acceleration engine specifically designed for Llama and its variants, providing efficient serving capabilities.",AI6;AI6-04,inference_engine;llm_serving,platform,C++,https://github.com/zhihu/ZhiLight,,Apache-2.0,llm;inference;acceleration;llama
1082,yolort,Runtime stack for YOLOv5 on accelerators,"A runtime stack that simplifies the deployment of YOLOv5 models on specialized accelerators such as TensorRT, LibTorch, ONNX Runtime, TVM, and NCNN.",AI6;AI6-04,inference_runtime;model_deployment,library,Python,https://github.com/zhiqwang/yolort,,GPL-3.0,yolov5;tensorrt;tvm;inference
1083,PTQD,Post-training quantization for diffusion models,"The official implementation of PTQD, a method for accurate post-training quantization specifically tailored for diffusion models.",AI6;AI6-04,quantization;diffusion_models,library,Jupyter Notebook,https://github.com/ziplab/PTQD,,None,quantization;diffusion;post-training
1084,KnowLM,Knowledgeable Large Language Model Framework,"An open-source framework for building and training Knowledgeable Large Language Models, focusing on integrating knowledge graphs and structured data.",AI6;AI6-04,llm_framework;knowledge_integration,workflow,Python,https://github.com/zjunlp/KnowLM,,MIT,llm;knowledge-graph;framework
1085,RepQ-ViT,Post-training quantization for Vision Transformers,"A tool implementing RepQ-ViT, a scale reparameterization method for post-training quantization of Vision Transformers (ViTs).",AI6;AI6-04,quantization;vision_transformer,library,Python,https://github.com/zkkli/RepQ-ViT,,Apache-2.0,quantization;vit;post-training
1086,zml,High-performance AI compiler and runtime stack,"A machine learning compiler and runtime stack built with Zig, OpenXLA, and MLIR, designed to run any model on any hardware with zero compromise.",AI6;AI6-04,compiler;runtime,platform,Zig,https://github.com/zml/zml,,Apache-2.0,compiler;zig;mlir;openxla
1087,ssh-dashboard,Lightweight CLI dashboard for monitoring GPU/CPU usage across SSH servers,"A terminal-based dashboard that aggregates and visualizes real-time resource usage (CPU, RAM, Disk, and specifically NVIDIA/AMD GPUs) from multiple remote servers via SSH. It is particularly useful for researchers managing small-scale AI/HPC clusters or GPU workstations.",AI6;AI6-05,monitoring;resource_visualization,platform,Go,https://github.com/AlpinDale/ssh-dashboard,,MIT,gpu-monitoring;ssh;cli;hpc-monitoring
1088,TensorDash,Remote monitoring application for deep learning model training,"A tool that allows researchers to remotely monitor their deep learning model's training metrics (loss, accuracy, etc.) in real-time via a mobile app or dashboard. It supports major frameworks like TensorFlow, PyTorch, and Keras, enabling tracking of long-running scientific experiments.",AI6;AI6-05,experiment_tracking;monitoring,platform,Java,https://github.com/CleanPegasus/TensorDash,,MIT,deep-learning;monitoring;mobile-app;experiment-tracking
1089,coffeeshop,Slack notification tool for deep learning training metrics,"A Python library that integrates with deep learning training loops to send real-time metrics and status updates (epoch completion, crash alerts) to a Slack channel. It facilitates remote monitoring of scientific machine learning experiments.",AI6;AI6-05,alerting;experiment_tracking,library,Python,https://github.com/CleanPegasus/coffeeshop,,MIT,slack;notification;deep-learning;monitoring
1090,Graphical Prototyping Toolbox for ML Experimentation,"Web-based toolbox for ML experiment setup, data preparation, and tracking","A composition of web applications for machine learning experimentation, including components for data preparation, experiment setup, and algorithm tracking (MLflow integration), developed by Fraunhofer MEVIS.",AI6;AI6-05;Medical Imaging,experiment_tracking;workflow_management,platform,Python,https://github.com/FraunhoferMEVIS/Graphical_prototyping_Toolbox_for_ML_Experimentation,,NOASSERTION,ml-experimentation;workflow;fraunhofer
1091,prometheus-cluster-exporter,Prometheus exporter for Lustre and Slurm metrics on HPC clusters,"A monitoring tool that exports Lustre metadata operations and IO throughput metrics associated with SLURM accounts and user processes, designed for HPC cluster observability.",AI6;AI6-05,hpc_monitoring;resource_observability,service,Go,https://github.com/GSI-HPC/prometheus-cluster-exporter,,GPL-3.0,hpc;lustre;slurm;prometheus;monitoring
1092,Tattle,Self-service dashboard application for Graphite and Ganglia monitoring,"A lightweight web application providing dashboards for Graphite and Ganglia, which are legacy but widely used monitoring systems in HPC environments.",AI6;AI6-05,hpc_monitoring;visualization,platform,PHP,https://github.com/Graphite-Tattle/Tattle,,None,ganglia;graphite;dashboard;hpc
1093,CompressAI-Trainer,Training platform for end-to-end deep learning compression models,"A platform for training, evaluating, and benchmarking end-to-end compression models using the CompressAI library, supporting scientific signal processing research.",Computer Science;Signal Processing,model_training;compression,platform,Python,https://github.com/InterDigitalInc/CompressAI-Trainer,,BSD-3-Clause-Clear,compression;deep-learning;compressai
1094,NVTX.jl,Julia bindings for NVIDIA Tools Extension (NVTX) profiling,"Provides Julia bindings for NVTX, allowing researchers to instrument Julia scientific code for profiling with NVIDIA Nsight Systems.",AI6;AI6-05;Scientific Computing,profiling;performance_analysis,library,Julia,https://github.com/JuliaGPU/NVTX.jl,,MIT,julia;gpu;profiling;nvtx;hpc
1095,KohakuBoard,Lightweight local ML experiment tracking system,"A high-efficiency, self-hosted machine learning experiment tracking dashboard, serving as a lightweight alternative to tools like TensorBoard or MLflow for researchers.",AI6;AI6-05,experiment_tracking;visualization,platform,Python,https://github.com/KohakuBlueleaf/KohakuBoard,,NOASSERTION,mlops;experiment-tracking;visualization
1096,BlendingToolKit,Simulation and analysis toolkit for galaxy blending in astronomy,"Tools to create blend catalogs, produce training samples, and implement blending metrics for astronomical surveys, specifically for the LSST Dark Energy Science Collaboration.",Astronomy;Astrophysics,simulation;data_analysis,library,Jupyter Notebook,https://github.com/LSSTDESC/BlendingToolKit,,MIT,astronomy;lsst;galaxy-blending;simulation
1097,extra_keras_metrics,Library of additional metrics for Keras models,"Integrates a comprehensive set of additional training and evaluation metrics into the Keras neural network library, facilitating detailed model performance analysis.",AI6;AI6-05,model_evaluation;metrics,library,Python,https://github.com/LucaCappelletti94/extra_keras_metrics,,MIT,keras;metrics;deep-learning;evaluation
1098,Vernier,Caliper-based profiler for scientific code on HPC platforms,"A profiling tool developed by the Met Office designed for scientific applications on High Performance Computing (HPC) platforms, using a caliper-based approach.",AI6;AI6-05;HPC,profiling;performance_analysis,solver,C++,https://github.com/MetOffice/Vernier,,BSD-3-Clause,hpc;profiling;met-office;performance
1099,dynolog,Telemetry daemon for AI/HPC performance monitoring and tracing,"A telemetry daemon that exports metrics from Linux kernel, CPU, GPU, and integrates with PyTorch to trigger traces for distributed training applications, developed by Moore Threads.",AI6;AI6-05,profiling;telemetry;distributed_training,service,C++,https://github.com/MooreThreads/dynolog,,NOASSERTION,telemetry;pytorch;gpu;profiling;hpc
1100,dcgm-exporter,NVIDIA GPU metrics exporter for Prometheus,"A tool that leverages the NVIDIA Data Center GPU Manager (DCGM) to export GPU metrics to Prometheus, essential for monitoring AI and HPC clusters.",AI6;AI6-05,gpu_monitoring;infrastructure_observability,service,Go,https://github.com/NVIDIA/dcgm-exporter,,Apache-2.0,nvidia;gpu;prometheus;monitoring;dcgm
1101,gpu-monitoring-tools,Legacy tools for monitoring NVIDIA GPUs on Linux,"A collection of tools for monitoring NVIDIA GPUs, including wrappers and exporters, widely used in HPC and AI infrastructure before the consolidation into dcgm-exporter.",AI6;AI6-05,gpu_monitoring;resource_management,solver,C,https://github.com/NVIDIA/gpu-monitoring-tools,,Apache-2.0,nvidia;gpu;monitoring;linux
1102,nsight-python,Python bindings for NVIDIA Nsight profiling tools,"Provides a Python interface to NVIDIA Nsight tools, enabling researchers to profile and optimize Python-based scientific and AI applications on GPUs.",AI6;AI6-05,profiling;optimization,library,Python,https://github.com/NVIDIA/nsight-python,,Apache-2.0,profiling;nvidia;python;cuda;nsight
1103,slurm2sql,Tool to convert Slurm accounting logs to SQLite for analysis,"A utility that dumps the Slurm workload manager's accounting database into a SQLite3 database, facilitating easy analysis of HPC usage and costs.",AI6;AI6-05,cost_analysis;usage_reporting,solver,Python,https://github.com/NordicHPC/slurm2sql,,MIT,slurm;hpc;accounting;sqlite
1104,sonar,HPC resource usage profiling tool,"A tool designed to profile the usage of HPC resources by regularly probing processes, helping to identify performance bottlenecks and resource efficiency.",AI6;AI6-05,profiling;resource_monitoring,solver,Rust,https://github.com/NordicHPC/sonar,,NOASSERTION,hpc;profiling;rust;monitoring
1105,Jobstats,Job monitoring platform for CPU and GPU clusters in HPC environments,"A job monitoring platform designed for CPU and GPU clusters, providing insights into job performance and resource utilization, specifically tailored for academic or research high-performance computing environments.",AI6;AI6-05,monitoring;resource_profiling,platform,Python,https://github.com/PrincetonUniversity/jobstats,,GPL-2.0,hpc;cluster-monitoring;slurm;gpu-monitoring
1106,ROCmValidationSuite,System validation and diagnostics tool for AMD GPUs in HPC,"A system validation and diagnostics tool designed for monitoring, stress testing, detecting, and troubleshooting issues impacting AMD GPUs specifically in high-performance computing environments.",AI6;AI6-05,hardware_validation;diagnostics,solver,C++,https://github.com/ROCm/ROCmValidationSuite,https://rocm.docs.amd.com/projects/RVS/en/latest/,MIT,rocm;amd-gpu;hpc;diagnostics;stress-testing
1107,gpu-utils,Utilities for monitoring and customizing GPU performance,"A set of utilities for monitoring and customizing GPU performance, useful for optimizing scientific computing workloads on GPU infrastructure.",AI6;AI6-05,monitoring;performance_tuning,solver,Python,https://github.com/Ricks-Lab/gpu-utils,,GPL-3.0,gpu;monitoring;performance;nvidia
1108,easy_metric_learning,Library for training metric learning models,"A Python library designed to simplify the training of metric learning models, facilitating scientific data analysis and machine learning research tasks.",AI4,model_training;metric_learning,library,Python,https://github.com/RocketFlash/easy_metric_learning,,Apache-2.0,metric-learning;machine-learning;deep-learning
1109,StoneNeedle,I/O workload profiling tool for HPC and Cloud computing,"A tool running in the Linux kernel environment to statistic I/O workload profiling data, aimed at enabling I/O optimizations for HPC and Cloud computing in the exascale era.",AI6;AI6-05,io_profiling;performance_analysis,solver,C,https://github.com/Samsung/StoneNeedle,,GPL-2.0,hpc;io-profiling;linux-kernel;performance
1110,slurm_exporter,Prometheus exporter for Slurm-managed clusters metrics,"A Prometheus exporter designed to scrape and expose performance and scheduling metrics from Slurm-managed clusters, supporting CPU and GPU resource accounting for HPC environments.",AI6;AI6-05,monitoring;resource_accounting,service,Go,https://github.com/SckyzO/slurm_exporter,,GPL-3.0,slurm;prometheus-exporter;hpc;monitoring
1111,gpu_mon,Lightweight Python script for monitoring GPU access,"A Python script designed to monitor GPU access and usage, providing a simple way to track GPU resources in scientific computing setups.",AI6;AI6-05,monitoring,solver,Python,https://github.com/Shmuma/gpu_mon,,GPL-3.0,gpu;monitoring;python
1112,nvtop,"Interactive GPU process monitor for NVIDIA, AMD, and others","A task monitor for GPUs and accelerators (AMD, Apple, Huawei, Intel, NVIDIA, Qualcomm), essential for monitoring scientific training and inference jobs.",AI6;AI6-05,monitoring;process_management,solver,C,https://github.com/Syllo/nvtop,,NOASSERTION,gpu;monitoring;hpc;nvidia;amd
1113,HPCPerfStats,Automated resource-usage monitoring and analysis for HPC Clusters,"An automated resource-usage monitoring and analysis package specifically designed for HPC Clusters, developed by TACC (Texas Advanced Computing Center).",AI6;AI6-05,monitoring;performance_analysis,platform,C,https://github.com/TACC/HPCPerfStats,,LGPL-2.1,hpc;monitoring;performance;tacc
1114,GFPGAN,Practical algorithms for real-world face restoration,"A deep learning tool for blind face restoration, utilizing Generative Facial Prior (GFP) for scientific image processing and computer vision research.",AI4,image_restoration;inference,solver,Python,https://github.com/TencentARC/GFPGAN,,NOASSERTION,gan;face-restoration;computer-vision;deep-learning
1115,uetai,Custom ML tracking experiment and debugging tools,"A toolset for tracking machine learning experiments and debugging, facilitating the scientific process of model development and evaluation.",AI6;AI6-05,experiment_tracking;debugging,library,Python,https://github.com/UETAILab/uetai,,MIT,ml-tracking;experiment-management;debugging
1116,TEGNAS,Neural Architecture Search with Training-Free Metrics,"Implementation of 'Understanding and Accelerating Neural Architecture Search with Training-Free and Theory-Grounded Metrics', a tool for scientific modeling and AI research.",AI4,neural_architecture_search;modeling,solver,Python,https://github.com/VITA-Group/TEGNAS,,MIT,nas;deep-learning;neural-architecture-search
1117,VevestaX,Lightweight ML experiment tracking and EDA tool,"A library to track machine learning experiments, perform exploratory data analysis (EDA), and manage versioning, supporting scientific data analysis workflows.",AI6;AI6-05,experiment_tracking;eda,library,Jupyter Notebook,https://github.com/Vevesta/VevestaX,,Apache-2.0,ml-tracking;eda;data-science
1118,nvitop,Interactive NVIDIA-GPU process viewer and management tool,"An interactive process viewer for NVIDIA GPUs, providing a one-stop solution for GPU process management and monitoring, critical for AI and HPC workloads.",AI6;AI6-05,monitoring;process_management,solver,Python,https://github.com/XuehaiPan/nvitop,https://nvitop.readthedocs.io,Apache-2.0,gpu;nvidia;monitoring;hpc
1119,Prometheus (Drone),Open source software platform for autonomous drone research,"Prometheus is an open-source software project for autonomous drones, providing a complete set of solutions for mapping, localization, planning, and control, facilitating robotics research.",AI6,robotics_control;simulation,platform,C++,https://github.com/amov-lab/Prometheus,https://github.com/amov-lab/Prometheus/wiki,Apache-2.0,robotics;drones;autonomous-control
1120,MOCHA,Dataset and metrics for evaluating reading comprehension models,"MOCHA is a dataset and evaluation suite for training and evaluating reading comprehension metrics, supporting scientific analysis of NLP models.",AI6,model_evaluation;dataset,dataset,Python,https://github.com/anthonywchen/MOCHA,,None,nlp;evaluation-metric;dataset
1121,Apache Ambari,Platform for provisioning and managing Hadoop clusters,"Apache Ambari is a tool for provisioning, managing, and monitoring Apache Hadoop clusters, which are essential infrastructure for big data scientific computing.",AI6;AI6-05,cluster_management;monitoring,platform,Java,https://github.com/apache/ambari,https://ambari.apache.org/,Apache-2.0,hadoop;cluster-management;big-data
1122,k8s-gpu-hpa,Horizontal Pod Autoscaling for Kubernetes using Nvidia GPU Metrics,"A tool to enable Horizontal Pod Autoscaling (HPA) in Kubernetes based on custom Nvidia GPU metrics, essential for optimizing AI/HPC workloads.",AI6;AI6-05,resource_optimization;autoscaling,solver,Go,https://github.com/ashrafgt/k8s-gpu-hpa,,MIT,kubernetes;gpu;autoscaling
1123,SageMaker Experiments,Experiment tracking library for Amazon SageMaker,"A library for tracking, organizing, and comparing machine learning experiments on Amazon SageMaker, facilitating scientific reproducibility.",AI6;AI6-05,experiment_tracking;model_management,library,Python,https://github.com/aws/sagemaker-experiments,https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html,Apache-2.0,sagemaker;experiment-tracking;ml
1124,selFIe,Lightweight profiling engine for Linux commands and HPC codes,"A very light profiling tool designed for Linux commands and HPC codes, developed by CEA-HPC. It provides self-profiling capabilities to analyze runtime performance.",AI6;AI6-05,profiling;performance_analysis,solver,C,https://github.com/cea-hpc/selFIe,,NOASSERTION,hpc;profiling;linux;performance
1125,ceph-scripts,Helper scripts for monitoring and managing Ceph clusters,"A collection of helper scripts developed by CERN for monitoring and managing Ceph storage clusters, facilitating infrastructure operations in scientific computing environments.",AI6;AI6-05,storage_management;monitoring,library,Python,https://github.com/cernceph/ceph-scripts,,GPL-2.0,ceph;storage;cern;monitoring
1126,chaiNNer,Node-based image processing GUI for AI upscaling and manipulation,A node-based image processing GUI aimed at making chaining image processing tasks easy and customizable. It supports AI upscaling and programmatic image processing workflows.,AI-Workflow;Image-Processing,image_processing;upscaling;workflow_automation,platform,Python,https://github.com/chaiNNer-org/chaiNNer,,GPL-3.0,image-processing;gui;ai-upscaling;workflow
1127,nsys2json,Converter for NVIDIA Nsight Systems output to JSON format,"A Python script to convert the output of NVIDIA Nsight Systems (SQLite format) to JSON in Google Chrome Trace Event Format, facilitating performance analysis of GPU workloads.",AI6;AI6-05,profiling;visualization;format_conversion,solver,Python,https://github.com/chenyu-jiang/nsys2json,,NOASSERTION,nvidia;nsight;profiling;gpu
1128,gputasker,Lightweight GPU task scheduler for cluster management,A lightweight and effective GPU cluster task scheduling tool designed to manage and orchestrate GPU tasks.,AI6;AI6-05,job_scheduling;resource_management,platform,Python,https://github.com/cnstark/gputasker,,MIT,gpu;scheduler;cluster-management
1129,mactop,Real-time monitoring tool for Apple Silicon chips,"A terminal-based monitoring tool specifically for Apple Silicon (M1/M2/M3) chips, displaying real-time metrics for CPU, GPU, and Neural Engine usage, useful for local AI development monitoring.",AI6-05,hardware_monitoring;resource_profiling,solver,Go,https://github.com/context-labs/mactop,,MIT,apple-silicon;monitoring;gpu;cli
1130,netdata_nv_plugin,NetData plugin for NVIDIA GPU statistics,"A plugin for NetData to poll and display statistics from NVIDIA GPUs, enabling infrastructure monitoring for AI/HPC nodes.",AI6-05,hardware_monitoring;gpu_metrics,library,Python,https://github.com/coraxx/netdata_nv_plugin,,None,netdata;nvidia;gpu;monitoring
1131,torch-log-wmse,Audio quality metric and loss function for source separation,"Implementation of logWMSE, an audio quality metric and loss function with support for digital silence targets, useful for training and evaluating audio source separation systems.",AI-Model;Audio,model_training;evaluation_metric,library,Python,https://github.com/crlandsc/torch-log-wmse,,Apache-2.0,audio;loss-function;pytorch;source-separation
1132,dantegpu-core,Core microservices for DanteGPU distributed GPU network,"Core microservices powering the DanteGPU distributed GPU network. It manages providers, orchestrates AI job scheduling, and handles authentication and monitoring for distributed AI computing.",AI6;AI6-05,job_scheduling;distributed_computing,platform,Go,https://github.com/dante-gpu/dantegpu-core,,MIT,gpu;distributed-systems;scheduler;ai-infra
1133,socpowerbud,Real-time power and frequency monitor for Apple Silicon,"A sudoless alternative to powermetrics for Apple Silicon, providing real-time monitoring of CPU & GPU frequency, voltage, and usage, useful for local scientific computing profiling.",AI6-05,hardware_monitoring;power_profiling,solver,Objective-C,https://github.com/dehydratedpotato/socpowerbud,,MIT,apple-silicon;power-monitoring;profiling
1134,kronos,HPC workload analysis and modeling tool,"Tools for analysing profiling information, modeling, and generating portable HPC workloads, developed by ECMWF (European Centre for Medium-Range Weather Forecasts).",AI6;HPC,workload_modeling;profiling;simulation,solver,Python,https://github.com/ecmwf/kronos,,Apache-2.0,hpc;workload-generation;ecmwf;profiling
1135,mltraq,Experiment tracking tool for ML and AI,"A tool to track and collaborate on Machine Learning and AI experiments, supporting metadata logging and experiment management.",AI6-05;MLOps,experiment_tracking;metadata_management,platform,Jupyter Notebook,https://github.com/elehcimd/mltraq,,BSD-3-Clause,mlops;experiment-tracking;reproducibility
1136,evidently,Open-source ML and LLM observability framework,"An open-source framework to evaluate, test, and monitor ML models and LLMs in production, covering data drift, model performance, and data quality metrics.",AI6-05;MLOps,model_monitoring;data_drift_detection;evaluation,platform,Jupyter Notebook,https://github.com/evidentlyai/evidently,https://docs.evidentlyai.com/,Apache-2.0,mlops;observability;data-drift;llm-monitoring
1137,Dynolog,Telemetry daemon for performance monitoring and tracing of AI/HPC workloads,"Dynolog is a telemetry daemon designed for performance monitoring and tracing in distributed training applications. It integrates with PyTorch to export metrics from system components (CPU, GPU, Linux kernel) and correlates them with training events, enabling performance analysis of AI models.",AI6;AI6-05,performance_monitoring;distributed_training_tracing,service,C++,https://github.com/facebookincubator/dynolog,,MIT,telemetry;pytorch;hpc;gpu-monitoring
1138,OmniSealBench,Benchmark and toolkit for evaluating neural watermarking techniques,"A comprehensive benchmark suite for evaluating the performance and robustness of neural watermarking techniques. It includes datasets, evaluation metrics, and tools for training and testing neural networks specifically for watermarking research.",AI4;AI4-11,model_evaluation;watermarking_benchmarking,library,Python,https://github.com/facebookresearch/omnisealbench,,NOASSERTION,neural-watermarking;benchmark;model-security
1139,gpuview,Lightweight web dashboard for monitoring GPU usage in AI labs,"A lightweight web-based dashboard for monitoring GPU status (usage, temperature, memory) across multiple machines. It is designed to help researchers and AI engineers track resource utilization in GPU clusters or local labs.",AI6;AI6-05,resource_monitoring;gpu_management,service,Python,https://github.com/fgaim/gpuview,,MIT,gpu;monitoring;dashboard;nvidia
1140,Ganglia Web,Web frontend for the Ganglia distributed monitoring system,"The web interface for Ganglia, a scalable distributed monitoring system for high-performance computing systems such as clusters and grids. It visualizes metrics collected by the Ganglia monitor core.",AI6;AI6-05,hpc_monitoring;cluster_visualization,service,PHP,https://github.com/ganglia/ganglia-web,http://ganglia.sourceforge.net/,BSD-3-Clause,hpc;monitoring;cluster;visualization
1141,Ganglia Contrib,Collection of user-contributed tools for Ganglia monitoring system,"A repository containing various add-ons, scripts, and extensions for the Ganglia monitoring system, enhancing its capability to monitor specific scientific and HPC workloads.",AI6;AI6-05,hpc_monitoring;metrics_collection,library,HTML,https://github.com/ganglia/ganglia_contrib,,None,hpc;monitoring;extensions
1142,JMXetric,Java JVM instrumentation for Ganglia monitoring,"A tool that provides a bridge between JMX (Java Management Extensions) and Ganglia, allowing monitoring of Java-based scientific applications and HPC middleware.",AI6;AI6-05,application_monitoring;jvm_metrics,library,Java,https://github.com/ganglia/jmxetric,,MIT,java;jmx;ganglia;monitoring
1143,Ganglia Monitor Core,Scalable distributed monitoring system for HPC clusters,"The core component of Ganglia, a scalable distributed monitoring system for high-performance computing systems such as clusters and grids. It handles metric collection and distribution.",AI6;AI6-05,hpc_monitoring;resource_tracking,service,C,https://github.com/ganglia/monitor-core,http://ganglia.info/,BSD-3-Clause,hpc;cluster;monitoring;distributed-systems
1144,Ganglia API,RESTful API layer for Ganglia distributed monitoring system,"A Python-based API that exposes Ganglia monitoring data in a RESTful JSON format, enabling programmatic access to HPC cluster metrics for scientific infrastructure observability.",AI6;AI6-05,monitoring;observability,service,Python,https://github.com/guardian/ganglia-api,,Apache-2.0,ganglia;hpc;monitoring;api
1145,Slurm Job Exporter,Prometheus exporter for Slurm job statistics and GPU usage,"A Prometheus exporter that collects statistics from Slurm cgroup accounting, including NVIDIA GPU usage per job, specifically designed for monitoring scientific HPC workloads.",AI6;AI6-05,monitoring;resource_tracking,service,Python,https://github.com/guilbaults/slurm-job-exporter,,Apache-2.0,slurm;prometheus;gpu-monitoring;hpc
1146,Guild AI,Experiment tracking and ML developer tool,"An open-source experiment tracking tool for machine learning that manages runs, hyperparameters, and results, facilitating reproducible scientific research and model development.",AI6;AI6-05,experiment_tracking;reproducibility,platform,Python,https://github.com/guildai/guildai,https://guild.ai,Apache-2.0,experiment-tracking;mlops;reproducibility
1147,gvtop,Interactive TUI for monitoring NVIDIA GPUs,"A terminal-based user interface (TUI) for monitoring NVIDIA GPU status, utilization, and processes, providing real-time observability for scientific computing resources.",AI6;AI6-05,monitoring;gpu_management,solver,Python,https://github.com/gvlassis/gvtop,,MIT,gpu;monitoring;nvidia;tui
1148,OptScale,FinOps and cloud cost optimization platform for ML/AI workloads,"A comprehensive FinOps and cloud cost optimization platform that supports Kubernetes and AI/ML workloads, helping scientific organizations manage and optimize computing costs across various cloud providers.",AI6;AI6-05,cost_optimization;resource_management,platform,Python,https://github.com/hystax/optscale,https://my.optscale.com,Apache-2.0,finops;cost-optimization;kubernetes;ml-cost
1149,LLaMA-Omni,Low-latency end-to-end speech interaction model,"A speech interaction model built upon Llama-3.1-8B-Instruct, designed for low-latency and high-quality end-to-end speech processing, serving as a solver for scientific speech tasks.",AI6;AI6-05,inference;speech_processing,solver,Python,https://github.com/ictnlp/LLaMA-Omni,,Apache-2.0,llm;speech-interaction;model;inference
1150,LACT,Linux GPU configuration and monitoring tool,"A robust tool for configuring and monitoring AMD and NVIDIA GPUs on Linux, providing essential hardware control and observability for scientific computing workstations and nodes.",AI6;AI6-05,monitoring;hardware_control,solver,Rust,https://github.com/ilya-zlobintsev/LACT,,MIT,gpu;linux;monitoring;overclocking
1151,all-smi,Unified command-line utility for monitoring GPU hardware,"A command-line tool that aggregates monitoring data from both NVIDIA (nvidia-smi) and AMD (rocm-smi) GPUs, facilitating unified observability in heterogeneous scientific computing environments.",AI6;AI6-05,monitoring;observability,solver,Rust,https://github.com/inureyes/all-smi,,Apache-2.0,gpu;monitoring;nvidia;amd
1152,gpu-sentry,Flask-based package for monitoring NVIDIA GPU utilization,"A lightweight monitoring package that exposes NVIDIA GPU utilization metrics via a web interface, useful for tracking resource usage in scientific deep learning servers.",AI6;AI6-05,monitoring;observability,service,Python,https://github.com/jacenkow/gpu-sentry,,MIT,gpu;monitoring;flask;nvidia
1153,Jina Serve,Cloud-native framework for building multimodal AI applications,"A framework for building and serving multimodal AI applications, providing the runtime infrastructure for deploying scientific AI models (e.g., neural search, generative AI) as services.",AI6;AI6-05,serving;inference_infrastructure,platform,Python,https://github.com/jina-ai/serve,https://jina.ai,Apache-2.0,ai-serving;multimodal;cloud-native;inference
1154,gpud,Automated monitoring and diagnostics tool for GPU infrastructure in AI/HPC,"GPUd is a lightweight daemon and library designed to automate the monitoring, diagnostics, and issue identification of NVIDIA GPUs in AI and HPC clusters. It provides real-time visibility into GPU health, ECC errors, NVLink topology, and thermal states, enabling researchers and cluster administrators to maintain the reliability of scientific computing infrastructure.",AI6;AI6-05,infrastructure_monitoring;hardware_diagnostics,platform,Go,https://github.com/leptonai/gpud,,Apache-2.0,gpu-monitoring;hpc;ai-infrastructure;nvidia;diagnostics
1155,torcheval,Performant model evaluation metrics library for PyTorch,"Torcheval is a library that provides a rich collection of performant metrics for evaluating PyTorch models. It supports distributed training scenarios and offers a simple interface to create custom metrics, facilitating the scientific analysis of model performance in AI research.",AI6;AI6-05,model_evaluation;metrics_computation,library,Python,https://github.com/meta-pytorch/torcheval,https://pytorch.org/torcheval,NOASSERTION,pytorch;metrics;model-evaluation;distributed-training
1156,gmonitor,NVIDIA GPU monitoring tool for terminal,"A command-line tool for monitoring NVIDIA GPU metrics such as usage, memory, and temperature, essential for tracking resource utilization in AI/HPC compute clusters.",AI6;AI6-05,resource_monitoring;gpu_observability,solver,C++,https://github.com/mountassir/gmonitor,,GPL-3.0,gpu-monitoring;nvidia;hpc;observability
1157,SparseCT,Framework for sparse-view CT reconstruction research,"A framework designed for developing, training, and benchmarking sparse-view Computed Tomography (CT) reconstruction algorithms, providing datasets, metrics, and baselines for medical imaging research.",Medical Imaging;Physics,image_reconstruction;scientific_modeling,library,Python,https://github.com/mozanunal/SparseCT,,MIT,ct-reconstruction;medical-imaging;sparse-view;deep-learning
1158,gpu_monitor,Multi-node GPU monitoring utility,"A Python-based tool to monitor GPU status across single machines or clusters, facilitating resource tracking for distributed AI training and scientific computing workloads.",AI6;AI6-05,resource_monitoring;cluster_observability,solver,Python,https://github.com/msalvaris/gpu_monitor,,MIT,gpu;monitoring;cluster;distributed-computing
1159,nviwatch,TUI for NVIDIA GPU process management and monitoring,"A terminal user interface (TUI) built in Rust for real-time monitoring and management of NVIDIA GPU processes, aiding in the optimization and debugging of AI/HPC jobs.",AI6;AI6-05,resource_monitoring;process_management,solver,Rust,https://github.com/msminhas93/nviwatch,,GPL-3.0,gpu;nvidia;tui;monitoring;rust
1160,datadog_nvml,NVIDIA GPU monitoring integration for Datadog,"A utility that collects NVIDIA GPU metrics via NVML and sends them to Datadog, enabling centralized monitoring of GPU resources in scientific computing environments.",AI6;AI6-05,resource_monitoring;observability,solver,Python,https://github.com/ngi644/datadog_nvml,,GPL-2.0,gpu;datadog;nvml;monitoring
1161,OpenLIT,OpenTelemetry-native observability and evaluation platform for LLMs and GenAI,"OpenLIT is an observability and evaluation platform designed for AI engineering. It provides automatic instrumentation for LLMs, vector databases, and GPU accelerators, enabling developers to trace model execution, monitor costs, and perform evaluations (e.g., hallucination detection) on AI model outputs.",AI6;AI6-05,model_evaluation;observability;performance_profiling,platform,Python,https://github.com/openlit/openlit,https://docs.openlit.io/,Apache-2.0,llm-ops;observability;evaluation;gpu-monitoring;opentelemetry
1162,EconML,A Python package for estimating heterogeneous treatment effects and causal inference,"ALICE (Automated Learning and Intelligence for Causation and Economics) is a Microsoft Research project. EconML is a toolkit that combines state-of-the-art machine learning techniques with econometrics to solve complex causal inference problems. It implements orthogonal machine learning algorithms such as double machine learning, enabling the measurement of causal effects of treatment variables on outcomes while controlling for high-dimensional features.",AI3-02;Social Science,causal_inference;estimation;statistical_analysis,library,Jupyter Notebook,https://github.com/py-why/EconML,https://econml.azurewebsites.net/,NOASSERTION,causal-inference;econometrics;machine-learning;treatment-effect
1163,ApeBench,Benchmark suite for autoregressive neural emulation of PDEs,"A benchmark suite designed for evaluating autoregressive neural networks in the context of emulating Partial Differential Equations (PDEs), supporting 1D, 2D, and 3D physics simulations.",AI4S;Physics,benchmarking;scientific_modeling;pde_solver,dataset,Python,https://github.com/tum-pbs/apebench,,MIT,pde;physics-ml;benchmark;neural-emulation
1164,stubl,SLURM Tools and UBiLities for HPC job management,"A collection of shell scripts and utilities to facilitate the management and monitoring of jobs on Slurm-based HPC clusters, simplifying common tasks for researchers.",AI6;HPC,job_scheduling;cluster_management,solver,Shell,https://github.com/ubccr/stubl,,GPL-3.0,slurm;hpc;job-management;cluster-tools
1165,HiddenLayer,Neural network graph visualization and training metrics library,"A lightweight library for visualizing neural network architectures (graphs) and tracking training metrics for PyTorch, TensorFlow, and Keras, aiding in model debugging and analysis.",AI6-05;AI3,model_visualization;training_monitoring,library,Python,https://github.com/waleedka/hiddenlayer,,MIT,visualization;deep-learning;pytorch;tensorflow
1166,GPUSitter,Lightweight GPU job scheduler for idle resource utilization,"A tool to monitor GPU usage and automatically launch jobs when resources are idle, designed for maximizing utilization in shared research server environments.",AI6;HPC,job_scheduling;resource_management,solver,Python,https://github.com/wilmerwang/GPUSitter,,MIT,gpu;scheduling;automation;hpc
1167,gpustat,Command-line utility for monitoring GPU status,"A standard command-line tool for querying and monitoring NVIDIA GPU status (usage, memory, temperature, processes) on Linux, widely used in AI/HPC research environments.",AI6-05;HPC,resource_monitoring;observability,solver,Python,https://github.com/wookayin/gpustat,,MIT,gpu;monitoring;nvidia;cli
1168,gpustat-web,Web interface for gpustat monitoring,"A web-based interface for the gpustat utility, allowing remote monitoring of GPU cluster status through a browser.",AI6-05;HPC,resource_monitoring;observability,platform,Python,https://github.com/wookayin/gpustat-web,,MIT,gpu;monitoring;web-ui;cluster
