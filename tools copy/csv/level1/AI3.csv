id,name,one_line_profile,detailed_description,domains,subtask_category,application_level,primary_language,repo_url,help_website,license,tags
1,AdaptiveCpp,"Independent open-source compiler for C++-based heterogeneous programming models (SYCL, CUDA, HIP)","AdaptiveCpp (formerly hipSYCL) is a community-driven compiler infrastructure that enables C++ applications to run on hardware from all major vendors (NVIDIA, AMD, Intel) using standard parallelism models like SYCL and C++17/20 parallel algorithms. It serves as a foundational tool for high-performance scientific computing and AI acceleration.",AI3;AI3-01,acceleration;compilation;heterogeneous_computing,platform,C++,https://github.com/AdaptiveCpp/AdaptiveCpp,,BSD-2-Clause,sycl;compiler;gpu-acceleration;hpc
2,AgentFly,Scalable and extensible reinforcement learning framework for Large Language Model agents,AgentFly is a research framework designed for training and evaluating LLM agents using reinforcement learning. It supports scalable training pipelines and provides extensibility for developing new agent-based RL algorithms.,AI3;AI3-01,reinforcement_learning;agent_training;model_training,library,Python,https://github.com/Agent-One-Lab/AgentFly,,Apache-2.0,reinforcement-learning;llm-agents;training-framework
3,AgileRL,Reinforcement learning framework with evolutionary hyperparameter optimization,"AgileRL is a deep reinforcement learning library focused on RLOps and efficiency. It implements evolutionary algorithms for hyperparameter optimization during training, allowing for faster convergence and better model performance in scientific and control tasks.",AI3;AI3-01,reinforcement_learning;hyperparameter_optimization;training_framework,library,Python,https://github.com/AgileRL/AgileRL,https://docs.agilerl.com,Apache-2.0,reinforcement-learning;evolutionary-algorithms;rlops
4,fsdp_qlora,Utility for training LLMs using QLoRA and FSDP,A specialized training utility that combines Fully Sharded Data Parallel (FSDP) with Quantized LoRA (QLoRA) to enable efficient fine-tuning of large language models on limited GPU resources. It serves as a practical solver for memory-constrained model training.,AI3;AI3-01,model_training;fine_tuning;memory_optimization,solver,Jupyter Notebook,https://github.com/AnswerDotAI/fsdp_qlora,,Apache-2.0,fsdp;qlora;llm-training;quantization
5,distribuuuu,Lightweight PyTorch distributed training framework,A pure and concise distributed training framework for PyTorch designed to simplify the setup and execution of multi-GPU training tasks. It provides abstractions for distributed data parallel (DDP) and other training strategies.,AI3;AI3-01,distributed_training;training_framework,library,Python,https://github.com/BIGBALLON/distribuuuu,,MIT,pytorch;distributed-training;ddp
6,PySNN,Efficient Spiking Neural Network framework based on PyTorch,"PySNN is a framework for simulating and training Spiking Neural Networks (SNNs) with GPU acceleration. It extends PyTorch to support neuromorphic computing models, enabling research into biologically plausible neural networks.",AI3;AI3-01,neuromorphic_computing;snn_simulation;model_training,library,Python,https://github.com/BasBuller/PySNN,,MIT,snn;spiking-neural-networks;neuromorphic
7,Bluefog,Distributed and decentralized training framework for PyTorch over graphs,Bluefog is a high-performance distributed training framework for PyTorch that implements decentralized optimization algorithms over virtual topologies (graphs). It is designed for large-scale deep learning training on heterogeneous or bandwidth-constrained networks.,AI3;AI3-01,distributed_training;decentralized_optimization;training_framework,library,Python,https://github.com/Bluefog-Lib/bluefog,,Apache-2.0,distributed-training;decentralized-optimization;pytorch
8,VeOmni,Model-centric distributed training framework for multi-modality models,VeOmni is a distributed training framework designed to scale model training across various modalities. It provides a collection of distributed recipes and optimizations to facilitate the training of large-scale foundation models.,AI3;AI3-01,distributed_training;large_scale_training;multimodal_learning,framework,Python,https://github.com/ByteDance-Seed/VeOmni,,Apache-2.0,distributed-training;foundation-models;multimodal
9,Verbalized Sampling,Training-free prompting framework to mitigate mode collapse in LLMs,"Verbalized Sampling is a framework and CLI tool that implements a training-free prompting strategy to improve the diversity of Large Language Model (LLM) outputs. It is used for synthetic data generation, dialogue simulation, and mitigating mode collapse in scientific and creative text generation tasks.",AI3;AI3-01,inference_control;synthetic_data_generation;prompt_engineering,library,Python,https://github.com/CHATS-lab/verbalized-sampling,,NOASSERTION,llm;sampling-strategy;inference
10,CV-CUDA,GPU-accelerated library for cloud-scale image processing and computer vision,"An open-source, GPU-accelerated library designed for building efficient, cloud-scale image processing and computer vision pipelines. It provides specialized kernels for pre-processing and post-processing tasks in AI workflows.",AI3;AI3-01,image_processing;computer_vision;acceleration,library,C++,https://github.com/CVCUDA/CV-CUDA,https://github.com/CVCUDA/CV-CUDA,NOASSERTION,gpu-acceleration;computer-vision;image-processing;cuda
11,trlx,Distributed training framework for RLHF on language models,A library for distributed training of large language models using Reinforcement Learning via Human Feedback (RLHF). It supports various RL algorithms and integrates with distributed training backends.,AI3;AI3-01,model_training;rlhf;distributed_training,library,Python,https://github.com/CarperAI/trlx,https://github.com/CarperAI/trlx,MIT,rlhf;distributed-training;llm;reinforcement-learning
12,Mist,Efficient distributed training system for LLMs via memory-parallelism co-optimization,A system for efficient distributed training of Large Language Models (LLMs) that optimizes memory usage and parallelism strategies. It implements techniques described in the EuroSys'25 paper.,AI3;AI3-01,distributed_training;memory_optimization;llm_training,solver,Python,https://github.com/CentML/Mist,https://github.com/CentML/Mist,Apache-2.0,distributed-training;llm;memory-optimization
13,wolpertinger_ddpg,Implementation of Wolpertinger Training with DDPG for discrete action spaces,"A PyTorch implementation of the Wolpertinger policy for Deep Reinforcement Learning in large discrete action spaces, compatible with Multi-GPU/CPU setups.",AI3;AI3-01,reinforcement_learning;model_training,solver,Python,https://github.com/ChangyWen/wolpertinger_ddpg,https://github.com/ChangyWen/wolpertinger_ddpg,None,reinforcement-learning;ddpg;pytorch
14,llm-rk3588,GPU-accelerated LLM inference on RK3588 edge devices,"A tool to run Large Language Models on Rockchip RK3588 platforms with GPU acceleration, enabling edge AI inference.",AI3;AI3-01,inference_acceleration;edge_computing,solver,C++,https://github.com/Chrisz236/llm-rk3588,https://github.com/Chrisz236/llm-rk3588,Apache-2.0,edge-ai;rk3588;llm-inference;gpu-acceleration
15,OpenGPT,Framework for creating grounded instruction datasets and training domain expert LLMs,"A framework designed to create grounded instruction-based datasets and train conversational domain expert Large Language Models, facilitating the development of specialized AI agents.",AI3;AI3-01,dataset_creation;model_training;domain_adaptation,framework,Jupyter Notebook,https://github.com/CogStack/OpenGPT,https://github.com/CogStack/OpenGPT,Apache-2.0,llm;dataset-generation;domain-expert
16,gdGPT,LLM training tool using DeepSpeed pipeline mode,"A tool for training large language models (BLOOM, LLaMA, Baichuan, ChatGLM) using DeepSpeed's pipeline parallelism mode, optimized for speed compared to Zero/FSDP.",AI3;AI3-01,model_training;distributed_training;pipeline_parallelism,solver,Python,https://github.com/CoinCheung/gdGPT,https://github.com/CoinCheung/gdGPT,Apache-2.0,llm-training;deepspeed;pipeline-parallelism
17,net2net,Network-to-Network Translation with Conditional Invertible Neural Networks,"A library implementing Network-to-Network translation using Conditional Invertible Neural Networks (cINNs), useful for generative modeling and domain translation tasks.",AI3;AI3-01,generative_modeling;network_translation,library,Python,https://github.com/CompVis/net2net,https://github.com/CompVis/net2net,None,generative-models;invertible-neural-networks;deep-learning
18,MPP-LLaVA,Multimodal Pipeline Parallel training framework for LLaVA-like models,"A project enabling Multimodal Pipeline Parallel (MPP) training for Qwen-based MLLMs, allowing the training of large multimodal models on consumer-grade GPUs (e.g., RTX 3090/4090).",AI3;AI3-01,distributed_training;multimodal_learning;pipeline_parallelism,framework,Jupyter Notebook,https://github.com/Coobiw/MPP-LLaVA,https://github.com/Coobiw/MPP-LLaVA,None,multimodal;pipeline-parallelism;llava;qwen
19,flash-attention,Fast and memory-efficient exact attention mechanism,"A library providing fast and memory-efficient implementations of exact attention (FlashAttention), a critical primitive for accelerating Transformer-based model training and inference.",AI3;AI3-01,acceleration;model_optimization,library,Python,https://github.com/Dao-AILab/flash-attention,https://github.com/Dao-AILab/flash-attention,BSD-3-Clause,attention-mechanism;gpu-acceleration;cuda;transformer
20,mixed_precision_for_JAX,Mixed Precision Training utilities for JAX based on Equinox,"A repository providing tools and utilities for implementing Mixed Precision Training in JAX, specifically built upon the Equinox library.",AI3;AI3-01,model_training;mixed_precision;optimization,library,Python,https://github.com/Data-Science-in-Mechanical-Engineering/mixed_precision_for_JAX,https://github.com/Data-Science-in-Mechanical-Engineering/mixed_precision_for_JAX,MIT,jax;mixed-precision;equinox;training
21,gpuRIR,GPU-accelerated Room Impulse Response (RIR) simulation library,"A Python library for simulating Room Impulse Responses (RIR) with GPU acceleration, used for generating acoustic data for audio processing and machine learning tasks.",AI3;AI3-01,simulation;data_generation;acoustics,library,Cuda,https://github.com/DavidDiazGuerra/gpuRIR,https://github.com/DavidDiazGuerra/gpuRIR,AGPL-3.0,simulation;acoustics;gpu-acceleration;rir
22,horizonml,Hybrid Model Parallelism Framework for Distributed Training on Edge Devices,A framework enabling efficient distributed training of machine learning models across heterogeneous edge devices using hybrid model parallelism.,AI3;AI3-01,distributed_training;edge_computing;model_parallelism,framework,Python,https://github.com/Deeptanshu-sankhwar/horizonml,https://github.com/Deeptanshu-sankhwar/horizonml,MIT,edge-ai;distributed-training;model-parallelism
23,Insanely-Fast-Transcription,GPU-accelerated audio transcription utility using Whisper,"A utility for rapid audio transcription leveraging GPU acceleration (CUDA/MPS) and the Whisper model, optimized for high-performance speech-to-text conversion.",AI3;AI3-01,data_processing;speech_recognition;acceleration,solver,Python,https://github.com/Doriandarko/Insanely-Fast-Transcription,https://github.com/Doriandarko/Insanely-Fast-Transcription,None,whisper;transcription;gpu-acceleration;audio-processing
24,nemesyst,"Hybrid-parallelism, database-based deep learning framework",A generalised and highly customisable deep learning framework that employs hybrid parallelism and a database-based approach for training.,AI3;AI3-01,model_training;distributed_training;framework,framework,Python,https://github.com/DreamingRaven/nemesyst,https://github.com/DreamingRaven/nemesyst,MIT,deep-learning;hybrid-parallelism;framework
25,xshinnosuke,Pure Numpy deep learning framework with GPU acceleration support,"A deep learning framework implemented purely in Numpy, supporting both dynamic and static graphs, with optional GPU acceleration.",AI3;AI3-01,model_training;framework;educational,framework,Python,https://github.com/E1eveNn/xshinnosuke,https://github.com/E1eveNn/xshinnosuke,MIT,deep-learning-framework;numpy;gpu-acceleration
26,sheeprl,Distributed Reinforcement Learning framework accelerated by Lightning Fabric,"A distributed Reinforcement Learning framework that leverages Lightning Fabric for acceleration, enabling scalable RL training.",AI3;AI3-01,reinforcement_learning;distributed_training;acceleration,framework,Python,https://github.com/Eclectic-Sheep/sheeprl,https://github.com/Eclectic-Sheep/sheeprl,Apache-2.0,reinforcement-learning;distributed-training;pytorch-lightning
27,gpt-neox,Library for model-parallel training of autoregressive transformers on GPUs,"An implementation of model-parallel autoregressive transformers on GPUs, built on Megatron-LM and DeepSpeed, designed for training massive language models.",AI3;AI3-01,distributed_training;model_parallelism;llm_training,library,Python,https://github.com/EleutherAI/gpt-neox,https://github.com/EleutherAI/gpt-neox,Apache-2.0,llm;distributed-training;megatron-lm;deepspeed
28,pytorch_tempest,Template/Scaffold for training neural nets with PyTorch Lightning and Hydra,"A structured template and workflow tool for training neural networks, integrating PyTorch Lightning for training loops and Hydra for configuration management.",AI3;AI3-01,workflow_management;model_training,workflow,Python,https://github.com/Erlemar/pytorch_tempest,https://github.com/Erlemar/pytorch_tempest,MIT,pytorch-lightning;hydra;template;training-workflow
29,llm_parallelisms.c,Pure C implementation of LLM training parallelisms,"A minimal, educational implementation of various LLM training parallelism strategies (Data Parallelism, FSDP, Tensor Parallelism, Pipeline Parallelism) in pure C.",AI3;AI3-01,distributed_training;parallelism;educational,library,C,https://github.com/EugenHotaj/llm_parallelisms.c,https://github.com/EugenHotaj/llm_parallelisms.c,MIT,llm;parallelism;c;distributed-training
30,LLaVA-OneVision-1.5,Open framework for democratized multimodal model training,"A fully open framework designed to democratize the training of multimodal models, specifically focusing on the LLaVA-OneVision architecture.",AI3;AI3-01,model_training;multimodal_learning;framework,framework,Python,https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5,https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5,Apache-2.0,multimodal;llava;training-framework
31,celldetection,Scalable Instance Segmentation library for bioimage analysis,"A library for scalable instance segmentation using PyTorch and PyTorch Lightning, specifically tailored for cell detection and bioimage analysis tasks.",AI3;AI3-01,image_segmentation;bioimage_analysis;model_training,library,Python,https://github.com/FZJ-INM1-BDA/celldetection,https://github.com/FZJ-INM1-BDA/celldetection,Apache-2.0,cell-detection;instance-segmentation;bioimage;pytorch
32,Medusa,Framework for accelerating LLM generation with multiple decoding heads,"A simple framework that accelerates Large Language Model (LLM) generation by employing multiple decoding heads, improving inference speed.",AI3;AI3-01,inference_acceleration;model_optimization,framework,Jupyter Notebook,https://github.com/FasterDecoding/Medusa,https://github.com/FasterDecoding/Medusa,Apache-2.0,llm-acceleration;decoding;inference
33,FedML,Unified library for distributed training and federated learning,"A scalable machine learning library for large-scale distributed training, model serving, and federated learning, supporting cross-cloud scheduling.",AI3;AI3-01,distributed_training;federated_learning;model_serving,framework,Python,https://github.com/FedML-AI/FedML,https://doc.fedml.ai,Apache-2.0,federated-learning;distributed-training;edge-ai
34,FlexQ,Post-training INT6 quantization framework for LLM inference,"A post-training quantization framework specifically tailored for Large Language Model (LLM) inference, utilizing INT6 quantization to improve efficiency.",AI3;AI3-01,model_quantization;inference_optimization,framework,Jupyter Notebook,https://github.com/FlyFoxPlayer/FlexQ,https://github.com/FlyFoxPlayer/FlexQ,Apache-2.0,quantization;llm;inference
35,LightningFSL,PyTorch Lightning implementations of Few-Shot Learning models,A library providing PyTorch Lightning implementations of various Few-Shot Learning algorithms and models.,AI3;AI3-01,model_training;few_shot_learning,library,Python,https://github.com/Frankluox/LightningFSL,https://github.com/Frankluox/LightningFSL,MIT,few-shot-learning;pytorch-lightning;meta-learning
36,CosyVoice,Multi-lingual large voice generation model framework,"A full-stack framework for multi-lingual large voice generation models, providing capabilities for inference, training, and deployment.",AI3;AI3-01,model_training;inference;voice_generation,framework,Python,https://github.com/FunAudioLLM/CosyVoice,https://github.com/FunAudioLLM/CosyVoice,Apache-2.0,voice-generation;tts;model-training
37,edm2,Multi-GPU implementation of EDM2 diffusion model training,A minimal multi-GPU implementation of the EDM2 (Analyzing and Improving the Training Dynamics of Diffusion Models) framework.,AI3;AI3-01,model_training;diffusion_models;distributed_training,solver,Python,https://github.com/FutureXiang/edm2,https://github.com/FutureXiang/edm2,None,diffusion-models;multi-gpu;training
38,Rust-SSP,Structured Stream Parallelism library for Rust,"A Rust library implementing Structured Stream Parallelism, providing high-performance parallel computing capabilities suitable for scientific data processing streams.",AI3;AI3-01,parallel_computing;data_processing,library,Rust,https://github.com/GMAP/Rust-SSP,https://github.com/GMAP/Rust-SSP,MIT,rust;parallelism;stream-processing
39,RadeonRays_SDK,Ray intersection acceleration library for CPU and GPU,"An acceleration library for ray intersection calculations, supporting hardware and software multiplatforms using CPU and GPU, useful for physics simulation and rendering.",AI3;AI3-01,acceleration;simulation;ray_tracing,library,C++,https://github.com/GPUOpen-LibrariesAndSDKs/RadeonRays_SDK,https://github.com/GPUOpen-LibrariesAndSDKs/RadeonRays_SDK,MIT,ray-tracing;acceleration;gpu;simulation
40,MG-GCN,Scalable Multi-GPU Graph Convolutional Network Training Framework,"A framework for scalable training of Graph Convolutional Networks (GCNs) across multiple GPUs, enabling the processing of large-scale graph data.",AI3;AI3-01,distributed_training;graph_neural_networks,framework,C++,https://github.com/GT-TDAlab/MG-GCN,https://github.com/GT-TDAlab/MG-GCN,NOASSERTION,gcn;multi-gpu;distributed-training;graph-learning
41,nvidia-nemo-on-gke,Infrastructure code for training NVIDIA NeMo LLMs on GKE,A set of configurations and scripts (Terraform/HCL) for deploying and training NVIDIA NeMo Megatron Large Language Models on Google Kubernetes Engine (GKE).,AI3;AI3-01,distributed_training;infrastructure_deployment;llm_training,workflow,HCL,https://github.com/GoogleCloudPlatform/nvidia-nemo-on-gke,https://github.com/GoogleCloudPlatform/nvidia-nemo-on-gke,Apache-2.0,kubernetes;gke;nemo;llm-training
42,relora,Implementation of ReLoRA for high-rank training through low-rank updates,"The official implementation of ReLoRA, a method for efficient high-rank training of neural networks using low-rank updates, reducing memory and compute requirements.",AI3;AI3-01,model_training;optimization;parameter_efficient_tuning,solver,Jupyter Notebook,https://github.com/Guitaricet/relora,https://github.com/Guitaricet/relora,Apache-2.0,peft;training-optimization;low-rank-updates
43,hedgehog-lab,Browser-based scientific computing and data visualization environment,"An open-source scientific computing environment that runs entirely in the browser, offering matrix operations with GPU acceleration, TeX support, and data visualization.",AI3;AI3-01,scientific_computing;visualization;data_analysis,platform,TypeScript,https://github.com/Hedgehog-Computing/hedgehog-lab,https://hedgehog-lab.github.io/,Apache-2.0,scientific-computing;visualization;web-based;gpu-acceleration
44,llm-trainer,Framework for training Large Language Models from scratch,"A complete framework designed to facilitate the training of Large Language Models (LLMs) from scratch, providing necessary tools and abstractions.",AI3;AI3-01,model_training;llm,framework,Python,https://github.com/HelpingAI/llm-trainer,https://github.com/HelpingAI/llm-trainer,Apache-2.0,llm-training;framework;deep-learning
45,revlib,Memory-efficient reversible network library for PyTorch,"A lightweight library implementing reversible neural networks in PyTorch, enabling significant memory savings during training by reconstructing activations during the backward pass. Supports DeepSpeed and XLA.",AI3;AI3-01,memory_optimization;model_training,library,Python,https://github.com/HomebrewML/revlib,,BSD-2-Clause,pytorch;reversible-networks;memory-efficient;deepspeed
46,Hetu,High-performance distributed deep learning system,"A distributed deep learning system targeting large-scale and automated distributed training, developed by PKU-DAIR. It optimizes communication and computation for efficient model training.",AI3;AI3-01,distributed_training;system_optimization,platform,Python,https://github.com/Hsword/Hetu,https://github.com/PKU-DAIR/Hetu,Apache-2.0,distributed-systems;deep-learning;training-framework
47,transpeeder,Efficient LLaMA training tool using Pipeline Parallelism,"A tool designed to train LLaMA models on limited hardware (e.g., single A100) by leveraging Hugging Face Transformers and DeepSpeed Pipeline Parallelism.",AI3;AI3-01,llm_training;distributed_training,solver,Python,https://github.com/HuangLK/transpeeder,,Apache-2.0,llama;deepspeed;pipeline-parallelism;training-optimization
48,DeepMath,Framework for training math reasoning agents,"A framework from Intel Labs for training and evaluating mathematical reasoning agents using local models, GRPO, and vLLM. Facilitates research in AI for mathematics.",AI3;AI3-01,math_reasoning;agent_training,framework,Python,https://github.com/IntelLabs/DeepMath,,Apache-2.0,math-ai;reasoning;training-framework;intel-labs
49,lmdeploy,Toolkit for compressing and serving LLMs,"A comprehensive toolkit for compressing, deploying, and serving Large Language Models. It supports high-performance inference and quantization, essential for the LLM lifecycle.",AI3;AI3-01,model_compression;inference_serving,tool,Python,https://github.com/InternLM/lmdeploy,,Apache-2.0,llm;deployment;quantization;inference
50,fast-reid,SOTA Re-identification Toolbox,A software library for object re-identification research and development. It provides state-of-the-art methods and efficient training pipelines for computer vision tasks.,AI3;AI3-01,computer_vision;re_identification,workflow,Python,https://github.com/JDAI-CV/fast-reid,,Apache-2.0,reid;computer-vision;pytorch;toolbox
51,Surge,High-performance matrix math library for Swift,"A Swift library leveraging the Accelerate framework to provide high-performance functions for matrix mathematics, digital signal processing (DSP), and image manipulation, serving as a scientific computing foundation for the Swift ecosystem.",AI3;AI3-01,matrix_computation;signal_processing,library,Swift,https://github.com/Jounce/Surge,,MIT,swift;linear-algebra;dsp;accelerate
52,bert-squeeze,Toolbox for Transformer model compression,"A set of tools for compressing Transformer models using techniques like distillation, quantization, and pruning, built on PyTorch Lightning.",AI3;AI3-01,model_compression;distillation,tool,Python,https://github.com/JulesBelveze/bert-squeeze,,None,transformers;compression;pytorch-lightning;distillation
53,demucs_lightning,PyTorch Lightning implementation of Demucs,"A PyTorch Lightning wrapper for the Demucs music source separation model, facilitating training with features like Hydra configuration and Tensorboard logging.",AI3;AI3-01,audio_processing;source_separation,library,Python,https://github.com/KinWaiCheuk/demucs_lightning,,None,audio;demucs;pytorch-lightning;music-separation
54,FlashDeBERTa,Flash attention implementation for DeBERTa,"An optimized implementation of the DeBERTa disentangled attention mechanism using Flash Attention, designed to accelerate training and inference of DeBERTa models.",AI3;AI3-01,model_acceleration;attention_mechanism,library,Python,https://github.com/Knowledgator/FlashDeBERTa,,Apache-2.0,deberta;flash-attention;optimization;nlp
55,libROM,Library for Reduced Order Modeling,"A C++ library for data-driven model reduction with an emphasis on large-scale parallelism and linear subspace methods, developed by LLNL for physical simulations.",AI3;AI3-01,model_reduction;physics_simulation,library,C++,https://github.com/LLNL/libROM,,NOASSERTION,model-reduction;hpc;physics;linear-algebra
56,lightning-thunder,PyTorch compiler for training acceleration,"A source-to-source compiler for PyTorch that accelerates training and inference by optimizing performance, memory usage, and parallelism.",AI3;AI3-01,compilation;model_acceleration,platform,Python,https://github.com/Lightning-AI/lightning-thunder,,Apache-2.0,compiler;pytorch;optimization;acceleration
57,lit-llama,Hackable implementation of LLaMA,"A clean, hackable implementation of the LLaMA language model based on nanoGPT. Supports pre-training, fine-tuning (LoRA, Adapter), and quantization, serving as a research workbench for LLMs.",AI3;AI3-01,llm_training;fine_tuning,solver,Python,https://github.com/Lightning-AI/lit-llama,,Apache-2.0,llama;llm;finetuning;nanogpt
58,pytorch-lightning,High-level framework for PyTorch training,"A lightweight PyTorch wrapper that decouples science code from engineering, enabling easy scaling of model training across multiple GPUs and TPUs.",AI3;AI3-01,training_framework;distributed_training,framework,Python,https://github.com/Lightning-AI/pytorch-lightning,https://lightning.ai/docs/pytorch/stable/,Apache-2.0,pytorch;deep-learning;framework;distributed
59,lightning-ColossalAI,ColossalAI strategy for PyTorch Lightning,An integration library that brings ColossalAI's large-scale distributed model training strategies to the PyTorch Lightning ecosystem.,AI3;AI3-01,distributed_training;strategy_integration,library,Python,https://github.com/Lightning-Universe/lightning-ColossalAI,,Apache-2.0,colossalai;distributed-training;pytorch-lightning
60,lightning-bolts,Toolbox of models and callbacks for Lightning,"A collection of pre-built models, callbacks, and datasets for PyTorch Lightning, designed to accelerate research prototyping and experimentation.",AI3;AI3-01,model_library;prototyping,library,Python,https://github.com/Lightning-Universe/lightning-bolts,,Apache-2.0,models;callbacks;research-tools;pytorch-lightning
61,lightning-flash,Task-based AI framework,"A high-level framework built on PyTorch Lightning that provides ready-to-use tasks for various domains (text, image, audio), simplifying the configuration and running of complex AI recipes.",AI3;AI3-01,task_framework;automl,framework,Python,https://github.com/Lightning-Universe/lightning-flash,,Apache-2.0,automl;tasks;pytorch-lightning;high-level-api
62,lightning-transformers,Transformers integration for Lightning,"A library that provides flexible components to pair Hugging Face Transformers with PyTorch Lightning, facilitating efficient training and fine-tuning of Transformer models.",AI3;AI3-01,model_integration;nlp_training,library,Python,https://github.com/Lightning-Universe/lightning-transformers,,Apache-2.0,transformers;huggingface;pytorch-lightning;nlp
63,naifu,Generative model training tool,"A tool for training generative models (specifically diffusion models) using PyTorch Lightning, often used for fine-tuning image generation models.",AI3;AI3-01,generative_models;diffusion_training,solver,Python,https://github.com/Mikubill/naifu,,MIT,diffusion;generative-ai;training-tool;pytorch-lightning
64,EasyLLM,Usability-focused LLM training framework,A framework built upon Megatron-Deepspeed and HuggingFace Trainer that reorganizes code logic to improve usability and training efficiency for Large Language Models.,AI3;AI3-01,llm_training;framework_wrapper,framework,Python,https://github.com/ModelTC/EasyLLM,,Apache-2.0,llm;megatron;deepspeed;training-framework
65,MyCaffe/NCCL,Windows port of NVIDIA's NCCL library for multi-GPU communication,"A Windows adaptation of the NVIDIA Collective Communications Library (NCCL), enabling multi-GPU and multi-node collective communication primitives for deep learning frameworks on Windows systems.",AI3;AI3-01,distributed_training;communication_primitives,library,Cuda,https://github.com/MyCaffe/NCCL,,NOASSERTION,nccl;windows;distributed-training;gpu
66,LARS-ImageNet-PyTorch,PyTorch implementation of LARS optimizer for large batch training,"A library implementing the Layer-wise Adaptive Rate Scaling (LARS) optimizer, designed for large batch training of deep neural networks (e.g., ResNet on ImageNet) with support for Horovod distributed training.",AI3;AI3-01,model_optimization;training_optimizer,library,Python,https://github.com/NUS-HPC-AI-Lab/LARS-ImageNet-PyTorch,,MIT,lars;optimizer;large-batch;pytorch
67,NVIDIA NeMo Automodel,Distributed training library for LLMs and VLMs with Hugging Face support,"A PyTorch Distributed native training library designed for Large Language Models (LLMs) and Vision Language Models (VLMs), offering out-of-the-box integration with Hugging Face models and optimized for NVIDIA hardware.",AI3;AI3-01,distributed_training;llm_training,library,Python,https://github.com/NVIDIA-NeMo/Automodel,,Apache-2.0,llm;distributed-training;pytorch;nemo
68,NVIDIA DALI,GPU-accelerated data loading and augmentation library,"A library containing highly optimized building blocks and an execution engine for data processing to accelerate deep learning training and inference applications, focusing on removing CPU bottlenecks.",AI3;AI3-01,data_processing;data_loading;augmentation,library,C++,https://github.com/NVIDIA/DALI,https://docs.nvidia.com/deeplearning/dali,Apache-2.0,data-loading;gpu-acceleration;augmentation;pipeline
69,Megatron-LM,Framework for large-scale distributed training of Transformer models,"A highly optimized library for training massive Transformer language models at scale, implementing efficient model parallelism (tensor and pipeline) and data parallelism techniques.",AI3;AI3-01,distributed_training;model_parallelism,library,Python,https://github.com/NVIDIA/Megatron-LM,,NOASSERTION,transformer;distributed-training;llm;parallelism
70,Transformer Engine,Library for accelerating Transformer models with FP8/FP4 precision,"A library for accelerating Transformer models on NVIDIA GPUs, enabling 8-bit and 4-bit floating point (FP8 and FP4) precision for better performance and lower memory utilization in training and inference.",AI3;AI3-01,acceleration;mixed_precision,library,Python,https://github.com/NVIDIA/TransformerEngine,https://docs.nvidia.com/deeplearning/transformer-engine,Apache-2.0,fp8;transformer;acceleration;hopper
71,Video Processing Framework,Hardware-accelerated video processing library for Python,"A set of Python bindings to C++ libraries providing full hardware acceleration for video decoding, encoding, and GPU-accelerated color space/pixel format conversions, useful for scientific video data pipelines.",AI3;AI3-01,data_processing;video_decoding,library,C++,https://github.com/NVIDIA/VideoProcessingFramework,,Apache-2.0,video-processing;gpu-acceleration;decoding;encoding
72,NVIDIA Apex,PyTorch extension for mixed precision and distributed training,"A library providing tools for easy mixed precision (AMP) and distributed training in PyTorch, including optimized fused optimizers and layers.",AI3;AI3-01,acceleration;mixed_precision;distributed_training,library,Python,https://github.com/NVIDIA/apex,https://nvidia.github.io/apex/,BSD-3-Clause,mixed-precision;pytorch;distributed-training;amp
73,JaxPP,JAX library for flexible MPMD pipeline parallelism,"A library for JAX that enables flexible MPMD (Multiple Program Multiple Data) pipeline parallelism, specifically designed for large-scale LLM training workflows.",AI3;AI3-01,distributed_training;pipeline_parallelism,library,Python,https://github.com/NVIDIA/jaxpp,,Apache-2.0,jax;pipeline-parallelism;llm;distributed
74,nvidia-dlfw-inspect,Debugging tool for LLM training convergence issues,"A tool designed to facilitate debugging of convergence issues and testing of new algorithms for training LLMs using NVIDIA libraries like Transformer Engine, Megatron-LM, and NeMo.",AI3;AI3-01,debugging;model_convergence,solver,Python,https://github.com/NVIDIA/nvidia-dlfw-inspect,,Apache-2.0,debugging;llm;convergence;training-tools
75,NVIDIA Warp,Python framework for high-performance simulation and spatial computing,"A Python framework that compiles Python functions to efficient kernel code for accelerated simulation, geometry processing, and data generation tasks on CPU and GPU.",AI3;AI3-01,simulation;data_generation,library,Python,https://github.com/NVIDIA/warp,https://nvidia.github.io/warp/,Apache-2.0,simulation;spatial-computing;cuda;physics
76,Kaolin,PyTorch library for 3D deep learning research,"A PyTorch library aimed at accelerating 3D deep learning research, providing implementations of 3D modules, differentiable rendering, and data processing for 3D structures.",AI3;AI3-01,scientific_modeling;3d_deep_learning,library,Python,https://github.com/NVIDIAGameWorks/kaolin,https://kaolin.readthedocs.io,Apache-2.0,3d-vision;pytorch;differentiable-rendering;geometry
77,Fast-dLLM,Acceleration library for Diffusion LLMs via KV cache,A training-free acceleration framework for Diffusion LLMs that enables KV cache and parallel decoding to improve inference speed and efficiency.,AI3;AI3-01,acceleration;inference_optimization,library,Python,https://github.com/NVlabs/Fast-dLLM,,Apache-2.0,diffusion-models;llm;acceleration;kv-cache
78,tiny-cuda-nn,High-performance C++/CUDA neural network framework,"A lightning-fast C++/CUDA neural network framework, particularly optimized for multi-resolution hash encodings and NeRF applications.",AI3;AI3-01,model_training;acceleration,library,C++,https://github.com/NVlabs/tiny-cuda-nn,,NOASSERTION,cuda;neural-network;nerf;optimization
79,mlstm_kernels,Optimized kernels for mLSTM and Flash Linear Attention,A library providing Tiled Flash Linear Attention kernels for fast and efficient training and inference of mLSTM (matrix LSTM) models.,AI3;AI3-01,acceleration;kernel_optimization,library,Jupyter Notebook,https://github.com/NX-AI/mlstm_kernels,,NOASSERTION,lstm;attention;cuda-kernels;acceleration
80,NoteDance Note,Lightweight distributed training and machine learning library,"A machine learning library supporting distributed training, deep learning, and reinforcement learning, compatible with TensorFlow and PyTorch.",AI3;AI3-01,distributed_training;model_training,library,Python,https://github.com/NoteDance/Note,,Apache-2.0,distributed-training;reinforcement-learning;deep-learning
81,DisTrO,Framework for decentralized distributed training over the internet,"A framework enabling Distributed Training Over-The-Internet, allowing for decentralized model training across geographically distributed resources with optimized communication.",AI3;AI3-01,distributed_training;decentralized_learning,library,,https://github.com/NousResearch/DisTrO,,None,distributed-training;decentralized;internet-scale
82,LiBai,Toolbox for large-scale distributed parallel training based on OneFlow,"A toolbox designed for large-scale distributed parallel training of deep learning models, built on top of the OneFlow framework.",AI3;AI3-01,distributed_training;model_parallelism,library,Python,https://github.com/Oneflow-Inc/libai,https://libai.readthedocs.io,Apache-2.0,distributed-training;oneflow;large-scale;parallelism
83,OneFlow,Scalable and efficient distributed deep learning framework,"A deep learning framework designed to be user-friendly, scalable, and efficient, with a strong focus on distributed training and performance optimization.",AI3;AI3-01,model_training;distributed_training,platform,C++,https://github.com/Oneflow-Inc/oneflow,https://docs.oneflow.org,Apache-2.0,deep-learning-framework;distributed-training;compiler
84,llm-finetune,Framework for fine-tuning large language models,"A framework for training and fine-tuning large language models, supporting LoRA and full parameter fine-tuning with YAML-based configuration.",AI3;AI3-01,model_finetuning;llm_training,workflow,Python,https://github.com/OpenCSGs/llm-finetune,,Apache-2.0,llm;finetuning;lora;training-framework
85,FlashVSR,Diffusion-based framework for real-time video super-resolution,An efficient one-step diffusion framework for streaming video super-resolution (VSR) utilizing locality-constrained sparse attention.,AI3;AI3-01,data_processing;super_resolution,library,Python,https://github.com/OpenImagingLab/FlashVSR,,Apache-2.0,video-super-resolution;diffusion-models;image-processing
86,CoLLiE,Library for efficient collaborative training of LLMs,Collaborative Training of Large Language Models in an Efficient Way (CoLLiE) is a library designed to facilitate efficient and collaborative training processes for LLMs.,AI3;AI3-01,distributed_training;llm_training,library,Python,https://github.com/OpenMOSS/CoLLiE,,Apache-2.0,llm;collaborative-training;efficient-training
87,MegatronApp,Toolchain and utilities for distributed training with Megatron-LM,"A toolchain built around Megatron-LM to facilitate distributed training workflows, providing additional utilities and ease of use.",AI3;AI3-01,distributed_training;workflow_management,workflow,Python,https://github.com/OpenSQZ/MegatronApp,,NOASSERTION,megatron-lm;distributed-training;toolchain
88,Safe-RLHF,Framework for constrained value alignment via Safe RLHF,"A library for Safe Reinforcement Learning from Human Feedback (RLHF), focusing on constrained value alignment to ensure safety in LLM training.",AI3;AI3-01,model_alignment;rlhf,library,Python,https://github.com/PKU-Alignment/safe-rlhf,https://safe-rlhf.readthedocs.io,Apache-2.0,rlhf;alignment;safety;llm
89,LLM-boost-recognition,OCR and voice recognition module with LLM-based correction,"A module for converting documents and audio into text using OCR and voice recognition, enhanced with LLM-based correction and GPU acceleration, suitable for scientific data digitization.",AI3;AI3-01,data_processing;ocr;speech_recognition,library,Python,https://github.com/PStarH/LLM-boost-recognition,,GPL-3.0,ocr;voice-recognition;llm-correction;data-ingestion
90,PARL,High-performance distributed training framework for Reinforcement Learning,"A flexible and high-performance framework for reinforcement learning (RL) training, supporting distributed architecture and massive parallel environment simulation.",AI3;AI3-01,reinforcement_learning;distributed_training,library,Python,https://github.com/PaddlePaddle/PARL,https://parl.readthedocs.io,Apache-2.0,reinforcement-learning;distributed-training;paddlepaddle
91,PaddlePaddle,Industrial-grade distributed deep learning framework,PArallel Distributed Deep LEarning (PaddlePaddle) is a comprehensive machine learning framework supporting high-performance distributed training and cross-platform deployment.,AI3;AI3-01,model_training;distributed_training,platform,C++,https://github.com/PaddlePaddle/Paddle,https://www.paddlepaddle.org.cn/documentation/,Apache-2.0,deep-learning-framework;distributed-training;industrial
92,Chimera,Library for bidirectional pipeline parallelism in large-scale training,"An implementation of Chimera, a bidirectional pipeline parallelism scheme for efficiently training large-scale models with improved resource utilization.",AI3;AI3-01,distributed_training;pipeline_parallelism,library,Python,https://github.com/ParCIS/Chimera,,GPL-3.0,pipeline-parallelism;distributed-training;efficiency
93,PERSIA,Distributed training framework for deep learning recommendation models,"A high-performance distributed framework specifically designed for training deep learning recommendation models, leveraging hybrid data/model parallelism.",AI3;AI3-01,distributed_training;recommendation_systems,library,Rust,https://github.com/PersiaML/PERSIA,https://persiaml-tutorials.readthedocs.io,MIT,recommendation-models;distributed-training;rust;pytorch
94,Search-R1,RL training framework for reasoning and search engine interleaved LLMs,An efficient and scalable Reinforcement Learning (RL) training framework designed for Large Language Models that interleave reasoning with search engine calls.,AI3;AI3-01,model_training;reinforcement_learning,library,Python,https://github.com/PeterGriffinJin/Search-R1,,Apache-2.0,rl;llm;reasoning;search-engine
95,NeuralSolvers,PyTorch library for solving PDEs and inverse problems using neural networks,A library implementing physics-informed neural networks (PINNs) and other neural solvers for partial differential equations (PDEs) and inverse problems.,AI3;AI3-01,scientific_modeling;pde_solver,solver,Python,https://github.com/Photon-AI-Research/NeuralSolvers,,MIT,pinn;pde;physics-informed;inverse-problems
96,sparse-frontier,Framework for evaluating training-free sparse attention in LLMs,An evaluation framework designed to analyze and benchmark training-free sparse attention mechanisms in Large Language Models.,AI3;AI3-01,model_evaluation;attention_analysis,library,Python,https://github.com/PiotrNawrot/sparse-frontier,,NOASSERTION,sparse-attention;llm;evaluation;benchmarking
97,OpenDiloco,Framework for globally distributed low-communication model training,"An open-source framework implementing the DiLoCo algorithm for globally distributed training with low communication overhead, enabling training across disconnected clusters.",AI3;AI3-01,distributed_training;decentralized_learning,library,Python,https://github.com/PrimeIntellect-ai/OpenDiloco,,Apache-2.0,distributed-training;low-bandwidth;diloco
98,Prime DiLoCo,Framework for globally distributed AI model training over the internet,"A framework designed for efficient, globally distributed training of AI models across geographically dispersed devices connected via the internet, enabling decentralized computing resources to collaborate on model training.",AI3;AI3-01,distributed_training;decentralized_computing,framework,Python,https://github.com/PrimeIntellect-ai/prime-diloco,,Apache-2.0,distributed-training;decentralized-ai;diloco
99,Prime Iroh,Asynchronous P2P communication backend for decentralized pipeline parallelism,A Rust-based asynchronous peer-to-peer (P2P) communication backend designed to support decentralized pipeline parallelism in distributed AI training workflows.,AI3;AI3-01,distributed_communication;pipeline_parallelism,library,Rust,https://github.com/PrimeIntellect-ai/prime-iroh,,MIT,p2p;distributed-training;communication-backend
100,Prime vLLM,Modified vLLM for pipeline parallelism over public networks,"A modification of the vLLM library tailored to execute pipeline parallelism across public networks, facilitating distributed inference and training setups in decentralized environments.",AI3;AI3-01,inference_optimization;pipeline_parallelism,framework,Python,https://github.com/PrimeIntellect-ai/prime-vllm,,None,vllm;pipeline-parallelism;distributed-inference
101,MAPLE,Hardware-software co-design for asynchronous memory parallelism,"A hardware-software co-design framework that enables programs to perform long-latency memory accesses asynchronously from the core, reducing pipeline stalls and increasing memory level parallelism (MLP).",AI3;AI3-01,memory_optimization;hardware_acceleration,solver,C,https://github.com/PrincetonUniversity/maple,,None,memory-parallelism;hardware-software-codesign;performance-optimization
102,TensorNet,Distributed training framework optimized for large-scale sparse data,"A C++ based distributed training framework built on TensorFlow, specifically optimized for handling large-scale sparse data typical in recommendation systems and advertising scenarios.",AI3;AI3-01,distributed_training;sparse_data_processing,framework,C++,https://github.com/Qihoo360/tensornet,,Apache-2.0,distributed-training;sparse-data;tensorflow
103,QizNLP,TensorFlow framework for rapid NLP task execution,"A TensorFlow-based framework designed for quickly running various Natural Language Processing (NLP) tasks such as classification, sequence labeling, matching, and generation, with support for distributed training.",AI3,nlp_tasks;model_training,framework,Python,https://github.com/Qznan/QizNLP,,MPL-2.0,nlp;tensorflow;distributed-training
104,Reinforce-Ada,Adaptive sampling framework for Reinforce-style LLM post-training,"A framework implementing adaptive sampling strategies for Reinforce-style post-training of Large Language Models (LLMs), aiming to improve alignment and performance efficiency.",AI3,post_training;rlhf;adaptive_sampling,framework,Python,https://github.com/RLHFlow/Reinforce-Ada,,Apache-2.0,llm;reinforcement-learning;post-training
105,Flash-Sparse-Attention,Efficient implementations of Native Sparse Attention,"A library providing efficient implementations of Native Sparse Attention mechanisms, designed to accelerate Transformer models by reducing computational complexity and memory usage.",AI3;AI3-01,attention_mechanism;model_acceleration,library,Python,https://github.com/Relaxed-System-Lab/Flash-Sparse-Attention,,Apache-2.0,sparse-attention;optimization;transformer
106,Flash Attention v2 RDNA3,Flash Attention v2 implementation for ROCm/RDNA3 GPUs,"A minimal implementation of Flash Attention v2 optimized for AMD RDNA3 GPUs using ROCm, enabling accelerated inference and training for models like Stable Diffusion in specific hardware environments.",AI3;AI3-01,hardware_acceleration;attention_mechanism,library,Python,https://github.com/Repeerc/flash-attention-v2-RDNA3-minimal,,Apache-2.0,rocm;flash-attention;rdna3
107,AI Attention Acceleration,Pre-compiled attention acceleration packages for Windows AI workflows,"A utility repository providing pre-compiled acceleration libraries (xformers, Flash Attention, SageAttention) to enhance the efficiency of AI workflows like ComfyUI and Fooocus on Windows systems.",AI3;AI3-01,workflow_optimization;hardware_acceleration,utility,Python,https://github.com/Rogala/AI_Attention,,Unlicense,windows;acceleration;xformers
108,FastCkpt,Rematerialization-aware gradient checkpointing for memory efficiency,"A Python package implementing rematerialization-aware gradient checkpointing, optimizing memory usage during the training of deep learning models by selectively recomputing activations.",AI3;AI3-01,memory_optimization;gradient_checkpointing,library,Python,https://github.com/RulinShao/FastCkpt,,Apache-2.0,gradient-checkpointing;memory-optimization;training
109,LightSeq (DistFlashAttn),Distributed memory-efficient attention for long-context LLM training,"The official repository for DistFlashAttn, providing distributed memory-efficient attention mechanisms to support the training of Large Language Models (LLMs) with long context windows.",AI3;AI3-01,attention_mechanism;distributed_training;long_context,library,Python,https://github.com/RulinShao/LightSeq,,None,distributed-attention;llm;long-context
110,MagiAttention,Distributed attention for linear scalability in ultra-long context training,"A distributed attention mechanism designed to achieve linear scalability, enabling the training of models with ultra-long contexts and heterogeneous data.",AI3;AI3-01,attention_mechanism;distributed_training;scalability,library,Python,https://github.com/SandAI-org/MagiAttention,,Apache-2.0,distributed-attention;long-context;linear-scalability
111,DiffEqGPU.jl,GPU-acceleration routines for DifferentialEquations.jl,"A library providing GPU-acceleration routines for the DifferentialEquations.jl package, facilitating high-performance scientific machine learning (SciML) and differential equation solving on GPUs.",AI3;AI3-01,scientific_computing;differential_equations;gpu_acceleration,library,Julia,https://github.com/SciML/DiffEqGPU.jl,,MIT,sciml;differential-equations;gpu;julia
112,Fast-LLM,Framework for accelerating LLM training,"A framework developed by ServiceNow Research to accelerate the training of Large Language Models (LLMs), optimizing performance and resource utilization.",AI3;AI3-01,model_training;performance_optimization,framework,Python,https://github.com/ServiceNow/Fast-LLM,,NOASSERTION,llm;training-acceleration;servicenow
113,LLM-Training,Distributed training framework for LLMs powered by Lightning,"A distributed training framework built on PyTorch Lightning, designed to facilitate the training of Large Language Models (LLMs) with distributed computing capabilities.",AI3;AI3-01,distributed_training;llm,framework,Python,https://github.com/ShinoharaHare/LLM-Training,,Apache-2.0,pytorch-lightning;distributed-training;llm
114,simpleT5,Wrapper for quick T5 model training using PyTorch Lightning,"A simplified wrapper library built on top of PyTorch Lightning and Hugging Face Transformers, designed to streamline and accelerate the training process for T5 (Text-to-Text Transfer Transformer) models.",AI3,model_training;nlp,library,Python,https://github.com/Shivanandroy/simpleT5,,MIT,t5;pytorch-lightning;transformers;nlp
115,DRPO (Dynamic Alignment Optimization),Tuning-free approach for self-alignment with prompt optimization,"An implementation of Dynamic Rewarding with Prompt Optimization (DRPO), a tuning-free framework that enables Large Language Models (LLMs) to iteratively self-improve and design optimal alignment instructions without additional training.",AI3,model_alignment;prompt_optimization,solver,Python,https://github.com/Singla17/dynamic-alignment-optimization,,Apache-2.0,alignment;prompt-optimization;llm
116,Tiresias,GPU cluster manager for distributed deep learning training,"A GPU cluster scheduling and management system designed specifically for distributed deep learning training workloads, optimizing resource allocation and job scheduling.",AI3;AI3-01,cluster_management;resource_scheduling,platform,Python,https://github.com/SymbioticLab/Tiresias,,Apache-2.0,gpu-scheduling;distributed-training;cluster-manager
117,Aparapi,Framework for executing native Java and Scala code on the GPU,"A framework that allows developers to write native Java or Scala code and execute it on the GPU by converting bytecode to OpenCL, facilitating parallel computing and acceleration.",AI3;AI3-01,parallel_computing;gpu_acceleration,framework,Java,https://github.com/Syncleus/aparapi,,Apache-2.0,gpu;java;opencl;parallel-computing
118,Slime,LLM post-training framework for RL Scaling,"A post-training framework for Large Language Models (LLMs) focused on Reinforcement Learning (RL) scaling, providing tools and methods to enhance model performance through RL techniques.",AI3,post_training;reinforcement_learning;rlhf,framework,Python,https://github.com/THUDM/slime,,Apache-2.0,llm;rlhf;post-training
119,MARTI,LLM-based Multi-Agent Reinforced Training and Inference Framework,"A framework designed for multi-agent reinforced training and inference using Large Language Models (LLMs), developed by Tsinghua University C3I.",AI3;AI3-01,training_framework;multi_agent_reinforcement_learning,framework,Python,https://github.com/TsinghuaC3I/MARTI,,MIT,llm;multi-agent;reinforcement-learning
120,Mandheling,Mixed-Precision On-Device DNN Training with DSP Offloading,An open-source implementation of the Mandheling system (MobiCom'2022) for efficient on-device deep neural network training using DSP offloading and mixed-precision techniques.,AI3;AI3-01,on_device_training;acceleration,solver,C,https://github.com/UbiquitousLearning/Mandheling-DSP-Training,,None,on-device-learning;dsp-offloading;mixed-precision
121,PP-Schedule-Visualization,Pipeline Parallelism Emulation and Visualization Tool,"A tool for emulating and visualizing the scheduling of pipeline parallelism in distributed deep learning training, aiding in performance analysis and optimization.",AI3;AI3-01,visualization;performance_analysis,tool,Python,https://github.com/Victarry/PP-Schedule-Visualization,,MIT,pipeline-parallelism;visualization;distributed-training
122,blitzdg,Parallel Discontinuous Galerkin (DG) Solver,"An open-source parallel discontinuous Galerkin (DG) solver implementation for partial differential equations, utilizing blitz++ for tensor manipulation and MPI for distributed parallelism.",Scientific Computing,pde_solver;simulation,solver,C++,https://github.com/WQCG/blitzdg,,NOASSERTION,pde;discontinuous-galerkin;mpi
123,SRUM,Fine-Grained Self-Rewarding Framework for Multimodal Models,"A post-training framework that creates a cost-effective, self-iterative optimization loop for unified multimodal models, implementing fine-grained self-rewarding mechanisms.",AI3;AI3-01,post_training;optimization,framework,Python,https://github.com/WayneJin0918/SRUM,,Apache-2.0,multimodal;self-rewarding;post-training
124,tf-recsys,TensorFlow-based Collaborative Filtering Library,"A library implementing collaborative filtering models (SVD, SVD++) using TensorFlow to utilize GPU acceleration for recommendation system tasks.",AI3,recommendation;model_implementation,library,Python,https://github.com/WindQAQ/tf-recsys,,MIT,recsys;tensorflow;collaborative-filtering
125,Mochi-Full-Finetuner,Full Finetuning Tool for Mochi Model,A specialized tool for performing full parameter finetuning of the Mochi video generation model using FSDP (Fully Sharded Data Parallel) and Context Parallelism.,AI3;AI3-01,model_finetuning;video_generation,solver,Python,https://github.com/Yaofang-Liu/Mochi-Full-Finetuner,,Apache-2.0,finetuning;fsdp;mochi
126,ray-skorch,Distributed Skorch on Ray Train,A library that integrates Skorch (a scikit-learn compatible neural network library) with Ray Train to enable distributed training capabilities.,AI3;AI3-01,distributed_training;framework_integration,library,Python,https://github.com/Yard1/ray-skorch,,Apache-2.0,ray;skorch;distributed
127,OptimalShardedDataParallel,Automated Parallel Training System (OSDP),"An automated parallel training system that combines the advantages of data and model parallelism, optimizing sharded data parallel strategies (IJCAI 2023).",AI3;AI3-01,distributed_training;parallelism_optimization,system,Python,https://github.com/Youhe-Jiang/IJCAI2023-OptimalShardedDataParallel,,MIT,distributed-training;sharding;parallelism
128,GNNAdvisor,Adaptive Runtime System for GNN Acceleration,An adaptive and efficient runtime system designed for accelerating Graph Neural Networks (GNNs) on GPUs (OSDI'21 Artifact).,AI3;AI3-01,gnn_acceleration;runtime_system,system,Cuda,https://github.com/YukeWang96/GNNAdvisor_OSDI21,,None,gnn;gpu-acceleration;runtime
129,train-CLIP,PyTorch Lightning Solution for Training CLIP,"A comprehensive PyTorch Lightning-based framework for training OpenAI's CLIP models from scratch, providing a reusable training pipeline.",AI3;AI3-01,model_training;multimodal,framework,Python,https://github.com/Zasder3/train-CLIP,,MIT,clip;pytorch-lightning;training-pipeline
130,TSDS,Task-Specific Data Selection Framework,An optimal-transport based framework for selecting domain-specific and task-specific training data to improve LLM finetuning and instruction tuning efficiency.,AI3,data_selection;finetuning_optimization,framework,Python,https://github.com/ZifanL/TSDS,,MIT,data-selection;llm;optimal-transport
131,ProteinWorkshop,Protein Representation Learning Benchmarking Framework,"A comprehensive framework for benchmarking protein representation learning, including datasets, pre-training models, and downstream task utilities (ICLR 2024).",AI4S;Biology,protein_modeling;benchmarking,framework,Python,https://github.com/a-r-j/ProteinWorkshop,,MIT,protein-structure;representation-learning;benchmark
132,MinimalGPT,Minimalist GPT Training and Inference Framework,"A concise and adaptable framework implemented in Keras/TensorFlow for constructing, training, and finetuning GPT models, serving as a lightweight tool for research and education.",AI3;AI3-01,model_training;inference,framework,Python,https://github.com/abhaskumarsinha/MinimalGPT,,MIT,gpt;keras;educational-framework
133,synth.,Synthetic Instruction Generation Framework,A framework designed for generating synthetic instructions to enhance Large Language Model (LLM) training datasets.,AI3,data_generation;synthetic_data,framework,Python,https://github.com/aboros98/synth,,Apache-2.0,synthetic-data;instruction-tuning;llm
134,AidLearning,Mobile AIOT Development and Inference Platform,"A powerful AIOT development platform supporting Linux on Android, enabling CPU+GPU+NPU accelerated inference and development directly on mobile devices.",AI3;AI3-01,edge_inference;mobile_ai,platform,Python,https://github.com/aidlearning/AidLearning-FrameWork,,NOASSERTION,mobile-ai;edge-computing;inference-acceleration
135,minPP,Minimalist Pipeline Parallelism Library,"A lightweight implementation of pipeline parallelism for distributed deep learning training, designed for simplicity and ease of integration.",AI3;AI3-01,distributed_training;pipeline_parallelism,library,Python,https://github.com/ailzhang/minPP,,MIT,pipeline-parallelism;distributed-training;minimalist
136,rllib-fast-serve,Lightweight Inference Tool for Ray RLlib Policies,"A set of tools to export policies trained with Ray RLlib for lightweight and fast inference, decoupling inference from the heavy Ray dependencies.",AI3;AI3-01,inference_serving;reinforcement_learning,tool,Python,https://github.com/airboxlab/rllib-fast-serve,,MIT,rllib;inference;serving
137,IceVision,Agnostic Computer Vision Framework,"A computer vision framework that is agnostic to the underlying training library, allowing pluggable integration with Fastai, PyTorch Lightning, and others.",AI3,computer_vision;training_framework,framework,Python,https://github.com/airctic/icevision,,Apache-2.0,computer-vision;framework-agnostic;object-detection
138,full_stack_transformer,End-to-End Transformer Training and Serving Library,"A PyTorch library designed for the complete lifecycle of transformer models, including training, inference, and serving.",AI3;AI3-01,model_training;serving,library,Python,https://github.com/alexeykarnachev/full_stack_transformer,,NOASSERTION,transformer;serving;pytorch
139,flashattention2-custom-mask,FlashAttention2 with Custom Mask Support,"A Triton-based implementation of FlashAttention2 that extends the original kernel to support custom attention masks, useful for specialized attention patterns.",AI3;AI3-01,acceleration_kernel;attention_mechanism,library,Python,https://github.com/alexzhang13/flashattention2-custom-mask,,Apache-2.0,flash-attention;triton;custom-mask
140,EasyParallelLibrary,Distributed Model Training Framework (EPL),"A general and efficient deep learning framework developed by Alibaba for distributed model training, simplifying the implementation of parallel strategies.",AI3;AI3-01,distributed_training;parallelism,framework,Python,https://github.com/alibaba/EasyParallelLibrary,,Apache-2.0,distributed-training;deep-learning;alibaba
141,Euler,Distributed Graph Deep Learning Framework,"A large-scale distributed graph learning framework developed by Alibaba, designed to handle massive graph data for deep learning tasks.",AI3;AI3-01,graph_learning;distributed_training,framework,C++,https://github.com/alibaba/euler,,Apache-2.0,graph-neural-networks;distributed-system;graph-learning
142,oss-connector-for-ai-ml,OSS Storage Connector for AI/ML Frameworks,"A high-performance Python library for connecting major AI/ML frameworks (like PyTorch, TensorFlow) directly with Alibaba Cloud OSS storage for efficient data loading.",AI3;AI3-01,data_io;storage_integration,library,Python,https://github.com/aliyun/oss-connector-for-ai-ml,,MIT,data-loading;oss;cloud-storage
143,AlpaServe,Statistical Multiplexing for Deep Learning Serving,A system for deep learning serving that utilizes statistical multiplexing with model parallelism to improve efficiency and throughput (OSDI 23).,AI3;AI3-01,model_serving;distributed_inference,system,Python,https://github.com/alpa-projects/mms,,None,serving;model-parallelism;multiplexing
144,alpaka,Abstraction Library for Parallel Kernel Acceleration,"A C++ header-only library that provides an abstraction layer for parallel kernel acceleration across various hardware backends (CUDA, HIP, OpenMP, etc.).",AI3;AI3-01,acceleration;hpc,library,C++,https://github.com/alpaka-group/alpaka,,MPL-2.0,hpc;kernel-acceleration;portability
145,jvp_flash_attention,Flash Attention with Second-Order Derivative Support,"A Flash Attention Triton kernel implementation that supports Jacobian-Vector Products (JVP), enabling second-order derivative computations.",AI3;AI3-01,acceleration_kernel;differentiation,library,Python,https://github.com/amorehead/jvp_flash_attention,,NOASSERTION,flash-attention;triton;second-order-derivatives
146,Galaxy_simulation,GPU-Accelerated N-Body Galaxy Simulation,"An N-body simulation tool utilizing GPU acceleration to simulate galaxies, galaxy collisions, and expanding universes.",Scientific Computing;Astrophysics,simulation;n_body,solver,C++,https://github.com/angeluriot/Galaxy_simulation,,MIT,n-body;galaxy-simulation;gpu
147,LLMOPT,Comprehensive resources and framework for LLM training and inference optimization,"A project offering a model, dataset, training framework, and inference code to enable users to utilize and optimize Large Language Models (LLMs), specifically focusing on instruction tuning and optimization.",AI3;AI3-01,model_training,platform,Python,https://github.com/antgroup/LLMOPT,,None,llm;training-framework;optimization;instruction-tuning
148,GLake,GPU memory management and IO transmission optimization library,"A library designed to optimize GPU memory management and I/O transmission for deep learning training, aiming to improve efficiency and performance in distributed environments.",AI3;AI3-01,infrastructure_optimization,library,Python,https://github.com/antgroup/glake,,Apache-2.0,gpu-optimization;memory-management;distributed-training
149,Apache MXNet,Flexible and efficient distributed deep learning framework,"A lightweight, portable, and flexible distributed deep learning framework that supports dynamic, mutation-aware dataflow dependency scheduling. It supports multiple languages including Python, R, and Julia.",AI3;AI3-01,model_training,solver,C++,https://github.com/apache/mxnet,https://mxnet.apache.org,Apache-2.0,deep-learning;distributed-training;framework
150,Apache SINGA,Distributed deep learning platform,"A distributed deep learning platform for training big deep learning models over large datasets, designed to be intuitive and usable.",AI3;AI3-01,model_training,platform,C++,https://github.com/apache/singa,http://singa.apache.org,Apache-2.0,deep-learning;distributed-system;training-platform
151,TensorFlow for macOS,TensorFlow accelerated for macOS using ML Compute,A version of TensorFlow optimized for macOS 11.0+ that leverages Apple's ML Compute framework for hardware-accelerated training and inference on Mac devices.,AI3;AI3-01,model_training,solver,Shell,https://github.com/apple/tensorflow_macos,,None,tensorflow;macos;acceleration;ml-compute
152,LLM-Inference-Bench,Benchmark suite for LLM inference performance,"A benchmarking tool designed to evaluate the inference performance of Large Language Models, likely developed by Argonne National Laboratory.",AI3;AI3-01,performance_analysis,solver,Jupyter Notebook,https://github.com/argonne-lcf/LLM-Inference-Bench,,BSD-3-Clause,llm;benchmarking;inference;hpc
153,Arkalos,Python framework for data analysis and LLM training,"A Python framework designed to simplify data analysis, building data apps, and training Large Language Models (LLMs) with an elegant syntax.",AI3;AI3-01,model_training,framework,Python,https://github.com/arkaloscom/arkalos,,None,llm-training;data-analysis;framework
154,SiLLM,LLM training and inference framework for Apple Silicon,A framework that simplifies the process of training and running Large Language Models (LLMs) on Apple Silicon devices by leveraging the MLX framework.,AI3;AI3-01,model_training,framework,Python,https://github.com/armbues/SiLLM,,MIT,apple-silicon;mlx;llm;training
155,StringZilla,High-performance string processing library leveraging SIMD,"A library providing up to 100x faster string operations (search, hashing, sorting, edit distances) for C, C++, Python, and other languages by leveraging NEON, AVX2, AVX-512, and other hardware acceleration. Useful for bioinformatics and text processing.",AI3;AI3-01,data_processing,library,C,https://github.com/ashvardanian/StringZilla,,Apache-2.0,simd;string-processing;hpc;acceleration
156,Fine-Tune Codebase,Tool for fine-tuning LLMs on codebases,"A scalable and efficient tool for fine-tuning large language models (LLMs) specifically on codebases. It supports LoRA, mixed precision training, and quantization.",AI3;AI3-01,model_training,solver,Python,https://github.com/ayminovitch/fine-tune-codebase,,MIT,llm;fine-tuning;lora;code-llm
157,Piper Plus,Enhanced Piper TTS training framework,"An enhanced version of Piper TTS supporting multi-GPU training, Japanese language support, and quality improvements. It serves as a training framework for text-to-speech models.",AI3;AI3-01,model_training,framework,C++,https://github.com/ayutaz/piper-plus,,MIT,tts;training-framework;multi-gpu
158,Distributed Llama,Distributed LLM inference on home devices,"A tool for distributed LLM inference that allows connecting multiple devices into a cluster to accelerate inference, effectively creating a distributed computing environment for LLMs.",AI3;AI3-01,inference,solver,C++,https://github.com/b4rtaz/distributed-llama,,MIT,distributed-inference;llm;edge-computing
159,tf2-gradient-checkpointing,Gradient checkpointing implementation for TensorFlow 2 eager execution,"A Python library providing gradient checkpointing functionality for TensorFlow 2 in eager mode, enabling the training of larger models by trading compute for memory.",AI3;AI3-01,memory_optimization;model_training,library,Python,https://github.com/davisyoshida/tf2-gradient-checkpointing,,MIT,tensorflow;gradient-checkpointing;memory-optimization
160,AdaSplash,Adaptive Sparse Flash Attention implementation,"A library implementing Adaptive Sparse Flash Attention (Flash Entmax Attention), designed to optimize attention mechanisms in transformer models for better efficiency.",AI3;AI3-01,attention_mechanism;model_optimization,library,Python,https://github.com/deep-spin/adasplash,,MIT,attention;sparse-attention;transformer
161,3FS,High-performance distributed file system for AI training,"A high-performance distributed file system specifically designed to address the I/O challenges of large-scale AI training and inference workloads, providing high throughput and low latency.",AI3;AI3-01,data_storage;distributed_training,solver,C++,https://github.com/deepseek-ai/3FS,,MIT,file-system;distributed-storage;ai-infrastructure
162,DualPipe,Bidirectional pipeline parallelism for LLM training,A bidirectional pipeline parallelism algorithm designed to overlap computation and communication during the training of large language models like DeepSeek V3/R1.,AI3;AI3-01,distributed_training;pipeline_parallelism,library,Python,https://github.com/deepseek-ai/DualPipe,,MIT,pipeline-parallelism;llm-training;distributed-computing
163,FlashMLA,Efficient Multi-head Latent Attention Kernels,"A library providing optimized kernels for Multi-head Latent Attention (MLA), designed to accelerate inference and training of large language models on GPUs.",AI3;AI3-01,kernel_optimization;attention_mechanism,library,C++,https://github.com/deepseek-ai/FlashMLA,,MIT,cuda-kernels;attention;optimization
164,DeepSpeed,Deep learning optimization library for distributed training,"A deep learning optimization library that enables massive-scale distributed training and inference with high efficiency, ease of use, and effectiveness, supporting techniques like ZeRO, pipeline parallelism, and 3D parallelism.",AI3;AI3-01,distributed_training;model_optimization,library,Python,https://github.com/deepspeedai/DeepSpeed,https://www.deepspeed.ai/,Apache-2.0,distributed-training;zero-redundancy;optimization
165,DeepSpeed-MII,Low-latency and high-throughput inference library,Model Implementations for Inference (MII) is a library powered by DeepSpeed that provides low-latency and high-throughput inference for deep learning models.,AI3;AI3-01,inference_optimization;model_serving,library,Python,https://github.com/deepspeedai/DeepSpeed-MII,,Apache-2.0,inference;latency-optimization;deepspeed
166,Determined,Open-source deep learning training platform,"A platform that simplifies distributed training, hyperparameter tuning, experiment tracking, and resource management for deep learning models, supporting PyTorch and TensorFlow.",AI3;AI3-01,training_platform;experiment_management;hyperparameter_tuning,platform,Go,https://github.com/determined-ai/determined,https://docs.determined.ai/,Apache-2.0,mlops;distributed-training;experiment-tracking
167,DeepDist,Distributed Deep Learning on Apache Spark,"A tool that enables distributed deep learning training on Apache Spark clusters, allowing users to leverage Spark's data processing capabilities for deep learning workflows.",AI3;AI3-01,distributed_training;spark_integration,library,Python,https://github.com/dirkneumann/deepdist,,None,spark;distributed-learning;deep-learning
168,Paracel,Distributed training framework with parameter server,A distributed training framework that implements the parameter server architecture to scale machine learning model training across multiple nodes.,AI3;AI3-01,distributed_training;parameter_server,solver,C++,https://github.com/douban/paracel,,NOASSERTION,parameter-server;distributed-ml;framework
169,Dragonfly,P2P-based data distribution and acceleration system,An intelligent P2P based image and file distribution system that provides efficient data distribution and acceleration for cloud native and AI workloads.,AI3;AI3-01,data_distribution;infrastructure_acceleration,solver,Go,https://github.com/dragonflyoss/dragonfly,https://d7y.io/,Apache-2.0,p2p;file-distribution;container-acceleration
170,VisDrone-dataset-python-toolkit,Toolkit for VisDrone aerial object detection dataset,"A PyTorch toolkit designed for the VisDrone dataset, providing training pipelines, inference tools, and format converters for aerial object detection tasks.",AI3;AI3-01,data_processing;object_detection;training_pipeline,workflow,Python,https://github.com/dronefreak/VisDrone-dataset-python-toolkit,,Apache-2.0,visdrone;object-detection;aerial-imagery
171,js-pytorch,JavaScript deep learning library with GPU acceleration,"A JavaScript library that provides a PyTorch-like API for deep learning, supporting GPU acceleration for training and inference in JavaScript environments.",AI3;AI3-01,model_training;inference,library,JavaScript,https://github.com/eduardoleao052/js-pytorch,,MIT,javascript;deep-learning;gpu-acceleration
172,jax-flash-attn2,Flash Attention 2.0 implementation for JAX,"A flexible and efficient implementation of Flash Attention 2.0 for JAX, supporting multiple backends (GPU/TPU) and enabling efficient attention computation in JAX-based models.",AI3;AI3-01,attention_mechanism;kernel_optimization,library,Python,https://github.com/erfanzar/jax-flash-attn2,,Apache-2.0,jax;flash-attention;optimization
173,fsdp_optimizers,Optimizer support for PyTorch FSDP,"A library that provides support for using various optimizers with PyTorch's Fully Sharded Data Parallel (FSDP) training, facilitating distributed training workflows.",AI3;AI3-01,distributed_training;optimization,library,Python,https://github.com/ethansmith2000/fsdp_optimizers,,Apache-2.0,fsdp;pytorch;distributed-training
174,nvblox_ros1,ROS1 wrappers for nvblox GPU volumetric mapping,"ROS1 wrappers for nvblox, enabling GPU-accelerated volumetric mapping for robotics and perception tasks, facilitating real-time 3D reconstruction.",AI3;AI3-01,volumetric_mapping;robotics_perception,library,C++,https://github.com/ethz-asl/nvblox_ros1,,Apache-2.0,ros;mapping;gpu-acceleration
175,Expert Kit,Expert Parallelism foundation for MoE inference,A library providing efficient implementations of Expert Parallelism (EP) for Mixture-of-Experts (MoE) model inference on heterogeneous hardware.,AI3;AI3-01,inference_optimization;moe_parallelism,library,Rust,https://github.com/expert-kit/expert-kit,,LGPL-3.0,moe;inference;parallelism
176,spaCy,Industrial-strength Natural Language Processing library,"A comprehensive library for Natural Language Processing (NLP) in Python, featuring pre-trained models, efficient tokenization, and support for deep learning integration.",AI3,nlp;text_processing;model_inference,library,Python,https://github.com/explosion/spaCy,https://spacy.io/,MIT,nlp;text-processing;linguistics
177,Dynolog,Telemetry daemon for AI performance monitoring,"A telemetry daemon for performance monitoring and tracing of AI workloads, capable of exporting metrics from system components and integrating with PyTorch for distributed training analysis.",AI3;AI3-01,performance_monitoring;profiling,solver,C++,https://github.com/facebookincubator/dynolog,,MIT,telemetry;profiling;gpu-monitoring
178,Flashy,Framework for deep learning training loops,"A lightweight framework for writing deep learning training loops that handles checkpointing, logging, and distributed training setup, allowing researchers to focus on model design.",AI3;AI3-01,training_framework;experiment_management,library,Python,https://github.com/facebookresearch/flashy,,MIT,training-loop;pytorch;boilerplate
179,moolib,Library for distributed ML training with PyTorch,"A C++ and Python library designed to facilitate distributed machine learning training with PyTorch, offering efficient communication primitives and data loading.",AI3;AI3-01,distributed_training;communication_primitives,library,C++,https://github.com/facebookresearch/moolib,,MIT,distributed-ml;rpc;pytorch
180,Stochastic Gradient Push,Stochastic Gradient Push algorithm for distributed learning,"An implementation of the Stochastic Gradient Push algorithm, enabling decentralized distributed deep learning on directed graphs.",AI3;AI3-01,distributed_training;optimization_algorithm,library,Python,https://github.com/facebookresearch/stochastic_gradient_push,,NOASSERTION,distributed-learning;gossip-algorithm;decentralized
181,flash-bidirectional-linear-attention,Triton implementation of bi-directional linear attention,A library providing efficient Triton-based implementations of bi-directional (non-causal) linear attention mechanisms for transformer models.,AI3;AI3-01,attention_mechanism;kernel_optimization,library,Python,https://github.com/fla-org/flash-bidirectional-linear-attention,,MIT,linear-attention;triton;optimization
182,flash-linear-attention,Efficient linear attention model implementations,"A library containing efficient implementations of state-of-the-art linear attention models, optimized for speed and memory usage in sequence modeling tasks.",AI3;AI3-01,attention_mechanism;model_optimization,library,Python,https://github.com/fla-org/flash-linear-attention,,MIT,linear-attention;efficient-transformers;cuda
183,Flash Sparse Attention,Fast and memory-efficient sparse attention mechanism for Transformer training,"A library providing trainable, fast, and memory-efficient sparse attention kernels, designed to accelerate the training of large-scale Transformer models by optimizing GPU memory usage and computation speed.",AI3;AI3-01,model_acceleration;training_optimization,library,Python,https://github.com/flash-algo/flash-sparse-attention,,BSD-3-Clause,sparse-attention;transformer;acceleration;gpu-kernels
184,FlashInfer,High-performance kernel library for LLM serving and inference acceleration,A kernel library designed to accelerate Large Language Model (LLM) serving. It provides optimized CUDA kernels for attention mechanisms and other operations critical for efficient inference in scientific and general AI applications.,AI3;AI3-01,inference_acceleration;model_serving,library,Cuda,https://github.com/flashinfer-ai/flashinfer,,Apache-2.0,llm-serving;cuda-kernels;inference;acceleration
185,FlexFlow,Deep learning framework for automatic distributed training parallelization,"A deep learning framework that automatically discovers fast parallelization strategies for distributed deep neural network training, optimizing performance across heterogeneous cluster environments.",AI3;AI3-01,distributed_training;parallelization_strategy,framework,C++,https://github.com/flexflow/flexflow-train,https://flexflow.ai,Apache-2.0,distributed-training;parallelization;deep-learning
186,Deep Learning on Flink,Integration of deep learning frameworks with Apache Flink for distributed training,"A framework that integrates Flink with deep learning libraries (TensorFlow, PyTorch) to enable distributed deep learning training and inference workflows on Flink clusters.",AI3;AI3-01,distributed_training;workflow_integration,framework,Java,https://github.com/flink-extended/dl-on-flink,,Apache-2.0,flink;distributed-training;tensorflow;pytorch
187,FMS Acceleration,Acceleration libraries for fine-tuning foundation models,A collection of libraries designed to work with fms-hf-tuning to accelerate the fine-tuning and training processes of large foundation models.,AI3;AI3-01,model_acceleration;fine_tuning,library,Python,https://github.com/foundation-model-stack/fms-acceleration,,Apache-2.0,fine-tuning;acceleration;foundation-models
188,FMS FSDP,Efficient foundation model training using PyTorch FSDP,"A library for efficiently pre-training and training foundation models leveraging native PyTorch features, specifically Fully Sharded Data Parallel (FSDP) and Flash Attention v2.",AI3;AI3-01,distributed_training;fsdp,library,Python,https://github.com/foundation-model-stack/fms-fsdp,,Apache-2.0,fsdp;distributed-training;pytorch
189,FMS HF Tuning,Tuning recipes for foundation models with HuggingFace and FSDP,A collection of tuning recipes and utilities integrating HuggingFace SFTTrainer with PyTorch FSDP for efficient model fine-tuning.,AI3;AI3-01,fine_tuning;training_recipes,library,Python,https://github.com/foundation-model-stack/fms-hf-tuning,,Apache-2.0,fine-tuning;huggingface;fsdp
190,Foundation Model Stack,Comprehensive stack for foundation model development and training,"A collection of components for the development, training, tuning, and inference of foundation models, leveraging native PyTorch components for modularity and performance.",AI3;AI3-01,model_development;training_stack,platform,Python,https://github.com/foundation-model-stack/foundation-model-stack,,Apache-2.0,foundation-models;training-stack;pytorch
191,SkipPipe,Framework for pipelined training of LLMs in heterogeneous networks,A framework implementing partial and reordered pipelining strategies to optimize the training of Large Language Models (LLMs) across heterogeneous network environments.,AI3;AI3-01,distributed_training;pipeline_parallelism,framework,Python,https://github.com/gensyn-ai/skippipe,,MIT,pipeline-parallelism;llm-training;heterogeneous-computing
192,Knowledge Distillation Toolkit,Toolkit for knowledge distillation based on PyTorch Lightning,"A toolkit designed to facilitate knowledge distillation experiments and implementation, built on top of PyTorch and PyTorch Lightning.",AI3;AI3-01,knowledge_distillation;model_compression,library,Python,https://github.com/georgian-io/Knowledge-Distillation-Toolkit,,Apache-2.0,knowledge-distillation;pytorch-lightning
193,Llama2 LoRA Fine-tuning,Scripts for fine-tuning Llama2 using DeepSpeed and LoRA,A utility repository providing scripts and configurations for fine-tuning Llama2 models using DeepSpeed for distributed training and LoRA for parameter-efficient adaptation.,AI3;AI3-01,fine_tuning;parameter_efficient_tuning,solver,Python,https://github.com/git-cloner/llama2-lora-fine-tuning,,MIT,llama2;lora;deepspeed;fine-tuning
194,Pax,Jax-based framework for training large scale machine learning models,"A machine learning framework built on Jax, designed for advanced configuration and parallelization to train large-scale models with high flop utilization.",AI3;AI3-01,training_framework;large_scale_training,framework,Python,https://github.com/google/paxml,,Apache-2.0,jax;large-scale-training;pax
195,GPGPU-Sim,Cycle-level simulator for NVIDIA GPUs,"A detailed simulation model of contemporary NVIDIA GPUs running CUDA and/or OpenCL workloads, used for computer architecture research and performance analysis of GPU-accelerated applications.",AI3;AI3-01,hardware_simulation;performance_analysis,solver,C++,https://github.com/gpgpu-sim/gpgpu-sim_distribution,http://www.gpgpu-sim.org/,NOASSERTION,gpu-simulator;cuda;computer-architecture
196,PyGraphistry,GPU-accelerated library for big graph visualization and analysis,"A Python library to load, shape, embed, and explore large graphs using GPU acceleration, facilitating visual graph analysis for scientific and data science applications.",AI3,scientific_visualization;graph_analysis,library,Python,https://github.com/graphistry/pygraphistry,https://github.com/graphistry/pygraphistry,BSD-3-Clause,graph-visualization;gpu-acceleration;data-analysis
197,Koifish,C++ framework for efficient LLM training and fine-tuning,"A C++ framework designed for the efficient training and fine-tuning of Large Language Models (LLMs), offering performance optimizations for model development.",AI3;AI3-01,training_framework;fine_tuning,framework,C++,https://github.com/gruai/koifish,,Apache-2.0,llm-training;c++;fine-tuning
198,gLLM,Global balanced pipeline parallelism system for distributed LLM serving,A system for distributed Large Language Model (LLM) serving that implements global balanced pipeline parallelism and token throttling to optimize throughput and latency.,AI3;AI3-01,model_serving;pipeline_parallelism,platform,Python,https://github.com/gty111/gLLM,,Apache-2.0,llm-serving;distributed-system;pipeline-parallelism
199,BERT Pre-training,Multi-GPU BERT pre-training implementation,"A utility implementation for multi-GPU pre-training of BERT models on a single machine without requiring Horovod, facilitating model training workflows.",AI3;AI3-01,model_training;pre_training,solver,Python,https://github.com/guotong1988/BERT-pre-training,,Apache-2.0,bert;pre-training;multi-gpu
200,BERT Classifier,General text classifier based on BERT with multi-GPU support,"A general-purpose text classification tool based on BERT, supporting multi-process data processing and multi-GPU parallel training.",AI3,text_classification;model_training,solver,Python,https://github.com/guoyaohua/BERT-Classifier,,Apache-2.0,bert;text-classification;nlp
201,LvLLM,NUMA-aware extension of vLLM for efficient CPU/GPU hybrid inference,"A specialized extension of vLLM that optimizes for NUMA architectures, enabling efficient use of CPU and memory resources alongside GPUs for hybrid inference of large models, particularly MOEs.",AI3;AI3-01,inference_acceleration;hybrid_inference,platform,Python,https://github.com/guqiong96/Lvllm,,Apache-2.0,vllm;numa;inference;moe
202,H2O-3,Distributed and scalable open-source machine learning platform,"A distributed, in-memory machine learning platform that provides scalable implementations of various algorithms (GBM, GLM, Deep Learning, etc.) and AutoML capabilities for data analysis and modeling.",AI3,machine_learning_platform;automl,platform,Jupyter Notebook,https://github.com/h2oai/h2o-3,http://docs.h2o.ai,Apache-2.0,machine-learning;distributed-computing;automl
203,APPy,Annotated Parallelism for Python to GPU compiler,A framework that enables users to annotate Python loops and tensor expressions with compiler directives to automatically generate and compile optimized GPU kernels.,AI3;AI3-01,code_acceleration;compilation,library,Python,https://github.com/habanero-lab/APPy,,MIT,gpu-compilation;parallelism;python
204,XReflection,Toolbox for single-image reflection removal,"A toolbox providing state-of-the-art solutions for single-image reflection removal (SIRR), including training and inference pipelines with multi-GPU/TPU support.",AI3,image_processing;image_restoration,library,Python,https://github.com/hainuo-wang/XReflection,,None,reflection-removal;image-processing;computer-vision
205,EfficientNetV2-pytorch,PyTorch implementation of EfficientNetV2 with pretrained models,"A PyTorch implementation of the EfficientNetV2 architecture, including pretrained models, facilitating its use in computer vision tasks.",AI3,model_implementation;computer_vision,library,Python,https://github.com/hankyul2/EfficientNetV2-pytorch,,Apache-2.0,efficientnetv2;pytorch;computer-vision
206,FastVideo,Framework for accelerated video generation inference and post-training,A unified framework designed to accelerate the inference and post-training processes for video generation models.,AI3;AI3-01,video_generation;inference_acceleration,framework,Python,https://github.com/hao-ai-lab/FastVideo,,Apache-2.0,video-generation;acceleration;inference
207,HeAT,Distributed tensor and machine learning framework with GPU/MPI acceleration,"A Python framework for distributed tensor processing and machine learning, leveraging GPU and MPI acceleration to handle large-scale scientific data analysis.",AI3;AI3-01,distributed_computing;tensor_processing,framework,Python,https://github.com/helmholtz-analytics/heat,https://heat.readthedocs.io,MIT,distributed-tensors;mpi;gpu;scientific-computing
208,VodaScheduler,GPU scheduler for elastic distributed deep learning workloads,A GPU scheduler designed for Kubernetes clusters to manage elastic and distributed deep learning workloads efficiently.,AI3;AI3-01,resource_scheduling;cluster_management,platform,Go,https://github.com/heyfey/vodascheduler,,Apache-2.0,gpu-scheduler;kubernetes;distributed-training
209,Higgsfield,Fault-tolerant GPU orchestration and training framework for large-scale models,"Higgsfield is a machine learning framework and GPU orchestration platform designed for training models with billions to trillions of parameters. It focuses on fault tolerance and high scalability, enabling efficient distributed training on large clusters.",AI3;AI3-01,distributed_training;orchestration,platform,Jupyter Notebook,https://github.com/higgsfield-ai/higgsfield,,Apache-2.0,gpu-orchestration;large-model-training;fault-tolerance
210,EasyR1,Efficient multi-modality reinforcement learning training framework,"EasyR1 is a scalable and efficient reinforcement learning (RL) training framework based on veRL. It supports multi-modality training, making it suitable for complex RLHF (Reinforcement Learning from Human Feedback) tasks and large model fine-tuning.",AI3;AI3-01,reinforcement_learning;fine_tuning,framework,Python,https://github.com/hiyouga/EasyR1,,Apache-2.0,rlhf;multi-modality;verl
211,mipnerf_pl,PyTorch Lightning implementation of Mip-NeRF for 3D reconstruction,"An unofficial but widely used PyTorch Lightning implementation of Mip-NeRF, a method for high-quality 3D reconstruction and rendering from 2D images. It serves as a solver for inverse rendering tasks.",AI3;AI3-01,3d_reconstruction;rendering,solver,Python,https://github.com/hjxwhy/mipnerf_pl,,MIT,nerf;pytorch-lightning;3d-rendering
212,ptlflow,Unified interface for Optical Flow models using PyTorch Lightning,"Ptlflow is a library that provides a unified interface for various optical flow models, scripts for training and inference, and pretrained weights. It facilitates the application of optical flow estimation in scientific video analysis.",AI3;AI3-01,optical_flow;computer_vision,library,Python,https://github.com/hmorimitsu/ptlflow,https://ptlflow.readthedocs.io/,Apache-2.0,optical-flow;pytorch-lightning;motion-estimation
213,Horovod,Distributed deep learning training framework,"Horovod is a distributed deep learning training framework for TensorFlow, Keras, PyTorch, and Apache MXNet. It simplifies the process of scaling single-GPU training scripts to run across many GPUs and nodes using MPI.",AI3;AI3-01,distributed_training,framework,Python,https://github.com/horovod/horovod,https://horovod.readthedocs.io/,Apache-2.0,distributed-training;mpi;deep-learning
214,CachedEmbedding,Memory-efficient embedding solution for DLRM training,CachedEmbedding is a library designed to optimize memory usage during the training of Deep Learning Recommendation Models (DLRM). It utilizes ColossalAI to enable efficient handling of large embedding tables.,AI3;AI3-01,model_training;memory_optimization,library,Python,https://github.com/hpcaitech/CachedEmbedding,,Apache-2.0,dlrm;embedding;colossalai
215,Colossal-AI,Unified deep learning system for large-scale model training and inference,"Colossal-AI is a comprehensive system designed to make large AI models cheaper, faster, and more accessible. It provides a collection of parallel components (data, pipeline, tensor, sequence parallelism) and optimization techniques for distributed training.",AI3;AI3-01,distributed_training;large_model_optimization,framework,Python,https://github.com/hpcaitech/ColossalAI,https://colossalai.org/,Apache-2.0,distributed-system;parallelism;large-models
216,ColossalAI-Benchmark,Benchmarking suite for ColossalAI performance,"A utility tool for benchmarking the performance of models trained with ColossalAI, helping researchers and engineers evaluate training throughput and efficiency.",AI3;AI3-01,benchmarking;performance_analysis,utility,Python,https://github.com/hpcaitech/ColossalAI-Benchmark,,Apache-2.0,benchmark;performance;colossalai
217,ColossalAI-Platform-CLI,Command-line interface for ColossalAI Platform,"The official CLI tool for interacting with the ColossalAI Platform, enabling users to manage jobs, datasets, and compute resources for large-scale AI training.",AI3;AI3-01,job_management;platform_interface,utility,Python,https://github.com/hpcaitech/ColossalAI-Platform-CLI,,Apache-2.0,cli;colossalai;cloud-platform
218,Titans,Model zoo for ColossalAI,"Titans is a collection of model implementations built with ColossalAI. It serves as a model zoo library, providing ready-to-use model definitions compatible with ColossalAI's distributed training features.",AI3;AI3-01,model_definition;model_zoo,library,Python,https://github.com/hpcaitech/Titans,,Apache-2.0,model-zoo;colossalai;transformers
219,Accelerate,Library for abstracting training loops across hardware configurations,"Accelerate is a library that enables the same PyTorch code to run across any distributed configuration (single GPU, multi-GPU, TPU, MPS) without significant code changes. It handles device placement and distributed communication.",AI3;AI3-01,distributed_training;hardware_abstraction,library,Python,https://github.com/huggingface/accelerate,https://huggingface.co/docs/accelerate/,Apache-2.0,pytorch;distributed;mixed-precision
220,Nanotron,Minimalistic 3D-parallelism training library for LLMs,"Nanotron is a library designed for training Large Language Models (LLMs) using 3D parallelism (Tensor, Pipeline, and Data Parallelism). It focuses on simplicity and efficiency for scaling model training.",AI3;AI3-01,distributed_training;llm_training,library,Python,https://github.com/huggingface/nanotron,,Apache-2.0,3d-parallelism;llm;training
221,Optimum,Hardware optimization toolkit for Transformers,"Optimum is an extension of Hugging Face Transformers that provides tools for training and inference optimization on specific hardware architectures (Intel, ONNX Runtime, AWS Trainium, etc.).",AI3;AI3-01,training_optimization;inference_optimization,library,Python,https://github.com/huggingface/optimum,https://huggingface.co/docs/optimum/,Apache-2.0,hardware-acceleration;optimization;transformers
222,Transformers,State-of-the-art machine learning model library,"Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. It supports a wide range of tasks across text, vision, and audio, serving as a foundational library for AI4S modeling.",AI3;AI3-01,model_training;model_definition,library,Python,https://github.com/huggingface/transformers,https://huggingface.co/docs/transformers/,Apache-2.0,nlp;computer-vision;pretrained-models
223,Machin,Reinforcement learning library for PyTorch,"Machin is a reinforcement learning library designed for PyTorch, implementing various algorithms like DQN, DDPG, PPO, SAC, etc. It provides a framework for developing and testing RL agents.",AI3;AI3-01,reinforcement_learning,library,Python,https://github.com/iffiX/machin,https://machin.readthedocs.io/,MIT,reinforcement-learning;pytorch;rl-algorithms
224,self_supervised,PyTorch Lightning implementation of self-supervised algorithms,"A library providing implementations of various self-supervised learning algorithms (SimCLR, BYOL, SwAV, etc.) using PyTorch Lightning, facilitating representation learning research.",AI3;AI3-01,self_supervised_learning;representation_learning,library,Python,https://github.com/imbue-ai/self_supervised,,MIT,self-supervised;contrastive-learning;pytorch-lightning
225,Multipack,Distributed sampler for padding-free LLM training,"Multipack is a specialized distributed sampler designed to optimize Large Language Model (LLM) training by enabling fast, padding-free data loading, improving training efficiency.",AI3;AI3-01,data_loading;training_optimization,library,Python,https://github.com/imoneoi/multipack,,MIT,llm;data-sampler;efficiency
226,Asystem-Awex,High-performance RL training-inference synchronization framework,"A framework designed for high-performance Reinforcement Learning (RL) workflows, specifically focusing on the rapid synchronization of weights between training and inference processes.",AI3;AI3-01,reinforcement_learning;distributed_system,framework,Python,https://github.com/inclusionAI/asystem-awex,,Apache-2.0,reinforcement-learning;synchronization;inference
227,Intel MLSL,Intel Machine Learning Scaling Library,"Intel MLSL is a library providing efficient implementations of communication patterns used in deep learning, designed to scale training across multiple nodes and clusters.",AI3;AI3-01,distributed_training;communication_optimization,library,C++,https://github.com/intel/MLSL,,Apache-2.0,hpc;distributed-learning;intel
228,Intel Extension for DeepSpeed,Intel GPU (XPU) support for DeepSpeed,"An extension that enables DeepSpeed features on Intel GPU (XPU) devices, allowing for optimized distributed training on Intel hardware architectures.",AI3;AI3-01,hardware_acceleration;distributed_training,library,C++,https://github.com/intel/intel-extension-for-deepspeed,,MIT,deepspeed;intel-xpu;acceleration
229,Intel Technology Enabling for OpenShift,Full-stack AI solution for OpenShift on Intel hardware,"A comprehensive solution for provisioning and managing Intel AI accelerators and software stacks on the OpenShift platform, facilitating enterprise AI workloads like LLM training and inference.",AI3;AI3-01,infrastructure_provisioning;platform_deployment,platform,Python,https://github.com/intel/intel-technology-enabling-for-openshift,,Apache-2.0,openshift;intel;ai-infrastructure
230,IPEX-LLM,LLM inference and finetuning acceleration on Intel XPU,"IPEX-LLM is a library for accelerating local Large Language Model (LLM) inference and fine-tuning on Intel hardware (CPUs, GPUs, NPUs). It integrates with popular ecosystems like HuggingFace, vLLM, and LlamaIndex.",AI3;AI3-01,inference_acceleration;fine_tuning,library,Python,https://github.com/intel/ipex-llm,https://ipex-llm.readthedocs.io/,Apache-2.0,intel;llm;acceleration
231,Nauta,Distributed deep learning platform for Intel Xeon systems,"Nauta is a multi-user, distributed computing environment designed for running deep learning model training experiments on Intel Xeon Scalable processor-based systems using Kubernetes.",AI3;AI3-01,cluster_management;job_scheduling,platform,Python,https://github.com/intel/nauta,,Apache-2.0,kubernetes;deep-learning-platform;intel
232,DLRover,Automatic distributed deep learning system,"DLRover is an automatic distributed deep learning system that provides fault tolerance, auto-scaling, and resource optimization for training jobs on Kubernetes clusters.",AI3;AI3-01,distributed_training;resource_management,system,Python,https://github.com/intelligent-machine-learning/dlrover,https://dlrover.readthedocs.io/,Apache-2.0,distributed-training;kubernetes;auto-scaling
233,NeuralNetworks,Java deep learning library with GPU acceleration,"A Java-based library for implementing deep learning algorithms and neural networks, featuring GPU acceleration support. It serves as a solver/library for Java-based scientific computing environments.",AI3;AI3-01,model_training;deep_learning,library,Java,https://github.com/ivan-vasilev/neuralnetworks,,Unknown,java;deep-learning;gpu
234,Alpaca-LoRA-RLHF-PyTorch,Pipeline for finetuning Alpaca with LoRA and RLHF,A complete pipeline implementation for fine-tuning Alpaca-style Large Language Models using Low-Rank Adaptation (LoRA) and Reinforcement Learning with Human Feedback (RLHF) on consumer hardware.,AI3;AI3-01,fine_tuning;rlhf,workflow,Python,https://github.com/jackaduma/Alpaca-LoRA-RLHF-PyTorch,,MIT,lora;rlhf;alpaca
235,ChatGLM-LoRA-RLHF-PyTorch,Pipeline for finetuning ChatGLM with LoRA and RLHF,A complete pipeline implementation for fine-tuning ChatGLM models using LoRA and RLHF. It provides the necessary workflows to adapt ChatGLM for specific tasks using reinforcement learning.,AI3;AI3-01,fine_tuning;rlhf,workflow,Python,https://github.com/jackaduma/ChatGLM-LoRA-RLHF-PyTorch,,MIT,chatglm;lora;rlhf
236,robo-gym,Open source toolkit for Distributed Deep Reinforcement Learning on real and simulated robots,"A toolkit that enables distributed Deep Reinforcement Learning on both real and simulated robots, facilitating the development and training of robotic control policies.",AI3;AI3-01,reinforcement_learning;robotics_simulation,workflow,Python,https://github.com/jr-robotics/robo-gym,,MIT,robotics;reinforcement-learning;simulation;distributed-training
237,torch_ACA,Adaptive Checkpoint Adjoint (ACA) method for gradient estimation in neural ODEs,Implementation of the Adaptive Checkpoint Adjoint method to improve gradient estimation accuracy and memory efficiency in Neural Ordinary Differential Equations (Neural ODEs).,AI3;AI3-01,model_training;gradient_estimation,library,Python,https://github.com/juntang-zhuang/torch_ACA,,None,neural-ode;gradient-estimation;pytorch
238,pykaldi2,Speech processing toolkit based on Kaldi and PyTorch,"A toolkit for speech recognition and processing that integrates Kaldi's efficiency with PyTorch's flexibility, supporting various speech modeling tasks.",AI3;AI3-01,speech_processing;model_training,library,Python,https://github.com/jzlianglu/pykaldi2,,MIT,speech-recognition;kaldi;pytorch
239,point2vec,Self-Supervised Representation Learning on Point Clouds,"A library for self-supervised representation learning on 3D point clouds, enabling effective feature extraction for downstream 3D vision tasks.",AI3;AI3-01,representation_learning;3d_vision,library,Python,https://github.com/kabouzeid/point2vec,,MIT,point-cloud;self-supervised-learning;3d-vision
240,FlashAttention.C,Raw CUDA C implementation of Flash Attention,"A highly optimized CUDA C implementation of the Flash Attention algorithm, designed to accelerate attention mechanisms in transformer models.",AI3;AI3-01,acceleration;kernel_optimization,library,Cuda,https://github.com/kilianhae/FlashAttention.C,,None,cuda;flash-attention;optimization
241,hydra,Execution framework for multi-task model parallelism,"A framework enabling the training of large models with multi-task model parallelism, offering linear speedups for multi-GPU execution.",AI3;AI3-01,distributed_training;model_parallelism,platform,Python,https://github.com/knagrecha/hydra,,Apache-2.0,distributed-training;model-parallelism;multi-task
242,Unity_GPUNearestNeighbor,GPU-accelerated Spatial Hashing Algorithm for Unity,"An implementation of the Spatial Hashing algorithm using GPU acceleration in Unity, useful for particle simulations and neighbor search in scientific visualization or simulation.",AI3;AI3-01,simulation;spatial_analysis,library,C#,https://github.com/kodai100/Unity_GPUNearestNeighbor,,None,unity;gpu-acceleration;spatial-hashing;simulation
243,raylight,Multi-GPU distributed inference/training for ComfyUI using Ray,"Enables distributed multi-GPU capabilities in ComfyUI workflows using XDiT, XFuser, and FSDP managed by Ray, facilitating large-scale image generation or processing.",AI3;AI3-01,distributed_inference;image_generation,workflow,Python,https://github.com/komikndr/raylight,,Apache-2.0,comfyui;ray;distributed-computing;fsdp
244,perceiver-io,PyTorch implementation of Perceiver architectures,"A PyTorch implementation of Perceiver, Perceiver IO, and Perceiver AR architectures, including PyTorch Lightning scripts for distributed training.",AI3;AI3-01,model_implementation;distributed_training,library,Python,https://github.com/krasserm/perceiver-io,,Apache-2.0,perceiver;pytorch;pytorch-lightning
245,mpi-operator,Kubernetes Operator for MPI-based applications,"A Kubernetes Operator to manage MPI-based applications, essential for distributed training and HPC workloads on Kubernetes clusters.",AI3;AI3-01,distributed_training;hpc_infrastructure,platform,Go,https://github.com/kubeflow/mpi-operator,,Apache-2.0,kubernetes;mpi;distributed-training;hpc
246,kubeflow-trainer,Distributed AI Model Training on Kubernetes,A component of Kubeflow for managing distributed AI model training and fine-tuning jobs on Kubernetes infrastructure.,AI3;AI3-01,distributed_training;mlops,platform,Go,https://github.com/kubeflow/trainer,,Apache-2.0,kubeflow;kubernetes;distributed-training
247,jobset,Kubernetes native API for distributed ML training and HPC,A Kubernetes native API designed to manage distributed machine learning training and HPC workloads as a set of related jobs.,AI3;AI3-01,distributed_training;hpc_infrastructure,platform,Python,https://github.com/kubernetes-sigs/jobset,,Apache-2.0,kubernetes;hpc;distributed-ml
248,keras_multi_gpu,Multi-GPU training utility for Keras,"A utility library to enable multi-GPU training for Keras models, facilitating parallel processing.",AI3;AI3-01,distributed_training;acceleration,library,Python,https://github.com/kuixu/keras_multi_gpu,,None,keras;multi-gpu;parallel-training
249,CasMVSNet_pl,Cascade Cost Volume for Multi-View Stereo using PyTorch Lightning,"Implementation of Cascade Cost Volume for High-Resolution Multi-View Stereo (MVS) and Stereo Matching, utilizing PyTorch Lightning for training.",AI3;AI3-01,3d_reconstruction;stereo_matching,solver,Jupyter Notebook,https://github.com/kwea123/CasMVSNet_pl,,GPL-3.0,mvs;3d-reconstruction;pytorch-lightning
250,nerf_pl,NeRF implementation using PyTorch Lightning,"A PyTorch Lightning implementation of Neural Radiance Fields (NeRF) and NeRF in the Wild, facilitating 3D scene synthesis and training.",AI3;AI3-01,neural_rendering;3d_synthesis,solver,Jupyter Notebook,https://github.com/kwea123/nerf_pl,,MIT,nerf;neural-rendering;pytorch-lightning
251,ngp_pl,Instant-NGP implementation in PyTorch,"A high-performance implementation of Instant Neural Graphics Primitives (Instant-NGP) using PyTorch and CUDA, trained with PyTorch Lightning.",AI3;AI3-01,neural_rendering;acceleration,solver,Jupyter Notebook,https://github.com/kwea123/ngp_pl,,MIT,instant-ngp;nerf;cuda
252,nsff_pl,Neural Scene Flow Fields using PyTorch Lightning,Implementation of Neural Scene Flow Fields for dynamic 3D scene reconstruction and flow estimation.,AI3;AI3-01,3d_reconstruction;scene_flow,solver,Jupyter Notebook,https://github.com/kwea123/nsff_pl,,MIT,scene-flow;nerf;dynamic-scene
253,FlashAttention20,FlashAttention 2.0 implementation in PyTorch,"A PyTorch implementation of the FlashAttention 2.0 algorithm, providing accelerated attention mechanisms without complex custom CUDA kernels.",AI3;AI3-01,acceleration;model_optimization,library,Python,https://github.com/kyegomez/FlashAttention20,,MIT,flash-attention;pytorch;optimization
254,FlashAttention20Triton,Triton implementation of Flash Attention 2.0,"An implementation of Flash Attention 2.0 using OpenAI Triton, enabling high-performance attention computation on GPUs.",AI3;AI3-01,acceleration;kernel_optimization,library,Python,https://github.com/kyegomez/FlashAttention20Triton,,MIT,triton;flash-attention;gpu-acceleration
255,kymatio,Wavelet scattering transforms with GPU acceleration,"A library for computing wavelet scattering transforms in Python, featuring GPU acceleration and compatibility with major deep learning frameworks.",AI3;AI3-01,signal_processing;feature_extraction,library,Python,https://github.com/kymatio/kymatio,https://www.kymat.io/,BSD-3-Clause,wavelet-scattering;signal-processing;gpu
256,alpaca-rlhf,RLHF Fine-tuning for LLaMA based on DeepSpeed Chat,"A tool for fine-tuning LLaMA models using Reinforcement Learning with Human Feedback (RLHF), built upon the DeepSpeed Chat framework.",AI3;AI3-01,model_finetuning;rlhf,workflow,Python,https://github.com/l294265421/alpaca-rlhf,,MIT,llm;rlhf;deepspeed;finetuning
257,Chatglm_lora_multi-gpu,Multi-GPU LoRA fine-tuning for ChatGLM,"A tool for performing multi-GPU fine-tuning of ChatGLM models using LoRA and DeepSpeed, enabling efficient training of large language models.",AI3;AI3-01,model_finetuning;distributed_training,workflow,Python,https://github.com/liangwq/Chatglm_lora_multi-gpu,,None,chatglm;lora;deepspeed;multi-gpu
258,Lightning-UQ-Box,Uncertainty Quantification for Neural Networks with PyTorch Lightning,"A comprehensive library for Uncertainty Quantification (UQ) in neural networks, leveraging PyTorch and PyTorch Lightning to provide various UQ methods.",AI3;AI3-01,uncertainty_quantification;model_evaluation,library,Python,https://github.com/lightning-uq-box/lightning-uq-box,,Apache-2.0,uncertainty-quantification;pytorch-lightning;uq
259,isolation-forest,Distributed Isolation Forest implementation for Spark/Scala,"A distributed implementation of the Isolation Forest algorithm for unsupervised outlier detection on Spark, supporting scalable training and ONNX export.",AI3;AI3-01,anomaly_detection;data_analysis,library,Scala,https://github.com/linkedin/isolation-forest,,NOASSERTION,spark;isolation-forest;anomaly-detection;distributed-computing
260,Crossbow,Multi-GPU Deep Learning System for Training with Small Batch Sizes,"Crossbow is a deep learning system designed for multi-GPU training, specifically optimized for small batch sizes to improve hardware efficiency and training speed.",AI3;AI3-01,distributed_training;model_training,platform,Java,https://github.com/lsds/Crossbow,,Apache-2.0,deep-learning;distributed-systems;gpu-acceleration
261,mu_transformer,Transformer with Mu-Parameterization implemented in Jax/Flax,"A library implementing Transformers with Mu-Parameterization (Maximal Update Parameterization) in Jax/Flax, supporting Fully Sharded Data Parallel (FSDP) on TPU pods.",AI3;AI3-01,modeling;distributed_training,library,Python,https://github.com/lucaslingle/mu_transformer,,Apache-2.0,jax;flax;transformer;fsdp;tpu
262,flash-attention-jax,JAX implementation of Flash Attention,"A JAX implementation of the Flash Attention algorithm, providing memory-efficient and fast attention mechanisms for deep learning models.",AI3;AI3-01,acceleration;model_training,library,Python,https://github.com/lucidrains/flash-attention-jax,,MIT,jax;flash-attention;optimization
263,flash-cosine-sim-attention,Fused cosine similarity attention implementation,"An implementation of fused cosine similarity attention, designed in the style of Flash Attention to optimize attention mechanisms in neural networks.",AI3;AI3-01,acceleration;modeling,library,Cuda,https://github.com/lucidrains/flash-cosine-sim-attention,,MIT,attention-mechanism;cuda;optimization
264,flash-genomics-model,Long context genomics model using Flash Attention,"A deep learning model designed for genomics, leveraging long context attention modeling techniques like Flash Attention to process genomic sequences.",AI3;Bioinformatics,modeling;genomics_analysis,solver,Python,https://github.com/lucidrains/flash-genomics-model,,MIT,genomics;deep-learning;long-context
265,JaxLightning,Integration of JAX with PyTorch Lightning,"A library that enables running JAX models and operations within the PyTorch Lightning training framework, facilitating mixed-framework workflows.",AI3;AI3-01,model_training;interoperability,library,Python,https://github.com/ludwigwinkler/JaxLightning,,MIT,jax;pytorch-lightning;training-framework
266,cute-flash-attention,Flash Attention implementation using CuTe,"An implementation of the Flash Attention algorithm utilizing the CuTe layout and algebra library for CUDA C++, aimed at high-performance GPU computing.",AI3;AI3-01,acceleration;optimization,library,Cuda,https://github.com/luliyucoordinate/cute-flash-attention,,None,cuda;flash-attention;cute
267,magix,Model parallelism for Hugging Face Transformers,"A tool to enable model parallelism for Hugging Face Transformers, allowing the training and inference of large models across multiple devices.",AI3;AI3-01,distributed_training;model_parallelism,library,Python,https://github.com/luyug/magix,,None,huggingface;transformers;parallel-computing
268,llama-tune,LLaMa tuning workflow with DeepSpeed,"A workflow tool for fine-tuning LLaMa models using the Stanford Alpaca dataset, leveraging DeepSpeed and Hugging Face Transformers for efficiency.",AI3;AI3-01,fine_tuning;model_training,workflow,Python,https://github.com/lxe/llama-tune,,None,llm;fine-tuning;deepspeed
269,Elephas,Distributed Deep Learning with Keras & Spark,"Elephas is an extension of Keras, which allows you to run distributed deep learning models at scale with Apache Spark.",AI3;AI3-01,distributed_training;model_training,library,Python,https://github.com/maxpumperla/elephas,,MIT,keras;spark;distributed-deep-learning
270,torcheval,PyTorch model metrics and evaluation toolkit,A library providing a rich collection of performant PyTorch model metrics and tools to facilitate metric computation in distributed training and model evaluation.,AI3;AI3-01,model_evaluation;metrics_computation,library,Python,https://github.com/meta-pytorch/torcheval,,NOASSERTION,pytorch;metrics;evaluation
271,torchft,Fault tolerance library for PyTorch,"A library providing fault tolerance mechanisms for PyTorch distributed training, including implementations for HSDP, LocalSGD, and DiLoCo.",AI3;AI3-01,distributed_training;fault_tolerance,library,Python,https://github.com/meta-pytorch/torchft,,NOASSERTION,pytorch;fault-tolerance;distributed-training
272,CNTK,Microsoft Cognitive Toolkit for deep learning,An open-source deep-learning toolkit by Microsoft that describes neural networks as a series of computational steps via a directed graph.,AI3;AI3-01,model_training;deep_learning,platform,C++,https://github.com/microsoft/CNTK,https://docs.microsoft.com/en-us/cognitive-toolkit/,NOASSERTION,deep-learning;neural-networks;toolkit
273,DirectML,Hardware-accelerated DirectX 12 library for machine learning,"A high-performance, hardware-accelerated DirectX 12 library for machine learning, providing GPU acceleration across a broad range of hardware.",AI3;AI3-01,acceleration;inference,library,C++,https://github.com/microsoft/DirectML,,MIT,directx;machine-learning;gpu-acceleration
274,ONNX Runtime,Cross-platform ML inferencing and training accelerator,"A cross-platform, high-performance engine for machine learning inference and training, supporting models from PyTorch, TensorFlow, and other frameworks via ONNX.",AI3;AI3-01,inference;model_training;acceleration,platform,C++,https://github.com/microsoft/onnxruntime,https://onnxruntime.ai,MIT,onnx;inference;acceleration
275,WebDNN,Fast DNN execution framework for web browsers,"A framework for running deep neural networks (DNN) on web browsers with high performance, utilizing WebGPU and WebAssembly.",AI3;AI3-01,inference;web_deployment,platform,TypeScript,https://github.com/mil-tokyo/webdnn,https://mil-tokyo.github.io/webdnn/,NOASSERTION,web-browser;deep-learning;inference
276,DistriFusion,Distributed Parallel Inference for High-Resolution Diffusion Models,"A framework for distributed parallel inference of high-resolution diffusion models, enabling efficient generation across multiple devices.",AI3;AI3-01,inference;distributed_computing,platform,Python,https://github.com/mit-han-lab/distrifuser,,MIT,diffusion-models;distributed-inference;parallel-computing
277,TorchSparse,Efficient Training and Inference for Sparse Convolution,A high-performance framework for training and inference of sparse convolutional neural networks on GPUs.,AI3;AI3-01,model_training;inference;acceleration,library,Cuda,https://github.com/mit-han-lab/torchsparse,,MIT,sparse-convolution;gpu;optimization
278,LiteAttention,Optimized attention mechanism implementation over FlashAttention-3,"A lightweight and efficient implementation of attention mechanisms built on top of FlashAttention-3, designed to accelerate Transformer model training and inference.",AI3;AI3-01,model_acceleration;attention_mechanism,library,Python,https://github.com/moonmath-ai/LiteAttention,,NOASSERTION,flash-attention;transformer;optimization
279,mptorch,Mixed-precision arithmetic simulation wrapper for PyTorch,"A wrapper framework built atop PyTorch to simulate the use of custom and mixed precision arithmetic in Deep Neural Network (DNN) training and inference workloads, aiding in hardware-aware algorithm development.",AI3;AI3-01,training_simulation;mixed_precision,library,C++,https://github.com/mptorch/mptorch,,GPL-3.0,pytorch;mixed-precision;simulation
280,QuIP,Interactive environment for scientific computing and psychophysics,"An interactive environment for computing, presenting images/sequences, and general scientific computing with built-in support for psychophysical experimentation and GPU acceleration.",Scientific Computing;Psychophysics,scientific_visualization;experiment_control,platform,C,https://github.com/nasa/QuIP,,NOASSERTION,scientific-computing;psychophysics;visualization
281,distributed_rl,Distributed deep reinforcement learning library for PyTorch,"A PyTorch-based implementation of distributed deep reinforcement learning algorithms, enabling scalable training of RL agents.",AI3;AI3-01,reinforcement_learning;distributed_training,library,Python,https://github.com/neka-nat/distributed_rl,,MIT,reinforcement-learning;distributed;pytorch
282,gsplat,CUDA accelerated rasterization for Gaussian Splatting,"A library providing CUDA-accelerated rasterization for Gaussian Splatting, a technique used in 3D reconstruction and novel view synthesis research.",Computer Vision;AI3-01,rendering;3d_reconstruction,library,Cuda,https://github.com/nerfstudio-project/gsplat,https://docs.nerf.studio/,Apache-2.0,gaussian-splatting;cuda;nerf
283,Newton,GPU-accelerated physics simulation engine for robotics,"An open-source, GPU-accelerated physics simulation engine built upon NVIDIA Warp, specifically targeting roboticists and simulation researchers for generating physical data.",Robotics;Physics Simulation,physics_simulation;data_generation,solver,Python,https://github.com/newton-physics/newton,,Apache-2.0,physics-engine;robotics;simulation
284,NexRL,Framework for LLM post-training and RLHF,"An ultra-loosely-coupled framework designed for Large Language Model (LLM) post-training, including Reinforcement Learning from Human Feedback (RLHF).",AI3;AI3-01,llm_training;rlhf,framework,Python,https://github.com/nex-agi/NexRL,,Apache-2.0,llm;rlhf;post-training
285,disent,Modular VAE disentanglement framework,"A modular framework for Variational Autoencoder (VAE) disentanglement research, built with PyTorch Lightning, including metrics, datasets, and various supervision methods.",AI3;Machine Learning,representation_learning;model_training,framework,Python,https://github.com/nmichlo/disent,,MIT,vae;disentanglement;pytorch-lightning
286,flash_attn_jax,JAX bindings for Flash Attention v2,"Provides JAX bindings for Flash Attention v2, enabling high-performance attention mechanism computation in JAX-based scientific machine learning workflows.",AI3;AI3-01,model_acceleration;attention_mechanism,library,C++,https://github.com/nshepperd/flash_attn_jax,,BSD-3-Clause,jax;flash-attention;acceleration
287,DI-star,Distributed training platform for StarCraft II AI,"An artificial intelligence platform for StarCraft II enabling large-scale distributed training of grand-master agents, used in reinforcement learning research.",AI3;Game AI,reinforcement_learning;distributed_training,platform,Python,https://github.com/opendilab/DI-star,,Apache-2.0,starcraft-ii;reinforcement-learning;distributed
288,ReaLHF,Efficient RLHF training framework for LLMs,A framework for super-efficient Reinforcement Learning from Human Feedback (RLHF) training of Large Language Models (LLMs) featuring parameter reallocation techniques.,AI3;AI3-01,rlhf;llm_training,framework,Python,https://github.com/openpsi-project/ReaLHF,,Apache-2.0,rlhf;llm;optimization
289,openspeech,Open-source toolkit for end-to-end speech recognition,"A comprehensive toolkit for End-to-End Speech Recognition leveraging PyTorch-Lightning and Hydra, supporting research and development of ASR models.",AI3;Speech Processing,speech_recognition;model_training,framework,Python,https://github.com/openspeech-team/openspeech,,MIT,asr;speech-recognition;pytorch-lightning
290,EE-LLM,Framework for early-exit LLM training and inference,"A framework designed for large-scale training and inference of early-exit (EE) Large Language Models (LLMs), optimizing efficiency.",AI3;AI3-01,llm_training;inference_optimization,framework,Python,https://github.com/pan-x-c/EE-LLM,,NOASSERTION,llm;early-exit;training-framework
291,AutoDist,Distributed Deep Learning framework for TensorFlow,"A framework for simple distributed deep learning on TensorFlow, automating the distribution strategy for model training.",AI3;AI3-01,distributed_training;model_parallelism,library,Python,https://github.com/petuum/autodist,,Apache-2.0,tensorflow;distributed-learning;automation
292,metal-flash-attention,FlashAttention implementation for Apple Metal,"A port of FlashAttention to Apple's Metal API, enabling accelerated attention mechanism computation on Apple Silicon GPUs for AI research.",AI3;AI3-01,model_acceleration;attention_mechanism,library,Swift,https://github.com/philipturner/metal-flash-attention,,MIT,metal;flash-attention;apple-silicon
293,energizer,Active learning library for PyTorch,"An active learning library for PyTorch based on Lightning-Fabric, facilitating the development of active learning loops for scientific data analysis.",AI3;Machine Learning,active_learning;data_selection,library,Python,https://github.com/pietrolesci/energizer,,Apache-2.0,active-learning;pytorch;lightning-fabric
294,VINS-Fusion-gpu,GPU-accelerated VINS-Fusion for SLAM,"A GPU-accelerated version of VINS-Fusion, a Visual-Inertial State Estimator, enabling real-time SLAM on embedded devices like Nvidia TX2.",Robotics;Computer Vision,slam;state_estimation,solver,C++,https://github.com/pjrambo/VINS-Fusion-gpu,,GPL-3.0,slam;vins-fusion;gpu-acceleration
295,libdnn,Lightweight C++ library for deep neural networks with GPU acceleration,A lightweight and user-friendly C++ library designed for implementing deep and convolutional neural networks with GPU acceleration support. It provides low-level primitives for building and training neural networks efficiently.,AI3;AI3-01,model_training;acceleration,library,C++,https://github.com/poweic/libdnn,,Apache-2.0,deep-learning;gpu-acceleration;cpp;neural-networks
296,DinkyTrain,Pre-training library based on fairseq with DeepSpeed integration,"A pre-training library developed by Princeton NLP, built upon fairseq and integrated with DeepSpeed kernels. It is designed to facilitate efficient training of large language models.",AI3;AI3-01,model_training;pretraining,library,Python,https://github.com/princeton-nlp/DinkyTrain,,MIT,nlp;pre-training;deepspeed;fairseq
297,PiPPy,Pipeline Parallelism library for PyTorch,"A library that provides pipeline parallelism capabilities for PyTorch, enabling the training of large models that do not fit into a single GPU memory by splitting them across multiple devices.",AI3;AI3-01,distributed_training;pipeline_parallelism,library,Python,https://github.com/pytorch/PiPPy,,BSD-3-Clause,pytorch;pipeline-parallelism;distributed-training
298,PyTorch,Open source machine learning framework,A comprehensive open-source machine learning framework that accelerates the path from research prototyping to production deployment. It provides tensor computation with strong GPU acceleration and deep neural networks built on a tape-based autograd system.,AI3;AI3-01,model_training;deep_learning_framework,platform,Python,https://github.com/pytorch/pytorch,https://pytorch.org,NOASSERTION,deep-learning;tensor;autograd;gpu-acceleration
299,Ray,Unified framework for scaling AI and Python applications,"An open-source unified compute framework that makes it easy to scale AI and Python workloads. It provides a core distributed runtime and a set of AI libraries for accelerating ML workloads, including training, tuning, and serving.",AI3;AI3-01,distributed_computing;scaling,platform,Python,https://github.com/ray-project/ray,https://docs.ray.io,Apache-2.0,distributed-systems;scaling;machine-learning;parallel-computing
300,Ray Lightning,PyTorch Lightning Distributed Accelerators using Ray,"A library that integrates PyTorch Lightning with Ray, allowing users to leverage Ray's distributed computing capabilities for training PyTorch Lightning models across clusters.",AI3;AI3-01,distributed_training;acceleration,library,Python,https://github.com/ray-project/ray_lightning,,Apache-2.0,pytorch-lightning;ray;distributed-training
301,RobotPerf Benchmarks,Benchmarking suite for robotics computing performance,A vendor-neutral benchmarking suite designed to evaluate robotics computing performance using grey-box and black-box approaches. It helps in assessing the efficiency of hardware and software stacks for robotics and AI workloads.,AI3;AI3-01,benchmarking;performance_evaluation,solver,Python,https://github.com/robotperf/benchmarks,,Apache-2.0,robotics;benchmarking;performance;ros2
302,KubeTorch,Distributed AI workloads on Kubernetes for Python,"A tool that allows users to distribute and run AI workloads on Kubernetes clusters seamlessly using Python, acting as an infrastructure layer for ML workflows similar to PyTorch's abstraction for tensors.",AI3;AI3-01,distributed_training;infrastructure_management,platform,Python,https://github.com/run-house/kubetorch,,Apache-2.0,kubernetes;distributed-training;mlops;infrastructure
303,l2hmc-qcd,L2HMC algorithm for Lattice QCD simulations,An implementation of the L2HMC (Learn to Hamiltonian Monte Carlo) algorithm applied to simulations in Lattice Quantum Chromodynamics (QCD). It serves as a scientific simulation tool for physics research.,AI3;AI3-01,simulation;scientific_modeling,solver,Jupyter Notebook,https://github.com/saforem2/l2hmc-qcd,,Apache-2.0,lattice-qcd;physics;mcmc;generative-models
304,PMLS-Caffe,Distributed Deep Learning Framework based on Caffe,"A distributed deep learning framework designed for Parallel Machine Learning Systems (PMLS). It extends Caffe to support distributed training, enabling efficient scaling of deep learning models.",AI3;AI3-01,model_training;distributed_training,platform,C++,https://github.com/sailing-pmls/pmls-caffe,,NOASSERTION,caffe;distributed-learning;deep-learning;framework
305,GRACE,Gradient Compression for distributed deep learning,"A library for gradient compression in distributed deep learning. It aims to reduce communication overhead during distributed training by compressing gradients, thereby accelerating the training process.",AI3;AI3-01,distributed_training;gradient_compression,library,Python,https://github.com/sands-lab/grace,,BSD-2-Clause,distributed-learning;compression;optimization;gradient-compression
306,FullLLM,"Full-stack library for LLM pre-training, fine-tuning, RLHF, and inference","A comprehensive toolkit for the Large Language Model lifecycle, supporting pre-training, supervised fine-tuning (SFT), reinforcement learning from human feedback (RLHF/PPO), inference, and quantization.",AI3;AI3-01,model_training;finetuning;rlhf,framework,Python,https://github.com/schinger/FullLLM,,MIT,llm;rlhf;finetuning;quantization
307,SpecForge,Framework for training speculative decoding models,"A tool designed to effortlessly train speculative decoding models and port them to SGLang serving, optimizing inference speed for large language models.",AI3;AI3-01,model_training;acceleration;inference_optimization,solver,Python,https://github.com/sgl-project/SpecForge,,MIT,speculative-decoding;llm;inference-acceleration
308,FlashAttention-PyTorch,PyTorch implementation of FlashAttention for efficient transformer training,"A PyTorch implementation of the FlashAttention algorithm, designed to accelerate attention computation and reduce memory usage in transformer models.",AI3;AI3-01,acceleration;model_training,library,Python,https://github.com/shreyansh26/FlashAttention-PyTorch,,MIT,flash-attention;pytorch;acceleration
309,ShallowSpeed,Lightweight distributed training library for deep learning,"A small-scale distributed training library built on Numpy and MPI, designed for educational purposes and training sequential deep learning models.",AI3;AI3-01,distributed_training;model_training,library,Python,https://github.com/siboehm/ShallowSpeed,,None,distributed-training;mpi;numpy
310,gpumonitor,GPU monitoring callbacks for TensorFlow and PyTorch Lightning,A utility library providing callbacks to monitor GPU usage during model training with TensorFlow 2.x and PyTorch Lightning.,AI3;AI3-01,monitoring;resource_management,utility,Python,https://github.com/sicara/gpumonitor,,MIT,gpu-monitoring;tensorflow;pytorch-lightning
311,ArcticTraining,Framework for post-training large language models,"A framework designed by Snowflake to simplify and accelerate the post-training process (fine-tuning, alignment) for large language models.",AI3;AI3-01,model_training;finetuning,framework,Python,https://github.com/snowflakedb/ArcticTraining,,Apache-2.0,llm;post-training;finetuning
312,parallax,Automatic parallelization tool for deep learning training,A tool that automates the parallelization of deep learning training across distributed multi-GPU environments.,AI3;AI3-01,distributed_training;parallelization,tool,Python,https://github.com/snuspl/parallax,,Apache-2.0,distributed-training;multi-gpu;parallelization
313,Flash-Attention-Softmax-N,Flash Attention implementation with SoftmaxN,"CUDA and Triton implementations of Flash Attention incorporating SoftmaxN, aimed at optimizing attention mechanisms in transformer models.",AI3;AI3-01,acceleration;model_training,library,Python,https://github.com/softmax1/Flash-Attention-Softmax-N,,GPL-3.0,flash-attention;cuda;triton
314,coom,Large-scale language model training framework,"A training framework based on Megatron-Core, designed to efficiently handle extensive model training, inspired by Deepseek's HAI-LLM optimizations.",AI3;AI3-01,model_training;distributed_training,framework,Python,https://github.com/soketlabs/coom,,NOASSERTION,llm;megatron-core;distributed-training
315,llms_tool,"Tool for LLM training, testing, and quantization","A tool based on HuggingFace for training, testing, and deploying large language models, supporting pre-training, SFT, RLHF, DPO, and quantization.",AI3;AI3-01,model_training;finetuning;quantization,workflow,Python,https://github.com/stanleylsx/llms_tool,,Apache-2.0,llm;sft;rlhf;quantization
316,flash-attention-windows,Pre-built Flash Attention wheels for Windows,"Provides pre-built binary wheels for Flash Attention 2 on Windows, enabling researchers to use accelerated attention mechanisms on Windows platforms without complex build setups.",AI3;AI3-01,acceleration;environment_setup,utility,,https://github.com/sunsetcoder/flash-attention-windows,,BSD-3-Clause,flash-attention;windows;wheels
317,RLHF,Implementation of RLHF pipeline for Chinese ChatGPT,"An implementation of the Reinforcement Learning from Human Feedback (RLHF) pipeline, specifically tailored for training Chinese language models similar to ChatGPT.",AI3;AI3-01,model_training;rlhf,workflow,Python,https://github.com/sunzeyeah/RLHF,,None,rlhf;llm;chatgpt
318,mixed-precision-pytorch,Library for mixed precision training in PyTorch,A library/implementation for training deep learning models using FP16 weights (mixed precision) in PyTorch to accelerate training and reduce memory usage.,AI3;AI3-01,acceleration;model_training,library,Python,https://github.com/suvojit-0x55aa/mixed-precision-pytorch,,WTFPL,mixed-precision;fp16;pytorch
319,Silice,Hardware description language for FPGA design,"A hardware description language that simplifies designing hardware algorithms with parallelism and pipelines, useful for creating custom hardware accelerators for scientific computing.",AI3;AI3-01,hardware_design;acceleration,language,C++,https://github.com/sylefeb/Silice,,NOASSERTION,fpga;hdl;hardware-acceleration
320,deep-gradient-compression,Deep Gradient Compression for distributed training,Implementation of Deep Gradient Compression (DGC) to reduce communication bandwidth requirements during distributed training of deep learning models.,AI3;AI3-01,distributed_training;compression,library,Python,https://github.com/synxlin/deep-gradient-compression,,Apache-2.0,distributed-training;gradient-compression;bandwidth-optimization
321,pytorch-distributed,Benchmark and quickstart for PyTorch distributed training,A repository providing benchmarks and quickstart guides for setting up and evaluating distributed training environments with PyTorch.,AI3;AI3-01,distributed_training;benchmarking,utility,Python,https://github.com/tczhangzhi/pytorch-distributed,,MIT,distributed-training;pytorch;benchmark
322,Qwen2-Audio-finetune,Fine-tuning toolkit for Qwen2-Audio models,"A repository specifically designed for fine-tuning the Qwen2-Audio model, supporting Distributed Data Parallel (DDP) and DeepSpeed for efficient training.",AI3;AI3-01,model_training;finetuning,workflow,Python,https://github.com/teamtee/Qwen2-Audio-finetune,,Apache-2.0,qwen2-audio;finetuning;deepspeed
323,cube-studio,Cloud-native one-stop MLOps and AI platform,"An open-source, cloud-native machine learning platform supporting the full MLOps lifecycle, including distributed training, hyperparameter search, inference serving, and LLM fine-tuning.",AI3;AI3-01,platform;model_training;mlops,platform,Python,https://github.com/tencentmusic/cube-studio,,NOASSERTION,mlops;distributed-training;llm-platform
324,TensorDiffEq,Physics-Informed Deep Learning framework on TensorFlow,"A library for Efficient and Scalable Physics-Informed Deep Learning (PINNs) and Scientific Machine Learning built on top of TensorFlow, supporting multi-worker distributed computing.",AI3;AI3-01,scientific_modeling;pinn_solver;differential_equations,library,Python,https://github.com/tensordiffeq/TensorDiffEq,,None,physics-informed-neural-networks;scientific-machine-learning;tensorflow;distributed-computing
325,Mesh TensorFlow,Distributed deep learning library for model parallelism,"A language for distributed deep learning capable of specifying a class of distributed tensor computations, enabling model parallelism for training very large models.",AI3;AI3-01,distributed_training;model_parallelism,library,Python,https://github.com/tensorflow/mesh,,Apache-2.0,distributed-training;model-parallelism;tensorflow
326,Tensor2Tensor,Library of deep learning models and datasets,"A library of deep learning models and datasets designed to make deep learning more accessible and accelerate ML research, featuring implementations of Transformers and other architectures.",AI3;AI3-01,model_training;deep_learning_models,library,Python,https://github.com/tensorflow/tensor2tensor,,Apache-2.0,deep-learning;transformer;datasets
327,ScalarLM,Unified training and inference stack for LLMs,"A unified stack for training and inference of Large Language Models, designed to streamline the lifecycle of LLM development.",AI3;AI3-01,llm_training;inference,platform,Python,https://github.com/tensorwavecloud/ScalarLM,,NOASSERTION,llm;training-stack;inference
328,ReMoE,Fully Differentiable Mixture-of-Experts implementation,"Codebase for ReMoE (Fully Differentiable Mixture-of-Experts with ReLU Routing), built on Megatron-LM, providing a specialized architecture for efficient large model training.",AI3;AI3-01,model_training;mixture_of_experts,library,Python,https://github.com/thu-ml/ReMoE,,NOASSERTION,mixture-of-experts;megatron-lm;llm-training
329,libflash_attn,Standalone Flash Attention v2 kernel,"A standalone Flash Attention v2 kernel implementation without libtorch dependency, providing optimized attention mechanisms for transformer models.",AI3;AI3-01,acceleration;attention_kernel,library,C++,https://github.com/tlc-pack/libflash_attn,,BSD-3-Clause,flash-attention;cuda;optimization
330,keypoint-detection,2D keypoint detection solver,A tool for 2D keypoint detection utilizing PyTorch Lightning and Weights & Biases for experiment tracking.,AI3,keypoint_detection;computer_vision,solver,Python,https://github.com/tlpss/keypoint-detection,,MIT,keypoint-detection;pytorch-lightning;computer-vision
331,TonY,Deep learning framework on Apache Hadoop,"TonY is a framework to natively run deep learning frameworks (like TensorFlow and PyTorch) on Apache Hadoop, enabling distributed training on big data clusters.",AI3;AI3-01,distributed_training;resource_scheduling,platform,Java,https://github.com/tony-framework/TonY,,NOASSERTION,hadoop;distributed-deep-learning;yarn
332,go-metal,Deep learning library for Go on Apple Silicon,A high-performance deep learning library for the Go programming language that leverages Apple's Metal API for GPU acceleration on Apple Silicon devices.,AI3;AI3-01,model_training;acceleration,library,Go,https://github.com/tsawler/go-metal,,MIT,deep-learning;go;metal;gpu-acceleration
333,cuSNN,GPU-accelerated Spiking Neural Networks library,"A library for simulating Spiking Neural Networks (SNNs) in C++ with strong GPU acceleration through CUDA, suitable for neuromorphic computing research.",AI3;AI3-01,neuromorphic_computing;snn_simulation,library,Cuda,https://github.com/tudelft/cuSNN,,GPL-3.0,spiking-neural-networks;cuda;neuromorphic
334,Cekirdekler,Multi-device OpenCL kernel load balancer,"A multi-device OpenCL kernel load balancer and pipeliner API for C#, designed to distribute workloads across multiple GPUs using a shared-distributed memory model.",AI3;AI3-01,gpu_acceleration;load_balancing,library,C#,https://github.com/tugrul512bit/Cekirdekler,,GPL-3.0,opencl;load-balancing;gpu-computing
335,Petastorm,Data loading library for deep learning from Parquet,"A library enabling single machine or distributed training and evaluation of deep learning models directly from datasets in Apache Parquet format, supporting TensorFlow, PyTorch, and PySpark.",AI3;AI3-01,data_loading;distributed_training,library,Python,https://github.com/uber/petastorm,,Apache-2.0,parquet;data-loading;distributed-training
336,Detoxify,Toxic comment detection models and library,"A library providing trained models and code to predict toxic comments, useful for dataset filtering and quality control in NLP research.",AI3,text_classification;data_filtering,library,Python,https://github.com/unitaryai/detoxify,,Apache-2.0,nlp;toxicity-detection;data-cleaning
337,PipeEdge,Pipeline parallelism for edge inference,A framework for pipeline parallelism designed to enable large-scale model inference on heterogeneous edge devices.,AI3;AI3-01,distributed_inference;pipeline_parallelism,library,Python,https://github.com/usc-isi/PipeEdge,,BSD-3-Clause,edge-computing;pipeline-parallelism;inference
338,OnnxStream,Lightweight ONNX inference library,"A lightweight inference library for ONNX files written in C++, capable of running large models like Stable Diffusion and Mistral on low-resource devices.",AI3;AI3-01,model_inference;edge_computing,library,C++,https://github.com/vitoplantamura/OnnxStream,,NOASSERTION,onnx;inference;edge-ai
339,veScale,PyTorch Distributed framework for hyperscale training,"A distributed training framework based on PyTorch, optimized for hyperscale training of Large Language Models (LLMs) and Reinforcement Learning (RL).",AI3;AI3-01,distributed_training;llm_training,platform,Python,https://github.com/volcengine/veScale,,Apache-2.0,distributed-training;pytorch;llm
340,PytorchAutoDrive,Segmentation and lane detection models library,"A library providing implementations of various segmentation and lane detection models based on PyTorch, including tools for training, visualization, and benchmarking.",AI3,image_segmentation;object_detection,library,Python,https://github.com/voldemortX/pytorch-auto-drive,,BSD-3-Clause,autonomous-driving;segmentation;lane-detection
341,solo-learn,Self-supervised visual representation learning library,"A library of self-supervised methods for visual representation learning, powered by PyTorch Lightning, facilitating research in unsupervised learning.",AI3,self_supervised_learning;representation_learning,library,Python,https://github.com/vturrisi/solo-learn,,MIT,self-supervised-learning;computer-vision;pytorch-lightning
342,modelparallel_pytorch,Model parallelism library for PyTorch,A library enabling model parallelism for training multiple networks across multiple GPUs using PyTorch.,AI3;AI3-01,model_parallelism;distributed_training,library,Python,https://github.com/waitwaitforget/modelparallel_pytorch,,MIT,pytorch;model-parallelism;multi-gpu
343,llm.scala,LLM training framework in Scala,An extensible implementation of a Language Model (LLM) training framework written in Scala.,AI3;AI3-01,llm_training,library,Scala,https://github.com/wassemgtk/llm.scala,,MIT,scala;llm;training-framework
344,cutlass_flash_atten_fp8,FP8 Flash Attention kernel implementation,"An implementation of Flash Attention using FP8 precision on Ada architecture GPUs via Cutlass, serving as an acceleration kernel.",AI3;AI3-01,acceleration;attention_kernel,library,Cuda,https://github.com/weishengying/cutlass_flash_atten_fp8,,None,fp8;flash-attention;cutlass;cuda
345,TernGrad,Ternary gradients implementation for reducing communication in distributed deep learning,"An implementation of Ternary Gradients (TernGrad) to reduce communication overhead in distributed deep learning training, specifically for TensorFlow.",AI3;AI3-01,distributed_training;gradient_compression,solver,Python,https://github.com/wenwei202/terngrad,,Apache-2.0,distributed-training;gradient-compression;tensorflow
346,FlashVGGT,Efficient descriptor-based global attention acceleration for VGGT,A tool to accelerate VGGT (Visual Geometry Grounded Transformer) using efficient descriptor-based global attention mechanisms.,AI3;AI3-01,model_acceleration;attention_mechanism,solver,Python,https://github.com/wzpscott/flashvggt,,None,attention;acceleration;transformer
347,PipeGoose,Large scale 4D parallelism pre-training library for transformers,"A library for large-scale 4D parallelism pre-training of Transformer models, specifically targeting Mixture of Experts (MoE) architectures.",AI3;AI3-01,distributed_training;parallelism,library,Python,https://github.com/xrsrke/pipegoose,,MIT,distributed-training;parallelism;moe;transformers
348,CaffeOnSpark,Distributed deep learning framework on Hadoop and Spark clusters,"A framework that enables distributed deep learning on Hadoop and Spark clusters, allowing for training of deep learning models on big data infrastructure.",AI3;AI3-01,distributed_training;deep_learning,platform,C++,https://github.com/yahoo/CaffeOnSpark,,Apache-2.0,distributed-learning;spark;hadoop;caffe
349,DeDLOC,Distributed Deep Learning in Open Collaborations,"Implementation of methods for distributed deep learning in open collaborations, enabling decentralized training workflows.",AI3;AI3-01,distributed_training;decentralized_learning,solver,Jupyter Notebook,https://github.com/yandex-research/DeDLOC,,Apache-2.0,distributed-training;collaborative-learning
350,SWARM,Communication-efficient SWARM parallelism for training large models,A library implementing SWARM parallelism to enable communication-efficient training of large models across unreliable or heterogeneous devices.,AI3;AI3-01,distributed_training;parallelism,library,Python,https://github.com/yandex-research/swarm,,None,distributed-training;swarm-parallelism
351,YaFSDP,Optimized Fully Sharded Data Parallel implementation,"Yet another Fully Sharded Data Parallel (YaFSDP) implementation, providing optimized memory and communication efficiency for training large language models.",AI3;AI3-01,distributed_training;memory_optimization,library,Python,https://github.com/yandex/YaFSDP,,Apache-2.0,fsdp;distributed-training;llm
352,LLM-SFT,Framework for Supervised Fine-Tuning of Large Language Models,"A framework for Supervised Fine-Tuning (SFT) of Chinese and other Large Language Models, supporting LoRA, QLoRA, DeepSpeed, and various model architectures.",AI3;AI3-01,fine_tuning;model_training,workflow,Python,https://github.com/yongzhuo/LLM-SFT,,Apache-2.0,llm;sft;fine-tuning;lora
353,Realtime Semantic Segmentation PyTorch,PyTorch implementation of realtime semantic segmentation models,"A comprehensive library providing PyTorch implementations for over 30 realtime semantic segmentation models, supporting distributed training and knowledge distillation.",AI3,semantic_segmentation;model_implementation,library,Python,https://github.com/zh320/realtime-semantic-segmentation-pytorch,,Apache-2.0,semantic-segmentation;pytorch;computer-vision
354,yolort,Runtime stack for YOLOv5 on specialized accelerators,"A runtime stack designed to accelerate YOLOv5 inference on specialized hardware accelerators such as TensorRT, LibTorch, ONNX Runtime, TVM, and NCNN.",AI3,inference_acceleration;model_deployment,solver,Python,https://github.com/zhiqwang/yolort,,GPL-3.0,inference;acceleration;yolo;tensorrt
355,Ring Flash Attention,Ring attention implementation with Flash Attention,An implementation of Ring Attention combined with Flash Attention to enable training with extremely long context windows in a distributed setting.,AI3;AI3-01,distributed_training;attention_mechanism,library,Python,https://github.com/zhuzilin/ring-flash-attention,,MIT,flash-attention;ring-attention;distributed-training
356,KnowLM,Knowledgeable Large Language Model Framework,"An open-source framework for training and utilizing Knowledgeable Large Language Models (KnowLM), focusing on knowledge extraction and reasoning.",AI3;AI3-01,llm_training;knowledge_extraction,framework,Python,https://github.com/zjunlp/KnowLM,,MIT,llm;knowledge-graph;framework
357,LLM-Adapters,A framework for Parameter-Efficient Fine-Tuning (PEFT) of Large Language Models,"A library integrating various adapter-based methods for parameter-efficient fine-tuning of Large Language Models (LLMs), enabling researchers to fine-tune models with limited compute resources.",AI3;AI3-02,fine_tuning;peft,library,Python,https://github.com/AGI-Edgerunners/LLM-Adapters,,Apache-2.0,peft;llm;adapters;fine-tuning
358,KG_RAG,Knowledge Graph based Retrieval-Augmented Generation framework for biomedicine,"A framework designed to empower Large Language Models (LLMs) with Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG), specifically optimized for knowledge-intensive scientific tasks such as biomedical information retrieval.",AI4;AI3,knowledge_retrieval;rag;biomedical_inference,library,Jupyter Notebook,https://github.com/BaranziniLab/KG_RAG,,Apache-2.0,knowledge-graph;rag;biomedicine;llm
359,bonito,Synthetic instruction tuning dataset generator,"A lightweight library for generating synthetic instruction tuning datasets from unannotated text, facilitating the creation of domain-specific training data for aligning Large Language Models.",AI3;AI3-02,data_generation;instruction_tuning,library,Python,https://github.com/BatsResearch/bonito,,BSD-3-Clause,synthetic-data;instruction-tuning;dataset-generation
360,EmotionBench,Benchmark suite for evaluating Large Language Models' emotional alignment with humans,A benchmarking tool designed to assess the emotional alignment of Large Language Models (LLMs) with human emotional responses. It provides datasets and evaluation metrics to measure how well models understand and generate emotionally appropriate content.,AI3;AI3-02,alignment;evaluation;benchmarking,dataset,Python,https://github.com/CUHK-ARISE/EmotionBench,,GPL-3.0,llm;alignment;benchmark;emotion-recognition
361,pykoi,Unified interface for active learning and RLHF fine-tuning of LLMs,"An open-source library for training and fine-tuning Large Language Models (LLMs) using Reinforcement Learning from Human Feedback (RLHF). It provides a unified interface for active learning, model comparison, and data collection to improve model alignment.",AI3;AI3-02,rlhf;fine-tuning;active_learning,library,Jupyter Notebook,https://github.com/CambioML/pykoi-rlhf-finetuned-transformers,,Apache-2.0,rlhf;llm;fine-tuning;active-learning
362,BiPO,Bi-directional Preference Optimization for personalized steering of LLMs,Implementation of Bi-directional Preference Optimization (BiPO) for creating versatile steering vectors to personalize Large Language Models. It focuses on aligning models with specific user preferences through efficient optimization techniques.,AI3;AI3-02,alignment;preference_optimization;steering,solver,Python,https://github.com/CaoYuanpu/BiPO,,MIT,llm;alignment;preference-optimization;steering-vectors
363,MELoRA,Mini-Ensemble Low-Rank Adapter for parameter-efficient fine-tuning,"Implementation of MELoRA, a parameter-efficient fine-tuning (PEFT) method that uses a mini-ensemble of low-rank adapters to improve model performance with minimal parameter overhead. It is designed for efficient adaptation of large pre-trained models.",AI3;AI3-02,peft;fine-tuning;lora,solver,Python,https://github.com/ChasonShi/MELoRA,,Apache-2.0,peft;lora;fine-tuning;ensemble
364,TimeCMA,Cross-modality alignment for LLM-empowered time series forecasting,A framework for multivariate time series forecasting that leverages Large Language Models (LLMs) through cross-modality alignment. It aligns time series data with the semantic space of LLMs to enhance forecasting capabilities.,AI3;AI3-02,alignment;time_series_forecasting;cross_modality,solver,Python,https://github.com/ChenxiLiu-HNU/TimeCMA,,NOASSERTION,time-series;llm;alignment;forecasting
365,Subspace-Tuning,Generalized framework for subspace tuning in parameter-efficient fine-tuning,"A unified framework for subspace tuning methods in Parameter-Efficient Fine-Tuning (PEFT). It generalizes various PEFT approaches by projecting optimization into lower-dimensional subspaces, facilitating research and application of efficient tuning techniques.",AI3;AI3-02,peft;fine-tuning;subspace_learning,library,Python,https://github.com/Chongjie-Si/Subspace-Tuning,,Apache-2.0,peft;fine-tuning;subspace;llm
366,Osprey,Pixel-level visual instruction tuning for fine-grained visual understanding,"A multimodal model and training framework for pixel-level visual understanding via visual instruction tuning. It enables fine-grained alignment between visual regions and textual instructions, supporting tasks like detailed image description and region-based QA.",AI3;AI3-02,instruction_tuning;multimodal_alignment;visual_understanding,solver,Python,https://github.com/CircleRadon/Osprey,,Apache-2.0,multimodal;instruction-tuning;visual-understanding;pixel-level
367,CLAIR_and_APO,Anchored Preference Optimization for addressing underspecification in alignment,Implementation of Anchored Preference Optimization (APO) and Contrastive Revisions (CLAIR) to improve the alignment of Large Language Models. These methods address underspecification in human preferences to produce more robustly aligned models.,AI3;AI3-02,alignment;preference_optimization;rlhf,solver,Jupyter Notebook,https://github.com/ContextualAI/CLAIR_and_APO,,MIT,alignment;preference-optimization;llm;apo
368,HALOs,"Library for Human-Aware Loss Functions (DPO, KTO, PPO) in LLM alignment","A comprehensive library providing implementations of various human-aware loss functions (HALOs) such as Direct Preference Optimization (DPO), Kahneman-Tversky Optimization (KTO), and PPO. It facilitates the alignment of LLMs with human preferences.",AI3;AI3-02,alignment;loss_functions;dpo;kto,library,Python,https://github.com/ContextualAI/HALOs,,Apache-2.0,alignment;dpo;kto;loss-functions
369,GritLM,Generative Representational Instruction Tuning for unified text embedding and generation,"Implementation of Generative Representational Instruction Tuning (GRIT), a method that unifies text embedding and generative capabilities in a single Large Language Model. It enables models to handle both representation learning and instruction following tasks.",AI3;AI3-02,instruction_tuning;representation_learning;embedding,solver,Jupyter Notebook,https://github.com/ContextualAI/gritlm,,MIT,instruction-tuning;embedding;llm;representation
370,Unsloth LLaMA-3 Pipeline,Optimized 4-bit QLoRA fine-tuning pipeline for LLaMA 3,A production-grade fine-tuning pipeline leveraging Unsloth and QLoRA for efficient 4-bit training of LLaMA 3 models. It focuses on memory efficiency and speed for instruction-following specialization.,AI3;AI3-02,fine-tuning;qlora;pipeline,workflow,Jupyter Notebook,https://github.com/Cre4T3Tiv3/unsloth-llama3-alpaca-lora,,Apache-2.0,fine-tuning;qlora;llama-3;unsloth
371,LongPO,Long context self-evolution via short-to-long preference optimization,A framework for extending the context window of Large Language Models through self-evolution and preference optimization. It utilizes short-to-long preference learning to align models for long-context understanding and generation.,AI3;AI3-02,alignment;long_context;preference_optimization,solver,Python,https://github.com/DAMO-NLP-SG/LongPO,,None,long-context;alignment;preference-optimization;llm
372,Video-LLaMA,Instruction-tuned audio-visual language model for video understanding,A multi-modal framework that empowers Large Language Models with video and audio understanding capabilities through instruction tuning. It aligns visual and audio encoders with the LLM embedding space to support video-based Q&A and dialogue.,AI3;AI3-02,instruction_tuning;multimodal_alignment;video_understanding,solver,Python,https://github.com/DAMO-NLP-SG/Video-LLaMA,,BSD-3-Clause,multimodal;video-llm;instruction-tuning;alignment
373,DISTRE,Fine-tuning transformer models for distantly supervised relation extraction,A tool for fine-tuning pre-trained transformer language models specifically for the task of distantly supervised relation extraction. It adapts general-purpose models to extract semantic relations from text using distant supervision signals.,AI3;AI3-02,fine-tuning;relation_extraction;nlp,solver,Python,https://github.com/DFKI-NLP/DISTRE,,Apache-2.0,relation-extraction;fine-tuning;transformer;nlp
374,General-Visual-Quality-RL,Reinforcement learning for image quality assessment via preference optimization,"Implementation of PreResQ-R1, a method using Reinforcement Learning and Preference-Response Disentangled Policy Optimization to align models for fine-grained image quality assessment. It focuses on rank-and-score capabilities.",AI3;AI3-02,alignment;reinforcement_learning;image_quality_assessment,solver,Python,https://github.com/DanceSkyCode/General-Visual-Quality-RL,,Apache-2.0,rl;alignment;image-quality;preference-optimization
375,Docta,Data-centric AI tool for detecting data errors and improving dataset quality,"A data-centric AI tool designed to diagnose and cure data issues such as label errors and outliers. It helps improve the quality of training data, which is a critical step before model training and alignment.",AI3;AI3-02,data_quality;data_cleaning;preprocessing,solver,Python,https://github.com/Docta-ai/docta,,NOASSERTION,data-centric-ai;data-cleaning;quality-control
376,3dpose_gan,Unsupervised adversarial learning for 3D human pose estimation,Implementation of a GAN-based approach for unsupervised learning of 3D human pose from 2D joint locations. It serves as a scientific modeling tool for converting 2D visual data into 3D structural information.,AI3;AI3-02,modeling;pose_estimation;gan,solver,Python,https://github.com/DwangoMediaVillage/3dpose_gan,,MIT,3d-pose;gan;computer-vision;modeling
377,AutoPrompt,Framework for intent-based prompt calibration and tuning,A framework for prompt tuning that utilizes Intent-based Prompt Calibration to automatically optimize prompts for Large Language Models. It helps in aligning model outputs with user intent without extensive fine-tuning.,AI3;AI3-02,prompt_tuning;alignment;calibration,solver,Python,https://github.com/Eladlev/AutoPrompt,,Apache-2.0,prompt-tuning;llm;alignment;calibration
378,UVQA,Alignment framework for answerability in Video LLMs,Code and dataset for aligning Video Large Language Models to refuse unanswerable questions. It focuses on improving the reliability and safety of multimodal models by teaching them to recognize the limits of visual information.,AI3;AI3-02,alignment;multimodal;evaluation,dataset,Python,https://github.com/EsYoon7/UVQA,,None,video-llm;alignment;safety;multimodal
379,Otter,Multi-modal model for in-context learning and instruction following,"A multi-modal model based on OpenFlamingo, designed for improved instruction-following and in-context learning capabilities. It is trained on the MIMIC-IT dataset to align visual and textual understanding.",AI3;AI3-02,instruction_tuning;multimodal_alignment;in_context_learning,solver,Python,https://github.com/EvolvingLMMs-Lab/Otter,,MIT,multimodal;instruction-tuning;openflamingo;llm
380,ComfyUI_ELLA,Enhanced semantic alignment for diffusion models via LLM integration,"A ComfyUI implementation of ELLA, a method that equips diffusion models with Large Language Models to improve semantic alignment between text prompts and generated images. It serves as a tool for enhanced generative modeling.",AI3;AI3-02,alignment;generative_modeling;diffusion,solver,Python,https://github.com/ExponentialML/ComfyUI_ELLA,,Apache-2.0,diffusion;alignment;llm;comfyui
381,SplitFM,Split parameter-efficient fine-tuning and inference framework,A framework for split parameter-efficient fine-tuning (PEFT) and inference of foundation models. It enables efficient model adaptation and deployment by splitting computational loads or parameters.,AI3;AI3-02,peft;fine-tuning;inference,library,Python,https://github.com/FDU-INC/SplitFM,,None,peft;fine-tuning;foundation-models
382,Chinese-Vicuna,Chinese instruction-following LLaMA model with LoRA fine-tuning,"A low-resource solution for fine-tuning LLaMA models on Chinese instruction datasets using LoRA. It provides tools for training, inference, and deployment of Chinese-aligned LLMs.",AI3;AI3-02,instruction_tuning;lora;fine-tuning,solver,C,https://github.com/Facico/Chinese-Vicuna,,Apache-2.0,llama;lora;chinese-llm;instruction-tuning
383,GOAT-PEFT,Adaptive singular value optimization for boosting LoRA alignment,Implementation of a method to boost LoRA performance using adaptive singular values and Mixture-of-Experts optimization. It aims to improve the alignment and efficiency of parameter-efficient fine-tuning.,AI3;AI3-02,peft;lora;alignment,solver,Python,https://github.com/Facico/GOAT-PEFT,,MIT,peft;lora;alignment;optimization
384,FantasyTalking2,Timestep-layer adaptive preference optimization for audio-driven animation,A framework for audio-driven portrait animation that utilizes timestep-layer adaptive preference optimization. It aligns generated animations with audio inputs using advanced preference learning techniques.,AI3;AI3-02,alignment;preference_optimization;generative_modeling,solver,,https://github.com/Fantasy-AMAP/fantasy-talking2,,None,alignment;audio-driven;animation;preference-optimization
385,GPS,Gradient-based parameter selection for efficient fine-tuning,"A method for selecting the most important parameters for fine-tuning based on gradients. It optimizes the fine-tuning process by focusing on a subset of parameters, enhancing efficiency.",AI3;AI3-02,peft;fine-tuning;parameter_selection,solver,Python,https://github.com/FightingFighting/GPS,,MIT,peft;fine-tuning;gradient-based;efficiency
386,MultilingualSIFT,Multilingual supervised instruction fine-tuning framework,"A framework for multilingual supervised instruction fine-tuning (SIFT) of large language models, enabling adaptation to multiple languages.",AI3;AI3-02,instruction_tuning;fine_tuning,workflow,Python,https://github.com/FreedomIntelligence/MultilingualSIFT,,Apache-2.0,sift;multilingual;llm-training
387,Diffusion-NPO,Negative Preference Optimization for diffusion model alignment,Implementation of Negative Preference Optimization (NPO) to align diffusion models with human preferences by minimizing the likelihood of generating negative samples.,AI3;AI3-02,alignment;preference_optimization,solver,Jupyter Notebook,https://github.com/G-U-N/Diffusion-NPO,,Apache-2.0,diffusion-models;alignment;npo
388,vlm-grpo,GRPO implementation for Vision-Language Model training,An implementation of the GRPO (Group Relative Policy Optimization) algorithm specifically designed for training Vision-Language Models (VLMs) within the Unsloth framework.,AI3;AI3-02,fine_tuning;reinforcement_learning,solver,Python,https://github.com/GAD-cell/vlm-grpo,,None,vlm;grpo;unsloth
389,IISAN,Efficient multimodal foundation model adaptation method,"Implementation of IISAN for efficient adaptation of multimodal foundation models, specifically targeting recommendation systems.",AI3;AI3-02,model_adaptation;fine_tuning,solver,Python,https://github.com/GAIR-Lab/IISAN,,None,multimodal;recommendation;adaptation
390,ChapTER,Contrastive historical modeling with prefix-tuning for temporal KGs,A tool for temporal knowledge graph reasoning using contrastive historical modeling and prefix-tuning techniques.,AI3;AI3-02,prefix_tuning;knowledge_graph_reasoning,solver,Python,https://github.com/GKNL/ChapTER,,None,temporal-knowledge-graph;prefix-tuning;reasoning
391,FineSSL,Fine-tuning foundation models for semi-supervised learning,Implementation of a method to erase bias and fine-tune foundation models specifically for semi-supervised learning tasks.,AI3;AI3-02,fine_tuning;semi_supervised_learning,solver,Python,https://github.com/Gank0078/FineSSL,,None,ssl;bias-mitigation;foundation-models
392,Beyond-Log-Likelihood,Alternative objectives for supervised fine-tuning,Explores and implements alternative objective functions beyond log-likelihood for the supervised fine-tuning of language models.,AI3;AI3-02,fine_tuning;objective_optimization,solver,Python,https://github.com/GaotangLi/Beyond-Log-Likelihood,,Apache-2.0,sft;loss-functions;llm
393,ScoreFlow,Score-based preference optimization for LLM agent workflows,A framework for optimizing LLM agent workflows using score-based preference optimization techniques to master complex tasks.,AI3;AI3-02,preference_optimization;agent_tuning,workflow,Python,https://github.com/Gen-Verse/ScoreFlow,,None,llm-agent;preference-optimization;workflow
394,dLLM-RL,Reinforcement learning framework for Diffusion LLMs,"TraceRL and TraDo-8B implementation, providing a reinforcement learning framework specifically tailored for Diffusion Large Language Models.",AI3;AI3-02,reinforcement_learning;fine_tuning,library,Python,https://github.com/Gen-Verse/dLLM-RL,,Apache-2.0,diffusion-llm;rlhf;reinforcement-learning
395,cognify,Auto-tuning tool for AI agents and workflows,"A tool for automatically optimizing LangChain, LangGraph, and DSPy programs to improve quality, latency, and cost of AI agent workflows.",AI3;AI3-02,workflow_optimization;auto_tuning,workflow,Python,https://github.com/GenseeAI/cognify,,Apache-2.0,agent-optimization;langchain;dspy
396,mlx-lm-lora,LoRA fine-tuning for LLMs on Apple MLX,A library for training and fine-tuning Large Language Models using LoRA on Apple Silicon via the MLX framework.,AI3;AI3-02,fine_tuning;lora,library,Python,https://github.com/Goekdeniz-Guelmez/mlx-lm-lora,,Apache-2.0,mlx;lora;apple-silicon
397,PiSSA,Principal Singular Values and Singular Vectors Adaptation for LLMs,"Implementation of PiSSA, a parameter-efficient fine-tuning method that adapts principal singular values and vectors of Large Language Models.",AI3;AI3-02,peft;fine_tuning,solver,Jupyter Notebook,https://github.com/GraphPKU/PiSSA,,None,peft;svd;llm-adaptation
398,ffrecord,High-performance file format for DL training samples,FireFlyer Record (ffrecord) is a file format and library designed for efficient reading and writing of deep learning training samples.,AI3,data_io;training_infrastructure,library,Python,https://github.com/HFAiLab/ffrecord,,MIT,data-format;io;deep-learning
399,GraphGPT,Graph instruction tuning for Large Language Models,"A framework for graph instruction tuning, enabling Large Language Models to understand and process graph-structured data.",AI3;AI3-02,instruction_tuning;graph_learning,solver,Python,https://github.com/HKUDS/GraphGPT,,Apache-2.0,graph-neural-networks;instruction-tuning;llm
400,UrbanGPT,Spatio-temporal Large Language Models,"A model and toolkit for spatio-temporal prediction tasks using Large Language Models, tailored for urban computing scenarios.",AI3,spatio_temporal_modeling;scientific_modeling,solver,Python,https://github.com/HKUDS/UrbanGPT,,Apache-2.0,urban-computing;spatio-temporal;llm
401,swarmlib,Library for swarm optimization algorithms,"A library implementing various swarm optimization algorithms including Particle Swarm Optimization, Firefly Algorithm, and Ant Colony Optimization.",AI3,optimization;scientific_computing,library,Python,https://github.com/HaaLeo/swarmlib,https://swarmlib.readthedocs.io/,BSD-3-Clause,optimization;swarm-intelligence;algorithms
402,transformers_tasks,Collection of NLP task implementations with Transformers,"A comprehensive library of scripts and implementations for various NLP tasks (classification, generation, extraction, RLHF, SFT) using the Transformers library.",AI3;AI3-02,fine_tuning;rlhf;nlp_tasks,library,Jupyter Notebook,https://github.com/HarderThenHarder/transformers_tasks,,None,nlp;transformers;rlhf
403,VistaDPO,Video hierarchical spatial-temporal Direct Preference Optimization,Implementation of VistaDPO for aligning large video models using hierarchical spatial-temporal direct preference optimization.,AI3;AI3-02,alignment;dpo;video_generation,solver,Python,https://github.com/HaroldChen19/VistaDPO,,None,video-models;dpo;alignment
404,HugNLP,Unified NLP library based on HuggingFace Transformers,"A comprehensive NLP library designed to simplify the development and training of NLP models, built on top of HuggingFace Transformers.",AI3;AI3-02,fine_tuning;model_training,library,Python,https://github.com/HugAILab/HugNLP,,Apache-2.0,nlp;transformers;framework
405,DiffuseKronA,Parameter efficient fine-tuning for personalized diffusion models,A parameter-efficient fine-tuning method (KronA) specifically designed for personalizing diffusion models.,AI3;AI3-02,peft;diffusion_personalization,solver,Python,https://github.com/IBM/DiffuseKronA,,Apache-2.0,diffusion;peft;personalization
406,VTAGML,Vision Transformer Adapters for generalizable multitask learning,Implementation of adapters for Vision Transformers to enable generalizable multitask learning.,AI3;AI3-02,peft;multitask_learning,solver,Python,https://github.com/IVRL/VTAGML,,MIT,vision-transformer;adapters;multitask-learning
407,rulm,Russian language modeling and instruction tuning toolkit,"A toolkit for language modeling and instruction tuning specifically for the Russian language, including datasets and training scripts.",AI3;AI3-02,instruction_tuning;language_modeling,workflow,Jupyter Notebook,https://github.com/IlyaGusev/rulm,,Apache-2.0,russian-nlp;instruction-tuning;llm
408,GPT-4-LLM,Instruction tuning data generation with GPT-4,A workflow and dataset collection for using GPT-4 to generate instruction-following data for fine-tuning LLMs.,AI3;AI3-02,data_synthesis;instruction_tuning,workflow,HTML,https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM,,Apache-2.0,instruction-tuning;synthetic-data;gpt-4
409,Condor,Knowledge-driven data synthesis for LLM alignment,A tool to enhance LLM alignment through knowledge-driven data synthesis and refinement.,AI3;AI3-02,alignment;data_synthesis,solver,,https://github.com/InternLM/Condor,,Apache-2.0,alignment;synthetic-data;llm
410,InternLM,Comprehensive Large Language Model training and inference suite,"The official codebase for the InternLM series, providing a complete toolchain for pre-training, fine-tuning, and deploying large language models.",AI3;AI3-02,model_training;fine_tuning,platform,Python,https://github.com/InternLM/InternLM,https://internlm.intern-ai.org.cn/,Apache-2.0,llm;training-framework;internlm
411,InternLM-XComposer,Multimodal LLM system for advanced interactions,"A comprehensive multimodal system based on InternLM for long-term streaming video and audio interactions, including training and inference tools.",AI3;AI3-02,multimodal_training;fine_tuning,solver,Python,https://github.com/InternLM/InternLM-XComposer,,Apache-2.0,multimodal;vlm;internlm
412,xtuner,High-efficiency fine-tuning toolkit for LLMs,"A next-generation training engine designed for efficient fine-tuning of Large Language Models, supporting various PEFT methods and ultra-large MoE models.",AI3;AI3-02,fine_tuning;peft,library,Python,https://github.com/InternLM/xtuner,https://xtuner.readthedocs.io/,Apache-2.0,fine-tuning;peft;lora
413,GraphGen,Knowledge-driven synthetic data generation for SFT,A tool for enhancing Supervised Fine-Tuning (SFT) of LLMs by generating knowledge-driven synthetic data.,AI3;AI3-02,data_synthesis;fine_tuning,solver,Python,https://github.com/InternScience/GraphGen,,Apache-2.0,synthetic-data;sft;knowledge-graph
414,DreamArtist-stable-diffusion,Stable Diffusion webui extension for contrastive prompt tuning,"A Stable Diffusion WebUI extension that implements the DreamArtist algorithm for contrastive prompt tuning, allowing for high-quality style and object learning with parameter efficiency.",AI3;AI3-02,parameter_efficient_fine_tuning;generative_model_tuning,library,Python,https://github.com/IrisRainbowNeko/DreamArtist-stable-diffusion,,None,stable-diffusion;prompt-tuning;peft
415,Point-PEFT,Parameter-Efficient Fine-Tuning for 3D Pre-trained Models,"Implementation of Point-PEFT (AAAI 2024), a method for parameter-efficient fine-tuning specifically designed for 3D pre-trained models, enabling adaptation to downstream 3D tasks with minimal trainable parameters.",AI3;AI3-02,parameter_efficient_fine_tuning;3d_modeling,solver,Python,https://github.com/Ivan-Tang-3D/Point-PEFT,,None,3d-deep-learning;peft;aaai-2024
416,MiniHF,"Local tool for inference, human preference data collection, and fine-tuning","A comprehensive tool for local language model development, facilitating inference, collection of human preference data (RLHF), and fine-tuning workflows to develop prompts into full models.",AI3;AI3-02,rlhf_data_collection;fine_tuning;inference,workflow,Python,https://github.com/JD-P/minihf,,Apache-2.0,rlhf;fine-tuning;data-collection
417,AMoPO,Adaptive Multi-objective Preference Optimization for LLMs,"Implementation of AMoPO, an alignment algorithm that performs adaptive multi-objective preference optimization without requiring reward models or reference models.",AI3;AI3-02,alignment;preference_optimization,solver,Python,https://github.com/Javkonline/AMoPO,,Apache-2.0,dpo;alignment;llm
418,InPO,Inversion Preference Optimization for Diffusion Model Alignment,"Implementation of InPO (CVPR 2025), a method for efficient diffusion model alignment using inversion preference optimization with reparametrized DDIM.",AI3;AI3-02,alignment;diffusion_model_tuning,solver,Python,https://github.com/JaydenLyh/InPO,,Apache-2.0,diffusion-models;alignment;cvpr-2025
419,AIDoctor,"Medical GPT model training pipeline including SFT, RLHF, and DPO","A complete training pipeline for medical domain LLMs, implementing Pretraining, Supervised Fine-tuning (SFT), Reward Modeling, Reinforcement Learning (RLHF), and Direct Preference Optimization (DPO).",AI3;AI3-02,domain_adaptation;rlhf;sft,workflow,Python,https://github.com/Jerry-XDL/AIDoctor,,Apache-2.0,medical-llm;rlhf;dpo
420,LLM-RLHF-Tuning,"LLM Tuning pipeline with PEFT, SFT, RM, PPO, and DPO","A comprehensive library for Large Language Model tuning, integrating Parameter-Efficient Fine-Tuning (PEFT) with LoRA, Supervised Fine-Tuning (SFT), Reward Modeling, PPO, and DPO algorithms.",AI3;AI3-02,rlhf;peft;fine_tuning,library,Python,https://github.com/Joyce94/LLM-RLHF-Tuning,,None,rlhf;lora;ppo
421,VPT,Visual Prompt Tuning for vision models,"Implementation of Visual Prompt Tuning (ECCV 2022), a parameter-efficient fine-tuning method for large-scale vision models.",AI3;AI3-02,visual_prompt_tuning;peft,solver,Python,https://github.com/KMnP/vpt,,NOASSERTION,computer-vision;prompt-tuning;eccv-2022
422,Kiln,Platform for building AI systems with fine-tuning and synthetic data,"A development platform for building AI systems that integrates evaluations, RAG, agents, fine-tuning, and synthetic data generation workflows.",AI3;AI3-02,fine_tuning;synthetic_data_generation;evaluation,platform,Python,https://github.com/Kiln-AI/Kiln,,NOASSERTION,fine-tuning;synthetic-data;rag
423,Time-LLM,Time Series Forecasting by Reprogramming Large Language Models,"Official implementation of Time-LLM (ICLR 2024), a framework for reprogramming large language models to perform time series forecasting tasks.",AI3,time_series_forecasting;model_reprogramming,solver,Python,https://github.com/KimMeen/Time-LLM,,Apache-2.0,time-series;llm;iclr-2024
424,LyCORIS,Parameter-efficient fine-tuning library for Stable Diffusion,"A library implementing various parameter-efficient fine-tuning methods (LoRA, LoCon, LoHa, etc.) specifically optimized for Stable Diffusion and other generative models.",AI3;AI3-02,parameter_efficient_fine_tuning;generative_model_tuning,library,Python,https://github.com/KohakuBlueleaf/LyCORIS,,Apache-2.0,lora;stable-diffusion;peft
425,LPO,Latent Preference Optimization for Diffusion Models,"Implementation of Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level Preference Optimization, enabling alignment of diffusion models.",AI3;AI3-02,alignment;preference_optimization,solver,Python,https://github.com/Kwai-Kolors/LPO,,MIT,diffusion-models;alignment;rlhf
426,MM-RLHF,Multimodal LLM Alignment Framework,"A framework for multimodal large language model alignment, implementing RLHF techniques adapted for multimodal contexts.",AI3;AI3-02,alignment;multimodal_learning;rlhf,library,Python,https://github.com/Kwai-YuanQi/MM-RLHF,,Apache-2.0,multimodal;rlhf;alignment
427,Open-Assistant,Open source chat-based assistant and data collection platform,"A massive open-source project providing tools for data collection, RLHF, and training of chat-based AI assistants.",AI3;AI3-02,data_collection;rlhf;model_training,platform,Python,https://github.com/LAION-AI/Open-Assistant,https://open-assistant.io/,Apache-2.0,rlhf;chatbot;open-source
428,CHiP,Cross-modal Hierarchical Direct Preference Optimization,"Implementation of CHiP (ICLR 2025), a method for cross-modal hierarchical direct preference optimization for aligning multimodal LLMs.",AI3;AI3-02,alignment;dpo;multimodal_learning,solver,Python,https://github.com/LVUGAI/CHiP,,Apache-2.0,dpo;multimodal;iclr-2025
429,BELLE,Open-source Chinese dialogue model engine and training codebase,"An open-source project for Chinese dialogue large language models, providing training code, data, and model checkpoints for instruction tuning and alignment.",AI3;AI3-02,instruction_tuning;model_training,solver,HTML,https://github.com/LianjiaTech/BELLE,,Apache-2.0,llm;chinese-nlp;instruction-tuning
430,Lit-LLaMA,Implementation of LLaMA for pre-training and fine-tuning,"A clean, hackable implementation of the LLaMA language model, supporting pre-training, fine-tuning (LoRA, Adapter), and quantization.",AI3;AI3-02,pre_training;fine_tuning;peft,library,Python,https://github.com/Lightning-AI/lit-llama,,Apache-2.0,llama;fine-tuning;lora
431,APO,Adversarial Preference Optimization for LLM alignment,"Implementation of Adversarial Preference Optimization (ACL 2024), a method for aligning large language models using adversarial training techniques.",AI3;AI3-02,alignment;preference_optimization,solver,Python,https://github.com/Linear95/APO,,Apache-2.0,alignment;acl-2024;adversarial-training
432,CTune-MLX,Fine-tuning tool for Apple Silicon (MLX),"A fine-tuning tool based on the MLX framework, designed to enable efficient model tuning on Apple Silicon devices.",AI3;AI3-02,fine_tuning;on_device_training,solver,Shell,https://github.com/Lt2023/CTune-MLX,,NOASSERTION,mlx;fine-tuning;apple-silicon
433,DGPO,Direct Group Preference Optimization for Diffusion Models,"Implementation of Direct Group Preference Optimization for reinforcing diffusion models, enabling efficient alignment with human preferences.",AI3;AI3-02,alignment;diffusion_model_tuning,solver,,https://github.com/Luo-Yihong/DGPO,,None,diffusion-models;alignment;rl
434,Genome_Factory,"Library for Tuning, Deploying and Interpreting Genomic Models","An integrated library designed for the development, fine-tuning, deployment, and interpretation of deep learning models in genomics.",AI3;AI3-02,genomics_modeling;fine_tuning;interpretation,library,Python,https://github.com/MAGICS-LAB/Genome_Factory,,None,genomics;bioinformatics;deep-learning
435,DPO-Shift,Shifting the Distribution of Direct Preference Optimization,"Implementation of DPO-Shift, an algorithm that improves Direct Preference Optimization by shifting the distribution of preference data.",AI3;AI3-02,alignment;dpo,solver,Python,https://github.com/Meaquadddd/DPO-Shift,,None,dpo;alignment;llm
436,SAN,Open-vocabulary Semantic Segmentation,"Implementation of Side Adapter Network (SAN) for open-vocabulary semantic segmentation, allowing models to segment objects based on arbitrary text descriptions.",AI3,semantic_segmentation;computer_vision,solver,Python,https://github.com/MendelXu/SAN,,MIT,semantic-segmentation;open-vocabulary;vision
437,Shimmy,Rust inference server for GGUF/SafeTensors models,"A high-performance, Python-free inference server written in Rust, supporting GGUF and SafeTensors models with OpenAI-API compatibility.",AI3,inference;model_serving,service,Rust,https://github.com/Michael-A-Kuykendall/shimmy,,MIT,inference-server;rust;gguf
438,VLA0-TRL,Reimplementation of VLA-0 using TRL,An unofficial reimplementation of the VLA-0 (Vision-Language-Action) model training using the TRL (Transformer Reinforcement Learning) library.,AI3;AI3-02,robotics;fine_tuning;vla,solver,Python,https://github.com/MilkClouds/vla0-trl,,None,robotics;trl;vla
439,GPTQModel,LLM model quantization toolkit with hardware acceleration,"A toolkit for LLM model quantization (compression) supporting hardware acceleration for Nvidia CUDA, AMD ROCm, and Intel XPU, facilitating efficient model deployment.",AI3,quantization;model_compression,library,Python,https://github.com/ModelCloud/GPTQModel,,NOASSERTION,quantization;gptq;model-compression
440,NExT-GPT,Any-to-Any Multimodal Large Language Model,"Code and models for NExT-GPT (ICML 2024), an any-to-any multimodal large language model capable of processing and generating various modalities.",AI3,multimodal_learning;model_training,solver,Python,https://github.com/NExT-GPT/NExT-GPT,https://next-gpt.github.io/,BSD-3-Clause,multimodal-llm;icml-2024;generative-ai
441,MAPO,Multilingual alignment-as-preference optimization implementation,An implementation of the MAPO algorithm designed to advance multilingual reasoning capabilities in large language models through preference optimization techniques.,AI3;AI3-02,alignment;preference_optimization,solver,Python,https://github.com/NJUNLP/MAPO,,None,multilingual;alignment;dpo;reasoning
442,DoRA,Weight-decomposed low-rank adaptation for parameter-efficient fine-tuning,"The official PyTorch implementation of DoRA, a PEFT method that decomposes weights into magnitude and direction components to improve fine-tuning performance and stability.",AI3;AI3-02,peft;model_adaptation,solver,Python,https://github.com/NVlabs/DoRA,,NOASSERTION,peft;lora;weight-decomposition;fine-tuning
443,catk,Closed-loop supervised fine-tuning toolkit for traffic models,"A toolkit for the closed-loop supervised fine-tuning of tokenized traffic models, enabling the generation and refinement of realistic traffic simulations.",AI3;AI3-02,fine_tuning;simulation_modeling,solver,Python,https://github.com/NVlabs/catk,,NOASSERTION,traffic-simulation;sft;closed-loop
444,OneTrainer,Comprehensive training platform for Stable Diffusion models,"A one-stop GUI and backend solution for training Stable Diffusion models, supporting various fine-tuning methods like LoRA and embeddings for generative modeling.",AI3;AI3-02,model_training;image_synthesis,platform,Python,https://github.com/Nerogar/OneTrainer,,AGPL-3.0,stable-diffusion;training-gui;lora
445,Vision-LLM-Alignment,Alignment toolkit for vision-based Large Language Models,"A codebase providing SFT, RLHF, and DPO implementations specifically designed for aligning vision-based LLMs such as LLaVA and LLaMA-Vision.",AI3;AI3-02,alignment;multimodal_learning,solver,Python,https://github.com/NiuTrans/Vision-LLM-Alignment,,None,vllm;dpo;rlhf;sft
446,InsTag,Data analysis tool for LLM supervised fine-tuning,"A tool designed to analyze and tag data used in Large Language Model supervised fine-tuning, helping researchers understand data distribution and quality.",AI3;AI3-02,data_analysis;data_tagging,solver,Python,https://github.com/OFA-Sys/InsTag,,None,sft;data-analysis;instruction-tuning
447,OFA,Unified sequence-to-sequence framework for multimodal tasks,"A framework unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning paradigm, supporting pretraining and fine-tuning.",AI3;AI3-02,multimodal_learning;model_training,library,Python,https://github.com/OFA-Sys/OFA,,Apache-2.0,multimodal;seq2seq;unified-architecture
448,Unlearn-Simple,Negative preference optimization for LLM unlearning,An implementation of negative preference optimization techniques designed for efficient and effective unlearning in Large Language Models.,AI3;AI3-02,unlearning;alignment,solver,Python,https://github.com/OPTML-Group/Unlearn-Simple,,MIT,unlearning;preference-optimization;safety
449,ViT_PEFT_Vision,Parameter-efficient fine-tuning library for Vision Transformers,A codebase providing implementations and insights for applying Parameter-Efficient Fine-Tuning (PEFT) methods specifically to Vision Transformers (ViT) in visual recognition tasks.,AI3;AI3-02,peft;computer_vision,solver,Jupyter Notebook,https://github.com/OSU-MLB/ViT_PEFT_Vision,,None,vit;peft;visual-recognition
450,InternVideo,Video foundation models for multimodal understanding,"A comprehensive library containing video foundation models and tools for multimodal video understanding, supporting various downstream tasks.",AI3;AI3-02,video_understanding;multimodal_modeling,library,Python,https://github.com/OpenGVLab/InternVideo,,Apache-2.0,video-foundation-model;multimodal;computer-vision
451,LLaMA-Adapter,Efficient fine-tuning method for LLaMA models,"An implementation of LLaMA-Adapter, a lightweight adaptation method for fine-tuning LLaMA models to follow instructions with minimal parameter overhead.",AI3;AI3-02,peft;instruction_tuning,solver,Python,https://github.com/OpenGVLab/LLaMA-Adapter,,GPL-3.0,adapter;llama;efficient-tuning
452,TPO,Task preference optimization for multimodal LLMs,"A tool for Task Preference Optimization, designed to improve Multimodal Large Language Models by aligning them with vision tasks.",AI3;AI3-02,alignment;multimodal_optimization,solver,Jupyter Notebook,https://github.com/OpenGVLab/TPO,,None,preference-optimization;mllm;vision-alignment
453,MOSS-RLHF,PPO-based RLHF implementation for LLMs,"A codebase revealing the implementation details of Reinforcement Learning from Human Feedback (RLHF), specifically focusing on the PPO algorithm for large language models.",AI3;AI3-02,rlhf;alignment,solver,Python,https://github.com/OpenLMLab/MOSS-RLHF,,Apache-2.0,ppo;rlhf;alignment
454,ART,Agent Reinforcement Trainer for multi-step tasks,A reinforcement learning training framework (Agent Reinforcement Trainer) designed for training multi-step agents using GRPO on models like Qwen and Llama.,AI3;AI3-02,reinforcement_learning;agent_training,library,Python,https://github.com/OpenPipe/ART,,Apache-2.0,grpo;agent-training;rl
455,OpenPipe,Platform for converting prompts into fine-tuned models,A developer tool and platform that facilitates the collection of prompt data and the creation of fine-tuned models to optimize cost and latency.,AI3;AI3-02,fine_tuning;model_distillation,platform,TypeScript,https://github.com/OpenPipe/OpenPipe,https://openpipe.ai,Apache-2.0,fine-tuning;distillation;prompt-engineering
456,OpenRLHF,Scalable and high-performance RLHF framework,"An easy-to-use, scalable, and high-performance framework for Reinforcement Learning from Human Feedback (RLHF), built on Ray and supporting PPO, GRPO, and other algorithms.",AI3;AI3-02,rlhf;alignment,library,Python,https://github.com/OpenRLHF/OpenRLHF,,Apache-2.0,rlhf;ray;ppo;distributed-training
457,align-anything,Framework for training all-modality models with feedback,"A comprehensive framework for aligning models across various modalities (text, image, video, audio) using feedback mechanisms.",AI3;AI3-02,alignment;multimodal_learning,library,Python,https://github.com/PKU-Alignment/align-anything,,Apache-2.0,alignment;multimodal;feedback-learning
458,safe-rlhf,Constrained value alignment via safe RLHF,"A library implementing Safe RLHF, which decouples helpfulness and harmlessness training to achieve constrained value alignment in large language models.",AI3;AI3-02,rlhf;safety_alignment,solver,Python,https://github.com/PKU-Alignment/safe-rlhf,,Apache-2.0,safety;rlhf;alignment
459,Video-LLaVA,Unified visual representation learning by alignment,"An implementation of Video-LLaVA that learns united visual representations for images and videos through alignment before projection, enhancing multimodal understanding.",AI3;AI3-02,multimodal_alignment;video_understanding,solver,Python,https://github.com/PKU-YuanGroup/Video-LLaVA,,Apache-2.0,video-llm;alignment;multimodal
460,UniPT,Universal parallel tuning for transfer learning,"A tool implementing Universal Parallel Tuning (UniPT), designed for efficient parameter and memory usage during transfer learning across various modalities.",AI3;AI3-02,transfer_learning;peft,solver,Python,https://github.com/Paranioar/UniPT,,Apache-2.0,parallel-tuning;transfer-learning;efficiency
461,Alpaca-CoT,Unified interface for instruction tuning and PEFT,"A platform that unifies interfaces for instruction-tuning data (including CoT), multiple LLMs, and parameter-efficient fine-tuning methods to facilitate research.",AI3;AI3-02,instruction_tuning;peft,platform,Jupyter Notebook,https://github.com/PhoebusSi/Alpaca-CoT,,Apache-2.0,instruction-tuning;cot;peft
462,tabpfn-time-series,Zero-shot time series forecasting with TabPFN,"An extension of TabPFN specifically designed for zero-shot time series forecasting, enabling high-quality predictions without task-specific training.",AI3;AI3-02,time_series_forecasting;zero_shot_learning,solver,Jupyter Notebook,https://github.com/PriorLabs/tabpfn-time-series,,Apache-2.0,time-series;forecasting;tabpfn
463,AdaLoRA,Adaptive budget allocation for PEFT,"The official implementation of AdaLoRA, a parameter-efficient fine-tuning method that adaptively allocates parameter budgets based on importance.",AI3;AI3-02,peft;model_compression,solver,Python,https://github.com/QingruZhang/AdaLoRA,,MIT,peft;lora;adaptive-tuning
464,RLHF-V,Behavior alignment for multimodal LLMs via RLHF,A tool for aligning Multimodal Large Language Models (MLLMs) using fine-grained correctional human feedback to improve trustworthiness and reduce hallucinations.,AI3;AI3-02,rlhf;multimodal_alignment,solver,Python,https://github.com/RLHF-V/RLHF-V,,None,rlhf;mllm;alignment
465,Directional-Preference-Alignment,Directional preference alignment for LLMs,"An implementation of Directional Preference Alignment, a method to align language models with user preferences by considering the direction of improvement.",AI3;AI3-02,alignment;preference_optimization,solver,,https://github.com/RLHFlow/Directional-Preference-Alignment,,Apache-2.0,dpo;alignment;preference-learning
466,Online-DPO-R1,Iterative DPO using rule-based rewards,"A codebase for Online Direct Preference Optimization (DPO), facilitating iterative alignment of models using rule-based reward systems.",AI3;AI3-02,dpo;alignment,solver,Python,https://github.com/RLHFlow/Online-DPO-R1,,None,online-dpo;alignment;iterative-training
467,Online-RLHF,A recipe and pipeline for online RLHF and online iterative DPO training,"This repository provides a comprehensive recipe and implementation for Online Reinforcement Learning from Human Feedback (RLHF) and Online Iterative Direct Preference Optimization (DPO), enabling efficient alignment of Large Language Models.",AI3;AI3-02,alignment;rlhf;dpo,workflow,Python,https://github.com/RLHFlow/Online-RLHF,,None,rlhf;dpo;alignment;llm-training
468,RLHF-Reward-Modeling,Recipes and tools to train reward models for RLHF,"A collection of recipes and scripts designed to train reward models, a critical component in the Reinforcement Learning from Human Feedback (RLHF) pipeline for aligning Large Language Models.",AI3;AI3-02,reward_modeling;alignment,solver,Python,https://github.com/RLHFlow/RLHF-Reward-Modeling,,Apache-2.0,reward-model;rlhf;alignment
469,APT,Adaptive Pruning and Tuning for efficient Pretrained Language Models,"Implementation of APT (Adaptive Pruning and Tuning), a method for efficient training and inference of Pretrained Language Models by dynamically pruning and tuning parameters.",AI3;AI3-02,peft;model_compression;pruning,solver,Python,https://github.com/ROIM1998/APT,,MIT,peft;pruning;efficient-training
470,gpu_poor,Calculator for LLM token generation speed and GPU memory requirements,"A utility tool to calculate expected token/s and GPU memory requirements for various Large Language Models, supporting different quantization methods like llama.cpp, ggml, bnb, and QLoRA.",AI3,resource_estimation;inference_planning,solver,JavaScript,https://github.com/RahulSChand/gpu_poor,,None,gpu-memory;llm-calculator;quantization
471,ICEdit,Efficient image editing using a single LoRA,"A tool for fantastic image editing using only a single LoRA and minimal training data (0.1%), surpassing larger models in ID persistence and running on low VRAM.",AI3;AI3-02,image_editing;generation;peft,solver,Python,https://github.com/River-Zhang/ICEdit,,NOASSERTION,lora;image-editing;generative-ai
472,CipherChat,Framework to evaluate safety alignment generalization in LLMs,"A framework designed to evaluate the generalization capability of safety alignment for Large Language Models, specifically testing robustness against cipher-based attacks.",AI3;AI3-02,safety_evaluation;alignment_evaluation,workflow,Python,https://github.com/RobustNLP/CipherChat,,MIT,safety;alignment;evaluation
473,SPO,Step-by-step Preference Optimization for diffusion models,Implementation of Step-by-step Preference Optimization (SPO) to align aesthetic post-training diffusion models with generic preferences.,AI3;AI3-02,alignment;preference_optimization;diffusion_models,solver,Python,https://github.com/RockeyCoss/SPO,,MIT,dpo;diffusion;alignment
474,S-LoRA,Scalable serving system for concurrent LoRA adapters,"A serving system designed to efficiently serve thousands of concurrent LoRA adapters, optimizing memory and throughput for multi-tenant LLM serving.",AI3;AI3-02,model_serving;peft_serving,platform,Python,https://github.com/S-LoRA/S-LoRA,,Apache-2.0,lora;serving;inference
475,ADHMR,Aligning Diffusion-based Human Mesh Recovery via DPO,"Official code for ADHMR, a method to align diffusion-based human mesh recovery models using Direct Preference Optimization.",AI3;AI3-02,alignment;human_mesh_recovery;dpo,solver,Python,https://github.com/SMPLCap/ADHMR,,NOASSERTION,diffusion;dpo;human-mesh
476,DiffusionDPO,Direct Preference Optimization for Diffusion Model Alignment,Implementation of Direct Preference Optimization (DPO) specifically adapted for aligning diffusion models to human preferences.,AI3;AI3-02,alignment;dpo;diffusion_models,solver,Python,https://github.com/SalesforceAIResearch/DiffusionDPO,,Apache-2.0,dpo;diffusion;alignment
477,TapeAgents,Framework for LLM Agent development lifecycle,"A framework that facilitates all stages of the Large Language Model (LLM) Agent development lifecycle, enabling the creation and management of intelligent agents.",AI3,agent_development;modeling,framework,Python,https://github.com/ServiceNow/TapeAgents,,Apache-2.0,llm-agent;framework;ai-agents
478,DePT,Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning,"Implementation of DePT (Decomposed Prompt Tuning), a parameter-efficient fine-tuning method for large language models.",AI3;AI3-02,peft;prompt_tuning,solver,Python,https://github.com/ShiZhengyan/DePT,,MIT,peft;prompt-tuning;llm
479,SparseAdapter,Sparse Adapter for Parameter-Efficient Fine-Tuning,"Source code for SparseAdapter, an approach to improve the parameter efficiency of adapters in fine-tuning pre-trained language models.",AI3;AI3-02,peft;adapter_tuning,solver,Python,https://github.com/Shwai-He/SparseAdapter,,None,peft;adapter;sparse-tuning
480,Simplifine,Easy open-source LLM finetuning tool,"A user-friendly tool for LLM fine-tuning offering one-line commands, cloud integration, and support for popular optimization frameworks.",AI3;AI3-02,fine_tuning;peft,workflow,Python,https://github.com/Simplifine-gamedev/Simplifine,,GPL-3.0,fine-tuning;llm;simplification
481,DRPO,Dynamic Rewarding with Prompt Optimization for self-alignment,"Implementation of DRPO (Dynamic Rewarding with Prompt Optimization), a tuning-free approach for self-alignment of LLMs using search-based optimization.",AI3;AI3-02,alignment;prompt_optimization,solver,Python,https://github.com/Singla17/dynamic-alignment-optimization,,Apache-2.0,alignment;prompt-optimization;self-improvement
482,SwanLab,AI training tracking and visualization tool,"An open-source, modern AI training tracking and visualization tool that integrates with popular frameworks like PyTorch, Transformers, and LLaMA Factory to monitor experiments.",AI3,experiment_tracking;visualization,platform,Python,https://github.com/SwanHubX/SwanLab,,Apache-2.0,experiment-tracking;visualization;mlops
483,LongAlign,Recipe for Long Context Alignment of LLMs,"A comprehensive recipe and toolset for aligning Large Language Models to handle long contexts effectively, including data processing and training strategies.",AI3;AI3-02,alignment;long_context,workflow,Python,https://github.com/THUDM/LongAlign,,Apache-2.0,alignment;long-context;llm
484,P-tuning,Method for prompt tuning language models,"Implementation of P-tuning, a novel method to tune language models using continuous prompt embeddings, enabling GPT models to understand prompts better.",AI3;AI3-02,peft;prompt_tuning,solver,Python,https://github.com/THUDM/P-tuning,,MIT,peft;prompt-tuning;p-tuning
485,P-tuning-v2,Optimized deep prompt tuning strategy,An optimized deep prompt tuning strategy (P-tuning v2) that achieves comparable performance to fine-tuning across various scales and tasks.,AI3;AI3-02,peft;prompt_tuning,solver,Python,https://github.com/THUDM/P-tuning-v2,,Apache-2.0,peft;prompt-tuning;deep-tuning
486,MoE-PEFT,Efficient fine-tuning factory optimized for Mixture-of-Experts (MoE) models,"A specialized framework designed for parameter-efficient fine-tuning (PEFT) of Mixture-of-Experts (MoE) large language models, supporting methods like LoRA and QLoRA specifically adapted for MoE architectures.",AI3;AI3-02,fine_tuning;peft;moe_training,solver,Python,https://github.com/TUDB-Labs/MoE-PEFT,,Apache-2.0,moe;peft;llm-training;lora
487,mLoRA,High-efficiency factory for building and training multiple LoRA adapters,An efficient framework for fine-tuning Large Language Models (LLMs) using LoRA (Low-Rank Adaptation) and its variants. It supports training multiple adapters concurrently and is optimized for throughput and memory usage.,AI3;AI3-02,fine_tuning;peft;adapter_management,solver,Python,https://github.com/TUDB-Labs/mLoRA,,Apache-2.0,lora;multi-adapter;fine-tuning;llm
488,PIXIU,Comprehensive benchmark and instruction tuning suite for financial LLMs,"An open-source resource featuring financial large language models (LLMs), instruction tuning datasets, and evaluation benchmarks designed to holistically assess the performance of financial AI models.",AI3;AI3-02,benchmarking;instruction_tuning;evaluation,dataset,Jupyter Notebook,https://github.com/The-FinAI/PIXIU,,MIT,financial-llm;benchmark;instruction-tuning;evaluation
489,VL-RLHF,RLHF infrastructure for fine-tuning Vision-Language Models,"A specialized infrastructure and codebase for performing Reinforcement Learning from Human Feedback (RLHF) on Vision-Language Models (VLMs), facilitating alignment and optimization of multimodal AI.",AI3;AI3-02,alignment;rlhf;multimodal_training,solver,Python,https://github.com/TideDra/VL-RLHF,,Apache-2.0,rlhf;vlm;alignment;multimodal
490,Effective LLM Alignment,Toolkit for efficient Large Language Model alignment,"A toolkit designed to streamline the process of aligning Large Language Models (LLMs), likely providing implementations of various alignment algorithms and utilities for training pipelines.",AI3;AI3-02,alignment;fine_tuning,solver,Python,https://github.com/VikhrModels/effective_llm_alignment,,Apache-2.0,alignment;llm;toolkit
491,SLAM-LLM,"Framework for speech, audio, and music processing using LLMs","A comprehensive framework leveraging Large Language Models for processing and understanding speech, language, audio, and music, enabling multimodal tasks and research.",AI3;AI3-02,multimodal_processing;audio_analysis;speech_processing,workflow,Python,https://github.com/X-LANCE/SLAM-LLM,,MIT,audio;speech;music;llm;multimodal
492,grpo-flat,Lightweight training tool for GRPO with low resource requirements,"A training tool designed to facilitate GRPO (Generative Reward Policy Optimization) training with minimal dataset requirements and support for low-resource environments, including 8bit/4bit quantization and LoRA/QLoRA.",AI3;AI3-02,alignment;fine_tuning;quantization,solver,Python,https://github.com/XU-YIJIE/grpo-flat,,Apache-2.0,grpo;low-resource;quantization;lora
493,TRLO,Efficient LiDAR Odometry with 3D dynamic object tracking,"A LiDAR odometry system that integrates 3D dynamic object tracking and removal, providing a robust solution for simultaneous localization and mapping (SLAM) in dynamic environments.",AI3,slam;lidar_processing;tracking,solver,C++,https://github.com/Yaepiii/TRLO,,None,lidar;odometry;slam;robotics
494,YiVal,Automatic prompt engineering and evaluation assistant for GenAI,"A tool designed to automate the prompt engineering process, providing evaluation and optimization capabilities for Generative AI applications to improve model performance and alignment.",AI3;AI3-02,prompt_engineering;evaluation;alignment,solver,Python,https://github.com/YiVal/YiVal,,Apache-2.0,prompt-engineering;genai;automation;evaluation
495,Adapters,A unified library for parameter-efficient and modular transfer learning,"Adapters is a library that integrates adapter modules into pre-trained language models, enabling efficient fine-tuning and modular transfer learning. It supports various PEFT methods and composition of adapters.",AI3;AI3-02,peft;transfer_learning;fine_tuning,library,Python,https://github.com/adapter-hub/adapters,https://docs.adapterhub.ml/,Apache-2.0,peft;adapters;transfer-learning;nlp
496,Firefly,A WebGL interactive particle viewer for scientific data,"Firefly is a browser-based interactive visualization tool designed for exploring particle-based scientific datasets, such as those from astronomical simulations.",Scientific Visualization,visualization;particle_viewing;data_exploration,solver,Jupyter Notebook,https://github.com/ageller/Firefly,http://ageller.github.io/Firefly/,AGPL-3.0,visualization;astronomy;webgl;particles
497,ROLL,Efficient scaling library for Reinforcement Learning with Large Language Models,"ROLL is a library designed to scale reinforcement learning with large language models (RLHF), focusing on efficiency and user-friendliness for aligning LLMs.",AI3;AI3-02,rlhf;alignment;fine_tuning,library,Python,https://github.com/alibaba/ROLL,,Apache-2.0,rlhf;llm;alignment;reinforcement-learning
498,RewardBench,Evaluation tool and benchmark for reward models,RewardBench is a toolkit and benchmark designed to evaluate the performance and capabilities of reward models used in RLHF pipelines.,AI3;AI3-02,evaluation;benchmarking;reward_modeling,solver,Python,https://github.com/allenai/reward-bench,https://huggingface.co/spaces/allenai/reward-bench,Apache-2.0,evaluation;rlhf;reward-model;benchmark
499,SMASHED,Toolkit for applying transformations to dataset samples in NLP pipelines,"SMASHED is a data processing toolkit designed to handle tokenization, prompting, batching, and field extraction for NLP datasets, supporting various data sources.",AI3,data_processing;tokenization;pipeline,library,Python,https://github.com/allenai/smashed,,Apache-2.0,data-processing;nlp;pipeline
500,Aphrodite Engine,Large-scale LLM inference engine,"Aphrodite Engine is a high-performance inference engine for Large Language Models, designed to serve thousands of users with fast throughput and low latency.",AI3,inference;serving;model_deployment,solver,C++,https://github.com/aphrodite-engine/aphrodite-engine,,AGPL-3.0,inference;llm;serving;vllm
501,Argilla,Collaboration tool for data annotation and dataset management,"Argilla is an open-source platform for data-centric AI, enabling collaboration between engineers and domain experts to label, validate, and refine datasets for LLM training and alignment.",AI3;AI3-02,data_annotation;rlhf;data_management;quality_control,platform,Python,https://github.com/argilla-io/argilla,https://docs.argilla.io/,Apache-2.0,data-annotation;rlhf;dataset;nlp
502,Distilabel,Framework for synthetic data generation and AI feedback,"Distilabel is a framework designed to build scalable pipelines for generating synthetic data and collecting AI feedback, facilitating the creation of high-quality datasets for model training and alignment.",AI3;AI3-02,synthetic_data_generation;ai_feedback;alignment;data_augmentation,library,Python,https://github.com/argilla-io/distilabel,https://distilabel.argilla.io/,Apache-2.0,synthetic-data;rlhf;dpo;feedback
503,Axolotl,A comprehensive post-training framework for fine-tuning Large Language Models (LLMs),"Axolotl is a tool designed to streamline the fine-tuning of various AI models, offering support for multiple training methods including full fine-tuning, LoRA, QLoRA, and ReLoRA. It provides a unified configuration interface (YAML) to manage datasets, model architectures, and training hyperparameters, widely used in the open-source AI community for customizing models.",AI3;AI3-02,fine_tuning;instruction_tuning;peft,workflow,Python,https://github.com/axolotl-ai-cloud/axolotl,https://axolotl-ai-cloud.github.io/axolotl/,Apache-2.0,llm;fine-tuning;lora;qlora;automation
504,Curator,Library for synthetic data curation and structured data extraction using LLMs,"Curator is a Python library designed to automate the creation and curation of high-quality synthetic datasets for post-training and fine-tuning AI models. It leverages Large Language Models to generate, filter, and structure data, facilitating the data preparation phase of model alignment and instruction tuning.",AI3;AI3-02,data_curation;synthetic_data_generation;alignment,library,Python,https://github.com/bespokelabsai/curator,https://github.com/bespokelabsai/curator,Apache-2.0,synthetic-data;data-curation;llm;alignment
505,bitsandbytes,Lightweight wrapper for CUDA custom functions focusing on 8-bit optimizers and quantization,"bitsandbytes is a library that provides efficient CUDA implementations for 8-bit optimizers, matrix multiplication (LLM.int8()), and quantization functions. It is a critical dependency for QLoRA and other parameter-efficient fine-tuning methods, enabling the training of large language models on consumer-grade hardware.",AI3;AI3-02,quantization;optimization;model_compression,library,Python,https://github.com/bitsandbytes-foundation/bitsandbytes,https://huggingface.co/docs/bitsandbytes/index,MIT,quantization;cuda;optimization;qlora
506,Prompt Poet,Tool for designing and managing prompts for LLMs,"Prompt Poet is a library that simplifies and streamlines the design of prompts for Large Language Models. It provides a low-code approach to constructing complex prompt contexts, managing templates, and integrating dynamic data, which is essential for instruction tuning and in-context learning workflows.",AI3;AI3-02,prompt_engineering;instruction_tuning;context_management,library,Python,https://github.com/character-ai/prompt-poet,https://github.com/character-ai/prompt-poet,MIT,prompt-engineering;llm;templating;low-code
507,LoRA (cloneofsimo),Implementation of Low-rank adaptation for fine-tuning diffusion models,"This repository provides a widely used implementation of Low-Rank Adaptation (LoRA) specifically tailored for fine-tuning diffusion models. It allows for parameter-efficient adaptation of large generative models, enabling users to train models on new concepts or styles with significantly reduced computational resources.",AI3;AI3-02,peft;fine_tuning;diffusion_models,library,Jupyter Notebook,https://github.com/cloneofsimo/lora,https://github.com/cloneofsimo/lora,Apache-2.0,lora;stable-diffusion;peft;fine-tuning
508,Fluxgym,Simple UI for training FLUX LoRA models with low VRAM support,"A lightweight user interface designed to simplify the training of LoRA (Low-Rank Adaptation) models for the FLUX image generation architecture. It lowers the barrier for fine-tuning foundation models by providing a streamlined workflow that supports low VRAM environments, making it accessible for researchers and developers working on generative model adaptation.",AI3;AI3-02,model_training;fine_tuning,workflow,Python,https://github.com/cocktailpeanut/fluxgym,,MIT,lora;flux;fine-tuning;ui;generative-ai
509,PEFT-SAM,Parameter Efficient Fine-Tuning for Segment Anything Model (SAM),"A specialized library for applying Parameter Efficient Fine-Tuning (PEFT) techniques to the Segment Anything Model (SAM), specifically tailored for computational cell analytics and biological image segmentation tasks. It enables the adaptation of the powerful SAM foundation model to specific scientific domains with limited data and computational resources.",AI3;AI3-02,fine_tuning;image_segmentation,library,Python,https://github.com/computational-cell-analytics/peft-sam,,MIT,sam;peft;bioimaging;segmentation;fine-tuning
510,LaMDA-rlhf-pytorch,PyTorch implementation of LaMDA with RLHF alignment,"An open-source implementation of Google's LaMDA architecture in PyTorch, incorporating Reinforcement Learning from Human Feedback (RLHF) for model alignment. It serves as a research framework for studying and developing large language models and alignment techniques similar to those used in ChatGPT.",AI3;AI3-02,alignment;model_training,library,Python,https://github.com/conceptofmind/LaMDA-rlhf-pytorch,,MIT,rlhf;lamda;alignment;llm;pytorch
511,ViT-Adapter,Vision Transformer Adapter for dense prediction tasks,"A framework that adapts plain Vision Transformers (ViT) for dense prediction tasks such as object detection and semantic segmentation. It introduces an adapter mechanism that injects inductive biases into the ViT architecture, enabling efficient fine-tuning and improved performance on downstream vision tasks.",AI3;AI3-02,fine_tuning;dense_prediction,library,Python,https://github.com/czczup/ViT-Adapter,,NOASSERTION,vision-transformer;adapter;peft;object-detection;segmentation
512,DataDreamer,Library for synthetic data generation and model alignment,"A comprehensive library for prompting, generating synthetic data, and training/aligning Large Language Models (LLMs). It automates the workflow of creating high-quality datasets from LLMs and using them to fine-tune or align models, facilitating research in data-centric AI and model adaptation.",AI3;AI3-02,data_generation;alignment,library,Python,https://github.com/datadreamer-dev/DataDreamer,https://datadreamer.dev,MIT,synthetic-data;alignment;llm;fine-tuning;prompt-engineering
513,Data-Juicer,Data processing system for foundation models,"A robust data processing system designed for Large Language Models (LLMs). It provides a wide range of operators for data filtering, cleaning, deduplication, and formatting, ensuring high-quality data input for pre-training and fine-tuning foundation models.",AI3,data_processing;quality_control,library,Python,https://github.com/datajuicer/data-juicer,,Apache-2.0,data-processing;llm;etl;data-cleaning;foundation-models
514,EPOSearch,Solver for preference-based multi-objective optimization,"A Python library implementing the Exact Pareto Optimal Search algorithm for preference-based Multi-Objective Optimization (MOO). It is designed to find solutions that align with user preferences in complex optimization landscapes, applicable in scientific modeling and decision-making processes.",AI3,optimization;scientific_analysis,solver,Python,https://github.com/dbmptr/EPOSearch,,MIT,optimization;multi-objective;pareto;preference-learning
515,Instruct-Eval,Evaluation suite for instruction-tuned models,"A framework for quantitatively evaluating instruction-tuned Large Language Models (LLMs) such as Alpaca and Flan-T5. It provides a standardized set of tasks and metrics to assess the performance of models on held-out instructions, facilitating the comparison and validation of alignment techniques.",AI3;AI3-02,evaluation;benchmarking,library,Python,https://github.com/declare-lab/instruct-eval,,Apache-2.0,evaluation;instruction-tuning;llm;benchmarking
516,LoRA Easy Training Scripts,GUI and scripts for training LoRA/LoCon models,"A user interface and collection of scripts designed to simplify the training of LoRA (Low-Rank Adaptation) and LoCon models using `sd-scripts`. It provides an accessible workflow for fine-tuning generative models, managing configuration, and executing training jobs without deep command-line expertise.",AI3;AI3-02,fine_tuning;model_training,workflow,Python,https://github.com/derrian-distro/LoRA_Easy_Training_Scripts,,GPL-3.0,lora;gui;fine-tuning;stable-diffusion;training-scripts
517,ControlNeXt,Library for controllable image and video generation,"A comprehensive library for controllable generation in image and video models. It implements advanced techniques like ControlNet and ControlNeXt, allowing for precise spatial and temporal control over the generation process, which is essential for scientific visualization and synthetic data generation.",AI3;AI3-02,generation;control,library,Python,https://github.com/dvlab-research/ControlNeXt,,Apache-2.0,controlnet;generation;video-generation;lora;controllable-ai
518,LongLoRA,Efficient fine-tuning for long-context LLMs,"A tool and method for extending the context window of Large Language Models (LLMs) through efficient fine-tuning. It utilizes shifted sparse attention (S2-Attn) to enable training on long sequences with reduced computational overhead, facilitating the processing of long scientific texts and data sequences.",AI3;AI3-02,fine_tuning;context_extension,library,Python,https://github.com/dvlab-research/LongLoRA,,Apache-2.0,long-context;lora;fine-tuning;llm;efficiency
519,TuneAI,Automation tool for OpenAI model fine-tuning,"A utility tool that automates the process of fine-tuning OpenAI models. It handles transcript cleaning, prompt-completion pair generation, and dataset preparation, streamlining the workflow for creating custom models from raw text or video inputs.",AI3;AI3-02,data_preparation;fine_tuning,workflow,Python,https://github.com/emmethalm/tuneAI,,MIT,openai;fine-tuning;automation;dataset-creation
520,DPO (Direct Preference Optimization),Reference implementation of Direct Preference Optimization for LLM alignment,"The official reference implementation for Direct Preference Optimization (DPO), a stable and computationally lightweight alternative to RLHF for aligning language models with human preferences. It provides the core loss functions and training loops required to fine-tune models directly on preference data.",AI3;AI3-02,alignment;preference_optimization;rlhf_alternative,solver,Python,https://github.com/eric-mitchell/direct-preference-optimization,,Apache-2.0,dpo;alignment;llm;preference-learning
521,GAST-Net,Graph Attention Spatio-temporal Convolutional Networks for 3D Human Pose Estimation,"A deep learning framework for 3D human pose estimation in video. It utilizes Graph Attention Spatio-temporal Convolutional Networks (GAST-Net) to model the spatial and temporal dependencies of human joints, serving as a solver for computer vision tasks related to human dynamics.",Computer Vision;AI3,pose_estimation;3d_reconstruction,solver,Python,https://github.com/fabro66/GAST-Net-3DPoseEstimation,,MIT,pose-estimation;computer-vision;graph-neural-networks
522,SecAlign,Safety alignment framework defending against prompt injection via preference optimization,A research tool from Facebook Research that implements safety alignment techniques to defend Large Language Models (LLMs) against prompt injection attacks. It utilizes preference optimization methods to enhance model robustness.,AI3;AI3-02;AI Safety,safety_alignment;defense;preference_optimization,solver,Python,https://github.com/facebookresearch/SecAlign,,NOASSERTION,safety;alignment;prompt-injection;llm
523,C3DPO,Canonical 3D Pose Networks for Non-rigid Structure From Motion,"A computer vision tool for Non-rigid Structure From Motion (NRSfM). It implements Canonical 3D Pose Networks to reconstruct 3D shape and motion from 2D landmarks, serving as a solver for 3D geometric reconstruction tasks.",Computer Vision;AI3,structure_from_motion;3d_reconstruction,solver,Python,https://github.com/facebookresearch/c3dpo_nrsfm,,MIT,nrsfm;3d-reconstruction;computer-vision
524,trlib,Library for solving trust region subproblems in optimization,"A C library dedicated to solving the trust region subproblem, a core component in many nonlinear optimization algorithms. It is used in scientific computing for numerical optimization tasks.",Mathematics;Scientific Computing,optimization;numerical_solver,library,C,https://github.com/felixlen/trlib,,MIT,optimization;trust-region;numerical-methods
525,finetune-whisper-lora,Workflow for fine-tuning Whisper models using LoRA and PEFT,A specialized tool for fine-tuning OpenAI's Whisper speech recognition models using Low-Rank Adaptation (LoRA) and Parameter-Efficient Fine-Tuning (PEFT) techniques. It enables efficient adaptation of ASR models on consumer hardware.,AI3;AI3-02;Audio,speech_recognition;fine_tuning;peft,workflow,Python,https://github.com/fengredrum/finetune-whisper-lora,,MIT,whisper;lora;peft;asr
526,CoPEFT,Parameter-efficient fine-tuning framework for multi-agent collaborative perception,An implementation of the CoPEFT framework (AAAI 2025) designed for fast adaptation in multi-agent collaborative perception tasks. It applies parameter-efficient fine-tuning strategies to optimize communication and perception in multi-agent systems.,AI3;AI3-02;Robotics,multi_agent_perception;fine_tuning;peft,solver,Python,https://github.com/fengxueguiren/CoPEFT,,NOASSERTION,multi-agent;perception;peft;aaai-2025
527,Atlas,Method for knowledge composition using task vectors with learned anisotropic scaling,The official implementation of the Atlas method (NeurIPS 2024) for composing knowledge from different models using task vectors. It provides a solver for merging model capabilities through learned anisotropic scaling.,AI3;AI3-02,model_merging;task_vectors;knowledge_composition,solver,Python,https://github.com/fredzzhang/atlas,,None,model-merging;neurips-2024;task-vectors
528,General Preference Model,General preference model for language model alignment beyond Bradley-Terry,Implementation of a general preference model (ICML 2025) for LLM alignment that extends beyond the standard Bradley-Terry model. It serves as a solver for more complex preference learning scenarios in model alignment.,AI3;AI3-02,alignment;preference_modeling;rlhf,solver,Python,https://github.com/general-preference/general-preference-model,,Apache-2.0,alignment;preference-model;icml-2025
529,llm_qlora,Workflow scripts for fine-tuning LLMs using QLoRA,A widely used collection of scripts and workflows for fine-tuning Large Language Models using Quantized LoRA (QLoRA). It facilitates the efficient adaptation of LLMs on consumer-grade GPUs.,AI3;AI3-02,fine_tuning;qlora;peft,workflow,Jupyter Notebook,https://github.com/georgesung/llm_qlora,,MIT,qlora;fine-tuning;llm
530,LLM-Finetuning-Toolkit,"Toolkit for fine-tuning, ablating, and testing open-source LLMs","A comprehensive toolkit developed by Georgian for fine-tuning, ablation studies, and unit testing of open-source Large Language Models. It provides a structured workflow for adapting LLMs to specific domains.",AI3;AI3-02,fine_tuning;model_evaluation;ablation_study,workflow,Python,https://github.com/georgian-io/LLM-Finetuning-Toolkit,,Apache-2.0,fine-tuning;llm;toolkit
531,UDS,Utility-Diversity Aware Online Batch Selection for LLM SFT,Implementation of the UDS algorithm for online batch selection during Supervised Fine-Tuning (SFT) of LLMs. It acts as a solver to optimize data efficiency by balancing utility and diversity in training batches.,AI3;AI3-02,data_selection;sft;fine_tuning,solver,Python,https://github.com/gfyddha/UDS,,None,data-selection;sft;llm
532,SelectiveDPO,Principled data selection method for DPO alignment,A tool implementing a principled data selection strategy for Direct Preference Optimization (DPO). It helps in identifying and filtering difficult or noisy examples to improve the stability and performance of model alignment.,AI3;AI3-02,data_selection;alignment;dpo,solver,Python,https://github.com/glorgao/SelectiveDPO,,Apache-2.0,data-selection;dpo;alignment
533,prompt-tuning,Original implementation of Prompt Tuning for parameter-efficient adaptation,"The original implementation of 'The Power of Scale for Parameter-Efficient Prompt Tuning' by Google Research. It provides the solver and methodology for adapting large pre-trained models using soft prompts, a key PEFT technique.",AI3;AI3-02,peft;prompt_tuning;model_adaptation,solver,Python,https://github.com/google-research/prompt-tuning,,Apache-2.0,prompt-tuning;peft;google-research
534,LLaVA,Visual Instruction Tuning framework for large multimodal models,"The official repository for LLaVA (Large Language-and-Vision Assistant), providing the codebase for visual instruction tuning. It serves as a platform for training and evaluating multimodal models that connect vision encoders with LLMs.",AI3;AI3-02;Computer Vision,visual_instruction_tuning;multimodal_training;vlm,platform,Python,https://github.com/haotian-liu/LLaVA,https://llava-vl.github.io/,Apache-2.0,vlm;multimodal;instruction-tuning;llava
535,ChatGLM-Efficient-Tuning,Efficient fine-tuning framework for ChatGLM models based on PEFT,"A comprehensive framework for fine-tuning ChatGLM-6B and related models using PEFT techniques (LoRA, P-Tuning, etc.). It is the predecessor to LLaMA-Factory and serves as a workflow tool for adapting ChatGLM models.",AI3;AI3-02,fine_tuning;peft;chatglm,workflow,Python,https://github.com/hiyouga/ChatGLM-Efficient-Tuning,,Apache-2.0,chatglm;peft;fine-tuning
536,LLaMA-Factory,Unified efficient fine-tuning platform for 100+ LLMs and VLMs,"A widely adopted platform for the efficient fine-tuning of over 100 large language and vision-language models. It integrates various PEFT methods, training strategies (SFT, RLHF, DPO), and provides a web UI and CLI for the entire model adaptation lifecycle.",AI3;AI3-02,fine_tuning;peft;rlhf;dpo;training_platform,platform,Python,https://github.com/hiyouga/LLaMA-Factory,,Apache-2.0,fine-tuning;llm;peft;rlhf;gui
537,visual_prompting,Visual prompting methods for adapting large-scale vision models,Research code implementing visual prompting techniques to adapt large-scale pre-trained vision models to downstream tasks without fine-tuning the model weights. It serves as a solver for pixel-level PEFT in computer vision.,Computer Vision;AI3-02,visual_prompting;model_adaptation;peft,solver,Python,https://github.com/hjbahng/visual_prompting,,MIT,visual-prompting;adaptation;computer-vision
538,Deita,Data-Efficient Instruction Tuning for Alignment,A tool for selecting high-quality instruction tuning data to align Large Language Models efficiently. It implements the Deita approach (ICLR 2024) to automatically filter and select data samples that maximize alignment performance.,AI3;AI3-02,data_selection;instruction_tuning;alignment,solver,Python,https://github.com/hkust-nlp/deita,,Apache-2.0,data-selection;instruction-tuning;alignment
539,IR-QLoRA,Accurate LoRA-Finetuning Quantization via Information Retention,"Implementation of IR-QLoRA (ICML 2024), a method for accurate quantization of LLMs during LoRA fine-tuning. It serves as a solver for creating high-performance quantized models with parameter-efficient fine-tuning.",AI3;AI3-02,quantization;peft;qlora,solver,Python,https://github.com/htqin/IR-QLoRA,,None,quantization;lora;peft;icml-2024
540,Alignment Handbook,Recipes and workflows for aligning language models with human preferences,"A collection of robust recipes and scripts from Hugging Face for aligning language models using methods like DPO, IPO, and KTO. It serves as a standard workflow reference for the community to perform model alignment.",AI3;AI3-02,alignment;rlhf;dpo;workflow_recipes,workflow,Python,https://github.com/huggingface/alignment-handbook,,Apache-2.0,alignment;huggingface;recipes;dpo
541,Optimum Benchmark,Unified multi-backend benchmarking utility for Transformers and PEFT,"A utility tool for benchmarking the performance of Transformers, PEFT, and other models across different backends and hardware. It supports measuring latency, throughput, and memory usage, essential for optimizing scientific model inference and training.",AI3;AI3-02;HPC,benchmarking;performance_analysis;optimization,solver,Python,https://github.com/huggingface/optimum-benchmark,,Apache-2.0,benchmarking;optimization;transformers
542,PEFT,State-of-the-art Parameter-Efficient Fine-Tuning (PEFT) library for adapting large pre-trained models,"A library that enables efficient adaptation of pre-trained language models to various downstream applications without fine-tuning all the model's parameters. It supports methods like LoRA, Prefix Tuning, P-Tuning, and Prompt Tuning, significantly reducing computational and storage costs.",AI3;AI3-02,fine_tuning;parameter_efficiency;model_adaptation,library,Python,https://github.com/huggingface/peft,https://huggingface.co/docs/peft,Apache-2.0,lora;qlora;fine-tuning;llm
543,TRL,Transformer Reinforcement Learning library for training and aligning language models,"A full-stack library for training transformer language models with Reinforcement Learning (RL). It supports the entire pipeline from Supervised Fine-Tuning (SFT), Reward Modeling (RM), to Proximal Policy Optimization (PPO) and Direct Preference Optimization (DPO) for model alignment.",AI3;AI3-02,alignment;rlhf;dpo;ppo;fine_tuning,library,Python,https://github.com/huggingface/trl,https://huggingface.co/docs/trl,Apache-2.0,rlhf;alignment;ppo;dpo
544,LLamaTuner,GUI and CLI tool for efficient fine-tuning and quantization of Large Language Models,"A comprehensive tool designed to simplify the fine-tuning and quantization of various Large Language Models (LLMs) such as Llama, Qwen, and Baichuan. It provides both a graphical user interface and command-line tools to facilitate parameter-efficient fine-tuning (PEFT) and model deployment.",AI3;AI3-02,fine_tuning;quantization;workflow_management,solver,Python,https://github.com/jianzhnie/LLamaTuner,,Apache-2.0,gui;fine-tuning;quantization;llm
545,MoRA,High-rank updating method for parameter-efficient fine-tuning (PEFT),"An implementation of MoRA, a PEFT method that employs a square matrix for high-rank updating to achieve parameter efficiency while maintaining high capacity, serving as an alternative to LoRA.",AI3;AI3-02,peft;model_training,solver,Python,https://github.com/kongds/MoRA,,Apache-2.0,peft;fine-tuning;llm
546,CM3Leon,Open source implementation of the CM3Leon multimodal model,"An implementation of the CM3Leon architecture, an autoregressive multi-modal model capable of generating both text and images, facilitating research in multi-modal pretraining and instruction tuning.",AI3;AI3-02,model_training;multimodal_generation,solver,Python,https://github.com/kyegomez/CM3Leon,,MIT,multimodal;transformer;generative-ai
547,Finetuning-Suite,Streamlined suite for fine-tuning Hugging Face models,"A tool designed to simplify and accelerate the fine-tuning process for various models available on Hugging Face, providing a quick setup for model adaptation.",AI3;AI3-02,fine_tuning;model_adaptation,workflow,Jupyter Notebook,https://github.com/kyegomez/Finetuning-Suite,,Apache-2.0,fine-tuning;huggingface;productivity
548,swarms-pytorch,PyTorch implementation of swarm intelligence algorithms,"A library implementing various swarm intelligence algorithms such as Particle Swarm Optimization (PSO) and Ant Colony Optimization in PyTorch, useful for scientific optimization tasks.",AI3,optimization;scientific_modeling,library,Python,https://github.com/kyegomez/swarms-pytorch,,MIT,optimization;swarm-intelligence;pytorch
549,tree-of-thoughts,Framework for Tree of Thoughts reasoning in LLMs,"An implementation of the Tree of Thoughts (ToT) framework, enabling large language models to perform deliberate problem solving and enhanced reasoning by exploring multiple thought paths.",AI3;AI3-02,inference;reasoning,library,Python,https://github.com/kyegomez/tree-of-thoughts,,Apache-2.0,reasoning;llm;inference-optimization
550,PRefLexOR,Preference-based recursive language modeling for reasoning optimization,"A framework for exploratory optimization of reasoning capabilities in language models using preference-based recursive modeling, useful for enhancing model performance on complex tasks.",AI3;AI3-02,optimization;reasoning;alignment,solver,Jupyter Notebook,https://github.com/lamm-mit/PRefLexOR,,Apache-2.0,reasoning;preference-learning;llm
551,VB-LoRA,Extreme parameter-efficient fine-tuning using Vector Banks,"An implementation of VB-LoRA, a method for parameter-efficient fine-tuning that utilizes vector banks to further reduce trainable parameters compared to standard LoRA.",AI3;AI3-02,peft;model_training,solver,Python,https://github.com/leo-yangli/VB-LoRA,,None,peft;lora;efficiency
552,flash-preference,Accelerated LLM preference tuning via prefix sharing,A library to accelerate preference tuning (alignment) of Large Language Models by implementing efficient prefix sharing mechanisms.,AI3;AI3-02,alignment;optimization,library,Python,https://github.com/li-plus/flash-preference,,MIT,alignment;preference-tuning;acceleration
553,prompt-optimizer,Tool for optimizing prompts to improve LLM outputs,"A tool designed to assist in writing and optimizing high-quality prompts, which is a critical part of the workflow for aligning and utilizing Large Language Models effectively.",AI3;AI3-02,prompt_engineering;alignment,workflow,TypeScript,https://github.com/linshenkx/prompt-optimizer,,NOASSERTION,prompt-engineering;optimization;llm
554,ChatGLM-Finetuning,Comprehensive fine-tuning workflow for ChatGLM models,"A widely used collection of scripts and workflows for fine-tuning ChatGLM series models, supporting various methods like Freeze, LoRA, P-tuning, and full parameter fine-tuning.",AI3;AI3-02,fine_tuning;peft,workflow,Python,https://github.com/liucongg/ChatGLM-Finetuning,,None,chatglm;fine-tuning;lora
555,MOELoRA-peft,Mixture-of-Experts based LoRA for PEFT,"Implementation of MOELoRA, a parameter-efficient fine-tuning method that combines Mixture of Experts (MoE) with LoRA to enhance model adaptation capabilities.",AI3;AI3-02,peft;model_training,solver,Python,https://github.com/liuqidong07/MOELoRA-peft,,MIT,peft;moe;lora
556,LLaVA-RLHF,Factually augmented RLHF for aligning Large Multimodal Models,"A tool/framework for aligning Large Multimodal Models (LMMs) using Reinforcement Learning with Human Feedback (RLHF), specifically focusing on reducing hallucinations and improving factual alignment.",AI3;AI3-02,alignment;rlhf;multimodal,solver,Python,https://github.com/llava-rlhf/LLaVA-RLHF,,GPL-3.0,rlhf;multimodal;alignment
557,PSEC,Framework for skill expansion and composition in parameter space,"Implementation of PSEC, a framework designed to facilitate efficient and flexible skill expansion and composition for agents by operating in the parameter space.",AI3;AI3-02,model_adaptation;skill_learning,solver,Python,https://github.com/ltlhuuu/PSEC,,MIT,skill-expansion;parameter-space;agents
558,trlda,Online inference algorithms for Latent Dirichlet Allocation (LDA),"A C++ library with Python bindings providing implementations of various online inference algorithms for Latent Dirichlet Allocation, useful for statistical topic modeling.",AI3,statistical_inference;topic_modeling,library,C++,https://github.com/lucastheis/trlda,,MIT,lda;topic-modeling;inference
559,DiscoPOP,Algorithm for discovering preference optimization methods,"Code and framework for discovering new preference optimization algorithms for Large Language Models, enabling the development of better alignment techniques.",AI3;AI3-02,alignment;preference_optimization,solver,Python,https://github.com/luchris429/DiscoPOP,,MIT,alignment;preference-optimization;llm
560,PaLM-rlhf-pytorch,PyTorch implementation of RLHF for PaLM architecture,"A complete implementation of Reinforcement Learning with Human Feedback (RLHF) on top of the PaLM architecture, serving as a reference library for training aligned LLMs.",AI3;AI3-02,alignment;rlhf;model_training,library,Python,https://github.com/lucidrains/PaLM-rlhf-pytorch,,MIT,rlhf;palm;pytorch
561,mDPO,Conditional Preference Optimization for Multimodal LLMs,"Implementation of mDPO, a method for aligning Multimodal Large Language Models using conditional preference optimization.",AI3;AI3-02,alignment;multimodal;dpo,solver,Python,https://github.com/luka-group/mDPO,,None,dpo;multimodal;alignment
562,RobustFT,Robust Supervised Fine-tuning for LLMs under noisy response,"A method and tool for performing robust supervised fine-tuning of Large Language Models, specifically designed to handle noisy training data effectively.",AI3;AI3-02,fine_tuning;robustness,solver,Python,https://github.com/luo-junyu/RobustFT,,None,fine-tuning;robustness;noise-handling
563,SemiEvol,Semi-supervised Fine-tuning for LLM Adaptation,"A framework for semi-supervised fine-tuning, enabling the adaptation of Large Language Models using both labeled and unlabeled data.",AI3;AI3-02,fine_tuning;semi_supervised_learning,solver,Python,https://github.com/luo-junyu/SemiEvol,,None,fine-tuning;semi-supervised;adaptation
564,LaVIN,Efficient Vision-Language Instruction Tuning,"Implementation of LaVIN, a method for cheap and quick vision-language instruction tuning for Large Language Models, facilitating efficient multimodal adaptation.",AI3;AI3-02,instruction_tuning;multimodal,solver,Python,https://github.com/luogen1996/LaVIN,,None,instruction-tuning;multimodal;efficiency
565,LangCode,Improving alignment and reasoning with natural language embedded programs,A tool/method for improving the alignment and reasoning capabilities of LLMs by utilizing natural language embedded programs (NLEP).,AI3;AI3-02,alignment;reasoning,solver,Python,https://github.com/luohongyin/LangCode,,MIT,alignment;reasoning;code-generation
566,simple-llm-finetuner,Simple UI for LLM Model Finetuning,"A user-friendly interface and workflow tool for fine-tuning Large Language Models, designed to make the process accessible without deep coding requirements.",AI3;AI3-02,fine_tuning;model_training,platform,Jupyter Notebook,https://github.com/lxe/simple-llm-finetuner,,MIT,ui;fine-tuning;low-code
567,AirLLM,Memory-efficient inference for large models on consumer GPUs,"A library enabling the inference of very large language models (e.g., 70B) on hardware with limited memory (e.g., single 4GB GPU) through layered execution and optimization.",AI3,inference;optimization,library,Jupyter Notebook,https://github.com/lyogavin/airllm,,Apache-2.0,inference;memory-optimization;consumer-hardware
568,memprompt,Method to fix LLMs after deployment with user feedback,"A tool implementing MemPrompt, a method that allows fixing errors in deployed GPT-3 style models using user feedback without requiring full re-training.",AI3;AI3-02,alignment;feedback_learning,solver,Python,https://github.com/madaan/memprompt,,Apache-2.0,alignment;human-feedback;memory
569,Magpie,Alignment Data Synthesis from Scratch,"A pipeline and tool for synthesizing high-quality alignment data by prompting aligned LLMs, facilitating efficient data generation for model training.",AI3;AI3-02,data_synthesis;alignment,workflow,Python,https://github.com/magpie-align/magpie,,MIT,synthetic-data;alignment;data-generation
570,Pruning-Weights-Biobjective,Biobjective optimization strategy for neural network weight pruning in Keras,A pruning strategy integrated into the training process that uses multiobjective optimization to reduce network complexity and inference time without requiring extensive hyperparameter search or retraining.,AI3;AI3-02,model_compression;pruning,solver,Python,https://github.com/malena1906/Pruning-Weights-with-Biobjective-Optimization-Keras,,None,pruning;optimization;keras;neural-networks
571,MaPO,Margin-aware Preference Optimization for aligning diffusion models,"Official codebase for MaPO, a method to align diffusion models without requiring reference images, utilizing margin-aware preference optimization.",AI3;AI3-02,alignment;diffusion_model_tuning,solver,Python,https://github.com/mapo-t2i/mapo,,Apache-2.0,diffusion-models;alignment;preference-optimization
572,6DPose,Implementation of 6D pose estimation algorithms,"A collection of algorithms and implementations for 6D pose estimation, useful for computer vision and robotics tasks involving spatial analysis.",AI3,pose_estimation;image_analysis,library,Python,https://github.com/meiqua/6DPose,,None,6d-pose;computer-vision;pose-estimation
573,PromptCBLUE,Large-scale Chinese medical instruction-tuning dataset,"A large-scale instruction-tuning dataset designed for multi-task and few-shot learning in the medical domain, facilitating the training of medical LLMs.",AI3;AI3-02,instruction_tuning;dataset_preparation,dataset,Python,https://github.com/michael-wzhu/PromptCBLUE,,None,medical-ai;instruction-tuning;dataset;chinese-nlp
574,InstructLLaMA,"Pipeline for pre-training, SFT, and RLHF of LLaMA models","A comprehensive implementation for pre-training, supervised fine-tuning (SFT), and reinforcement learning from human feedback (RLHF) to align LLaMA models with human instructions.",AI3;AI3-02,rlhf;supervised_fine_tuning;alignment,workflow,Jupyter Notebook,https://github.com/michaelnny/InstructLLaMA,,MIT,llama;rlhf;sft;instruction-following
575,CoMOLA,Constrained Multi-objective Optimization of Land use Allocation,"A generic Python tool for optimizing land use allocation considering ecosystem services and biodiversity, using constrained multi-objective optimization techniques.",AI3,optimization;simulation;spatial_analysis,solver,Python,https://github.com/michstrauch/CoMOLA,,GPL-3.0,optimization;land-use;multi-objective;spatial-planning
576,LoRA,Reference implementation of Low-Rank Adaptation for LLMs,"The official implementation of LoRA (Low-Rank Adaptation), a widely used parameter-efficient fine-tuning technique for large language models.",AI3;AI3-02,peft;fine_tuning,library,Python,https://github.com/microsoft/LoRA,,MIT,lora;peft;llm;fine-tuning
577,mttl,Library for modular LLMs with parameter-efficient fine-tuning,"A library for building modular language models using parameter-efficient fine-tuning (PEFT) techniques, facilitating flexible model adaptation.",AI3;AI3-02,peft;modular_learning,library,Python,https://github.com/microsoft/mttl,,MIT,peft;modular-ai;llm
578,PEFT Proteomics,LoRA implementation for protein language models,A specialized implementation of Low-Rank Adaptation (LoRA) tailored for fine-tuning protein language models in proteomics research.,AI3;AI3-02,protein_modeling;peft,solver,Jupyter Notebook,https://github.com/microsoft/peft_proteomics,,MIT,proteomics;protein-language-models;lora;bio-ai
579,SAMMO,Structure-aware Multi-Objective Metaprompt Optimization library,A library for prompt engineering and optimization that uses structure-aware multi-objective techniques to improve the performance of large language models.,AI3;AI3-02,prompt_optimization;prompt_engineering,library,Python,https://github.com/microsoft/sammo,,MIT,prompt-engineering;optimization;llm
580,VADER,Video Diffusion Alignment via Reward Gradients,"A tool for aligning video diffusion models using reward gradients, supporting fine-tuning with various reward models like HPS, PickScore, and VideoMAE.",AI3;AI3-02,alignment;video_generation,solver,Python,https://github.com/mihirp1998/VADER,,None,video-diffusion;alignment;reward-gradients
581,UniTS,Unified multi-task time series model,"A unified model and library for multi-task time series analysis, capable of handling forecasting, classification, and other temporal data tasks.",AI3,time_series_analysis;forecasting,library,Python,https://github.com/mims-harvard/UniTS,,MIT,time-series;multi-task-learning;forecasting
582,DiffFit,Parameter-Efficient Fine-Tuning for Diffusion Models,"Implementation of DiffFit, a method for parameter-efficient fine-tuning of large diffusion models to unlock their transferability.",AI3;AI3-02,peft;diffusion_model_tuning,solver,Python,https://github.com/mkshing/DiffFit-pytorch,,MIT,diffusion-models;peft;fine-tuning
583,Trinity-RFT,Framework for reinforcement fine-tuning of LLMs,"A general-purpose, flexible, and scalable framework designed for reinforcement fine-tuning (RFT) of large language models.",AI3;AI3-02,reinforcement_learning;fine_tuning,framework,Python,https://github.com/modelscope/Trinity-RFT,,Apache-2.0,rlhf;fine-tuning;llm;reinforcement-learning
584,SWIFT,Comprehensive framework for LLM/MLLM fine-tuning and alignment,"A scalable framework supporting PEFT, full-parameter fine-tuning, and alignment (DPO/GRPO) for a wide range of LLMs and MLLMs.",AI3;AI3-02,fine_tuning;alignment;peft,framework,Python,https://github.com/modelscope/ms-swift,,Apache-2.0,peft;llm;mllm;alignment;fine-tuning
585,DPoser-X,Diffusion Model as Robust 3D Whole-body Human Pose Prior,A tool utilizing diffusion models as a robust prior for 3D whole-body human pose estimation tasks.,AI3,pose_estimation;structure_prediction,solver,Python,https://github.com/moonbow721/DPoser-X,,MIT,3d-pose;diffusion-models;human-pose-estimation
586,LLM-Dojo,Open source LLM training and RLHF framework,"A framework for building model training pipelines and RLHF workflows (DPO/CPO/KTO/PPO), supporting various mainstream models.",AI3;AI3-02,rlhf;fine_tuning,framework,Python,https://github.com/mst272/LLM-Dojo,,None,rlhf;llm-training;dpo;ppo
587,ChatGLM-Tuning,LoRA fine-tuning solution for ChatGLM-6B,A widely used fine-tuning solution based on LoRA specifically designed for the ChatGLM-6B model.,AI3;AI3-02,fine_tuning;peft,workflow,Python,https://github.com/mymusise/ChatGLM-Tuning,,MIT,chatglm;lora;fine-tuning
588,llama2-fine-tune,Scripts for fine-tuning Llama2 via SFT and DPO,A collection of scripts and workflows for fine-tuning Llama2 models using Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO).,AI3;AI3-02,fine_tuning;alignment,workflow,Python,https://github.com/mzbac/llama2-fine-tune,,None,llama2;sft;dpo;fine-tuning
589,Nunchaku,Inference engine and quantization library for 4-bit diffusion models,"Nunchaku (SVDQuant) is a library designed for the quantization and efficient inference of diffusion models. It implements the SVDQuant algorithm to absorb outliers using low-rank components, enabling high-quality 4-bit quantization.",AI3;AI3-02,quantization;inference;diffusion_models,library,Python,https://github.com/nunchaku-tech/nunchaku,,Apache-2.0,quantization;diffusion;inference-engine
590,Oumi,"Framework for fine-tuning, evaluating, and deploying open-source LLMs","Oumi is a comprehensive library that simplifies the lifecycle of Large Language Models (LLMs) and Vision Language Models (VLMs), providing tools for fine-tuning, evaluation, and deployment of models like Llama, Qwen, and DeepSeek.",AI3;AI3-02,fine-tuning;evaluation;deployment,library,Python,https://github.com/oumi-ai/oumi,,Apache-2.0,llm;fine-tuning;inference
591,LoRAX,Multi-LoRA inference server for scaling fine-tuned LLMs,LoRAX is an inference server designed to serve thousands of fine-tuned models on a single GPU using Low-Rank Adaptation (LoRA). It optimizes resource usage for multi-tenant LLM serving.,AI3;AI3-02,inference;serving;lora,service,Python,https://github.com/predibase/lorax,,Apache-2.0,inference-server;lora;llm-serving
592,LESS,Data selection tool for targeted instruction tuning,LESS is a tool and method for selecting influential data for targeted instruction tuning of Large Language Models. It helps in optimizing training data to improve model performance on specific tasks.,AI3;AI3-02,data_selection;instruction_tuning;data_optimization,solver,Jupyter Notebook,https://github.com/princeton-nlp/LESS,,MIT,data-selection;instruction-tuning;llm
593,SimPO,Simple Preference Optimization algorithm implementation,"SimPO provides the reference implementation for Simple Preference Optimization, a reference-free reward optimization method for aligning Large Language Models. It serves as a solver for applying this alignment technique.",AI3;AI3-02,preference_optimization;alignment;rlhf,solver,Python,https://github.com/princeton-nlp/SimPO,,MIT,alignment;dpo;preference-optimization
594,Promptify,Library for structured output generation using LLMs,Promptify is a library that simplifies prompt engineering to obtain structured outputs (like JSON) from Large Language Models. It is used for NLP tasks such as Named Entity Recognition (NER) and classification.,AI3,prompt_engineering;information_extraction;nlp,library,Jupyter Notebook,https://github.com/promptslab/Promptify,,Apache-2.0,prompt-engineering;nlp;structured-output
595,T-Few,Implementation of Few-Shot Parameter-Efficient Fine-Tuning,"T-Few provides the code and implementation for the T-Few method, enabling few-shot parameter-efficient fine-tuning of language models. It serves as a solver/baseline for PEFT research.",AI3;AI3-02,peft;few_shot_learning;fine-tuning,solver,Python,https://github.com/r-three/t-few,,MIT,peft;few-shot;fine-tuning
596,LLM-RLHF-Tuning-with-PPO-and-DPO,Toolkit for RLHF training using PPO and DPO,"A comprehensive toolkit for Reinforcement Learning from Human Feedback (RLHF) training. It integrates instruction fine-tuning and reward modeling, supporting algorithms like PPO and DPO for models such as LLaMA.",AI3;AI3-02,rlhf;fine-tuning;alignment,workflow,Python,https://github.com/raghavc/LLM-RLHF-Tuning-with-PPO-and-DPO,,None,rlhf;ppo;dpo
597,Crater,Cloud-native AI training and inference platform,"Crater is a platform designed for cloud-native AI training and inference, providing infrastructure management for AI workloads.",AI3,model_training;inference;infrastructure,platform,TypeScript,https://github.com/raids-lab/crater,,Apache-2.0,ai-platform;training;inference
598,TRLC-DK1,Development kit for robot learning and control,"A development kit provided by The Robot Learning Company, likely containing software interfaces and tools for controlling robotic hardware for learning tasks.",AI4;Robotics,robot_control;reinforcement_learning,library,Python,https://github.com/robot-learning-co/trlc-dk1,,Apache-2.0,robotics;robot-learning;sdk
599,OAT,Research-friendly framework for LLM online alignment,"A framework designed for online alignment of Large Language Models, supporting reinforcement learning and preference learning techniques.",AI3;AI3-02,alignment;rlhf;preference_learning,library,Python,https://github.com/sail-sg/oat,,Apache-2.0,llm-alignment;rlhf;preference-optimization
600,DialogStudio,Unified dataset collection and loader for conversational AI,A library providing access to a diverse collection of unified datasets and instruction-aware models for conversational AI research.,AI3;AI3-01,data_loading;dataset_collection,library,Python,https://github.com/salesforce/DialogStudio,,Apache-2.0,conversational-ai;datasets;instruction-tuning
601,Finetune-Qwen2.5-VL,Fine-tuning toolkit for Qwen2.5-VL vision-language models,"A specialized toolkit for fine-tuning the Qwen2.5-VL model, optimized for vision understanding tasks with support for LoRA and PEFT.",AI3;AI3-02,fine_tuning;peft;vision_language_modeling,workflow,Python,https://github.com/sandy1990418/Finetune-Qwen2.5-VL,,Apache-2.0,qwen;vlm;lora;fine-tuning
602,XtunerGUI,Graphical User Interface for Xtuner fine-tuning toolkit,"A GUI wrapper for the Xtuner library, facilitating the fine-tuning process of Large Language Models for users who prefer a visual interface.",AI3;AI3-02,fine_tuning;gui,platform,Python,https://github.com/scchy/XtunerGUI,,MIT,xtuner;gui;fine-tuning
603,GraphRAG-Local-UI,Local platform for GraphRAG with LLMs,"A comprehensive tool for running GraphRAG (Retrieval Augmented Generation with Knowledge Graphs) locally, including indexing, prompt tuning, and querying capabilities.",AI3;AI3-03,rag;knowledge_graph;information_retrieval,platform,Python,https://github.com/severian42/GraphRAG-Local-UI,,MIT,graphrag;rag;local-llm
604,Vodalus-Expert-LLM-Forge,Toolkit for dataset crafting and efficient LLM fine-tuning,A tool suite for creating datasets using RAG/Wikipedia ground truth and performing efficient fine-tuning using MLX and Unsloth.,AI3;AI3-02,dataset_creation;fine_tuning;rag,workflow,Jupyter Notebook,https://github.com/severian42/Vodalus-Expert-LLM-Forge,,None,dataset-generation;fine-tuning;mlx;unsloth
605,MedicalGPT,Comprehensive pipeline for training medical LLMs,"A complete workflow for training medical large language models, including incremental pre-training, supervised fine-tuning (SFT), RLHF, DPO, and other alignment techniques.",AI3;AI3-02,model_training;fine_tuning;rlhf;medical_ai,workflow,Python,https://github.com/shibing624/MedicalGPT,,Apache-2.0,medical-llm;rlhf;dpo;sft
606,promptimal,Minimalist prompt optimizer for LLMs,"A tool designed to optimize prompts for large language models, improving response quality and efficiency.",AI3;AI3-04,prompt_optimization;prompt_engineering,solver,Python,https://github.com/shobrook/promptimal,,MIT,prompt-optimization;llm
607,chatGLM-6B-QLoRA,QLoRA fine-tuning implementation for ChatGLM-6B,"A tool implementing 4-bit QLoRA efficient fine-tuning for ChatGLM-6B/ChatGLM2-6B models, including model merging and quantization utilities.",AI3;AI3-02,fine_tuning;qlora;quantization,workflow,Python,https://github.com/shuxueslpi/chatGLM-6B-QLoRA,,None,chatglm;qlora;peft
608,OneDiff,Acceleration library for diffusion models,An out-of-the-box acceleration library designed to optimize the inference speed of diffusion models.,AI3;AI3-05,inference_acceleration;diffusion_models,library,Jupyter Notebook,https://github.com/siliconflow/onediff,,Apache-2.0,diffusion;acceleration;inference
609,baichuan_finetuning,Fine-tuning scripts for Baichuan models,"A collection of scripts and tools for fine-tuning Baichuan and Baichuan2 models, supporting Alpaca-style instruction tuning.",AI3;AI3-02,fine_tuning;instruction_tuning,workflow,Python,https://github.com/ssbuild/baichuan_finetuning,,Apache-2.0,baichuan;fine-tuning;llm
610,chatglm_finetuning,Fine-tuning toolkit for ChatGLM models,"A widely used toolkit for fine-tuning ChatGLM-6B and related models, supporting various fine-tuning methods including Alpaca-style instruction tuning.",AI3;AI3-02,fine_tuning;instruction_tuning,workflow,Python,https://github.com/ssbuild/chatglm_finetuning,,Apache-2.0,chatglm;fine-tuning;llm
611,chatglm_rlhf,RLHF fine-tuning implementation for ChatGLM,A specialized tool for performing Reinforcement Learning from Human Feedback (RLHF) fine-tuning on ChatGLM models.,AI3;AI3-02,rlhf;alignment;fine_tuning,workflow,Python,https://github.com/ssbuild/chatglm_rlhf,,None,chatglm;rlhf;alignment
612,llm_finetuning,"Fine-tuning scripts for various Large Language Models (Bloom, OPT, GPT, LLaMA, etc.)","A collection of scripts and tools for fine-tuning multiple open-source Large Language Models including Bloom, OPT, GPT-2, LLaMA, and CPM-Ant, supporting various training configurations.",AI3;AI3-02,fine_tuning;model_training,solver,Python,https://github.com/ssbuild/llm_finetuning,,None,llm;fine-tuning;llama;bloom
613,llm_rlhf,Reinforcement Learning from Human Feedback (RLHF) implementation for LLMs,"Implements reinforcement learning training pipelines (RLHF) for large language models such as GPT-2, LLaMA, and Bloom, facilitating alignment with human preferences.",AI3;AI3-02,alignment;rlhf,solver,Python,https://github.com/ssbuild/llm_rlhf,,None,rlhf;alignment;llm
614,moss_finetuning,Fine-tuning tools specifically for the MOSS chat model,"Provides scripts and utilities tailored for fine-tuning the MOSS conversational model, enabling domain adaptation and instruction tuning.",AI3;AI3-02,fine_tuning,solver,Python,https://github.com/ssbuild/moss_finetuning,,None,moss;fine-tuning;chat-model
615,qwen_finetuning,Fine-tuning framework for Qwen series models,"A dedicated toolkit for fine-tuning Qwen (Tongyi Qianwen) models, supporting instruction tuning and domain adaptation workflows.",AI3;AI3-02,fine_tuning,solver,Python,https://github.com/ssbuild/qwen_finetuning,,Apache-2.0,qwen;fine-tuning;llm
616,rwkv_finetuning,Fine-tuning scripts for RWKV RNN models,"Tools designed for fine-tuning RWKV models, a type of RNN-based large language model, enabling customization and performance improvement on specific tasks.",AI3;AI3-02,fine_tuning,solver,Python,https://github.com/ssbuild/rwkv_finetuning,,Apache-2.0,rwkv;rnn;fine-tuning
617,SNELL,Sparse tuning method for low-memory LLM adaptation,Implementation of the SNELL method (NeurIPS 2024) for expanding sparse tuning to reduce memory usage during Large Language Model fine-tuning.,AI3;AI3-02,fine_tuning;peft,solver,Python,https://github.com/ssfgunner/SNELL,,MIT,sparse-tuning;memory-efficient;peft
618,xTuring,Framework for building and personalizing LLMs,"An easy-to-use framework for building, personalizing, and controlling LLMs, covering the pipeline from data pre-processing to fine-tuning open-source models.",AI3;AI3-02,fine_tuning;data_processing,framework,Python,https://github.com/stochasticai/xTuring,,Apache-2.0,llm-personalization;fine-tuning;framework
619,Simple-Trl-Training,Simplified DPO training wrapper for LLMs,"A lightweight tool based on the DPO (Direct Preference Optimization) algorithm for fine-tuning large language models, designed for ease of use.",AI3;AI3-02,alignment;dpo,solver,Python,https://github.com/sugarandgugu/Simple-Trl-Training,,None,dpo;alignment;fine-tuning
620,ChiMed-GPT,Chinese medical LLM training and alignment implementation,"Implementation for ChiMed-GPT, a Chinese medical large language model, including pipelines for pre-training, supervised fine-tuning (SFT), and RLHF on medical data.",AI3;AI3-02,fine_tuning;alignment;domain_adaptation,solver,,https://github.com/synlp/ChiMed-GPT,,MIT,medical-llm;sft;rlhf
621,Llama3.1-Finetuning,Fine-tuning toolkit for Llama 3.1 models,"Provides tools for full-parameter fine-tuning, LoRA, and QLoRA fine-tuning specifically optimized for the Llama 3.1 model family.",AI3;AI3-02,fine_tuning;peft,solver,Python,https://github.com/taishan1994/Llama3.1-Finetuning,,Apache-2.0,llama-3;lora;qlora
622,qlora-chinese-LLM,QLoRA fine-tuning for Chinese LLMs,"A tool for fine-tuning Chinese large language models (ChatGLM, Chinese-LLaMA-Alpaca, BELLE) using QLoRA (Quantized LoRA) for efficient adaptation.",AI3;AI3-02,fine_tuning;peft,solver,Python,https://github.com/taishan1994/qlora-chinese-LLM,,None,qlora;chinese-llm;fine-tuning
623,alpaca_eval,Automatic evaluator for instruction-following models,"A framework for automatic evaluation of instruction-following language models, providing a fast, cheap, and human-validated metric for model quality.",AI3;AI3-02,evaluation;quality_control,solver,Jupyter Notebook,https://github.com/tatsu-lab/alpaca_eval,,Apache-2.0,evaluation;llm-benchmark;instruction-following
624,alpaca_farm,Simulation framework for RLHF research,"A simulation framework designed to facilitate research in Reinforcement Learning from Human Feedback (RLHF) and alternatives by simulating human feedback, enabling method development without expensive data collection.",AI3;AI3-02,alignment;simulation,framework,Python,https://github.com/tatsu-lab/alpaca_farm,,Apache-2.0,rlhf;simulation;alignment
625,qlora-pipe,Pipeline parallel training script for QLoRA,"A training script enabling pipeline parallelism for Large Language Models, specifically optimized for QLoRA workflows to handle large models on limited hardware.",AI3;AI3-02,fine_tuning;peft,solver,Python,https://github.com/tdrussell/qlora-pipe,,MIT,pipeline-parallelism;qlora;training
626,unsloth-5090-multiple,Configuration and scripts for Unsloth on RTX 5090,Utilities and configuration scripts for running Unsloth (LLM training optimization tool) on multi-GPU setups involving RTX 5090 hardware.,AI3;AI3-02,fine_tuning;optimization,solver,Python,https://github.com/thad0ctor/unsloth-5090-multiple,,None,unsloth;hardware-optimization;fine-tuning
627,FinetuneGLMWithPeft,Simple LoRA fine-tuning implementation for ChatGLM-6B,"A lightweight implementation using the PEFT library to fine-tune the ChatGLM-6B model with LoRA, serving as a straightforward solver for this specific model.",AI3;AI3-02,fine_tuning;peft,solver,Python,https://github.com/thaumstrial/FinetuneGLMWithPeft,,None,chatglm;lora;peft
628,LoRD,Low-Rank adapter extraction tool,"A utility for extracting Low-Rank adapters (LoRA) from fully fine-tuned transformer models, enabling the conversion of full weights back into modular adapters.",AI3;AI3-02,model_processing;peft,solver,Jupyter Notebook,https://github.com/thomasgauthier/LoRD,,Apache-2.0,lora-extraction;adapter;transformers
629,KnowledgeablePromptTuning,Knowledgeable Prompt Tuning (KPT) implementation,"Implementation of Knowledgeable Prompt Tuning, a method to optimize prompts for pre-trained language models by incorporating external knowledge.",AI3;AI3-02,fine_tuning;prompt_tuning,solver,Python,https://github.com/thunlp/KnowledgeablePromptTuning,,None,prompt-tuning;kpt;nlp
630,Cherry_LLM,Self-data filtering tool for LLM instruction tuning,"A tool for filtering LLM instruction-tuning data using a perplexity-based difficulty score (Cherry Score), enabling data quality improvement without external models.",AI3;AI3-02,data_processing;quality_control,solver,Python,https://github.com/tianyi-lab/Cherry_LLM,,None,data-filtering;instruction-tuning;data-quality
631,Reflection_Tuning,Selective Reflection-Tuning implementation,"Implementation of Selective Reflection-Tuning, a method for recycling student-selected data to improve LLM instruction tuning performance.",AI3;AI3-02,fine_tuning;data_processing,solver,Python,https://github.com/tianyi-lab/Reflection_Tuning,,None,instruction-tuning;reflection-tuning;llm
632,alpaca-lora,Instruct-tune LLaMA on consumer hardware using LoRA,"A seminal tool for fine-tuning LLaMA models on consumer-grade hardware using Low-Rank Adaptation (LoRA), enabling widespread access to LLM instruction tuning.",AI3;AI3-02,fine_tuning;peft,solver,Jupyter Notebook,https://github.com/tloen/alpaca-lora,,Apache-2.0,lora;llama;fine-tuning
633,ICLR25-FSCA,Context-Alignment method for Time Series LLMs,Implementation of the Context-Alignment (FSCA) method to activate and enhance Large Language Model capabilities specifically for time series analysis tasks.,AI3;AI3-02,alignment;domain_adaptation,solver,Python,https://github.com/tokaka22/ICLR25-FSCA,,None,time-series;alignment;llm
634,axolotl-mobile-sensing,Framework for mobile sensor data extraction and ML,"A machine learning framework designed to extract and process accelerometric and gyroscopic data from mobile phones. (Note: Name collision with the popular LLM fine-tuning tool 'axolotl', but this is a distinct tool for sensor data).",IoT;Sensor_Analysis,data_processing;feature_extraction,framework,Python,https://github.com/tomasreimers/axolotl,,None,sensor-data;mobile-sensing;machine-learning
635,transformerlab-app,Desktop application for LLM and Diffusion model engineering,"An open-source desktop application that allows users to interact with, train, fine-tune, and evaluate large language models and diffusion models locally.",AI3;AI3-02,fine_tuning;evaluation;inference,platform,Python,https://github.com/transformerlab/transformerlab-app,,AGPL-3.0,gui;llm-training;local-inference
636,Unsloth,Optimized fine-tuning library for LLMs with significantly reduced VRAM usage and faster training speeds,"Unsloth is a lightweight and highly optimized library for fine-tuning Large Language Models (LLMs). It implements custom kernels and backpropagation logic to achieve up to 2x faster training and 70% less memory usage compared to standard Hugging Face implementations, supporting models like Llama, Mistral, and Qwen.",AI3;AI3-02,model_training;peft;optimization,library,Python,https://github.com/unslothai/unsloth,https://github.com/unslothai/unsloth,Apache-2.0,llm;fine-tuning;optimization;peft;lora
637,Unsloth Zoo,Utility library and dataset collection for the Unsloth fine-tuning ecosystem,"Unsloth Zoo provides supplementary utilities, data collators, and dataset preparation scripts designed to work seamlessly with the Unsloth library. It facilitates the setup of training pipelines for various LLM fine-tuning tasks.",AI3;AI3-02,data_processing;model_training,library,Python,https://github.com/unslothai/unsloth-zoo,https://github.com/unslothai/unsloth-zoo,LGPL-3.0,utils;datasets;fine-tuning
638,GLiNER,Generalist and lightweight model/library for zero-shot Named Entity Recognition,"GLiNER is a model and library capable of identifying any entity type using a bidirectional transformer encoder (BERT-like). It provides a practical alternative to traditional LLMs for information extraction tasks, offering high performance with lower resource requirements.",AI3;AI3-02,information_extraction;ner;inference,library,Python,https://github.com/urchade/GLiNER,https://github.com/urchade/GLiNER,Apache-2.0,ner;nlp;information-extraction;zero-shot
639,TextRL,Library for Reinforcement Learning with Human Feedback (RLHF) on text generation models,"TextRL is a Python library that implements RLHF pipelines compatible with Hugging Face Transformers. It allows users to fine-tune any text generation model using reinforcement learning techniques, supporting various reward models and environments.",AI3;AI3-02,alignment;rlhf;model_training,library,Python,https://github.com/voidful/TextRL,https://github.com/voidful/TextRL,MIT,rlhf;reinforcement-learning;nlp;alignment
640,transformers-qwen3-moe-fused,Fused Mixture-of-Experts (MoE) layer implementation for accelerated Qwen3 training,"This repository provides a highly optimized, fused implementation of the MoE layer for Qwen3 models. It is designed to be compatible with Hugging Face Transformers, LoRA, and Unsloth, enabling faster training and inference for MoE-based architectures.",AI3;AI3-02,model_training;optimization;acceleration,library,Python,https://github.com/woct0rdho/transformers-qwen3-moe-fused,https://github.com/woct0rdho/transformers-qwen3-moe-fused,Apache-2.0,moe;optimization;cuda;qwen
641,cycleformers,Library for cycle-consistency training of transformer models,"Cycleformers is a Python library that enables efficient cycle-consistency training (back-translation) for transformer models. It incorporates memory-efficient techniques like PEFT adapter switching, allowing for the training of larger models on limited hardware.",AI3;AI3-02,model_training;alignment;peft,library,Python,https://github.com/wrmthorne/cycleformers,https://github.com/wrmthorne/cycleformers,CC-BY-4.0,transformers;cycle-consistency;peft;training
642,Xtreme1,Multimodal data labeling and annotation platform for AI training,"Xtreme1 is an open-source platform for multimodal training data annotation. It supports 3D LiDAR point clouds, images, and LLM data, providing tools for data visualization, labeling, and management to accelerate AI model development.",AI3;AI3-02,data_processing;annotation;visualization,platform,TypeScript,https://github.com/xtreme1-io/xtreme1,https://docs.xtreme1.io/,Apache-2.0,annotation;labeling;lidar;multimodal;llm
643,LongQLoRA,Efficient context extension tool for Large Language Models using QLoRA,"A parameter-efficient fine-tuning tool designed to extend the context length of Large Language Models (LLMs) such as LLaMA. It utilizes QLoRA to reduce memory usage while maintaining performance, enabling the training of long-context models on consumer-grade hardware.",AI3;AI3-02,context_extension;fine_tuning;qlora,solver,Python,https://github.com/yangjianxin1/LongQLoRA,,None,llm;context-window;qlora;fine-tuning
644,Self-Instruct,Framework for aligning language models with self-generated instructions,"A seminal framework for generating synthetic instruction-following data by bootstrapping off a pre-trained language model. It enables the creation of large-scale instruction tuning datasets with minimal human annotation, widely used for aligning LLMs.",AI3;AI3-02,data_generation;instruction_tuning;alignment,solver,Python,https://github.com/yizhongw/self-instruct,,Apache-2.0,synthetic-data;instruction-tuning;alignment;llm
645,Chinese-LLaMA-Alpaca,Chinese-adapted LLaMA and Alpaca LLM training and deployment suite,"A comprehensive project providing Chinese vocabulary expansion, LoRA fine-tuning scripts, and merged model weights for LLaMA and Alpaca. It serves as a foundational platform for training and deploying Chinese-capable LLMs in research and industry.",AI3;AI3-02,model_training;vocabulary_expansion;fine_tuning,platform,Python,https://github.com/ymcui/Chinese-LLaMA-Alpaca,https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki,Apache-2.0,chinese-llm;llama;lora;fine-tuning
646,Chinese-LLaMA-Alpaca-2,Second generation Chinese LLaMA-2 & Alpaca-2 training suite with long context support,"The successor to Chinese-LLaMA-Alpaca, targeting LLaMA-2. It includes tools for training, quantization, and inference, with specific support for 64K long-context models, serving as a key toolchain for Chinese LLM research.",AI3;AI3-02,model_training;long_context;fine_tuning,platform,Python,https://github.com/ymcui/Chinese-LLaMA-Alpaca-2,https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki,Apache-2.0,llama-2;long-context;chinese-llm;peft
647,qwen2-sft,Fine-tuning and inference toolkit specifically for Qwen model family,A specialized toolkit for Supervised Fine-Tuning (SFT) and LoRA adaptation of the Qwen (Qwen1.5/Qwen2) model series. It streamlines the process of adapting Qwen models for downstream tasks using transformers and peft libraries.,AI3;AI3-02,fine_tuning;inference;model_adaptation,solver,Python,https://github.com/yongzhuo/qwen2-sft,,Apache-2.0,qwen;sft;lora;fine-tuning
648,Olympus,Universal task routing model for computer vision tasks,"A universal task router that directs input queries to appropriate vision experts or models. It serves as a meta-tool for managing and orchestrating diverse computer vision tasks, facilitating multi-task learning and model composition.",AI3;AI3-02,task_routing;model_orchestration;computer_vision,solver,Python,https://github.com/yuanze-lin/Olympus,,None,task-routing;computer-vision;model-composition
649,ImageReward,Human preference evaluation metric for text-to-image generation,"A comprehensive text-to-image human preference reward model. It serves as a scientific metric tool to evaluate and align generative models with human aesthetics and instruction following, addressing the lack of robust evaluation metrics in visual generation.",AI3;AI3-02,evaluation;reward_modeling;alignment,solver,Python,https://github.com/zai-org/ImageReward,,Apache-2.0,reward-model;rlhf;evaluation-metric;text-to-image
650,VisionReward,Fine-grained multi-dimensional preference learning for visual generation,"An advanced reward modeling tool for image and video generation that evaluates outputs across multiple dimensions. It enables fine-grained alignment of visual generative models, supporting research in multimodal preference optimization.",AI3;AI3-02,evaluation;reward_modeling;alignment,solver,Python,https://github.com/zai-org/VisionReward,,Apache-2.0,reward-model;video-generation;preference-learning
651,LLaMA-LoRA-Tuner,GUI tool for fine-tuning LLaMA models using LoRA,"A user-friendly interface (UI) for fine-tuning LLaMA and other LLMs using LoRA. It simplifies the parameter configuration and training process, making advanced fine-tuning techniques accessible for research and experimentation without deep coding requirements.",AI3;AI3-02,fine_tuning;workflow_management;ui_tool,platform,Python,https://github.com/zetavg/LLaMA-LoRA-Tuner,,None,gui;lora;fine-tuning;llama
652,lmms-finetune,Minimalist codebase for fine-tuning Large Multimodal Models,"A streamlined and extensible codebase for fine-tuning various Large Multimodal Models (LMMs) such as LLaVA, Qwen-VL, and Phi3-V. It supports multiple architectures and provides a unified interface for multimodal instruction tuning.",AI3;AI3-02,multimodal_fine_tuning;instruction_tuning;model_adaptation,library,Python,https://github.com/zjysteven/lmms-finetune,,Apache-2.0,multimodal;fine-tuning;llava;qwen-vl
653,text-extract-api,API for extracting and cleaning text from various document formats including PDFs for dataset creation,"A robust tool for parsing and extracting text from documents (PDF, Word, PPTX), essential for building scientific corpora from literature. It includes features for PII removal and structured data conversion.",AI3;AI3-03,data_extraction;cleaning;preprocessing,service,Python,https://github.com/CatchTheTornado/text-extract-api,,MIT,ocr;pdf-parsing;dataset-creation;pii-removal
654,text-dedup,All-in-one text de-duplication tool for NLP datasets,"A comprehensive library for deduplicating text datasets using methods like MinHash and SimHash, widely used in preparing training corpora for Large Language Models.",AI3;AI3-03,deduplication;cleaning;preprocessing,workflow,Python,https://github.com/ChenghaoMou/text-dedup,,Apache-2.0,deduplication;minhash;simhash;nlp;dataset-cleaning
655,PMLB,Python interface for a curated repository of benchmark datasets for evaluating ML algorithms,"PMLB (Penn Machine Learning Benchmarks) provides a standardized interface to access a large collection of curated benchmark datasets, facilitating the evaluation and comparison of supervised machine learning algorithms in scientific research.",AI3;AI3-03,benchmarking;data_loading;evaluation,library,Python,https://github.com/EpistasisLab/pmlb,https://epistasislab.github.io/pmlb/,MIT,benchmark;datasets;machine-learning;evaluation
656,paper-qa,High accuracy RAG for answering questions from scientific documents with citations,"A specialized Retrieval-Augmented Generation (RAG) tool designed for scientific workflows. It ingests scientific papers (PDFs/text) and provides answers to queries with precise citations, enabling efficient literature review and information extraction.",AI3;AI3-03,information_retrieval;question_answering;literature_review,solver,Python,https://github.com/Future-House/paper-qa,,Apache-2.0,rag;scientific-literature;citations;llm
657,ccNetViz,Lightweight JavaScript library for visualization of large-scale biological network graphs,"A high-performance WebGL-based library developed by Helikar Lab for visualizing large-scale networks, specifically tailored for biological systems and complex network analysis.",AI3;AI3-03,visualization;network_analysis,library,JavaScript,https://github.com/HelikarLab/ccNetViz,http://helikarlab.github.io/ccNetViz/,None,visualization;network-biology;webgl;graphs
658,OneCite,"Toolkit to parse, complete, and format academic references","An intelligent toolkit designed to automate the processing of academic references. It supports parsing, completion, and formatting, which is essential for cleaning and structuring bibliographic data in scientific corpora.",AI3;AI3-03,metadata_processing;cleaning;reference_management,library,Python,https://github.com/HzaCode/OneCite,,MIT,citations;bibliography;academic-references;parsing
659,Seave,Web platform for filtering and annotating genetic variants,"Seave is a web platform that enables genetic variants to be easily filtered and annotated with in silico pathogenicity prediction scores and annotations from popular disease databases. It stores genomic variation of all types and sizes, allowing filtering for specific inheritance patterns, quality values, allele frequencies, and gene lists.",AI3;AI3-03,variant_filtering;genomic_annotation,platform,HTML,https://github.com/KCCG/seave,,NOASSERTION,genomics;variant-filtering;bioinformatics
660,SmCCNet,Canonical correlation analysis for regulatory network discovery,A canonical correlation analysis based method for discovering (quantitative) trait-specific heterogeneous regulatory networks. It integrates multi-omics data to identify regulatory relationships.,AI3;AI3-03,network_analysis;regulatory_network_inference,library,R,https://github.com/KechrisLab/SmCCNet,,None,bioinformatics;regulatory-networks;multi-omics
661,NeMo Curator,Scalable data pre-processing and curation toolkit for LLMs,"A scalable data pre-processing and curation toolkit for Large Language Models (LLMs). It provides modules for data download, text extraction, cleaning, quality filtering, and deduplication, essential for training scientific domain models.",AI3;AI3-03,dataset_curation;deduplication;data_cleaning,workflow,Python,https://github.com/NVIDIA-NeMo/Curator,,Apache-2.0,llm;data-curation;nlp
662,nougat-latex-ocr,Fine-tuning and evaluation codebase for Nougat scientific OCR models,"Codebase for fine-tuning and evaluating Nougat-based image-to-LaTeX generation models. Nougat is specialized for parsing scientific documents, converting PDFs to Markdown with LaTeX math support.",AI3;AI3-03,ocr;scientific_document_parsing,solver,Python,https://github.com/NormXU/nougat-latex-ocr,,Apache-2.0,ocr;latex;scientific-papers
663,AfterQC,"Automatic filtering, trimming, and quality control for FASTQ data","Automatic Filtering, Trimming, Error Removing and Quality Control for fastq data. It is designed to process high-throughput sequencing data efficiently.",AI3;AI3-03,quality_control;read_trimming,solver,Python,https://github.com/OpenGene/AfterQC,,MIT,bioinformatics;fastq;quality-control
664,fastp,Ultra-fast all-in-one FASTQ preprocessor,"An ultra-fast all-in-one FASTQ preprocessor that provides quality control, adapter trimming, filtering, splitting, and merging capabilities for sequencing data.",AI3;AI3-03,quality_control;adapter_trimming;preprocessing,solver,C++,https://github.com/OpenGene/fastp,,MIT,bioinformatics;fastq;ngs
665,PteRedactyl,PII redaction tool for clinical free-text,A python module for redaction of personally identifiable information (PII) in clinical free-text. It builds on Presidio and is designed for de-identifying medical records for research.,AI3;AI3-03,pii_redaction;clinical_data_cleaning,library,Python,https://github.com/SETT-Centre-Data-and-AI/PteRedactyl,,None,clinical-nlp;de-identification;medical-data
666,CCNet-Pure-Pytorch,Pure PyTorch implementation of Criss-Cross Attention for semantic segmentation,"A faster and more precise implementation of Criss-Cross Attention (2D & 3D) for Semantic Segmentation in pure PyTorch, serving as a solver for computer vision tasks.",AI3,semantic_segmentation;model_implementation,solver,Python,https://github.com/Serge-weihao/CCNet-Pure-Pytorch,,MIT,pytorch;semantic-segmentation;attention-mechanism;computer-vision
667,OmniStyle,Data filtering tool for high-quality style transfer datasets,"Official implementation for filtering high-quality style transfer data at scale, providing tools to curate and clean image datasets for model training.",AI3;AI3-03,data_filtering;dataset_curation,solver,Python,https://github.com/StyleX-Research/OmniStyle,,None,style-transfer;data-filtering;computer-vision
668,awesome-semantic-segmentation-pytorch,Collection of semantic segmentation model implementations in PyTorch,"A comprehensive library providing implementations for various semantic segmentation models (FCN, PSPNet, Deeplabv3, etc.) on PyTorch, serving as a reference solver.",AI3,semantic_segmentation;model_implementation,solver,Python,https://github.com/Tramac/awesome-semantic-segmentation-pytorch,,Apache-2.0,pytorch;semantic-segmentation;deep-learning;computer-vision
669,MLM_Filter,Multimodal language model based data filtering tool,"Official implementation of 'Finetuned Multimodal Language Models are High-Quality Image-Text Data Filters', providing a solver for cleaning and filtering multimodal datasets.",AI3;AI3-03,data_filtering;multimodal_learning,solver,Python,https://github.com/Victorwz/MLM_Filter,,MIT,data-cleaning;multimodal;llm;image-text
670,dense_parser,Dependency parser using Head Selection,"Implementation of the DeNSe parser for Dependency Parsing as Head Selection, serving as a solver for NLP structure prediction tasks.",AI3,dependency_parsing;nlp,solver,Lua,https://github.com/XingxingZhang/dense_parser,,NOASSERTION,nlp;dependency-parsing;deep-learning
671,pydoxtools,Library for data extraction from unstructured documents,"A library to extract information from unstructured data using AI techniques, supporting customizable pipelines for data ingestion and cleaning in scientific workflows.",AI3;AI3-03,data_extraction;data_cleaning,library,Python,https://github.com/Xyntopia/pydoxtools,https://pydoxtools.readthedocs.io,MIT,etl;unstructured-data;pdf-extraction;pipeline
672,CCNet,Palmprint recognition model implementation,"Implementation of Comprehensive Competition Mechanism in Palmprint Recognition (IEEE TIFS), serving as a solver for biometric identification tasks.",AI3,biometrics;image_recognition,solver,Python,https://github.com/Zi-YuanYang/CCNet,,None,palmprint-recognition;computer-vision;biometrics
673,trafilatura,Web scraping and text extraction tool,"A Python and command-line tool to gather text and metadata from the Web, facilitating the creation of domain corpora through crawling, scraping, and extraction.",AI3;AI3-03,web_scraping;text_extraction;corpus_creation,library,Python,https://github.com/adbar/trafilatura,https://trafilatura.readthedocs.io,Apache-2.0,scraping;text-extraction;crawler;nlp
674,deidentify,Tool for identifying and anonymizing personal information,"A simple yet powerful tool for identifying and anonymizing personal information (PII) in various formats, essential for data cleaning in scientific corpora.",AI3;AI3-03,pii_removal;data_anonymization,solver,Go,https://github.com/aliengiraffe/deidentify,,MIT,pii;anonymization;data-privacy;gdpr
675,dolma,Data curation tools for OLMo pre-training data,"A library and toolkit for generating, inspecting, and processing large-scale pre-training data (OLMo), including deduplication and filtering pipelines.",AI3;AI3-03,dataset_curation;pretraining_data;deduplication,workflow,Python,https://github.com/allenai/dolma,,Apache-2.0,llm;dataset-curation;nlp;pretraining
676,duplodocus,Exact and MinHash deduplication tool for text datasets,"Tooling for performing exact and MinHash-based deduplication on large-scale text datasets, a critical step in preparing scientific corpora for model training.",AI3;AI3-03,deduplication;data_cleaning,solver,Rust,https://github.com/allenai/duplodocus,,Apache-2.0,deduplication;minhash;nlp;rust
677,deepfabric,Platform for dataset curation and model training,"A tool to curate high-quality datasets, train, evaluate, and ship models, providing an end-to-end workflow for AI model development.",AI3;AI3-03,dataset_curation;ml_workflow,platform,Python,https://github.com/always-further/deepfabric,,Apache-2.0,dataset-management;mlops;training-pipeline
678,consimilo,Clojure library for similarity querying on large datasets,"A library for querying large datasets based on similarity (LSH/Simhash), useful for deduplication and near-duplicate detection in data pipelines.",AI3;AI3-03,similarity_search;deduplication,library,Clojure,https://github.com/andrewmcloud/consimilo,,Apache-2.0,clojure;lsh;simhash;deduplication
679,semlib,Library for building LLM-powered data processing pipelines,"A library to build data processing and analysis pipelines that leverage Large Language Models, facilitating complex data transformation and cleaning tasks.",AI3;AI3-03,data_processing;pipeline_construction,library,Python,https://github.com/anishathalye/semlib,,MIT,llm;data-pipeline;semantic-processing
680,pii-lib,PII detection and redaction library for code datasets,"A library designed for the BigCode project to detect and redact Personally Identifiable Information (PII) specifically in code datasets, supporting privacy compliance in LLM training.",AI3;AI3-03,pii_redaction;data_cleaning,library,Python,https://github.com/bigcode-project/pii-lib,,Apache-2.0,pii;redaction;code-dataset;llm
681,BigScience Data Preparation,Data sourcing and cleaning pipeline for the ROOTS corpus,"A collection of scripts and notebooks used for sourcing, processing, and cleaning the BigScience ROOTS corpus, a large-scale multilingual dataset for training open science language models.",AI3;AI3-03,data_cleaning;corpus_preparation,workflow,Jupyter Notebook,https://github.com/bigscience-workshop/data-preparation,,Apache-2.0,bigscience;roots-corpus;data-cleaning;nlp
682,pdfdiff,Tool to inspect text differences between PDF files,"A command-line tool that allows users to compare the text content of two PDF files, useful for verifying data extraction fidelity or tracking changes in scientific documents.",AI3;AI3-03,pdf_processing;quality_control,solver,Python,https://github.com/cascremers/pdfdiff,,None,pdf;diff;text-extraction;cli
683,PDFeXpress,PDF manipulation and extraction tool,"A tool to handle various PDF operations such as merging, splitting, and extracting images and text, facilitating the preprocessing of PDF documents for corpus creation.",AI3;AI3-03,pdf_processing;text_extraction,solver,Python,https://github.com/chianjin/PDFeXpress,,AGPL-3.0,pdf;extraction;preprocessing
684,Cocoindex,Incremental data transformation framework for AI,"A high-performance framework for data transformation in AI pipelines, supporting incremental processing to efficiently handle large-scale datasets.",AI3;AI3-03,data_transformation;pipeline_orchestration,framework,Rust,https://github.com/cocoindex-io/cocoindex,,Apache-2.0,data-pipeline;incremental-processing;etl;rust
685,text_dedup,High-performance text deduplication toolkit,"A toolkit designed for efficient text deduplication, essential for cleaning large language model training corpora to remove redundant data.",AI3;AI3-03,deduplication;data_cleaning,solver,C++,https://github.com/conanhujinming/text_dedup,,MIT,deduplication;nlp;corpus-cleaning
686,pdf2htmlEX,High-fidelity PDF to HTML converter,"A tool that converts PDF documents to HTML while preserving layout and typography, widely used in scientific literature parsing pipelines to extract structured data.",AI3;AI3-03,pdf_processing;format_conversion,solver,HTML,https://github.com/coolwanglu/pdf2htmlEX,,NOASSERTION,pdf-to-html;parsing;document-processing
687,marimba,Framework for FAIR scientific image datasets,"A Python framework developed by CSIRO for structuring, processing, packaging, and distributing scientific image datasets in accordance with FAIR principles.",AI3;AI3-03,image_processing;dataset_management,framework,Python,https://github.com/csiro-fair/marimba,,NOASSERTION,fair-data;scientific-imaging;csiro
688,Lilac,Data curation and exploration tool for LLMs,"A tool for curating, filtering, and exploring datasets for Large Language Models, offering features for PII detection, quality filtering, and data visualization.",AI3;AI3-03,data_curation;pii_detection;quality_control,platform,Python,https://github.com/databricks/lilac,https://lilacml.com,Apache-2.0,data-curation;llm;visualization;data-cleaning
689,undatum,CLI tool for data conversion and processing,"A command-line utility for converting between various data formats (CSV, NDJSON, BSON, XML) and performing basic data processing tasks, useful in data pipelines.",AI3;AI3-03,format_conversion;data_processing,solver,Python,https://github.com/datacoon/undatum,,MIT,cli;data-conversion;etl
690,Haystack,AI orchestration framework for LLM pipelines,"An orchestration framework to build LLM applications, including components for data ingestion, preprocessing, cleaning, and vectorization, suitable for managing scientific corpora.",AI3;AI3-03,pipeline_orchestration;data_ingestion;preprocessing,framework,MDX,https://github.com/deepset-ai/haystack,https://haystack.deepset.ai,Apache-2.0,rag;llm;pipeline;nlp
691,dockstring,Package for molecular docking benchmarks,"A Python package that facilitates molecular docking tasks, providing curated datasets and realistic benchmarks for drug discovery research.",AI3;AI3-03,molecular_docking;drug_discovery,library,Python,https://github.com/dockstring/dockstring,,Apache-2.0,molecular-docking;drug-discovery;benchmark;chemistry
692,docling-parse,PDF parsing and text extraction tool,"A package for extracting text and coordinates from programmatic PDFs, part of the Docling ecosystem for document processing and parsing.",AI3;AI3-03,pdf_parsing;text_extraction,library,C++,https://github.com/docling-project/docling-parse,,MIT,pdf;parsing;document-processing
693,LSHR,Locality Sensitive Hashing (LSH) library for R,"An R implementation of Locality Sensitive Hashing (LSH) for finding similar items in large datasets, commonly used for deduplication of scientific corpora or genomic sequences.",AI3;AI3-03,deduplication;similarity_search,library,R,https://github.com/dselivanov/LSHR,,NOASSERTION,lsh;deduplication;r-package;similarity-search
694,luftdatenpumpe,Tool for acquiring and processing air quality data,"A pipeline tool to acquire, filter, process, and visualize live and historical air quality data from sources like Sensor.Community and OpenAQ, supporting time-series storage and reverse geocoding.",AI3;AI3-03,data_acquisition;data_processing;environmental_science,workflow,Python,https://github.com/earthobservations/luftdatenpumpe,,AGPL-3.0,air-quality;data-pipeline;earth-science;etl
695,datasketch,Probabilistic data structures for big data processing,"A Python library providing implementations of MinHash, LSH, LSH Forest, and HyperLogLog for processing and deduplicating massive datasets, widely used in scientific corpus cleaning.",AI3;AI3-03,deduplication;similarity_estimation,library,Python,https://github.com/ekzhu/datasketch,https://ekzhu.github.io/datasketch/,MIT,minhash;lsh;deduplication;big-data
696,minhash-lsh,MinHash LSH implementation in Go,A Go library implementing MinHash and Locality Sensitive Hashing (LSH) for efficient similarity search and deduplication in large-scale data processing pipelines.,AI3;AI3-03,deduplication;similarity_search,library,Go,https://github.com/ekzhu/minhash-lsh,,MIT,minhash;lsh;go;deduplication
697,Evidently,ML and LLM observability and data quality framework,"An open-source framework to evaluate, test, and monitor ML models and data pipelines, providing metrics for data drift, data quality, and model performance, essential for maintaining scientific datasets and models.",AI3;AI3-03,quality_control;data_drift_detection;model_evaluation,platform,Jupyter Notebook,https://github.com/evidentlyai/evidently,https://docs.evidentlyai.com/,Apache-2.0,data-quality;mlops;observability;drift-detection
698,bitext-lexind,Unsupervised bitext mining and lexicon induction pipeline,"A research tool for inducing high-quality bilingual lexicons and mining bitexts from monolingual corpora using unsupervised methods, useful for constructing parallel scientific corpora.",AI3;AI3-03,corpora_mining;alignment;nlp,workflow,Python,https://github.com/facebookresearch/bitext-lexind,,MIT,nlp;bitext-mining;lexicon-induction;alignment
699,Nougat,Neural Optical Understanding for Academic Documents,"A visual transformer model and tool designed to convert scientific PDF documents into structured Markdown, specifically handling mathematical formulas and academic layouts.",AI3;AI3-03,data_extraction;ocr;pdf_processing,solver,Python,https://github.com/facebookresearch/nougat,https://facebookresearch.github.io/nougat/,MIT,ocr;pdf-to-markdown;scientific-papers;transformer
700,Moira,Quality filtering tool for metagenomic amplicon sequences,"A tool for accurate quality filtering of metagenomic amplicon sequences, reducing errors in microbiome data analysis.",AI3;AI3-03,quality_control;bioinformatics;filtering,solver,Python,https://github.com/fpusan/moira,,NOASSERTION,metagenomics;bioinformatics;quality-control;amplicon
701,OCRmyPDF,Tool to add OCR text layers to scanned PDFs,"A pipeline tool that adds an OCR text layer to scanned PDF files, enabling text search and extraction, widely used in digitizing scientific literature and archives.",AI3;AI3-03,data_extraction;ocr;digitization,solver,Python,https://github.com/fritz-hh/OCRmyPDF,https://ocrmypdf.readthedocs.io/,None,ocr;pdf;text-extraction;archiving
702,pdfocr,Ruby script for PDF OCR using Cuneiform,"A wrapper tool to add text layers to PDF files using the Cuneiform OCR software, facilitating text extraction from scanned documents.",AI3;AI3-03,data_extraction;ocr,solver,Ruby,https://github.com/gkovacs/pdfocr,,MIT,ocr;pdf;ruby;text-extraction
703,Datatrove,Large-scale data processing library for LLM training,"A platform-agnostic library providing customizable pipeline processing blocks for filtering, deduplicating, and extracting data, specifically designed for preparing large-scale datasets for LLM training.",AI3;AI3-03,data_pipeline;deduplication;filtering,workflow,Python,https://github.com/huggingface/datatrove,,Apache-2.0,data-processing;llm;pipeline;deduplication
704,hydrobr,R interface for Brazilian National Water Agency data,"An R package to download, filter, and perform quality checks on hydrological data from the Brazilian National Water Agency (ANA), facilitating hydrological research and analysis.",AI3;AI3-03,data_acquisition;quality_control;hydrology,library,R,https://github.com/hydroversebr/hydrobr,https://hydroversebr.github.io/hydrobr/,GPL-3.0,hydrology;r-package;data-access;earth-science
705,WordCab PII,PII/PHI/PCI redaction models based on GLiNER architecture for data cleaning,"A collection of state-of-the-art PII (Personally Identifiable Information) redaction models designed to clean sensitive data from corpora. It utilizes the GLiNER architecture to detect and redact entities, facilitating the preparation of safe scientific and medical datasets.",AI3;AI3-03,data_cleaning;pii_redaction,library,Python,https://github.com/info-wordcab/wordcab-pii,,Apache-2.0,pii-redaction;data-cleaning;nlp;gliner
706,FiftyOne Image Deduplication Plugin,Plugin for FiftyOne to remove exact and approximate duplicates from image datasets,"A plugin for the FiftyOne computer vision toolset that provides functionality to detect and remove duplicate images from datasets. It supports both exact and approximate deduplication, essential for cleaning scientific image corpora.",AI3;AI3-03,deduplication;data_cleaning,library,Python,https://github.com/jacobmarks/image-deduplication-plugin,,MIT,deduplication;computer-vision;data-cleaning;fiftyone
707,LLM Corpus Quality,Tool for cleaning and quality assessment of large model pre-training corpora,"A toolkit designed for the pre-processing of large language model (LLM) corpora. It includes functions for rule-based cleaning, sensitive word filtering, advertisement filtering, deduplication, and quality assessment, specifically tailored for Chinese and general text data.",AI3;AI3-03,data_cleaning;quality_control;deduplication,library,Java,https://github.com/jiangnanboy/llm_corpus_quality,,MIT,corpus-cleaning;data-quality;llm;preprocessing
708,Arxiv Parser,Tool to filter and parse publications from arXiv for corpus creation,A basic tool utilizing the arXiv API to filter and retrieve the latest publications. It assists researchers in creating scientific corpora by automating the collection of papers based on specific criteria.,AI3;AI3-03,data_acquisition;literature_mining,library,Python,https://github.com/katjaschwarz/arxiv_parser,,MIT,arxiv;data-mining;literature-review
709,dpsprep,DJVU to PDF converter preserving OCR text and metadata for scientific documents,A Python utility that converts DJVU files to PDF format while preserving the original OCR text layer and bookmark metadata (such as Table of Contents). This is particularly useful for digitizing and processing legacy scientific literature for downstream AI tasks.,AI3;AI3-03,data_preparation;format_conversion;ocr_handling,solver,Python,https://github.com/kcroker/dpsprep,,NOASSERTION,djvu;pdf;ocr;document-conversion
710,MarieAI,Complex data extraction and orchestration framework for unstructured documents,"A framework designed for processing unstructured documents, integrating AI-powered pipelines (GenAI, LLM, VLLM) for tasks like document cleanup, OCR, classification, and NER. Useful for creating scientific corpora from raw documents.",AI3;AI3-03,data_parsing,workflow,Python,https://github.com/marieai/marie-ai,,MIT,ocr;document-processing;pipeline;llm
711,go-trafilatura,Go port of the Trafilatura library for web text extraction,"A Go implementation of the Trafilatura library, designed to extract text and metadata from web pages. Essential for building large-scale domain corpora from web sources.",AI3;AI3-03,data_extraction,library,HTML,https://github.com/markusmobius/go-trafilatura,,Apache-2.0,web-scraping;text-extraction;corpus-creation
712,TICCL,Text-Induced Corpus Clean-up tool,"A tool for cleaning and correcting text corpora, specifically handling spelling variations and normalization. Useful for preparing high-quality NLP datasets.",AI3;AI3-03,data_cleaning,solver,Python,https://github.com/martinreynaert/TICCL,,GPL-3.0,corpus-cleaning;nlp;normalization
713,Juicer,Web API for extracting text and metadata from HTML pages,"A Scala-based tool for extracting main text, metadata, and named entities from HTML articles. Used for gathering data for scientific corpora.",AI3;AI3-03,data_extraction,service,Scala,https://github.com/matth/juicer,,MIT,text-extraction;html-parsing;corpus-creation
714,LSH,Locality Sensitive Hashing using MinHash for near-duplicate detection,A Python/Cython implementation of MinHash LSH to detect near-duplicate text documents. Critical for deduplicating large scientific corpora.,AI3;AI3-03,deduplication,library,Python,https://github.com/mattilyra/LSH,,MIT,lsh;deduplication;minhash;text-mining
715,prok-quality,Workflow for assessing the quality of prokaryotic genomes,"A Nextflow pipeline for filtering, dereplication, and quality assessment of prokaryotic genomes. Specifically designed for bioinformatics data processing.",AI3;AI3-03,quality_control,workflow,Nextflow,https://github.com/metashot/prok-quality,,GPL-3.0,bioinformatics;genome-assembly;quality-control;nextflow
716,ARXGEN,Scripts to parse arXiv documents for NLP tasks,"A set of scripts from Microsoft to parse and process arXiv LaTeX source files, extracting figures, tables, and text for training NLP models.",AI3;AI3-03,data_parsing,workflow,Python,https://github.com/microsoft/ARXGEN,,MIT,arxiv;latex-parsing;nlp;corpus-creation
717,NGSQCToolkit,Toolkit for quality check and filtering of NGS data,A toolkit for quality control and filtering of Next Generation Sequencing (NGS) data from Roche and Illumina platforms. Essential for bioinformatics data preprocessing.,AI3;AI3-03,quality_control,solver,Perl,https://github.com/mjain-lab/NGSQCToolkit,http://www.nipgr.res.in/ngsqctoolkit.html,None,ngs;bioinformatics;quality-control;filtering
718,pdf2json,Converts binary PDF to JSON and text,"A tool to convert PDF documents into JSON format, enabling server-side processing and text extraction. Widely used in pipelines to parse scientific literature.",AI3;AI3-03,data_parsing,library,Java,https://github.com/modesty/pdf2json,,NOASSERTION,pdf-parsing;text-extraction;json
719,comparable-text-miner,Miner for comparable Arabic-English documents and corpus processing,"A tool for mining comparable documents, performing morphological analysis, POS tagging, and corpus cleaning/alignment. Useful for creating multilingual scientific corpora.",AI3;AI3-03,data_alignment,solver,Python,https://github.com/motazsaad/comparable-text-miner,,Apache-2.0,text-mining;nlp;corpus-alignment;arabic
720,MinerU,Transforms complex documents like PDFs into LLM-ready markdown/JSON,"A comprehensive tool for extracting content from complex documents (PDFs, etc.) and converting them into clean Markdown or JSON formats suitable for LLM training and RAG workflows.",AI3;AI3-03,data_parsing,solver,Python,https://github.com/opendatalab/MinerU,,AGPL-3.0,pdf-parsing;llm-data;markdown-conversion;rag
721,MinerU-HTML,SLM-powered HTML main content extractor,"A tool that uses Small Language Models (SLM) to extract main content from HTML pages, outputting clean HTML bodies. Designed for deep research agents and training data generation.",AI3;AI3-03,data_extraction,solver,HTML,https://github.com/opendatalab/MinerU-HTML,,Apache-2.0,html-extraction;web-scraping;slm
722,open-semantic-etl,"ETL tools for file crawling, text extraction, and content analysis","A Python-based ETL toolkit for processing documents (text extraction, OCR) and performing content analysis (NER, Entity Extraction). Used to enrich data for search indices and knowledge graphs.",AI3;AI3-03,data_processing,workflow,Python,https://github.com/opensemanticsearch/open-semantic-etl,,GPL-3.0,etl;ocr;ner;text-extraction
723,open-semantic-search,Semantic Search Engine and Text Mining platform,"An integrated research tool for searching and analyzing large document collections. Combines ETL, OCR, NER, and a search UI to facilitate semantic exploration of scientific or unstructured data.",AI3;AI3-03,data_analysis,platform,Shell,https://github.com/opensemanticsearch/open-semantic-search,,GPL-3.0,semantic-search;text-mining;knowledge-graph
724,modis_restservice_qc_filter_Python,Access and quality filter MODIS data,A tool from ORNL DAAC to access MODIS web services and perform quality filtering on the retrieved earth science data.,AI3;AI3-03,quality_control,library,Jupyter Notebook,https://github.com/ornldaac/modis_restservice_qc_filter_Python,,NOASSERTION,earth-science;modis;quality-control;data-access
725,Phileas,Engine for PII and PHI redaction and de-identification,A configuration-based engine for identifying and redacting sensitive information (PII/PHI) from text data. It supports various filter strategies and is essential for cleaning research corpora containing sensitive human data.,AI3-03;AI3,pii_redaction;data_cleaning,solver,Java,https://github.com/philterd/phileas,,Apache-2.0,pii-redaction;de-identification;nlp
726,Philter,Command-line tool and library for text redaction,A tool designed to redact Personally Identifiable Information (PII) and Protected Health Information (PHI) from text. It serves as a component in data cleaning pipelines for preparing privacy-compliant datasets.,AI3-03;AI3,pii_redaction;data_cleaning,solver,CSS,https://github.com/philterd/philter,,Apache-2.0,redaction;privacy;data-cleaning
727,pvanalytics,Quality control and feature labeling for photovoltaic data,"A library providing functions for quality control, filtering, and feature labeling of data from photovoltaic energy systems. It supports scientific analysis of energy production data through rigorous data cleaning and validation methods.",AI3-03;AI3,quality_control;filtering;feature_extraction,library,Python,https://github.com/pvlib/pvanalytics,https://pvanalytics.readthedocs.io/,MIT,photovoltaic;quality-control;energy-data
728,FastSketchLSH,High-performance LSH-based deduplication for large text corpora,"A C++ implementation of FastSketch and MinHash-based Jaccard estimators using Locality Sensitive Hashing (LSH). It is designed to efficiently deduplicate extremely large text corpora, a critical step in training large language models.",AI3-03;AI3,deduplication;hashing,library,C++,https://github.com/pzcddm/FastSketchLSH,,MIT,deduplication;lsh;minhash;nlp
729,Filtlong,Quality filtering tool for long-read sequencing data,"A tool for filtering long sequencing reads (e.g., Nanopore, PacBio) based on quality and length. It is essential for quality control in genomics data pipelines to ensure high-quality input for downstream assembly or analysis.",AI3-03;AI3,quality_control;filtering,solver,C++,https://github.com/rrwick/Filtlong,,GPL-3.0,bioinformatics;long-reads;quality-control
730,docconv,Library for converting documents to plain text,"A Go library that converts various document formats (PDF, DOCX, HTML, etc.) into plain text. It is widely used in data ingestion pipelines to extract raw text from heterogeneous document sources for NLP tasks.",AI3-03;AI3,document_parsing;text_extraction,library,Go,https://github.com/sajari/docconv,,MIT,document-conversion;pdf-parsing;text-extraction
731,openredaction,Local PII detection and redaction library,"A TypeScript library for detecting and redacting Personally Identifiable Information (PII) locally. It provides high-performance, privacy-preserving data cleaning capabilities for text processing pipelines.",AI3-03;AI3,pii_redaction;data_cleaning,library,TypeScript,https://github.com/sam247/openredaction,,MIT,pii;redaction;privacy
732,doc_redaction,GUI tool for document redaction,"A Python-based tool with a graphical interface for redacting sensitive information from PDF, Word, and Excel files. It facilitates the manual or semi-automated cleaning of document datasets.",AI3-03;AI3,pii_redaction;data_cleaning,solver,Python,https://github.com/seanpedrick-case/doc_redaction,https://huggingface.co/spaces/seanpedrickcase/document_redaction,None,redaction;document-processing;gui
733,gaoya,Locality Sensitive Hashing (LSH) library in Rust,"A Rust implementation of Locality Sensitive Hashing (LSH) algorithms, including MinHash and SimHash. It is a core building block for developing high-performance deduplication and similarity search tools for large-scale datasets.",AI3-03;AI3,deduplication;hashing,library,Rust,https://github.com/serega/gaoya,,MIT,lsh;minhash;deduplication;rust
734,Text-file-to-handwritten-pdf-file,Synthetic handwritten data generator,A tool that converts digital text files into simulated handwritten PDF documents. It is useful for generating synthetic training data for Optical Character Recognition (OCR) and handwriting analysis models.,AI3-03;AI3,data_synthesis;data_augmentation,solver,Python,https://github.com/sharanya02/Text-file-to-handwritten-pdf-file,,MIT,synthetic-data;ocr;handwriting-generation
735,dupandas,Flexible deduplication for pandas DataFrames,A Python package designed for performing deduplication on pandas DataFrames using flexible text matching and cleaning strategies. It simplifies the data cleaning process for tabular datasets.,AI3-03;AI3,deduplication;data_cleaning,library,Python,https://github.com/shivam5992/dupandas,,None,pandas;deduplication;data-cleaning
736,markdrop,PDF to Markdown converter with LLM-based enrichment,"A pipeline tool for converting PDF documents to Markdown format while extracting images and tables. It integrates with LLMs to generate descriptive text for extracted visual elements, enhancing the quality of data for RAG or training corpora.",AI3-03;AI3,document_parsing;data_enrichment,library,Python,https://github.com/shoryasethia/markdrop,,GPL-3.0,pdf-to-markdown;llm;data-extraction
737,PREQUAL,Pre-alignment quality filter for comparative sequence analysis,A tool for filtering non-homologous residues from unaligned sequences. It is used in bioinformatics pipelines to improve the quality of multiple sequence alignments by removing noise prior to alignment.,AI3-03;AI3,quality_control;filtering,solver,C++,https://github.com/simonwhelan/prequal,,GPL-3.0,bioinformatics;sequence-analysis;quality-control
738,UltimateKalman,High-quality polymorphic implementations of Kalman filters and smoothers,"A library providing implementations of Square-Root Kalman filters and smoothers in MATLAB, C, and Java. It is designed for scientific estimation and signal processing tasks, offering consistent APIs across languages.",AI3,estimation;signal_processing,library,C,https://github.com/sivantoledo/ultimate-kalman,,NOASSERTION,kalman-filter;estimation;signal-processing
739,slncky,lncRNA discovery and filtering tool from RNA-Seq data,"A bioinformatics tool for filtering high-quality noncoding transcripts, discovering lncRNA orthologs, and characterizing conserved lncRNA evolution from RNA-Seq data.",AI3;AI3-03,bioinformatics_analysis;filtering,solver,CSS,https://github.com/slncky/slncky,,MIT,lncrna;rna-seq;bioinformatics
740,Splunk Attack Data,Curated datasets of various security attacks for simulation and testing,A repository containing curated datasets generated from various simulated attacks. It serves as a domain corpus for training and testing security analytics and machine learning models.,AI3;AI3-03,dataset_generation;simulation,dataset,Python,https://github.com/splunk/attack_data,https://attack.splunk.com,Apache-2.0,security-dataset;attack-simulation;corpus
741,minhashcuda,Weighted MinHash implementation on CUDA for multi-GPU,"A high-performance implementation of Weighted MinHash using CUDA, designed for fast deduplication and similarity estimation on large datasets using multiple GPUs.",AI3;AI3-03,deduplication;similarity_search,library,C++,https://github.com/src-d/minhashcuda,,NOASSERTION,minhash;cuda;deduplication
742,STORM,LLM-powered knowledge curation and research system,"An LLM-powered system that automates the research process by researching a topic and generating full-length reports with citations, aiding in knowledge curation and scientific literature review.",AI3,knowledge_curation;literature_review,workflow,Python,https://github.com/stanford-oval/storm,https://storm.genie.stanford.edu,MIT,llm;research-assistant;knowledge-curation
743,German Wikipedia Text Corpus,Cleaned and preprocessed German Wikipedia corpus for NLP,"A cleaned, preprocessed, and sentence-split German text corpus derived from Wikipedia, intended for training NLP embeddings like fastText or ELMo.",AI3;AI3-03,corpus_preparation;nlp_training,dataset,Python,https://github.com/t-systems-on-site-services-gmbh/german-wikipedia-text-corpus,,NOASSERTION,corpus;nlp;german-wikipedia
744,slate,Python library for extracting text from PDFs,"A Python library that simplifies the process of extracting text from PDF documents, wrapping the PDFMiner library for easier use in data processing pipelines.",AI3;AI3-03,text_extraction;data_cleaning,library,Python,https://github.com/timClicks/slate,,GPL-3.0,pdf-extraction;text-mining;python
745,RedPajama-Data,Code for preparing large-scale datasets for LLM training,"A repository containing code and workflows for preparing, cleaning, and deduplicating large-scale datasets (RedPajama) used for training large language models.",AI3;AI3-03,dataset_preparation;deduplication,workflow,Python,https://github.com/togethercomputer/RedPajama-Data,,Apache-2.0,llm-dataset;data-pipeline;redpajama
746,Towhee,Framework for neural data processing pipelines,"A framework dedicated to making neural data processing pipelines simple and fast, supporting tasks like embedding generation, ETL for unstructured data, and multimodal processing.",AI3;AI3-03,data_pipeline;embedding_generation,platform,Python,https://github.com/towhee-io/towhee,https://towhee.io,Apache-2.0,etl;neural-pipeline;unstructured-data
747,Upgini,Data search and enrichment library for Machine Learning,A library for automating data search and enrichment for machine learning pipelines. It helps find and add relevant features from external data sources to improve model accuracy.,AI3;AI3-03,feature_enrichment;data_augmentation,library,Python,https://github.com/upgini/upgini,https://upgini.com,BSD-3-Clause,feature-engineering;data-enrichment;automl
748,NIST OCR Pipeline,Distributed pipeline for converting PDF corpora to clean text,"A tool developed by NIST to convert a corpus of PDF documents into clean text files using a distributed architecture, facilitating the creation of scientific text corpora.",AI3;AI3-03,ocr;text_extraction,workflow,Python,https://github.com/usnistgov/ocr-pipeline,,NOASSERTION,ocr;pdf-processing;nist
749,Superpipe,Optimized LLM pipelines for structured data extraction,"A library for building optimized pipelines that use LLMs to extract structured data from unstructured sources, focusing on efficiency and accuracy in data processing workflows.",AI3;AI3-03,data_extraction;pipeline_optimization,library,Python,https://github.com/villagecomputing/superpipe,https://superpipe.ai,NOASSERTION,llm-pipeline;structured-data;extraction
750,hotpdf,Fast PDF parsing and text extraction library,"A fast PDF parsing library built on top of pdfminer.six, designed to extract text and find text coordinates within PDF documents, useful for data ingestion pipelines.",AI3;AI3-03,text_extraction;pdf_parsing,library,Python,https://github.com/weareprestatech/hotpdf,,MIT,pdf-parser;text-extraction;python
751,GROOT,Resistome profiler for metagenomic data,A tool for graphing resistance out of metagenomes (GROOT). It is a resistome profiler that uses variation graphs to index and align reads to antimicrobial resistance genes.,AI3;AI3-03,bioinformatics_analysis;alignment,solver,Go,https://github.com/will-rowe/groot,https://groot-documentation.readthedocs.io,MIT,metagenomics;bioinformatics;resistome
752,faster-nougat,Optimized local implementation of the Nougat model for scientific PDF parsing,"A highly efficient, local implementation of the Nougat (Neural Optical Understanding for Academic Documents) model. It is designed to convert scientific PDF documents into lightweight Markdown formats, accurately preserving mathematical formulas, tables, and citations, which is a critical step in building high-quality scientific corpora.",AI3;AI3-03,data_extraction;document_parsing;ocr,solver,Python,https://github.com/zhuzilin/faster-nougat,,MIT,pdf-parsing;scientific-papers;nougat;ocr;markdown
753,lazy-astroph,Automated parser and notifier for arXiv Astrophysics papers,"A workflow automation tool for researchers in Astrophysics. It parses the daily arXiv astro-ph feed, filters papers based on user-defined keywords, and delivers relevant results via email or Slack, facilitating efficient literature tracking and data collection.",AI3;AI3-03,literature_mining;data_collection,workflow,Python,https://github.com/zingale/lazy-astroph,,BSD-3-Clause,arxiv;astrophysics;literature-search;automation
754,GraphRAG Agent,Integrated framework for GraphRAG construction and custom evaluation,"A comprehensive tool that integrates GraphRAG, LightRAG, and Neo4j for knowledge graph construction and search. It includes a custom evaluation framework specifically designed for assessing GraphRAG performance, making it relevant for model evaluation and retrieval robustness.",AI3;AI3-04,rag_evaluation;knowledge_graph_construction;retrieval_analysis,workflow,Python,https://github.com/1517005260/graph-rag-agent,,MIT,rag;graphrag;evaluation;neo4j
755,Prompt Injection Generator,Generator for prompt injection attacks to test model robustness,A tool designed to generate prompt injection payloads. It serves as a red teaming utility to test the robustness of Large Language Models against adversarial inputs.,AI3;AI3-04,red_teaming;adversarial_attack_generation;robustness_testing,solver,Python,https://github.com/1celand/prompt-injection-generator,,MIT,prompt-injection;red-teaming;security
756,Indic-Bias,Benchmark for evaluating fairness of LLMs in Indian contexts,A comprehensive benchmark and evaluation suite designed to assess the fairness and bias of Large Language Models specifically within Indian cultural and linguistic contexts. Developed by AI4Bharat.,AI3;AI3-04,bias_evaluation;fairness_benchmarking,dataset,Python,https://github.com/AI4Bharat/indic-bias,,MIT,bias;fairness;llm-evaluation;indic-languages
757,AISBench Benchmark,Model evaluation tool extending OpenCompass for service-based models,"A model evaluation tool built upon the OpenCompass framework. It maintains compatibility with OpenCompass's configuration and datasets while extending support for evaluating service-based models, facilitating standardized benchmarking.",AI3;AI3-04,model_evaluation;performance_benchmarking,solver,Python,https://github.com/AISBench/benchmark,,Apache-2.0,benchmark;opencompass;model-evaluation
758,Agenta,Open-source LLMOps platform for prompt management and evaluation,"A platform for LLM operations that provides tools for prompt management, experimentation, and systematic evaluation of LLM applications. It enables researchers and developers to test and benchmark model performance.",AI3;AI3-04,model_evaluation;prompt_engineering;llm_ops,platform,Python,https://github.com/Agenta-AI/agenta,https://agenta.ai,NOASSERTION,llmops;evaluation;prompt-management
759,Strata-Sword,Hierarchical Chinese-English jailbreak safety benchmark,A safety benchmark developed by Alibaba-AAIG that evaluates the robustness of LLMs against jailbreak attacks. It uses 'reasoning complexity' as a dimension to assess safety boundaries in both Chinese and English contexts.,AI3;AI3-04,safety_benchmarking;jailbreak_testing;robustness_evaluation,dataset,Python,https://github.com/Alibaba-AAIG/Strata-Sword,,None,jailbreak;safety;benchmark;llm
760,ALERT,Benchmark for assessing LLM safety through red teaming,A comprehensive benchmark designed to assess the safety of Large Language Models through red teaming methodologies. It provides a framework for evaluating model responses to adversarial and harmful inputs.,AI3;AI3-04,safety_benchmarking;red_teaming;robustness_evaluation,dataset,Python,https://github.com/Babelscape/ALERT,,NOASSERTION,red-teaming;safety;benchmark;llm
761,PromptInjectionBench,Benchmark for prompt injection attacks against LLMs,"A benchmarking tool for evaluating the robustness of various Large Language Models (including GPT-4, Gemini, Azure) against prompt injection attacks and jailbreak attempts.",AI3;AI3-04,prompt_injection_testing;robustness_benchmarking;red_teaming,solver,Python,https://github.com/BenderScript/PromptInjectionBench,,Apache-2.0,prompt-injection;benchmark;security
762,ko-lm-evaluation-harness,Evaluation harness for Korean Large Language Models,"A fork of the EleutherAI lm-evaluation-harness, specifically adapted for evaluating Korean Large Language Models. It provides a standardized framework for benchmarking Korean language understanding and generation capabilities.",AI3;AI3-04,model_evaluation;language_specific_benchmarking,library,Python,https://github.com/Beomi/ko-lm-evaluation-harness,,MIT,evaluation;korean;llm;benchmark
763,HonestyMeter,NLP framework for evaluating objectivity and bias in media,"An NLP-powered framework designed to evaluate objectivity and detect bias in text content. It identifies manipulative techniques and provides feedback, serving as a tool for analyzing model outputs or training data for fairness.",AI3;AI3-04,bias_evaluation;objectivity_analysis;fairness_testing,library,TypeScript,https://github.com/BetterForAll/HonestyMeter,,Apache-2.0,bias-detection;nlp;fairness;evaluation
764,prompt-injector,Library for research-informed prompt injection attacks,A TypeScript library that implements various research-informed prompt injection attack patterns. It is designed to help developers and researchers test the vulnerability of their LLM applications to prompt injection.,AI3;AI3-04,prompt_injection_testing;red_teaming;vulnerability_assessment,library,TypeScript,https://github.com/BlueprintLabIO/prompt-injector,,None,prompt-injection;security;testing
765,Spell Whisperer,Platform for prompt injection challenges and red teaming,"A platform designed for prompt injection challenges, serving as a gamified environment for red teaming and understanding LLM vulnerabilities. It facilitates the collection of adversarial prompts and testing of model robustness.",AI3;AI3-04,red_teaming;prompt_injection_challenges;robustness_training,platform,TypeScript,https://github.com/CX330Blake/Spell-Whisperer,,GPL-3.0,prompt-injection;red-teaming;ctf
766,OmniVerifier,Generative Universal Verifier as Multimodal Meta-Reasoner,"A framework serving as a generative universal verifier, utilizing multimodal meta-reasoning to enhance the verification process of AI models.",AI3;AI3-04,model_verification;reasoning_evaluation,solver,Python,https://github.com/Cominclip/OmniVerifier,,None,verification;multimodal;meta-reasoning
767,NormalyzerDE,Tools for normalization and differential expression analysis of omics data,"A framework for normalization, outlier evaluation, technical bias assessment, batch effect handling, and differential expression analysis in proteomics and other omics data.",AI3;AI3-04,normalization;differential_expression;quality_control,library,R,https://github.com/ComputationalProteomics/NormalyzerDE,,None,proteomics;normalization;differential-expression;r-package
768,CartAI,Open-source AI supervisor agent for lifecycle oversight and compliance,"An intelligent agent designed for end-to-end oversight and compliance in the AI lifecycle, ensuring trustworthy AI development and deployment.",AI3;AI3-04,ai_governance;compliance_checking;model_monitoring,platform,Jupyter Notebook,https://github.com/ContrastoAI/cartai,,Apache-2.0,ai-safety;compliance;agent;trustworthy-ai
769,DeepRobust,PyTorch adversarial library for attack and defense on images and graphs,"A comprehensive PyTorch library for adversarial attacks and defenses, covering both image processing and graph neural networks to evaluate and improve model robustness.",AI3;AI3-04,adversarial_attack;adversarial_defense;robustness_evaluation,library,Python,https://github.com/DSE-MSU/DeepRobust,https://deeprobust.readthedocs.io/,MIT,adversarial-learning;pytorch;graph-neural-networks;robustness
770,DreamLayer,Benchmarking and evaluation automation for diffusion models,"A tool to automate evaluations, seed management, and metric calculation for benchmarking diffusion models, ensuring reproducible results.",AI3;AI3-04,model_benchmarking;evaluation_automation;reproducibility,workflow,Python,https://github.com/DreamLayer-AI/DreamLayer,,GPL-3.0,diffusion-models;benchmarking;evaluation
771,lm-evaluation-harness,Framework for few-shot evaluation of language models,"A widely used framework for evaluating autoregressive language models on a large number of tasks, supporting few-shot evaluation and providing a standardized interface for model comparison.",AI3;AI3-04,model_evaluation;few_shot_testing;benchmark_suite,platform,Python,https://github.com/EleutherAI/lm-evaluation-harness,,MIT,llm;evaluation;nlp;benchmark
772,JamAIBase,Collaborative spreadsheet interface for AI pipeline creation and evaluation,"A platform that combines a spreadsheet interface with AI capabilities, allowing users to chain cells into pipelines, experiment with prompts, and evaluate LLM responses in real-time.",AI3;AI3-04,prompt_engineering;response_evaluation;pipeline_orchestration,platform,Python,https://github.com/EmbeddedLLM/JamAIBase,https://jamaibase.com,Apache-2.0,llm-ops;spreadsheet-ui;evaluation;collaboration
773,Cognitive-Hijacking-in-Long-Context-LLMs,Implementation of prompt injection via forged internal states,A research tool demonstrating a novel prompt injection method that exploits forged internal states in long-context Large Language Models.,AI3;AI3-04,red_teaming;prompt_injection;vulnerability_research,solver,Python,https://github.com/Eric-Terminal/Cognitive-Hijacking-in-Long-Context-LLMs,,NOASSERTION,prompt-injection;llm-security;exploit
774,universal-triggers,Universal Adversarial Triggers for Attacking and Analyzing NLP,"Code for generating universal adversarial triggers that can cause specific predictions when concatenated to any input, used for analyzing NLP model robustness.",AI3;AI3-04,adversarial_attack;robustness_analysis;nlp_security,solver,Python,https://github.com/Eric-Wallace/universal-triggers,,MIT,adversarial-nlp;triggers;robustness
775,xai,Explainability toolbox for machine learning,"A library designed to provide explainability and fairness analysis for machine learning models, helping to evaluate model behavior and detect bias.",AI3;AI3-04,explainability;fairness_evaluation;model_interpretation,library,Python,https://github.com/EthicalML/xai,,MIT,explainable-ai;fairness;machine-learning
776,OpenFed,Comprehensive Federated Learning Framework,"A versatile open-source framework for federated learning, enabling distributed model training and evaluation while preserving data privacy.",AI3;AI3-04,federated_learning;distributed_training;privacy_preserving_ml,platform,Python,https://github.com/FederalLab/OpenFed,,MIT,federated-learning;privacy;distributed-systems
777,LLMZoo,"Data, models, and evaluation benchmark for LLMs","A project providing a collection of instruction-tuned models, datasets, and evaluation benchmarks to facilitate research and development of Large Language Models.",AI3;AI3-04,model_benchmarking;instruction_tuning;dataset_provision,dataset,Python,https://github.com/FreedomIntelligence/LLMZoo,,Apache-2.0,llm;benchmark;instruction-tuning
778,LRV-Instruction,Mitigating Hallucination in Large Multi-Modal Models,Code and resources for robust instruction tuning aimed at mitigating hallucinations in Large Multi-Modal Models (LMMs).,AI3;AI3-04,hallucination_mitigation;instruction_tuning;robustness,solver,Python,https://github.com/FuxiaoLiu/LRV-Instruction,,BSD-3-Clause,multimodal;hallucination;instruction-tuning
779,LLM-Check,Detection of Hallucinations in Large Language Models,"Implementation of methods for investigating and detecting hallucinations in Large Language Models, as presented at NeurIPS 2024.",AI3;AI3-04,hallucination_detection;model_evaluation,solver,Jupyter Notebook,https://github.com/GaurangSriramanan/LLM_Check_Hallucination_Detection,,NOASSERTION,hallucination;llm;neurips-2024
780,mcp-guard,Security tool for Model Context Protocol (MCP) clients,A security tool designed to protect Model Context Protocol (MCP) clients from prompt injection attacks and other vulnerabilities.,AI3;AI3-04,prompt_injection_defense;client_security;ai_protocol_security,solver,TypeScript,https://github.com/General-Analysis/mcp-guard,,MIT,mcp;prompt-injection;security
781,giskard-client,API Client for Giskard AI evaluation platform,"The Python client library for interacting with the Giskard platform, enabling programmatic control over AI model testing and evaluation workflows.",AI3;AI3-04,model_testing;evaluation_workflow;api_client,library,Python,https://github.com/Giskard-AI/giskard-client,https://docs.giskard.ai/,Apache-2.0,giskard;testing;client-library
782,giskard-hub,SDK for Giskard Enterprise platform,"SDK for the Giskard Hub, facilitating enterprise-level LLM agent testing, team collaboration, and continuous red teaming.",AI3;AI3-04,red_teaming;collaborative_testing;enterprise_sdk,library,Jupyter Notebook,https://github.com/Giskard-AI/giskard-hub,,Apache-2.0,giskard;enterprise;red-teaming
783,giskard-oss,Open-Source Evaluation & Testing library for LLM Agents,"A comprehensive open-source library for testing and evaluating LLM agents and AI models, focusing on detecting vulnerabilities, hallucinations, and performance issues.",AI3;AI3-04,model_testing;vulnerability_scanning;quality_assurance,library,Python,https://github.com/Giskard-AI/giskard-oss,https://docs.giskard.ai/,Apache-2.0,llm-testing;evaluation;quality-assurance
784,giskard-vision,Evaluation & Testing for Computer Vision AI systems,A specialized module within the Giskard ecosystem for evaluating and testing computer vision models for robustness and correctness.,AI3;AI3-04,computer_vision_testing;robustness_evaluation,library,Python,https://github.com/Giskard-AI/giskard-vision,,Apache-2.0,computer-vision;testing;giskard
785,phare,LLM benchmark for security and safety dimensions,A benchmark suite designed to evaluate Large Language Models across key dimensions of AI security and safety.,AI3;AI3-04,safety_benchmarking;security_evaluation,dataset,Python,https://github.com/Giskard-AI/phare,,None,benchmark;ai-safety;llm
786,prompt-injections,Collection of prompt injections for AI scanning,A dataset and collection of prompt injection patterns used by the Giskard Scan tool to test LLMs for security vulnerabilities.,AI3;AI3-04,prompt_injection_testing;security_dataset,dataset,Python,https://github.com/Giskard-AI/prompt-injections,,MIT,prompt-injection;dataset;security
787,Knowledge-Constrained-Decoding,Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection,"Implementation of the KCTS method for decoding in language models, incorporating token-level hallucination detection to improve factual accuracy.",AI3;AI3-04,decoding_strategy;hallucination_detection;factuality,solver,Python,https://github.com/HKUST-KnowComp/Knowledge-Constrained-Decoding,,None,decoding;hallucination;nlp
788,Graph Adversarial Attack,Library for adversarial attacks on graph structured data,"A Python library providing implementations of various adversarial attack methods specifically designed for Graph Neural Networks (GNNs), enabling robustness evaluation of graph-based models in scientific domains like chemistry and biology.",AI3;AI3-04,adversarial_attack;robustness_evaluation,library,Python,https://github.com/Hanjun-Dai/graph_adversarial_attack,,MIT,graph-neural-networks;adversarial-attacks;robustness
789,PGD-pytorch,PyTorch implementation of Projected Gradient Descent (PGD) attacks,"A focused implementation of the Projected Gradient Descent (PGD) adversarial attack method in PyTorch, widely used as a standard baseline for evaluating the robustness of deep learning models against adversarial perturbations.",AI3;AI3-04,adversarial_attack;robustness_evaluation,library,Jupyter Notebook,https://github.com/Harry24k/PGD-pytorch,,MIT,pytorch;adversarial-attacks;pgd
790,TorchAttacks,Comprehensive PyTorch library for adversarial attacks,"A lightweight and comprehensive PyTorch library providing a wide range of adversarial attack algorithms (FGSM, PGD, CW, etc.) to evaluate the robustness of neural networks.",AI3;AI3-04,adversarial_attack;robustness_evaluation,library,Python,https://github.com/Harry24k/adversarial-attacks-pytorch,https://adversarial-attacks-pytorch.readthedocs.io/,MIT,pytorch;adversarial-attacks;security
791,Helicone,Open-source observability and evaluation platform for LLMs,"A platform designed for monitoring, logging, and evaluating Large Language Model (LLM) interactions, providing tools for tracking costs, latency, and quality metrics to ensure model reliability in production and research.",AI3;AI3-04,model_monitoring;performance_evaluation,platform,TypeScript,https://github.com/Helicone/helicone,https://docs.helicone.ai/,Apache-2.0,llm-ops;observability;evaluation
792,Robust Tube MPC,Implementation of Robust Model Predictive Control using Tube methods,"A MATLAB implementation of Robust Model Predictive Control (MPC) utilizing tube-based methods to handle uncertainties in system dynamics, applicable in control theory research and robotics.",AI3,control_simulation;scientific_modeling,solver,MATLAB,https://github.com/HiroIshida/robust-tube-mpc,,MIT,mpc;control-theory;robust-control
793,TrustGPT,"Benchmark for evaluating toxicity, bias, and value-alignment in LLMs","A benchmark framework designed to assess the trustworthiness of Large Language Models by evaluating them across dimensions such as toxicity, bias, and value alignment, ensuring responsible AI development.",AI3;AI3-04,safety_benchmark;bias_evaluation,dataset,Python,https://github.com/HowieHwong/TrustGPT,,MIT,llm;benchmark;trustworthiness
794,TrustLLM,Comprehensive toolkit for evaluating trustworthiness in Large Language Models,"A comprehensive framework and benchmark for evaluating the trustworthiness of LLMs, covering multiple dimensions including truthfulness, safety, fairness, and robustness.",AI3;AI3-04,safety_benchmark;model_evaluation,library,Python,https://github.com/HowieHwong/TrustLLM,https://trustllmbenchmark.github.io/TrustLLM-Website/,MIT,llm;safety;evaluation
795,TrustRAG,Framework for enhancing and evaluating robustness in RAG systems,"A research tool focused on improving and evaluating the trustworthiness and robustness of Retrieval-Augmented Generation (RAG) systems, addressing issues like retrieval errors and generation hallucinations.",AI3;AI3-04,rag_evaluation;robustness_enhancement,library,Python,https://github.com/HuichiZhou/TrustRAG,,MIT,rag;robustness;trustworthiness
796,Tensor Trust,Platform for collecting prompt injection data for robust ML research,A gamified platform and dataset designed to crowdsource adversarial prompts (prompt injections) to facilitate research into the robustness and security of Large Language Models.,AI3;AI3-04,data_collection;adversarial_attack,platform,Python,https://github.com/HumanCompatibleAI/tensor-trust,https://tensortrust.ai/,BSD-2-Clause,prompt-injection;security;crowdsourcing
797,xFinder,Automated evaluator using LLMs for reliable evaluation,"A tool that leverages Large Language Models as automated evaluators to assess the quality and correctness of outputs from other models, aiming to improve the reliability of automated evaluation metrics.",AI3;AI3-04,automated_evaluation;llm_as_judge,library,Python,https://github.com/IAAR-Shanghai/xFinder,,NOASSERTION,evaluation;llm;automation
798,xVerify,Efficient answer verifier for reasoning model evaluations,"A tool designed to verify the correctness of answers generated by reasoning models, facilitating efficient and accurate evaluation of complex reasoning tasks.",AI3;AI3-04,result_verification;model_evaluation,library,Jupyter Notebook,https://github.com/IAAR-Shanghai/xVerify,,NOASSERTION,reasoning;verification;evaluation
799,SCERL,Safety Constrained Environments for Reinforcement Learning,"A collection of benchmark environments and datasets for evaluating Reinforcement Learning algorithms under safety constraints, supporting research into safe and robust RL agents.",AI3;AI3-04,safety_benchmark;reinforcement_learning,dataset,Inform 7,https://github.com/IBM/SCERL,,Apache-2.0,reinforcement-learning;safety;benchmark
800,EvalAssist,Tool for refining LLM-as-a-Judge evaluation criteria,"An open-source tool that assists users in iteratively refining evaluation criteria and prompts when using Large Language Models as evaluators (LLM-as-a-Judge), featuring a web-based interface for analysis.",AI3;AI3-04,evaluation_workflow;prompt_engineering,platform,TypeScript,https://github.com/IBM/eval-assist,,Apache-2.0,llm-as-a-judge;evaluation;ui
801,S-Eval,Automated and comprehensive safety evaluation framework for LLMs,"A framework designed for the automated and comprehensive safety evaluation of Large Language Models, providing metrics and datasets to assess various safety risks.",AI3;AI3-04,safety_evaluation;risk_assessment,library,Python,https://github.com/IS2Lab/S-Eval,,NOASSERTION,safety;llm;evaluation
802,Infosys Responsible AI Toolkit,"Toolkit for AI safety, security, explainability, and fairness","A comprehensive toolkit incorporating features for safety, security, explainability, fairness, bias, and hallucination detection to ensure the development of trustworthy and transparent AI solutions.",AI3;AI3-04,responsible_ai;model_audit,library,Python,https://github.com/Infosys/Infosys-Responsible-AI-Toolkit,,MIT,responsible-ai;explainability;fairness
803,Factorio Learning Environment,Open-ended environment for evaluating LLMs and agents in Factorio,"A non-saturating, open-ended simulation environment based on the game Factorio, designed for evaluating the planning and problem-solving capabilities of Large Language Models and Reinforcement Learning agents.",AI3;AI3-04,agent_evaluation;simulation_environment,dataset,Python,https://github.com/JackHopkins/factorio-learning-environment,,NOASSERTION,rl;llm-agent;simulation
804,JailbreakBench,Benchmark for jailbreaking language models,"An open robustness benchmark specifically designed for evaluating the susceptibility of Language Models to jailbreaking attacks, providing a standardized dataset and evaluation protocol.",AI3;AI3-04,safety_benchmark;adversarial_attack,dataset,Python,https://github.com/JailbreakBench/jailbreakbench,https://jailbreakbench.github.io/,MIT,jailbreak;robustness;benchmark
805,Multilingual Safety Benchmark,Safety benchmark for Large Language Models across multiple languages,"A benchmark dataset and framework for evaluating the safety and robustness of Large Language Models in multilingual contexts, addressing the gap in non-English safety evaluation.",AI3;AI3-04,safety_benchmark;multilingual_evaluation,dataset,Python,https://github.com/Jarviswang94/Multilingual_safety_benchmark,,Apache-2.0,multilingual;safety;llm
806,Model Predictive Control (MPC),C++ implementation of MPC for vehicle control simulation,"A C++ implementation of Model Predictive Control (MPC) designed to drive a vehicle in a simulator by optimizing steering and throttle commands, useful for research in control systems and autonomous driving.",AI3,control_simulation;scientific_modeling,solver,C++,https://github.com/JunshengFu/Model-Predictive-Control,,MIT,mpc;control;simulation
807,LettuceDetect,Hallucination detection framework for RAG applications,"A framework designed to detect hallucinations in Retrieval-Augmented Generation (RAG) applications, helping to ensure the factual accuracy and reliability of generated content.",AI3;AI3-04,hallucination_detection;rag_evaluation,library,Python,https://github.com/KRLabsOrg/LettuceDetect,,MIT,rag;hallucination;evaluation
808,Mithra Scanner,API testing tool for prompt injection and LLM security benchmarking,"An interactive security testing tool for Large Language Model endpoints, supporting prompt injection testing, refusal detection, and security benchmarking via CLI and REST API integration.",AI3;AI3-04,security_scanning;red_teaming,solver,Python,https://github.com/KadirArslan/Mithra-Scanner,,None,security;red-teaming;prompt-injection
809,HouYi,Automated prompt injection framework for LLM applications,"A framework for automating prompt injection attacks against LLM-integrated applications, serving as a red-teaming tool to identify security vulnerabilities in AI systems.",AI3;AI3-04,red_teaming;adversarial_attack,library,Python,https://github.com/LLMSecurity/HouYi,,Apache-2.0,prompt-injection;security;red-teaming
810,aac-metrics,Metrics for evaluating Automated Audio Captioning systems,"A PyTorch-based library providing a collection of metrics (SPIDEr, FENSE, etc.) for evaluating the performance of Automated Audio Captioning (AAC) systems.",AI3;AI3-04,model_evaluation;audio_analysis,library,Python,https://github.com/Labbeti/aac-metrics,https://aac-metrics.readthedocs.io/,MIT,audio-captioning;metrics;evaluation
811,BERT-Attack,Adversarial attack method against BERT models,"An implementation of the BERT-Attack method, which generates high-quality adversarial samples to attack BERT-based models, used for evaluating the robustness of NLP models.",AI3;AI3-04,adversarial_attack;robustness_evaluation,library,Python,https://github.com/LinyangLee/BERT-Attack,,None,nlp;adversarial-attack;bert
812,R-Judge,Benchmark for safety risk awareness in LLM agents,"A benchmark designed to evaluate the safety risk awareness of Large Language Model (LLM) agents, focusing on their ability to identify and handle risky scenarios.",AI3;AI3-04,safety_benchmark;agent_evaluation,dataset,Python,https://github.com/Lordog/R-Judge,https://r-judge.github.io/,None,llm-agent;safety;benchmark
813,Trustworthy AI Fetal Brain Segmentation,Trustworthy AI method for fetal brain MRI segmentation,"An implementation of a trustworthy AI method based on Dempster-Shafer theory for the segmentation of fetal brains in 3D T2w MRI scans, providing uncertainty estimation for medical imaging analysis.",AI3,medical_image_segmentation;scientific_data_analysis,solver,Python,https://github.com/LucasFidon/trustworthy-ai-fetal-brain-segmentation,,BSD-3-Clause,medical-imaging;segmentation;uncertainty-estimation
814,GenoArmory,Unified evaluation framework for adversarial attacks on genomic foundation models,A comprehensive framework designed to evaluate the robustness of genomic foundation models against adversarial attacks. It provides a standardized environment for testing model vulnerabilities in bioinformatics contexts.,AI3-04;Bioinformatics,adversarial_attack;model_evaluation;robustness,framework,Python,https://github.com/MAGICS-LAB/GenoArmory,,MIT,genomics;adversarial-attacks;foundation-models
815,MJ-Bench,Benchmark for evaluating multimodal reward models in text-to-image generation,"A benchmark suite designed to assess whether multimodal reward models effectively judge the quality of text-to-image generation outputs, providing datasets and evaluation scripts.",AI3-04,benchmarking;reward_model_evaluation,dataset,Jupyter Notebook,https://github.com/MJ-Bench/MJ-Bench,,MIT,multimodal;reward-model;text-to-image
816,nlg-eval,Evaluation code for unsupervised automated metrics for Natural Language Generation,"A library providing implementations for various unsupervised automated metrics (such as BLEU, METEOR, ROUGE, CIDEr) used to evaluate Natural Language Generation (NLG) models.",AI3-04,nlg_evaluation;metrics,library,Python,https://github.com/Maluuba/nlg-eval,,NOASSERTION,nlg;evaluation-metrics;nlp
817,AutoRAG,Automated framework for RAG evaluation and optimization,"An AutoML-style framework designed to automatically evaluate and optimize Retrieval-Augmented Generation (RAG) pipelines, helping researchers select the best RAG modules and parameters.",AI3-04,rag_evaluation;optimization;automl,framework,Python,https://github.com/Marker-Inc-Korea/AutoRAG,https://docs.autorag.ai/,Apache-2.0,rag;evaluation;automl
818,pytector,Python package for LLM prompt injection detection,"A lightweight Python package designed to detect prompt injection attacks in Large Language Model (LLM) inputs, enhancing the security and robustness of LLM applications.",AI3-04,prompt_injection_detection;security,library,Python,https://github.com/MaxMLang/pytector,,Apache-2.0,prompt-injection;security;llm
819,Dingo,"Comprehensive AI data, model, and application quality evaluation tool","A tool designed to evaluate the quality of AI data, models, and applications, providing metrics and insights to ensure the reliability and performance of AI systems.",AI3-04,model_evaluation;data_quality,tool,JavaScript,https://github.com/MigoXLab/dingo,,Apache-2.0,evaluation;quality-assurance;ai-testing
820,summarization-eval,Reference-free automatic summarization evaluation tool,"A toolkit for evaluating text summarization models without reference summaries, including features for potential hallucination detection.",AI3-04,summarization_evaluation;hallucination_detection,library,Python,https://github.com/Muhtasham/summarization-eval,,None,summarization;evaluation;hallucination
821,garak,LLM vulnerability scanner and red teaming tool,"A comprehensive vulnerability scanner for Large Language Models (LLMs), designed to probe for hallucinations, data leakage, prompt injection, and other security weaknesses.",AI3-04,vulnerability_scanning;red_teaming;robustness,tool,Python,https://github.com/NVIDIA/garak,https://garak.ai,Apache-2.0,llm;security;red-teaming
822,RADTTS,Flow-based TTS models with robust alignment learning,"A library providing training and inference recipes for RADTTS and RADTTS++, enabling robust text-to-speech synthesis with fine-grained control over speech attributes.",AI3,text_to_speech;generative_model;model_training,library,Roff,https://github.com/NVIDIA/radtts,,MIT,tts;speech-synthesis;generative-ai
823,sentiment-discovery,Unsupervised language modeling for robust sentiment classification,"A library implementing unsupervised language modeling techniques at scale to achieve robust sentiment classification, useful for analyzing large-scale text data.",AI3,sentiment_analysis;language_modeling,library,Python,https://github.com/NVIDIA/sentiment-discovery,,NOASSERTION,sentiment-analysis;nlp;unsupervised-learning
824,LLM Colosseum,Benchmark for evaluating LLMs via game-playing interactions,"A unique benchmarking tool that evaluates the quality and reasoning capabilities of Large Language Models (LLMs) by having them compete in Street Fighter 3, providing a dynamic evaluation environment.",AI3-04,benchmarking;llm_evaluation;game_based_eval,tool,Jupyter Notebook,https://github.com/OpenGenerativeAI/llm-colosseum,,MIT,llm;benchmark;game-ai
825,EasyDetect,Hallucination detection framework for LLMs,"An easy-to-use framework designed to detect hallucinations in Large Language Model outputs, supporting various detection methods to ensure model reliability.",AI3-04,hallucination_detection;model_evaluation,framework,Python,https://github.com/OpenKG-ORG/EasyDetect,,Apache-2.0,hallucination;llm;reliability
826,Bag-of-Tricks-for-AT,Collection of empirical tricks for adversarial training,A library implementing various empirical tricks and best practices for training robust deep learning models using adversarial training techniques.,AI3-04,adversarial_training;robustness;model_training,library,Python,https://github.com/P2333/Bag-of-Tricks-for-AT,,Apache-2.0,adversarial-training;robustness;deep-learning
827,Safety-Gymnasium,Unified benchmark environments for safe reinforcement learning,"A highly scalable and customizable benchmark suite for Safe Reinforcement Learning, providing environments to evaluate the safety and performance of RL agents.",AI3-04,reinforcement_learning;safety_benchmark;evaluation,library,Python,https://github.com/PKU-Alignment/safety-gymnasium,https://www.safety-gymnasium.com/,Apache-2.0,reinforcement-learning;safety;benchmark
828,LIFT3D,Foundation policy for robust 3D robotic manipulation,"A framework that lifts 2D large-scale pretrained models to 3D for robust robotic manipulation, serving as a foundation policy for robotics research.",AI3;Robotics,robotic_manipulation;3d_policy;model_training,solver,Python,https://github.com/PKU-HMI-Lab/LIFT3D,,MIT,robotics;3d-manipulation;foundation-model
829,Themis,Reference-free NLG evaluation language model,"A model-based evaluation tool for Natural Language Generation that operates without references, offering flexibility and interpretability in assessing text quality.",AI3-04,nlg_evaluation;model_based_evaluation,solver,Python,https://github.com/PKU-ONELab/Themis,,Apache-2.0,nlg;evaluation;llm
830,rko_lio,Robust LiDAR-Inertial Odometry without sensor-specific modelling,"A robust implementation of LiDAR-Inertial Odometry (LIO) that does not require sensor-specific modeling, useful for robotic navigation and mapping tasks.",Robotics,lidar_inertial_odometry;slam;navigation,solver,C++,https://github.com/PRBonn/rko_lio,,MIT,slam;lidar;robotics
831,SafeLife,Safety benchmarks for reinforcement learning agents,"A set of environments and benchmarks designed to test the safety and robustness of reinforcement learning agents in complex, dynamic gridworlds.",AI3-04,reinforcement_learning;safety_benchmark,library,Python,https://github.com/PartnershipOnAI/safelife,,Apache-2.0,reinforcement-learning;safety;benchmark
832,Parrot Paraphraser,Paraphrasing framework for NLU data augmentation,"A practical framework for generating paraphrases to augment training data for Natural Language Understanding (NLU) models, helping to build more robust conversational agents.",AI3,data_augmentation;paraphrasing;model_training,library,Python,https://github.com/PrithivirajDamodaran/Parrot_Paraphraser,,Apache-2.0,data-augmentation;nlp;paraphrasing
833,TextAttack,Framework for adversarial attacks and data augmentation in NLP,"A comprehensive Python framework for generating adversarial attacks, performing data augmentation, and training robust models in Natural Language Processing (NLP).",AI3-04,adversarial_attack;data_augmentation;robustness,framework,Python,https://github.com/QData/TextAttack,https://textattack.readthedocs.io/,MIT,nlp;adversarial-attacks;data-augmentation
834,TextAttack-A2T,Implementation of A2T adversarial training method for NLP models,"A repository containing the implementation of the 'A2T: Towards Improving Adversarial Training of NLP Models' method, designed to enhance the robustness of Natural Language Processing models against adversarial attacks.",AI3;AI3-04,adversarial_training;model_robustness,solver,Python,https://github.com/QData/TextAttack-A2T,,MIT,nlp;adversarial-training;robustness
835,TextAttack-Search-Benchmark,Benchmark for search algorithms in NLP adversarial example generation,"A benchmarking suite for evaluating various search algorithms used to generate adversarial examples in Natural Language Processing, supporting research into the efficiency and effectiveness of adversarial attacks.",AI3;AI3-04,adversarial_attack;benchmarking,solver,Jupyter Notebook,https://github.com/QData/TextAttack-Search-Benchmark,,None,nlp;adversarial-attacks;benchmarking
836,RLAIF-V,Framework for AI feedback on Vision-Language Models,An open-source framework implementing Reinforcement Learning from AI Feedback (RLAIF) specifically for Vision-Language Models (VLMs) to improve their trustworthiness and alignment.,AI3;AI3-04,alignment;rlhf;multimodal_evaluation,framework,Python,https://github.com/RLHF-V/RLAIF-V,,None,vlm;rlaif;trustworthiness
837,LLMBox,Unified library for LLM training and evaluation,"A comprehensive library for implementing Large Language Models, featuring a unified pipeline for training and extensive model evaluation capabilities.",AI3;AI3-04,model_training;model_evaluation,library,Python,https://github.com/RUCAIBox/LLMBox,,MIT,llm;training-pipeline;evaluation
838,RobustBench,Standardized benchmark for adversarial robustness,"A standardized benchmark and library for evaluating the adversarial robustness of image classification models, providing a leaderboard and easy access to robust models.",AI3;AI3-04,robustness_evaluation;benchmarking,library,Python,https://github.com/RobustBench/robustbench,https://robustbench.github.io/,NOASSERTION,adversarial-robustness;computer-vision;benchmark
839,RouterArena,Evaluation framework for LLM routing strategies,"An open framework designed to evaluate Large Language Model routers, featuring standardized datasets, metrics, and an automated evaluation pipeline.",AI3;AI3-04,model_routing;evaluation,framework,Python,https://github.com/RouteWorks/RouterArena,,Apache-2.0,llm-routing;evaluation-framework;benchmark
840,RAG-evaluation-harnesses,Evaluation suite for Retrieval-Augmented Generation,A comprehensive evaluation suite specifically designed for assessing the performance of Retrieval-Augmented Generation (RAG) systems.,AI3;AI3-04,rag_evaluation;retrieval_augmented_generation,framework,Python,https://github.com/RulinShao/RAG-evaluation-harnesses,,MIT,rag;evaluation;llm
841,SORRY-Bench,Benchmark for evaluating LLM safety refusal,A benchmark and evaluation toolkit for systematically assessing the safety refusal mechanisms of Large Language Models.,AI3;AI3-04,safety_evaluation;alignment,dataset,Jupyter Notebook,https://github.com/SORRY-Bench/sorry-bench,https://sorry-bench.github.io/,MIT,llm-safety;benchmark;refusal
842,JailBreakV-28K,Benchmark for LLM to MLLM jailbreak transferability,"A comprehensive benchmark designed to evaluate the transferability of jailbreak attacks from Large Language Models to Multimodal Large Language Models, assessing robustness and safety.",AI3;AI3-04,red_teaming;safety_evaluation;multimodal,dataset,Python,https://github.com/SaFo-Lab/JailBreakV_28K,https://jailbreakv.github.io/,None,jailbreak;mllm;safety-benchmark
843,Robust Gymnasium,Unified benchmark for robust Reinforcement Learning,A unified modular benchmark designed to evaluate the robustness of Reinforcement Learning agents under various perturbations and conditions.,AI3;AI3-04,reinforcement_learning;robustness_evaluation,framework,Python,https://github.com/SafeRL-Lab/Robust-Gymnasium,,MIT,reinforcement-learning;robustness;benchmark
844,Langtrace,Observability and evaluation tool for LLM applications,"An open-source observability tool based on Open Telemetry for LLM applications, providing real-time tracing, evaluations, and metrics.",AI3;AI3-04,observability;model_evaluation;monitoring,platform,TypeScript,https://github.com/Scale3-Labs/langtrace,https://docs.langtrace.ai/,AGPL-3.0,llm-ops;observability;evaluation
845,giskardpy,Robot motion control library,The core Python library of the Giskard framework for constraint- and optimization-based robot motion control.,AI_Robotics,motion_control;robotics,library,Python,https://github.com/SemRoCo/giskardpy,,LGPL-3.0,robotics;motion-control;optimization
846,Universal-Prompt-Injection,Implementation of universal prompt injection attacks,"Official implementation of the paper 'Automatic and Universal Prompt Injection Attacks against Large Language Models', providing methods to generate prompt injection attacks.",AI3;AI3-04,prompt_injection;red_teaming,solver,Python,https://github.com/SheltonLiu-N/Universal-Prompt-Injection,,MIT,prompt-injection;llm-security;adversarial-attacks
847,JailDAM,Jailbreak detection for Vision-Language Models,"Implementation of 'JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model', a method for detecting jailbreak attempts in multimodal models.",AI3;AI3-04,jailbreak_detection;safety_defense,solver,Python,https://github.com/ShenzheZhu/JailDAM,,MIT,jailbreak-detection;vlm;safety
848,JudgeDeceiver,Prompt injection attack against LLM-as-a-Judge,Implementation of an optimization-based prompt injection attack specifically targeting LLM-as-a-Judge systems.,AI3;AI3-04,prompt_injection;red_teaming;llm_as_a_judge,solver,Python,https://github.com/ShiJiawenwen/JudgeDeceiver,,None,prompt-injection;llm-judge;adversarial
849,Gorilla,Training and evaluation for LLM function calling,A framework and model suite for training and evaluating Large Language Models on function calling (tool use) capabilities.,AI3;AI3-04,function_calling;model_evaluation;tool_use,framework,Python,https://github.com/ShishirPatil/gorilla,https://gorilla.cs.berkeley.edu/,Apache-2.0,llm;function-calling;api
850,StruQ,Defense against prompt injection using structured queries,"Official implementation of StruQ, a method for defending against prompt injection attacks by utilizing structured queries.",AI3;AI3-04,prompt_injection_defense;safety,solver,Python,https://github.com/Sizhe-Chen/StruQ,,NOASSERTION,prompt-injection;defense;llm-security
851,Skywork,Open-source bilingual LLM suite and evaluation tools,"A suite of large language models pre-trained on multilingual data, including open-source models, training data, and evaluation methods.",AI3;AI3-04,model_training;model_evaluation,platform,Python,https://github.com/SkyworkAI/Skywork,,NOASSERTION,llm;bilingual;foundation-model
852,EmoLLM,Mental health LLM framework and evaluation,"A comprehensive framework for mental health Large Language Models, covering pre-training, post-training, datasets, and evaluation.",AI3;AI3-04,domain_adaptation;mental_health;model_evaluation,framework,Python,https://github.com/SmartFlowAI/EmoLLM,,MIT,mental-health;llm;domain-specific
853,AI-Safety_Benchmark,Benchmark for guided jailbreak attacks,"The official repository for a guided jailbreak benchmark, designed to evaluate the safety of AI models against sophisticated attacks.",AI3;AI3-04,safety_benchmarking;jailbreak_evaluation,dataset,Python,https://github.com/SproutNan/AI-Safety_Benchmark,,None,ai-safety;benchmark;jailbreak
854,Bullet-Safety-Gym,Safety benchmark framework for Reinforcement Learning,An open-source framework based on Bullet Physics to benchmark and assess safety specifications in Reinforcement Learning problems.,AI3;AI3-04,reinforcement_learning;safety_evaluation;simulation,framework,Python,https://github.com/SvenGronauer/Bullet-Safety-Gym,,MIT,rl;safety;benchmark
855,HPCPerfStats,HPC resource-usage monitoring and analysis tool,An automated resource-usage monitoring and analysis package designed for High Performance Computing (HPC) clusters.,Scientific_Computing,performance_monitoring;hpc_analysis,platform,C,https://github.com/TACC/HPCPerfStats,,LGPL-2.1,hpc;monitoring;performance
856,Omni-SafetyBench,Safety benchmark for Audio-Visual LLMs,"A benchmark designed for the safety evaluation of Audio-Visual Large Language Models, assessing risks across multiple modalities.",AI3;AI3-04,safety_benchmarking;multimodal_evaluation,dataset,Python,https://github.com/THU-BPM/Omni-SafetyBench,,Apache-2.0,multimodal;safety;benchmark
857,AgentBench,Benchmark to evaluate LLMs as Agents,A comprehensive benchmark framework to evaluate the capabilities of Large Language Models acting as autonomous agents across various environments.,AI3;AI3-04,agent_evaluation;benchmarking,framework,Python,https://github.com/THUDM/AgentBench,,Apache-2.0,llm-agent;benchmark;evaluation
858,FeverSymmetric,Symmetric evaluation dataset for fact verification,"A symmetric evaluation dataset based on the FEVER (fact verification) dataset, designed to test model consistency and bias.",AI3;AI3-04,fact_verification;dataset_creation,dataset,Python,https://github.com/TalSchuster/FeverSymmetric,,MIT,fever;fact-verification;dataset
859,AI-Infra-Guard,AI Red Teaming platform,"A comprehensive, intelligent, and easy-to-use AI Red Teaming platform developed to secure AI infrastructure and models.",AI3;AI3-04,red_teaming;security_evaluation,platform,Python,https://github.com/Tencent/AI-Infra-Guard,,NOASSERTION,red-teaming;ai-security;platform
860,AICGSecEval,AI-generated code security evaluation benchmark,A repository-level benchmark for evaluating the security of code generated by AI models.,AI3;AI3-04,code_security;model_evaluation,dataset,Python,https://github.com/Tencent/AICGSecEval,,NOASSERTION,code-generation;security;benchmark
861,WeKnora,RAG framework for document understanding,"An LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using the RAG paradigm.",AI3;AI3-04,rag;document_understanding;retrieval,framework,Go,https://github.com/Tencent/WeKnora,,NOASSERTION,rag;llm;document-analysis
862,PedestrianDetection-NohNMS,NOH-NMS algorithm for pedestrian detection,"Implementation of 'NOH-NMS: Improving Pedestrian Detection by Nearby Objects Hallucination', improving detection performance in crowded scenes.",AI_Computer_Vision,object_detection;pedestrian_detection,solver,Python,https://github.com/TencentYoutuResearch/PedestrianDetection-NohNMS,,NOASSERTION,computer-vision;pedestrian-detection;nms
863,trust-safety-evals,Reference stack for AI model trust and safety evaluation,"A project defining a reference stack for AI model and system evaluation, including evaluations, benchmarks, and leaderboards for trust and safety.",AI3;AI3-04,trust_safety;model_evaluation,framework,Makefile,https://github.com/The-AI-Alliance/trust-safety-evals,,None,ai-safety;evaluation;trust
864,Ensemble-Pytorch,Unified ensemble framework for PyTorch models,"A library to implement, train, and evaluate ensemble learning methods in PyTorch, aiming to improve the performance and robustness of deep learning models.",AI3;AI3-04,robustness_enhancement;model_ensemble,library,Python,https://github.com/TorchEnsemble-Community/Ensemble-Pytorch,https://ensemble-pytorch.readthedocs.io/,BSD-3-Clause,pytorch;ensemble-learning;robustness;deep-learning
865,TrustJudge,Probabilistic evaluation framework for LLM-as-a-judge systems,"A framework designed to reduce score-comparison and pairwise transitivity inconsistencies in Large Language Model (LLM) based evaluation systems, enhancing the reliability of automated judging.",AI3;AI3-04,model_evaluation;llm_as_a_judge,library,Python,https://github.com/TrustJudge/TrustJudge,,MIT,llm-evaluation;reliability;benchmarking
866,Adversarial Robustness Toolbox (ART),Python library for machine learning security and robustness,"A comprehensive library for machine learning security, providing tools for evasion, poisoning, extraction, and inference attacks, as well as defenses and robustness certification for red and blue teams.",AI3;AI3-04,adversarial_attack;robustness_testing;model_defense,library,Python,https://github.com/Trusted-AI/adversarial-robustness-toolbox,https://adversarial-robustness-toolbox.readthedocs.io/,MIT,adversarial-ml;security;robustness;red-teaming
867,TransferAttack,Framework for transferable adversarial attacks,A PyTorch-based framework specifically designed to benchmark and boost the transferability of adversarial attacks in image classification tasks.,AI3;AI3-04,adversarial_attack;robustness_testing,library,Python,https://github.com/Trustworthy-AI-Group/TransferAttack,,MIT,adversarial-transferability;pytorch;security
868,vllm-safety-benchmark,Safety evaluation benchmark for Vision LLMs,"A benchmark suite for evaluating the safety of Vision Large Language Models (VLLMs), focusing on detecting vulnerabilities and unsafe outputs in multimodal contexts.",AI3;AI3-04,safety_evaluation;multimodal_benchmarking,dataset,Python,https://github.com/UCSC-VLAA/vllm-safety-benchmark,,None,vllm;safety;benchmark;vision-language
869,Inspect,Framework for large language model evaluations,"An open-source framework developed by the UK AI Safety Institute for creating and running evaluations of large language models, supporting diverse metrics and safety checks.",AI3;AI3-04,model_evaluation;safety_testing,framework,Python,https://github.com/UKGovernmentBEIS/inspect_ai,https://inspect.ai-safety-institute.org.uk/,MIT,llm-eval;ai-safety;benchmarking
870,LLM-judge-reporting,Statistical reporting framework for LLM-as-a-judge,"A plug-in framework that corrects bias and computes confidence intervals for LLM-as-a-judge evaluations, including adaptive algorithms for sample allocation.",AI3;AI3-04,evaluation_statistics;bias_correction,library,Jupyter Notebook,https://github.com/UW-Madison-Lee-Lab/LLM-judge-reporting,,None,statistics;llm-evaluation;confidence-intervals
871,Pangaea-Bench,Evaluation benchmark for geospatial foundation models,A benchmark suite designed to evaluate the robustness and performance of foundation models in geospatial and earth science tasks.,AI3;AI3-04;Earth Science,domain_benchmarking;robustness_testing,dataset,Python,https://github.com/VMarsocci/pangaea-bench,,GPL-3.0,geospatial;foundation-models;earth-science;benchmark
872,Fair Sense AI,Bias detection and risk management tool for AI,"An AI-powered tool for detecting bias and managing risks in AI systems, promoting sustainable and trustworthy AI development.",AI3;AI3-04,bias_detection;risk_management,library,Python,https://github.com/VectorInstitute/fair-sense-ai,,NOASSERTION,fairness;bias-detection;trustworthy-ai
873,owl-eval,Evaluation harness for diffusion world models,A TypeScript-based evaluation harness specifically designed for assessing the performance of diffusion-based world models.,AI3;AI3-04,model_evaluation;diffusion_models,framework,TypeScript,https://github.com/Wayfarer-Labs/owl-eval,,MIT,world-models;diffusion;evaluation
874,CValues,Evaluation and alignment for Chinese LLM values,"A project focused on evaluating and aligning the values of Chinese Large Language Models, providing datasets and methodologies for value assessment.",AI3;AI3-04,value_alignment;model_evaluation,dataset,Python,https://github.com/X-PLUG/CValues,,Apache-2.0,alignment;chinese-llm;evaluation
875,VLBiasBench,Benchmark for social biases in Large Vision-Language Models,A large-scale dataset and benchmark composed of synthetic images aimed at evaluating and analyzing social biases in Large Vision-Language Models (LVLMs).,AI3;AI3-04,bias_evaluation;multimodal_benchmarking,dataset,Python,https://github.com/Xiangkui-Cao/VLBiasBench,,NOASSERTION,bias;lvlm;synthetic-data;benchmark
876,DASH,Detection and Assessment of Systematic Hallucinations of VLMs,"A tool and framework for detecting and assessing systematic hallucinations in Vision-Language Models, helping to quantify model reliability.",AI3;AI3-04,hallucination_detection;model_evaluation,library,Python,https://github.com/YanNeu/DASH,,None,hallucination;vlm;evaluation
877,Veridical Flow,Framework for trustworthy data-science pipelines,"A tool to facilitate building stable and trustworthy data-science pipelines based on the PCS (Predictability, Computability, Stability) framework.",AI3;AI3-04;Data Science,pipeline_stability;trustworthiness,framework,Jupyter Notebook,https://github.com/Yu-Group/veridical-flow,,MIT,data-science;pcs-framework;stability
878,Whisper-AT,Noise-robust automatic speech recognition and audio tagging,"A unified model and toolkit for automatic speech recognition (ASR) and audio tagging, emphasizing noise robustness and multi-task learning capabilities.",AI3;Audio,speech_recognition;audio_tagging,solver,Python,https://github.com/YuanGongND/whisper-at,,BSD-2-Clause,asr;audio-tagging;whisper;robustness
879,ECC,Affective bias-inspired measures for visual emotion recognition,"Implementation of evaluation measures for Visual Emotion Recognition (VER) that account for affective biases, aiming to err more like humans.",AI3;AI3-04,evaluation_metric;emotion_recognition,library,Python,https://github.com/ZhaoChenxi-nku/ECC,,None,emotion-recognition;evaluation-metric;bias
880,TransferAttackEval,Evaluation framework for transferable adversarial images,"A codebase for revisiting and evaluating transferable adversarial images, providing tools to assess attack performance across different models.",AI3;AI3-04,adversarial_evaluation;robustness_testing,library,Python,https://github.com/ZhengyuZhao/TransferAttackEval,,None,adversarial-attack;transferability;evaluation
881,math-evaluation-harness,Benchmark toolkit for LLM mathematical reasoning,A simple toolkit designed for benchmarking Large Language Models on various mathematical reasoning tasks.,AI3;AI3-04,model_benchmarking;math_reasoning,framework,Python,https://github.com/ZubinGou/math-evaluation-harness,,MIT,math;llm-benchmark;reasoning
882,ZoneEval,Evaluation tool for spatial bias in object detection,"A tool for revealing and evaluating spatial bias in object detection models, providing insights into performance variations across different image zones.",AI3;AI3-04,bias_analysis;object_detection_eval,library,Jupyter Notebook,https://github.com/Zzh-tju/ZoneEval,,Apache-2.0,object-detection;spatial-bias;evaluation
883,ACADO Toolkit,Toolkit for automatic control and dynamic optimization,"A software environment and algorithm collection for automatic control and dynamic optimization, supporting model predictive control and parameter estimation.",Scientific Computing;Control Theory,optimal_control;dynamic_optimization,library,C++,https://github.com/acado/acado,http://acado.github.io/,LGPL-3.0,optimization;control-theory;mpc;c++
884,AdvBox,Adversarial example generation and robustness benchmark toolbox,"A toolbox to generate adversarial examples to fool neural networks across multiple frameworks (PaddlePaddle, PyTorch, etc.) and benchmark the robustness of machine learning models.",AI3;AI3-04,adversarial_attack;robustness_benchmarking,framework,Jupyter Notebook,https://github.com/advboxes/AdvBox,,Apache-2.0,adversarial-examples;robustness;paddlepaddle;pytorch
885,T2ISafety,"Benchmark for assessing fairness, toxicity, and privacy in image generation","A benchmark suite for evaluating safety aspects such as fairness, toxicity, and privacy in Text-to-Image (T2I) generation models.",AI3;AI3-04,safety_benchmarking;image_generation_eval,dataset,Python,https://github.com/adwardlee/t2i_safety,,None,text-to-image;safety;fairness;benchmark
886,PromptInject,Framework for adversarial prompt attacks on LLMs,A modular framework for assembling prompts to quantitatively analyze the robustness of Large Language Models (LLMs) to adversarial prompt injection attacks.,AI3;AI3-04,prompt_injection;robustness_analysis,framework,Python,https://github.com/agencyenterprise/PromptInject,,MIT,prompt-injection;llm-security;red-teaming
887,AgentFence,Platform for AI agent security testing,"An open-source platform for automatically testing the security of AI agents, identifying vulnerabilities like prompt injection, secret leakage, and instruction exposure.",AI3;AI3-04,agent_security;vulnerability_scanning,platform,Python,https://github.com/agentfence/agentfence,,MIT,ai-agents;security-testing;red-teaming
888,judgy,Confidence interval estimator for LLM-as-a-Judge metrics,"A Python package for estimating confidence intervals for metrics evaluated by LLM-as-a-Judge systems, helping to quantify uncertainty in automated evaluations.",AI3;AI3-04,evaluation_statistics;uncertainty_quantification,library,Python,https://github.com/ai-evals-course/judgy,,MIT,statistics;llm-evaluation;confidence-intervals
889,AIMon Python SDK,SDK for detecting LLM hallucinations and quality issues,"The Python SDK for AIMon, a system for detecting Large Language Model (LLM) quality issues such as hallucinations during evaluation or continuous monitoring.",AI3;AI3-04,hallucination_detection;model_monitoring,library,Python,https://github.com/aimonlabs/aimon-python-sdk,,MIT,hallucination;llm-monitoring;quality-control
890,ABLE,Ableism Bias Language Evaluation tool,A project to research and evaluate how AI systems reproduce discriminatory content and biases related to ableism.,AI3;AI3-04,bias_evaluation;ethics,library,Python,https://github.com/aktionmensch/ABLE,,MIT,bias;ableism;ai-ethics
891,safety-eval,Evaluation toolkit for generative language models and safety classifiers,"A simple evaluation framework designed to assess the safety and robustness of generative language models and safety classifiers, providing metrics for potential harms.",AI3;AI3-04,model_evaluation;safety_check,library,Python,https://github.com/allenai/safety-eval,,NOASSERTION,safety;evaluation;llm;generative-ai
892,last_layer,Fast LLM prompt injection and jailbreak detection library,"A lightweight and ultra-fast Python library designed to detect prompt injections and jailbreak attempts in Large Language Models (LLMs), suitable for real-time security monitoring.",AI3;AI3-04,security_monitoring;jailbreak_detection,library,Python,https://github.com/arekusandr/last_layer,,MIT,prompt-injection;jailbreak-detection;llm-security;robustness
893,OD-test,Evaluation framework for Out-of-Distribution detectors,"A library for evaluating Out-of-Distribution (OOD) detection methods in a less biased manner, providing standardized metrics and datasets for robust model assessment.",AI3;AI3-04,ood_detection;model_evaluation,library,Python,https://github.com/ashafaei/OD-test,,MIT,ood;out-of-distribution;evaluation;pytorch
894,BEIR,Heterogeneous benchmark for information retrieval,"A heterogeneous benchmark for zero-shot evaluation of information retrieval models across diverse datasets, facilitating robust assessment of retrieval systems.",AI3;AI3-04,information_retrieval;model_evaluation;benchmarking,library,Python,https://github.com/beir-cellar/beir,,Apache-2.0,information-retrieval;benchmark;zero-shot;evaluation
895,Foolbox,Adversarial attacks toolbox for neural networks,"A Python toolbox to create adversarial examples that fool neural networks, supporting PyTorch, TensorFlow, and JAX, used for evaluating model robustness.",AI3;AI3-04,adversarial_attack;robustness_evaluation,library,Python,https://github.com/bethgelab/foolbox,https://foolbox.readthedocs.io,MIT,adversarial-attacks;robustness;pytorch;tensorflow;jax
896,model-vs-human,Benchmark for comparing model robustness against human perception,"A benchmark framework to evaluate machine learning models on out-of-distribution datasets with collected human comparison data, assessing robustness and alignment with human perception.",AI3;AI3-04,ood_evaluation;human_comparison;robustness,library,Python,https://github.com/bethgelab/model-vs-human,,None,benchmark;ood;human-alignment;computer-vision
897,BigCode Evaluation Harness,Evaluation framework for code generation models,"A framework for the evaluation of autoregressive code generation language models, supporting various coding benchmarks and metrics.",AI3;AI3-04,code_generation_eval;model_benchmarking,library,Python,https://github.com/bigcode-project/bigcode-evaluation-harness,,Apache-2.0,code-generation;evaluation;llm;benchmark
898,gmmreg,Robust point set registration using Gaussian Mixture Models,"C++ implementation of the robust point set registration algorithm using Gaussian Mixture Models (GMM), used for aligning point cloud data in computer vision and medical imaging.",AI3;AI3-04,point_set_registration;data_alignment,solver,C++,https://github.com/bing-jian/gmmreg,,GPL-3.0,point-cloud;registration;gmm;computer-vision
899,nn_robust_attacks,Robust evasion attacks implementation (Carlini & Wagner),"Implementation of robust evasion attacks against neural networks (including the Carlini & Wagner attack), serving as a standard baseline for evaluating model robustness.",AI3;AI3-04,adversarial_attack;robustness_benchmarking,library,Python,https://github.com/carlini/nn_robust_attacks,,BSD-2-Clause,adversarial-attacks;robustness;carlini-wagner;neural-networks
900,yet-another-applied-llm-benchmark,Applied benchmark for evaluating LLM problem-solving capabilities,"A benchmark suite designed to evaluate Large Language Models on practical, applied questions and problem-solving tasks.",AI3;AI3-04,model_benchmarking;llm_evaluation,library,Python,https://github.com/carlini/yet-another-applied-llm-benchmark,,GPL-3.0,llm;benchmark;evaluation;applied-ai
901,HarmBench,Standardized evaluation framework for automated red teaming,"A standardized evaluation framework for automated red teaming and robust refusal, designed to assess the safety and security of Large Language Models.",AI3;AI3-04,red_teaming;safety_evaluation;robustness,framework,Jupyter Notebook,https://github.com/centerforaisafety/HarmBench,https://www.harmbench.org,MIT,red-teaming;safety;llm;evaluation
902,Simple Black-box Adversarial Attacks,Implementation of simple black-box adversarial attacks for deep learning models,A Python implementation of the query-efficient black-box adversarial attack method proposed in the ICML 2019 paper. It allows researchers to evaluate the robustness of machine learning models against black-box attacks where gradients are unavailable.,AI3;AI3-04,adversarial_attack;robustness_testing,solver,Python,https://github.com/cg563/simple-blackbox-attack,,MIT,adversarial-attacks;black-box-attacks;robustness;deep-learning
903,CleverHans,Adversarial example library for constructing attacks and building defenses,A Python library to benchmark machine learning systems' vulnerability to adversarial examples. It provides standard implementations of state-of-the-art attack algorithms and defenses to facilitate robust model development.,AI3;AI3-04,adversarial_attack;robustness_testing;defense_benchmarking,library,Python,https://github.com/cleverhans-lab/cleverhans,,MIT,adversarial-machine-learning;security;robustness;benchmarking
904,Opik,"Platform for evaluating, testing, and monitoring LLM applications","An open-source platform designed to debug, evaluate, and monitor Large Language Model (LLM) applications. It provides tracing, automated evaluation metrics, and dashboards to ensure the reliability and performance of RAG systems and agents.",AI3;AI3-04,model_evaluation;monitoring;tracing,platform,Python,https://github.com/comet-ml/opik,https://www.comet.com/docs/opik/,Apache-2.0,llm-evaluation;observability;rag;monitoring
905,DeepEval,Unit testing and evaluation framework for LLMs,"An open-source evaluation framework for Large Language Models (LLMs). It allows developers to build and run unit tests for LLM applications, measuring metrics such as hallucination, answer relevancy, and faithfulness to ensure model quality.",AI3;AI3-04,model_evaluation;unit_testing;hallucination_detection,library,Python,https://github.com/confident-ai/deepeval,https://docs.confident-ai.com/,Apache-2.0,llm-evaluation;testing;metrics;rag
906,DeepTeam,Automated red teaming framework for LLMs,"A framework designed to automate the red teaming process for Large Language Models. It helps identify vulnerabilities, biases, and safety issues in LLM systems through automated adversarial testing.",AI3;AI3-04,red_teaming;safety_testing;vulnerability_scanning,library,Python,https://github.com/confident-ai/deepteam,,Apache-2.0,red-teaming;llm-safety;adversarial-testing
907,3DFuse,Robust text-to-3D generation using 2D diffusion models,"A framework that leverages pre-trained 2D diffusion models to generate 3D consistent assets from text prompts. It introduces a method to inject 3D consistency into 2D models, enabling robust 3D generation for scientific and creative applications.",AI3;AI3-03,3d_generation;generative_modeling,solver,Python,https://github.com/cvlab-kaist/3DFuse,,None,text-to-3d;diffusion-models;3d-generation;nerf
908,UQLM,Uncertainty quantification and hallucination detection for LLMs,"A Python package for quantifying uncertainty in Large Language Models to detect hallucinations. It provides methods to estimate the confidence of model generations, aiding in the reliability assessment of LLM outputs.",AI3;AI3-04,uncertainty_quantification;hallucination_detection;model_evaluation,library,Python,https://github.com/cvs-health/uqlm,,Apache-2.0,uncertainty-quantification;hallucination;llm;reliability
909,Simple LLM Eval,Lightweight library for LLM evaluation using LLM-as-a-Judge,A simple Python library that implements the 'LLM-as-a-Judge' paradigm for evaluating Large Language Model outputs. It facilitates the creation of automated evaluation pipelines using stronger models to judge weaker ones.,AI3;AI3-04,model_evaluation;llm_as_a_judge,library,Python,https://github.com/cyberark/simple-llm-eval,,Apache-2.0,llm-evaluation;automation;testing
910,GNN Meta Attack,Adversarial attacks on Graph Neural Networks via meta-learning,An implementation of adversarial attacks on Graph Neural Networks (GNNs) using meta-learning techniques. It allows researchers to evaluate the robustness of GNN models against perturbations in graph structure and node features.,AI3;AI3-04,adversarial_attack;graph_neural_networks;robustness_testing,solver,Python,https://github.com/danielzuegner/gnn-meta-attack,,MIT,gnn;adversarial-attacks;meta-learning;graph-mining
911,Nettack,Adversarial attacks on Neural Networks for Graph Data,"A tool for generating adversarial attacks on Graph Neural Networks, specifically targeting node classification tasks. It helps in assessing the vulnerability of graph-based models to structural and feature perturbations.",AI3;AI3-04,adversarial_attack;graph_neural_networks;robustness_testing,solver,Python,https://github.com/danielzuegner/nettack,,MIT,gnn;adversarial-attacks;graph-data;security
912,MAGSAC,Robust model fitting algorithm without inlier-outlier threshold,An implementation of the MAGSAC (Model Agnostic Sample Consensus) algorithm for robust model estimation in computer vision. It improves upon RANSAC by eliminating the need for a manually tuned inlier-outlier threshold.,AI3;AI3-04,model_fitting;robust_estimation;computer_vision,solver,C++,https://github.com/danini/magsac,,NOASSERTION,ransac;robust-estimation;computer-vision;model-fitting
913,Bisheng,Open LLM DevOps platform for application development and evaluation,"A comprehensive platform for developing, managing, and evaluating Large Language Model applications. It includes features for RAG, agent workflows, model evaluation, and dataset management, facilitating the full lifecycle of enterprise AI apps.",AI3;AI3-04,model_evaluation;llmops;rag_management,platform,TypeScript,https://github.com/dataelement/bisheng,https://bisheng.dataelement.com/,Apache-2.0,llmops;rag;evaluation;agent
914,HuMoR,3D Human Motion Model for Robust Pose Estimation,"A library implementing a generative model for 3D human motion, used for robust pose estimation and motion generation. It enables the recovery of plausible 3D human motion from noisy or partial observations.",AI3;AI3-03,pose_estimation;motion_modeling;3d_reconstruction,solver,Python,https://github.com/davrempe/humor,,MIT,human-motion;pose-estimation;generative-model;3d-vision
915,WEFE,Word Embeddings Fairness Evaluation Framework,"A framework for measuring and mitigating bias in word embedding models. It standardizes various fairness metrics to evaluate gender, racial, and other biases in pre-trained embeddings.",AI3;AI3-04,bias_evaluation;fairness_metrics;embedding_analysis,library,Python,https://github.com/dccuchile/wefe,https://wefe.readthedocs.io/,MIT,fairness;bias-detection;word-embeddings;nlp
916,Vigil LLM,Security scanner for detecting prompt injections and jailbreaks in LLMs,"A security tool designed to detect and mitigate risks in Large Language Model inputs, such as prompt injections and jailbreak attempts. It acts as a firewall or scanner for LLM applications.",AI3;AI3-04,prompt_injection_detection;jailbreak_detection;security_scanning,solver,Python,https://github.com/deadbits/vigil-llm,,Apache-2.0,llm-security;prompt-injection;jailbreak;defense
917,DebiAI,Bias detection and contextual evaluation tool for AI projects,"A tool for visualizing and analyzing AI model performance to detect biases and errors. It allows users to explore model results in context, identify underperforming subsets of data, and ensure model fairness.",AI3;AI3-04,bias_detection;model_evaluation;error_analysis,platform,Vue,https://github.com/debiai/DebiAI,https://debiai.io/,Apache-2.0,bias-detection;visualization;evaluation;fairness
918,HaloScope,Hallucination detection using unlabeled LLM generations,A tool implementing the HaloScope method for detecting hallucinations in Large Language Models. It leverages unlabeled generations to identify inconsistencies and factual errors without requiring extensive labeled datasets.,AI3;AI3-04,hallucination_detection;model_evaluation,solver,Python,https://github.com/deeplearning-wisc/haloscope,,None,hallucination;llm;evaluation;consistency
919,LLM Prompt Injection Filtering,Safety filter for LLM inputs using LLM-based classification,"A Python tool that uses a secondary LLM call to evaluate user inputs for safety, specifically filtering out prompt injection attacks and dangerous queries before they reach the main model.",AI3;AI3-04,input_filtering;safety_guardrails;prompt_injection_defense,solver,Python,https://github.com/derwiki/llm-prompt-injection-filtering,,None,prompt-injection;safety;filtering;llm
920,PHUDGE,Scalable LLM-as-a-Judge framework using Phi-3,"A framework for evaluating LLMs using the Phi-3 model as a scalable judge. It supports custom rubrics, reference-based and reference-free evaluation, and hallucination detection.",AI3;AI3-04,model_evaluation;llm_as_a_judge;grading,library,Jupyter Notebook,https://github.com/deshwalmahesh/PHUDGE,,None,llm-evaluation;judge;phi-3;grading
921,Ollama Grid Search,Desktop application for evaluating and comparing local LLMs,A cross-platform desktop tool designed to perform grid search evaluations on local LLMs (via Ollama). It allows users to compare model outputs across different parameters and prompts to assess performance.,AI3;AI3-04,model_evaluation;parameter_tuning;comparison,platform,TypeScript,https://github.com/dezoito/ollama-grid-search,,MIT,llm-evaluation;ollama;grid-search;local-llm
922,Diffusion Classifier,Zero-shot classification using pretrained diffusion models,"A method and library for performing zero-shot image classification by leveraging the density estimates of pretrained diffusion models, without requiring additional training or fine-tuning.",AI3;AI3-04,zero_shot_classification;model_inference;diffusion_models,solver,Python,https://github.com/diffusion-classifier/diffusion-classifier,,None,diffusion-models;classification;zero-shot;inference
923,Docling SDG,Synthetic data generation from documents for AI training,A toolkit for generating synthetic training data from document sources. It helps in creating labeled datasets for training or evaluating AI models when real data is scarce or sensitive.,AI3;AI3-01,synthetic_data_generation;data_augmentation,library,Python,https://github.com/docling-project/docling-sdg,,MIT,synthetic-data;document-processing;data-generation
924,AI Eval System,Frontend UI system for OpenCompass model evaluation,"A web-based evaluation system built on top of OpenCompass, providing a user interface for configuring and running AI model evaluations. It simplifies the process of benchmarking models for researchers.",AI3;AI3-04,model_evaluation;benchmarking_platform,platform,Vue,https://github.com/domonic18/ai-eval-system,,Apache-2.0,evaluation-ui;opencompass;benchmarking
925,Non-Targeted Adversarial Attacks,Implementation of momentum-based non-targeted adversarial attacks,Code implementation for the NIPS 2017 competition winning method on non-targeted adversarial attacks. It provides algorithms to generate adversarial examples that mislead models into incorrect classifications.,AI3;AI3-04,adversarial_attack;robustness_testing,solver,Python,https://github.com/dongyp13/Non-Targeted-Adversarial-Attacks,,Apache-2.0,adversarial-attacks;deep-learning;robustness
926,Targeted Adversarial Attack,Implementation of momentum-based targeted adversarial attacks,Code implementation for the NIPS 2017 competition winning method on targeted adversarial attacks. It enables the generation of perturbations that force a model to classify an input as a specific target class.,AI3;AI3-04,adversarial_attack;robustness_testing,solver,Python,https://github.com/dongyp13/Targeted-Adversarial-Attack,,Apache-2.0,adversarial-attacks;targeted-attack;robustness
927,Translation-Invariant Attacks,Translation-invariant adversarial attack method for transferability,Implementation of the translation-invariant attack method designed to improve the transferability of adversarial examples across different models. It is useful for black-box robustness testing.,AI3;AI3-04,adversarial_attack;transferability;robustness_testing,solver,Python,https://github.com/dongyp13/Translation-Invariant-Attacks,,Apache-2.0,adversarial-attacks;transferability;robustness
928,SafeDialBench,Multi-turn dialogue benchmark for evaluating LLM safety,A comprehensive multi-turn dialogue benchmark dataset and evaluation framework designed to assess the safety of Large Language Models across various risk categories.,AI3;AI3-04,safety_evaluation;benchmark_dataset,dataset,Python,https://github.com/drivetosouth/SafeDialBench-Dataset,,None,llm-safety;benchmark;dialogue-systems
929,FormatBiasEval,Evaluation framework for output format bias in LLMs,"Official implementation for evaluating and mitigating output format bias in Large Language Models, providing metrics to quantify how format constraints affect model reasoning and performance.",AI3;AI3-04,bias_evaluation;model_robustness,library,Python,https://github.com/dxlong2000/FormatBiasEval,,None,llm-bias;format-bias;evaluation-metric
930,ibicus,Bias correction toolkit for climate models,"A flexible Python toolkit for the bias correction of climate models and associated evaluation, implementing various state-of-the-art methods for meteorological data adjustment.",AI3;AI3-04,bias_correction;climate_modeling;evaluation,library,Jupyter Notebook,https://github.com/ecmwf-projects/ibicus,https://ibicus.readthedocs.io,Apache-2.0,climate-science;bias-correction;meteorology
931,STEGOSAURUS-WRECKS,Steganographic prompt injection tool for AI red teaming,A tool for automatically encoding images with steganographic payloads to act as prompt injections or jailbreaks for multimodal AI systems with code interpreter and vision capabilities.,AI3;AI3-04,red_teaming;adversarial_attack;prompt_injection,solver,Python,https://github.com/elder-plinius/STEGOSAURUS-WRECKS,,AGPL-3.0,steganography;prompt-injection;red-teaming;multimodal-security
932,acceptance-bench,LLM evaluation framework for acceptance vs refusal behavior,"A robust evaluation framework for measuring Large Language Model acceptance versus refusal rates across difficulty levels, featuring multi-prompt variation testing and LLM-as-judge evaluation mechanisms.",AI3;AI3-04,safety_evaluation;refusal_benchmarking,library,Python,https://github.com/ellydee/acceptance-bench,,MIT,llm-evaluation;safety-alignment;benchmarking
933,RL2Grid,Reinforcement learning benchmark for power grid operations,"A standardized benchmark for reinforcement learning agents in realistic power grid environments, modeling real-time operations, topology optimization, and safety-critical constraints.",AI3;AI3-04,rl_benchmark;power_grid_simulation;safety_evaluation,library,Python,https://github.com/emarche/RL2Grid,,MIT,reinforcement-learning;power-grid;benchmark
934,ChatProtect,Hallucination detection and mitigation for LLMs,"Implementation of methods for evaluating, detecting, and mitigating self-contradictory hallucinations in Large Language Models, focusing on improving model reliability.",AI3;AI3-04,hallucination_detection;model_evaluation;mitigation,library,Python,https://github.com/eth-sri/ChatProtect,,Apache-2.0,hallucination;llm-reliability;evaluation
935,diffai,Certifiable defense against adversarial examples,"A system for training neural networks to be provably robust against adversarial examples, providing certifiable defenses for deep learning models.",AI3;AI3-04,adversarial_defense;robustness_verification;model_training,library,Python,https://github.com/eth-sri/diffai,,MIT,adversarial-robustness;formal-verification;deep-learning
936,EvalPlus,Rigorous evaluation framework for LLM-synthesized code,A framework for rigorously evaluating code generation models (like HumanEval+) by generating large amounts of test cases to ensure functional correctness and robustness.,AI3;AI3-04,code_evaluation;model_benchmarking,library,Python,https://github.com/evalplus/evalplus,https://evalplus.github.io,Apache-2.0,code-generation;evaluation;llm
937,decoding-biases,Bias evaluation scripts for NLG models,A collection of scripts and tools to evaluate various bias metrics for Natural Language Generation models across different decoding algorithms.,AI3;AI3-04,bias_evaluation;nlg_assessment,library,Python,https://github.com/ewsheng/decoding-biases,,MIT,bias-metrics;nlg;evaluation
938,Meta SecAlign,Secure foundation LLM against prompt injection,"Implementation of Meta SecAlign, a method to create secure foundation LLMs that are robust against prompt injection attacks through safety alignment techniques.",AI3;AI3-04,safety_alignment;prompt_injection_defense,library,Python,https://github.com/facebookresearch/Meta_SecAlign,,NOASSERTION,llm-safety;prompt-injection;alignment
939,rl-injector,RL-based prompt injection attack generation,A reinforcement learning approach to generating stronger prompt injection attacks for evaluating the robustness of Large Language Models.,AI3;AI3-04,red_teaming;adversarial_attack;rl_generation,library,Python,https://github.com/facebookresearch/rl-injector,,NOASSERTION,red-teaming;reinforcement-learning;prompt-injection
940,unibench,Robustness evaluation library for VLM models,A Python library designed to evaluate the robustness of Vision-Language Models (VLMs) across diverse benchmarks and multimodal tasks.,AI3;AI3-04,vlm_evaluation;robustness_benchmarking,library,Jupyter Notebook,https://github.com/facebookresearch/unibench,,NOASSERTION,vlm;robustness;benchmarking
941,Bank Account Fraud Dataset,Datasets for evaluating ML fairness and robustness in fraud detection,"A suite of biased, imbalanced, and dynamic tabular datasets designed for evaluating machine learning models in fraud detection scenarios, specifically focusing on fairness and robustness metrics.",AI3;AI3-04,fairness_evaluation;dataset_benchmarking,dataset,Jupyter Notebook,https://github.com/feedzai/bank-account-fraud,,NOASSERTION,ml-fairness;fraud-detection;evaluation-dataset
942,NewsWCL50,Evaluation dataset for media bias identification,"An open-access evaluation dataset for methods to identify bias by word choice and labeling in news media, facilitating the development of bias detection algorithms.",AI3;AI3-04,bias_detection;dataset_benchmarking,dataset,,https://github.com/fhamborg/NewsWCL50,,CC-BY-SA-4.0,media-bias;nlp-dataset;evaluation
943,Fiddler Auditor,Tool for evaluating language model robustness and bias,"An open-source tool designed to evaluate Large Language Models for robustness, bias, and correctness through perturbation testing and other evaluation techniques.",AI3;AI3-04,model_evaluation;robustness_testing;bias_detection,library,Python,https://github.com/fiddler-labs/fiddler-auditor,https://docs.fiddler.ai,NOASSERTION,llm-evaluation;robustness;red-teaming
944,Video-SafetyBench,Benchmark for safety evaluation of Video LVLMs,"A benchmark suite specifically designed for evaluating the safety of Video Large Vision-Language Models (LVLMs), covering various safety dimensions and risk categories.",AI3;AI3-04,safety_benchmarking;video_llm_evaluation,dataset,Python,https://github.com/flageval-baai/Video-SafetyBench,,None,video-llm;safety-benchmark;evaluation
945,AutoAttack,Ensemble of parameter-free attacks for robustness evaluation,"A reliable evaluation framework for adversarial robustness using an ensemble of diverse parameter-free attacks (APGD, etc.) to test deep learning models.",AI3;AI3-04,adversarial_attack;robustness_evaluation,library,Python,https://github.com/fra31/auto-attack,,MIT,adversarial-robustness;deep-learning;attack-ensemble
946,gender-bias,Library for detecting gender bias in text,"A Python library designed to detect and measure gender bias in natural language text, useful for evaluating NLP datasets and model outputs.",AI3;AI3-04,bias_detection;text_analysis,library,Python,https://github.com/gender-bias/gender-bias,,MIT,gender-bias;nlp;fairness
947,TOG,Adversarial objectness gradient attacks for object detection,"Implementation of TOG (Targeted Adversarial Objectness Gradient) attacks, a suite of adversarial attacks designed to deceive object detection systems (vanishing, fabrication, mislabeling).",AI3;AI3-04,adversarial_attack;object_detection_robustness,library,Jupyter Notebook,https://github.com/git-disl/TOG,,None,adversarial-attack;object-detection;computer-vision
948,camel-prompt-injection,Code for defeating prompt injections by design,"Research code and implementation for the paper 'Defeating Prompt Injections by Design', providing methods and evaluations for securing LLMs against injection attacks.",AI3;AI3-04,prompt_injection_defense;safety_research,library,Jupyter Notebook,https://github.com/google-research/camel-prompt-injection,,Apache-2.0,prompt-injection;llm-security;defense
949,lapeigvals,Hallucination detection using spectral features of attention maps,Implementation of a method to detect hallucinations in Large Language Models by analyzing the spectral features (Laplacian eigenvalues) of their attention maps.,AI3;AI3-04,hallucination_detection;model_interpretability,library,Python,https://github.com/graphml-lab-pwr/lapeigvals,,None,hallucination;spectral-analysis;attention-maps
950,PromptCARE,Prompt copyright protection via watermark injection,"A tool for protecting the copyright of prompts in LLMs by injecting and verifying watermarks, ensuring intellectual property protection for prompt engineering.",AI3;AI3-04,copyright_protection;watermarking;model_security,library,Python,https://github.com/grasses/PromptCARE,,MIT,watermarking;prompt-protection;security
951,MM-Eval,Multilingual meta-evaluation benchmark for LLM-as-a-Judge and reward models,"A benchmark designed to evaluate the performance of LLM-as-a-Judge systems and reward models across multiple languages, focusing on meta-evaluation metrics.",AI3;AI3-04,model_evaluation;meta_evaluation,dataset,Jupyter Notebook,https://github.com/guijinSON/MM-Eval,,Apache-2.0,llm-as-a-judge;multilingual;benchmark
952,Verdict,Inference-time scaling library for LLM-as-a-judge systems,A library that implements inference-time scaling techniques to improve the accuracy and reliability of Large Language Models when used as evaluators (LLM-as-a-judge).,AI3;AI3-04,model_evaluation;inference_optimization,library,Jupyter Notebook,https://github.com/haizelabs/verdict,,MIT,llm-as-a-judge;scaling;evaluation
953,DDDM-VC,Decoupled Denoising Diffusion Models for robust voice conversion,"Official implementation of DDDM-VC, a voice conversion model using decoupled denoising diffusion models with disentangled representation and prior mixup.",AI2;AI3,voice_conversion;generative_modeling,solver,Python,https://github.com/hayeong0/DDDM-VC,,None,diffusion-models;voice-conversion;audio-processing
954,Adversarial Explainable AI,Library for adversarial attacks on Explainable AI (XAI) methods,"A collection of implementations for performing adversarial attacks on model explanations and methods to defend against them, facilitating robustness research in XAI.",AI3;AI3-04,adversarial_attack;explainability_evaluation,library,Python,https://github.com/hbaniecki/adversarial-explainable-ai,,CC-BY-SA-4.0,xai;adversarial-attacks;robustness
955,HalluciDet,Hallucination-based RGB modality generation for person detection,"Implementation of a method that hallucinates RGB modality from other inputs to improve person detection, using privileged information during training.",AI2;Computer Vision,object_detection;modality_hallucination,solver,Python,https://github.com/heitorrapela/HalluciDet,,MIT,computer-vision;person-detection;multimodal
956,EvalView,Pytest-style test harness for AI agent evaluation,"A testing framework for AI agents that supports YAML scenarios, tool-call checks, cost/latency tracking, and safety evaluations in a CI-friendly format.",AI3;AI3-04,agent_evaluation;test_harness,workflow,Python,https://github.com/hidai25/eval-view,,Apache-2.0,ai-agents;evaluation;testing-framework
957,HolisticAI,Library for assessing and improving AI system trustworthiness,"An open-source tool to measure and mitigate risks in AI systems, focusing on bias, efficacy, robustness, and explainability.",AI3;AI3-04,trustworthiness_assessment;bias_detection,library,Jupyter Notebook,https://github.com/holistic-ai/holisticai,https://holisticai.readthedocs.io/,Apache-2.0,ai-safety;bias;fairness
958,Circular Bias Detection,Statistical framework for detecting circular reasoning bias in AI evaluation,A comprehensive statistical framework designed to detect circular reasoning bias in the evaluation of AI algorithms.,AI3;AI3-04,evaluation_bias;statistical_analysis,library,Python,https://github.com/hongping-zh/circular-bias-detection,,MIT,bias-detection;evaluation;statistics
959,TrustworthyAI,Collection of projects and tools for Trustworthy AI research,"A repository containing various tools and libraries developed by Huawei Noah's Ark Lab for research in trustworthy AI, including robustness, explainability, and fairness.",AI3;AI3-04,trustworthy_ai;robustness;explainability,platform,Python,https://github.com/huawei-noah/trustworthyAI,,Apache-2.0,trustworthy-ai;robustness;causality
960,LightEval,Comprehensive toolkit for evaluating LLMs across multiple backends,"An all-in-one evaluation toolkit designed to assess Large Language Models using various metrics and benchmarks, supporting multiple inference backends.",AI3;AI3-04,model_evaluation;benchmarking,library,Python,https://github.com/huggingface/lighteval,,MIT,llm-evaluation;benchmarking;huggingface
961,Garak Analyzer & Mitigator,Tool for analyzing Garak reports and generating mitigations,"A utility to analyze adversarial reports generated by Garak, visualize attack attempts, detect triggers, and generate system prompt mitigations.",AI3;AI3-04,red_teaming_analysis;mitigation_generation,workflow,Python,https://github.com/huseyingulsin/Garak-Analyzer-Mitigator,,MIT,red-teaming;security;llm-safety
962,ChainForge,Visual programming environment for prompt engineering and evaluation,"An open-source visual environment for battle-testing, evaluating, and comparing prompts and responses from Large Language Models.",AI3;AI3-04,prompt_evaluation;model_comparison,platform,TypeScript,https://github.com/ianarawjo/ChainForge,https://chainforge.ai/,MIT,prompt-engineering;evaluation;visualization
963,JudgeIt,Automation framework for LLM-as-a-judge evaluation,"A framework using LLM-as-a-judge to evaluate Agentic AI, RAG systems, and Text2SQL applications at scale.",AI3;AI3-04,model_evaluation;llm-as-a-judge,workflow,Python,https://github.com/ibm-self-serve-assets/JudgeIt-LLM-as-a-Judge,,Apache-2.0,evaluation;rag;agentic-ai
964,PPTAgent,Agent for generating and evaluating presentation slides,"A system for generating presentations from text and evaluating them, moving beyond simple text-to-slide generation.",AI3;AI3-04,content_generation;evaluation,solver,Python,https://github.com/icip-cas/PPTAgent,,MIT,agent;presentation-generation;evaluation
965,Hallucination Detection,Tool for detecting hallucinations in BART summarization models,A tool to automatically detect hallucinations in BART summarization models by analyzing attention maps and decoding probabilities.,AI3;AI3-04,hallucination_detection;model_analysis,solver,Python,https://github.com/idiap/hallucination-detection,,MIT,nlp;hallucination;summarization
966,Innodata LLM Safety,Benchmarking suite for LLM safety and factuality,"A benchmarking tool for evaluating LLMs (Llama, Mistral, Gemma, GPT) on factuality, toxicity, bias, and hallucination propensity.",AI3;AI3-04,safety_benchmarking;model_evaluation,workflow,Python,https://github.com/innodatalabs/innodata-llm-safety,,Apache-2.0,llm-safety;benchmarking;toxicity
967,BIS,Benchmark on Interactive Safety for AI agents,A benchmark designed to evaluate the interactive safety of AI systems.,AI3;AI3-04,safety_benchmarking;interactive_evaluation,dataset,Python,https://github.com/intelligent-control-lab/BIS,,MIT,safety;benchmark;interactive-ai
968,Earthquake Detection,Deep metric learning algorithm for detecting dynamically triggered earthquakes,Code for automating the detection of dynamically triggered earthquakes using a deep metric learning algorithm.,Earth Science;Geophysics,earthquake_detection;signal_analysis,solver,Python,https://github.com/interactiveaudiolab/earthquakes,,None,seismology;deep-learning;detection
969,SAC3,Semantic-aware cross-check consistency for hallucination detection,"Implementation of SAC3, a method for reliable hallucination detection in black-box language models via semantic-aware cross-check consistency.",AI3;AI3-04,hallucination_detection;model_evaluation,solver,Jupyter Notebook,https://github.com/intuit/sac3,,Apache-2.0,hallucination;consistency-check;llm
970,ReadabilityMetrics,Library for computing text readability metrics,"A tool that computes various readability metrics (ARI, Coleman-Liau, Flesch-Kincaid, etc.) for text analysis.",AI2;NLP,text_analysis;metric_calculation,library,Java,https://github.com/ipeirotis/ReadabilityMetrics,,Apache-2.0,nlp;readability;text-analysis
971,DALL-Eval,Benchmark for reasoning skills and social biases in text-to-image models,A toolkit for probing the reasoning skills and social biases of text-to-image generation models.,AI3;AI3-04,model_evaluation;bias_detection,dataset,Jupyter Notebook,https://github.com/j-min/DallEval,,MIT,text-to-image;bias;evaluation
972,LLM Warden,Jailbreak detection tool for safeguarding LLMs,A tool designed to detect and prevent jailbreak attempts in Large Language Models.,AI3;AI3-04,jailbreak_detection;safety_guardrail,solver,Python,https://github.com/jackhhao/llm-warden,,MIT,llm-safety;jailbreak;security
973,Adversarial Library,PyTorch library for adversarial attacks,A library containing PyTorch implementations of various adversarial attacks for evaluating model robustness.,AI3;AI3-04,adversarial_attack;robustness_evaluation,library,Python,https://github.com/jeromerony/adversarial-library,,BSD-3-Clause,adversarial-attacks;pytorch;robustness
974,Fast Adversarial,Efficient gradient-based L2 adversarial attacks and defenses,Implementation of decoupled direction and norm methods for efficient gradient-based L2 adversarial attacks and defenses.,AI3;AI3-04,adversarial_attack;defense_mechanism,solver,Python,https://github.com/jeromerony/fast_adversarial,,BSD-3-Clause,adversarial-attacks;optimization;robustness
975,ModelNet40-C,Benchmark for 3D point cloud recognition robustness,A benchmark dataset and codebase for evaluating the robustness of 3D point cloud recognition models against common corruptions.,AI3;AI3-04;Computer Vision,robustness_benchmarking;3d_vision,dataset,Python,https://github.com/jiachens/ModelNet40-C,,BSD-3-Clause,3d-vision;robustness;point-cloud
976,runcharter,Automated run chart analysis and visualization tool,"An R package designed to automate the creation and analysis of run charts for faceted data displays across multiple metrics or locations, facilitating statistical process control and data visualization.",Scientific Visualization;Statistics,data_visualization;statistical_analysis,library,R,https://github.com/johnmackintosh/runcharter,,GPL-3.0,r-package;visualization;run-chart;statistics
977,adv_attack_capsnet,Adversarial attack implementation for Capsule Networks,"A TensorFlow implementation of adversarial attacks specifically targeting Capsule Networks, serving as a tool for evaluating the robustness of this specific neural network architecture.",AI3-04,adversarial_attack;robustness_evaluation,solver,Python,https://github.com/jsikyoon/adv_attack_capsnet,,None,adversarial-attacks;capsule-networks;robustness
978,Defense-GAN,Generative model-based defense against adversarial attacks,"An implementation of Defense-GAN, a mechanism that uses generative adversarial networks to project input images onto the range of the generator to purify adversarial perturbations before classification.",AI3-04,model_defense;robustness_evaluation,solver,Python,https://github.com/kabkabm/defensegan,,Apache-2.0,gan;adversarial-defense;security
979,VSDFLOW,Automated RTL-to-GDSII flow for semiconductor design,"An automated open-source hardware design flow that converts Verilog RTL designs into GDSII layouts, integrating synthesis, placement, routing, and timing analysis tools for semiconductor engineering.",Electronic Design Automation;Hardware Engineering,circuit_synthesis;layout_generation,workflow,Verilog,https://github.com/kunalg123/vsdflow,,Apache-2.0,eda;vlsi;rtl-to-gds;verilog
980,limited-blackbox-attacks,Black-box adversarial attacks with limited queries,"A research codebase implementing black-box adversarial attack methods that operate under restricted query budgets and partial information, used for evaluating model robustness in realistic threat models.",AI3-04,adversarial_attack;robustness_evaluation,solver,Python,https://github.com/labsix/limited-blackbox-attacks,,None,black-box-attacks;adversarial-ml;robustness
981,pint-benchmark,Benchmark for prompt injection detection systems,"A benchmark suite designed to evaluate the effectiveness of prompt injection detection systems in Large Language Models, providing a standardized dataset and evaluation metrics for AI safety research.",AI3-04,safety_evaluation;prompt_injection_benchmarking,dataset,Jupyter Notebook,https://github.com/lakeraai/pint-benchmark,,MIT,prompt-injection;benchmark;llm-safety
982,chembench,Chemistry evaluation benchmark for LLMs,"A framework and dataset for evaluating the capabilities of Large Language Models in solving chemistry-related tasks, assessing their scientific reasoning and domain knowledge.",AI3-04;Chemistry,domain_evaluation;scientific_reasoning,dataset,Python,https://github.com/lamalab-org/chembench,,MIT,chemistry;llm-evaluation;benchmark
983,Langfuse,LLM engineering platform for observability and evaluation,"An open-source platform providing observability, metrics, and evaluation pipelines for Large Language Models, enabling researchers and engineers to trace model execution, manage datasets, and run systematic evaluations.",AI3-04,model_evaluation;observability;metrics_tracking,platform,TypeScript,https://github.com/langfuse/langfuse,https://langfuse.com/docs,NOASSERTION,llm-ops;evaluation;observability
984,LangWatch,LLM Ops platform for analytics and evaluation,"A platform for monitoring and evaluating LLM applications, offering tools for trace analysis, dataset management, and prompt optimization to ensure model quality and safety.",AI3-04,model_evaluation;analytics,platform,TypeScript,https://github.com/langwatch/langwatch,https://docs.langwatch.ai,NOASSERTION,llm-ops;analytics;evaluation
985,Latitude,Prompt engineering and evaluation platform,"An open-source platform focused on the development, evaluation, and refinement of prompts for LLMs, providing tools to systematically test and improve model responses.",AI3-04,prompt_evaluation;prompt_engineering,platform,TypeScript,https://github.com/latitude-dev/latitude-llm,,LGPL-3.0,prompt-engineering;evaluation;llm
986,robotic_world_model,Neural network simulator for robotics policy optimization,"A neural network-based simulator designed to model robotic environments, facilitating robust policy optimization and reinforcement learning research in robotics.",Robotics;AI3,simulation;policy_optimization,solver,Python,https://github.com/leggedrobotics/robotic_world_model,,Apache-2.0,robotics;simulation;reinforcement-learning
987,PIGuard,Prompt injection guardrail via mitigating overdefense,"An implementation of a defense mechanism against prompt injection attacks that specifically addresses the issue of overdefense, serving as a tool for enhancing LLM safety.",AI3-04,safety_defense;prompt_injection_mitigation,solver,Python,https://github.com/leolee99/PIGuard,,MIT,prompt-injection;guardrails;llm-safety
988,Guided-Denoise,Denoising-based defense against adversarial attacks,"The winning submission for the NIPS 2017 Defense Against Adversarial Attack challenge, providing a guided denoising method to protect classifiers from adversarial perturbations.",AI3-04,model_defense;image_denoising,solver,Python,https://github.com/lfz/Guided-Denoise,,None,adversarial-defense;denoising;nips-2017
989,Open-Prompt-Injection,Benchmark for prompt injection attacks and defenses,A comprehensive benchmark repository for evaluating Large Language Models against various prompt injection attacks and assessing the effectiveness of defense mechanisms.,AI3-04,safety_benchmarking;prompt_injection,dataset,Python,https://github.com/liu00222/Open-Prompt-Injection,,MIT,prompt-injection;benchmark;llm-security
990,DSRL,Datasets and environment wrappers for safe reinforcement learning,"A collection of datasets and environment wrappers specifically designed for offline safe reinforcement learning research, facilitating the development and evaluation of safe RL algorithms.",AI3;Robotics,dataset_provision;environment_wrapping,dataset,Python,https://github.com/liuzuxin/DSRL,,Apache-2.0,safe-rl;offline-rl;datasets
991,RouteLLM,Framework for serving and evaluating LLM routers,"A framework designed to evaluate and deploy Large Language Model routers, enabling efficient model selection and cost optimization without compromising generation quality.",AI3-04,model_routing;efficiency_evaluation,framework,Python,https://github.com/lm-sys/RouteLLM,,Apache-2.0,llm-routing;evaluation;optimization
992,convex_adversarial,Provably robust neural network training method,"A library and method for training neural networks that are provably robust to adversarial attacks, utilizing convex relaxation techniques to certify robustness bounds.",AI3-04,robust_training;verification,library,Python,https://github.com/locuslab/convex_adversarial,,MIT,robustness;adversarial-training;verification
993,Square Attack,Query-efficient black-box adversarial attack algorithm for model robustness evaluation,"A Python implementation of Square Attack, a score-based black-box adversarial attack that does not rely on local gradient information. It is used to evaluate the robustness of machine learning models (particularly image classifiers) against adversarial perturbations in a query-efficient manner.",AI3;AI3-04,adversarial_attack;robustness_evaluation,solver,Python,https://github.com/max-andr/square-attack,,BSD-3-Clause,adversarial-attacks;black-box-attack;robustness
994,Video-ChatGPT,Video conversation model and quantitative evaluation benchmarking framework,A framework combining a video conversation model with a rigorous quantitative evaluation benchmarking suite. It enables the assessment of video-based conversational models using LLMs to generate meaningful conversations about videos and evaluate performance across various metrics.,AI3;AI3-04,model_evaluation;multimodal_benchmarking,workflow,Python,https://github.com/mbzuai-oryx/Video-ChatGPT,,CC-BY-4.0,video-llm;benchmarking;multimodal
995,Agent-as-a-Judge,Framework for evaluating open-ended agentic tasks using agents as judges,"A framework designed to evaluate AI agents in open-ended scenarios by employing other agents as judges. It addresses the challenges of assessing agent performance in complex, non-deterministic environments, providing a methodology for scalable and automated evaluation.",AI3;AI3-04,agent_evaluation;automated_benchmarking,workflow,Python,https://github.com/metauto-ai/agent-as-a-judge,,MIT,llm-as-a-judge;agent-evaluation;open-endedness
996,BIPIA,Benchmark for Indirect Prompt Injection Attacks on LLMs,A benchmark suite for evaluating the robustness of Large Language Models (LLMs) and their defenses against indirect prompt injection attacks. It provides a standardized dataset and evaluation methodology to assess security risks in LLM-integrated applications.,AI3;AI3-04,security_benchmarking;prompt_injection;robustness_evaluation,dataset,Python,https://github.com/microsoft/BIPIA,,NOASSERTION,prompt-injection;llm-security;benchmark
997,CoNLI,Framework for ungrounded hallucination detection and reduction in LLMs,"A plug-and-play framework designed to detect and reduce ungrounded hallucinations in Large Language Models. It utilizes Natural Language Inference (NLI) techniques to verify the consistency of generated text against source knowledge, improving model reliability.",AI3;AI3-04,hallucination_detection;model_alignment,library,Python,https://github.com/microsoft/CoNLI_hallucination,,MIT,hallucination;nli;fact-checking
998,HaDes,Token-level reference-free hallucination detection for LLMs,A tool for detecting hallucinations in Large Language Model outputs at the token level without requiring reference texts. It focuses on identifying self-contradictions and logical inconsistencies within the generated content to assess model faithfulness.,AI3;AI3-04,hallucination_detection;quality_control,solver,Python,https://github.com/microsoft/HaDes,,MIT,hallucination-detection;token-level;llm-evaluation
999,PromptBench,Unified evaluation framework for Large Language Models,"A comprehensive framework for evaluating Large Language Models across various dimensions, including adversarial robustness, prompt sensitivity, and task performance. It supports multiple datasets, models, and attack methods to facilitate systematic LLM assessment.",AI3;AI3-04,model_evaluation;robustness_benchmarking;prompt_engineering,workflow,Python,https://github.com/microsoft/promptbench,,MIT,llm-evaluation;adversarial-robustness;benchmark
1000,Prompty,"Tool for managing, debugging, and evaluating LLM prompts","An asset class and tooling format designed to enhance the observability, understandability, and portability of LLM prompts. It facilitates the development lifecycle of prompts, including creation, management, and evaluation within AI applications.",AI3;AI3-04,prompt_engineering;model_evaluation,library,Python,https://github.com/microsoft/prompty,,MIT,prompt-management;observability;llm-ops
1001,RobustDG,Toolkit for domain generalization and robust machine learning,A toolkit for building machine learning models that generalize well to unseen domains and are robust against privacy attacks and other perturbations. It provides implementations of various domain generalization algorithms and evaluation metrics.,AI3;AI3-04,domain_generalization;robustness_optimization,library,Python,https://github.com/microsoft/robustdg,,MIT,domain-generalization;robustness;privacy
1002,FortisAVQA,Robustness evaluation and bias mitigation for Audio-Visual Question Answering,A framework for evaluating the robustness of Audio-Visual Question Answering (AVQA) models and mitigating biases. It includes datasets and model implementations to analyze performance under various conditions and improve model reliability.,AI3;AI3-04,robustness_evaluation;bias_mitigation;multimodal_analysis,workflow,Python,https://github.com/mira-ai-lab/fortisavqa,,GPL-3.0,avqa;robustness;bias-mitigation
1003,MAITE,Modular AI Trustworthy Engineering library for test and evaluation,"A library providing common types, protocols, and utilities to support AI Test and Evaluation (T&E) workflows. It aims to standardize and facilitate the engineering of trustworthy AI systems through modular components.",AI3;AI3-04,test_and_evaluation;trustworthy_ai,library,Python,https://github.com/mit-ll-ai-technology/maite,,MIT,test-and-evaluation;trustworthy-ai;protocols
1004,ModelBench,Safety benchmark runner for AI models,A tool developed by MLCommons to run safety benchmarks against AI models and generate detailed performance reports. It standardizes the evaluation of model safety across different dimensions and test sets.,AI3;AI3-04,safety_benchmarking;model_evaluation,platform,Python,https://github.com/mlcommons/modelbench,,Apache-2.0,safety;benchmark;mlcommons
1005,WiSE-FT,Robust fine-tuning method for zero-shot models,"An implementation of the WiSE-FT (Weight-Space Ensembles for Fine-Tuning) method, which improves the robustness of fine-tuned zero-shot models. It enables models to maintain high accuracy on distribution shifts while adapting to new tasks.",AI3;AI3-04,robust_fine_tuning;domain_adaptation,library,Python,https://github.com/mlfoundations/wise-ft,,NOASSERTION,fine-tuning;robustness;zero-shot
1006,EvalScope,Streamlined framework for LLM/VLM evaluation and benchmarking,"A customizable framework for the efficient evaluation and performance benchmarking of Large Language Models (LLMs), Vision Language Models (VLMs), and AIGC models. It supports various datasets and metrics to assess model capabilities.",AI3;AI3-04,model_evaluation;benchmarking,workflow,Python,https://github.com/modelscope/evalscope,,Apache-2.0,llm-evaluation;benchmark;modelscope
1007,Agentic Security,Vulnerability scanner and red teaming kit for Agentic LLMs,"A security tool designed to scan for vulnerabilities in Agentic LLM systems. It serves as an AI red teaming kit, helping researchers and developers identify security flaws and robustness issues in autonomous agent deployments.",AI3;AI3-04,red_teaming;vulnerability_scanning,workflow,Python,https://github.com/msoedov/agentic_security,,Apache-2.0,red-teaming;llm-security;agent-evaluation
1008,Disrupting Deepfakes,Adversarial attacks on conditional image translation networks for deepfake defense,An implementation of adversarial attack methods designed to disrupt deepfake generation models (conditional image translation networks). It serves as a defensive tool to protect images from being used to generate deepfakes.,AI3;AI3-04,adversarial_defense;deepfake_detection,solver,Python,https://github.com/natanielruiz/disrupting-deepfakes,,None,deepfake-defense;adversarial-attack;image-translation
1009,Korean Safety Benchmarks,Safety benchmarks (SQuARe and KoSBi) for Korean LLMs,"A repository containing datasets and PyTorch implementations for SQuARe and KoSBi, which are safety benchmarks specifically designed for evaluating Korean Large Language Models. It addresses social bias and safety concerns in a non-English context.",AI3;AI3-04,safety_benchmarking;bias_evaluation,dataset,Python,https://github.com/naver-ai/korean-safety-benchmarks,,MIT,korean-llm;safety-benchmark;bias
1010,TD-MPC2,Scalable and robust world models for continuous control,"An implementation of TD-MPC2, a model-based reinforcement learning algorithm that learns scalable and robust world models for continuous control tasks. It is used for scientific modeling in robotics and control systems.",AI3;AI3-04,reinforcement_learning;robust_control;world_modeling,solver,Python,https://github.com/nicklashansen/tdmpc2,,MIT,world-models;reinforcement-learning;robust-control
1011,MoNA-Bench,Benchmark for monocular depth estimation in UAV autonomous navigation,"A benchmark suite designed for evaluating monocular depth estimation models in the context of unmanned aircraft autonomous navigation, focusing on obstacle avoidance and target tracking safety.",AI3-04;Robotics,model_evaluation;safety_benchmarking,dataset,C++,https://github.com/npu-ius-lab/MoNA-Bench,,GPL-3.0,depth-estimation;uav;benchmark;safety
1012,Oak AI Auto Eval Tools,LLM-as-a-judge evaluation tools for educational resources,A set of tools developed by Oak National Academy to perform automated evaluation of lesson plans and educational resources using Large Language Models (LLM-as-a-judge).,AI3-04,model_evaluation;llm_as_a_judge,solver,Python,https://github.com/oaknational/oak-ai-autoeval-tools,,MIT,llm-eval;education;automated-evaluation
1013,Hallucination Probes,Real-time detection of hallucinated entities in long-form generation,"A tool for detecting hallucinations in Large Language Model generations, specifically focusing on entity-level errors in long-form text using probing techniques.",AI3-04,hallucination_detection;model_evaluation,library,Python,https://github.com/obalcells/hallucination_probes,,Apache-2.0,hallucination;llm;probing
1014,LLM Proteomics Hallucination,Hallucination risk evaluation for LLMs in clinical proteomics,A systematic evaluation framework and benchmark for detecting hallucinations in Large Language Models when interpreting clinical proteomics and mass spectrometry data.,AI3-04;Bioinformatics,hallucination_detection;domain_specific_eval,solver,Python,https://github.com/olaflaitinen/llm-proteomics-hallucination,,MIT,proteomics;hallucination;clinical-ai
1015,Meme-Safety-Bench,Benchmark for evaluating safety of Vision-Language Models on memes,A benchmark study and dataset for assessing the safety and robustness of Vision-Language Models (VLMs) when processing meme-based content in the wild.,AI3-04,safety_benchmarking;multimodal_eval,dataset,Python,https://github.com/oneonlee/Meme-Safety-Bench,,None,vlm;safety;benchmark;memes
1016,GenAIEval,OPEA evaluation framework for Generative AI performance and safety,"A comprehensive evaluation toolkit from the Open Platform for Enterprise AI (OPEA) project, covering throughput, latency, accuracy, safety, and hallucination metrics for GenAI models.",AI3-04,model_evaluation;performance_benchmarking,library,Jupyter Notebook,https://github.com/opea-project/GenAIEval,,Apache-2.0,genai;evaluation;opea;safety
1017,CompassJudger,All-in-one Judge Models for LLM evaluation,"A collection of specialized 'Judge Models' developed by OpenCompass to perform automated evaluation of other Large Language Models, facilitating scalable and consistent assessment.",AI3-04,llm_as_a_judge;model_evaluation,solver,,https://github.com/open-compass/CompassJudger,,Apache-2.0,judge-model;opencompass;llm-eval
1018,VLMEvalKit,Evaluation toolkit for Large Multi-modality Models,"An open-source toolkit for evaluating Large Multi-modality Models (LMMs), supporting over 200 models and 80 benchmarks, enabling comprehensive assessment of vision-language capabilities.",AI3-04,multimodal_eval;benchmarking,library,Python,https://github.com/open-compass/VLMEvalKit,,Apache-2.0,vlm;lmm;evaluation;benchmark
1019,OpenCompass,Comprehensive LLM evaluation platform,"A unified platform for evaluating Large Language Models across a wide range of datasets and capabilities, supporting distributed evaluation and various model architectures.",AI3-04,model_evaluation;benchmarking,platform,Python,https://github.com/open-compass/opencompass,https://opencompass.org.cn/,Apache-2.0,llm-eval;benchmark;platform
1020,OpenAI Evals,Framework for evaluating LLMs and benchmark registry,"A framework for evaluating Large Language Models and LLM systems, providing an open-source registry of benchmarks to test model capabilities and prevent regressions.",AI3-04,model_evaluation;benchmarking,library,Python,https://github.com/openai/evals,,NOASSERTION,openai;evaluation;benchmark
1021,Safety Starter Agents,Constrained RL agents for benchmarking safe exploration,A collection of basic constrained Reinforcement Learning agents designed to serve as baselines for benchmarking safe exploration algorithms in deep RL.,AI3-04,safety_benchmarking;reinforcement_learning,library,Python,https://github.com/openai/safety-starter-agents,,MIT,rl;safety;safe-exploration
1022,OpenLIT,OpenTelemetry-native LLM observability and evaluation platform,"An open-source platform for AI engineering that provides OpenTelemetry-native observability, guardrails, and evaluation capabilities for LLMs and GPUs.",AI3-04;AI3,model_monitoring;model_evaluation;guardrails,platform,Python,https://github.com/openlit/openlit,https://docs.openlit.io/,Apache-2.0,observability;opentelemetry;llm-eval;guardrails
1023,AdvHat,Real-world adversarial attack implementation on Face ID systems,"A tool implementing real-world adversarial attacks against ArcFace Face ID systems using a sticker on a hat, useful for testing the robustness of face recognition models.",AI3-04,adversarial_attack;robustness_testing,solver,Jupyter Notebook,https://github.com/papermsucode/advhat,,MIT,adversarial-attack;face-recognition;robustness
1024,Project Mantis,Prompt injection tool for defense against LLM-driven cyberattacks,"A framework exploring 'hacking back' AI hackers by using prompt injection as a defensive mechanism against LLM-driven cyberattacks, serving as a red-teaming tool.",AI3-04,prompt_injection;red_teaming;defense,solver,Python,https://github.com/pasquini-dario/project_mantis,,None,prompt-injection;security;llm
1025,VideoHallucer,Benchmark for hallucination detection in Large Video-Language Models,A comprehensive benchmark dataset and evaluation tool designed to detect and assess hallucinations in Large Video-Language Models (LVLMs).,AI3-04,hallucination_detection;multimodal_eval,dataset,Python,https://github.com/patrick-tssn/VideoHallucer,,MIT,video-llm;hallucination;benchmark
1026,Deck of Many Prompts,Manual prompt injection and red teaming tool,A collection of prompts and a tool designed for manual red teaming and prompt injection testing against Large Language Models to identify security vulnerabilities.,AI3-04,red_teaming;prompt_injection,dataset,Python,https://github.com/peluche/deck-of-many-prompts,,None,red-teaming;prompt-injection;security
1027,Deep Mahalanobis Detector,Framework for detecting out-of-distribution samples and adversarial attacks,A unified framework implementing the Mahalanobis distance-based method for detecting out-of-distribution (OOD) samples and adversarial attacks in deep neural networks.,AI3-04,ood_detection;adversarial_defense,library,Python,https://github.com/pokaxpoka/deep_Mahalanobis_detector,,None,ood-detection;adversarial-defense;robustness
1028,SelfCheckGPT,Zero-resource black-box hallucination detection for LLMs,"A tool for detecting hallucinations in Generative Large Language Models using a zero-resource, black-box approach that checks the consistency of sampled responses.",AI3-04,hallucination_detection;model_evaluation,library,Python,https://github.com/potsawee/selfcheckgpt,,MIT,hallucination;llm;consistency-check
1029,Adversarial Face Attack,Black-box adversarial attack tool for face recognition systems,"A tool implementing black-box adversarial attacks against public face recognition systems, useful for evaluating the robustness of biometric security models.",AI3-04,adversarial_attack;robustness_testing,solver,Python,https://github.com/ppwwyyxx/Adversarial-Face-Attack,,GPL-3.0,adversarial-attack;face-recognition;black-box
1030,SecML Malware,Adversarial attacks against malware detectors,"A Python library for creating and testing adversarial attacks against machine learning-based Windows malware detectors, evaluating their robustness.",AI3-04;Cybersecurity,adversarial_attack;robustness_testing,library,Python,https://github.com/pralab/secml_malware,,MIT,adversarial-ml;malware-detection;security
1031,Prometheus Eval,Evaluate LLM responses with Prometheus and GPT-4,"A tool for evaluating Large Language Model responses using the Prometheus model or GPT-4, providing a structured way to assess generation quality.",AI3-04,model_evaluation;llm_as_a_judge,library,Python,https://github.com/prometheus-eval/prometheus-eval,,Apache-2.0,llm-eval;prometheus;judge-model
1032,Promptfoo,"CLI tool for testing, red teaming, and evaluating LLMs","A CLI tool and library for testing prompts, agents, and RAG systems, supporting red teaming, vulnerability scanning, and performance comparison across multiple LLM providers.",AI3-04,red_teaming;model_evaluation;prompt_testing,solver,TypeScript,https://github.com/promptfoo/promptfoo,https://www.promptfoo.dev/,MIT,red-teaming;prompt-engineering;evaluation
1033,Rebuff,LLM Prompt Injection Detector,"A security tool designed to detect and prevent prompt injection attacks in Large Language Model applications, enhancing the safety and robustness of AI systems.",AI3-04,prompt_injection;defense;security,library,TypeScript,https://github.com/protectai/rebuff,https://rebuff.ai/,Apache-2.0,prompt-injection;security;defense
1034,RagaAI-Catalyst,"Comprehensive framework for Agent AI observability, monitoring, and evaluation","A Python SDK designed for the evaluation and debugging of Agentic AI systems. It provides features for tracing agents, LLMs, and tools, debugging multi-agent systems, and visualizing execution graphs. It supports the assessment of reliability and performance in AI applications.",AI3;AI3-04,model_evaluation;observability;debugging,platform,Python,https://github.com/raga-ai-hub/RagaAI-Catalyst,,Apache-2.0,llm-evaluation;agent-observability;debugging
1035,texture-vs-shape,Evaluation artifacts for analyzing texture vs. shape bias in CNNs,"Provides pre-trained models, datasets, and code to evaluate the inductive biases of Convolutional Neural Networks (CNNs), specifically measuring the trade-off between texture bias and shape bias. This tool helps in understanding model robustness and interpretability.",AI3;AI3-04,model_evaluation;robustness_analysis;interpretability,library,R,https://github.com/rgeirhos/texture-vs-shape,,NOASSERTION,cnn-bias;robustness;computer-vision
1036,auto-evaluator,Automated evaluation tool for LLM QA chains,"A lightweight tool designed to evaluate the performance of Question Answering (QA) chains powered by Large Language Models. It automates the process of judging response quality, facilitating rapid iteration and testing of RAG (Retrieval-Augmented Generation) systems.",AI3;AI3-04,model_evaluation;qa_testing,tool,Python,https://github.com/rlancemartin/auto-evaluator,,None,llm-eval;rag;qa-evaluation
1037,winogender-schemas,Benchmark dataset for evaluating gender bias in coreference resolution,A collection of Winograd-schema-style sentences designed to test for the presence of gender bias in automated coreference resolution systems. It serves as a diagnostic tool for evaluating the fairness and robustness of NLP models.,AI3;AI3-04,bias_evaluation;fairness_testing,dataset,Python,https://github.com/rudinger/winogender-schemas,,MIT,gender-bias;nlp-evaluation;coreference-resolution
1038,PsiloQA,Pipeline for constructing hallucination detection datasets,"Automates the creation of multilingual, span-level hallucination detection datasets with context. This pipeline aids in the evaluation of Large Language Models by generating data to test their faithfulness and detect hallucinations.",AI3;AI3-04,dataset_generation;hallucination_detection,workflow,Python,https://github.com/s-nlp/PsiloQA,,None,hallucination;dataset-construction;llm-evaluation
1039,AuditNLG,Library for auditing trustworthiness in Natural Language Generation,"A Python library developed by Salesforce for auditing and evaluating the trustworthiness of Generative AI language models. It provides metrics and utilities to assess safety, bias, and quality in NLG outputs.",AI3;AI3-04,model_auditing;trustworthiness_evaluation,library,Python,https://github.com/salesforce/AuditNLG,,BSD-3-Clause,nlg-evaluation;trustworthy-ai;auditing
1040,YESciEval,Robust LLM-as-a-Judge for Scientific Question Answering,An evaluation framework designed to assess the performance of Large Language Models in scientific question answering tasks. It employs a robust 'LLM-as-a-Judge' methodology to provide reliable metrics for scientific reasoning capabilities.,AI3;AI3-04,model_evaluation;scientific_qa,library,Python,https://github.com/sciknoworg/YESciEval,https://pypi.org/project/YESciEval/,MIT,llm-as-a-judge;scientific-qa;evaluation
1041,frai,Open-source toolkit for responsible AI governance and evaluation,"A CLI and SDK toolkit designed to facilitate responsible AI practices. It includes features to scan code, collect evidence, generate model cards, manage risk files, and run evaluations, supporting the governance and documentation of AI systems.",AI3;AI3-04,responsible_ai;model_governance;evaluation,tool,JavaScript,https://github.com/sebuzdugan/frai,,MIT,responsible-ai;model-cards;governance
1042,ST-WebAgentBench,Benchmark for evaluating safety and trustworthiness in web agents,"A benchmark suite specifically designed to evaluate the safety and trustworthiness of AI agents operating in web environments, focusing on enterprise scenarios. It helps identify risks and validate agent behavior.",AI3;AI3-04,agent_evaluation;safety_benchmarking,dataset,Python,https://github.com/segev-shlomov/ST-WebAgentBench,,NOASSERTION,web-agents;safety-benchmark;trustworthiness
1043,robust-physical-attack,Physical adversarial attack tool for object detectors,Implements physical adversarial attacks designed to fool object detection models like Faster R-CNN. This tool is used for evaluating the robustness of computer vision models against real-world physical perturbations.,AI3;AI3-04,adversarial_attack;robustness_testing,solver,Jupyter Notebook,https://github.com/shangtse/robust-physical-attack,,BSD-3-Clause,adversarial-attack;object-detection;robustness
1044,prompt-injection,Assessment tool for prompt injection risks in GPTs,A repository containing code and data to assess and demonstrate prompt injection risks in user-designed GPTs. It serves as a resource for red teaming and evaluating the security of LLM applications.,AI3;AI3-04,red_teaming;security_evaluation,tool,,https://github.com/sherdencooper/prompt-injection,,None,prompt-injection;llm-security;red-teaming
1045,ad_examples,Collection of anomaly detection methods and adversarial attacks,"A comprehensive library implementing various anomaly detection algorithms (point-based, graph, time series) and adversarial attacks (e.g., on Graph Convolutional Networks). It serves as a toolkit for researching and evaluating anomaly detection robustness.",AI3;AI3-04,anomaly_detection;adversarial_attack;algorithm_library,library,Python,https://github.com/shubhomoydas/ad_examples,,MIT,anomaly-detection;adversarial-learning;graph-neural-networks
1046,llm-security-prompt-injection,Framework for detecting malicious prompts in LLMs,Investigates Large Language Model security by implementing binary classification of input prompts to detect malicious prompt injection attacks. It includes approaches using classical ML and fine-tuned LLMs for security evaluation.,AI3;AI3-04,security_evaluation;prompt_injection_detection,solver,Jupyter Notebook,https://github.com/sinanw/llm-security-prompt-injection,,MIT,llm-security;prompt-injection;classification
1047,local-llm-judge,Tool for using local LLMs as search relevance judges,A utility that enables the use of locally hosted Large Language Models to evaluate search relevance. It facilitates the 'LLM-as-a-Judge' pattern for offline or privacy-preserving evaluation workflows.,AI3;AI3-04,model_evaluation;search_relevance,tool,Python,https://github.com/softwaredoug/local-llm-judge,,None,llm-as-a-judge;search-evaluation;local-llm
1048,AIR-Bench 2024,Safety benchmark aligning with AI regulations and policies,A safety evaluation benchmark designed to align with emerging government regulations and corporate policies for AI. It provides a standardized way to assess the compliance and safety risks of foundation models.,AI3;AI3-04,safety_benchmarking;compliance_testing,dataset,Jupyter Notebook,https://github.com/stanford-crfm/air-bench-2024,,Apache-2.0,ai-safety;benchmark;regulation
1049,HELM,Holistic Evaluation of Language Models framework,"A comprehensive framework developed by Stanford CRFM for the holistic, reproducible, and transparent evaluation of foundation models. It covers a wide range of metrics including accuracy, robustness, fairness, and bias across diverse scenarios.",AI3;AI3-04,model_evaluation;benchmarking,platform,Python,https://github.com/stanford-crfm/helm,,Apache-2.0,llm-evaluation;foundation-models;benchmarking
1050,PhiSat-2 Trustworthy AI,Trustworthy AI pipeline for onboard satellite Earth Observation data processing,"A toolchain for deploying trustworthy AI on satellite hardware, featuring quantization (PyTorch to ONNX to INT8), calibration, and telemetry for Earth Observation tasks.",AI3;AI3-04;Earth Science,model_deployment;trustworthiness_calibration;onboard_inference,solver,Python,https://github.com/sylvesterkaczmarek/phisat2-trustworthy-onboard-ai,,MIT,satellite-ai;edge-computing;trustworthy-ai;earth-observation
1051,AutoTrust,Benchmark for assessing trustworthiness of Vision-Language Models in autonomous driving,"A benchmark suite designed to evaluate the trustworthiness of DriveVLMs across critical safety dimensions, ensuring reliable operation in autonomous driving scenarios.",AI3;AI3-04;Autonomous Systems,safety_benchmarking;trustworthiness_evaluation,dataset,Python,https://github.com/taco-group/AutoTrust,,Apache-2.0,autonomous-driving;vlm;safety-benchmark;trustworthiness
1052,AISafetyLab,"Comprehensive framework for AI safety attack, defense, and evaluation","A framework integrating various methods for AI safety research, including adversarial attacks, defense mechanisms, and safety evaluation metrics for machine learning models.",AI3;AI3-04,adversarial_attack;safety_defense;model_evaluation,library,Python,https://github.com/thu-coai/AISafetyLab,,MIT,ai-safety;adversarial-ml;robustness
1053,DiaSafety,Benchmark and dataset for evaluating safety of conversational models,"A repository providing a taxonomy, dataset, and benchmark suite for assessing the safety of conversational AI models, focusing on dialogue safety risks.",AI3;AI3-04,safety_benchmarking;dialogue_safety,dataset,Python,https://github.com/thu-coai/DiaSafety,,Apache-2.0,dialogue-safety;benchmark;llm-safety
1054,Safety-Prompts,Chinese safety prompts dataset for evaluating LLM safety,"A collection of Chinese safety prompts designed to evaluate and improve the safety of Large Language Models, covering various risk categories.",AI3;AI3-04,safety_evaluation;red_teaming,dataset,,https://github.com/thu-coai/Safety-Prompts,,Apache-2.0,safety-prompts;llm-evaluation;chinese-llm
1055,SafetyBench,Comprehensive benchmark for evaluating LLM safety,"A comprehensive benchmark suite for evaluating the safety of Large Language Models across multiple languages and safety dimensions, supporting automated evaluation.",AI3;AI3-04,safety_benchmarking;automated_evaluation,dataset,Python,https://github.com/thu-coai/SafetyBench,,MIT,llm-safety;benchmark;evaluation-framework
1056,MLA-Trust,Toolbox for benchmarking Multimodal LLM Agents trustworthiness,"A benchmarking toolbox designed to assess the trustworthiness of Multimodal LLM Agents across dimensions such as truthfulness, controllability, safety, and privacy.",AI3;AI3-04,agent_evaluation;trustworthiness_benchmarking,library,Python,https://github.com/thu-ml/MLA-Trust,,MIT,multimodal-agents;trustworthiness;benchmark
1057,MMTrustEval,Toolbox for benchmarking trustworthiness of multimodal LLMs,"A comprehensive toolbox for evaluating the trustworthiness of Multimodal Large Language Models, covering safety, hallucination, and robustness aspects.",AI3;AI3-04,multimodal_evaluation;trustworthiness_benchmarking,library,Python,https://github.com/thu-ml/MMTrustEval,,CC-BY-SA-4.0,multimodal-llm;trustworthiness;evaluation-toolbox
1058,OpenAttack,Open-source package for textual adversarial attacks,"A Python library for generating textual adversarial examples, supporting various attack models, evaluation metrics, and victim models for NLP robustness research.",AI3;AI3-04,adversarial_attack;robustness_testing,library,Python,https://github.com/thunlp/OpenAttack,https://openattack.readthedocs.io/,MIT,adversarial-nlp;text-attack;robustness
1059,Tiger,Toolkit for building trustworthy LLM applications,"A toolkit comprising TigerArmor for AI safety, TigerRAG for retrieval-augmented generation, and TigerTune for fine-tuning, aiming to build secure and reliable LLM systems.",AI3;AI3-04,safety_guardrails;rag_optimization;fine_tuning,library,Jupyter Notebook,https://github.com/tigerlab-ai/tiger,,Apache-2.0,ai-safety;rag;llm-toolkit
1060,OS-Harm,Benchmark for measuring safety of computer use agents,"A benchmark designed to evaluate the safety of agents that interact with operating systems (OS-use agents), identifying potential risks in automated computer control.",AI3;AI3-04,agent_safety;safety_benchmarking,dataset,Jupyter Notebook,https://github.com/tml-epfl/os-harm,,Apache-2.0,agent-safety;benchmark;os-agents
1061,Anamorpher,Image scaling attacks for multi-modal prompt injection,"A tool for generating adversarial images using scaling attacks to perform prompt injection in multi-modal models, bypassing visual safety filters.",AI3;AI3-04,adversarial_attack;prompt_injection;multimodal_security,solver,Python,https://github.com/trailofbits/anamorpher,,Apache-2.0,adversarial-images;prompt-injection;security
1062,TransformerLab,"Platform for LLM training, fine-tuning, and evaluation","A local application platform that provides a GUI for interacting with, training, fine-tuning, and evaluating Large Language Models and Diffusion models.",AI3;AI3-04,model_evaluation;fine_tuning;experiment_management,platform,Python,https://github.com/transformerlab/transformerlab-app,https://transformerlab.ai,AGPL-3.0,llm-platform;fine-tuning;evaluation-gui
1063,TruLens,Evaluation and tracking for LLM experiments and agents,"A library for evaluating and tracking the performance of LLM applications and agents, providing feedback functions (RAG triad) and experiment management.",AI3;AI3-04,model_evaluation;experiment_tracking;rag_evaluation,library,Python,https://github.com/truera/trulens,https://www.trulens.org,MIT,llm-evaluation;observability;rag
1064,SafeBench,Benchmark for evaluating autonomous vehicles in safety-critical scenarios,"A platform and benchmark for evaluating the safety of autonomous driving algorithms in critical scenarios, supporting simulation and adversarial testing.",AI3;AI3-04;Autonomous Systems,safety_benchmarking;simulation_testing,dataset,Python,https://github.com/trust-ai/SafeBench,https://trust-ai.github.io/SafeBench/,MIT,autonomous-driving;safety-benchmark;simulation
1065,Folly,Playground for LLM prompt injection and jailbreaking,An open-source playground tool designed for testing and experimenting with prompt injection and jailbreaking techniques on Large Language Models.,AI3;AI3-04,red_teaming;jailbreak_testing,platform,Python,https://github.com/user1342/Folly,,GPL-3.0,prompt-injection;jailbreak;playground
1066,PyTorch CNN Adversarial Attacks,PyTorch implementation of CNN adversarial attack techniques,"A collection of implementations for various adversarial attack algorithms on Convolutional Neural Networks using PyTorch, serving as a reference library for robustness research.",AI3;AI3-04,adversarial_attack;robustness_research,library,Python,https://github.com/utkuozbulak/pytorch-cnn-adversarial-attacks,,MIT,adversarial-attacks;pytorch;cnn-robustness
1067,Ragas,Framework for evaluating Retrieval Augmented Generation (RAG) pipelines,"A framework designed to evaluate RAG pipelines using metrics like faithfulness, answer relevance, and context precision, enabling automated assessment of LLM applications.",AI3;AI3-04,rag_evaluation;automated_metrics,library,Python,https://github.com/vibrantlabsai/ragas,https://docs.ragas.io,Apache-2.0,rag-evaluation;llm-metrics;automated-testing
1068,caption-eval,Automated metrics for sentence and image caption evaluation,"A Python library providing standard evaluation metrics (BLEU, METEOR, ROUGE, CIDEr, SPICE) for assessing the quality of image captions and sentence generation models.",AI3;AI3-04,model_evaluation;natural_language_processing,library,Python,https://github.com/vsubhashini/caption-eval,,None,evaluation-metrics;nlp;image-captioning;bleu;cider
1069,Adversarial Box,PyTorch library for adversarial attacks and robust training,"A toolbox for generating adversarial examples and performing adversarial training with PyTorch, supporting various attack methods to evaluate and improve model robustness.",AI3;AI3-04,adversarial_attack;adversarial_training;robustness,library,Python,https://github.com/wanglouis49/pytorch-adversarial_box,,None,pytorch;adversarial-attacks;robustness;security
1070,Circle Guard Bench,Benchmark for evaluating LLM guardrail systems,"A benchmark suite designed to evaluate the protection capabilities and effectiveness of Large Language Model (LLM) guard systems, including guardrails and safeguards against various attacks.",AI3;AI3-04,safety_evaluation;guardrail_benchmarking;red_teaming,dataset,Python,https://github.com/whitecircle-ai/circle-guard-bench,,Apache-2.0,llm-safety;benchmark;guardrails;red-teaming
1071,whylogs,Data logging and quality monitoring library for ML/AI pipelines,"An open-source library for logging data profiles, monitoring data quality, and tracking model performance over time. It enables privacy-preserving data collection and robustness checks for machine learning workflows.",AI3;AI3-04,data_quality;model_monitoring;drift_detection,library,Jupyter Notebook,https://github.com/whylabs/whylogs,https://whylabs.ai/whylogs,Apache-2.0,data-logging;mlops;data-quality;model-monitoring
1072,RiOSWorld,Benchmark for assessing risks of multimodal computer-use agents,"A benchmark environment and dataset for evaluating the safety and risks associated with multimodal agents that operate computer interfaces, focusing on robustness and safety in agentic workflows.",AI3;AI3-04,agent_evaluation;safety_benchmarking;multimodal_agents,dataset,HTML,https://github.com/yjyddq/RiOSWorld,,None,benchmark;multimodal-agents;ai-safety;neurips-2025
1073,EasyLM,"JAX/Flax library for training, fine-tuning, and serving LLMs","A comprehensive solution for Large Language Model (LLM) pre-training, fine-tuning, evaluation, and serving using JAX and Flax. It simplifies scaling LLMs on TPU/GPU clusters.",AI3;AI3-01;AI3-02,model_training;model_serving;fine_tuning,platform,Python,https://github.com/young-geng/EasyLM,,Apache-2.0,jax;flax;llm;distributed-training
1074,MT-Consistency,Framework for evaluating LLM acquiescence bias and consistency,"A research framework investigating Large Language Models' tendency for acquiescence bias in sequential QA. It includes evaluation methods, datasets, and benchmarks to assess conversational consistency and robustness.",AI3;AI3-04,consistency_evaluation;bias_evaluation;robustness,library,Python,https://github.com/yubol-bobo/MT-Consistency,,MIT,llm-bias;consistency;evaluation;qa
1075,GLM-ASR,Robust open-source speech recognition model,"A robust 1.5B parameter speech recognition model (GLM-ASR-Nano) designed for high-quality automatic speech recognition tasks, serving as a tool for audio data analysis.",AI3;AI3-04,speech_recognition;audio_analysis,solver,Python,https://github.com/zai-org/GLM-ASR,,Apache-2.0,asr;speech-recognition;glm;audio-processing
1076,PE-RLHF,RLHF framework incorporating physics knowledge for safe autonomous driving,"Implementation of Reinforcement Learning with Human Feedback (RLHF) augmented with physics knowledge, designed to improve the safety and trustworthiness of autonomous driving agents.",AI3;AI3-04,reinforcement_learning;safety_alignment;autonomous_driving,solver,Python,https://github.com/zilin-huang/PE-RLHF,,MIT,rlhf;autonomous-driving;physics-informed;safety
1077,ChineseHarm-bench,Benchmark for detecting harmful content in Chinese LLMs,"A benchmark dataset and evaluation suite for detecting harmful content in Chinese Large Language Models, facilitating safety alignment and red teaming research.",AI3;AI3-04,safety_evaluation;harmful_content_detection,dataset,Python,https://github.com/zjunlp/ChineseHarm-bench,,MIT,benchmark;chinese-llm;safety;harm-detection
1078,FactCHD,Benchmark for fact-conflicting hallucination detection,"A benchmark specifically designed to evaluate the detection of fact-conflicting hallucinations in Large Language Models, supporting research in model faithfulness.",AI3;AI3-04,hallucination_detection;benchmark,dataset,Python,https://github.com/zjunlp/FactCHD,,MIT,hallucination;benchmark;fact-checking
1079,HyperGen,Optimized inference and fine-tuning framework for diffusion models,"A framework designed to optimize the inference and fine-tuning of diffusion models (image and video), offering significant speed improvements and reduced VRAM usage compared to standard implementations.",AI3;AI3-05,inference_optimization;model_finetuning,library,Python,https://github.com/0xCrunchyy/hypergen,,MIT,diffusion-models;inference-optimization;fine-tuning
1080,micronet,Model compression and deployment library,"A library for neural network model compression and deployment, supporting quantization (QAT, PTQ, Low-Bit), pruning (channel pruning), and deployment optimization via TensorRT.",AI3;AI3-05,model_compression;quantization;pruning,library,Python,https://github.com/666DZY666/micronet,,MIT,quantization;pruning;tensorrt;model-compression
1081,JetStream,Throughput and memory optimized LLM inference engine for XLA devices,"A high-performance inference engine designed for Large Language Models (LLMs), optimized for throughput and memory efficiency on XLA devices such as TPUs.",AI3;AI3-05,inference_serving;throughput_optimization,solver,Python,https://github.com/AI-Hypercomputer/JetStream,,Apache-2.0,llm-inference;tpu;xla;optimization
1082,optimum-transformers,Accelerated NLP pipelines for fast inference on CPU and GPU,"A library providing accelerated inference pipelines for NLP models, built upon Hugging Face Transformers, Optimum, and ONNX Runtime to enhance performance on CPUs and GPUs.",AI3;AI3-05,inference_acceleration;nlp_pipeline,library,Python,https://github.com/AlekseyKorshuk/optimum-transformers,,GPL-3.0,nlp;inference;onnx;optimization
1083,llumnix,Efficient multi-instance LLM serving system,"A serving system designed for efficient and easy deployment of multiple Large Language Model (LLM) instances, optimizing resource utilization and request handling.",AI3;AI3-05,model_serving;resource_scheduling,platform,Python,https://github.com/AlibabaPAI/llumnix,,Apache-2.0,llm-serving;distributed-systems;inference
1084,REASONING_COMPILER,LLM-guided optimizations for efficient model serving,"A compiler-based approach that utilizes LLMs to guide optimizations for efficient model serving, as presented in NeurIPS 2025.",AI3;AI3-05,serving_optimization;compiler_optimization,solver,Python,https://github.com/Anna-Bele/REASONING_COMPILER,,Apache-2.0,llm;compiler;serving-optimization
1085,AutoGPTQ,Easy-to-use LLM quantization package based on GPTQ,"A library providing user-friendly APIs for quantizing Large Language Models (LLMs) using the GPTQ algorithm, enabling efficient inference on consumer hardware.",AI3;AI3-05,model_quantization;inference_optimization,library,Python,https://github.com/AutoGPTQ/AutoGPTQ,,MIT,gptq;quantization;llm
1086,BitNet-Transformers,1-bit Transformer implementation for LLMs,"A PyTorch implementation of the BitNet architecture, enabling 1-bit scaling for Large Language Models within the Hugging Face Transformers ecosystem.",AI3;AI3-05,model_architecture;quantization,library,Python,https://github.com/Beomi/BitNet-Transformers,,None,bitnet;1-bit;transformers;quantization
1087,LMDeploy-Jetson,Offline LLM deployment tools for NVIDIA Jetson platform,"A toolkit and set of scripts for deploying Large Language Models (LLMs) offline on NVIDIA Jetson edge devices, facilitating embodied intelligence applications.",AI3;AI3-05,edge_deployment;inference_serving,workflow,,https://github.com/BestAnHongjun/LMDeploy-Jetson,,Apache-2.0,jetson;edge-computing;llm-deployment
1088,Audio-Denoiser-ONNX,Audio denoising tool using ONNX Runtime,"A tool utilizing ONNX Runtime to perform audio denoising, applicable for cleaning scientific audio data or speech signals.",AI3;AI3-05,signal_processing;audio_denoising,solver,Python,https://github.com/DakeQQ/Audio-Denoiser-ONNX,,Apache-2.0,audio-processing;onnx;denoising
1089,F5-TTS-ONNX,F5-TTS implementation using ONNX Runtime,An implementation of the F5-TTS text-to-speech model optimized for inference using ONNX Runtime.,AI3;AI3-05,speech_synthesis;inference_optimization,solver,Python,https://github.com/DakeQQ/F5-TTS-ONNX,,Apache-2.0,tts;onnx;inference
1090,ReflectionFlow,Inference-time optimization for text-to-image diffusion models,"A method and tool for scaling inference-time optimization for text-to-image diffusion models via Reflection Tuning, improving generation quality.",AI3;AI3-05,inference_optimization;image_generation,library,Python,https://github.com/Diffusion-CoT/ReflectionFlow,,None,diffusion-models;inference-time-optimization
1091,keras_compressor,Model compression CLI tool for Keras,"A Command Line Interface tool for compressing Keras models, facilitating efficient deployment.",AI3;AI3-05,model_compression;deployment,solver,Python,https://github.com/DwangoMediaVillage/keras_compressor,,None,keras;compression;cli
1092,transformer-deploy,Efficient CPU/GPU inference server for Transformer models,An enterprise-grade inference server designed for efficient and scalable deployment of Hugging Face transformer models on CPUs and GPUs.,AI3;AI3-05,inference_serving;model_deployment,service,Python,https://github.com/ELS-RD/transformer-deploy,,Apache-2.0,transformers;inference-server;gpu-acceleration
1093,ENOVA,Serverless LLM serving with autoscaling,"A deployment, monitoring, and autoscaling service framework designed for serverless serving of Large Language Models.",AI3;AI3-05,model_serving;autoscaling,platform,Python,https://github.com/Emerging-AI/ENOVA,,Apache-2.0,serverless;llm-serving;autoscaling
1094,candle-vllm,Efficient local LLM inference and serving platform,"A platform for efficient inference and serving of local LLMs, written in Rust and providing an OpenAI-compatible API server.",AI3;AI3-05,inference_serving;local_inference,service,Rust,https://github.com/EricLBuehler/candle-vllm,,MIT,rust;llm-serving;inference
1095,FaceONNX,Face recognition library based on ONNX Runtime,A library for face recognition and analytics utilizing Deep Neural Networks and ONNX Runtime for inference.,AI3;AI3-05,computer_vision;biometrics;inference,library,C#,https://github.com/FaceONNX/FaceONNX,,MIT,face-recognition;onnx;c-sharp
1096,fasterai,Model pruning and distillation library for FastAI/PyTorch,"A library to prune and distill neural network models using FastAI and PyTorch, aiming to reduce model size and increase inference speed.",AI3;AI3-05,model_pruning;knowledge_distillation,library,Jupyter Notebook,https://github.com/FasterAI-Labs/fasterai,,Apache-2.0,pruning;distillation;fastai;optimization
1097,RoboBrain,Unified brain model for robotic manipulation,"A unified model framework for robotic manipulation, bridging abstract reasoning to concrete control, useful for robotics research and simulation.",AI3;AI3-05,robotics_modeling;control_inference,library,Python,https://github.com/FlagOpen/RoboBrain,,Apache-2.0,robotics;manipulation;foundation-model
1098,nano-vllm,Lightweight implementation of vLLM for LLM inference,A lightweight version or implementation of the vLLM library designed for efficient Large Language Model serving and inference.,AI3;AI3-05,inference_serving,library,Python,https://github.com/GeeeekExplorer/nano-vllm,,MIT,llm;inference;vllm;serving
1099,Depths-CPP,High-performance C++ inference for depth estimation models,"A C++ application and header library for real-time metric depth estimation using Depth-Anything-V2 models, supporting ONNX Runtime and OpenCV.",AI3;AI3-05,inference_serving;depth_estimation,solver,C++,https://github.com/Geekgineer/Depths-CPP,,None,depth-estimation;cpp;onnx;inference
1100,YOLOs-CPP,C++ inference headers for YOLO object detection models,"High-performance C++ headers for real-time object detection and segmentation using various YOLO model versions, leveraging ONNX Runtime.",AI3;AI3-05,inference_serving;object_detection,library,C++,https://github.com/Geekgineer/YOLOs-CPP,,None,yolo;object-detection;cpp;onnx
1101,furnace,Rust-based ML inference server using Burn framework,"A machine learning inference server built with Rust and the Burn framework, designed for high performance.",AI3;AI3-05,inference_serving,service,Rust,https://github.com/Gilfeather/furnace,,MIT,rust;inference-server;burn-framework
1102,BurstGPT,Workload traces for optimizing LLM serving systems,A dataset of ChatGPT and GPT-4 workload traces designed to help researchers and developers optimize Large Language Model serving systems.,AI3;AI3-05,benchmarking;system_optimization,dataset,Python,https://github.com/HPMLL/BurstGPT,,CC-BY-4.0,workload-trace;llm-serving;optimization;dataset
1103,YOLO-Multi-Backbones-Attention,Compressed YOLOv3 with lightweight backbones and attention,"A model compression tool/implementation for YOLOv3 incorporating multiple lightweight backbones (ShuffleNetV2, GhostNet), attention mechanisms, pruning, and quantization.",AI3;AI3-05,model_compression;object_detection,library,Python,https://github.com/HaloTrouvaille/YOLO-Multi-Backbones-Attention,,None,model-compression;yolo;pruning;quantization
1104,FlashTTS,High-quality Chinese TTS and voice cloning service,"A text-to-speech service and library based on SparkTTS and OrpheusTTS models, providing high-quality Chinese speech synthesis and voice cloning capabilities.",AI3;AI3-05,inference_serving;text_to_speech,service,Python,https://github.com/HuiResearch/FlashTTS,,None,tts;voice-cloning;speech-synthesis
1105,onnxmlir-triton-backend,ONNX MLIR backend for Triton Inference Server,"A backend component that allows the usage of ONNX MLIR compiled models with the Triton Inference Server, enabling optimized inference on supported hardware.",AI3;AI3-05,inference_serving;compiler_backend,library,C++,https://github.com/IBM/onnxmlir-triton-backend,,BSD-3-Clause,triton-inference-server;onnx;mlir;backend
1106,gptq,Post-training quantization for generative pretrained transformers,"The official implementation of GPTQ, a method for accurate post-training quantization of generative pretrained transformers to reduce model size and inference cost.",AI3;AI3-05,quantization;model_compression,library,Python,https://github.com/IST-DASLab/gptq,,Apache-2.0,quantization;llm;compression;gptq
1107,gptq-gguf-toolkit,Toolkit for GPTQ quantization with GGUF format,A toolkit for performing efficient non-uniform quantization using GPTQ specifically for models in the GGUF format.,AI3;AI3-05,quantization;model_conversion,library,Python,https://github.com/IST-DASLab/gptq-gguf-toolkit,,None,quantization;gguf;gptq
1108,qmoe,Sub-1-bit compression for trillion-parameter models,"Implementation of QMoE, a compression method designed for practical sub-1-bit compression of massive Mixture-of-Experts (MoE) models.",AI3;AI3-05,model_compression;quantization,library,Python,https://github.com/IST-DASLab/qmoe,,Apache-2.0,compression;moe;quantization;llm
1109,py-txi,Python wrapper for HuggingFace TGI and TEI servers,A Python client wrapper for interacting with HuggingFace's Text Generation Inference (TGI) and Text Embedding Inference (TEI) servers.,AI3;AI3-05,inference_client;api_wrapper,library,Python,https://github.com/IlyasMoutawwakil/py-txi,,Apache-2.0,tgi;tei;inference;client
1110,InferenceMAX,Continuous inference benchmarking for AI hardware,"An open-source benchmarking tool for continuous evaluation of inference performance across various AI hardware accelerators (GPUs, TPUs, etc.).",AI3;AI3-05,benchmarking;performance_analysis,solver,Python,https://github.com/InferenceMAX/InferenceMAX,,Apache-2.0,benchmarking;inference;hardware-evaluation
1111,nlp-architect,Library for exploring NLP topologies and optimization techniques,A model library by Intel Labs for exploring state-of-the-art deep learning topologies and techniques for optimizing Natural Language Processing neural networks.,AI3;AI3-05,modeling;optimization,library,Python,https://github.com/IntelLabs/nlp-architect,,Apache-2.0,nlp;optimization;deep-learning;intel
1112,gbnfgen,TypeScript generator for llama.cpp grammars,"A tool to generate GBNF grammars for llama.cpp directly from TypeScript interfaces, enabling structured output generation from LLMs.",AI3;AI3-05,inference_utility;structured_generation,library,TypeScript,https://github.com/IntrinsicLabsAI/gbnfgen,,MIT,grammar;llama.cpp;structured-output
1113,chatglm-q,ChatGLM2 implementation for GPTQ quantization,An implementation of ChatGLM2 specifically designed to support GPTQ quantization for efficient inference.,AI3;AI3-05,quantization;inference_serving,library,Python,https://github.com/K024/chatglm-q,,MIT,chatglm;gptq;quantization
1114,fastT5,Inference speed optimization for T5 models,"A tool to boost inference speed of T5 models by converting them to ONNX and quantizing them, reducing model size and latency.",AI3;AI3-05,inference_optimization;quantization,library,Python,https://github.com/Ki6an/fastT5,,Apache-2.0,t5;onnx;optimization;inference
1115,csle,Research platform for automated security policies using quantitative methods,"A research platform for developing automated security policies using quantitative methods such as reinforcement learning, game theory, and causal inference.",AI3,scientific_modeling;simulation,platform,Python,https://github.com/Kim-Hammar/csle,,NOASSERTION,security;reinforcement-learning;game-theory;simulation
1116,index-tts-vllm,vLLM support integration for IndexTTS,"A tool/library that adds vLLM support to IndexTTS, enabling faster inference for text-to-speech applications.",AI3;AI3-05,inference_serving;text_to_speech,library,Python,https://github.com/Ksuriuri/index-tts-vllm,,Apache-2.0,tts;vllm;inference
1117,dds,Server-driven video streaming for deep learning inference,"A system for server-driven video streaming optimized for deep learning inference, balancing bandwidth and accuracy.",AI3;AI3-05,inference_serving;video_processing,platform,Python,https://github.com/KuntaiDu/dds,,None,video-streaming;inference;deep-learning
1118,DistServe,Disaggregated serving system for Large Language Models,A disaggregated serving system for LLMs that separates the prefill and decoding phases to optimize performance and resource utilization.,AI3;AI3-05,inference_serving;distributed_computing,platform,Jupyter Notebook,https://github.com/LLMServe/DistServe,,Apache-2.0,llm-serving;distributed-systems;optimization
1119,LMCache,High-performance KV cache layer for LLMs,A specialized KV cache layer designed to supercharge Large Language Model inference by optimizing memory access and caching strategies.,AI3;AI3-05,inference_optimization;memory_management,library,Python,https://github.com/LMCache/LMCache,,Apache-2.0,kv-cache;llm;optimization;inference
1120,AutoGPTQ.tvm,TVM kernel for GPTQ inference,A TVM-based kernel implementation for efficient inference of GPTQ quantized models.,AI3;AI3-05,inference_optimization;kernel_implementation,library,Cuda,https://github.com/LeiWang1999/AutoGPTQ.tvm,,None,tvm;gptq;cuda;inference
1121,VitsServer,VITS ONNX TTS server for fast inference,A fast inference server for VITS Text-to-Speech models using ONNX Runtime.,AI3;AI3-05,inference_serving;text_to_speech,service,Python,https://github.com/LlmKira/VitsServer,,BSD-3-Clause,tts;onnx;server;vits
1122,KokoroSharp,Fast local TTS inference engine in C#,"A multi-platform, multi-lingual Text-to-Speech inference engine implemented in C# using ONNX runtime.",AI3;AI3-05,inference_serving;text_to_speech,library,C#,https://github.com/Lyrcaxis/KokoroSharp,,MIT,tts;csharp;onnx;inference
1123,mpeg-pcc-tmc13,Geometry-based Point Cloud Compression (G-PCC) Test Model,The reference software implementation (Test Model) for the MPEG Geometry-based Point Cloud Compression (G-PCC) standard.,AI3;AI3-05,compression;point_cloud_processing,solver,C++,https://github.com/MPEGGroup/mpeg-pcc-tmc13,,NOASSERTION,point-cloud;compression;mpeg;standard
1124,mpeg-pcc-tmc2,Video-based Point Cloud Compression (V-PCC) Test Model,The reference software implementation (Test Model) for the MPEG Video-based Point Cloud Compression (V-PCC) standard.,AI3;AI3-05,compression;point_cloud_processing,solver,C++,https://github.com/MPEGGroup/mpeg-pcc-tmc2,,NOASSERTION,point-cloud;compression;mpeg;standard
1125,dcsam,Factored inference for discrete-continuous smoothing and mapping,"A library for factored inference in discrete-continuous smoothing and mapping (SLAM) problems, useful in robotics and navigation.",AI3,scientific_inference;slam,library,C++,https://github.com/MarineRoboticsGroup/dcsam,,MIT,slam;inference;robotics;optimization
1126,llama-cpp-agent,Framework for structured interaction with LLMs,"A framework designed to facilitate interaction with Large Language Models, supporting structured function calls and output generation.",AI3;AI3-05,inference_utility;agent_framework,library,Python,https://github.com/Maximilian-Winter/llama-cpp-agent,,NOASSERTION,llm;agent;function-calling;inference
1127,shimmy,Rust-based OpenAI-compatible inference server,"A high-performance, Python-free inference server written in Rust, compatible with the OpenAI API and supporting GGUF/SafeTensors models.",AI3;AI3-05,inference_serving,service,Rust,https://github.com/Michael-A-Kuykendall/shimmy,,MIT,inference-server;rust;openai-api;gguf
1128,LightCompress,Toolkit for compressing large models including LLMs and VLMs,"A toolkit designed for compressing large-scale models such as Large Language Models (LLMs), Vision-Language Models (VLMs), and video generation models, aiming to reduce model size and improve inference efficiency.",AI3;AI3-05,model_compression;quantization,library,Python,https://github.com/ModelTC/LightCompress,,Apache-2.0,compression;llm;vlm;model-optimization
1129,LightLLM,Lightweight and scalable LLM inference and serving framework,"A Python-based framework for Large Language Model (LLM) inference and serving, featuring a lightweight design, easy scalability, and high-speed performance for deploying LLMs.",AI3;AI3-05,inference;serving,platform,Python,https://github.com/ModelTC/LightLLM,,Apache-2.0,inference-server;llm;serving;high-performance
1130,MQBench,Benchmark and toolkit for model quantization algorithms,"A framework for evaluating and implementing model quantization techniques, providing a standardized benchmark for assessing the performance and accuracy of quantized models.",AI3;AI3-05,quantization;benchmarking,library,Python,https://github.com/ModelTC/MQBench,,Apache-2.0,quantization;benchmark;model-compression
1131,flash-tokenizer,High-performance tokenizer engine for LLM inference,"An efficient and optimized tokenizer engine designed specifically for Large Language Model (LLM) inference serving, aiming to minimize tokenization latency.",AI3;AI3-05,tokenization;inference_optimization,library,C++,https://github.com/NLPOptimize/flash-tokenizer,,None,tokenizer;llm;inference;optimization
1132,nanoowl,Optimized OWL-ViT inference with NVIDIA TensorRT,"A project that optimizes the OWL-ViT (Open-Vocabulary Object Detection) model for real-time inference using NVIDIA TensorRT, enabling efficient deployment on edge devices.",AI3;AI3-05,inference_optimization;computer_vision,library,Python,https://github.com/NVIDIA-AI-IOT/nanoowl,,Apache-2.0,tensorrt;owl-vit;object-detection;optimization
1133,Model-Optimizer,Unified library for SOTA model optimization techniques,"A library providing state-of-the-art model optimization techniques such as quantization, pruning, distillation, and speculative decoding to compress deep learning models for efficient deployment on NVIDIA hardware.",AI3;AI3-05,model_optimization;quantization;pruning,library,Python,https://github.com/NVIDIA/Model-Optimizer,,Apache-2.0,optimization;compression;tensorrt;llm
1134,TensorRT-LLM,High-performance LLM inference library for NVIDIA GPUs,A library that provides an easy-to-use Python API to define Large Language Models (LLMs) and supports state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs.,AI3;AI3-05,inference;serving,library,Python,https://github.com/NVIDIA/TensorRT-LLM,,NOASSERTION,inference;llm;nvidia;gpu;optimization
1135,grps,High-performance deep learning deployment framework,"A deep learning deployment framework supporting multiple backends (TF, Torch, TRT, vLLM) with dynamic batching and streaming modes, compatible with Python and C++ for scalable service deployment.",AI3;AI3-05,serving;deployment,framework,C++,https://github.com/NetEase-Media/grps,,Apache-2.0,serving;inference;deployment;multi-backend
1136,grps_trtllm,High-performance OpenAI-compatible LLM service based on TensorRT-LLM,"A C++ high-performance LLM service implementation using GRPS and TensorRT-LLM, supporting OpenAI API, chat, function calls, and distributed multi-GPU inference.",AI3;AI3-05,serving;inference,service,Python,https://github.com/NetEase-Media/grps_trtllm,,Apache-2.0,llm-serving;tensorrt-llm;openai-api;inference
1137,sparse_quant_llms,SparseGPT and GPTQ compression tools for LLMs,"A toolkit for applying SparseGPT and GPTQ compression techniques to Large Language Models like LLaMa, OPT, and Pythia to reduce model size and computational requirements.",AI3;AI3-05,model_compression;quantization;sparsification,library,Python,https://github.com/NolanoOrg/sparse_quant_llms,,None,compression;sparsegpt;gptq;llm
1138,BMCook,Model compression toolkit for large-scale models,"A model compression toolkit designed for big models, providing methods for quantization, pruning, and distillation to optimize models for deployment.",AI3;AI3-05,model_compression;quantization;pruning,library,Python,https://github.com/OpenBMB/BMCook,,Apache-2.0,compression;large-models;optimization
1139,CPM.cu,Lightweight CUDA implementation for LLM inference on end-devices,"A high-performance CUDA implementation for Large Language Models, optimized for end-device inference with support for sparse architectures, speculative sampling, and quantization.",AI3;AI3-05,inference;on-device_ai,library,Cuda,https://github.com/OpenBMB/CPM.cu,,Apache-2.0,cuda;inference;llm;edge-computing
1140,UltraRAG,Framework for building complex RAG pipelines,"A framework for constructing Retrieval Augmented Generation (RAG) pipelines, facilitating the integration of external knowledge bases with LLMs for enhanced inference and reasoning.",AI3;AI3-05,rag;inference_augmentation,framework,Python,https://github.com/OpenBMB/UltraRAG,,Apache-2.0,rag;retrieval;llm;pipeline
1141,EfficientQAT,Efficient Quantization-Aware Training for LLMs,"A library implementing efficient Quantization-Aware Training (QAT) techniques for Large Language Models, enabling the creation of high-performance quantized models.",AI3;AI3-05,quantization;training,library,Python,https://github.com/OpenGVLab/EfficientQAT,,None,qat;quantization;llm;training
1142,VideoChat-Flash,Hierarchical compression for long-context video modeling,A tool and model implementation for efficient long-context video modeling using hierarchical compression techniques to manage memory and computational complexity.,AI3;AI3-05,video_modeling;compression,library,Python,https://github.com/OpenGVLab/VideoChat-Flash,,MIT,video;compression;long-context;multimodal
1143,CTranslate2,Fast inference engine for Transformer models,"A C++ and Python library for efficient inference with Transformer models, supporting quantization (INT8, INT16) and hardware acceleration on CPU and GPU.",AI3;AI3-05,inference;quantization,library,C++,https://github.com/OpenNMT/CTranslate2,https://opennmt.net/CTranslate2/,MIT,inference;transformer;quantization;acceleration
1144,Orion,Orion-14B foundation model and inference tools,"A repository providing the Orion-14B foundation LLM and associated tools for inference, quantization, and fine-tuning, including chat and RAG capabilities.",AI3;AI3-05,modeling;inference,library,Python,https://github.com/OrionStarAI/Orion,,Apache-2.0,llm;foundation-model;inference;quantization
1145,simple-onnx-processing-tools,Tools for manipulating and optimizing ONNX models,"A collection of tools for splitting, merging, compressing, and modifying ONNX models, facilitating model optimization and deployment workflows.",AI3;AI3-05,model_optimization;onnx_manipulation,library,Python,https://github.com/PINTO0309/simple-onnx-processing-tools,,MIT,onnx;model-processing;optimization;tools
1146,tflite2tensorflow,Converter for TFLite models to other formats,"A tool to convert .tflite models to various formats including TensorFlow, ONNX, TensorRT, and OpenVINO, supporting quantization and inverse quantization.",AI3;AI3-05,model_conversion;interoperability,library,Python,https://github.com/PINTO0309/tflite2tensorflow,,MIT,conversion;tflite;onnx;tensorrt
1147,FastDeploy,High-performance inference and deployment toolkit,"A comprehensive toolkit for deploying Large Language Models (LLMs) and Vision-Language Models (VLMs) based on PaddlePaddle, supporting various hardware backends.",AI3;AI3-05,deployment;inference,library,Python,https://github.com/PaddlePaddle/FastDeploy,,Apache-2.0,deployment;inference;paddlepaddle;llm
1148,PaddleNLP,Comprehensive NLP library with LLM support,"A library for Natural Language Processing based on PaddlePaddle, providing a model zoo of LLMs and SLMs along with tools for training, fine-tuning, and inference.",AI3;AI3-05,nlp;modeling;inference,library,Python,https://github.com/PaddlePaddle/PaddleNLP,https://paddlenlp.readthedocs.io/,Apache-2.0,nlp;llm;paddlepaddle;model-zoo
1149,PaddleSlim,Model compression and architecture search library,"A library for deep model compression (quantization, pruning, distillation) and neural architecture search (NAS) based on PaddlePaddle.",AI3;AI3-05,model_compression;nas,library,Python,https://github.com/PaddlePaddle/PaddleSlim,https://paddleslim.readthedocs.io/,Apache-2.0,compression;quantization;pruning;nas
1150,MixQ_Tensorrt_LLM,Mixed precision inference implementation using TensorRT-LLM,"A tool enabling mixed precision inference for Large Language Models using NVIDIA's TensorRT-LLM, optimizing performance and memory usage.",AI3;AI3-05,inference_optimization;mixed_precision,library,C++,https://github.com/Qcompiler/MixQ_Tensorrt_LLM,,None,tensorrt-llm;mixed-precision;inference
1151,MIVisionX,AMD computer vision and machine intelligence toolkit,"A comprehensive toolkit from AMD for computer vision and machine intelligence, including optimized implementations of OpenVX and utilities for model inference on AMD hardware.",AI3;AI3-05,computer_vision;inference,library,C++,https://github.com/ROCm/MIVisionX,,MIT,amd;rocm;openvx;computer-vision
1152,rwkv.cpp,CPU inference engine for RWKV models,"A C++ implementation for efficient inference of RWKV language models on CPUs, supporting INT4, INT5, INT8, and FP16 quantization.",AI3;AI3-05,inference;quantization,library,C++,https://github.com/RWKV/rwkv.cpp,,MIT,rwkv;inference;cpu;quantization
1153,redis-inference-optimization,Redis module for serving tensors and executing DL graphs,"A Redis module (RedisAI) designed for serving tensors and executing deep learning graphs directly within Redis, enabling high-performance inference pipelines.",AI3;AI3-05,serving;inference,service,C,https://github.com/RedisAI/redis-inference-optimization,,NOASSERTION,redis;serving;inference;deep-learning
1154,PowerInfer,High-speed LLM serving engine for local deployment,"A high-speed inference engine for Large Language Models optimized for local deployment, leveraging activation sparsity to accelerate serving on consumer-grade hardware.",AI3;AI3-05,serving;inference_optimization,library,C++,https://github.com/SJTU-IPADS/PowerInfer,,MIT,inference;llm;sparsity;local-deployment
1155,MLServer,Multi-framework inference server for ML models,"An open-source inference server that supports multiple machine learning frameworks, enabling standardized model serving and deployment in production environments.",AI3;AI3-05,serving;deployment,service,Python,https://github.com/SeldonIO/MLServer,https://mlserver.readthedocs.io/,Apache-2.0,inference-server;serving;mlops;multi-framework
1156,ServerlessLLM,Serverless serving framework for LLMs,"A framework designed for serverless deployment of Large Language Models, optimizing cold-start times and resource utilization for efficient LLM serving.",AI3;AI3-05,serving;deployment,platform,Python,https://github.com/ServerlessLLM/ServerlessLLM,,Apache-2.0,serverless;llm;serving;cloud-computing
1157,Model Compression Toolkit (MCT),Neural network model optimization and compression toolkit,"An open-source project providing advanced quantization and compression tools for optimizing neural network models for deployment on efficient, constrained hardware.",AI3;AI3-05,model_compression;quantization,library,Python,https://github.com/SonySemiconductorSolutions/mct-model-optimization,,Apache-2.0,compression;quantization;optimization;neural-networks
1158,YOLOv3v4-ModelCompression,Model compression scripts for YOLO object detection models,"A collection of scripts and tools for compressing YOLOv3 and YOLOv4 models, including pruning and quantization techniques for efficient inference.",AI3;AI3-05,model_compression;object_detection,library,Python,https://github.com/SpursLipu/YOLOv3v4-ModelCompression-MultidatasetTraining-Multibackbone,,GPL-3.0,yolo;compression;pruning;quantization
1159,Torch-TRTLLM,Converter from HuggingFace models to TensorRT-LLM engines,"A framework (Ditto) that enables direct conversion of HuggingFace PreTrainedModels into TensorRT-LLM engines, simplifying the optimization pipeline for LLMs.",AI3;AI3-05,model_conversion;inference_optimization,library,Python,https://github.com/SqueezeBits/Torch-TRTLLM,,Apache-2.0,tensorrt-llm;huggingface;conversion;optimization
1160,EmbedAnything,High-performance inference and ingestion pipeline in Rust,"A modular and memory-safe library built in Rust for high-performance inference, data ingestion, and indexing, suitable for building efficient RAG and search pipelines.",AI3;AI3-05,inference;data_ingestion,library,Rust,https://github.com/StarlightSearch/EmbedAnything,,Apache-2.0,rust;inference;embedding;rag
1161,torch-model-compression,Automated model structure analysis and compression toolset for PyTorch,A toolset designed for PyTorch models that provides automated model structure analysis and a library of model compression algorithms to optimize inference efficiency.,AI3;AI3-05,model_compression;structure_analysis,library,Python,https://github.com/THU-MIG/torch-model-compression,,MIT,pytorch;model-compression;optimization
1162,AngelSlim,Model compression toolkit for enhanced usability and efficiency,"A comprehensive model compression toolkit developed by Tencent, designed to improve the usability and efficiency of deploying deep learning models through various compression techniques.",AI3;AI3-05,model_compression;optimization,library,Python,https://github.com/Tencent/AngelSlim,,NOASSERTION,model-compression;deep-learning;tencent
1163,PocketFlow,Automatic Model Compression (AutoMC) framework,An open-source framework for automatic model compression (AutoMC) that integrates various compression algorithms to develop smaller and faster AI applications with minimal human effort.,AI3;AI3-05,model_compression;automl,framework,Python,https://github.com/Tencent/PocketFlow,https://pocketflow.github.io/,NOASSERTION,automc;model-compression;tensorflow
1164,TNN,High-performance deep learning inference framework,"A uniform deep learning inference framework for mobile, desktop, and server platforms, featuring cross-platform capability, high performance, and model compression support.",AI3;AI3-05,inference_engine;model_serving,framework,C++,https://github.com/Tencent/TNN,,NOASSERTION,inference;cross-platform;mobile-ai
1165,ncnn,High-performance neural network inference framework for mobile,"A high-performance neural network inference framework optimized for mobile platforms, supporting various model formats and enabling efficient AI deployment on edge devices.",AI3;AI3-05,inference_engine;edge_computing,framework,C++,https://github.com/Tencent/ncnn,,NOASSERTION,inference;mobile;neural-network
1166,AQLM,Extreme Compression of LLMs via Additive Quantization,"Official implementation of Additive Quantization for Language Models (AQLM), providing tools for extreme compression of Large Language Models while maintaining performance.",AI3;AI3-05,quantization;model_compression,library,Python,https://github.com/Vahe1994/AQLM,,Apache-2.0,quantization;llm;compression
1167,voltaML,Lightweight library for accelerating ML/DL models,"A lightweight library designed to convert and run machine learning and deep learning models in high-performance inference runtimes like TensorRT, TorchScript, ONNX, and TVM.",AI3;AI3-05,inference_optimization;model_conversion,library,Python,https://github.com/VoltaML/voltaML,,Apache-2.0,acceleration;tensorrt;inference
1168,MACE,Mobile AI Compute Engine,"A deep learning inference framework optimized for mobile heterogeneous computing platforms, supporting efficient execution of neural networks on mobile devices.",AI3;AI3-05,inference_engine;mobile_computing,framework,C++,https://github.com/XiaoMi/mace,https://mace.readthedocs.io/,Apache-2.0,mobile-ai;inference;heterogeneous-computing
1169,Keras-inference-time-optimizer,Keras model layer structure optimizer,A tool to optimize the layer structure of Keras models to reduce computation time and improve inference speed.,AI3;AI3-05,inference_optimization;model_profiling,library,Python,https://github.com/ZFTurbo/Keras-inference-time-optimizer,,MIT,keras;optimization;inference
1170,KVCache-Factory,Unified KV Cache Compression Methods for Auto-Regressive Models,A unified framework and library for applying various Key-Value (KV) cache compression methods to auto-regressive models to optimize memory usage and inference speed.,AI3;AI3-05,memory_optimization;inference_acceleration,library,Python,https://github.com/Zefan-Cai/KVCache-Factory,,MIT,kv-cache;compression;llm
1171,llama-cpp-python,Python bindings for llama.cpp,"Python bindings for llama.cpp, enabling the execution of quantized Large Language Models (LLMs) efficiently in Python environments.",AI3;AI3-05,inference_runtime;model_serving,library,Python,https://github.com/abetlen/llama-cpp-python,https://llama-cpp-python.readthedocs.io/,MIT,llm;inference;quantization
1172,ggify,Huggingface to GGML/GGUF converter,A utility tool to download models from Huggingface Hub and convert them to GGML/GGUF formats for use with llama.cpp.,AI3;AI3-05,model_conversion;data_preparation,solver,Python,https://github.com/akx/ggify,,MIT,gguf;conversion;llama.cpp
1173,optillm,Optimizing inference proxy for LLMs,"An optimizing inference proxy that sits between LLM applications and providers, implementing techniques like mixture-of-agents and speculative decoding to improve performance and accuracy.",AI3;AI3-05,inference_optimization;proxy_service,service,Python,https://github.com/algorithmicsuperintelligence/optillm,,Apache-2.0,inference;proxy;optimization
1174,ServeGen,LLM serving workload generator,A framework for generating realistic Large Language Model (LLM) serving workloads to benchmark and evaluate serving systems.,AI3;AI3-05,benchmarking;workload_generation,solver,Python,https://github.com/alibaba/ServeGen,,Apache-2.0,benchmarking;serving;llm
1175,TinyNeuralNetwork,Efficient deep learning model compression framework,"An efficient and easy-to-use framework for deep learning model compression, supporting techniques like pruning and quantization to optimize models for deployment.",AI3;AI3-05,model_compression;optimization,framework,Python,https://github.com/alibaba/TinyNeuralNetwork,,MIT,compression;pruning;quantization
1176,SQLFlow,SQL-based machine learning bridge,"A bridge that connects SQL engines with machine learning toolkits like TensorFlow, enabling users to perform model training, prediction, and inference using extended SQL syntax.",AI3;AI3-05,model_training;inference_interface,platform,Go,https://github.com/alipay/SQLFlow,https://sqlflow.org/,None,sql;machine-learning;interface
1177,byzer-llm,Full-lifecycle LLM toolchain,"A comprehensive toolchain for pretraining, fine-tuning, and serving Large Language Models (LLMs), designed to make LLM deployment accessible and efficient.",AI3;AI3-05,model_serving;fine_tuning,workflow,Python,https://github.com/allwefantasy/byzer-llm,,Apache-2.0,llm;serving;finetuning
1178,Alpa,Auto-parallelization for large-scale neural networks,A system for training and serving large-scale neural networks that automatically generates parallelization strategies for distributed execution.,AI3;AI3-05,distributed_serving;distributed_training,framework,Python,https://github.com/alpa-projects/alpa,https://alpa.ai/,Apache-2.0,distributed-systems;parallelization;serving
1179,cONNXr,Pure C ONNX runtime for embedded devices,"A pure C implementation of the ONNX runtime with zero dependencies, designed for inference on embedded devices.",AI3;AI3-05,inference_runtime;embedded_ai,library,C,https://github.com/alrevuelta/cONNXr,,MIT,onnx;embedded;c
1180,RyzenAI-SW,AMD Ryzen AI inference software,Software tools and runtime libraries provided by AMD for optimizing and deploying AI inference on Ryzen AI-powered hardware.,AI3;AI3-05,inference_optimization;hardware_acceleration,platform,Python,https://github.com/amd/RyzenAI-SW,https://ryzenai.docs.amd.com/,MIT,amd;inference;npu
1181,flux-fp8-api,Optimized Flux diffusion model serving implementation,"An implementation of the Flux diffusion model using quantized FP8 matrix multiplication and optimized layers for faster inference on consumer devices, exposed via an API.",AI3;AI3-05,inference_serving;quantization,service,Python,https://github.com/aredden/flux-fp8-api,,Apache-2.0,diffusion;quantization;serving
1182,sqlite-lembed,SQLite extension for GGUF embeddings,"A SQLite extension that enables the generation of text embeddings directly within the database using GGUF models via llama.cpp, facilitating local vector search and data processing.",AI3;AI3-05,data_processing;embedding_generation,library,C,https://github.com/asg017/sqlite-lembed,,None,sqlite;embedding;gguf
1183,nos,Fast and flexible PyTorch inference server for local and cloud deployment,"A high-performance inference server designed to run PyTorch models efficiently on various hardware backends. It supports dynamic batching and hardware acceleration, facilitating the deployment of scientific AI models.",AI3;AI3-05,model_serving;inference_optimization,service,Python,https://github.com/autonomi-ai/nos,,Apache-2.0,inference-server;pytorch;gpu-acceleration
1184,Multi Model Server,Tool for serving neural net models for inference,A flexible and easy-to-use tool for serving deep learning models trained with various frameworks. It provides an HTTP frontend for inference requests and manages model loading and scaling.,AI3;AI3-05,model_serving,service,Java,https://github.com/awslabs/multi-model-server,,Apache-2.0,inference-serving;model-deployment;mxnet;pytorch
1185,llama-on-lambda,Deployment tool for running llama.cpp compatible LLMs on AWS Lambda,"A utility that enables the deployment of quantized Large Language Models (LLMs) using llama.cpp on serverless infrastructure (AWS Lambda), facilitating cost-effective inference for scientific NLP tasks.",AI3;AI3-05,model_serving;deployment,workflow,Python,https://github.com/baileytec-labs/llama-on-lambda,,NOASSERTION,serverless;llm-inference;aws-lambda;quantization
1186,BentoLMDeploy,Integration tool for self-hosting LLMs with LMDeploy and BentoML,"A bridge tool that combines the high-performance inference capabilities of LMDeploy with the model serving infrastructure of BentoML, enabling efficient deployment of Large Language Models.",AI3;AI3-05,model_serving;inference_optimization,workflow,Python,https://github.com/bentoml/BentoLMDeploy,,None,llm-serving;bentoml;lmdeploy
1187,llm-optimizer,Benchmark and optimize LLM inference across frameworks,"A toolkit designed to profile, benchmark, and optimize the inference performance of Large Language Models across different serving frameworks, aiding in the efficient deployment of scientific models.",AI3;AI3-05,inference_optimization;benchmarking,library,Python,https://github.com/bentoml/llm-optimizer,,Apache-2.0,llm;optimization;inference-benchmark
1188,X-LLM,Library for cutting edge and easy LLM finetuning,"A library designed to simplify the fine-tuning process of Large Language Models, supporting various optimization techniques to adapt models for specific scientific or domain tasks.",AI3,model_training;fine_tuning,library,Python,https://github.com/bobazooba/xllm,,Apache-2.0,llm;fine-tuning;training-framework
1189,ByteTransformer,Optimized BERT transformer inference on NVIDIA GPU,"A high-performance inference engine for Transformer models (like BERT), providing highly optimized CUDA kernels for variable-length sequence processing, significantly accelerating scientific text analysis tasks.",AI3;AI3-05,inference_optimization;model_serving,solver,C++,https://github.com/bytedance/ByteTransformer,,Apache-2.0,transformer;inference-acceleration;cuda;bert
1190,AutoAWQ,Implementation of the AWQ algorithm for 4-bit quantization,"A library implementing Activation-aware Weight Quantization (AWQ) for LLMs, enabling significant speedups and memory reduction during inference while maintaining model accuracy.",AI3;AI3-05,quantization;inference_optimization,library,Python,https://github.com/casper-hansen/AutoAWQ,,MIT,quantization;awq;llm-inference
1191,LLMServingSim,HW/SW Co-Simulation Infrastructure for LLM Inference Serving,"A simulation framework designed to evaluate and optimize the hardware/software stack for Large Language Model inference serving at scale, aiding in system architecture research.",AI3;AI3-05,simulation;inference_optimization,solver,Python,https://github.com/casys-kaist/LLMServingSim,,MIT,simulation;llm-serving;system-architecture
1192,flex-nano-vllm,Minimal vllm-style inference engine for fast Gemma 2 inference,"A lightweight inference engine leveraging FlexAttention to provide fast inference capabilities for specific LLM architectures (e.g., Gemma 2), serving as a specialized tool for model execution.",AI3;AI3-05,model_serving;inference_optimization,solver,Python,https://github.com/changjonathanc/flex-nano-vllm,,MIT,inference-engine;vllm;gemma
1193,model_compression,Implementation of model compression with knowledge distilling,"A toolkit implementing various model compression techniques, specifically knowledge distillation, to reduce model size and improve inference speed for deployment.",AI3;AI3-05,model_compression;distillation,library,Python,https://github.com/chengshengchan/model_compression,,None,model-compression;knowledge-distillation
1194,Comfy-WaveSpeed,Inference optimization solution for ComfyUI,"An optimization framework integrated into ComfyUI to accelerate the inference of generative AI models, facilitating faster image generation for research and creative workflows.",AI3;AI3-05,inference_optimization;image_generation,plugin,Python,https://github.com/chengzeyi/Comfy-WaveSpeed,https://wavespeed.ai/,MIT,comfyui;inference-acceleration;stable-diffusion
1195,stable-fast,Inference performance optimization framework for HuggingFace Diffusers,"A highly optimized inference framework for Stable Diffusion models on NVIDIA GPUs, providing significant speedups for diffusion-based generative tasks.",AI3;AI3-05,inference_optimization;image_generation,library,Python,https://github.com/chengzeyi/stable-fast,https://wavespeed.ai/,MIT,stable-diffusion;inference-optimization;cuda
1196,ialacol,Lightweight OpenAI drop-in replacement for Kubernetes,"A serving infrastructure tool that allows deploying open-source LLMs on Kubernetes with an OpenAI-compatible API, facilitating scalable model inference in research environments.",AI3;AI3-05,model_serving;deployment,service,Python,https://github.com/chenhunghan/ialacol,,MIT,kubernetes;llm-serving;openai-api
1197,topicGPT,Prompt-Based Framework for Topic Modeling,"A framework that utilizes Large Language Models to perform topic modeling on text data, providing a tool for qualitative and quantitative text analysis in social and computational sciences.",AI3,data_analysis;text_mining,library,Python,https://github.com/chtmp223/topicGPT,,None,topic-modeling;llm;nlp
1198,ComfyUI-GGUF,GGUF Quantization support for native ComfyUI models,"A plugin for ComfyUI that enables the loading and inference of models quantized in the GGUF format, allowing for efficient execution of generative models on consumer hardware.",AI3;AI3-05,quantization;inference_optimization,plugin,Python,https://github.com/city96/ComfyUI-GGUF,,Apache-2.0,gguf;comfyui;quantization
1199,WhisperLive,A nearly-live implementation of OpenAI's Whisper,"A real-time implementation of the Whisper automatic speech recognition model, enabling live audio transcription and processing for research and application development.",AI3;AI3-05,inference_implementation;speech_recognition,solver,Python,https://github.com/collabora/WhisperLive,,MIT,whisper;asr;real-time-inference
1200,ramalama,Tool for local serving of AI models using containers,"A command-line tool that simplifies the management and serving of AI models using container technology (OCI), making it easier to deploy inference services reproducibly.",AI3;AI3-05,model_serving;deployment,workflow,Python,https://github.com/containers/ramalama,,MIT,containers;inference-serving;local-ai
1201,cuckoo,Decentralized AI Model-Serving Platform,"A platform for decentralized serving of AI models, enabling distributed inference for generative AI and LLMs, potentially utilizing shared GPU resources.",AI3;AI3-05,model_serving;distributed_inference,platform,TypeScript,https://github.com/cuckoo-network/cuckoo,,Apache-2.0,decentralized-ai;model-serving;gpu-sharing
1202,Diffbot LLM Inference Server,High-performance inference server for Large Language Models,"A dedicated server implementation for deploying and serving Large Language Models, focusing on inference capabilities.",AI3;AI3-05,model_serving;inference_server,service,Python,https://github.com/diffbot/diffbot-llm-inference,,None,llm;inference-server;serving
1203,NanoLLM,Optimized local inference library for LLMs and multimodal agents,"A lightweight and optimized library for running Large Language Models locally, supporting quantization, vision-language models, and RAG pipelines, particularly suitable for edge computing in scientific data collection.",AI3;AI3-05,inference_optimization;quantization,library,Python,https://github.com/dusty-nv/NanoLLM,,MIT,edge-ai;quantization;rag;local-inference
1204,mixtral-offloading,Efficient inference of Mixtral-8x7B on consumer hardware via offloading,"A tool enabling the execution of large Mixture-of-Experts models (like Mixtral-8x7B) on limited memory hardware (e.g., Colab, consumer GPUs) through efficient RAM/VRAM offloading strategies.",AI3;AI3-05,inference_optimization;memory_optimization,solver,Python,https://github.com/dvmazur/mixtral-offloading,,MIT,offloading;mixture-of-experts;inference-optimization
1205,Atom,Low-bit quantization framework for efficient LLM serving,A quantization library implementing low-bit techniques to maintain accuracy while significantly reducing the memory footprint and increasing the throughput of Large Language Model serving.,AI3;AI3-05,quantization;model_compression,library,Cuda,https://github.com/efeslab/Atom,,None,quantization;llm-serving;low-bit
1206,Nanoflow,High-throughput serving framework for Large Language Models,"A high-performance serving system designed to maximize throughput for LLM inference, utilizing advanced scheduling and memory management techniques.",AI3;AI3-05,model_serving;inference_acceleration,platform,Jupyter Notebook,https://github.com/efeslab/Nanoflow,,None,high-throughput;serving-framework;llm
1207,cake,Distributed inference engine for LLMs and StableDiffusion,"A Rust-based distributed inference framework supporting both Large Language Models and image generation models, designed to run across diverse hardware including mobile, desktop, and servers.",AI3;AI3-05,distributed_inference;model_serving,service,Rust,https://github.com/evilsocket/cake,,NOASSERTION,distributed-computing;rust;inference-engine
1208,FBTT-Embedding,Tensor Train compression library for sparse embedding tables,"A library for compressing sparse embedding tables in large-scale machine learning models using Tensor Train decomposition, reducing memory footprint while maintaining model quality.",AI3;AI3-05,model_compression;embedding_optimization,library,Cuda,https://github.com/facebookresearch/FBTT-Embedding,,MIT,tensor-train;compression;embeddings
1209,LLM-QAT,Data-free quantization aware training for LLMs,"A toolkit for performing Quantization Aware Training (QAT) on Large Language Models without requiring original training data, enabling the creation of efficient quantized models.",AI3;AI3-05,quantization;model_training,library,Python,https://github.com/facebookresearch/LLM-QAT,,NOASSERTION,qat;quantization;data-free
1210,LayerSkip,Early exit inference and self-speculative decoding for LLMs,An inference optimization tool that enables early exit strategies and self-speculative decoding to accelerate Large Language Model generation.,AI3;AI3-05,inference_acceleration;speculative_decoding,library,Python,https://github.com/facebookresearch/LayerSkip,,NOASSERTION,early-exit;acceleration;inference
1211,diffq,Differentiable quantization library,"A library for differentiable quantization using pseudo quantization noise, allowing automatic tuning of bit-width per weight to balance model size and accuracy.",AI3;AI3-05,quantization;model_compression,library,Python,https://github.com/facebookresearch/diffq,,NOASSERTION,differentiable-quantization;compression;pytorch
1212,GPTQ-triton,Triton kernel implementation for GPTQ inference,"A specialized Triton kernel implementation for running inference on models quantized with GPTQ, enabling efficient execution on GPUs.",AI3;AI3-05,quantization;inference_acceleration,library,Jupyter Notebook,https://github.com/fpgaminer/GPTQ-triton,,Apache-2.0,gptq;triton;quantization
1213,EvaDB,Database system for AI-powered applications,"A database system designed to facilitate the management and analysis of data using AI models, supporting SQL-like queries for video, image, and text analysis.",AI3;AI3-05,data_management;model_inference,platform,Python,https://github.com/georgia-tech-db/evadb,https://evadb.readthedocs.io/,Apache-2.0,ai-database;sql;multimodal
1214,llama.cpp,Port of Facebook's LLaMA model in C/C++ for efficient local inference,"A widely used C/C++ implementation for running Large Language Models efficiently on consumer hardware (CPU/GPU), supporting various quantization methods and model architectures.",AI3;AI3-05,model_inference;quantization,solver,C++,https://github.com/ggml-org/llama.cpp,,MIT,inference;quantization;cpp;local-llm
1215,XNNPACK,High-efficiency floating-point neural network inference operators,"A library of highly optimized neural network inference operators for ARM, x86, and WebAssembly, serving as a backend for frameworks like TensorFlow Lite and PyTorch.",AI3;AI3-05,inference_acceleration;kernel_optimization,library,C,https://github.com/google/XNNPACK,,NOASSERTION,inference-operators;optimization;simd
1216,llama.go,Pure Golang implementation of llama.cpp,"A pure Go implementation of the LLaMA inference engine, providing an alternative runtime for deploying LLMs in Go-based scientific or infrastructure environments.",AI3;AI3-05,model_inference,solver,Go,https://github.com/gotzmann/llama.go,,NOASSERTION,golang;inference;llm
1217,gpustack,GPU cluster manager for optimized AI model deployment,"A platform for managing GPU clusters to efficiently deploy and serve AI models, handling scheduling and resource allocation for inference workloads.",AI3;AI3-05,model_serving;resource_management,platform,Python,https://github.com/gpustack/gpustack,,Apache-2.0,gpu-cluster;deployment;serving
1218,llama-box,LM inference server implementation based on llama.cpp,"A lightweight inference server wrapping llama.cpp, providing API endpoints for serving Large Language Models.",AI3;AI3-05,model_serving;inference_server,service,C++,https://github.com/gpustack/llama-box,,MIT,inference-server;llama.cpp;api
1219,llgtrt,TensorRT-LLM server with Structured Outputs,"A Rust-based server for TensorRT-LLM that specifically supports structured output generation (JSON), useful for extracting structured scientific data from LLMs.",AI3;AI3-05,model_serving;structured_generation,service,Rust,https://github.com/guidance-ai/llgtrt,,MIT,tensorrt-llm;structured-output;rust
1220,h2oGPT,Private local GPT platform for document analysis,"A platform for running LLMs locally to query documents, images, and videos privately, supporting RAG and various inference backends, highly relevant for secure scientific data analysis.",AI3;AI3-05,model_serving;rag_platform,platform,Python,https://github.com/h2oai/h2ogpt,https://gpt-docs.h2o.ai/,Apache-2.0,local-gpt;rag;private-ai
1221,Hailo Model Zoo,Pre-trained models and evaluation environment for Hailo hardware,"A collection of pre-trained models and tools for building, compiling, and evaluating models on Hailo AI processors, facilitating edge AI deployment.",AI3;AI3-05,model_management;inference_optimization,dataset,Python,https://github.com/hailo-ai/hailo_model_zoo,,MIT,model-zoo;edge-ai;hailo
1222,LLM-Pruner,Structural pruning tool for Large Language Models,"A tool for performing structural pruning on Large Language Models to reduce model size and inference cost while preserving performance, supporting various open-source models.",AI3;AI3-05,model_compression;pruning,library,Python,https://github.com/horseee/LLM-Pruner,,Apache-2.0,pruning;model-compression;efficient-llm
1223,FastFold,Optimized training and inference for AlphaFold,"A high-performance implementation for training and inference of AlphaFold, optimizing protein structure prediction workflows on GPU clusters.",AI3;AI3-05,inference_optimization;scientific_modeling,solver,Python,https://github.com/hpcaitech/FastFold,,Apache-2.0,alphafold;protein-folding;optimization
1224,SINQ,Fast and high-quality quantization method for LLMs,"A quantization tool designed to compress Large Language Models while preserving accuracy, offering a balance between model size and performance.",AI3;AI3-05,quantization;model_compression,library,Python,https://github.com/huawei-csl/SINQ,,Apache-2.0,quantization;compression;llm
1225,Huawei Noah Pretrained Language Model,Pretrained models and optimization techniques from Huawei Noah's Ark Lab,"A repository containing pretrained language models and associated optimization code (compression, quantization) developed by Huawei Noah's Ark Lab.",AI3;AI3-05,model_management;model_optimization,library,Python,https://github.com/huawei-noah/Pretrained-Language-Model,,None,pretrained-models;optimization;huawei
1226,Inference Benchmarker,Benchmarking tool for inference servers,"A tool designed to benchmark the performance of various inference servers, helping to evaluate latency and throughput for model serving.",AI3;AI3-05,benchmarking;performance_evaluation,solver,Rust,https://github.com/huggingface/inference-benchmarker,,Apache-2.0,benchmarking;inference;latency
1227,Optimum Intel,Intel-specific optimization for Hugging Face models,A library that accelerates inference and training of Hugging Face models on Intel hardware using Intel's optimization tools like OpenVINO and Neural Compressor.,AI3;AI3-05,inference_optimization;quantization,library,Jupyter Notebook,https://github.com/huggingface/optimum-intel,https://huggingface.co/docs/optimum/intel/index,Apache-2.0,intel;openvino;optimization
1228,Optimum ONNX,ONNX export and inference optimization tool,A tool to export Hugging Face models to ONNX format and run optimized inference using ONNX Runtime.,AI3;AI3-05,model_conversion;inference_optimization,library,Python,https://github.com/huggingface/optimum-onnx,,Apache-2.0,onnx;inference;export
1229,yzma,Go bindings for local llama.cpp inference,A library enabling Go applications to directly integrate llama.cpp for local inference with hardware acceleration support.,AI3;AI3-05,inference_serving;model_integration,library,Go,https://github.com/hybridgroup/yzma,,NOASSERTION,go;llama.cpp;inference
1230,ik_llama.cpp,Optimized fork of llama.cpp with SOTA quantization,A fork of the llama.cpp inference engine featuring additional state-of-the-art quantization methods and performance improvements for running LLMs locally.,AI3;AI3-05,inference_engine;quantization,solver,C++,https://github.com/ikawrakow/ik_llama.cpp,,MIT,llm;quantization;inference
1231,ShaderNN,Lightweight mobile inference framework for CNNs,A deep learning inference framework optimized for running Convolutional Neural Networks on mobile platforms using shader-based acceleration.,AI3;AI3-05,inference_engine;mobile_inference,solver,C++,https://github.com/inferenceengine/shadernn,,NOASSERTION,mobile;cnn;inference
1232,Triton Co-Pilot,Glue code generator for Triton Inference Server,A utility to generate configuration and glue code to simplify the deployment of models on Nvidia Triton Inference Server.,AI3;AI3-05,deployment_automation;serving_configuration,solver,Python,https://github.com/inferless/triton-co-pilot,,None,triton;deployment;code-generation
1233,Semi-PD,Disaggregated LLM serving framework,"A serving framework that disaggregates prefill and decode phases for LLMs, featuring shared GPU memory and fine-grained compute isolation to optimize throughput.",AI3;AI3-05,inference_serving;resource_scheduling,platform,Python,https://github.com/infinigence/Semi-PD,,Apache-2.0,llm-serving;distributed-systems;optimization
1234,Intel AI Reference Models,Optimized deep learning reference implementations for Intel hardware,"A collection of deep learning model implementations optimized for Intel Xeon processors and Data Center GPUs, serving as a reference for efficient inference and training.",AI3;AI3-05,inference_optimization;model_implementation,library,Python,https://github.com/intel/ai-reference-models,,Apache-2.0,intel;optimization;reference-models
1235,Auto-Round,Advanced quantization toolkit for LLMs and VLMs,"A toolkit providing advanced quantization schemes (WOQ, MXFP4, NVFP4, etc.) for Large Language Models and Vision Language Models, integrating with transformers and vLLM.",AI3;AI3-05,quantization;model_compression,library,Python,https://github.com/intel/auto-round,,Apache-2.0,quantization;llm;compression
1236,Intel Neural Compressor,Model compression and quantization toolkit,"A toolkit for low-bit quantization (INT8, FP8, etc.) and sparsity, providing model compression techniques for PyTorch, TensorFlow, and ONNX Runtime.",AI3;AI3-05,model_compression;quantization,library,Python,https://github.com/intel/neural-compressor,https://intel.github.io/neural-compressor/,Apache-2.0,compression;quantization;sparsity
1237,Paddler,Load balancer and serving platform for LLMs,An open-source load balancer and serving platform designed for self-hosting Large Language Models at scale.,AI3;AI3-05,inference_serving;load_balancing,platform,Rust,https://github.com/intentee/paddler,,Apache-2.0,serving;load-balancer;llm
1238,PKD-for-BERT-Model-Compression,Patient Knowledge Distillation for BERT,A PyTorch implementation of Patient Knowledge Distillation (PKD) for compressing BERT models.,AI3;AI3-05,model_compression;knowledge_distillation,solver,Python,https://github.com/intersun/PKD-for-BERT-Model-Compression,,None,bert;compression;distillation
1239,IREE,MLIR-based machine learning compiler and runtime,"A retargetable compiler and runtime toolkit based on MLIR, designed to optimize and run machine learning models on various hardware backends.",AI3;AI3-05,compiler;inference_runtime,platform,C++,https://github.com/iree-org/iree,https://iree.dev/,Apache-2.0,compiler;mlir;runtime
1240,ChatGPTQAG,Automated QA pair generation using ChatGPT,"A tool for automatically generating question-answer pairs using ChatGPT, applicable for creating training datasets for NLP tasks.",AI3,data_generation;dataset_synthesis,solver,Python,https://github.com/itlubber/ChatGPTQAG,,GPL-3.0,data-generation;nlp;qa
1241,yolov5-onnxruntime,C++ inference implementation for YOLOv5 using ONNX Runtime,"A C++ implementation for running YOLOv5 object detection models using ONNX Runtime, serving as a reference solver for deployment.",AI3;AI3-05,inference_implementation;object_detection,solver,C++,https://github.com/itsnine/yolov5-onnxruntime,,None,yolo;onnx;inference
1242,InferenceHelper,C++ helper library for multiple inference frameworks,"A C++ helper class that provides a unified interface for various deep learning inference frameworks including TensorFlow Lite, TensorRT, OpenVINO, and ONNX Runtime.",AI3;AI3-05,inference_integration;framework_abstraction,library,C++,https://github.com/iwatake2222/InferenceHelper,,Apache-2.0,inference;cpp;wrapper
1243,xllm,High-performance LLM inference engine,"A high-performance inference engine for Large Language Models, optimized for diverse AI accelerators.",AI3;AI3-05,inference_engine;acceleration,solver,C++,https://github.com/jd-opensource/xllm,,NOASSERTION,inference;llm;engine
1244,GPTQ-for-LLaMa-CUDA,Packaged CUDA version of GPTQ for LLaMa,"A packaged distribution of the GPTQ-for-LLaMa tool with CUDA support, facilitating the quantization and inference of LLaMa models.",AI3;AI3-05,quantization;inference_optimization,solver,Python,https://github.com/jllllll/GPTQ-for-LLaMa-CUDA,,Apache-2.0,gptq;cuda;quantization
1245,openai-clip-js,JavaScript port of OpenAI's CLIP model,"A port of OpenAI's CLIP model to JavaScript using ONNX web runtime, enabling CLIP inference in web environments.",AI3;AI3-05,inference_implementation;model_porting,library,Jupyter Notebook,https://github.com/josephrocca/openai-clip-js,,MIT,clip;javascript;onnx
1246,Sparrow,Structured data extraction using LLMs,"A tool for structured data extraction and instruction calling using Machine Learning and Large Language Models, suitable for processing scientific documents or data.",AI3,data_extraction;information_retrieval,solver,Python,https://github.com/katanaml/sparrow,,GPL-3.0,extraction;llm;data-processing
1247,gpt-llama.cpp,OpenAI API adapter for local llama.cpp models,"A utility that acts as a drop-in replacement for OpenAI's GPT endpoints, allowing applications to interface with local llama.cpp models via standard APIs.",AI3;AI3-05,inference_serving;api_adaptation,service,JavaScript,https://github.com/keldenl/gpt-llama.cpp,,MIT,api;llama.cpp;serving
1248,search,Embedded vector search library using llama.cpp,"A Go library for embedded vector search and semantic embeddings utilizing llama.cpp, enabling semantic analysis and retrieval.",AI3,vector_search;embedding_generation,library,Go,https://github.com/kelindar/search,,MIT,search;embeddings;go
1249,java-llama.cpp,Java bindings for llama.cpp,"Java bindings for the llama.cpp inference engine, enabling Java applications to run LLaMA models locally.",AI3;AI3-05,inference_integration;language_binding,library,C++,https://github.com/kherud/java-llama.cpp,,MIT,java;llama.cpp;inference
1250,ONNX Runtime Server,REST API server for ONNX inference,A server implementation that provides TCP and HTTP/HTTPS REST APIs for running inference using ONNX Runtime.,AI3;AI3-05,inference_serving;model_deployment,service,C++,https://github.com/kibae/onnxruntime-server,,MIT,onnx;server;rest-api
1251,triton-grpc-proxy-rs,Proxy server for Triton gRPC inference,"A Rust-based proxy server for the Triton gRPC server, specifically designed for handling embedding model inference requests.",AI3;AI3-05,inference_serving;proxy_service,service,Rust,https://github.com/kozistr/triton-grpc-proxy-rs,,Apache-2.0,triton;proxy;rust
1252,KServe,Standardized AI inference platform for Kubernetes,"A standardized, distributed inference platform for deploying generative and predictive AI models on Kubernetes, supporting scalable multi-framework deployment.",AI3;AI3-05,inference_serving;model_deployment,platform,Shell,https://github.com/kserve/kserve,https://kserve.github.io/website/,Apache-2.0,kubernetes;serving;mlops
1253,KubeAI,Kubernetes operator for managing and scaling AI inference workloads,"KubeAI is an AI Inference Operator for Kubernetes that simplifies serving machine learning models in production. It supports various model types including VLMs, LLMs, embeddings, and speech-to-text, providing auto-scaling and infrastructure management for AI services.",AI3;AI3-05,model_serving;inference_orchestration,platform,Go,https://github.com/kubeai-project/kubeai,https://github.com/kubeai-project/kubeai,Apache-2.0,kubernetes;inference-server;llm-serving;operator
1254,Mooncake,High-performance KVCache-centric LLM serving platform,"Mooncake is a serving platform designed for Large Language Models (LLMs), utilizing a KVCache-centric architecture to optimize inference performance. It is used in production for the Kimi LLM service, focusing on efficient resource utilization and low-latency serving.",AI3;AI3-05,model_serving;inference_optimization,platform,C++,https://github.com/kvcache-ai/Mooncake,https://github.com/kvcache-ai/Mooncake,Apache-2.0,llm-serving;kv-cache;inference-engine
1255,ktransformers,Framework for heterogeneous LLM inference and fine-tuning optimization,ktransformers is a flexible framework designed to optimize Large Language Model (LLM) inference and fine-tuning on heterogeneous hardware. It provides tools for experiencing and developing advanced optimization techniques for transformer-based models.,AI3;AI3-05,inference_optimization;model_finetuning,library,Python,https://github.com/kvcache-ai/ktransformers,https://github.com/kvcache-ai/ktransformers,Apache-2.0,transformers;inference-optimization;llm
1256,Larq Compute Engine,Highly optimized inference engine for Binarized Neural Networks (BNNs),"Larq Compute Engine (LCE) is a highly optimized inference engine specifically designed for Binarized Neural Networks (BNNs). It targets mobile and embedded devices, providing efficient execution of quantized models.",AI3;AI3-05,inference_acceleration;quantization,library,C++,https://github.com/larq/compute-engine,https://docs.larq.dev/compute-engine/,Apache-2.0,bnn;inference-engine;quantization;mobile-ai
1257,Mobile-ID,Deep face model compression and acceleration toolkit,A MATLAB-based toolkit for compressing deep face recognition models. It implements algorithms for model compression to enable efficient deployment on mobile devices.,AI3;AI3-05,model_compression;quantization,solver,MATLAB,https://github.com/liuziwei7/mobile-id,https://github.com/liuziwei7/mobile-id,None,model-compression;face-recognition;matlab
1258,LLMKit,"Toolkit for LLM prompt management, testing, and inference serving","LLMKit is a comprehensive toolkit and inference server for managing prompts, versioning, testing, and evaluating Large Language Models. It provides an OpenAI-compatible API and UI for model interaction.",AI3;AI3-05,model_serving;prompt_engineering,platform,Rust,https://github.com/llmkit-ai/llmkit,https://github.com/llmkit-ai/llmkit,MIT,llm-serving;prompt-management;inference-server
1259,MLX Omni Server,Local inference server for Apple Silicon using MLX framework,"MLX Omni Server is a local inference server built on Apple's MLX framework, optimized for Apple Silicon. It provides OpenAI-compatible API endpoints for serving LLMs locally with high efficiency.",AI3;AI3-05,model_serving;inference_server,platform,Python,https://github.com/madroidmaq/mlx-omni-server,https://github.com/madroidmaq/mlx-omni-server,MIT,mlx;apple-silicon;inference-server;llm
1260,Altius,Lightweight ONNX inference runtime in Rust,"Altius is a small, efficient ONNX inference runtime written in Rust. It is designed to run ONNX models with low overhead, suitable for embedding in applications requiring fast inference.",AI3;AI3-05,inference_runtime;model_execution,library,Rust,https://github.com/maekawatoshiki/altius,https://github.com/maekawatoshiki/altius,MIT,onnx;inference-runtime;rust
1261,rust-llama.cpp,Rust bindings for llama.cpp inference engine,"This library provides Rust bindings for llama.cpp, enabling Rust applications to leverage the efficient LLM inference capabilities of llama.cpp.",AI3;AI3-05,inference_runtime;model_serving,library,Rust,https://github.com/mdrokz/rust-llama.cpp,https://github.com/mdrokz/rust-llama.cpp,MIT,rust;llama.cpp;bindings;inference
1262,Sparsebit,Model compression and acceleration toolbox,"Sparsebit is a toolbox based on PyTorch for model compression and acceleration. It provides tools for quantization, pruning, and other optimization techniques to improve inference efficiency.",AI3;AI3-05,model_compression;quantization,library,Python,https://github.com/megvii-research/Sparsebit,https://github.com/megvii-research/Sparsebit,Apache-2.0,model-compression;quantization;pytorch
1263,llama_ros,ROS 2 integration for llama.cpp and llava.cpp,"llama_ros provides a set of ROS 2 packages to integrate llama.cpp (for LLMs) and llava.cpp (for VLMs) into robotics systems, enabling on-robot inference.",AI3;AI3-05,inference_integration;robotics_inference,library,C++,https://github.com/mgonzs13/llama_ros,https://github.com/mgonzs13/llama_ros,MIT,ros2;robotics;llama.cpp;inference
1264,Infinity,High-throughput serving engine for embeddings and reranking models,"Infinity is a high-performance serving engine specialized for text-embeddings, reranking models, and other vector-based models (CLIP, etc.). It focuses on high throughput and low latency for vector search applications.",AI3;AI3-05,model_serving;embedding_generation,platform,Python,https://github.com/michaelfeil/infinity,https://github.com/michaelfeil/infinity,MIT,embedding-server;inference-engine;vector-search
1265,Olive,Automated machine learning model optimization toolkit,"Olive is a toolkit that simplifies the process of model fine-tuning, conversion, quantization, and optimization for deployment on various hardware targets (CPUs, GPUs, NPUs). It automates the optimization pipeline.",AI3;AI3-05,model_optimization;quantization;model_conversion,library,Python,https://github.com/microsoft/Olive,https://microsoft.github.io/Olive/,MIT,model-optimization;onnx;quantization;automl
1266,ParrotServe,Efficient serving engine for LLM-based applications,ParrotServe is a serving system designed to optimize the execution of LLM-based applications by using semantic variables to manage context and requests efficiently.,AI3;AI3-05,model_serving;inference_optimization,platform,Python,https://github.com/microsoft/ParrotServe,https://github.com/microsoft/ParrotServe,MIT,llm-serving;inference-system;optimization
1267,NNI,AutoML toolkit for neural architecture search and model compression,"Neural Network Intelligence (NNI) is an open-source AutoML toolkit that automates feature engineering, neural architecture search (NAS), hyper-parameter tuning, and model compression to optimize model performance and efficiency.",AI3;AI3-05,model_optimization;model_compression;automl,library,Python,https://github.com/microsoft/nni,https://nni.readthedocs.io/,MIT,automl;nas;model-compression;hyperparameter-tuning
1268,ONNX Server Open Enclave,Confidential inference server for ONNX models,"This tool is a port of the ONNX inference server designed to run within Open Enclave, enabling confidential inference with data encryption and attestation capabilities, specifically for Azure Confidential Computing.",AI3;AI3-05,model_serving;confidential_computing,platform,C,https://github.com/microsoft/onnx-server-openenclave,https://github.com/microsoft/onnx-server-openenclave,MIT,confidential-computing;onnx;inference-server;security
1269,onnxruntime-extensions,Custom operators and extensions for ONNX Runtime,"A library providing custom operators and extensions for ONNX Runtime, enabling pre- and post-processing steps (like tokenization and image processing) to be embedded directly within the ONNX model graph.",AI3;AI3-05,data_processing;inference_support,library,C++,https://github.com/microsoft/onnxruntime-extensions,https://github.com/microsoft/onnxruntime-extensions,MIT,onnx;extensions;preprocessing;custom-operators
1270,Sarathi-Serve,Low-latency and high-throughput LLM serving engine,Sarathi-Serve is a serving engine for Large Language Models designed to maximize throughput and minimize latency through techniques like chunked prefill and decode-maximal batching.,AI3;AI3-05,model_serving;inference_optimization,platform,Python,https://github.com/microsoft/sarathi-serve,https://github.com/microsoft/sarathi-serve,Apache-2.0,llm-serving;inference-engine;optimization
1271,vAttention,Dynamic memory management system for LLM serving,"vAttention is a system for dynamic memory management in LLM serving, enabling efficient handling of KV-cache without the need for PagedAttention, optimizing memory usage and performance.",AI3;AI3-05,memory_management;inference_optimization,library,C,https://github.com/microsoft/vattention,https://github.com/microsoft/vattention,MIT,memory-management;llm-serving;cuda
1272,Vidur,Large-scale simulation framework for LLM inference,Vidur is a high-fidelity simulation framework for Large Language Model (LLM) inference. It allows researchers and practitioners to estimate the performance of LLM serving systems under various configurations and workloads.,AI3;AI3-05,system_simulation;performance_analysis,solver,Python,https://github.com/microsoft/vidur,https://github.com/microsoft/vidur,MIT,simulation;llm-inference;performance-modeling
1273,AMC,AutoML for Model Compression on mobile devices,"AMC (AutoML for Model Compression) leverages reinforcement learning to automatically find the optimal compression strategy (pruning ratio, quantization bits) for deep neural networks, targeting mobile device constraints.",AI3;AI3-05,model_compression;automl,solver,Python,https://github.com/mit-han-lab/amc,https://github.com/mit-han-lab/amc,MIT,model-compression;reinforcement-learning;automl
1274,LLM-AWQ,Activation-aware Weight Quantization for LLMs,AWQ is a quantization toolkit for Large Language Models that protects salient weights based on activation magnitude. It enables efficient 4-bit quantization with minimal performance degradation.,AI3;AI3-05,model_quantization;inference_acceleration,library,Python,https://github.com/mit-han-lab/llm-awq,https://github.com/mit-han-lab/llm-awq,MIT,quantization;llm;compression
1275,OmniServe,Unified efficient serving system for LLMs,"OmniServe (encompassing QServe and LServe) is a serving system designed for efficient LLM inference. It features advanced quantization (W4A8KV4) and system co-design, as well as optimizations for long-sequence serving.",AI3;AI3-05,model_serving;inference_optimization,platform,C++,https://github.com/mit-han-lab/omniserve,https://github.com/mit-han-lab/omniserve,Apache-2.0,llm-serving;quantization;long-context
1276,SmoothQuant,Post-training quantization for Large Language Models,"SmoothQuant is a post-training quantization framework that enables 8-bit weight, 8-bit activation (W8A8) quantization for LLMs by smoothing activation outliers, maintaining accuracy while improving efficiency.",AI3;AI3-05,model_quantization;inference_optimization,library,Python,https://github.com/mit-han-lab/smoothquant,https://github.com/mit-han-lab/smoothquant,MIT,quantization;llm;post-training-optimization
1277,MLC LLM,Universal LLM deployment engine using machine learning compilation,"A universal deployment solution that enables large language models to run natively on a diverse set of hardware backends and native applications, utilizing machine learning compilation technology (TVM).",AI3;AI3-05,inference_optimization;model_deployment;quantization,solver,Python,https://github.com/mlc-ai/mlc-llm,https://llm.mlc.ai/,Apache-2.0,llm;compilation;inference;edge-computing
1278,Stopwatch,Benchmarking tool for LLMs on Modal,"A utility for benchmarking the performance (latency, throughput) of Large Language Models running on the Modal serverless platform.",AI3;AI3-05,benchmarking;performance_analysis,solver,Python,https://github.com/modal-labs/stopwatch,,MIT,benchmarking;llm;latency
1279,Mosec,High-performance ML model serving framework,A machine learning model serving framework that offers dynamic batching and efficient CPU/GPU pipelines to maximize hardware utilization for inference.,AI3;AI3-05,model_serving;inference_optimization,platform,Python,https://github.com/mosecorg/mosec,https://mosecorg.github.io/mosec/,Apache-2.0,serving;dynamic-batching;inference
1280,Llama Swap,Model swapping utility for local LLM servers,"A proxy service that enables reliable model swapping for OpenAI/Anthropic compatible local inference servers like llama.cpp or vllm, facilitating dynamic model management.",AI3;AI3-05,model_management;serving_utility,service,Go,https://github.com/mostlygeek/llama-swap,,MIT,proxy;model-swapping;llm-serving
1281,Splitwise Sim,LLM serving cluster simulator,"A simulation tool for modeling and analyzing the behavior of LLM serving clusters, useful for research into scheduling and resource allocation strategies.",AI3;AI3-05,simulation;system_modeling,solver,Jupyter Notebook,https://github.com/mutinifni/splitwise-sim,,MIT,simulation;cluster;llm-serving
1282,AutoGPTQ-API,API wrapper for AutoGPTQ inference,"A tool to host GPTQ quantized models using AutoGPTQ as an API, compatible with text generation UI APIs, facilitating the serving of quantized models.",AI3;AI3-05,model_serving;quantization,service,Python,https://github.com/mzbac/AutoGPTQ-API,,None,gptq;api;serving
1283,GPTQ-for-LLaMa-API,API for GPT-QLLama models,"A lightweight API implementation for serving GPT-QLLama models, enabling programmatic access to quantized LLaMa inference.",AI3;AI3-05,model_serving;quantization,service,Python,https://github.com/mzbac/GPTQ-for-LLaMa-API,,Apache-2.0,llama;gptq;api
1284,MLX LLM Server,Local LLM serving using MLX framework,"A server implementation for inferring and serving local Large Language Models using Apple's MLX framework, optimized for Apple Silicon.",AI3;AI3-05,model_serving;inference_optimization,service,Python,https://github.com/mzbac/mlx-llm-server,,None,mlx;apple-silicon;serving
1285,MLX-Textgen,OpenAI-compatible API for MLX LLM serving,"A Python package for serving LLMs on OpenAI-compatible API endpoints with features like prompt caching, utilizing the MLX framework.",AI3;AI3-05,model_serving;inference_optimization,service,Python,https://github.com/nath1295/MLX-Textgen,,MIT,mlx;api;serving
1286,onnxruntime-rs,Rust wrapper for ONNX Runtime,"A Rust language binding for Microsoft's ONNX Runtime, enabling high-performance inference of ONNX models within Rust applications.",AI3;AI3-05,inference_runtime;language_binding,library,Rust,https://github.com/nbigaouette/onnxruntime-rs,,Apache-2.0,rust;onnx;inference
1287,DeepSparse,Sparsity-aware deep learning inference runtime,"A CPU inference runtime that leverages sparsity to accelerate deep learning models, offering significant performance improvements for sparse models.",AI3;AI3-05,inference_optimization;sparsity,solver,Python,https://github.com/neuralmagic/deepsparse,https://docs.neuralmagic.com/deepsparse/,NOASSERTION,sparsity;cpu-inference;acceleration
1288,SparseZoo,Repository for sparse and quantized models,"A repository and tooling for accessing highly sparse and sparse-quantized neural network models, along with their sparsification recipes.",AI3;AI3-05,model_repository;model_management,dataset,Python,https://github.com/neuralmagic/sparsezoo,https://docs.neuralmagic.com/sparsezoo/,Apache-2.0,sparse-models;model-zoo;quantization
1289,Sparsify,Model optimization tool for inference acceleration,A product and toolset for optimizing machine learning models through sparsification and quantization to accelerate inference.,AI3;AI3-05,model_optimization;quantization;pruning,solver,Python,https://github.com/neuralmagic/sparsify,https://docs.neuralmagic.com/sparsify/,Apache-2.0,optimization;pruning;inference
1290,Wllama,WebAssembly binding for llama.cpp,"A WebAssembly binding for llama.cpp that enables running LLM inference directly in the browser or other Wasm runtimes, facilitating client-side scientific computing.",AI3;AI3-05,inference_runtime;webassembly,library,TypeScript,https://github.com/ngxson/wllama,,MIT,wasm;llama.cpp;browser-inference
1291,vLLM-gfx906,vLLM port for AMD gfx906 GPUs,"A specialized port of the vLLM serving engine optimized for AMD gfx906 GPUs (e.g., Radeon VII, MI50, MI60), enabling high-throughput serving on this hardware.",AI3;AI3-05,model_serving;inference_optimization,solver,Python,https://github.com/nlzy/vllm-gfx906,,Apache-2.0,amd;rocm;vllm;serving
1292,pygpt4all,Python bindings for llama.cpp and gpt4all,"Official Python bindings for the gpt4all and llama.cpp ecosystem, allowing developers to run quantized LLMs locally via Python.",AI3;AI3-05,inference_runtime;language_binding,library,C++,https://github.com/nomic-ai/pygpt4all,,MIT,gpt4all;llama.cpp;bindings
1293,openai_trtllm,OpenAI compatible API for TensorRT-LLM,"A backend that exposes TensorRT-LLM via an OpenAI-compatible API, facilitating the integration of optimized TensorRT inference into standard LLM workflows.",AI3;AI3-05,model_serving;inference_optimization,service,Rust,https://github.com/npuichigo/openai_trtllm,,MIT,tensorrt-llm;api;serving
1294,DeepCompressor,Model compression toolbox for LLMs and Diffusion Models,"A toolbox for compressing Large Language Models and Diffusion Models, enabling efficient storage and inference through advanced quantization and compression techniques.",AI3;AI3-05,model_compression;quantization,solver,Python,https://github.com/nunchaku-tech/deepcompressor,,Apache-2.0,compression;llm;diffusion
1295,Whisper TFLite,Optimized Whisper TFLite port for edge inference,"A port of OpenAI's Whisper model to TensorFlow Lite, optimized for efficient offline inference on edge devices.",AI3;AI3-05,inference_optimization;edge_computing,library,C++,https://github.com/nyadla-sys/whisper.tflite,,MIT,whisper;tflite;edge-inference
1296,ORT Builder,ONNX Runtime static library builder,"A utility to build static libraries for ONNX Runtime, facilitating the embedding of the inference engine into various applications and systems.",AI3;AI3-05,build_tool;inference_deployment,solver,C++,https://github.com/olilarkin/ort-builder,,MIT,onnx-runtime;build-tool;static-library
1297,Anomalib,Deep learning library for anomaly detection,"A library comprising state-of-the-art algorithms for anomaly detection, including features for experiment management, hyper-parameter optimization, and edge inference.",AI3;AI3-05,anomaly_detection;inference_optimization,library,Python,https://github.com/open-edge-platform/anomalib,https://anomalib.readthedocs.io/,Apache-2.0,anomaly-detection;computer-vision;edge-inference
1298,OpenVINO Training Extensions,Toolbox for training and optimizing CV models via OpenVINO,"A toolkit to train, evaluate, optimize, and deploy computer vision models, specifically designed to work with the OpenVINO ecosystem for efficient inference.",AI3;AI3-05,model_optimization;training_pipeline,workflow,Python,https://github.com/open-edge-platform/training_extensions,https://github.com/openvinotoolkit/training_extensions,Apache-2.0,openvino;computer-vision;optimization
1299,MMRazor,OpenMMLab model compression toolbox,"A model compression toolbox that provides various algorithms for network pruning, knowledge distillation, and neural architecture search to optimize models for inference.",AI3;AI3-05,model_compression;pruning;distillation,library,Python,https://github.com/open-mmlab/mmrazor,https://mmrazor.readthedocs.io/,Apache-2.0,compression;openmmlab;optimization
1300,OpenVINO Model Server,Scalable inference server for OpenVINO models,"A high-performance system for serving machine learning models optimized with OpenVINO, supporting scalable inference via gRPC and REST endpoints.",AI3;AI3-05,model_serving;inference_optimization,service,C++,https://github.com/openvinotoolkit/model_server,https://docs.openvino.ai/latest/ovms_what_is_openvino_model_server.html,Apache-2.0,serving;openvino;inference
1301,OpenVINO,Toolkit for optimizing and deploying AI inference,"An open-source toolkit for optimizing and deploying deep learning models across various hardware platforms, focusing on high-performance inference.",AI3;AI3-05,inference_optimization;model_deployment,platform,C++,https://github.com/openvinotoolkit/openvino,https://docs.openvino.ai/,Apache-2.0,inference;optimization;intel
1302,sd4j,Stable Diffusion pipeline in Java using ONNX Runtime,"A Java implementation of the Stable Diffusion pipeline leveraging ONNX Runtime for inference, enabling image generation within Java environments.",AI3;AI3-05,inference_pipeline;image_generation,library,Java,https://github.com/oracle/sd4j,,UPL-1.0,java;stable-diffusion;onnx
1303,KVCached,Virtualized elastic KV cache for LLM serving,"A system for virtualized and elastic Key-Value (KV) cache management, designed to optimize dynamic GPU sharing and memory usage in LLM serving.",AI3;AI3-05,inference_optimization;memory_management,solver,Python,https://github.com/ovg-project/kvcached,,Apache-2.0,kv-cache;llm-serving;optimization
1304,ONNX Transformers,Accelerated NLP pipelines using ONNX Runtime,A collection of pipelines and utilities for running fast NLP inference on CPUs using Hugging Face Transformers and ONNX Runtime.,AI3;AI3-05,inference_optimization;nlp_pipeline,library,Jupyter Notebook,https://github.com/patil-suraj/onnx_transformers,,Apache-2.0,onnx;transformers;nlp
1305,BambooAI,LLM-powered library for data discovery and analysis,"A Python library that uses Large Language Models to assist in conversational data discovery, analysis, and visualization, acting as an AI agent for data science tasks.",AI3;AI3-05,data_analysis;scientific_visualization,solver,Python,https://github.com/pgalko/BambooAI,,MIT,data-analysis;llm-agent;pandas
1306,llama.clj,Clojure wrapper for llama.cpp,"A Clojure language wrapper for llama.cpp, enabling the use of local Large Language Models within Clojure applications and research workflows.",AI3;AI3-05,inference_binding;language_binding,library,Clojure,https://github.com/phronmophobic/llama.clj,,MIT,clojure;llama.cpp;inference
1307,Neural Imaging,Toolbox for modeling photo acquisition pipelines,"A Python toolbox for modeling and optimizing photo acquisition and distribution pipelines, including camera ISP, compression, and manipulation detection.",AI3;AI3-05,image_processing;simulation;modeling,library,Python,https://github.com/pkorus/neural-imaging,,None,imaging;isp;simulation
1308,PowerServe,High-speed LLM serving framework,"A high-performance framework for serving Large Language Models locally, designed for speed and ease of use in deployment scenarios.",AI3;AI3-05,model_serving;inference_optimization,platform,C++,https://github.com/powerserve-project/PowerServe,,Apache-2.0,serving;llm;inference
1309,Prometheus-Eval,Evaluation library for LLM responses using Prometheus and GPT-4,"Prometheus-Eval provides tools to evaluate the quality of Large Language Model responses, serving as a critical component for validating scientific models and generated data.",AI3;AI3-05,model_evaluation;quality_assessment,library,Python,https://github.com/prometheus-eval/prometheus-eval,,Apache-2.0,evaluation;llm;benchmark
1310,Punica,System for serving multiple LoRA fine-tuned LLMs efficiently,"Punica is a serving system designed to run multiple LoRA fine-tuned Large Language Models simultaneously on shared GPUs, optimizing throughput for diverse scientific inference tasks.",AI3;AI3-05,model_serving;inference_optimization,platform,Python,https://github.com/punica-ai/punica,https://punica-ai.github.io/punica/,Apache-2.0,lora;multi-tenant;serving
1311,PyTorch-ORT,Acceleration library for PyTorch models using ONNX Runtime,"PyTorch-ORT enables the acceleration of PyTorch model training and inference by leveraging ONNX Runtime, optimizing computational efficiency for scientific AI workloads.",AI3;AI3-05,inference_acceleration;model_optimization,library,Python,https://github.com/pytorch/ort,https://cloudblogs.microsoft.com/opensource/2021/07/13/accelerate-pytorch-training-with-torch-ort/,MIT,onnx;pytorch;acceleration
1312,Qualcomm AI Hub Models,Library for accessing and deploying optimized ML models on Qualcomm devices,"This tool provides a Python API to access, optimize, and deploy a collection of state-of-the-art machine learning models, facilitating edge AI inference for scientific data collection and processing.",AI3;AI3-05,model_deployment;edge_inference,library,Python,https://github.com/quic/ai-hub-models,https://aihub.qualcomm.com/,BSD-3-Clause,edge-ai;model-zoo;optimization
1313,AIMET,AI Model Efficiency Toolkit for quantization and compression,AIMET (AI Model Efficiency Toolkit) provides advanced model quantization and compression techniques to optimize neural networks for efficient inference in scientific applications.,AI3;AI3-05,quantization;model_compression,library,Python,https://github.com/quic/aimet,https://quic.github.io/aimet-pages/index.html,NOASSERTION,quantization;compression;efficiency
1314,GPTQ-for-LLaMa,4-bit quantization implementation for LLaMA models using GPTQ,"This tool implements the GPTQ algorithm for 4-bit quantization of LLaMA models, enabling efficient inference of large language models on consumer-grade hardware for research purposes.",AI3;AI3-05,quantization;inference_optimization,solver,Python,https://github.com/qwopqwop200/GPTQ-for-LLaMa,,Apache-2.0,gptq;quantization;llama
1315,Tritony,Simplified client library for Triton Inference Server,"Tritony is a helper library that simplifies the configuration and interaction with NVIDIA Triton Inference Server, facilitating the deployment of scientific models.",AI3;AI3-05,model_serving;inference_client,library,Python,https://github.com/rtzr/tritony,,BSD-3-Clause,triton;inference;client
1316,OpenCvSharp Mini Runtime,Minimal runtime for OpenCVSharp optimized for server inference,"A lightweight runtime library for OpenCVSharp, designed to facilitate computer vision model inference in server environments for image processing tasks.",AI3;AI3-05,image_processing;inference_runtime,library,C#,https://github.com/sdcb/opencvsharp-mini-runtime,,Apache-2.0,opencv;runtime;inference
1317,GenAI-Bench,Benchmark tool for evaluating LLM serving systems,"GenAI-Bench is a benchmarking suite designed to evaluate the token-level performance, throughput, and latency of Large Language Model serving systems.",AI3;AI3-05,benchmarking;performance_evaluation,solver,Python,https://github.com/sgl-project/genai-bench,,MIT,benchmark;serving;llm
1318,SGLang,Fast serving framework for LLMs and VLMs,"SGLang is a high-performance serving framework for large language and vision-language models, offering optimized runtime execution for scientific AI applications.",AI3;AI3-05,model_serving;inference_engine,platform,Python,https://github.com/sgl-project/sglang,https://sgl-project.github.io/,Apache-2.0,serving;inference;vlm
1319,GPT Server,Production-grade serving framework for multimodal AI models,"gpt_server is an open-source framework for deploying various AI models including LLMs, Embeddings, and Rerankers, facilitating the creation of scientific inference services.",AI3;AI3-05,model_serving;multimodal_inference,platform,Python,https://github.com/shell-nlp/gpt_server,,Apache-2.0,serving;deployment;multimodal
1320,llm-llama-cpp,Plugin to run llama.cpp models via the LLM CLI,"This tool is a plugin for the 'llm' command-line utility, enabling the execution of models using the llama.cpp backend, facilitating local inference for researchers.",AI3;AI3-05,inference_runtime;model_execution,library,Python,https://github.com/simonw/llm-llama-cpp,,Apache-2.0,llama.cpp;plugin;inference
1321,Nano-PEARL,Parallel speculative decoding serving system,"Nano-PEARL is a serving system implementing Draft-Target Disaggregation via Parallel Speculative Decoding, designed to accelerate LLM inference.",AI3;AI3-05,inference_optimization;speculative_decoding,solver,Python,https://github.com/smart-lty/nano-PEARL,,None,speculative-decoding;serving;acceleration
1322,ArcticInference,vLLM plugin for high-throughput inference of Arctic models,A specialized plugin for the vLLM serving engine designed to enable high-throughput and low-latency inference specifically for Snowflake's Arctic series of Large Language Models.,AI3;AI3-05,model_serving;inference_optimization,library,Python,https://github.com/snowflakedb/ArcticInference,,Apache-2.0,vllm;inference;arctic-model
1323,Cube Studio,Cloud-native one-stop MLOps and AI platform,"A comprehensive cloud-native AI platform supporting the full MLOps lifecycle, including distributed training, hyperparameter search, and inference serving for deep learning and large language models.",AI3;AI3-05,mlops;model_training;model_serving,platform,Python,https://github.com/tencentmusic/cube-studio,https://github.com/tencentmusic/cube-studio/wiki,NOASSERTION,mlops;distributed-training;inference-server
1324,OpenModelZ,Autoscaling infrastructure for LLM inference on Kubernetes,A deployment tool designed to automate the scaling and management of Large Language Model (LLM) inference servers (like vLLM and SGLang) on Kubernetes clusters.,AI3;AI3-05,model_serving;infrastructure_scaling,platform,Go,https://github.com/tensorchord/openmodelz,,Apache-2.0,kubernetes;autoscaling;llm-serving
1325,TensorFlow Model Optimization Toolkit,Toolkit to optimize ML models for deployment,"A suite of tools for optimizing machine learning models for deployment and execution, supporting techniques such as quantization and pruning to reduce model size and improve latency.",AI3;AI3-05,model_optimization;quantization;pruning,library,Python,https://github.com/tensorflow/model-optimization,https://www.tensorflow.org/model_optimization,Apache-2.0,tensorflow;optimization;quantization
1326,Indexify,Realtime serving engine for data-intensive AI applications,"A serving engine and extraction framework designed for building data-intensive generative AI applications, facilitating the ingestion and processing of unstructured data for RAG and inference pipelines.",AI3;AI3-05,model_serving;data_extraction;rag,service,Rust,https://github.com/tensorlakeai/indexify,https://docs.getindexify.ai,Apache-2.0,serving-engine;rag;unstructured-data
1327,llamacpp-python,Python bindings for llama.cpp inference engine,"Python bindings for the llama.cpp library, enabling efficient local inference of Large Language Models directly within Python environments commonly used for scientific computing.",AI3;AI3-05,model_inference;local_deployment,library,C++,https://github.com/thomasantony/llamacpp-python,,NOASSERTION,llama.cpp;inference;python-binding
1328,SageAttention,Quantized attention library for model acceleration,"A library implementing quantized attention mechanisms to accelerate inference speed for language, image, and video models without significant loss in accuracy.",AI3;AI3-05,inference_acceleration;quantization,library,Cuda,https://github.com/thu-ml/SageAttention,,Apache-2.0,attention-mechanism;quantization;acceleration
1329,SpargeAttention,Training-free sparse attention for inference acceleration,A library providing a training-free sparse attention mechanism to accelerate the inference of transformer-based models by optimizing attention computation.,AI3;AI3-05,inference_acceleration;sparse_attention,library,Cuda,https://github.com/thu-ml/SpargeAttn,,Apache-2.0,sparse-attention;inference;optimization
1330,llama.onnx,Tools for converting and running LLaMA/RWKV models in ONNX,"A utility toolkit for exporting LLaMA and RWKV language models to the ONNX format, including quantization support and test cases for verification.",AI3;AI3-05,model_conversion;quantization,library,Python,https://github.com/tpoisonooo/llama.onnx,,GPL-3.0,onnx;model-conversion;llama
1331,Triton Core,Core library for Triton Inference Server,"The core library and API implementation for the NVIDIA Triton Inference Server, providing the fundamental infrastructure for model serving.",AI3;AI3-05,model_serving;infrastructure,library,C++,https://github.com/triton-inference-server/core,https://github.com/triton-inference-server/server/blob/main/docs/README.md,BSD-3-Clause,triton;inference-server;core
1332,Triton FIL Backend,Forest Inference Library backend for Triton,"A backend for the Triton Inference Server that enables high-performance inference of tree-based models (e.g., XGBoost, LightGBM, Scikit-Learn) using the Forest Inference Library (FIL).",AI3;AI3-05,model_serving;inference_backend,library,Jupyter Notebook,https://github.com/triton-inference-server/fil_backend,,Apache-2.0,triton;xgboost;random-forest
1333,Triton Local Cache,In-memory cache implementation for Triton,"A local in-memory cache implementation for the Triton Inference Server, designed to reduce latency by caching inference responses.",AI3;AI3-05,model_serving;caching,library,C++,https://github.com/triton-inference-server/local_cache,,BSD-3-Clause,triton;cache;optimization
1334,Triton Model Analyzer,Profiling tool for Triton Inference Server models,"A CLI tool for profiling and analyzing the compute and memory requirements of models served by Triton, helping to optimize configuration for performance.",AI3;AI3-05,performance_profiling;resource_optimization,solver,Python,https://github.com/triton-inference-server/model_analyzer,https://github.com/triton-inference-server/model_analyzer/blob/main/docs/README.md,Apache-2.0,profiling;triton;optimization
1335,Triton Model Navigator,Toolkit for optimizing and deploying models on NVIDIA GPUs,"An inference toolkit that automates the process of moving models from training to deployment, including optimization and conversion for NVIDIA GPUs within the Triton ecosystem.",AI3;AI3-05,model_deployment;model_optimization,workflow,Python,https://github.com/triton-inference-server/model_navigator,,Apache-2.0,deployment;optimization;nvidia
1336,Triton ONNX Runtime Backend,ONNX Runtime backend for Triton,The backend integration that allows the Triton Inference Server to execute models using the ONNX Runtime engine.,AI3;AI3-05,model_serving;inference_backend,library,C++,https://github.com/triton-inference-server/onnxruntime_backend,,BSD-3-Clause,triton;onnx;backend
1337,Triton Inference Server,High-performance inference serving software,"An open-source inference serving software that streamlines AI inference by enabling teams to deploy, run, and scale trained AI models from any framework on any GPU- or CPU-based infrastructure.",AI3;AI3-05,model_serving;inference_server,platform,Python,https://github.com/triton-inference-server/server,https://developer.nvidia.com/nvidia-triton-inference-server,BSD-3-Clause,inference-server;nvidia;deployment
1338,Triton TensorRT-LLM Backend,TensorRT-LLM backend for Triton,The backend for Triton Inference Server that enables optimized serving of Large Language Models using NVIDIA's TensorRT-LLM library.,AI3;AI3-05,model_serving;llm_inference,library,C++,https://github.com/triton-inference-server/tensorrtllm_backend,,Apache-2.0,tensorrt-llm;triton;backend
1339,Triton CLI,Command line interface for Triton Inference Server,"A command-line tool to simplify the creation, deployment, and profiling of models served by the Triton Inference Server.",AI3;AI3-05,model_management;deployment_tools,solver,Python,https://github.com/triton-inference-server/triton_cli,,NOASSERTION,cli;triton;management
1340,TrustGraph,Graph-based RAG tool for AI reliability,"A tool designed to eliminate hallucinations in AI agents by constructing and utilizing knowledge graphs, enhancing the reliability of scientific information retrieval and inference.",AI3;AI3-05,rag;knowledge_graph;inference_reliability,library,Python,https://github.com/trustgraph-ai/trustgraph,,Apache-2.0,rag;knowledge-graph;hallucination-reduction
1341,LLaVA C++ Server,Server implementation for LLaVA multimodal models,"A lightweight server implementation for LLaVA (Large Language-and-Vision Assistant) models based on llama.cpp, enabling multimodal inference.",AI3;AI3-05,model_serving;multimodal_inference,service,C++,https://github.com/trzy/llava-cpp-server,,MIT,llava;multimodal;inference-server
1342,ExLlamaV3,Optimized quantization and inference library for local LLMs,"A highly optimized library for quantization and inference of Large Language Models on consumer-class GPUs, focusing on performance and memory efficiency.",AI3;AI3-05,model_quantization;inference_optimization,library,Python,https://github.com/turboderp-org/exllamav3,,MIT,quantization;inference;exllama
1343,Pinferencia,Simple Python model deployment library,A lightweight library for deploying Python machine learning models as inference services with minimal configuration.,AI3;AI3-05,model_serving;deployment,library,Python,https://github.com/underneathall/pinferencia,https://pinferencia.underneathall.app,Apache-2.0,deployment;inference;python
1344,Super JSON Mode,Library for structured JSON generation from LLMs,"A framework designed to ensure low-latency and reliable JSON output generation from Large Language Models, facilitating structured data extraction from scientific text.",AI3;AI3-05,data_extraction;structured_generation,library,Jupyter Notebook,https://github.com/varunshenoy/super-json-mode,,NOASSERTION,json;llm-output;structured-data
1345,ScaleLLM,High-performance LLM inference system,"A high-performance inference system designed for deploying Large Language Models in production environments, optimizing throughput and latency.",AI3;AI3-05,model_serving;inference_system,platform,C++,https://github.com/vectorch-ai/ScaleLLM,,Apache-2.0,inference;llm;production
1346,Orkhon,Rust-based ML inference framework,"A machine learning inference framework and server runtime written in Rust, focusing on performance and safety for model deployment.",AI3;AI3-05,model_serving;inference_runtime,framework,Rust,https://github.com/vertexclique/orkhon,https://orkhon.neocities.org,MIT,rust;inference;machine-learning
1347,LLM Compressor,Library for LLM compression and optimization,"A library compatible with Transformers for applying compression algorithms (quantization, pruning) to Large Language Models to optimize them for deployment with vLLM.",AI3;AI3-05,model_compression;quantization,library,Python,https://github.com/vllm-project/llm-compressor,,Apache-2.0,compression;quantization;vllm
1348,vLLM Production Stack,Reference stack for K8s-native vLLM deployment,"A reference implementation and toolkit for deploying vLLM on Kubernetes clusters, providing best practices for production-grade model serving.",AI3;AI3-05,model_deployment;infrastructure,workflow,Python,https://github.com/vllm-project/production-stack,,Apache-2.0,kubernetes;deployment;vllm
1349,Semantic Router,Routing layer for LLM inference pipelines,"A superfast decision-making layer for LLMs and agents that routes requests to the appropriate model or prompt based on semantic meaning, optimizing inference costs and performance.",AI3;AI3-05,inference_routing;pipeline_optimization,library,Go,https://github.com/vllm-project/semantic-router,https://semantic-router.readthedocs.io,Apache-2.0,routing;semantic-search;inference
1350,vLLM,High-throughput LLM inference and serving engine,"A state-of-the-art library for fast and memory-efficient inference and serving of Large Language Models, featuring PagedAttention and continuous batching.",AI3;AI3-05,model_serving;inference_engine,service,Python,https://github.com/vllm-project/vllm,https://docs.vllm.ai,Apache-2.0,inference;serving;paged-attention
1351,vllm-ascend,Hardware backend plugin enabling vLLM execution on Huawei Ascend NPUs,"A community-maintained hardware abstraction layer that extends the vLLM inference engine to support Huawei Ascend AI processors (NPUs), enabling high-throughput LLM serving on this specific hardware architecture.",AI3;AI3-05,inference_optimization;serving,library,Python,https://github.com/vllm-project/vllm-ascend,,Apache-2.0,vllm;ascend;npu;inference
1352,vllm-omni,Inference framework for omni-modality large models,"An extension of the vLLM architecture designed to support efficient inference for multimodal models (audio, video, text), handling the complexities of cross-modal generation and serving.",AI3;AI3-05,serving;inference_optimization,library,Python,https://github.com/vllm-project/vllm-omni,,Apache-2.0,multimodal;inference;vllm;serving
1353,QLLM,Quantization toolbox for Large Language Models,"A general-purpose quantization library supporting multiple algorithms (GPTQ, AWQ, HQQ, VPTQ) for compressing Large Language Models to 2-8 bits, with support for exporting to ONNX/ONNX Runtime.",AI3;AI3-05,quantization;model_compression,library,Python,https://github.com/wejoncy/QLLM,,Apache-2.0,quantization;gptq;awq;onnx
1354,quantkit,CLI tool for LLM quantization formats,"A command-line interface utility for quantizing Large Language Models into various formats including GGUF, GPTQ, AWQ, HQQ, and EXL2, facilitating model deployment on consumer hardware.",AI3;AI3-05,quantization;model_conversion,solver,Python,https://github.com/xhedit/quantkit,,MIT,cli;quantization;gguf;gptq
1355,onnx_runtime_cpp,C++ wrapper for ONNX Runtime deployment,"A lightweight C++ library designed to simplify the deployment of ONNX models using ONNX Runtime, providing an abstraction layer for inference integration in C++ applications.",AI3;AI3-05,inference_optimization;deployment,library,C++,https://github.com/xmba15/onnx_runtime_cpp,,MIT,onnx;cpp;inference;deployment
1356,Xinference,Unified inference serving platform for LLMs and multimodal models,"A comprehensive inference server that supports running open-source LLMs, speech recognition, and multimodal models. It provides a unified API compatible with OpenAI's interface and supports distributed deployment.",AI3;AI3-05,serving;inference_optimization,platform,Python,https://github.com/xorbitsai/inference,https://inference.readthedocs.io,Apache-2.0,serving;llm;distributed-inference;api
1357,LOPQ,Locally Optimized Product Quantization for ANN search,"A library for training Locally Optimized Product Quantization (LOPQ) models, enabling efficient approximate nearest neighbor search for high-dimensional data, suitable for large-scale scientific data retrieval.",AI3;AI3-05,quantization;data_analysis,library,Python,https://github.com/yahoo/lopq,,Apache-2.0,ann;quantization;search;high-dimensional
1358,ZhiLight,High-performance inference engine for Llama models,"A highly optimized inference acceleration engine specifically designed for Llama and its variants, focusing on high throughput and low latency serving in production environments.",AI3;AI3-05,serving;inference_optimization,solver,C++,https://github.com/zhihu/ZhiLight,,Apache-2.0,inference;llama;acceleration;serving
