{
  "generated_at": "2025-12-16T01:22:33.981892+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "G1",
      "leaf_cluster_name": "科研文献-检索/解析/引用网络生态",
      "domain": "Sci Knowledge",
      "typical_objects": "PDFs/citations",
      "task_chain": "解析→抽取→索引→检索→评测",
      "tool_form": "解析器 + 检索 + 评测"
    },
    "unit": {
      "unit_id": "G1-01",
      "unit_name": "PDF/LaTeX 解析与结构化抽取",
      "target_scale": "200–450",
      "coverage_tools": "parsers、GROBID类、layout"
    },
    "search": {
      "target_candidates": 450,
      "queries": [
        "[GH] Tabula",
        "[GH] PDFMiner",
        "[GH] DeepDoctection",
        "[GH] Marker",
        "[GH] Unstructured",
        "[GH] CERMINE",
        "[GH] Science Parse",
        "[GH] LayoutParser",
        "[GH] Nougat",
        "[GH] GROBID",
        "[GH] pdf parser",
        "[GH] scientific paper parsing",
        "[GH] document layout analysis",
        "[GH] pdf structure extraction",
        "[GH] table extraction",
        "[GH] formula extraction",
        "[GH] latex parser",
        "[GH] citation parser",
        "[GH] grobid",
        "[GH] pdf to markdown",
        "[GH] academic document processing",
        "[GH] ocr scientific papers",
        "[GH] pdf mining",
        "[WEB] scientific pdf parsing tools github",
        "[WEB] document layout analysis deep learning github",
        "[WEB] pdf table extraction scientific papers github",
        "[WEB] latex formula extraction github",
        "[WEB] pdf to structured data converter github"
      ],
      "total_candidates": 1092,
      "tool_candidates": 685,
      "final_tools": 232
    }
  },
  "tools": [
    {
      "name": "GNN-TableExtraction",
      "one_line_profile": "Graph Neural Networks based table extraction implementation for PDF documents",
      "detailed_description": "Implementation of the ICPR2022 paper 'Graph Neural Networks and Representation Embedding for table extraction in PDF Documents', providing a deep learning approach to identify and extract tabular structures from scientific PDFs.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "structure_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AILab-UniFI/GNN-TableExtraction",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "gnn",
        "table-extraction",
        "pdf-parsing",
        "deep-learning"
      ],
      "id": 1
    },
    {
      "name": "CTE-Dataset",
      "one_line_profile": "Contextualized Table Extraction Dataset for document analysis",
      "detailed_description": "A dataset designed for the task of contextualized table extraction, supporting the development and benchmarking of models that extract tables along with their surrounding context from documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "dataset_creation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/AILab-UniFI/cte-dataset",
      "help_website": [],
      "license": null,
      "tags": [
        "dataset",
        "table-extraction",
        "document-analysis"
      ],
      "id": 2
    },
    {
      "name": "PDF_Form_OCR",
      "one_line_profile": "Table recognition and content extraction tool for PDF files",
      "detailed_description": "A Python-based tool for extracting content and recognizing tables within PDF documents, facilitating the digitization of structured data from scanned or native PDF forms.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_recognition",
        "pdf_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AlsoSprachZarathushtra/PDF_Form_OCR",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ocr",
        "table-recognition",
        "pdf-extraction"
      ],
      "id": 3
    },
    {
      "name": "TableNet",
      "one_line_profile": "Deep learning model for end-to-end table detection and extraction",
      "detailed_description": "An implementation of the TableNet architecture, an end-to-end deep learning model designed to detect tabular regions and recognize table structures (rows and columns) directly from scanned document images.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_detection",
        "structure_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/AmanSavaria1402/TableNet",
      "help_website": [],
      "license": null,
      "tags": [
        "deep-learning",
        "table-detection",
        "ocr",
        "document-analysis"
      ],
      "id": 4
    },
    {
      "name": "PTC-Mathcad-to-LaTeX-parser",
      "one_line_profile": "Converter for PTC Mathcad files to LaTeX format",
      "detailed_description": "A Python application that parses PTC Mathcad 15 files and converts the mathematical content into LaTeX, enabling the migration of engineering calculations to scientific publishing formats.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "format_conversion",
        "latex_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ArtificialTruth/PTC-Mathcad-to-LaTeX-parser",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "mathcad",
        "latex",
        "converter",
        "engineering-tools"
      ],
      "id": 5
    },
    {
      "name": "TableExtractor-Advanced-PDF-Table-Extraction",
      "one_line_profile": "Advanced PDF table extraction using OCR and image processing",
      "detailed_description": "A Python project leveraging OCR and image processing techniques to extract tabular data from scanned PDF documents, addressing challenges in digitizing unstructured scientific data.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "ocr"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Baskar-forever/TableExtractor-Advanced-PDF-Table-Extraction",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf",
        "table-extraction",
        "ocr",
        "image-processing"
      ],
      "id": 6
    },
    {
      "name": "GIANT-Dataset",
      "one_line_profile": "Large-scale synthetic bibliographic reference string dataset and generator",
      "detailed_description": "A massive dataset of 1 billion annotated synthetic bibliographic reference strings, accompanied by scripts to generate tagged XML citation strings, used for training and evaluating citation parsing models.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "citation_parsing",
        "dataset_creation"
      ],
      "application_level": "dataset",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/BeelGroup/GIANT-The-1-Billion-Annotated-Synthetic-Bibliographic-Reference-String-Dataset",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "citation-parsing",
        "bibliometrics",
        "dataset",
        "synthetic-data"
      ],
      "id": 7
    },
    {
      "name": "BADLAD",
      "one_line_profile": "Bengali Document Layout Analysis Dataset",
      "detailed_description": "A dataset specifically designed for document layout analysis of Bengali documents, supporting the development of OCR and layout recognition models for non-Latin scripts.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "layout_analysis",
        "dataset_creation"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/BengaliAI/BADLAD",
      "help_website": [],
      "license": null,
      "tags": [
        "document-layout-analysis",
        "dataset",
        "ocr",
        "bengali"
      ],
      "id": 8
    },
    {
      "name": "DocumentLayoutAnalysis",
      "one_line_profile": "C# resources and algorithms for document layout analysis",
      "detailed_description": "A collection of algorithms and resources for performing document layout analysis (DLA) using C# and PdfPig, including implementations of various page segmentation and reading order detection methods.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "layout_analysis",
        "page_segmentation"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/BobLd/DocumentLayoutAnalysis",
      "help_website": [],
      "license": null,
      "tags": [
        "c-sharp",
        "pdfpig",
        "document-layout-analysis",
        "pdf-parsing"
      ],
      "id": 9
    },
    {
      "name": "camelot-sharp",
      "one_line_profile": "C# port of the Camelot PDF table extraction library",
      "detailed_description": "A C# library for extracting tabular data from PDFs, ported from the popular Python 'Camelot' library, utilizing PdfPig for underlying PDF operations.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "pdf_parsing"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/BobLd/camelot-sharp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "c-sharp",
        "table-extraction",
        "pdf",
        "camelot"
      ],
      "id": 10
    },
    {
      "name": "tabula-sharp",
      "one_line_profile": "C# port of the Tabula PDF table extraction library",
      "detailed_description": "A C# library for extracting tables from PDF files, ported from 'tabula-java', enabling .NET developers to integrate table extraction capabilities into their applications.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "pdf_parsing"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/BobLd/tabula-sharp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "c-sharp",
        "table-extraction",
        "pdf",
        "tabula"
      ],
      "id": 11
    },
    {
      "name": "any-parser",
      "one_line_profile": "Configurable document retrieval and parsing LLM tool",
      "detailed_description": "A tool designed to accurately parse and retrieve information from documents (PDFs, images) using Large Language Models, focusing on privacy and configurability for unstructured data extraction.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "information_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CambioML/any-parser",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "document-parsing",
        "pdf",
        "ocr"
      ],
      "id": 12
    },
    {
      "name": "uniflow",
      "one_line_profile": "LLM-based workflow for PDF extraction, cleaning, and clustering",
      "detailed_description": "A unified interface to extract text from unstructured data (PDFs, Word, HTML) using LLMs, clean the data, and transform it into structured formats for downstream R&D tasks.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "text_extraction",
        "data_cleaning",
        "clustering"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "pdf-extraction",
        "etl",
        "unstructured-data"
      ],
      "id": 13
    },
    {
      "name": "publaynet-models",
      "one_line_profile": "Pre-trained Detectron2 models for document layout analysis",
      "detailed_description": "A collection of Detectron2 object detection models trained on the PubLayNet dataset, ready for use in document layout analysis tasks to identify text, figures, tables, and lists.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "layout_analysis",
        "object_detection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CaseDrive/publaynet-models",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "detectron2",
        "publaynet",
        "document-layout-analysis",
        "deep-learning"
      ],
      "id": 14
    },
    {
      "name": "text-extract-api",
      "one_line_profile": "API for extracting structured data from documents using OCR and LLMs",
      "detailed_description": "A comprehensive API solution for parsing and extracting text from various document formats (PDF, Word, PPTX) into structured JSON or Markdown, utilizing modern OCRs and Ollama-supported models.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "ocr",
        "text_extraction"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/CatchTheTornado/text-extract-api",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ocr",
        "pdf-parsing",
        "llm",
        "api"
      ],
      "id": 15
    },
    {
      "name": "CERMINE",
      "one_line_profile": "Java library for extracting metadata and content from scientific PDFs",
      "detailed_description": "Content ExtRactor and MINEr (CERMINE) is a comprehensive Java library and web service for extracting metadata, bibliographic references, and structured full text from scientific articles in PDF format.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "metadata_extraction",
        "citation_parsing",
        "structure_recognition"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/CeON/CERMINE",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "pdf-extraction",
        "metadata-extraction",
        "bibliometrics",
        "java"
      ],
      "id": 16
    },
    {
      "name": "eparse",
      "one_line_profile": "Excel spreadsheet crawler and table parser",
      "detailed_description": "A Python library designed to crawl and parse tables from Excel spreadsheets, facilitating the extraction of structured scientific data often stored in spreadsheet formats.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "data_extraction",
        "spreadsheet_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChrisPappalardo/eparse",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "excel",
        "data-extraction",
        "parser",
        "python"
      ],
      "id": 17
    },
    {
      "name": "gptpdf",
      "one_line_profile": "PDF parsing tool utilizing GPT models",
      "detailed_description": "A tool that leverages GPT models (like GPT-4o) to parse PDF documents, converting them into structured formats like Markdown, suitable for ingesting scientific literature into RAG systems.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "text_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CosmosShadow/gptpdf",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpt",
        "pdf-parsing",
        "rag",
        "llm"
      ],
      "id": 18
    },
    {
      "name": "pdf_table",
      "one_line_profile": "Unified toolkit for deep learning-based table extraction",
      "detailed_description": "A toolkit that integrates various deep learning models and techniques for extracting tables from PDF documents, aiming to provide a unified interface for table detection and structure recognition.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "deep_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CycloneBoy/pdf_table",
      "help_website": [],
      "license": null,
      "tags": [
        "table-extraction",
        "pdf",
        "deep-learning",
        "toolkit"
      ],
      "id": 19
    },
    {
      "name": "dsRAG",
      "one_line_profile": "High-performance retrieval engine for unstructured data",
      "detailed_description": "A retrieval engine designed for unstructured data, facilitating the creation of RAG (Retrieval-Augmented Generation) pipelines for scientific literature and other document collections.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "information_retrieval",
        "rag"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/D-Star-AI/dsRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "retrieval",
        "unstructured-data",
        "llm"
      ],
      "id": 20
    },
    {
      "name": "PySysML2",
      "one_line_profile": "Python parser for SysML 2.0 textual modeling language",
      "detailed_description": "A Python-based parser for the SysML 2.0 textual modeling language, enabling the transformation of system models into Python objects for analysis and data science applications in systems engineering.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "modeling_language_parsing",
        "systems_engineering"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DAF-Digital-Transformation-Office/PySysML2",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sysml",
        "parser",
        "systems-engineering",
        "modeling"
      ],
      "id": 21
    },
    {
      "name": "DawDreamer",
      "one_line_profile": "Python-based Digital Audio Workstation with JAX support",
      "detailed_description": "A library enabling audio generation and processing in Python, supporting VSTs and JAX for differentiable signal processing, applicable in audio research and machine learning.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "signal_processing",
        "audio_synthesis"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/DBraun/DawDreamer",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "audio-processing",
        "jax",
        "signal-processing",
        "python"
      ],
      "id": 22
    },
    {
      "name": "refchaser",
      "one_line_profile": "Tool for checking reference lists in systematic reviews",
      "detailed_description": "A Python tool designed to assist in systematic reviews and literature reviews by checking reference lists, performing backward/forward searching, and ranking articles by relevance.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "literature_review",
        "citation_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DQ-Zhang/refchaser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "systematic-review",
        "citation-analysis",
        "literature-search"
      ],
      "id": 23
    },
    {
      "name": "DocLayNet",
      "one_line_profile": "Large human-annotated dataset for document layout analysis",
      "detailed_description": "A large-scale, human-annotated dataset for document layout analysis, covering diverse document types to support the training of robust layout recognition models.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "layout_analysis",
        "dataset_creation"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/DS4SD/DocLayNet",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "dataset",
        "document-layout-analysis",
        "computer-vision"
      ],
      "id": 24
    },
    {
      "name": "SemTabNet",
      "one_line_profile": "Code for universal information extraction from tables using LLMs",
      "detailed_description": "Repository containing code for the ACL paper on universal information extraction from tables, leveraging Large Language Models to extract structured data like ESG KPIs.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DS4SD/SemTabNet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "table-extraction",
        "llm",
        "information-extraction",
        "esg"
      ],
      "id": 25
    },
    {
      "name": "MarkPDFdown",
      "one_line_profile": "High-quality PDF to Markdown conversion tool based on LLM visual recognition",
      "detailed_description": "A tool that leverages large language model visual recognition capabilities to convert PDF documents into high-quality Markdown format, preserving layout and structure.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "pdf_to_markdown"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MarkPDFdown/markpdfdown",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf-parser",
        "llm",
        "markdown",
        "ocr"
      ],
      "id": 26
    },
    {
      "name": "Arabic Nougat",
      "one_line_profile": "Fine-tuned Nougat model for Arabic document parsing",
      "detailed_description": "A specialized version of the Nougat model fine-tuned for parsing and extracting text from Arabic PDF documents.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "ocr"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MohamedAliRashad/arabic-nougat",
      "help_website": [],
      "license": null,
      "tags": [
        "arabic",
        "nougat",
        "pdf-parser",
        "ocr"
      ],
      "id": 27
    },
    {
      "name": "nv-ingest",
      "one_line_profile": "Scalable microservice for document content and metadata extraction",
      "detailed_description": "A scalable, performance-oriented microservice by NVIDIA for extracting text, tables, charts, and images from documents, designed for generative AI and RAG workflows.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "data_ingestion",
        "rag"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/nv-ingest",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "document-extraction",
        "rag",
        "nvidia-nim",
        "pdf-parsing"
      ],
      "id": 28
    },
    {
      "name": "docext",
      "one_line_profile": "OCR-free unstructured data extraction and markdown conversion toolkit",
      "detailed_description": "An on-premises toolkit for extracting unstructured data from documents and converting them to markdown without relying on traditional OCR, suitable for benchmarking.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "data_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NanoNets/docext",
      "help_website": [
        "https://idp-leaderboard.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "document-extraction",
        "markdown",
        "pdf-parsing"
      ],
      "id": 29
    },
    {
      "name": "docstrange",
      "one_line_profile": "Intelligent structured data extraction from various document formats",
      "detailed_description": "A tool to extract and convert data from documents (PDFs, images, Word, etc.) into structured formats like Markdown, JSON, and CSV using advanced OCR and extraction techniques.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "structured_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NanoNets/docstrange",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ocr",
        "data-extraction",
        "pdf-to-json",
        "document-processing"
      ],
      "id": 30
    },
    {
      "name": "nougat-latex-ocr",
      "one_line_profile": "Codebase for fine-tuning and evaluating Nougat-based image-to-LaTeX models",
      "detailed_description": "A repository providing tools and code for fine-tuning and evaluating Nougat-based models specifically for converting document images to LaTeX.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "model_training",
        "document_parsing",
        "latex_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NormXU/nougat-latex-ocr",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nougat",
        "latex-ocr",
        "fine-tuning",
        "document-processing"
      ],
      "id": 31
    },
    {
      "name": "General-Documents-Layout-parser",
      "one_line_profile": "Tool for general document layout analysis and parsing",
      "detailed_description": "A Python-based tool for analyzing document layouts and parsing content, with support for Chinese documents.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OKC13/General-Documents-Layout-parser",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "layout-analysis",
        "document-parsing",
        "pdf-parser"
      ],
      "id": 32
    },
    {
      "name": "MegaParse",
      "one_line_profile": "File parser optimized for LLM ingestion without information loss",
      "detailed_description": "A powerful file parsing tool designed to convert PDFs, Docx, and PPTx into formats ideal for Large Language Model (LLM) ingestion, ensuring no data loss.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "data_ingestion",
        "llm_preprocessing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/QuivrHQ/MegaParse",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf-parser",
        "llm",
        "data-ingestion",
        "document-processing"
      ],
      "id": 33
    },
    {
      "name": "RapidLaTeXOCR",
      "one_line_profile": "Efficient formula recognition tool based on LaTeX-OCR and ONNXRuntime",
      "detailed_description": "A tool for recognizing mathematical formulas from images and converting them to LaTeX, optimized for speed using ONNXRuntime.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "formula_recognition",
        "ocr"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RapidAI/RapidLaTeXOCR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "latex-ocr",
        "formula-recognition",
        "onnx"
      ],
      "id": 34
    },
    {
      "name": "Spotlight",
      "one_line_profile": "Interactive exploration and quality control tool for unstructured datasets",
      "detailed_description": "A tool for interactively exploring, visualizing, and curating unstructured datasets (images, audio, text) directly from dataframes, useful for scientific data quality control.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "data_visualization",
        "quality_control",
        "data_exploration"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/Renumics/spotlight",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-visualization",
        "unstructured-data",
        "quality-control",
        "eda"
      ],
      "id": 35
    },
    {
      "name": "MarkEverythingDown",
      "one_line_profile": "Multimodal LLM-based tool to convert various files to Markdown",
      "detailed_description": "A tool that uses multimodal Large Language Models to convert a wide range of file formats (PDF, images, Word, Excel, etc.) into Markdown.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "multimodal_conversion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RoffyS/MarkEverythingDown",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-to-markdown",
        "multimodal-llm",
        "document-conversion"
      ],
      "id": 36
    },
    {
      "name": "SCOREC core",
      "one_line_profile": "Parallel finite element unstructured mesh management library",
      "detailed_description": "A library for managing parallel finite element unstructured meshes, supporting adaptive mesh refinement and load balancing for scientific simulations.",
      "domains": [
        "Physics",
        "Engineering"
      ],
      "subtask_category": [
        "mesh_generation",
        "finite_element_method"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/SCOREC/core",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "fem",
        "mesh-generation",
        "parallel-computing"
      ],
      "id": 37
    },
    {
      "name": "ThermoParser",
      "one_line_profile": "Data analysis and visualization tool for thermoelectrics",
      "detailed_description": "A tool designed to streamline data analysis and visualization for thermoelectrics and charge carrier transport in computational materials science.",
      "domains": [
        "Materials Science"
      ],
      "subtask_category": [
        "data_analysis",
        "visualization",
        "thermoelectrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SMTG-Bham/ThermoParser",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "materials-science",
        "thermoelectrics",
        "data-analysis"
      ],
      "id": 38
    },
    {
      "name": "SPECFEM3D Cartesian",
      "one_line_profile": "Seismic wave propagation simulator",
      "detailed_description": "A software package that simulates acoustic, elastic, coupled acoustic/elastic, or poroelastic seismic wave propagation in any type of conforming mesh of hexahedra.",
      "domains": [
        "Geophysics",
        "Seismology"
      ],
      "subtask_category": [
        "simulation",
        "wave_propagation"
      ],
      "application_level": "solver",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/SPECFEM/specfem3d",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "seismology",
        "wave-propagation",
        "simulation",
        "fem"
      ],
      "id": 39
    },
    {
      "name": "Table-Detection-using-Deep-learning",
      "one_line_profile": "Deep learning based table detection and extraction using Tensorflow and Luminoth",
      "detailed_description": "A deep learning implementation for detecting and extracting tabular data from documents, utilizing the Luminoth toolkit and Tensorflow.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "document_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Sargunan/Table-Detection-using-Deep-learning",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "table-detection",
        "deep-learning",
        "pdf-parsing"
      ],
      "id": 40
    },
    {
      "name": "VirtualMarker",
      "one_line_profile": "3D Human Mesh Estimation from Virtual Markers",
      "detailed_description": "Official PyTorch implementation of the CVPR 2023 paper for estimating 3D human meshes using virtual markers, serving as a scientific inference tool in computer vision.",
      "domains": [
        "Computer Vision",
        "Scientific Modeling"
      ],
      "subtask_category": [
        "human_mesh_estimation",
        "3d_reconstruction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ShirleyMaxx/VirtualMarker",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "cvpr",
        "3d-human-mesh",
        "pytorch"
      ],
      "id": 41
    },
    {
      "name": "Tabular-LLM",
      "one_line_profile": "Datasets and fine-tuning scripts for Table-related LLM tasks",
      "detailed_description": "A project collecting tabular intelligence datasets and providing instruction fine-tuning formats to enhance Large Language Models' understanding of tabular data.",
      "domains": [
        "G1",
        "Scientific Data Processing"
      ],
      "subtask_category": [
        "table_understanding",
        "llm_finetuning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/SpursGoZmy/Tabular-LLM",
      "help_website": [],
      "license": null,
      "tags": [
        "tabular-data",
        "llm",
        "fine-tuning"
      ],
      "id": 42
    },
    {
      "name": "Merlin",
      "one_line_profile": "3D Vision Language Model for Computed Tomography",
      "detailed_description": "A 3D VLM leveraging structured EHR and unstructured radiology reports for pretraining on CT scans, serving medical imaging research.",
      "domains": [
        "Medical AI",
        "Scientific Modeling"
      ],
      "subtask_category": [
        "medical_imaging",
        "vlm"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/StanfordMIMI/Merlin",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ct-scan",
        "medical-ai",
        "vision-language-model"
      ],
      "id": 43
    },
    {
      "name": "table-transformer",
      "one_line_profile": "Table extraction tool combining OCR and Computer Vision",
      "detailed_description": "An open-source solution for extracting structured tabular data from images using OCR and computer vision techniques, suitable for LLM preprocessing.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "ocr"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Sudhanshu1304/table-transformer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "table-extraction",
        "ocr",
        "computer-vision"
      ],
      "id": 44
    },
    {
      "name": "Extractable",
      "one_line_profile": "Library for table extraction from documents",
      "detailed_description": "A library designed to extract tabular data from documents, facilitating data mining and analysis workflows.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/SuleyNL/Extractable",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "table-extraction",
        "pdf-mining"
      ],
      "id": 45
    },
    {
      "name": "TrialAndErrorOrg-parsers",
      "one_line_profile": "Suite of unified-compatible converters for scientific documents",
      "detailed_description": "A monorepo containing converters for transforming between formats like .docx, JATS XML, LaTeX, and PDF, specifically targeting scientific publishing workflows.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_conversion",
        "jats_parsing"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/TrialAndErrorOrg/parsers",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "jats-xml",
        "latex",
        "pdf-conversion"
      ],
      "id": 46
    },
    {
      "name": "PagePlus",
      "one_line_profile": "PAGE XML processing script for document layout analysis",
      "detailed_description": "A tool from UB Mannheim for processing PAGE XML files, performing validation, repair, and modification of text regions for OCR and layout analysis.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "layout_analysis",
        "ocr_postprocessing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/UB-Mannheim/PagePlus",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "page-xml",
        "ocr",
        "layout-analysis"
      ],
      "id": 47
    },
    {
      "name": "science_parse_py_api",
      "one_line_profile": "Python API wrapper for Science Parse",
      "detailed_description": "A Python interface for the Science Parse tool, developed by UCREL, facilitating the extraction of metadata and content from scientific PDFs.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "metadata_extraction"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/UCREL/science_parse_py_api",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "science-parse",
        "pdf-extraction"
      ],
      "id": 48
    },
    {
      "name": "uxarray",
      "one_line_profile": "Xarray extension for unstructured climate data analysis",
      "detailed_description": "A Python package extending Xarray to support unstructured grid data, specifically designed for climate and global weather data analysis and visualization.",
      "domains": [
        "Climate Science",
        "Scientific Data Analysis"
      ],
      "subtask_category": [
        "data_analysis",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/UXARRAY/uxarray",
      "help_website": [
        "https://uxarray.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "climate-data",
        "unstructured-grids",
        "xarray"
      ],
      "id": 49
    },
    {
      "name": "fiducials",
      "one_line_profile": "Simultaneous localization and mapping using fiducial markers",
      "detailed_description": "A system for robot localization and mapping using fiducial markers, applicable in robotics research and scientific instrumentation tracking.",
      "domains": [
        "Robotics",
        "Scientific Inference"
      ],
      "subtask_category": [
        "slam",
        "localization"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/UbiquityRobotics/fiducials",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "slam",
        "robotics",
        "fiducial-markers"
      ],
      "id": 50
    },
    {
      "name": "unstructured",
      "one_line_profile": "ETL solution for transforming unstructured documents into structured data",
      "detailed_description": "A comprehensive library for ingesting and processing unstructured documents (PDFs, HTML, etc.) to prepare them for Large Language Models and scientific data mining.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "etl"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/Unstructured-IO/unstructured",
      "help_website": [
        "https://unstructured.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "etl",
        "pdf-parsing",
        "llm-preprocessing"
      ],
      "id": 51
    },
    {
      "name": "texify",
      "one_line_profile": "Math OCR model converting images to LaTeX and Markdown",
      "detailed_description": "A deep learning model designed to recognize mathematical equations and text in images and convert them into LaTeX or Markdown format.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "ocr",
        "latex_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/VikParuchuri/texify",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "math-ocr",
        "latex",
        "deep-learning"
      ],
      "id": 52
    },
    {
      "name": "pdftabextract",
      "one_line_profile": "Tools for extracting tables from PDF files",
      "detailed_description": "A set of tools developed by WZB Social Science Center for mining data from tables in scanned or OCR-processed PDF documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "data_mining"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/WZBSocialScienceCenter/pdftabextract",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf-mining",
        "table-extraction",
        "ocr-postprocessing"
      ],
      "id": 53
    },
    {
      "name": "HE2LaTeX",
      "one_line_profile": "Converting handwritten equations to LaTeX",
      "detailed_description": "A tool for recognizing handwritten mathematical equations and converting them into LaTeX code, facilitating digitization of scientific notes.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "ocr",
        "handwriting_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Wikunia/HE2LaTeX",
      "help_website": [],
      "license": null,
      "tags": [
        "handwriting-recognition",
        "latex",
        "math-ocr"
      ],
      "id": 54
    },
    {
      "name": "Document-Layout-Analysis",
      "one_line_profile": "Tools for extracting figures, tables, and text from PDFs",
      "detailed_description": "A collection of tools for analyzing document layout and extracting structural elements like figures and tables from PDF documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "layout_analysis",
        "extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Wild-Rift/Document-Layout-Analysis",
      "help_website": [],
      "license": null,
      "tags": [
        "pdf-extraction",
        "layout-analysis"
      ],
      "id": 55
    },
    {
      "name": "GEM",
      "one_line_profile": "Online Globally consistent dense elevation mapping",
      "detailed_description": "A system for generating globally consistent dense elevation maps for unstructured terrain, used in robotics and terrain analysis.",
      "domains": [
        "Robotics",
        "Scientific Mapping"
      ],
      "subtask_category": [
        "mapping",
        "terrain_analysis"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ZJU-Robotics-Lab/GEM",
      "help_website": [],
      "license": null,
      "tags": [
        "elevation-mapping",
        "robotics",
        "slam"
      ],
      "id": 56
    },
    {
      "name": "Citr",
      "one_line_profile": "Library for parsing citations between Markdown and CSL JSON",
      "detailed_description": "A library from the Zettlr ecosystem for parsing and converting citation data between Markdown and CSL JSON formats, supporting scientific writing workflows.",
      "domains": [
        "G1",
        "Citation Analysis"
      ],
      "subtask_category": [
        "citation_parsing",
        "reference_management"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/Zettlr/Citr",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "citation-parsing",
        "csl-json",
        "markdown"
      ],
      "id": 57
    },
    {
      "name": "unstract",
      "one_line_profile": "Platform to structure unstructured documents via LLM pipelines",
      "detailed_description": "A platform for building ETL pipelines that use Large Language Models to extract structured data from unstructured documents, suitable for scientific knowledge base construction.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "etl",
        "document_structuring"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zipstack/unstract",
      "help_website": [
        "https://unstract.com"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "llm-etl",
        "unstructured-data",
        "pipeline"
      ],
      "id": 58
    },
    {
      "name": "TableExtraction",
      "one_line_profile": "Line-based framework for tabular data extraction",
      "detailed_description": "A framework using computer vision and Tesseract OCR to detect and extract tabular data from raster images into JSON format.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "ocr"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/abdullahibneat/TableExtraction",
      "help_website": [],
      "license": null,
      "tags": [
        "table-detection",
        "ocr",
        "computer-vision"
      ],
      "id": 59
    },
    {
      "name": "marker-api",
      "one_line_profile": "API wrapper for the Marker PDF-to-Markdown conversion engine",
      "detailed_description": "A deployable API service that wraps the Marker library to convert PDF documents into markdown format with high accuracy, facilitating the integration of PDF parsing capabilities into other applications.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "format_conversion"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/adithya-s-k/marker-api",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pdf-to-markdown",
        "api",
        "document-parsing"
      ],
      "id": 60
    },
    {
      "name": "npm-pdfreader",
      "one_line_profile": "Node.js library for parsing text and tables from PDFs",
      "detailed_description": "A JavaScript library designed to parse text and tabular data from PDF files, enabling automated extraction of content for further processing in web-based or Node.js environments.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "text_extraction"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/adrienjoly/npm-pdfreader",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-parser",
        "nodejs",
        "table-extraction"
      ],
      "id": 61
    },
    {
      "name": "PDFs-TextExtract",
      "one_line_profile": "Tool for bulk text extraction from large PDF collections",
      "detailed_description": "A Python-based utility designed to handle the extraction of text from multiple and large PDF documents, suitable for building corpora from scientific literature or technical reports.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "text_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ahmedkhemiri95/PDFs-TextExtract",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf",
        "text-mining",
        "bulk-processing"
      ],
      "id": 62
    },
    {
      "name": "CCTag",
      "one_line_profile": "Fiducial marker detection library for computer vision",
      "detailed_description": "A library for the detection of CCTag markers (concentric circles), widely used in photogrammetry, computer vision, and augmented reality for precise tracking and measurement.",
      "domains": [
        "Computer Vision",
        "Photogrammetry"
      ],
      "subtask_category": [
        "marker_detection",
        "image_processing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/alicevision/CCTag",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "computer-vision",
        "fiducial-markers",
        "photogrammetry"
      ],
      "id": 63
    },
    {
      "name": "science-parse",
      "one_line_profile": "Scientific paper parser converting PDFs to structured JSON",
      "detailed_description": "A Java-based tool developed by AllenAI to parse scientific papers in PDF format and extract structured information such as titles, authors, abstracts, and references into JSON format.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "metadata_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/allenai/science-parse",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf-parsing",
        "scientific-literature",
        "allenai"
      ],
      "id": 64
    },
    {
      "name": "spv2",
      "one_line_profile": "Version 2 of the Science Parse tool for PDF extraction",
      "detailed_description": "The second iteration of AllenAI's Science Parse, designed to improve the extraction of structured data from scientific PDF documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "metadata_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/spv2",
      "help_website": [],
      "license": null,
      "tags": [
        "pdf-parsing",
        "scientific-literature",
        "allenai"
      ],
      "id": 65
    },
    {
      "name": "TexSoup",
      "one_line_profile": "Fault-tolerant Python library for parsing and navigating LaTeX",
      "detailed_description": "A Python library that provides a Beautiful Soup-like interface for searching, navigating, and modifying LaTeX documents, enabling programmatic analysis of LaTeX source code.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "latex_parsing",
        "structure_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/alvinwan/TexSoup",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "latex",
        "parser",
        "python"
      ],
      "id": 66
    },
    {
      "name": "tex2py",
      "one_line_profile": "Converter for LaTeX to Python parse trees",
      "detailed_description": "A utility that converts LaTeX documents into a Python parse tree, allowing for hierarchical navigation and analysis of the document structure.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "latex_parsing",
        "structure_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/alvinwan/tex2py",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "latex",
        "parse-tree",
        "python"
      ],
      "id": 67
    },
    {
      "name": "rosgpt",
      "one_line_profile": "Interface connecting ChatGPT with ROS for robot control",
      "detailed_description": "A framework that integrates Large Language Models (like ChatGPT) with the Robot Operating System (ROS), enabling the translation of unstructured natural language commands into actionable robotic instructions.",
      "domains": [
        "Robotics",
        "AI4S"
      ],
      "subtask_category": [
        "robot_control",
        "human_robot_interaction"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/aniskoubaa/rosgpt",
      "help_website": [],
      "license": null,
      "tags": [
        "ros",
        "llm",
        "robotics"
      ],
      "id": 68
    },
    {
      "name": "ioc_parser",
      "one_line_profile": "Extractor for Indicators of Compromise from security PDFs",
      "detailed_description": "A specialized tool for extracting technical indicators of compromise (IOCs) from security reports in PDF format, useful for cybersecurity research and threat intelligence analysis.",
      "domains": [
        "Cybersecurity",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/armbues/ioc_parser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "security",
        "pdf-extraction",
        "ioc"
      ],
      "id": 69
    },
    {
      "name": "Table-Detection-Extraction",
      "one_line_profile": "Tool for detecting and extracting tables from forms",
      "detailed_description": "A Python-based tool designed to detect table structures within document forms and extract both the table boundaries and the cell contents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "layout_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/arnavdutta/Table-Detection-Extraction",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "table-detection",
        "ocr",
        "document-processing"
      ],
      "id": 70
    },
    {
      "name": "ocr-llm",
      "one_line_profile": "LLM-powered OCR for structured text extraction",
      "detailed_description": "A tool leveraging vision-language models to perform high-accuracy text extraction from images and PDFs, outputting structured markdown, suitable for handling complex document layouts.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "ocr",
        "pdf_parsing"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/arshad-yaseen/ocr-llm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "ocr",
        "markdown-extraction"
      ],
      "id": 71
    },
    {
      "name": "artoolkitx",
      "one_line_profile": "SDK for augmented reality tracking and video acquisition",
      "detailed_description": "A high-performance Software Development Kit (SDK) for augmented reality, providing capabilities for video acquisition, marker tracking, and texture tracking across multiple platforms.",
      "domains": [
        "Computer Vision",
        "Augmented Reality"
      ],
      "subtask_category": [
        "tracking",
        "image_processing"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/artoolkitx/artoolkitx",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ar",
        "tracking",
        "sdk"
      ],
      "id": 72
    },
    {
      "name": "Sycamore",
      "one_line_profile": "LLM-powered search and analytics platform for unstructured data",
      "detailed_description": "A platform designed to process unstructured data (such as PDFs and documents) using Large Language Models, enabling search, analytics, and information extraction workflows for scientific and technical documentation.",
      "domains": [
        "G1",
        "G1-01",
        "Data Science"
      ],
      "subtask_category": [
        "document_processing",
        "information_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/aryn-ai/sycamore",
      "help_website": [
        "https://sycamore.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "etl",
        "unstructured-data"
      ],
      "id": 73
    },
    {
      "name": "MERMaid",
      "one_line_profile": "Multimodal tool for mining chemical reactions from PDFs",
      "detailed_description": "A specialized tool developed by the Aspuru-Guzik group for extracting chemical reaction data from scientific PDF documents using multimodal analysis techniques.",
      "domains": [
        "Chemistry",
        "G1-01"
      ],
      "subtask_category": [
        "reaction_mining",
        "pdf_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aspuru-guzik-group/MERMaid",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chemistry",
        "text-mining",
        "multimodal"
      ],
      "id": 74
    },
    {
      "name": "Camelot",
      "one_line_profile": "Python library for extracting tables from PDFs",
      "detailed_description": "A popular Python library specifically designed to extract tabular data from PDF files with high precision, offering fine-grained control over table detection parameters.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "pdf_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/atlanhq/camelot",
      "help_website": [
        "https://camelot-py.readthedocs.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "pdf",
        "table-extraction",
        "python"
      ],
      "id": 75
    },
    {
      "name": "latex2sympy",
      "one_line_profile": "Parser converting LaTeX math to SymPy expressions",
      "detailed_description": "A Python tool that parses LaTeX mathematical expressions and converts them into SymPy objects, facilitating symbolic mathematics and analysis from LaTeX sources.",
      "domains": [
        "Mathematics",
        "G1-01"
      ],
      "subtask_category": [
        "formula_parsing",
        "symbolic_math"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/augustt198/latex2sympy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "latex",
        "sympy",
        "math-parsing"
      ],
      "id": 76
    },
    {
      "name": "Parsr",
      "one_line_profile": "Document processing tool for extracting structured data from PDFs",
      "detailed_description": "A toolchain that transforms PDF documents and images into enriched structured data (JSON, Markdown, Text), handling hierarchy, paragraphs, and tables.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "layout_analysis"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/axa-group/Parsr",
      "help_website": [
        "https://parsr.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "pdf-parsing",
        "ocr",
        "document-structure"
      ],
      "id": 77
    },
    {
      "name": "schema-to-json",
      "one_line_profile": "Schema-driven information extraction from heterogeneous tables",
      "detailed_description": "Implementation of the EMNLP 2024 Findings paper for extracting structured information from diverse table formats based on a defined schema.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bflashcp3f/schema-to-json",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "nlp",
        "table-extraction",
        "emnlp"
      ],
      "id": 78
    },
    {
      "name": "geovista",
      "one_line_profile": "Cartographic rendering and mesh analytics library",
      "detailed_description": "A Python library powered by PyVista for cartographic rendering and mesh analytics, enabling the visualization and analysis of geospatial scientific data.",
      "domains": [
        "Earth Science",
        "Visualization"
      ],
      "subtask_category": [
        "visualization",
        "geospatial_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bjlittle/geovista",
      "help_website": [
        "https://geovista.readthedocs.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "geospatial",
        "visualization",
        "mesh-analytics"
      ],
      "id": 79
    },
    {
      "name": "dependency2tree",
      "one_line_profile": "Converter for dependency parser output to tree visualizations",
      "detailed_description": "A tool to convert CoNLL output from dependency parsers into LaTeX or Graphviz tree visualizations, aiding in the analysis of linguistic structures.",
      "domains": [
        "NLP",
        "Linguistics"
      ],
      "subtask_category": [
        "visualization",
        "syntax_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/boberle/dependency2tree",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "nlp",
        "dependency-parsing",
        "visualization"
      ],
      "id": 80
    },
    {
      "name": "Contextualise",
      "one_line_profile": "Knowledge management tool for organizing unstructured information",
      "detailed_description": "A tool for organizing information-heavy projects using topic maps, suitable for managing unstructured scientific data and building knowledge graphs.",
      "domains": [
        "Knowledge Management",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "information_organization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/brettkromkamp/contextualise",
      "help_website": [
        "https://contextualise.dev"
      ],
      "license": "MIT",
      "tags": [
        "topic-maps",
        "knowledge-graph",
        "unstructured-data"
      ],
      "id": 81
    },
    {
      "name": "table-parser-opencv",
      "one_line_profile": "Table extraction from images and PDFs using OpenCV",
      "detailed_description": "A shell/Python utility that uses OpenCV to detect and extract tables from images or PDF documents, converting them into Excel format.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "image_processing"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/brian-yang/table-parser-opencv",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "opencv",
        "table-extraction",
        "pdf"
      ],
      "id": 82
    },
    {
      "name": "CDLA",
      "one_line_profile": "Chinese Document Layout Analysis Dataset",
      "detailed_description": "A large-scale dataset specifically designed for Chinese document layout analysis, supporting the training and evaluation of document parsing models.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "layout_analysis",
        "dataset"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/buptlihang/CDLA",
      "help_website": [],
      "license": null,
      "tags": [
        "dataset",
        "layout-analysis",
        "document-parsing"
      ],
      "id": 83
    },
    {
      "name": "Dolphin",
      "one_line_profile": "Document image parsing model via heterogeneous anchor prompting",
      "detailed_description": "The official implementation of the Dolphin model (ACL 2025), designed for document image parsing using heterogeneous anchor prompting techniques.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "layout_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bytedance/Dolphin",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "document-parsing",
        "deep-learning",
        "acl-2025"
      ],
      "id": 84
    },
    {
      "name": "bibtex-js",
      "one_line_profile": "JavaScript library for parsing BibTeX files",
      "detailed_description": "A TypeScript library for parsing BibTeX formatted citation files, enabling the integration of bibliographic data into web-based scientific applications.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "citation_parsing",
        "bibliography_management"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/cacfd3a/bibtex-js",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bibtex",
        "parser",
        "typescript"
      ],
      "id": 85
    },
    {
      "name": "Caradoc",
      "one_line_profile": "A PDF parser and validator written in OCaml",
      "detailed_description": "Caradoc is a PDF parser and validator that allows users to inspect the internal structure of PDF files, validate them against the PDF standard, and extract information. It is useful for ensuring the integrity of scientific documents and analyzing their structure.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "document_validation"
      ],
      "application_level": "solver",
      "primary_language": "OCaml",
      "repo_url": "https://github.com/caradoc-org/caradoc",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "pdf-parser",
        "validation",
        "ocaml"
      ],
      "id": 86
    },
    {
      "name": "pulldown-latex",
      "one_line_profile": "A pull parser for LaTeX parsing and MathML rendering",
      "detailed_description": "A Rust-based pull parser designed to process LaTeX syntax, specifically useful for parsing mathematical expressions and converting them to MathML. This supports the extraction and rendering of mathematical content from scientific LaTeX documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "latex_parsing",
        "mathml_rendering"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/carloskiki/pulldown-latex",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "latex",
        "parser",
        "mathml",
        "rust"
      ],
      "id": 87
    },
    {
      "name": "Docuglean OCR",
      "one_line_profile": "Intelligent document processing to extract structured data",
      "detailed_description": "An intelligent document processing tool that uses AI to extract structured data (JSON, Markdown, HTML) from documents. It integrates OCR capabilities to handle scanned scientific documents and convert them into machine-readable formats.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "ocr",
        "document_parsing",
        "structured_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/cernis-intelligence/docuglean-ocr",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ocr",
        "document-processing",
        "pdf-to-json"
      ],
      "id": 88
    },
    {
      "name": "nom-bibtex",
      "one_line_profile": "A feature-complete BibTeX parser using nom",
      "detailed_description": "A Rust library for parsing BibTeX files, which are standard for bibliography management in scientific writing. It enables the extraction and manipulation of citation data from BibTeX databases.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "citation_parsing",
        "bibliography_management"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/charlesvdv/nom-bibtex",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bibtex",
        "parser",
        "rust",
        "citation"
      ],
      "id": 89
    },
    {
      "name": "ParseStudio",
      "one_line_profile": "Python package to parse PDFs with different parsers",
      "detailed_description": "A Python package that provides a unified interface to parse PDF documents using various underlying parsers. It facilitates the extraction of text and metadata from scientific PDFs for downstream analysis.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "text_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chatclimate-ai/ParseStudio",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-parser",
        "python",
        "document-analysis"
      ],
      "id": 90
    },
    {
      "name": "OCRFlux",
      "one_line_profile": "Multimodal toolkit for PDF-to-Markdown conversion and layout analysis",
      "detailed_description": "A lightweight yet powerful multimodal toolkit designed for PDF-to-Markdown conversion. It excels in handling complex layouts, parsing complicated tables, and merging cross-page content, making it highly suitable for processing scientific papers.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "ocr",
        "layout_analysis",
        "table_extraction",
        "pdf_to_markdown"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chatdoc-com/OCRFlux",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ocr",
        "pdf-parsing",
        "layout-analysis",
        "markdown"
      ],
      "id": 91
    },
    {
      "name": "tabula-py",
      "one_line_profile": "Simple wrapper of tabula-java to extract tables from PDF into pandas DataFrame",
      "detailed_description": "A Python wrapper for tabula-java that enables the extraction of tables from PDF files directly into pandas DataFrames. This is a critical tool for extracting structured data from scientific reports and papers.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "pdf_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chezou/tabula-py",
      "help_website": [
        "https://tabula-py.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "pdf",
        "table-extraction",
        "pandas",
        "data-mining"
      ],
      "id": 92
    },
    {
      "name": "Blob Service",
      "one_line_profile": "Out-of-the-box file parsing service supporting Text/PDF/Docx/OCR",
      "detailed_description": "A comprehensive file parsing service that supports various formats including PDF, Docx, and images. It includes OCR capabilities and supports multiple storage backends, suitable for building pipelines to process scientific documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "ocr",
        "file_processing"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/coaidev/blob-service",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "parsing",
        "ocr",
        "pdf",
        "service"
      ],
      "id": 93
    },
    {
      "name": "gmft",
      "one_line_profile": "Lightweight, performant, deep table extraction from PDFs",
      "detailed_description": "A specialized tool for extracting tables from PDFs using deep learning methods. It is designed to be lightweight and performant, making it suitable for extracting data from scientific literature.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "pdf_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/conjuncts/gmft",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "table-extraction",
        "pdf",
        "deep-learning"
      ],
      "id": 94
    },
    {
      "name": "ocr-table",
      "one_line_profile": "Extract tables from scanned image PDFs using OCR",
      "detailed_description": "A tool designed to extract tabular data from scanned PDF documents using Optical Character Recognition (OCR). This is particularly useful for digitizing legacy scientific data stored in scanned papers.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "ocr",
        "pdf_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cseas/ocr-table",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ocr",
        "table-extraction",
        "scanned-pdf"
      ],
      "id": 95
    },
    {
      "name": "marker",
      "one_line_profile": "Convert PDF to markdown + JSON quickly with high accuracy",
      "detailed_description": "A high-performance tool for converting PDF documents into Markdown and JSON formats. It uses deep learning models to handle layout analysis, formula recognition, and table extraction, making it a state-of-the-art tool for parsing scientific papers.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_to_markdown",
        "layout_analysis",
        "formula_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/datalab-to/marker",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pdf-parsing",
        "markdown",
        "deep-learning",
        "layout-analysis"
      ],
      "id": 96
    },
    {
      "name": "pdftext",
      "one_line_profile": "Extract structured text from PDFs quickly",
      "detailed_description": "A fast and efficient library for extracting structured text from PDF files. It focuses on performance and clean text extraction, suitable for processing large corpora of scientific documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "text_extraction",
        "pdf_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/datalab-to/pdftext",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf",
        "text-extraction",
        "python"
      ],
      "id": 97
    },
    {
      "name": "probablepeople",
      "one_line_profile": "Library for parsing unstructured western names into name components",
      "detailed_description": "A Python library using conditional random fields to parse unstructured name strings into structured components. In scientific literature analysis, it is essential for cleaning and normalizing author names in citation networks.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "name_parsing",
        "metadata_cleaning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/datamade/probablepeople",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "name-parsing",
        "citation-analysis"
      ],
      "id": 98
    },
    {
      "name": "usaddress",
      "one_line_profile": "Library for parsing unstructured US address strings",
      "detailed_description": "A Python library for parsing unstructured address strings into address components. It is widely used in bibliometrics and scientific knowledge graph construction to parse and normalize author affiliations and institutional addresses.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "address_parsing",
        "metadata_cleaning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/datamade/usaddress",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "address-parsing",
        "affiliation-normalization"
      ],
      "id": 99
    },
    {
      "name": "tex-math-parser",
      "one_line_profile": "Parser to evaluate TeX math and convert it into a MathJS expression tree",
      "detailed_description": "A TypeScript library that parses TeX mathematical expressions and converts them into a structured expression tree (MathJS). This is useful for semantic analysis of mathematical content in scientific documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "math_parsing",
        "latex_parsing",
        "semantic_analysis"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/davidtranhq/tex-math-parser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "latex",
        "math-parser",
        "typescript"
      ],
      "id": 100
    },
    {
      "name": "deepdoctection",
      "one_line_profile": "A comprehensive Document AI package for layout analysis and extraction",
      "detailed_description": "A robust document AI package that orchestrates OCR, layout analysis, and table extraction pipelines. It is designed to extract structured information from complex documents like scientific papers and technical reports.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "layout_analysis",
        "table_extraction",
        "document_ai",
        "ocr"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepdoctection/deepdoctection",
      "help_website": [
        "https://deepdoctection.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "document-ai",
        "layout-analysis",
        "pdf-extraction",
        "deep-learning"
      ],
      "id": 101
    },
    {
      "name": "pdfsyntax",
      "one_line_profile": "Library to inspect and modify the internal structure of a PDF file",
      "detailed_description": "A lightweight Python library for inspecting and modifying the low-level internal structure of PDF files. It is useful for deep analysis of PDF composition and debugging extraction issues in scientific document processing.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_structure_analysis",
        "low_level_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/desgeeko/pdfsyntax",
      "help_website": [
        "https://pdfsyntax.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "pdf",
        "structure-analysis",
        "python"
      ],
      "id": 102
    },
    {
      "name": "PyScholar",
      "one_line_profile": "A supervised parser for Google Scholar search results",
      "detailed_description": "A Python library designed to parse Google Scholar search results, enabling the programmatic retrieval of bibliographic data and citation metrics for scientific literature analysis.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "literature_retrieval",
        "citation_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dnlcrl/PyScholar",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "google-scholar",
        "parser",
        "bibliometrics"
      ],
      "id": 103
    },
    {
      "name": "DocBank",
      "one_line_profile": "Benchmark dataset for document layout analysis",
      "detailed_description": "A large-scale dataset constructed for document layout analysis, providing fine-grained token-level annotations for reading order and layout elements, essential for training AI models to parse scientific documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "layout_analysis",
        "model_training"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/doc-analysis/DocBank",
      "help_website": [
        "https://github.com/doc-analysis/DocBank"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dataset",
        "layout-analysis",
        "document-understanding"
      ],
      "id": 104
    },
    {
      "name": "pdfminer-layout-scanner",
      "one_line_profile": "Advanced layout scanning tool based on PDFMiner",
      "detailed_description": "A tool that extends PDFMiner to provide enhanced layout analysis and text extraction capabilities, useful for parsing structured information from PDF documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "layout_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dpapathanasiou/pdfminer-layout-scanner",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdfminer",
        "layout-analysis",
        "text-extraction"
      ],
      "id": 105
    },
    {
      "name": "seerai",
      "one_line_profile": "AI assistant plugin for Zotero with OCR and extraction capabilities",
      "detailed_description": "A Zotero plugin that integrates AI capabilities for OCR, table extraction, and semantic search, enhancing the management and analysis of scientific literature within the Zotero ecosystem.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "literature_management",
        "ocr",
        "table_extraction"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/dralkh/seerai",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "zotero-plugin",
        "ocr",
        "literature-review"
      ],
      "id": 106
    },
    {
      "name": "docling-api",
      "one_line_profile": "Backend service for converting documents to Markdown for AI processing",
      "detailed_description": "A scalable backend server designed to convert various document formats (PDF, DOCX, etc.) into Markdown, featuring OCR and table extraction, specifically optimized for feeding documents into Large Language Models (LLMs) for analysis.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_conversion",
        "text_extraction",
        "ocr"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/drmingler/docling-api",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "document-conversion",
        "llm-preprocessing",
        "ocr"
      ],
      "id": 107
    },
    {
      "name": "unit_parse",
      "one_line_profile": "Parser for physical units and numerical values",
      "detailed_description": "A Python tool for parsing and normalizing messy numerical strings and physical units, essential for cleaning and structuring scientific data extracted from text.",
      "domains": [
        "Sci Knowledge",
        "Data Processing"
      ],
      "subtask_category": [
        "data_cleaning",
        "normalization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dylanwal/unit_parse",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "unit-parsing",
        "data-cleaning",
        "scientific-data"
      ],
      "id": 108
    },
    {
      "name": "pdfssa4met",
      "one_line_profile": "PDF structure analysis for metadata extraction",
      "detailed_description": "A tool for PDF Structure and Syntactic Analysis, specifically designed to extract metadata and tag document elements, aiding in the structured parsing of scientific publications.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "metadata_extraction",
        "structure_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/eliask/pdfssa4met",
      "help_website": [
        "https://code.google.com/p/pdfssa4met/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "pdf-parsing",
        "metadata-extraction",
        "structure-analysis"
      ],
      "id": 109
    },
    {
      "name": "sciencebeam-parser",
      "one_line_profile": "Pipeline for converting scientific PDFs to XML",
      "detailed_description": "A set of tools utilizing Apache Beam to convert scientific PDF documents into structured XML (JATS/TEI), facilitating large-scale literature mining and analysis.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_conversion",
        "xml_generation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/elifesciences/sciencebeam-parser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-to-xml",
        "jats",
        "scientific-publishing"
      ],
      "id": 110
    },
    {
      "name": "paper_autotranslation",
      "one_line_profile": "Automatic translation tool for scientific papers",
      "detailed_description": "A tool designed to convert scientific papers from PDF to text and translate them (specifically English to Chinese), aiding in the consumption of foreign language scientific literature.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "translation",
        "pdf_to_text"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/elliotxx/paper_autotranslation",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "translation",
        "scientific-paper",
        "pdf-processing"
      ],
      "id": 111
    },
    {
      "name": "PDFScraper",
      "one_line_profile": "CLI for searching and extracting text/tables from PDFs",
      "detailed_description": "A command-line interface tool for searching text and extracting tables from PDF documents, useful for data mining within scientific reports.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "text_extraction",
        "table_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/erikkastelec/PDFScraper",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-scraping",
        "data-mining",
        "cli"
      ],
      "id": 112
    },
    {
      "name": "pdfminer",
      "one_line_profile": "Python PDF parser for extracting text and information",
      "detailed_description": "A foundational Python library for parsing PDF files, focusing on extracting text, layout information, and metadata, widely used as a building block for scientific document analysis tools.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "text_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/euske/pdfminer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-parser",
        "text-extraction",
        "python"
      ],
      "id": 113
    },
    {
      "name": "tabula-js",
      "one_line_profile": "JavaScript wrapper for Tabula PDF table extractor",
      "detailed_description": "A Node.js wrapper for Tabula-java, enabling the extraction of data tables from PDF files into CSV format, a critical task for recovering data from scientific publications.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "data_recovery"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/ezodude/tabula-js",
      "help_website": [
        "https://github.com/tabulapdf/tabula-java"
      ],
      "license": "MIT",
      "tags": [
        "table-extraction",
        "pdf",
        "csv"
      ],
      "id": 114
    },
    {
      "name": "nougat",
      "one_line_profile": "Neural Optical Understanding for Academic Documents",
      "detailed_description": "A deep learning model and tool by Meta AI for converting scientific PDF documents into structured Markdown, specifically handling mathematical formulas and complex layouts.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_understanding",
        "formula_extraction",
        "ocr"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/nougat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ocr",
        "academic-papers",
        "transformer"
      ],
      "id": 115
    },
    {
      "name": "mathparser",
      "one_line_profile": "Mathematical expression evaluator and parser",
      "detailed_description": "A C++ library for parsing and evaluating mathematical expressions, serving as a utility for scientific computing and modeling tasks.",
      "domains": [
        "Scientific Computing"
      ],
      "subtask_category": [
        "math_parsing",
        "calculation"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/fkkarakurt/mathparser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "math",
        "parser",
        "cpp"
      ],
      "id": 116
    },
    {
      "name": "maltego_academia",
      "one_line_profile": "Maltego transforms for exploring academic literature",
      "detailed_description": "A set of transforms for the Maltego link analysis tool, enabling the exploration and visualization of academic literature networks, citations, and author relationships.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "network_analysis",
        "literature_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/flppgg/maltego_academia",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "maltego",
        "bibliometrics",
        "citation-network"
      ],
      "id": 117
    },
    {
      "name": "tabulator-py",
      "one_line_profile": "Stream-based tabular data reading and writing library",
      "detailed_description": "A Python library for reading and writing tabular data via streams, part of the Frictionless Data ecosystem, widely used for processing and normalizing scientific data tables.",
      "domains": [
        "Data Processing"
      ],
      "subtask_category": [
        "data_io",
        "tabular_data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/frictionlessdata/tabulator-py",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tabular-data",
        "frictionless-data",
        "etl"
      ],
      "id": 118
    },
    {
      "name": "kabeja",
      "one_line_profile": "Java library for parsing and processing DXF format",
      "detailed_description": "A library for parsing, processing, and converting Autodesk's DXF format, enabling the extraction and manipulation of engineering and CAD data for scientific modeling and analysis.",
      "domains": [
        "Engineering",
        "Data Processing"
      ],
      "subtask_category": [
        "cad_parsing",
        "geometry_extraction"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/fuzziness/kabeja",
      "help_website": [],
      "license": null,
      "tags": [
        "dxf",
        "cad",
        "parser"
      ],
      "id": 119
    },
    {
      "name": "COVID-Text-Extractor",
      "one_line_profile": "OCR tool for extracting COVID-19 info from documents",
      "detailed_description": "A specialized OCR tool designed to extract COVID-19 related information from images, PDFs, and text, supporting pandemic-related data collection and analysis.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "text_extraction",
        "ocr",
        "domain_specific_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gagangulyani/COVID-Text-Extractor",
      "help_website": [],
      "license": null,
      "tags": [
        "covid-19",
        "ocr",
        "text-mining"
      ],
      "id": 120
    },
    {
      "name": "pdf-text-extraction",
      "one_line_profile": "CLI for extracting text from PDF files",
      "detailed_description": "A C++ command-line tool specifically designed for extracting text content from PDF files, suitable for high-performance batch processing of scientific documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "text_extraction"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/galkahana/pdf-text-extraction",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf",
        "text-extraction",
        "cli"
      ],
      "id": 121
    },
    {
      "name": "pdfshapeminer",
      "one_line_profile": "PDF text extraction using geometric shape analysis",
      "detailed_description": "A tool that combines PDFMiner with Shapely to perform layout analysis based on geometric shapes, improving text extraction accuracy for complex PDF layouts common in scientific papers.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "layout_analysis",
        "text_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/garabik/pdfshapeminer",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "pdfminer",
        "shapely",
        "layout-analysis"
      ],
      "id": 122
    },
    {
      "name": "parsemypdf",
      "one_line_profile": "Unified interface for various PDF parsing libraries",
      "detailed_description": "A wrapper library that integrates multiple PDF parsing tools (like Docling, PDFMiner, PyMuPDF) and AI models to provide efficient extraction of text, tables, and metadata from documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "extraction_pipeline"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/genieincodebottle/parsemypdf",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-parsing",
        "wrapper",
        "ocr"
      ],
      "id": 123
    },
    {
      "name": "pdf_header_and_footer_detector",
      "one_line_profile": "Detector for PDF headers and footers",
      "detailed_description": "A Python tool using PdfMiner to detect and remove headers and footers from PDF pages, a crucial pre-processing step for cleaning scientific text before analysis.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "data_cleaning",
        "preprocessing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gentrith78/pdf_header_and_footer_detector",
      "help_website": [],
      "license": null,
      "tags": [
        "pdf-cleaning",
        "header-detection",
        "preprocessing"
      ],
      "id": 124
    },
    {
      "name": "pdf-rag-assistant",
      "one_line_profile": "RAG system for Q&A on PDF documents",
      "detailed_description": "A Retrieval-Augmented Generation (RAG) system designed for performing Question & Answer tasks on PDF documents, featuring parsing, chunking, and citation support, useful for interacting with scientific literature.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "rag",
        "question_answering",
        "literature_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/giasinguyen/pdf-rag-assistant",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "pdf-qa",
        "spring-ai"
      ],
      "id": 125
    },
    {
      "name": "langextract",
      "one_line_profile": "LLM-based structured information extraction tool",
      "detailed_description": "A library for extracting structured information from unstructured text using Large Language Models (LLMs), featuring precise source grounding, highly applicable to knowledge extraction from scientific literature.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "information_extraction",
        "llm_application"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google/langextract",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "information-extraction",
        "structured-data"
      ],
      "id": 126
    },
    {
      "name": "Gretel Synthetics",
      "one_line_profile": "Synthetic data generators for structured and unstructured text with differential privacy",
      "detailed_description": "A library for generating synthetic data using recurrent neural networks (LSTMs) and differential privacy mechanisms. It is widely used in scientific research to create privacy-preserving datasets for healthcare, finance, and social sciences, enabling data sharing and model training without compromising sensitive information.",
      "domains": [
        "Scientific Data Generation",
        "Privacy Preserving ML"
      ],
      "subtask_category": [
        "synthetic_data_generation",
        "privacy_protection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gretelai/gretel-synthetics",
      "help_website": [
        "https://gretel.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "synthetic-data",
        "differential-privacy",
        "lstm",
        "nlp"
      ],
      "id": 127
    },
    {
      "name": "pdfminer3",
      "one_line_profile": "Python library for extracting text, information, and layout from PDF documents",
      "detailed_description": "A Python 3 port of the pdfminer library, designed for parsing PDF files. It focuses on extracting textual content, analyzing document layout, and retrieving metadata, which is essential for mining scientific literature and converting unstructured PDF data into structured formats.",
      "domains": [
        "G1-01",
        "Document Parsing"
      ],
      "subtask_category": [
        "pdf_parsing",
        "text_extraction",
        "layout_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gwk/pdfminer3",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-parser",
        "text-extraction",
        "layout-analysis"
      ],
      "id": 128
    },
    {
      "name": "Rowfill",
      "one_line_profile": "AI-powered spreadsheet platform for deep research and document processing",
      "detailed_description": "An open-source spreadsheet interface designed for research tasks, integrating LLMs to process, fill, and analyze tabular data. It facilitates 'deep research' by automating data enrichment and document processing workflows within a familiar spreadsheet environment.",
      "domains": [
        "Scientific Data Analysis",
        "Research Workflow"
      ],
      "subtask_category": [
        "data_enrichment",
        "document_processing",
        "tabular_analysis"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/harishdeivanayagam/rowfill",
      "help_website": [
        "https://rowfill.ai"
      ],
      "license": "NOASSERTION",
      "tags": [
        "spreadsheet",
        "llm",
        "research-automation",
        "data-processing"
      ],
      "id": 129
    },
    {
      "name": "PyTorch Tabular",
      "one_line_profile": "Deep learning library for tabular data modeling and analysis",
      "detailed_description": "A library that makes state-of-the-art deep learning models for tabular data easy to use with PyTorch. It is applicable in scientific domains where data is structured in tables (e.g., bioinformatics, physical measurements) and requires advanced modeling beyond traditional tree-based methods.",
      "domains": [
        "Scientific Modeling",
        "Tabular Data Analysis"
      ],
      "subtask_category": [
        "tabular_modeling",
        "deep_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hcarlens/pytorch-tabular",
      "help_website": [
        "https://pytorch-tabular.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "pytorch",
        "tabular-data",
        "deep-learning",
        "modeling"
      ],
      "id": 130
    },
    {
      "name": "PDF Document Layout Analysis",
      "one_line_profile": "Service for segmenting and classifying PDF document elements",
      "detailed_description": "A Docker-based service that performs layout analysis on PDF documents. It segments pages and classifies elements into text, titles, images, and tables, providing a structural foundation for extracting information from scientific literature and reports.",
      "domains": [
        "G1-01",
        "Document Analysis"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_segmentation"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/huridocs/pdf-document-layout-analysis",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf",
        "layout-analysis",
        "computer-vision",
        "document-structure"
      ],
      "id": 131
    },
    {
      "name": "PDF Text Extraction",
      "one_line_profile": "Tool for extracting text from PDFs based on layout analysis",
      "detailed_description": "A utility that leverages the output of layout analysis tools to extract clean text from PDF files. It is designed to handle complex document structures found in reports and scientific papers, ensuring text is extracted in a logical order.",
      "domains": [
        "G1-01",
        "Text Extraction"
      ],
      "subtask_category": [
        "text_extraction",
        "pdf_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Makefile",
      "repo_url": "https://github.com/huridocs/pdf-text-extraction",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf",
        "text-mining",
        "layout-aware"
      ],
      "id": 132
    },
    {
      "name": "Vision Parse",
      "one_line_profile": "Parse PDFs into markdown using Vision LLMs",
      "detailed_description": "A tool that utilizes Vision-Language Models (VLMs) to visually parse PDF documents and convert them into structured Markdown. This approach is particularly effective for scientific papers containing complex layouts, formulas, and tables that traditional OCR might miss.",
      "domains": [
        "G1-01",
        "Document Parsing"
      ],
      "subtask_category": [
        "pdf_to_markdown",
        "visual_document_understanding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/iamarunbrahma/vision-parse",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-parsing",
        "vision-llm",
        "markdown",
        "ocr"
      ],
      "id": 133
    },
    {
      "name": "AnyStyle",
      "one_line_profile": "Fast and accurate citation reference parser",
      "detailed_description": "A powerful tool for parsing bibliographic references from academic texts. It uses machine learning (Conditional Random Fields) to identify and extract structured metadata (author, title, year, etc.) from raw citation strings, essential for bibliometrics and citation network analysis.",
      "domains": [
        "G1",
        "Bibliometrics"
      ],
      "subtask_category": [
        "citation_parsing",
        "reference_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/inukshuk/anystyle",
      "help_website": [
        "https://anystyle.io"
      ],
      "license": "NOASSERTION",
      "tags": [
        "citation-parser",
        "bibliometrics",
        "crf",
        "ruby"
      ],
      "id": 134
    },
    {
      "name": "Parsing PDFs using YOLOv3",
      "one_line_profile": "Table detection and extraction from PDFs using YOLOv3",
      "detailed_description": "An implementation of table detection in PDF documents using the YOLOv3 object detection model. It addresses the specific challenge of extracting structured tabular data from scientific papers and reports for downstream analysis.",
      "domains": [
        "G1-01",
        "Table Extraction"
      ],
      "subtask_category": [
        "table_detection",
        "pdf_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ismail-mebsout/Parsing-PDFs-using-YOLOV3",
      "help_website": [],
      "license": null,
      "tags": [
        "yolov3",
        "table-extraction",
        "pdf",
        "deep-learning"
      ],
      "id": 135
    },
    {
      "name": "Dedoc",
      "one_line_profile": "Universal document parsing and structure extraction system",
      "detailed_description": "A comprehensive library for automating the parsing of various document formats (PDF, DOCX, HTML, images) into a uniform structure. It extracts logical structure, tables, and metadata, making it a critical tool for ingesting scientific literature and technical documentation into analysis pipelines.",
      "domains": [
        "G1-01",
        "Document Ingestion"
      ],
      "subtask_category": [
        "document_parsing",
        "structure_extraction",
        "format_conversion"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ispras/dedoc",
      "help_website": [
        "https://dedoc.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "document-parsing",
        "ocr",
        "structure-extraction",
        "pdf"
      ],
      "id": 136
    },
    {
      "name": "TableNet Implementation",
      "one_line_profile": "Deep learning model for end-to-end table detection and extraction",
      "detailed_description": "An implementation of the TableNet architecture for detecting and extracting tabular data from scanned document images. This tool is valuable for digitizing historical scientific data and processing papers where tables are preserved only as images.",
      "domains": [
        "G1-01",
        "Table Extraction"
      ],
      "subtask_category": [
        "table_detection",
        "tabular_data_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/jainammm/TableNet",
      "help_website": [],
      "license": null,
      "tags": [
        "tablenet",
        "deep-learning",
        "table-extraction",
        "ocr"
      ],
      "id": 137
    },
    {
      "name": "Citation Map",
      "one_line_profile": "Tool to generate citation graphs from Zotero PDF collections",
      "detailed_description": "A Python tool that analyzes PDFs stored in Zotero to extract citations and generate a network graph file (for Gephi). It enables researchers to visualize and analyze the citation topology of their personal or project-specific literature collections.",
      "domains": [
        "G1",
        "Scientometrics"
      ],
      "subtask_category": [
        "citation_network_analysis",
        "visualization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/jaks6/citation_map",
      "help_website": [],
      "license": null,
      "tags": [
        "zotero",
        "citation-graph",
        "gephi",
        "network-analysis"
      ],
      "id": 138
    },
    {
      "name": "Chinese Layout Analysis",
      "one_line_profile": "YOLOv8-based layout detection for Chinese documents",
      "detailed_description": "A tool utilizing YOLOv8 to perform layout analysis specifically on Chinese document images. It detects regions such as text, headers, and tables, facilitating the digitization and structural analysis of Chinese scientific literature and archives.",
      "domains": [
        "G1-01",
        "Document Analysis"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jiangnanboy/layout_analysis",
      "help_website": [],
      "license": null,
      "tags": [
        "yolov8",
        "layout-analysis",
        "chinese-nlp",
        "ocr"
      ],
      "id": 139
    },
    {
      "name": "Layout Analysis 4J",
      "one_line_profile": "Java implementation of YOLOv8-based layout analysis",
      "detailed_description": "The Java implementation of the Chinese layout analysis tool. It allows integration of document layout detection capabilities into Java-based scientific data processing pipelines.",
      "domains": [
        "G1-01",
        "Document Analysis"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_segmentation"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/jiangnanboy/layout_analysis4j",
      "help_website": [],
      "license": null,
      "tags": [
        "java",
        "yolov8",
        "layout-analysis"
      ],
      "id": 140
    },
    {
      "name": "AutoTabular",
      "one_line_profile": "Automated Machine Learning (AutoML) for tabular data",
      "detailed_description": "An AutoML library designed to automate the processing and modeling of tabular data. It simplifies the pipeline of feature engineering, model selection, and hyperparameter tuning, which is useful for scientific data analysis where tabular datasets are common.",
      "domains": [
        "Scientific Data Analysis",
        "AutoML"
      ],
      "subtask_category": [
        "automl",
        "tabular_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jianzhnie/AutoTabular",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "automl",
        "tabular-data",
        "machine-learning"
      ],
      "id": 141
    },
    {
      "name": "PDF to Markdown",
      "one_line_profile": "Utility to convert PDF files into Markdown format",
      "detailed_description": "A Python tool designed to convert PDF documents into Markdown. This conversion is a critical step in modern scientific literature processing pipelines (e.g., for RAG or LLM ingestion), allowing unstructured PDF content to be treated as structured text.",
      "domains": [
        "G1-01",
        "Document Conversion"
      ],
      "subtask_category": [
        "pdf_parsing",
        "format_conversion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/johnlinp/pdf-to-markdown",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "pdf",
        "markdown",
        "converter",
        "text-extraction"
      ],
      "id": 142
    },
    {
      "name": "GROBID",
      "one_line_profile": "Machine learning library for extracting, parsing, and restructuring raw documents such as PDF into structured XML/TEI.",
      "detailed_description": "GROBID (GeneRation Of BIbliographic Data) is a machine learning library for extracting, parsing and re-structuring raw documents such as PDF into structured XML/TEI encoded documents with a particular focus on technical and scientific publications.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "structure_extraction",
        "citation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/kermitt2/grobid",
      "help_website": [
        "https://grobid.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "pdf-parsing",
        "citation-extraction",
        "scholarly-documents",
        "crf",
        "machine-learning"
      ],
      "id": 143
    },
    {
      "name": "GROBID-astro",
      "one_line_profile": "GROBID extension for identifying and extracting astronomical entities from scientific documents.",
      "detailed_description": "A module for GROBID that specializes in recognizing and extracting astronomical objects, locations, and other domain-specific entities from scholarly articles in the field of astronomy.",
      "domains": [
        "G1",
        "G1-01",
        "Astronomy"
      ],
      "subtask_category": [
        "entity_recognition",
        "domain_specific_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/kermitt2/grobid-astro",
      "help_website": [],
      "license": null,
      "tags": [
        "astronomy",
        "ner",
        "grobid-extension"
      ],
      "id": 144
    },
    {
      "name": "GROBID-NER",
      "one_line_profile": "Named Entity Recognition module for GROBID to extract general and scientific entities.",
      "detailed_description": "A sequence labelling tool for Named Entity Recognition (NER) based on GROBID, designed to extract entities such as persons, locations, organizations, and other scientific entities from text.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "text_mining"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/kermitt2/grobid-ner",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ner",
        "nlp",
        "grobid-extension"
      ],
      "id": 145
    },
    {
      "name": "space_packet_parser",
      "one_line_profile": "Library for decoding CCSDS telemetry packets using XTCE packet definitions.",
      "detailed_description": "A Python library developed by LASP for parsing CCSDS telemetry packets based on the XTCE (XML Telemetric and Command Exchange) standard, widely used in space science missions.",
      "domains": [
        "Space Science",
        "Astrophysics"
      ],
      "subtask_category": [
        "telemetry_decoding",
        "data_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lasp/space_packet_parser",
      "help_website": [
        "https://space-packet-parser.readthedocs.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "ccsds",
        "telemetry",
        "space-science",
        "xtce"
      ],
      "id": 146
    },
    {
      "name": "llmdocparser",
      "one_line_profile": "Pipeline for parsing PDFs and analyzing content using Large Language Models (LLMs).",
      "detailed_description": "A Python package that leverages LLMs (like GPT-4 or local models) to parse PDF documents, extract structured content, and perform analysis, suitable for processing scientific literature.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "content_analysis",
        "llm_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/lazyFrogLOL/llmdocparser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-parsing",
        "llm",
        "rag",
        "document-analysis"
      ],
      "id": 147
    },
    {
      "name": "GROBID-quantities",
      "one_line_profile": "GROBID extension for identifying, parsing, and normalizing physical quantities and measurements.",
      "detailed_description": "A machine learning module for GROBID that extracts physical quantities (values and units) from text and normalizes them, essential for scientific data mining.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "quantity_normalization"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/lfoppiano/grobid-quantities",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantities",
        "measurements",
        "grobid-extension",
        "normalization"
      ],
      "id": 148
    },
    {
      "name": "GROBID-superconductors",
      "one_line_profile": "GROBID module for extracting superconductor materials and their properties from scientific literature.",
      "detailed_description": "A specialized GROBID module designed to mine superconductor material names, critical temperatures (Tc), and other related properties from scientific papers.",
      "domains": [
        "G1",
        "G1-01",
        "Materials Science"
      ],
      "subtask_category": [
        "material_extraction",
        "property_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/lfoppiano/grobid-superconductors",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "superconductors",
        "materials-science",
        "text-mining",
        "grobid-extension"
      ],
      "id": 149
    },
    {
      "name": "material-parsers",
      "one_line_profile": "Collection of parsers and utility scripts for processing material science data.",
      "detailed_description": "A set of Python tools and parsers initially developed for the Grobid Superconductor project, used for processing and structuring material science data extracted from literature.",
      "domains": [
        "Materials Science",
        "G1-01"
      ],
      "subtask_category": [
        "data_parsing",
        "text_mining"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lfoppiano/material-parsers",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "materials-science",
        "parsing",
        "utility"
      ],
      "id": 150
    },
    {
      "name": "structure-vision",
      "one_line_profile": "Visualization tool for inspecting the structured data extracted by GROBID from PDF documents.",
      "detailed_description": "A viewer application designed to visualize the XML/TEI structure extracted by GROBID overlaid on the original PDF, aiding in the validation and debugging of scientific document parsing.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "visualization",
        "quality_control"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/lfoppiano/structure-vision",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "grobid",
        "pdf-structure",
        "quality-control"
      ],
      "id": 151
    },
    {
      "name": "LaTeX-OCR",
      "one_line_profile": "Deep learning model (ViT) to convert images of mathematical equations into LaTeX code.",
      "detailed_description": "A tool using a Vision Transformer (ViT) architecture to recognize mathematical formulas in images and convert them into their corresponding LaTeX representation, facilitating the digitization of scientific documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "optical_character_recognition",
        "formula_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lukas-blecher/LaTeX-OCR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ocr",
        "latex",
        "mathematical-formulas",
        "deep-learning"
      ],
      "id": 152
    },
    {
      "name": "iFEM",
      "one_line_profile": "MATLAB toolbox for adaptive finite element methods (FEM) on unstructured grids.",
      "detailed_description": "A MATLAB software package containing robust and efficient codes for adaptive finite element methods on unstructured simplicial grids in 2D and 3D, used for numerical simulation in physics and engineering.",
      "domains": [
        "Mathematics",
        "Physics"
      ],
      "subtask_category": [
        "finite_element_analysis",
        "simulation"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/lyc102/ifem",
      "help_website": [
        "https://github.com/lyc102/ifem/wiki"
      ],
      "license": "GPL-3.0",
      "tags": [
        "fem",
        "finite-element-method",
        "simulation",
        "matlab"
      ],
      "id": 153
    },
    {
      "name": "mhchemParser",
      "one_line_profile": "Parser for converting mhchem chemical equation syntax to standard LaTeX",
      "detailed_description": "A JavaScript library designed to parse the 'mhchem' LaTeX extension syntax, enabling the rendering of chemical equations and formulas in web environments or downstream LaTeX processors.",
      "domains": [
        "G1",
        "G1-01",
        "Chemistry"
      ],
      "subtask_category": [
        "formula_parsing",
        "latex_rendering"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/mhchem/mhchemParser",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "chemistry",
        "latex",
        "parser",
        "mhchem"
      ],
      "id": 154
    },
    {
      "name": "LaTeX.js",
      "one_line_profile": "JavaScript LaTeX to HTML5 translator",
      "detailed_description": "A JavaScript library that parses LaTeX source code and renders it to HTML5. It enables the structured extraction and display of LaTeX-based scientific documents in web browsers.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "latex_rendering"
      ],
      "application_level": "library",
      "primary_language": "LiveScript",
      "repo_url": "https://github.com/michael-brade/LaTeX.js",
      "help_website": [
        "https://latex.js.org"
      ],
      "license": "MIT",
      "tags": [
        "latex",
        "parser",
        "html5",
        "rendering"
      ],
      "id": 155
    },
    {
      "name": "Document Knowledge Mining Solution Accelerator",
      "one_line_profile": "Azure-based solution for extracting knowledge from unstructured documents",
      "detailed_description": "A solution accelerator that leverages Azure OpenAI and Document Intelligence to ingest, parse, and extract structured metadata, entities, and summaries from unstructured multi-modal documents (PDFs, images).",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "information_extraction",
        "document_summarization",
        "knowledge_mining"
      ],
      "application_level": "workflow",
      "primary_language": "C#",
      "repo_url": "https://github.com/microsoft/Document-Knowledge-Mining-Solution-Accelerator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "azure",
        "openai",
        "document-intelligence",
        "knowledge-mining"
      ],
      "id": 156
    },
    {
      "name": "MarkItDown",
      "one_line_profile": "Converter for transforming office documents and PDFs to Markdown",
      "detailed_description": "A Python tool developed by Microsoft for converting various file formats (PDF, Word, Excel, PowerPoint) into Markdown. It facilitates the ingestion of scientific documents into LLM pipelines or text analysis workflows.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_conversion",
        "layout_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/markitdown",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-to-markdown",
        "document-conversion",
        "nlp",
        "llm-preprocessing"
      ],
      "id": 157
    },
    {
      "name": "Table Transformer (TATR)",
      "one_line_profile": "Deep learning model for table extraction from unstructured documents",
      "detailed_description": "A deep learning model based on the DETR architecture, specifically trained for detecting and extracting tables from PDFs and images. It includes the PubTables-1M dataset and GriTS evaluation metric.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "layout_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/table-transformer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "table-extraction",
        "deep-learning",
        "pdf-parsing",
        "transformer"
      ],
      "id": 158
    },
    {
      "name": "YOLOv10-Document-Layout-Analysis",
      "one_line_profile": "YOLOv10 model fine-tuned for document layout analysis",
      "detailed_description": "A YOLOv10-based object detection model trained on the DocLayNet dataset to segment and classify document layout elements (headers, footers, tables, figures) in scientific and technical documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/moured/YOLOv10-Document-Layout-Analysis",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "yolov10",
        "document-layout-analysis",
        "doclaynet",
        "computer-vision"
      ],
      "id": 159
    },
    {
      "name": "YOLOv11-Document-Layout-Analysis",
      "one_line_profile": "YOLOv11 model fine-tuned for document layout analysis",
      "detailed_description": "An updated YOLOv11-based model trained on the DocLayNet dataset for high-performance document layout analysis, identifying structure in PDFs and images.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/moured/YOLOv11-Document-Layout-Analysis",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "yolov11",
        "document-layout-analysis",
        "doclaynet",
        "computer-vision"
      ],
      "id": 160
    },
    {
      "name": "pdf2md",
      "one_line_profile": "Browser-based PDF to Markdown converter",
      "detailed_description": "A tool to convert PDF documents into Markdown format, facilitating the extraction of text and structure from scientific papers for downstream processing or LLM ingestion.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_conversion",
        "text_extraction"
      ],
      "application_level": "tool",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/mrmps/pdf2md",
      "help_website": [],
      "license": null,
      "tags": [
        "pdf",
        "markdown",
        "converter",
        "text-extraction"
      ],
      "id": 161
    },
    {
      "name": "pdf3md",
      "one_line_profile": "Web application for converting PDFs to formatted Markdown",
      "detailed_description": "A modern web tool designed to convert PDF documents into clean, formatted Markdown text, useful for digitizing and restructuring scientific literature.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_conversion",
        "text_extraction"
      ],
      "application_level": "tool",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/murtaza-nasir/pdf3md",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "pdf",
        "markdown",
        "converter",
        "ocr"
      ],
      "id": 162
    },
    {
      "name": "pretty-formula",
      "one_line_profile": "Java library to parse and render mathematical formulas",
      "detailed_description": "A library that parses mathematical formulas into LaTeX and renders them as images, supporting the visualization of mathematical content in scientific applications.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "formula_parsing",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/mzur/pretty-formula",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "math",
        "latex",
        "formula-rendering",
        "java"
      ],
      "id": 163
    },
    {
      "name": "image_tabular",
      "one_line_profile": "Integration of image and tabular data for deep learning",
      "detailed_description": "A library extending fastai to handle multimodal datasets containing both images and tabular data, facilitating complex scientific data analysis tasks.",
      "domains": [
        "Scientific Data Analysis"
      ],
      "subtask_category": [
        "multimodal_learning",
        "data_integration"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/naity/image_tabular",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deep-learning",
        "multimodal",
        "fastai",
        "tabular-data"
      ],
      "id": 164
    },
    {
      "name": "pyDownlinkParser",
      "one_line_profile": "CCSDS binary downlink parser for space science data",
      "detailed_description": "A NASA-developed Python tool for parsing binary downlink files following CCSDS standards, specifically designed for the Europa-Clipper Science Data System.",
      "domains": [
        "Space Science",
        "Data Processing"
      ],
      "subtask_category": [
        "binary_parsing",
        "telemetry_processing"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/nasa/pyDownlinkParser",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nasa",
        "ccsds",
        "space-science",
        "telemetry"
      ],
      "id": 165
    },
    {
      "name": "llm-graph-builder",
      "one_line_profile": "Knowledge graph construction from unstructured data using LLMs",
      "detailed_description": "A tool by Neo4j Labs that uses Large Language Models to extract entities and relationships from unstructured text (documents, PDFs) and construct a knowledge graph.",
      "domains": [
        "G1",
        "Knowledge Graph"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "graph_construction"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/neo4j-labs/llm-graph-builder",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "neo4j",
        "llm",
        "knowledge-graph",
        "unstructured-data"
      ],
      "id": 166
    },
    {
      "name": "TabInOut",
      "one_line_profile": "Framework for information extraction from tables",
      "detailed_description": "A framework designed to extract information from tables in documents, supporting the structured analysis of scientific data presented in tabular format.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "information_extraction"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/nikolamilosevic86/TabInOut",
      "help_website": [],
      "license": null,
      "tags": [
        "table-extraction",
        "information-extraction",
        "document-analysis"
      ],
      "id": 167
    },
    {
      "name": "arucogen",
      "one_line_profile": "Online generator for ArUco markers",
      "detailed_description": "A tool to generate ArUco markers, which are widely used in computer vision and robotics research for pose estimation and camera calibration.",
      "domains": [
        "Computer Vision",
        "Robotics"
      ],
      "subtask_category": [
        "marker_generation",
        "calibration"
      ],
      "application_level": "tool",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/okalachev/arucogen",
      "help_website": [
        "http://chev.me/arucogen/"
      ],
      "license": "MIT",
      "tags": [
        "aruco",
        "computer-vision",
        "robotics",
        "marker-generator"
      ],
      "id": 168
    },
    {
      "name": "DocLayout-YOLO",
      "one_line_profile": "Advanced document layout analysis model using YOLO architecture",
      "detailed_description": "A specialized computer vision model for document layout analysis, capable of detecting and segmenting diverse document elements (text, tables, figures) to support downstream scientific literature parsing.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/opendatalab/DocLayout-YOLO",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "layout-analysis",
        "yolo",
        "document-understanding"
      ],
      "id": 169
    },
    {
      "name": "MinerU",
      "one_line_profile": "High-quality PDF to Markdown/JSON converter for scientific documents",
      "detailed_description": "A comprehensive data extraction tool designed to transform complex scientific PDFs into LLM-ready structured formats (Markdown/JSON), handling formulas, tables, and layout preservation.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "text_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/opendatalab/MinerU",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "pdf-to-markdown",
        "llm-ready",
        "data-extraction"
      ],
      "id": 170
    },
    {
      "name": "PDF-Extract-Kit",
      "one_line_profile": "Comprehensive toolkit for high-quality PDF content extraction",
      "detailed_description": "A toolkit integrating layout analysis, formula detection, table recognition, and OCR to extract high-quality structured content from PDF documents for scientific research and QA systems.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_extraction",
        "ocr",
        "layout_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/opendatalab/PDF-Extract-Kit",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "pdf-extraction",
        "ocr",
        "table-recognition"
      ],
      "id": 171
    },
    {
      "name": "Open Semantic Search",
      "one_line_profile": "Integrated search engine and text analytics platform for document collections",
      "detailed_description": "An open-source research tool combining ETL, OCR, Named Entity Recognition (NER), and full-text search to analyze and explore large collections of unstructured documents.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "semantic_search",
        "text_mining",
        "document_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/opensemanticsearch/open-semantic-search",
      "help_website": [
        "https://www.opensemanticsearch.org/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "semantic-search",
        "etl",
        "text-analytics"
      ],
      "id": 172
    },
    {
      "name": "CRRF-Det",
      "one_line_profile": "Web application for PDF content and table extraction for climate data",
      "detailed_description": "A tool developed under OS-Climate for extracting structured data from PDF reports, featuring visual layout analysis and table parsing, specifically targeted at climate risk and financial reporting.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "pdf_parsing"
      ],
      "application_level": "application",
      "primary_language": "C++",
      "repo_url": "https://github.com/os-climate/crrf-det",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "climate-data",
        "pdf-extraction",
        "table-parsing"
      ],
      "id": 173
    },
    {
      "name": "OpenAlex PDF Parser",
      "one_line_profile": "GROBID-based PDF parser for OpenAlex pipeline",
      "detailed_description": "A Python wrapper and utility set used by OpenAlex to parse scientific PDFs using GROBID, facilitating the extraction of metadata and full text for the OpenAlex knowledge graph.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "citation_parsing",
        "metadata_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ourresearch/openalex-pdf-parser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "openalex",
        "grobid",
        "pdf-parsing"
      ],
      "id": 174
    },
    {
      "name": "Papercast",
      "one_line_profile": "Pipeline tool for processing technical documents from arXiv/PDF",
      "detailed_description": "A modular pipeline tool for processing scientific papers (from arXiv or local PDFs) using GROBID and LangChain, capable of converting technical documents into various formats including audio summaries.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_processing",
        "summarization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/papercast-dev/papercast",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arxiv",
        "grobid",
        "pipeline"
      ],
      "id": 175
    },
    {
      "name": "Parsee Core",
      "one_line_profile": "Structured data extraction framework for PDFs and HTML",
      "detailed_description": "A framework for extracting fully structured data from PDFs and HTML files, supporting LLMs and custom models, with a focus on tabular data and multimodal queries for scientific and financial documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "data_extraction",
        "table_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/parsee-ai/parsee-core",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "structured-extraction",
        "pdf-parsing",
        "llm"
      ],
      "id": 176
    },
    {
      "name": "Parsee PDF Reader",
      "one_line_profile": "Specialized PDF reader for table and text extraction",
      "detailed_description": "A tool specialized in extracting tables with numeric values and preserving text paragraphs from PDFs, including support for scanned documents and images.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "ocr"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/parsee-ai/parsee-pdf-reader",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-reader",
        "table-extraction",
        "ocr"
      ],
      "id": 177
    },
    {
      "name": "Parsing Science Toolkit",
      "one_line_profile": "Toolkit for parsing and analyzing scientific literature",
      "detailed_description": "A collection of utilities designed for parsing scientific documents and analyzing their structure and content, supporting bibliometric and meta-scientific research.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_parsing",
        "bibliometrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/parsing-science/ps-toolkit",
      "help_website": [],
      "license": null,
      "tags": [
        "science-parsing",
        "bibliometrics"
      ],
      "id": 178
    },
    {
      "name": "pdfminer.six",
      "one_line_profile": "Community maintained PDF parsing library",
      "detailed_description": "A robust Python library for extracting text, layout, and metadata from PDF files, serving as a foundational component for many scientific document analysis pipelines.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "text_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pdfminer/pdfminer.six",
      "help_website": [
        "https://pdfminersix.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "pdf-parsing",
        "text-extraction",
        "layout-analysis"
      ],
      "id": 179
    },
    {
      "name": "geodict",
      "one_line_profile": "Library for extracting location information from unstructured text",
      "detailed_description": "A tool for identifying and extracting geographic location names from unstructured text, useful for geoparsing scientific literature and reports.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "geoparsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/petewarden/geodict",
      "help_website": [],
      "license": null,
      "tags": [
        "geoparsing",
        "ner",
        "text-mining"
      ],
      "id": 180
    },
    {
      "name": "pylatexenc",
      "one_line_profile": "Simple LaTeX parser and encoder/decoder",
      "detailed_description": "A Python library providing a LaTeX parser and converters for LaTeX-to-Unicode and Unicode-to-LaTeX, essential for processing mathematical formulas and special characters in scientific texts.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "latex_parsing",
        "text_normalization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/phfaist/pylatexenc",
      "help_website": [
        "https://pylatexenc.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "latex",
        "parser",
        "unicode-conversion"
      ],
      "id": 181
    },
    {
      "name": "YOLO-DocLayNet",
      "one_line_profile": "YOLO models trained on DocLayNet for document layout analysis",
      "detailed_description": "Provides YOLO-based models trained on the DocLayNet dataset to perform document layout analysis, identifying headers, footers, paragraphs, and tables in scientific documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ppaanngggg/yolo-doclaynet",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "yolo",
        "doclaynet",
        "layout-analysis"
      ],
      "id": 182
    },
    {
      "name": "QMiner",
      "one_line_profile": "Analytic platform for real-time large-scale data streams",
      "detailed_description": "A high-performance analytics platform for processing structured and unstructured data (including text) streams, suitable for large-scale text mining and citation network analysis.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "text_mining",
        "data_analytics"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/qminer/qminer",
      "help_website": [
        "http://qminer.github.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "data-mining",
        "stream-processing",
        "text-analytics"
      ],
      "id": 183
    },
    {
      "name": "Eynollah",
      "one_line_profile": "Document Layout Analysis tool for historical and scientific documents",
      "detailed_description": "A tool developed by the Berlin State Library for document layout analysis, capable of segmenting pages into regions (text, image, table) and extracting reading order, useful for digitizing scientific archives.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/qurator-spk/eynollah",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "layout-analysis",
        "ocr",
        "document-processing"
      ],
      "id": 184
    },
    {
      "name": "Pdf2Dom",
      "one_line_profile": "PDF to HTML DOM parser based on PDFBox",
      "detailed_description": "A Java library that parses PDF documents and converts them into an HTML DOM representation, facilitating the structural analysis and content extraction of PDF files.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "format_conversion"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/radkovo/Pdf2Dom",
      "help_website": [
        "http://cssbox.sourceforge.net/pdf2dom/"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "pdf-to-html",
        "dom-parsing",
        "pdfbox"
      ],
      "id": 185
    },
    {
      "name": "PyBibTeX",
      "one_line_profile": "Utility functions for parsing BibTeX files",
      "detailed_description": "A Python utility library for parsing BibTeX files and managing citation reference lists, supporting the construction and analysis of citation networks.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "citation_parsing",
        "bibliography_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rasbt/pybibtex",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bibtex",
        "citation-parsing",
        "reference-management"
      ],
      "id": 186
    },
    {
      "name": "document-layout-analysis",
      "one_line_profile": "Document layout analysis tool using Python-OpenCV",
      "detailed_description": "A Python-based tool leveraging OpenCV to perform layout analysis on documents, identifying and segmenting different regions such as text blocks and images, useful for preprocessing scientific literature.",
      "domains": [
        "G1-01",
        "Computer Vision"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/rbaguila/document-layout-analysis",
      "help_website": [],
      "license": null,
      "tags": [
        "opencv",
        "layout-analysis",
        "document-processing"
      ],
      "id": 187
    },
    {
      "name": "smilesDrawer",
      "one_line_profile": "High performance SMILES parser and drawer",
      "detailed_description": "A robust JavaScript component for parsing SMILES strings (chemical structure notation) and rendering them as 2D chemical structure diagrams, essential for cheminformatics and chemical data visualization.",
      "domains": [
        "Chemistry",
        "Cheminformatics"
      ],
      "subtask_category": [
        "molecular_visualization",
        "structure_parsing"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/reymond-group/smilesDrawer",
      "help_website": [
        "https://doc.gdb.tools/smilesDrawer/"
      ],
      "license": "MIT",
      "tags": [
        "smiles",
        "chemistry",
        "visualization"
      ],
      "id": 188
    },
    {
      "name": "TaG",
      "one_line_profile": "Table-to-Graph generation for entity and relation extraction",
      "detailed_description": "Implementation of the ACL 2023 paper 'A Novel Table-to-Graph Generation Approach', providing a method for joint entity and relation extraction from document tables, supporting structured data extraction from scientific literature.",
      "domains": [
        "G1-01",
        "NLP"
      ],
      "subtask_category": [
        "information_extraction",
        "table_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ridiculouz/TaG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "table-extraction",
        "relation-extraction",
        "acl-2023"
      ],
      "id": 189
    },
    {
      "name": "reftagger",
      "one_line_profile": "Parser for unstructured academic citations",
      "detailed_description": "A Python tool designed to parse and tag unstructured academic citations, facilitating the extraction of metadata from scientific bibliographies.",
      "domains": [
        "G1",
        "Bibliometrics"
      ],
      "subtask_category": [
        "citation_parsing",
        "metadata_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rmcgibbo/reftagger",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "citation",
        "parsing",
        "academic-ref"
      ],
      "id": 190
    },
    {
      "name": "BotanicGarden",
      "one_line_profile": "Dataset for robot navigation in unstructured environments",
      "detailed_description": "A high-quality dataset designed for training and evaluating robot navigation algorithms in unstructured natural environments, supporting robotics research.",
      "domains": [
        "Robotics",
        "Computer Vision"
      ],
      "subtask_category": [
        "dataset",
        "navigation_simulation"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/robot-pesg/BotanicGarden",
      "help_website": [],
      "license": null,
      "tags": [
        "robotics",
        "dataset",
        "navigation"
      ],
      "id": 191
    },
    {
      "name": "tabulapdf",
      "one_line_profile": "R bindings for Tabula PDF Table Extractor",
      "detailed_description": "An R package providing bindings to the Tabula Java library, enabling the extraction of data tables from PDF documents into R dataframes for scientific data analysis.",
      "domains": [
        "G1-01",
        "Data Science"
      ],
      "subtask_category": [
        "table_extraction",
        "pdf_parsing"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/ropensci/tabulapdf",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf",
        "table-extraction",
        "r-package"
      ],
      "id": 192
    },
    {
      "name": "TabularSemanticParsing",
      "one_line_profile": "Translating natural language questions to SQL",
      "detailed_description": "A research codebase from Salesforce Research for semantic parsing, specifically translating natural language questions into structured query language (SQL), supporting interaction with structured scientific databases.",
      "domains": [
        "NLP",
        "Database"
      ],
      "subtask_category": [
        "semantic_parsing",
        "nl2sql"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/salesforce/TabularSemanticParsing",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "nlp",
        "sql",
        "semantic-parsing"
      ],
      "id": 193
    },
    {
      "name": "python-bibtexparser",
      "one_line_profile": "BibTeX parsing library for Python",
      "detailed_description": "A robust Python library for parsing, modifying, and writing BibTeX files, essential for managing and processing bibliographic data in scientific workflows.",
      "domains": [
        "G1",
        "Bibliometrics"
      ],
      "subtask_category": [
        "bibliography_parsing",
        "metadata_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sciunto-org/python-bibtexparser",
      "help_website": [
        "https://bibtexparser.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "bibtex",
        "parser",
        "bibliography"
      ],
      "id": 194
    },
    {
      "name": "ACL-anthology-corpus",
      "one_line_profile": "ACL Anthology corpus with PDFs and GROBID extractions",
      "detailed_description": "A dataset repository providing the ACL Anthology corpus, including PDFs, BibTeX metadata, and structured extractions generated by GROBID, serving as a resource for NLP and scientific literature mining research.",
      "domains": [
        "G1",
        "NLP"
      ],
      "subtask_category": [
        "dataset",
        "corpus_construction"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/shauryr/ACL-anthology-corpus",
      "help_website": [],
      "license": null,
      "tags": [
        "acl",
        "corpus",
        "grobid"
      ],
      "id": 195
    },
    {
      "name": "markdrop",
      "one_line_profile": "PDF to Markdown converter with LLM-based description generation",
      "detailed_description": "A Python package for converting PDF documents to Markdown, featuring extraction of images and tables, and utilizing LLMs to generate descriptive text for extracted elements, facilitating semantic analysis of scientific papers.",
      "domains": [
        "G1-01",
        "NLP"
      ],
      "subtask_category": [
        "pdf_parsing",
        "content_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/shoryasethia/markdrop",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pdf-to-markdown",
        "llm",
        "extraction"
      ],
      "id": 196
    },
    {
      "name": "latex-parser",
      "one_line_profile": "LaTeX parser and AST generator",
      "detailed_description": "A tool to parse LaTeX code into an Abstract Syntax Tree (AST) and pretty-print it, enabling programmatic analysis and manipulation of LaTeX-based scientific documents.",
      "domains": [
        "G1-01",
        "Document Processing"
      ],
      "subtask_category": [
        "latex_parsing",
        "ast_generation"
      ],
      "application_level": "library",
      "primary_language": "TeX",
      "repo_url": "https://github.com/siefkenj/latex-parser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "latex",
        "parser",
        "ast"
      ],
      "id": 197
    },
    {
      "name": "unified-latex",
      "one_line_profile": "Unified.js processor for LaTeX",
      "detailed_description": "A comprehensive ecosystem for parsing, inspecting, transforming, and printing LaTeX, built on the Unified.js interface. It allows for structured manipulation of scientific manuscripts written in LaTeX.",
      "domains": [
        "G1-01",
        "Document Processing"
      ],
      "subtask_category": [
        "latex_processing",
        "ast_transformation"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/siefkenj/unified-latex",
      "help_website": [
        "https://unified-latex.siefkenj.com/"
      ],
      "license": "MIT",
      "tags": [
        "latex",
        "unifiedjs",
        "parsing"
      ],
      "id": 198
    },
    {
      "name": "suql",
      "one_line_profile": "Conversational search over structured and unstructured data",
      "detailed_description": "A framework for conversational search that integrates structured (SQL) and unstructured data retrieval using LLMs, applicable to querying complex scientific databases and literature collections.",
      "domains": [
        "NLP",
        "Information Retrieval"
      ],
      "subtask_category": [
        "conversational_search",
        "hybrid_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanford-oval/suql",
      "help_website": [
        "https://suql.stanford.edu/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "search",
        "sql"
      ],
      "id": 199
    },
    {
      "name": "laypa",
      "one_line_profile": "Document layout analysis tool",
      "detailed_description": "A tool for layout analysis to identify and classify elements in documents, similar to P2PaLA, useful for structural analysis of scientific papers.",
      "domains": [
        "G1-01",
        "Computer Vision"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_understanding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/stefanklut/laypa",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "layout-analysis",
        "document-processing"
      ],
      "id": 200
    },
    {
      "name": "pdf2text",
      "one_line_profile": "A simplified wrapper for PDFMiner to facilitate text extraction from PDFs",
      "detailed_description": "A Python library that wraps PDFMiner to provide a simpler interface for extracting text content from PDF files, aiming to reduce the complexity of using the raw PDFMiner API.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "text_extraction",
        "pdf_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/syllabs/pdf2text",
      "help_website": [],
      "license": null,
      "tags": [
        "pdf",
        "text-extraction",
        "pdfminer-wrapper"
      ],
      "id": 201
    },
    {
      "name": "mdast-util-math",
      "one_line_profile": "Extension for mdast to parse and serialize mathematical equations",
      "detailed_description": "A utility library for the mdast (Markdown Abstract Syntax Tree) ecosystem that enables parsing and serialization of math syntax (LaTeX equations) within Markdown documents.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "math_parsing",
        "syntax_tree_processing"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/syntax-tree/mdast-util-math",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "markdown",
        "latex",
        "math",
        "ast"
      ],
      "id": 202
    },
    {
      "name": "Tabula",
      "one_line_profile": "A tool for liberating data tables trapped inside PDF files",
      "detailed_description": "A popular tool designed to extract tabular data from PDF files into CSV or Excel formats. It provides a user-friendly interface and a robust extraction engine to handle various PDF table layouts.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "data_liberation"
      ],
      "application_level": "solver",
      "primary_language": "CSS",
      "repo_url": "https://github.com/tabulapdf/tabula",
      "help_website": [
        "https://tabula.technology/"
      ],
      "license": "MIT",
      "tags": [
        "pdf",
        "table-extraction",
        "ocr"
      ],
      "id": 203
    },
    {
      "name": "tabula-extractor",
      "one_line_profile": "Ruby-based engine for extracting tables from PDF files",
      "detailed_description": "The core extraction engine for Tabula written in Ruby, providing the functionality to detect and extract tables from PDF documents programmatically.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction"
      ],
      "application_level": "library",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/tabulapdf/tabula-extractor",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ruby",
        "pdf",
        "table-extraction"
      ],
      "id": 204
    },
    {
      "name": "tabula-java",
      "one_line_profile": "Java library for extracting tables from PDF files",
      "detailed_description": "The Java implementation of the Tabula extraction engine, allowing developers to embed PDF table extraction capabilities into Java applications.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/tabulapdf/tabula-java",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "java",
        "pdf",
        "table-extraction"
      ],
      "id": 205
    },
    {
      "name": "latex-utensils",
      "one_line_profile": "A LaTeX and BibTeX parser and utility library",
      "detailed_description": "A TypeScript library providing parsers for LaTeX and BibTeX formats, enabling the analysis and manipulation of bibliographic data and scientific document structures.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "latex_parsing",
        "bibtex_parsing"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/tamuratak/latex-utensils",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "latex",
        "bibtex",
        "parser",
        "typescript"
      ],
      "id": 206
    },
    {
      "name": "parse-latex",
      "one_line_profile": "Pandoc filter to parse raw LaTeX snippets",
      "detailed_description": "A Lua filter for Pandoc that parses raw LaTeX snippets within documents and includes the structured results in the output, facilitating mixed-format document processing.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "document_conversion",
        "latex_parsing"
      ],
      "application_level": "library",
      "primary_language": "Lua",
      "repo_url": "https://github.com/tarleb/parse-latex",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pandoc",
        "latex",
        "filter",
        "lua"
      ],
      "id": 207
    },
    {
      "name": "galactic",
      "one_line_profile": "Data cleaning and curation library for unstructured text",
      "detailed_description": "A Python library designed for massive-scale data cleaning and curation of unstructured text, particularly useful for preparing scientific text datasets for LLM training.",
      "domains": [
        "Sci Knowledge",
        "G1"
      ],
      "subtask_category": [
        "data_cleaning",
        "text_curation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/taylorai/galactic",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "data-cleaning",
        "unstructured-data"
      ],
      "id": 208
    },
    {
      "name": "Tabulo",
      "one_line_profile": "Deep learning based table detection and extraction tool",
      "detailed_description": "A Python tool leveraging deep learning models (Luminoth, TensorFlow) to detect and extract tables from document images, providing labeled coordinates and confidence scores.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "table_detection",
        "layout_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/the-black-knight-01/Tabulo",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "deep-learning",
        "table-detection",
        "ocr"
      ],
      "id": 209
    },
    {
      "name": "markdown2pdf",
      "one_line_profile": "Markdown to PDF transpiler written in Rust",
      "detailed_description": "A high-performance command-line tool and library written in Rust for converting Markdown documents into PDF format, useful for generating scientific reports from structured text.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "document_generation",
        "format_conversion"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/theiskaa/markdown2pdf",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "markdown",
        "pdf",
        "rust",
        "converter"
      ],
      "id": 210
    },
    {
      "name": "wdoc",
      "one_line_profile": "Tool for summarizing and querying heterogeneous documents using LLMs",
      "detailed_description": "A Python tool that enables advanced RAG (Retrieval-Augmented Generation) and summarization over large collections of heterogeneous documents, supporting scientific literature review and knowledge extraction.",
      "domains": [
        "Sci Knowledge",
        "G1"
      ],
      "subtask_category": [
        "literature_review",
        "summarization",
        "rag"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/thiswillbeyourgithub/wdoc",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "llm",
        "rag",
        "summarization",
        "document-analysis"
      ],
      "id": 211
    },
    {
      "name": "traprange",
      "one_line_profile": "Java method to extract tabular content from PDF files",
      "detailed_description": "A Java library implementing the TrapRange method for extracting complex tables from PDF documents, focusing on handling row and column detection in challenging layouts.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/thoqbk/traprange",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf",
        "table-extraction",
        "java"
      ],
      "id": 212
    },
    {
      "name": "synonym_detection",
      "one_line_profile": "Tool for mining synonyms from unstructured and semi-structured data",
      "detailed_description": "A Python toolkit for detecting and mining synonyms from large-scale unstructured text data, useful for constructing scientific knowledge graphs and normalizing terminology.",
      "domains": [
        "Sci Knowledge",
        "G1"
      ],
      "subtask_category": [
        "synonym_mining",
        "terminology_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tigerchen52/synonym_detection",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "synonym-detection",
        "text-mining"
      ],
      "id": 213
    },
    {
      "name": "scipdf_parser",
      "one_line_profile": "Python parser for scientific PDF publications",
      "detailed_description": "A Python library specifically designed to parse scientific PDF publications, extracting structured content including title, abstract, sections, and figures using GROBID and other backend tools.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "structure_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/titipata/scipdf_parser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf",
        "scientific-literature",
        "grobid",
        "parsing"
      ],
      "id": 214
    },
    {
      "name": "wos_parser",
      "one_line_profile": "Parser for Web of Science XML data",
      "detailed_description": "A Python library for parsing XML data exports from Web of Science, enabling bibliometric analysis and metadata extraction from scientific citation databases.",
      "domains": [
        "Sci Knowledge",
        "G1"
      ],
      "subtask_category": [
        "metadata_extraction",
        "bibliometrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/titipata/wos_parser",
      "help_website": [],
      "license": null,
      "tags": [
        "web-of-science",
        "xml-parser",
        "bibliometrics"
      ],
      "id": 215
    },
    {
      "name": "ColiVara",
      "one_line_profile": "Visual retrieval service for documents using vision models",
      "detailed_description": "A document retrieval system that uses vision models to generate visual embeddings for pages, allowing for search and retrieval without relying on OCR or text extraction, particularly useful for complex scientific layouts.",
      "domains": [
        "Sci Knowledge",
        "G1"
      ],
      "subtask_category": [
        "document_retrieval",
        "visual_search"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/tjmlabs/ColiVara",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "vision-model",
        "document-retrieval"
      ],
      "id": 216
    },
    {
      "name": "SpanMarkerNER",
      "one_line_profile": "Named Entity Recognition using SpanMarker",
      "detailed_description": "A library for Named Entity Recognition (NER) that uses the SpanMarker architecture to effectively identify and classify entities in text, applicable to scientific entity extraction.",
      "domains": [
        "Sci Knowledge",
        "G1"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "information_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tomaarsen/SpanMarkerNER",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ner",
        "nlp",
        "transformers"
      ],
      "id": 217
    },
    {
      "name": "YaLafi",
      "one_line_profile": "Yet another LaTeX filter for text processing",
      "detailed_description": "A Python tool designed to filter and process LaTeX documents, often used to prepare LaTeX text for grammar checking or other NLP tasks by stripping commands while preserving content.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "latex_processing",
        "text_filtering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/torik42/YaLafi",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "latex",
        "filter",
        "nlp"
      ],
      "id": 218
    },
    {
      "name": "citationberg",
      "one_line_profile": "Library for parsing CSL (Citation Style Language) styles",
      "detailed_description": "A Rust library for parsing and processing Citation Style Language (CSL) files, used for formatting citations and bibliographies in scientific publishing workflows (e.g., within Typst).",
      "domains": [
        "Sci Knowledge",
        "G1"
      ],
      "subtask_category": [
        "citation_parsing",
        "bibliography_formatting"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/typst/citationberg",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "csl",
        "citation",
        "rust",
        "typst"
      ],
      "id": 219
    },
    {
      "name": "UCNS3D",
      "one_line_profile": "Unstructured Compressible Navier Stokes 3D solver",
      "detailed_description": "A high-order computational fluid dynamics (CFD) code for solving the Unstructured Compressible Navier-Stokes equations in 3D, used for aerodynamic and fluid flow simulations.",
      "domains": [
        "Physics",
        "Fluid Dynamics"
      ],
      "subtask_category": [
        "simulation",
        "cfd_solver"
      ],
      "application_level": "solver",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/ucns3d-team/UCNS3D",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "cfd",
        "fluid-dynamics",
        "simulation",
        "fortran"
      ],
      "id": 220
    },
    {
      "name": "nanonispy",
      "one_line_profile": "Library to parse Nanonis binary and ASCII files",
      "detailed_description": "A Python library for parsing binary (.sxm) and ASCII (.dat) files generated by Nanonis control systems, widely used in scanning tunneling microscopy (STM) and atomic force microscopy (AFM).",
      "domains": [
        "Materials Science",
        "Physics"
      ],
      "subtask_category": [
        "data_parsing",
        "microscopy_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/underchemist/nanonispy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nanonis",
        "stm",
        "afm",
        "file-parsing"
      ],
      "id": 221
    },
    {
      "name": "GraphGPT",
      "one_line_profile": "Tool for extrapolating knowledge graphs from unstructured text using LLMs",
      "detailed_description": "A tool that leverages GPT models to extract entities and relationships from unstructured text and visualize them as a knowledge graph, aiding in scientific knowledge discovery.",
      "domains": [
        "Sci Knowledge",
        "G1"
      ],
      "subtask_category": [
        "knowledge_graph_extraction",
        "relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/varunshenoy/GraphGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "llm",
        "visualization"
      ],
      "id": 222
    },
    {
      "name": "tabular-feature-selection",
      "one_line_profile": "Feature selection library for tabular data models",
      "detailed_description": "A Python repository providing methods and tools for feature selection specifically designed for tabular data, supporting machine learning workflows in data science.",
      "domains": [
        "Data Science",
        "Machine Learning"
      ],
      "subtask_category": [
        "feature_selection",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vcherepanova/tabular-feature-selection",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "feature-selection",
        "tabular-data",
        "machine-learning"
      ],
      "id": 223
    },
    {
      "name": "algebra-latex",
      "one_line_profile": "Library to parse and calculate LaTeX formatted math",
      "detailed_description": "A JavaScript library that parses LaTeX-formatted mathematical expressions and performs calculations or algebraic manipulations, useful for educational tools or scientific web applications.",
      "domains": [
        "Sci Knowledge",
        "G1-01"
      ],
      "subtask_category": [
        "math_parsing",
        "calculation"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/viktorstrate/algebra-latex",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "latex",
        "math",
        "parser",
        "calculator"
      ],
      "id": 224
    },
    {
      "name": "Knowledge Table",
      "one_line_profile": "Tool for extracting structured data from unstructured documents for RAG/KG",
      "detailed_description": "A package designed to simplify the extraction and exploration of structured data (tables, entities) from unstructured documents like PDFs, facilitating knowledge base construction.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "information_extraction",
        "structured_data_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/whyhow-ai/knowledge-table",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "unstructured-data",
        "knowledge-graph"
      ],
      "id": 225
    },
    {
      "name": "E2M",
      "one_line_profile": "Universal document to Markdown converter for LLM pipelines",
      "detailed_description": "A tool that converts various file types (doc, docx, pdf, epub, html) into Markdown, specifically designed to normalize scientific and technical documents for LLM processing and RAG systems.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "document_conversion",
        "format_normalization"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/wisupai/e2m",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf-to-markdown",
        "rag",
        "document-parsing"
      ],
      "id": 226
    },
    {
      "name": "img2table",
      "one_line_profile": "Table identification and extraction from PDFs and images",
      "detailed_description": "A library for identifying and extracting tables from PDF documents and images, utilizing OpenCV for image processing to recover structural data from scientific literature.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "table_extraction",
        "ocr"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/xavctn/img2table",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "table-extraction",
        "pdf-mining",
        "opencv"
      ],
      "id": 227
    },
    {
      "name": "freki",
      "one_line_profile": "Analyzer for XML extracted from scientific PDFs",
      "detailed_description": "A tool to analyze and process XML data extracted from PDFs (e.g., via PDFMiner or TET), facilitating the structural analysis of scientific documents.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "xml_parsing",
        "document_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/xigt/freki",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-analysis",
        "xml-processing",
        "scientific-literature"
      ],
      "id": 228
    },
    {
      "name": "llm-based-ocr",
      "one_line_profile": "LLM-powered PDF to Markdown OCR tool",
      "detailed_description": "An API and tool that leverages Large Language Models with vision capabilities to perform high-accuracy OCR and convert PDF documents into Markdown, suitable for scientific paper digitization.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "ocr",
        "document_conversion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yigitkonur/llm-based-ocr",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "ocr",
        "pdf-to-markdown"
      ],
      "id": 229
    },
    {
      "name": "extractous",
      "one_line_profile": "High-performance unstructured data extraction library",
      "detailed_description": "A fast data extraction library written in Rust that converts unstructured files (PDF, DOCX, etc.) into structured text, suitable for building scientific knowledge bases and ETL pipelines.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "data_extraction",
        "etl"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/yobix-ai/extractous",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rust",
        "pdf-extraction",
        "unstructured-data"
      ],
      "id": 230
    },
    {
      "name": "RoDLA",
      "one_line_profile": "Benchmark for Document Layout Analysis robustness",
      "detailed_description": "A benchmark suite and dataset designed to evaluate the robustness of Document Layout Analysis (DLA) models, critical for assessing tools used in scientific literature parsing.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "benchmarking",
        "layout_analysis"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/yufanchen96/RoDLA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "document-layout-analysis",
        "robustness"
      ],
      "id": 231
    },
    {
      "name": "faster-nougat",
      "one_line_profile": "Optimized local implementation of Nougat PDF parser",
      "detailed_description": "An efficient implementation of the Nougat model designed for local processing of scientific PDFs, converting them into structured Markdown with mathematical formulas.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "pdf_parsing",
        "ocr"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhuzilin/faster-nougat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nougat",
        "pdf-to-markdown",
        "scientific-parsing"
      ],
      "id": 232
    }
  ]
}