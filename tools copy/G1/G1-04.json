{
  "generated_at": "2025-12-16T03:41:26.445237+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "G1",
      "leaf_cluster_name": "科研文献-检索/解析/引用网络生态",
      "domain": "Sci Knowledge",
      "typical_objects": "PDFs/citations",
      "task_chain": "解析→抽取→索引→检索→评测",
      "tool_form": "解析器 + 检索 + 评测"
    },
    "unit": {
      "unit_id": "G1-04",
      "unit_name": "文献RAG 与证据链（AI）",
      "target_scale": "250–600",
      "coverage_tools": "RAG frameworks、grounding"
    },
    "search": {
      "target_candidates": 600,
      "queries": [
        "[GH] Khoj",
        "[GH] Verba",
        "[GH] PrivateGPT",
        "[GH] STORM",
        "[GH] RAGFlow",
        "[GH] Haystack",
        "[GH] LangChain",
        "[GH] LlamaIndex",
        "[GH] GPT Researcher",
        "[GH] PaperQA",
        "[GH] retrieval augmented generation scientific",
        "[GH] paper qa",
        "[GH] citation grounding",
        "[GH] literature review agent",
        "[GH] evidence extraction",
        "[GH] academic rag",
        "[GH] scientific document understanding",
        "[GH] research assistant",
        "[GH] hallucination detection",
        "[GH] fact checking llm",
        "[GH] rag framework",
        "[GH] knowledge graph rag",
        "[GH] pdf chat",
        "[WEB] scientific literature rag framework github",
        "[WEB] llm citation grounding tools github",
        "[WEB] ai research assistant open source github",
        "[WEB] evidence chain reasoning papers github",
        "[WEB] retrieval augmented generation for academic writing github"
      ],
      "total_candidates": 1243,
      "tool_candidates": 809,
      "final_tools": 194
    }
  },
  "tools": [
    {
      "name": "GraphRAG Agent",
      "one_line_profile": "Integrated RAG framework combining GraphRAG, LightRAG, and Neo4j for knowledge graph construction and search",
      "detailed_description": "A comprehensive RAG solution that integrates multiple advanced RAG techniques (GraphRAG, LightRAG) and graph databases (Neo4j) to construct knowledge graphs from documents and perform deep search reasoning. It includes a custom evaluation framework for GraphRAG performance.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "retrieval_augmented_generation",
        "deep_search"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/1517005260/graph-rag-agent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graphrag",
        "knowledge-graph",
        "neo4j",
        "rag"
      ],
      "id": 1
    },
    {
      "name": "Zotero MCP",
      "one_line_profile": "Model Context Protocol server connecting Zotero libraries to AI agents",
      "detailed_description": "A bridge tool that enables AI agents (like Claude) to directly access and interact with Zotero research libraries via the Model Context Protocol (MCP). It allows for analyzing citations, retrieving paper summaries, and discussing research papers stored in Zotero.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_management",
        "citation_analysis",
        "evidence_retrieval"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/54yyyu/zotero-mcp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "zotero",
        "mcp",
        "literature-review",
        "citation"
      ],
      "id": 2
    },
    {
      "name": "Tetsuo Dox Agent",
      "one_line_profile": "Graph-based research assistant for drafting answers with robust citations",
      "detailed_description": "A research assistant agent designed to provide technically focused answers with strict citation backing. It utilizes a graph-based architecture to perform iterative research, self-reflection, and drafts responses based on discovered evidence, ensuring grounding in source materials.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "evidence_grounding",
        "citation_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/7etsuo/tetsuo-dox-agent",
      "help_website": [],
      "license": null,
      "tags": [
        "research-assistant",
        "citations",
        "agent",
        "grounding"
      ],
      "id": 3
    },
    {
      "name": "VerbaAurea",
      "one_line_profile": "Document preprocessing tool for high-quality knowledge base construction",
      "detailed_description": "A specialized tool for preprocessing documents to build high-quality text data for knowledge bases. It focuses on cleaning, formatting, and structuring text data to improve the performance of downstream RAG and retrieval tasks.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "data_preprocessing",
        "text_cleaning",
        "knowledge_base_construction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AEPAX/VerbaAurea",
      "help_website": [],
      "license": "CC-BY-4.0",
      "tags": [
        "preprocessing",
        "rag",
        "knowledge-base",
        "text-mining"
      ],
      "id": 4
    },
    {
      "name": "Deep Research Web UI",
      "one_line_profile": "AI-powered assistant for iterative deep research and synthesis",
      "detailed_description": "A web interface and agent system designed for deep research tasks. It supports iterative searching, web scraping, and synthesis of information using Large Language Models (including DeepSeek R1), enabling users to conduct comprehensive literature reviews and topic research.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "information_synthesis",
        "web_research"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/AnotiaWang/deep-research-web-ui",
      "help_website": [],
      "license": null,
      "tags": [
        "deep-research",
        "literature-review",
        "agent",
        "web-scraping"
      ],
      "id": 5
    },
    {
      "name": "DeepParseX",
      "one_line_profile": "Multimodal document parsing and knowledge graph construction platform",
      "detailed_description": "A platform for parsing multimodal documents (PDF, Word, PPT, Images) to extract key information and construct Knowledge Graphs (KG) and RAG systems. It focuses on structured data extraction and reasoning for intelligent retrieval.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "document_parsing",
        "knowledge_graph_construction",
        "multimodal_extraction"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Arterning/DeepParseX",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "document-parsing",
        "knowledge-graph",
        "rag",
        "multimodal"
      ],
      "id": 6
    },
    {
      "name": "PapersChat",
      "one_line_profile": "Agentic AI for chatting with papers and retrieving from ArXiv/PubMed",
      "detailed_description": "An AI agent application that enables users to interact with their local papers and retrieve information directly from scientific repositories like ArXiv and PubMed. It facilitates literature discovery and reading comprehension.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_retrieval",
        "paper_reading",
        "arxiv_integration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AstraBert/PapersChat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arxiv",
        "pubmed",
        "literature-chat",
        "agent"
      ],
      "id": 7
    },
    {
      "name": "AutoRA",
      "one_line_profile": "Framework for automating the closed-loop scientific research process",
      "detailed_description": "AutoRA (Automated Research Assistant) is a framework designed to automate the empirical research process. It supports closed-loop discovery by integrating experimental design, data collection, and model discovery/refinement.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "automated_discovery",
        "experimental_design",
        "scientific_modeling"
      ],
      "application_level": "framework",
      "primary_language": "TeX",
      "repo_url": "https://github.com/AutoResearch/autora",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "automated-science",
        "closed-loop",
        "experiment-design"
      ],
      "id": 8
    },
    {
      "name": "GraphRAG Accelerator",
      "one_line_profile": "Accelerator for deploying Knowledge Graph powered RAG on Azure",
      "detailed_description": "A deployment tool and accelerator for setting up GraphRAG (Retrieval-Augmented Generation with Knowledge Graphs) infrastructure. It facilitates the creation of knowledge-driven retrieval systems essential for complex scientific query answering.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_deployment",
        "knowledge_graph_infrastructure"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Azure-Samples/graphrag-accelerator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graphrag",
        "azure",
        "knowledge-graph",
        "deployment"
      ],
      "id": 9
    },
    {
      "name": "KG-RAG",
      "one_line_profile": "Knowledge Graph based RAG framework for biomedical knowledge tasks",
      "detailed_description": "A framework developed by Baranzini Lab that leverages Knowledge Graphs to empower Large Language Models for knowledge-intensive tasks, specifically tailored for biomedical research and discovery.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "biomedical_rag",
        "knowledge_graph_reasoning",
        "literature_mining"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/BaranziniLab/KG_RAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "biomedical",
        "knowledge-graph",
        "rag",
        "llm"
      ],
      "id": 10
    },
    {
      "name": "ClaimeAI",
      "one_line_profile": "AI-powered fact-checking system using LangGraph for claim verification",
      "detailed_description": "A system that dissects text into verifiable claims and cross-references them with real-world evidence via web searches to generate accuracy reports. It is designed to combat misinformation in LLM outputs and other text sources.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "fact_checking",
        "evidence_verification"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/BharathxD/ClaimeAI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fact-checking",
        "langgraph",
        "misinformation-detection"
      ],
      "id": 11
    },
    {
      "name": "Verbalized Sampling",
      "one_line_profile": "Training-free prompting strategy for diverse LLM sampling",
      "detailed_description": "A framework implementing a prompting strategy to mitigate mode collapse in LLMs by requesting responses with probabilities. It serves as a tool for synthetic data generation and creative writing without model fine-tuning.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "synthetic_data_generation",
        "sampling_strategy"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CHATS-lab/verbalized-sampling",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "prompting",
        "synthetic-data"
      ],
      "id": 12
    },
    {
      "name": "pyhaystack",
      "one_line_profile": "Python client for Project Haystack IoT data retrieval",
      "detailed_description": "A module allowing Python programs to connect to Haystack servers (Niagara, Skyspark, etc.) to retrieve and process building automation and IoT sensor data, facilitating engineering and scientific analysis of building performance.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "data_retrieval",
        "iot_data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChristianTremblay/pyhaystack",
      "help_website": [
        "https://pyhaystack.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "iot",
        "building-automation",
        "haystack-protocol"
      ],
      "id": 13
    },
    {
      "name": "Doctor Dok",
      "one_line_profile": "Medical data parsing and analysis framework",
      "detailed_description": "A framework to parse health-related PDFs or images into JSON format and utilize LLMs for analysis. It serves as a tool for digitizing and processing medical records for research or personal health data management.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "medical_data_parsing",
        "ocr",
        "clinical_data_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/Doctor-One/doctor-dok",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-data",
        "ocr",
        "pdf-parsing"
      ],
      "id": 14
    },
    {
      "name": "RAGMeUp",
      "one_line_profile": "Generic RAG framework for dataset interaction",
      "detailed_description": "A generic Retrieval-Augmented Generation (RAG) framework designed to apply LLM capabilities to arbitrary datasets, facilitating knowledge retrieval and analysis.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "knowledge_retrieval"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ErikTromp/RAGMeUp",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "llm",
        "data-analysis"
      ],
      "id": 15
    },
    {
      "name": "PaperQA",
      "one_line_profile": "High-accuracy RAG for scientific document QA with citations",
      "detailed_description": "A specialized RAG tool for answering questions from scientific documents (PDFs/text) with high accuracy. It provides grounded answers with specific citations, designed for literature review and evidence extraction.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "scientific_qa",
        "citation_generation",
        "literature_review"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Future-House/paper-qa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "scientific-literature",
        "citations"
      ],
      "id": 16
    },
    {
      "name": "OpenResearcher",
      "one_line_profile": "AI assistant for scientific research workflows",
      "detailed_description": "An advanced scientific research assistant tool designed to aid researchers in literature review, information synthesis, and research workflow automation.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "research_assistant"
      ],
      "application_level": "platform",
      "primary_language": "HTML",
      "repo_url": "https://github.com/GAIR-NLP/OpenResearcher",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "research-assistant",
        "literature-review",
        "ai4s"
      ],
      "id": 17
    },
    {
      "name": "Auto-Deep-Research",
      "one_line_profile": "Automated agent for deep scientific research",
      "detailed_description": "A fully automated AI assistant designed to conduct deep research, likely including literature search, reading, and summarization, streamlining the scientific discovery process.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "research_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUDS/Auto-Deep-Research",
      "help_website": [],
      "license": null,
      "tags": [
        "agent",
        "research-automation",
        "literature-mining"
      ],
      "id": 18
    },
    {
      "name": "RAG-Anything",
      "one_line_profile": "Comprehensive RAG framework for diverse data types",
      "detailed_description": "An all-in-one Retrieval-Augmented Generation framework capable of handling various data modalities, suitable for building complex scientific knowledge retrieval systems.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "multimodal_retrieval"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUDS/RAG-Anything",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "multimodal",
        "knowledge-base"
      ],
      "id": 19
    },
    {
      "name": "AutoSchemaKG",
      "one_line_profile": "Framework for automatic knowledge graph construction",
      "detailed_description": "A framework for automatic knowledge graph construction that combines schema generation via conceptualization. It facilitates the structuring of unstructured scientific data into knowledge graphs.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "schema_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUST-KnowComp/AutoSchemaKG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "schema-induction",
        "data-structuring"
      ],
      "id": 20
    },
    {
      "name": "Infosys Responsible AI Toolkit",
      "one_line_profile": "Toolkit for ensuring AI safety, security, and explainability",
      "detailed_description": "A comprehensive toolkit incorporating features for safety, security, explainability, fairness, bias, and hallucination detection to ensure AI solutions are trustworthy. Crucial for validating evidence chains in scientific RAG systems.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "ai_safety",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Infosys/Infosys-Responsible-AI-Toolkit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "responsible-ai",
        "hallucination-detection",
        "explainability"
      ],
      "id": 21
    },
    {
      "name": "RAG-FiT",
      "one_line_profile": "Framework for enhancing LLMs for RAG tasks using fine-tuning",
      "detailed_description": "A framework developed by Intel Labs designed to enhance Large Language Models (LLMs) specifically for Retrieval-Augmented Generation (RAG) tasks through fine-tuning techniques.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_optimization",
        "model_finetuning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/IntelLabs/RAG-FiT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "fine-tuning",
        "llm"
      ],
      "id": 22
    },
    {
      "name": "fastRAG",
      "one_line_profile": "Efficient Retrieval Augmentation and Generation Framework",
      "detailed_description": "An efficient framework by Intel Labs for building Retrieval-Augmented Generation (RAG) systems, optimized for performance and integration with various retrieval and generation components.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "information_retrieval"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/IntelLabs/fastRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "efficient-retrieval",
        "intel"
      ],
      "id": 23
    },
    {
      "name": "Research Agents 3.0",
      "one_line_profile": "Multi-agent framework for autonomous research workflows",
      "detailed_description": "A framework combining Autogen and GPTs to build swarms of AI researchers, enabling autonomous information gathering and synthesis for research tasks.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "autonomous_research",
        "agent_simulation",
        "literature_mining"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/JayZeeDesign/research-agents-3.0",
      "help_website": [],
      "license": null,
      "tags": [
        "autogen",
        "multi-agent",
        "research-automation"
      ],
      "id": 24
    },
    {
      "name": "LettuceDetect",
      "one_line_profile": "Hallucination detection framework for RAG applications",
      "detailed_description": "A specialized framework designed to detect hallucinations in Retrieval-Augmented Generation (RAG) applications, ensuring the factual accuracy of generated scientific content.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "fact_checking",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KRLabsOrg/LettuceDetect",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination-detection",
        "rag",
        "reliability"
      ],
      "id": 25
    },
    {
      "name": "OWL Verbalizer",
      "one_line_profile": "Tool for converting OWL ontologies into human-readable text",
      "detailed_description": "A Prolog-based tool that converts machine-readable knowledge (OWL ontologies) into human-readable text, useful for validating scientific knowledge graphs and ontologies.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "ontology_parsing",
        "knowledge_representation",
        "text_generation"
      ],
      "application_level": "solver",
      "primary_language": "Prolog",
      "repo_url": "https://github.com/Kaljurand/owl-verbalizer",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "owl",
        "ontology",
        "prolog",
        "verbalization"
      ],
      "id": 26
    },
    {
      "name": "QualiGPT",
      "one_line_profile": "Tool for qualitative research analysis using LLMs",
      "detailed_description": "An easy-to-use tool designed to assist in qualitative research, likely automating the coding and analysis of textual data using GPT models.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "qualitative_analysis",
        "text_mining",
        "social_science_research"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/KindOPSTAR/QualiGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "qualitative-research",
        "gpt",
        "text-analysis"
      ],
      "id": 27
    },
    {
      "name": "LeanRAG",
      "one_line_profile": "Knowledge-Graph-Based RAG with Semantic Aggregation",
      "detailed_description": "A RAG framework that utilizes Knowledge Graphs and hierarchical retrieval with semantic aggregation to improve generation quality, particularly for complex knowledge domains.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "knowledge_graph_rag",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KnowledgeXLab/LeanRAG",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "rag",
        "semantic-aggregation"
      ],
      "id": 28
    },
    {
      "name": "HyperGraphRAG",
      "one_line_profile": "RAG via Hypergraph-Structured Knowledge Representation",
      "detailed_description": "Implementation of HyperGraphRAG (NeurIPS 2025), a method for Retrieval-Augmented Generation that uses hypergraph structures to represent complex relationships in knowledge bases.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_algorithm",
        "knowledge_representation",
        "hypergraph_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LHRLAB/HyperGraphRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hypergraph",
        "rag",
        "neurips-2025"
      ],
      "id": 29
    },
    {
      "name": "LazyLLM",
      "one_line_profile": "Low-code framework for building multi-agent LLM applications",
      "detailed_description": "A framework designed to simplify the construction of multi-agent Large Language Model applications, facilitating the development of complex AI workflows including research agents.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "agent_framework",
        "workflow_automation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/LazyAGI/LazyLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "llm",
        "low-code"
      ],
      "id": 30
    },
    {
      "name": "Local Deep Research",
      "one_line_profile": "Local AI agent for deep scientific research across multiple sources",
      "detailed_description": "A local, privacy-focused AI research tool that searches and synthesizes information from over 10 sources including arXiv, PubMed, and the web, achieving high performance on QA benchmarks.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_search",
        "scientific_qa",
        "evidence_synthesis"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/LearningCircuit/local-deep-research",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "deep-research",
        "arxiv",
        "pubmed",
        "local-llm"
      ],
      "id": 31
    },
    {
      "name": "docGPT-langchain",
      "one_line_profile": "Tool for chatting with documents using GPT and LangChain",
      "detailed_description": "A tool leveraging LangChain and GPT models to enable natural language queries over various document formats (PDF, WORD, CSV, TXT), facilitating literature review and data extraction.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "document_qa",
        "literature_mining"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lin-jun-xiang/docGPT-langchain",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "document-qa",
        "langchain",
        "pdf-parsing"
      ],
      "id": 32
    },
    {
      "name": "MiniCheck",
      "one_line_profile": "Efficient fact-checking tool for LLM grounding",
      "detailed_description": "A tool for efficient fact-checking of Large Language Model outputs against grounding documents, implementing methods from EMNLP 2024 to ensure scientific accuracy.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "fact_checking",
        "hallucination_detection",
        "grounding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Liyan06/MiniCheck",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fact-checking",
        "emnlp-2024",
        "grounding"
      ],
      "id": 33
    },
    {
      "name": "SurfSense",
      "one_line_profile": "Open source knowledge aggregation and RAG platform",
      "detailed_description": "An open-source alternative to NotebookLM and Perplexity that connects to various data sources (search engines, GitHub, etc.) for comprehensive information retrieval and synthesis.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "knowledge_aggregation",
        "rag_platform",
        "literature_search"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/MODSetter/SurfSense",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "notebooklm-alternative",
        "rag",
        "search-aggregation"
      ],
      "id": 34
    },
    {
      "name": "AutoRAG",
      "one_line_profile": "Automated framework for RAG evaluation and optimization",
      "detailed_description": "An AutoML-style framework for evaluating and optimizing Retrieval-Augmented Generation (RAG) pipelines, helping researchers select the best RAG strategies for their data.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "automl",
        "pipeline_optimization"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag-evaluation",
        "automl",
        "optimization"
      ],
      "id": 35
    },
    {
      "name": "ChatPaper2Xmind",
      "one_line_profile": "Tool to convert academic papers into XMind mind maps",
      "detailed_description": "A tool that uses ChatGPT to summarize academic PDF papers and convert them into XMind mind maps containing images and formulas, facilitating rapid literature review.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_visualization",
        "summarization",
        "pdf_parsing"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/MasterYip/ChatPaper2Xmind",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "xmind",
        "paper-summarization",
        "visualization"
      ],
      "id": 36
    },
    {
      "name": "go-light-rag",
      "one_line_profile": "Go implementation of LightRAG for graph-based retrieval",
      "detailed_description": "A Go library implementation of the LightRAG system, which combines vector databases with graph database relationships to enhance knowledge retrieval capabilities.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "graph_retrieval",
        "knowledge_graph"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/MegaGrindStone/go-light-rag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lightrag",
        "go",
        "graph-rag"
      ],
      "id": 37
    },
    {
      "name": "MemOS",
      "one_line_profile": "Memory management framework for long-term AI agent memory",
      "detailed_description": "An open-source framework for building memory-native AI agents, providing systems for long-term memory, retrieval, and adaptive learning, essential for complex research agents.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "agent_memory",
        "context_management",
        "long_term_retrieval"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/MemTensor/MemOS",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "memory-management",
        "ai-agents",
        "long-context"
      ],
      "id": 38
    },
    {
      "name": "ResearchGPT",
      "one_line_profile": "LLM-based research assistant for conversing with research papers",
      "detailed_description": "An open-source research assistant that leverages Large Language Models (LLMs) to enable interactive conversations with research papers, facilitating literature review and information extraction.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "qa"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/MrPeterJin/researchgpt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "research-assistant",
        "rag",
        "literature-review"
      ],
      "id": 39
    },
    {
      "name": "summarization-eval",
      "one_line_profile": "Reference-free automatic summarization evaluation toolkit",
      "detailed_description": "A toolkit for evaluating automatic summarization systems without reference summaries, featuring potential hallucination detection capabilities, useful for NLP research and quality control of generated text.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "evaluation",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Muhtasham/summarization-eval",
      "help_website": [],
      "license": null,
      "tags": [
        "summarization",
        "evaluation",
        "hallucination-detection",
        "nlp"
      ],
      "id": 40
    },
    {
      "name": "Context-Aware RAG",
      "one_line_profile": "Context-aware RAG library for Knowledge Graph ingestion",
      "detailed_description": "A library by NVIDIA for building context-aware Retrieval-Augmented Generation (RAG) systems, specifically focusing on Knowledge Graph ingestion and retrieval functions to enhance evidence grounding.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag",
        "knowledge_graph_construction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/context-aware-rag",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "knowledge-graph",
        "nvidia",
        "context-aware"
      ],
      "id": 41
    },
    {
      "name": "GaussianSTORM",
      "one_line_profile": "Spatiotemporal reconstruction model for large-scale outdoor scenes",
      "detailed_description": "A PyTorch implementation of STORM (Spatiotemporal Reconstruction Model) for reconstructing large-scale outdoor scenes using Gaussian Splatting, applicable in computer vision and spatial modeling research.",
      "domains": [
        "Sci Knowledge"
      ],
      "subtask_category": [
        "reconstruction",
        "modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVlabs/GaussianSTORM",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "3d-reconstruction",
        "gaussian-splatting",
        "computer-vision",
        "spatiotemporal"
      ],
      "id": 42
    },
    {
      "name": "HippoRAG",
      "one_line_profile": "Neurobiologically inspired RAG framework for long-term memory integration",
      "detailed_description": "A novel RAG framework inspired by human long-term memory (hippocampal indexing theory) that enables LLMs to continuously integrate knowledge across external documents using Knowledge Graphs and Personalized PageRank.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag",
        "knowledge_integration"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/OSU-NLP-Group/HippoRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "knowledge-graph",
        "long-term-memory",
        "nlp"
      ],
      "id": 43
    },
    {
      "name": "UltraRAG",
      "one_line_profile": "Low-code framework for building complex RAG pipelines",
      "detailed_description": "A framework for building advanced Retrieval-Augmented Generation (RAG) pipelines, supporting complex information retrieval and generation tasks, suitable for scientific knowledge management systems.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag",
        "pipeline_construction"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenBMB/UltraRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "pipeline",
        "llm",
        "retrieval"
      ],
      "id": 44
    },
    {
      "name": "Ask-Anything",
      "one_line_profile": "Multimodal ChatGPT for video understanding and analysis",
      "detailed_description": "A multimodal AI tool (VideoChatGPT) that extends ChatGPT capabilities to video understanding, allowing users to query and analyze video content, applicable in multimodal scientific data analysis.",
      "domains": [
        "Sci Knowledge"
      ],
      "subtask_category": [
        "multimodal_analysis",
        "video_understanding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/Ask-Anything",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multimodal",
        "video-understanding",
        "chatgpt",
        "visual-qa"
      ],
      "id": 45
    },
    {
      "name": "InternGPT",
      "one_line_profile": "Interactive multimodal AI platform for model showcasing and editing",
      "detailed_description": "An open-source demo platform (iGPT) supporting various multimodal AI models like DragGAN, ChatGPT, and ImageBind, facilitating interactive image editing and multimodal chat for research demonstration and experimentation.",
      "domains": [
        "Sci Knowledge"
      ],
      "subtask_category": [
        "multimodal_interaction",
        "visualization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/InternGPT",
      "help_website": [
        "http://igpt.opengvlab.com"
      ],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "interactive-demo",
        "image-editing",
        "llm"
      ],
      "id": 46
    },
    {
      "name": "EasyDetect",
      "one_line_profile": "Hallucination detection framework for Large Language Models",
      "detailed_description": "An easy-to-use framework designed to detect hallucinations in Large Language Models (LLMs), providing tools for evaluating and improving the reliability of generative AI in scientific contexts.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenKG-ORG/EasyDetect",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination-detection",
        "llm",
        "evaluation",
        "reliability"
      ],
      "id": 47
    },
    {
      "name": "KAG",
      "one_line_profile": "Logical form-guided reasoning and retrieval framework",
      "detailed_description": "A framework combining OpenSPG engine and LLMs for logical reasoning and factual Q&A over professional domain knowledge bases, addressing limitations of vector-based RAG in scientific reasoning.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "reasoning",
        "retrieval",
        "qa"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenSPG/KAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "reasoning",
        "rag",
        "logical-form"
      ],
      "id": 48
    },
    {
      "name": "local-rag-llamaindex",
      "one_line_profile": "Local RAG assistant for navigating research papers",
      "detailed_description": "A local RAG implementation using LlamaIndex designed to assist researchers in quickly navigating and querying research papers, ensuring data privacy and efficient literature review.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "navigation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Otman404/local-rag-llamaindex",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "llamaindex",
        "research-assistant",
        "local-deployment"
      ],
      "id": 49
    },
    {
      "name": "ollama-deep-researcher-ts",
      "one_line_profile": "Local web research and report writing assistant",
      "detailed_description": "A fully local web research and report writing assistant powered by Ollama, designed to automate the process of gathering information and synthesizing research reports.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_search",
        "report_generation"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/PacoVK/ollama-deep-researcher-ts",
      "help_website": [],
      "license": "Unlicense",
      "tags": [
        "research-assistant",
        "ollama",
        "automation",
        "report-writing"
      ],
      "id": 50
    },
    {
      "name": "ITFormer",
      "one_line_profile": "Framework for temporal-textual multimodal question answering",
      "detailed_description": "Implementation of ITFormer, a framework for temporal-textual multimodal question answering (QA), enabling complex reasoning over multimodal data with temporal context.",
      "domains": [
        "Sci Knowledge"
      ],
      "subtask_category": [
        "multimodal_qa",
        "reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Pandalin98/ITFormer-ICML25",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multimodal",
        "qa",
        "temporal-reasoning",
        "transformer"
      ],
      "id": 51
    },
    {
      "name": "LatteReview",
      "one_line_profile": "Automated systematic literature review agent",
      "detailed_description": "A low-code Python package designed to automate systematic literature review processes through AI-powered agents, facilitating the screening and synthesis of research papers.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "automation"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/PouriaRouzrokh/LatteReview",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "literature-review",
        "agent",
        "automation",
        "systematic-review"
      ],
      "id": 52
    },
    {
      "name": "ScholiumAI",
      "one_line_profile": "AI research assistant for scientific literature",
      "detailed_description": "An AI-powered research assistant designed to help researchers interact with and extract information from scientific literature.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "research_assistant"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/QDScholium/ScholiumAI",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "research-assistant",
        "ai",
        "literature"
      ],
      "id": 53
    },
    {
      "name": "quantcoder-cli",
      "one_line_profile": "CLI tool to transform research papers into trading algorithms",
      "detailed_description": "An AI-powered command-line interface that utilizes GPT-4 to parse trading research papers and convert them into executable QuantConnect algorithms, automating the literature-to-code workflow.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_parsing",
        "code_generation"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/SL-Mar/quantcoder-cli",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cli",
        "research-to-code",
        "quant",
        "llm"
      ],
      "id": 54
    },
    {
      "name": "ragflow-upload",
      "one_line_profile": "Automated document uploader for RagFlow knowledge bases",
      "detailed_description": "A utility tool designed to batch upload and parse documents into the RagFlow knowledge base, streamlining the data ingestion process for RAG systems.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "data_ingestion",
        "knowledge_base_management"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/Samge0/ragflow-upload",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ragflow",
        "document-upload",
        "automation"
      ],
      "id": 55
    },
    {
      "name": "EmbedAI",
      "one_line_profile": "Private document interaction application using GPT",
      "detailed_description": "A desktop application enabling private interaction with local documents via GPT models, ensuring data privacy while performing retrieval-augmented generation tasks.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "document_qa",
        "rag"
      ],
      "application_level": "application",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/SamurAIGPT/EmbedAI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "privacy",
        "document-chat",
        "gpt",
        "desktop-app"
      ],
      "id": 56
    },
    {
      "name": "GPT-Agent",
      "one_line_profile": "CAMEL role-playing agent framework",
      "detailed_description": "An implementation of the CAMEL (Communicative Agents for \"Mind\" Exploration of Large Scale Society) framework, enabling autonomous multi-agent collaboration for complex task solving.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "agent_simulation",
        "multi_agent_collaboration"
      ],
      "application_level": "framework",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/SamurAIGPT/GPT-Agent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent",
        "camel",
        "multi-agent",
        "llm"
      ],
      "id": 57
    },
    {
      "name": "RAG-Performance",
      "one_line_profile": "Benchmarking tool for RAG solution throughput and latency",
      "detailed_description": "A toolkit for measuring and evaluating the performance metrics (throughput and latency) of various Retrieval-Augmented Generation (RAG) solutions.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_evaluation"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/SciPhi-AI/RAG-Performance",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "benchmark",
        "latency",
        "throughput"
      ],
      "id": 58
    },
    {
      "name": "SciPhi Synthesizer",
      "one_line_profile": "LLM framework for RAG and synthetic data creation",
      "detailed_description": "A multi-purpose Large Language Model framework designed to facilitate Retrieval-Augmented Generation (RAG) workflows and the generation of synthetic datasets for training and evaluation.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "synthetic_data_generation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/SciPhi-AI/synthesizer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "rag",
        "data-generation"
      ],
      "id": 59
    },
    {
      "name": "DeepLiterature",
      "one_line_profile": "Open-source intelligent research assistant",
      "detailed_description": "A comprehensive research assistant tool integrating search, code execution, link resolution, and information expansion to support scientific research workflows.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_search",
        "research_assistant"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/ScienceOne-AI/DeepLiterature",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "research-assistant",
        "literature-review",
        "automation"
      ],
      "id": 60
    },
    {
      "name": "ResearchGPT",
      "one_line_profile": "Intelligent research assistant for literature analysis",
      "detailed_description": "An AI assistant designed to help researchers analyze literature, identify research gaps, design experiments, and draft papers using LLMs.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_analysis",
        "paper_writing"
      ],
      "application_level": "application",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/Scodive/ResearchGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "research-assistant",
        "gpt",
        "academic-writing"
      ],
      "id": 61
    },
    {
      "name": "SeekStorm",
      "one_line_profile": "Sub-millisecond full-text search library and server",
      "detailed_description": "A high-performance full-text search library and multi-tenancy server written in Rust, suitable for indexing and retrieving large-scale scientific literature and text data.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "full_text_search",
        "indexing"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/SeekStorm/SeekStorm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "search-engine",
        "rust",
        "information-retrieval"
      ],
      "id": 62
    },
    {
      "name": "chatWeb",
      "one_line_profile": "Web crawler and document parser for QA",
      "detailed_description": "A tool capable of crawling web pages and parsing PDF/DOCX/TXT files to extract content and perform question answering or summarization.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "web_crawling",
        "document_parsing",
        "summarization"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/SkywalkerDarren/chatWeb",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "crawler",
        "parser",
        "qa",
        "summarization"
      ],
      "id": 63
    },
    {
      "name": "solace-agent-mesh",
      "one_line_profile": "Event-driven multi-agent orchestration framework",
      "detailed_description": "A framework for building and orchestrating multi-agent AI systems using an event-driven architecture, enabling integration with real-world data sources for complex workflows.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "agent_orchestration",
        "workflow_automation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/SolaceLabs/solace-agent-mesh",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "event-driven",
        "orchestration"
      ],
      "id": 64
    },
    {
      "name": "pdfchat",
      "one_line_profile": "Local PDF chat application with Mistral 7B",
      "detailed_description": "A local application leveraging Mistral 7B, Langchain, and Ollama to enable chat-based interaction with PDF documents.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "document_qa",
        "local_inference"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/SonicWarrior1/pdfchat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf",
        "chat",
        "local-llm",
        "mistral"
      ],
      "id": 65
    },
    {
      "name": "AdalFlow",
      "one_line_profile": "Library to build and auto-optimize LLM applications",
      "detailed_description": "A library designed to assist developers in building and automatically optimizing Large Language Model (LLM) applications, suitable for constructing scientific RAG pipelines.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "llm_optimization",
        "application_building"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SylphAI-Inc/AdalFlow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "optimization",
        "pipeline"
      ],
      "id": 66
    },
    {
      "name": "TaskingAI",
      "one_line_profile": "Open source platform for AI-native application development",
      "detailed_description": "A platform providing infrastructure for building AI-native applications, including tools for model inference, retrieval, and agent management.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "ai_development",
        "agent_management",
        "retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/TaskingAI/TaskingAI",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-platform",
        "agent",
        "retrieval"
      ],
      "id": 67
    },
    {
      "name": "WeKnora",
      "one_line_profile": "LLM-powered framework for deep document understanding and RAG",
      "detailed_description": "A framework leveraging LLMs for deep document understanding, semantic retrieval, and context-aware question answering using the RAG paradigm.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "document_understanding",
        "semantic_retrieval",
        "rag"
      ],
      "application_level": "framework",
      "primary_language": "Go",
      "repo_url": "https://github.com/Tencent/WeKnora",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "document-understanding",
        "llm"
      ],
      "id": 68
    },
    {
      "name": "chipper",
      "one_line_profile": "AI interface for RAG using Ollama and Haystack",
      "detailed_description": "An AI interface designed for experimentation with local LLMs (Ollama) and RAG pipelines (Haystack), facilitating custom AI workflows.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_interface",
        "local_llm"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/TilmanGriesel/chipper",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ollama",
        "haystack",
        "rag",
        "ui"
      ],
      "id": 69
    },
    {
      "name": "Stormwater Management Model (SWMM)",
      "one_line_profile": "Dynamic hydrology-hydraulic water quality simulation model",
      "detailed_description": "A dynamic rainfall-runoff simulation model used for single event or long-term (continuous) simulation of runoff quantity and quality from primarily urban areas.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "hydrology_simulation",
        "water_quality_modeling"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/USEPA/Stormwater-Management-Model",
      "help_website": [
        "https://www.epa.gov/water-research/storm-water-management-model-swmm"
      ],
      "license": null,
      "tags": [
        "hydrology",
        "simulation",
        "epa",
        "water-quality"
      ],
      "id": 70
    },
    {
      "name": "unstructured",
      "one_line_profile": "ETL tool for processing unstructured documents",
      "detailed_description": "An open-source library for ingesting and processing unstructured documents (PDF, HTML, Word, etc.) into structured formats for use with Large Language Models and data processing pipelines.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "document_parsing",
        "etl",
        "data_cleaning"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/Unstructured-IO/unstructured",
      "help_website": [
        "https://unstructured.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "etl",
        "nlp",
        "pdf-parsing",
        "preprocessing"
      ],
      "id": 71
    },
    {
      "name": "Researcher",
      "one_line_profile": "Automated research assistant for query answering with citations",
      "detailed_description": "A tool that leverages Google Search and GPT-3 to provide concise answers to research queries, explicitly including citations to ensure evidence-based responses.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_search",
        "citation_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/VikParuchuri/researcher",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "literature-search",
        "citations",
        "rag",
        "research-assistant"
      ],
      "id": 72
    },
    {
      "name": "Cyber Doctor (Cyber Huatuo)",
      "one_line_profile": "Medical agent framework based on LLM and Knowledge Graph",
      "detailed_description": "A framework for building personal doctor agents using multimodal LLMs and medical knowledge graphs. It supports disease preliminary diagnosis, medical record analysis, and professional Q&A.",
      "domains": [
        "Sci Knowledge",
        "Medical AI"
      ],
      "subtask_category": [
        "medical_diagnosis",
        "clinical_decision_support"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Warma10032/cyber-doctor",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "medical-ai",
        "knowledge-graph",
        "diagnosis",
        "llm-agent"
      ],
      "id": 73
    },
    {
      "name": "SAG",
      "one_line_profile": "SQL-driven RAG engine with automatic knowledge graph construction",
      "detailed_description": "A RAG engine that uses SQL to drive retrieval and automatically builds knowledge graphs during querying, facilitating structured knowledge management and retrieval for complex queries.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "rag"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zleap-AI/SAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "knowledge-graph",
        "sql",
        "retrieval"
      ],
      "id": 74
    },
    {
      "name": "AutoSurveyGPT",
      "one_line_profile": "Automated literature survey and review assistant",
      "detailed_description": "An intelligent research assistant that leverages GPT-3.5/4 to automatically find, analyze, and rank relevant academic papers from Google Scholar based on user queries, generating literature reviews.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "paper_ranking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/a554b554/AutoSurveyGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "literature-survey",
        "google-scholar",
        "automated-review",
        "gpt"
      ],
      "id": 75
    },
    {
      "name": "LARS",
      "one_line_profile": "Local LLM application for document QA with detailed citations",
      "detailed_description": "A local RAG application designed to run LLMs on personal devices with user documents, specifically focusing on generating detailed citations in responses to ensure research integrity.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "local_rag",
        "citation_generation"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/abgulati/LARS",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "local-llm",
        "citations",
        "rag",
        "privacy"
      ],
      "id": 76
    },
    {
      "name": "DeepLake",
      "one_line_profile": "Database for AI data (vectors, images, videos) management",
      "detailed_description": "A data lake for deep learning that allows storing, querying, versioning, and visualizing complex AI data (vectors, images, text). It streamlines data streaming to PyTorch/TensorFlow for scientific modeling.",
      "domains": [
        "Sci Data",
        "AI Infrastructure"
      ],
      "subtask_category": [
        "data_management",
        "vector_storage"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/activeloopai/deeplake",
      "help_website": [
        "https://activeloop.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "database",
        "deep-learning",
        "vector-store",
        "data-lake"
      ],
      "id": 77
    },
    {
      "name": "OpenResearchAssistant",
      "one_line_profile": "Tool for discovering insights from research paper corpora",
      "detailed_description": "An automated tool designed to analyze corpora of research papers to discover insights, aiding researchers in understanding large collections of scientific literature.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "insight_discovery",
        "literature_analysis"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/ai8hyf/OpenResearchAssistant",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "literature-analysis",
        "insight-discovery",
        "research-assistant"
      ],
      "id": 78
    },
    {
      "name": "singleCellHaystack",
      "one_line_profile": "Method for finding differentially active genes in single-cell transcriptome data",
      "detailed_description": "A bioinformatics tool for finding surprising 'needles' (genes) in 'haystacks' (single-cell transcriptome data) by detecting genes with non-random spatial distributions or differential expression patterns.",
      "domains": [
        "Bioinformatics",
        "Single Cell"
      ],
      "subtask_category": [
        "differential_expression",
        "spatial_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/alexisvdb/singleCellHaystack",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "single-cell",
        "transcriptomics",
        "gene-expression",
        "bioinformatics"
      ],
      "id": 79
    },
    {
      "name": "Zotero Review Assistant",
      "one_line_profile": "Zotero plugin for streamlining systematic literature reviews",
      "detailed_description": "A plugin for Zotero that helps researchers organize and manage articles specifically for review research, streamlining the evidence synthesis process by providing tools for tagging, sorting, and tracking review progress.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "evidence_synthesis",
        "reference_management"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/alima-webdev/zotero-review-assistant",
      "help_website": [],
      "license": null,
      "tags": [
        "zotero",
        "systematic-review",
        "literature-management",
        "plugin"
      ],
      "id": 80
    },
    {
      "name": "RAGChecker",
      "one_line_profile": "Diagnostic framework for analyzing Retrieval-Augmented Generation systems",
      "detailed_description": "A fine-grained framework for diagnosing RAG systems, providing metrics and tools to evaluate the quality of retrieval and generation. It is essential for validating the reliability of literature-based RAG systems in scientific workflows.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "quality_control",
        "model_diagnostics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/amazon-science/RAGChecker",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "metrics",
        "hallucination-detection"
      ],
      "id": 81
    },
    {
      "name": "GPT Researcher",
      "one_line_profile": "Autonomous agent for comprehensive online research and report generation",
      "detailed_description": "An LLM-based autonomous agent that conducts deep research on a given topic by scraping web sources, aggregating information, and generating detailed reports with citations. It automates the literature review and information synthesis process.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "information_retrieval",
        "report_generation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/assafelovic/gpt-researcher",
      "help_website": [
        "https://gptr.dev"
      ],
      "license": "Apache-2.0",
      "tags": [
        "agent",
        "autonomous-research",
        "web-scraping",
        "citations"
      ],
      "id": 82
    },
    {
      "name": "DeerFlow",
      "one_line_profile": "Community-driven framework for deep research and agentic workflows",
      "detailed_description": "A framework combining language models with tools like web search and crawling to perform deep research tasks, automating the collection and synthesis of information for scientific or general inquiry.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "deep_research",
        "information_synthesis",
        "agentic_workflow"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bytedance/deer-flow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent",
        "deep-research",
        "workflow-automation"
      ],
      "id": 83
    },
    {
      "name": "Langchain-Chatchat",
      "one_line_profile": "Local knowledge-based LLM RAG and Agent application framework",
      "detailed_description": "A RAG and Agent application based on Langchain and local LLMs (like ChatGLM, Qwen, Llama), enabling offline knowledge base construction and question answering.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "knowledge_base_qa"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/chatchat-space/Langchain-Chatchat",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "llm",
        "knowledge-base",
        "agent"
      ],
      "id": 84
    },
    {
      "name": "langchain-chat-with-documents",
      "one_line_profile": "Application to chat with documents using ChatGPT and LangChain",
      "detailed_description": "A tool enabling users to interact with documents (PDF, DOCX, TXT) via a chat interface powered by ChatGPT and LangChain, facilitating document analysis and information retrieval.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "document_qa",
        "rag_application"
      ],
      "application_level": "application",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/ciocan/langchain-chat-with-documents",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "chat-with-pdf",
        "langchain"
      ],
      "id": 85
    },
    {
      "name": "Eino",
      "one_line_profile": "Ultimate LLM/AI application development framework in Golang",
      "detailed_description": "A framework for building LLM and AI applications in Golang, providing components for orchestration, retrieval, and agent construction, suitable for high-performance RAG systems.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "agent_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Go",
      "repo_url": "https://github.com/cloudwego/eino",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "golang",
        "llm-framework",
        "rag"
      ],
      "id": 86
    },
    {
      "name": "CocoIndex",
      "one_line_profile": "High-performance data transformation framework for AI",
      "detailed_description": "A data transformation framework designed for AI workflows, supporting incremental processing and high-performance ETL for RAG and vector search pipelines.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "data_processing",
        "etl_for_rag"
      ],
      "application_level": "workflow",
      "primary_language": "Rust",
      "repo_url": "https://github.com/cocoindex-io/cocoindex",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "etl",
        "rag",
        "data-pipeline"
      ],
      "id": 87
    },
    {
      "name": "CodeFuse-muAgent",
      "one_line_profile": "Multi-agent framework driven by Knowledge Graph engine",
      "detailed_description": "An agent framework that integrates Knowledge Graph engines to drive multi-agent collaboration, enhancing reasoning and information retrieval capabilities for complex tasks.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "agent_framework",
        "knowledge_graph_reasoning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/codefuse-ai/CodeFuse-muAgent",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "multi-agent",
        "knowledge-graph",
        "llm"
      ],
      "id": 88
    },
    {
      "name": "CodeFuse-ChatBot",
      "one_line_profile": "Intelligent assistant for SDLC with Multi-Agent and RAG support",
      "detailed_description": "A chatbot framework designed for the software development lifecycle, incorporating Multi-Agent collaboration and RAG for code and document repositories.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_chatbot",
        "agent_framework"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/codefuse-ai/codefuse-chatbot",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "chatbot",
        "rag",
        "devops-agent"
      ],
      "id": 89
    },
    {
      "name": "Ollama Ebook Summary",
      "one_line_profile": "LLM-based tool for long text and ebook summarization",
      "detailed_description": "A tool utilizing Ollama and LLMs to generate comprehensive bulleted summaries for long texts and ebooks, aiding in literature review and knowledge extraction.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "summarization",
        "literature_analysis"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/cognitivetech/ollama-ebook-summary",
      "help_website": [],
      "license": null,
      "tags": [
        "summarization",
        "ollama",
        "ebook"
      ],
      "id": 90
    },
    {
      "name": "Opik",
      "one_line_profile": "Platform for debugging, evaluating, and monitoring LLM/RAG applications",
      "detailed_description": "A comprehensive platform for tracing, automated evaluation, and monitoring of LLM applications, RAG systems, and agentic workflows, ensuring reliability and performance.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "evaluation",
        "monitoring",
        "rag_optimization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/comet-ml/opik",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "rag-monitoring",
        "observability"
      ],
      "id": 91
    },
    {
      "name": "Open Co-Scientist Agents",
      "one_line_profile": "Implementation of AI co-scientist agents for research automation",
      "detailed_description": "An open-source implementation of AI co-scientist agents using LangGraph and GPT Researcher, designed to assist in scientific research tasks such as hypothesis generation and literature review.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "scientific_agent",
        "literature_review"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/conradry/open-coscientist-agents",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ai-scientist",
        "agent",
        "research-automation"
      ],
      "id": 92
    },
    {
      "name": "Coze-Loop",
      "one_line_profile": "Next-generation AI Agent optimization platform",
      "detailed_description": "A platform for the full-lifecycle management of AI agents, including development, debugging, evaluation, and monitoring, aimed at optimizing agent performance.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "agent_optimization",
        "agent_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/coze-dev/coze-loop",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent-platform",
        "optimization",
        "llm"
      ],
      "id": 93
    },
    {
      "name": "UQLM",
      "one_line_profile": "Uncertainty Quantification for Language Models",
      "detailed_description": "A Python package for uncertainty quantification-based hallucination detection in Large Language Models, enhancing the reliability of LLM outputs in scientific and other critical contexts.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "uncertainty_quantification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cvs-health/uqlm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "uncertainty-quantification",
        "hallucination",
        "llm-reliability"
      ],
      "id": 94
    },
    {
      "name": "LibreChat",
      "one_line_profile": "Advanced LLM interface with RAG and Agent capabilities",
      "detailed_description": "A comprehensive chat platform supporting multiple LLM providers, Agents, and RAG, offering features like code interpretation and plugin integration for advanced data interaction.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_platform",
        "llm_interface"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/danny-avila/LibreChat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chat-ui",
        "rag",
        "multi-model"
      ],
      "id": 95
    },
    {
      "name": "RAG Chatbot",
      "one_line_profile": "Local RAG chatbot for multiple PDFs",
      "detailed_description": "A chatbot application that enables users to chat with multiple PDF documents locally using RAG technology, facilitating private document analysis.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "document_qa",
        "rag_application"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/datvodinh/rag-chatbot",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "pdf-chat",
        "local-llm"
      ],
      "id": 96
    },
    {
      "name": "Neural RDF Verbalizer",
      "one_line_profile": "Multilingual RDF to text generation tool",
      "detailed_description": "A tool for verbalizing RDF triples into natural language text, supporting multilingual output, useful for interpreting Knowledge Graph data.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "knowledge_graph_verbalization",
        "nlg"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dbpedia/neural-rdf-verbalizer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rdf",
        "knowledge-graph",
        "nlg"
      ],
      "id": 97
    },
    {
      "name": "Hayhooks",
      "one_line_profile": "Deployment tool for Haystack pipelines as REST APIs",
      "detailed_description": "A utility to easily deploy Haystack RAG pipelines as REST APIs and MCP Tools, facilitating the integration of RAG workflows into other applications.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "pipeline_deployment",
        "rag_service"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepset-ai/hayhooks",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "haystack",
        "deployment",
        "rest-api"
      ],
      "id": 98
    },
    {
      "name": "Haystack",
      "one_line_profile": "AI orchestration framework for RAG and LLM applications",
      "detailed_description": "A powerful framework for building production-ready LLM applications, specializing in Retrieval-Augmented Generation (RAG), semantic search, and question answering pipelines.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "semantic_search"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepset-ai/haystack",
      "help_website": [
        "https://haystack.deepset.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "llm-framework",
        "orchestration"
      ],
      "id": 99
    },
    {
      "name": "Haystack Core Integrations",
      "one_line_profile": "Core integration packages for Haystack framework",
      "detailed_description": "A collection of additional components and document stores that extend the core capabilities of the Haystack framework, enabling integration with various vector databases and model providers.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_components",
        "integration_library"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepset-ai/haystack-core-integrations",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "haystack",
        "integrations",
        "rag"
      ],
      "id": 100
    },
    {
      "name": "Haystack Experimental",
      "one_line_profile": "Experimental features and components for Haystack",
      "detailed_description": "A library containing experimental components and features for the Haystack framework, allowing users to test cutting-edge RAG and LLM functionalities.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag_components",
        "experimental_features"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepset-ai/haystack-experimental",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "haystack",
        "experimental",
        "rag"
      ],
      "id": 101
    },
    {
      "name": "Denser Chat",
      "one_line_profile": "Chat with PDF files with source highlights",
      "detailed_description": "An application enabling users to chat with PDF documents, featuring source highlighting to ground answers in the original text, enhancing verification and evidence tracking.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "document_qa",
        "evidence_highlighting"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/denser-org/denser-chat",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "pdf-chat",
        "source-highlighting"
      ],
      "id": 102
    },
    {
      "name": "Deep Research",
      "one_line_profile": "AI-powered research assistant for iterative deep research and synthesis",
      "detailed_description": "An autonomous agentic workflow that performs deep research on any topic by combining search engines, web scraping, and LLMs. It iteratively refines research directions, gathers evidence, and synthesizes findings, directly supporting scientific literature review and knowledge discovery.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "knowledge_synthesis",
        "evidence_gathering"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/dzhng/deep-research",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "research-agent",
        "literature-review",
        "autonomous-agent",
        "rag"
      ],
      "id": 103
    },
    {
      "name": "GPT-4o Research Assistant",
      "one_line_profile": "Automated academic paper research assistant using ArXiv and GPT-4o",
      "detailed_description": "A specialized tool designed to assist with academic research by searching ArXiv, identifying promising papers, downloading and extracting content, and generating summaries. It automates the evidence gathering and literature screening process.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_search",
        "paper_summarization",
        "arxiv_mining"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/echohive42/GPT-4o-Research-assistant",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arxiv",
        "research-assistant",
        "literature-mining",
        "summarization"
      ],
      "id": 104
    },
    {
      "name": "Open Researcher",
      "one_line_profile": "Visual AI research assistant with real-time analysis and automatic citations",
      "detailed_description": "A visual research assistant that leverages LLMs (Claude) and web crawling (Firecrawl) to perform research tasks. It features split-view analysis and automatic citation generation, directly supporting the evidence chain and grounding in scientific research.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "citation_generation",
        "evidence_grounding"
      ],
      "application_level": "application",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/firecrawl/open-researcher",
      "help_website": [],
      "license": null,
      "tags": [
        "research-assistant",
        "citations",
        "grounding",
        "web-research"
      ],
      "id": 105
    },
    {
      "name": "Deep Research Agent",
      "one_line_profile": "Agentic deep research assistant for automated literature review and synthesis",
      "detailed_description": "An AI agent designed to conduct deep research by searching, reading, and synthesizing information from multiple sources, automating the literature review process similar to OpenAI's Deep Research.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "evidence_synthesis",
        "automated_research"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/grapeot/deep_research_agent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent",
        "literature-review",
        "research-assistant",
        "rag"
      ],
      "id": 106
    },
    {
      "name": "RAGFlow",
      "one_line_profile": "Retrieval-Augmented Generation engine with deep document understanding",
      "detailed_description": "A RAG engine that combines retrieval-augmented generation with agent capabilities, featuring a specialized 'DeepDoc' module for parsing complex scientific documents (PDFs, tables, layouts) to build high-quality evidence chains.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "document_parsing",
        "knowledge_base_management",
        "rag_pipeline",
        "evidence_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/infiniflow/ragflow",
      "help_website": [
        "https://ragflow.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "pdf-parsing",
        "knowledge-graph",
        "document-understanding"
      ],
      "id": 107
    },
    {
      "name": "OntologyRAG",
      "one_line_profile": "Biomedical code mapping with RAG and ontology knowledge graphs",
      "detailed_description": "A specialized tool for biomedical code mapping that leverages Retrieval-Augmented Generation (RAG) and Ontology Knowledge Graphs to improve the accuracy of mapping medical text to standardized codes.",
      "domains": [
        "G1-04",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "entity_normalization",
        "biomedical_mapping",
        "ontology_alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/iqvianlp/ontologyRAG",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "biomedical",
        "ontology",
        "rag",
        "normalization"
      ],
      "id": 108
    },
    {
      "name": "Chat With Your Docs",
      "one_line_profile": "RAG-based tool to converse with documents (PDFs, web pages) using various LLMs",
      "detailed_description": "A Python-based application that enables users to interact with documents such as PDFs and web pages using advanced LLMs like Mistral, Llama2, and GPT. It facilitates information extraction and insight generation from scientific literature.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "document_qa",
        "information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jorge-armando-navarro-flores/chat_with_your_docs",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "pdf-chat",
        "llm"
      ],
      "id": 109
    },
    {
      "name": "IncarnaMind",
      "one_line_profile": "Multi-document chat tool supporting PDF/TXT and multiple LLM backends",
      "detailed_description": "A tool designed to connect and chat with multiple documents simultaneously using GPT-4, Claude, or local open-source LLMs. It supports RAG workflows for processing research documents.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "document_qa",
        "literature_review"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/junruxiong/IncarnaMind",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "multi-doc-qa",
        "llm"
      ],
      "id": 110
    },
    {
      "name": "Gemini PDF Chatbot",
      "one_line_profile": "Streamlit application for chatting with multiple PDFs using Gemini AI",
      "detailed_description": "A user-friendly chatbot interface built with Streamlit that allows users to upload multiple PDF files and engage in natural language conversations to extract context-aware responses, suitable for literature review.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "document_qa",
        "literature_review"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kaifcoder/gemini_multipdf_chat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "streamlit",
        "gemini",
        "pdf-chat"
      ],
      "id": 111
    },
    {
      "name": "Khoj",
      "one_line_profile": "Self-hostable AI second brain for searching and chatting with local docs and web",
      "detailed_description": "An open-source, self-hostable AI assistant that acts as a second brain. It indexes local documents (PDFs, markdown) and web content, allowing researchers to perform deep semantic search and RAG-based Q&A.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "literature_search",
        "knowledge_management",
        "document_qa"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/khoj-ai/khoj",
      "help_website": [
        "https://khoj.dev"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "second-brain",
        "rag",
        "search"
      ],
      "id": 112
    },
    {
      "name": "Open Paper",
      "one_line_profile": "Workbench for managing research library and conducting AI-assisted literature reviews",
      "detailed_description": "A dedicated tool for managing research papers, offering features to read, annotate, and understand papers. It includes an AI assistant to help conduct literature reviews and synthesize information from the library.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "reference_management"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/khoj-ai/openpaper",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "literature-review",
        "paper-management",
        "ai-assistant"
      ],
      "id": 113
    },
    {
      "name": "Kreuzberg",
      "one_line_profile": "Polyglot document intelligence framework for extracting text from PDFs and images",
      "detailed_description": "A document intelligence library that provides text, metadata, and structured information extraction from PDFs, Office documents, and images. It serves as a critical preprocessing tool for scientific literature parsing and RAG pipelines.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "document_parsing",
        "text_extraction"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/kreuzberg-dev/kreuzberg",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ocr",
        "pdf-parsing",
        "document-intelligence"
      ],
      "id": 114
    },
    {
      "name": "Swarms",
      "one_line_profile": "Enterprise-grade multi-agent orchestration framework",
      "detailed_description": "A framework for building and orchestrating multi-agent systems. In the context of scientific research, it enables the creation of autonomous research agents that can perform complex tasks like literature search, synthesis, and reasoning.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "agent_orchestration",
        "autonomous_research"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kyegomez/swarms",
      "help_website": [
        "https://swarms.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "agents",
        "framework"
      ],
      "id": 115
    },
    {
      "name": "DeepAgents",
      "one_line_profile": "Agent harness for complex agentic tasks built on LangChain",
      "detailed_description": "A framework equipped with planning tools and filesystem backends to spawn subagents, designed to handle complex tasks which can include deep research and evidence gathering.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "agent_orchestration",
        "task_planning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/langchain-ai/deepagents",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agents",
        "langchain",
        "planning"
      ],
      "id": 116
    },
    {
      "name": "LangChain",
      "one_line_profile": "Framework for developing applications powered by language models",
      "detailed_description": "The foundational framework for building RAG applications and agents. It provides the necessary abstractions for document loading, text splitting, embedding, and vector storage, enabling scientific literature analysis and QA systems.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "agent_development"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/langchain-ai/langchain",
      "help_website": [
        "https://python.langchain.com"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "llm",
        "framework"
      ],
      "id": 117
    },
    {
      "name": "LangChain.js",
      "one_line_profile": "JavaScript framework for building context-aware reasoning applications",
      "detailed_description": "The JavaScript/TypeScript implementation of the LangChain framework, enabling the development of RAG and agentic applications in Node.js and web environments.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "agent_development"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/langchain-ai/langchainjs",
      "help_website": [
        "https://js.langchain.com"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "javascript",
        "framework"
      ],
      "id": 118
    },
    {
      "name": "Local Deep Researcher",
      "one_line_profile": "Fully local web research and report writing assistant",
      "detailed_description": "An AI agent designed to perform deep web research and generate reports locally. It automates the process of gathering evidence and synthesizing information from online sources.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "web_research",
        "report_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/langchain-ai/local-deep-researcher",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "research-agent",
        "local-llm",
        "automation"
      ],
      "id": 119
    },
    {
      "name": "LangChain4j",
      "one_line_profile": "Java library for integrating LLMs and building RAG applications",
      "detailed_description": "The Java implementation of the LangChain ecosystem, simplifying the integration of LLMs and vector databases for Java-based scientific applications and RAG pipelines.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "agent_development"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/langchain4j/langchain4j",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "java",
        "rag",
        "llm"
      ],
      "id": 120
    },
    {
      "name": "Bricky",
      "one_line_profile": "Haystack/OpenAI based chatbot for curating custom knowledge bases",
      "detailed_description": "A chatbot tool that uses Haystack and OpenAI to curate and interact with a custom knowledge base, facilitating information retrieval from specific document sets.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "knowledge_base_curation",
        "document_qa"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/larsbaunwall/bricky",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "haystack",
        "chatbot",
        "knowledge-base"
      ],
      "id": 121
    },
    {
      "name": "LaVague",
      "one_line_profile": "Large Action Model framework to develop AI Web Agents",
      "detailed_description": "A framework for building AI web agents that can automate browser interactions. In a scientific context, it can be used to automate data collection, literature search, and interaction with web-based scientific databases.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "web_automation",
        "data_collection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lavague-ai/LaVague",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "web-agent",
        "automation",
        "lam"
      ],
      "id": 122
    },
    {
      "name": "PaperQA Zotero",
      "one_line_profile": "LLM tool to answer questions from Zotero documents",
      "detailed_description": "A tool that integrates with Zotero to allow users to perform Question Answering (QA) on their reference library using LLMs, directly supporting literature review workflows.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "reference_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lejacobroy/paperqa-zotero",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "zotero",
        "paper-qa",
        "rag"
      ],
      "id": 123
    },
    {
      "name": "ChatGPT Doc Translator",
      "one_line_profile": "Service to translate PDF, Word, and PPTX documents using GPT",
      "detailed_description": "A FastAPI-based service for translating various document formats. It aids in the preprocessing and accessibility of scientific literature across different languages.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "document_translation",
        "preprocessing"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/leogogog/chatgpt-doc-translator",
      "help_website": [],
      "license": null,
      "tags": [
        "translation",
        "pdf",
        "gpt"
      ],
      "id": 124
    },
    {
      "name": "Contextual Chunking Graph RAG",
      "one_line_profile": "Advanced retrieval system combining semantic search with knowledge graphs",
      "detailed_description": "A RAG implementation that utilizes contextual chunking and knowledge graphs to improve retrieval accuracy. It includes LLM-based answer checking and graph visualization for evidence verification.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "rag_implementation",
        "knowledge_graph_construction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lesteroliver911/contextual-chunking-graphpowered-rag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-rag",
        "contextual-chunking",
        "retrieval"
      ],
      "id": 125
    },
    {
      "name": "Aria AI Research Assistant",
      "one_line_profile": "AI Research Assistant powered by GPT models",
      "detailed_description": "A research assistant tool named Aria that leverages Large Language Models to assist with scientific research tasks, likely including literature query and summarization.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "research_assistant",
        "literature_review"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/lifan0127/ai-research-assistant",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "research-assistant",
        "gpt",
        "automation"
      ],
      "id": 126
    },
    {
      "name": "Chat With Your Doc",
      "one_line_profile": "Tool to chat with PDF/PPTX/DOCX using LangChain and Azure OpenAI",
      "detailed_description": "A document QA tool that supports multiple formats (PDF, PPTX, DOCX) and integrates with Azure OpenAI and LangChain to provide RAG-based interaction with user documents.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "document_qa",
        "rag_implementation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/linjungz/chat-with-your-doc",
      "help_website": [],
      "license": null,
      "tags": [
        "azure-openai",
        "langchain",
        "document-chat"
      ],
      "id": 127
    },
    {
      "name": "RAGAT",
      "one_line_profile": "Relation Aware Graph Attention Network for Knowledge Graph Completion",
      "detailed_description": "An implementation of the RAGAT model for Knowledge Graph Completion. It serves as a scientific modeling tool for inferring missing links in knowledge graphs, which is relevant to citation networks and evidence chains.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "knowledge_graph_completion",
        "scientific_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liuxiyang641/RAGAT",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "gnn",
        "link-prediction"
      ],
      "id": 128
    },
    {
      "name": "EmbedJs",
      "one_line_profile": "NodeJS RAG framework for LLMs and embeddings",
      "detailed_description": "A framework designed to simplify the creation of RAG applications in Node.js. It provides tools for working with LLMs and embeddings, facilitating the development of scientific text analysis tools in JS environments.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "embedding_management"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/llm-tools/embedJs",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nodejs",
        "rag",
        "embeddings"
      ],
      "id": 129
    },
    {
      "name": "LLMWare",
      "one_line_profile": "Unified framework for building enterprise RAG pipelines with specialized models",
      "detailed_description": "A comprehensive framework for building RAG pipelines, focusing on small, specialized models. It provides an integrated stack for parsing, indexing, and querying documents, suitable for secure and efficient scientific data processing.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "pipeline_orchestration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/llmware-ai/llmware",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "enterprise",
        "small-models"
      ],
      "id": 130
    },
    {
      "name": "ScienceQA",
      "one_line_profile": "Benchmark dataset and baseline models for multimodal science question answering",
      "detailed_description": "A large-scale multimodal science question answering dataset that annotates answers with lectures and explanations, designed to evaluate reasoning capabilities of AI models in scientific domains.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "question_answering",
        "multimodal_reasoning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/lupantech/ScienceQA",
      "help_website": [
        "https://scienceqa.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "benchmark",
        "multimodal",
        "science-qa"
      ],
      "id": 131
    },
    {
      "name": "FIRE",
      "one_line_profile": "Agent-style framework for fact-checking atomic claims",
      "detailed_description": "A lightweight framework for fact-checking atomic claims using iterative retrieval and verification, designed to reduce LLM and search costs while maintaining strong factuality performance.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "fact_checking",
        "evidence_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mbzuai-nlp/fire",
      "help_website": [],
      "license": null,
      "tags": [
        "fact-checking",
        "retrieval",
        "verification"
      ],
      "id": 132
    },
    {
      "name": "fid-med-eval",
      "one_line_profile": "Feature extraction metrics for generative medical imaging evaluation",
      "detailed_description": "A tool providing feature extraction methods and metrics (like FID) specifically calibrated for evaluating generative models in medical imaging.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "quality_control",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mckellwoodland/fid-med-eval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-imaging",
        "evaluation",
        "generative-models"
      ],
      "id": 133
    },
    {
      "name": "CoNLI",
      "one_line_profile": "Framework for ungrounded hallucination detection and reduction",
      "detailed_description": "A plug-and-play framework designed to detect and reduce ungrounded hallucinations in large language models, applicable to ensuring factual consistency in scientific text generation.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "factuality"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/CoNLI_hallucination",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination-detection",
        "nli",
        "factuality"
      ],
      "id": 134
    },
    {
      "name": "HaDes",
      "one_line_profile": "Token-level reference-free hallucination detection",
      "detailed_description": "A framework and benchmark for detecting hallucinations at the token level without references, useful for validating the accuracy of generated scientific content.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/HaDes",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "detection",
        "benchmark"
      ],
      "id": 135
    },
    {
      "name": "OpenKP",
      "one_line_profile": "Keyphrase extraction dataset and models for document understanding",
      "detailed_description": "A large-scale dataset and baseline models for extracting salient keyphrases from documents, facilitating semantic document understanding and information retrieval in scientific and open domains.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "keyphrase_extraction",
        "parsing"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/OpenKP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "keyphrase-extraction",
        "nlp",
        "document-understanding"
      ],
      "id": 136
    },
    {
      "name": "A2rchi",
      "one_line_profile": "RAG framework specialized for scientific and academic applications",
      "detailed_description": "A general Retrieval-Augmented Generation (RAG) framework specifically designed to handle the requirements of scientific and academic data, developed with institutional backing.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "rag",
        "knowledge_retrieval"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/mit-submit/A2rchi",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "science",
        "academic"
      ],
      "id": 137
    },
    {
      "name": "ResearchGPT",
      "one_line_profile": "LLM-based research assistant for conversing with papers",
      "detailed_description": "A tool that enables researchers to have interactive conversations with research papers, facilitating information extraction and understanding of scientific literature.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_analysis",
        "qa"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/mukulpatnaik/researchgpt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "research-assistant",
        "pdf-chat",
        "literature-review"
      ],
      "id": 138
    },
    {
      "name": "LLM Graph Builder",
      "one_line_profile": "Tool to construct Knowledge Graphs from unstructured data using LLMs for GraphRAG",
      "detailed_description": "A Neo4j-based tool that leverages Large Language Models to extract nodes and relationships from unstructured text documents (PDFs, YouTube transcripts, Wikipedia) to build knowledge graphs, enabling GraphRAG applications.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "rag_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/neo4j-labs/llm-graph-builder",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "rag",
        "neo4j",
        "llm",
        "unstructured-data"
      ],
      "id": 139
    },
    {
      "name": "txtai",
      "one_line_profile": "All-in-one embeddings database and RAG framework for semantic search and LLM workflows",
      "detailed_description": "An open-source platform for semantic search, LLM orchestration, and language model workflows. It integrates vector indexes, graph networks, and relational databases to support advanced RAG and retrieval tasks.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "semantic_search",
        "rag_pipeline",
        "embeddings"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/neuml/txtai",
      "help_website": [
        "https://neuml.github.io/txtai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "semantic-search",
        "rag",
        "llm-orchestration",
        "embeddings",
        "vector-search"
      ],
      "id": 140
    },
    {
      "name": "KG2RAG",
      "one_line_profile": "Knowledge Graph-Guided Retrieval Augmented Generation framework",
      "detailed_description": "Implementation of a Knowledge Graph-Guided Retrieval Augmented Generation approach (NAACL 2025), designed to enhance LLM generation by retrieving structured knowledge from KGs.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "rag_pipeline",
        "knowledge_graph_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nju-websoft/KG2RAG",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "knowledge-graph",
        "rag",
        "retrieval-augmented-generation",
        "nlp"
      ],
      "id": 141
    },
    {
      "name": "Pautobot",
      "one_line_profile": "Private RAG assistant for document Q&A",
      "detailed_description": "A private task assistant that enables users to ask questions about their documents using GPT models, functioning as a local RAG application for personal knowledge management.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "document_qa",
        "rag_application"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/nrl-ai/pautobot",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "document-qa",
        "gpt",
        "private-ai"
      ],
      "id": 142
    },
    {
      "name": "Hallucination Probes",
      "one_line_profile": "Real-time detection of hallucinated entities in long-form generation",
      "detailed_description": "A tool for detecting hallucinations in Large Language Model generations, specifically focusing on entity consistency and grounding in long-form text.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/obalcells/hallucination_probes",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination-detection",
        "llm-evaluation",
        "grounding"
      ],
      "id": 143
    },
    {
      "name": "Knowledge MCP",
      "one_line_profile": "Local knowledge base with hybrid vector and graph RAG engine",
      "detailed_description": "A Model Context Protocol (MCP) server that runs a local knowledge base using LightRAG, combining vector and graph retrieval for AI agents.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "rag_engine",
        "knowledge_base"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/olafgeibig/knowledge-mcp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "rag",
        "graph-rag",
        "lightrag",
        "knowledge-base"
      ],
      "id": 144
    },
    {
      "name": "LLM Proteomics Hallucination",
      "one_line_profile": "Framework for evaluating hallucination risks in LLMs for clinical proteomics",
      "detailed_description": "A systematic evaluation and detection framework for assessing hallucination risks in Large Language Models when applied to clinical proteomics and mass spectrometry interpretation.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "domain_specific_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/olaflaitinen/llm-proteomics-hallucination",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "proteomics",
        "hallucination",
        "llm-evaluation",
        "clinical-ai"
      ],
      "id": 145
    },
    {
      "name": "INSIGHT",
      "one_line_profile": "Autonomous AI agent for medical research",
      "detailed_description": "An autonomous AI system designed to conduct medical research, capable of processing medical literature and data to generate insights.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "literature_analysis",
        "autonomous_research"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/oneil512/INSIGHT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-research",
        "autonomous-agent",
        "ai-researcher"
      ],
      "id": 146
    },
    {
      "name": "Palico AI",
      "one_line_profile": "Framework for building and productionizing LLM RAG applications",
      "detailed_description": "An integrated framework to build, improve performance, and productionize LLM applications, specifically focusing on RAG workflows.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "llm_ops"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/palico-ai/palico-ai",
      "help_website": [
        "https://palico.ai"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "llm-framework",
        "typescript"
      ],
      "id": 147
    },
    {
      "name": "PapersGPT for Zotero",
      "one_line_profile": "Zotero plugin for AI-assisted literature analysis",
      "detailed_description": "A Zotero plugin that integrates various LLMs (ChatGPT, Claude, DeepSeek, etc.) to assist with reading, summarizing, and analyzing scientific papers directly within the reference manager.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "literature_analysis",
        "reference_management"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/papersgpt/papersgpt-for-zotero",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "zotero",
        "literature-review",
        "llm-plugin",
        "academic-writing"
      ],
      "id": 148
    },
    {
      "name": "RAPTOR",
      "one_line_profile": "Recursive Abstractive Processing for Tree-Organized Retrieval",
      "detailed_description": "The official implementation of RAPTOR, a retrieval technique that constructs a tree of document summaries to enable retrieval across different levels of abstraction, improving RAG performance for long documents.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "retrieval",
        "summarization",
        "rag_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/parthsarthi03/raptor",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "retrieval",
        "summarization",
        "tree-structure"
      ],
      "id": 149
    },
    {
      "name": "Pathway",
      "one_line_profile": "High-performance data processing framework for RAG and LLM pipelines",
      "detailed_description": "A Python ETL framework for stream processing and real-time analytics, optimized for building live RAG pipelines and handling data updates for LLM applications.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "data_pipeline",
        "rag_infrastructure",
        "stream_processing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/pathwaycom/pathway",
      "help_website": [
        "https://pathway.com"
      ],
      "license": "NOASSERTION",
      "tags": [
        "etl",
        "rag",
        "stream-processing",
        "real-time-analytics"
      ],
      "id": 150
    },
    {
      "name": "RasaGPT",
      "one_line_profile": "Headless LLM chatbot platform for RAG applications",
      "detailed_description": "A chatbot platform built on Rasa and LangChain that integrates LlamaIndex and vector databases to create RAG-based agents for querying documents and data.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "rag_platform",
        "chatbot_agent"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/paulpierre/RasaGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rasa",
        "langchain",
        "rag",
        "chatbot"
      ],
      "id": 151
    },
    {
      "name": "GPT4 Internet Research Agent",
      "one_line_profile": "Agent for automated internet research and report generation",
      "detailed_description": "A Streamlit web application that uses GPT-4 and LangChain to conduct internet research, retrieve information, and generate comprehensive research reports with citations.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "automated_research",
        "report_generation"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/petermartens98/GPT4-LangChain-Internet-Research-Agent-App",
      "help_website": [],
      "license": null,
      "tags": [
        "research-agent",
        "gpt-4",
        "langchain",
        "automated-reporting"
      ],
      "id": 152
    },
    {
      "name": "arXivRAG",
      "one_line_profile": "RAG tool for arXiv academic content",
      "detailed_description": "A tool designed to enhance the retrieval and generation of academic content specifically from the arXiv database using RAG techniques.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "literature_retrieval",
        "rag_pipeline"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/phitrann/arXivRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "arxiv",
        "rag",
        "academic-retrieval"
      ],
      "id": 153
    },
    {
      "name": "Canopy",
      "one_line_profile": "RAG framework and context engine by Pinecone",
      "detailed_description": "An open-source RAG framework and context engine that handles chunking, embedding, and retrieval to simplify building RAG applications powered by Pinecone.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "context_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/pinecone-io/canopy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "pinecone",
        "vector-database",
        "context-engine"
      ],
      "id": 154
    },
    {
      "name": "AutoFlow",
      "one_line_profile": "Graph RAG based conversational knowledge base tool",
      "detailed_description": "A conversational knowledge base tool that utilizes Graph RAG and TiDB Serverless Vector Storage to provide advanced retrieval and question answering capabilities.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "graph_rag",
        "knowledge_base"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/pingcap/autoflow",
      "help_website": [
        "https://tidb.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "graph-rag",
        "knowledge-base",
        "tidb",
        "conversational-ai"
      ],
      "id": 155
    },
    {
      "name": "Deep Research MCP",
      "one_line_profile": "MCP server for integrating Deep Research APIs",
      "detailed_description": "A Model Context Protocol (MCP) server that integrates OpenAI's Deep Research APIs and Hugging Face's Open Deep Research, enabling AI assistants to perform deep research tasks.",
      "domains": [
        "Sci Knowledge",
        "G1-04"
      ],
      "subtask_category": [
        "research_integration",
        "agent_tool"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/pminervini/deep-research-mcp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "deep-research",
        "ai-agent",
        "integration"
      ],
      "id": 156
    },
    {
      "name": "QASMBench",
      "one_line_profile": "Low-level OpenQASM benchmark suite for NISQ evaluation",
      "detailed_description": "A benchmark suite for evaluating and simulating Noisy Intermediate-Scale Quantum (NISQ) devices using OpenQASM. It provides a collection of quantum circuits to assess the performance of quantum compilers, simulators, and hardware.",
      "domains": [
        "Quantum Computing"
      ],
      "subtask_category": [
        "benchmarking",
        "simulation",
        "quantum_circuit_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "OpenQASM",
      "repo_url": "https://github.com/pnnl/QASMBench",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "quantum-computing",
        "benchmark",
        "openqasm",
        "nisq"
      ],
      "id": 157
    },
    {
      "name": "SelfCheckGPT",
      "one_line_profile": "Hallucination detection tool for generative LLMs",
      "detailed_description": "A zero-resource, black-box tool for detecting hallucinations in generative Large Language Models (LLMs). It assesses the factual consistency of generated text without requiring external databases or ground truth.",
      "domains": [
        "G1-04",
        "NLP"
      ],
      "subtask_category": [
        "hallucination_detection",
        "fact_checking",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/potsawee/selfcheckgpt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "llm",
        "fact-checking",
        "nlp"
      ],
      "id": 158
    },
    {
      "name": "Promptify",
      "one_line_profile": "Structured output generation tool for LLMs",
      "detailed_description": "A library for prompt engineering and versioning that helps generate structured outputs (like JSON) from LLMs. It is useful for extracting entities, relations, and other structured data from scientific text.",
      "domains": [
        "G1",
        "NLP"
      ],
      "subtask_category": [
        "prompt_engineering",
        "information_extraction",
        "ner"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/promptslab/Promptify",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prompt-engineering",
        "nlp",
        "ner",
        "structured-output"
      ],
      "id": 159
    },
    {
      "name": "qKnow",
      "one_line_profile": "Open-source knowledge graph platform",
      "detailed_description": "A platform for knowledge extraction, fusion, graph construction, and visualization. It supports building structured knowledge systems, which is essential for scientific knowledge management and reasoning.",
      "domains": [
        "G1",
        "Knowledge Graph"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "graph_construction",
        "knowledge_fusion"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/qiantongtech/qKnow",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "knowledge-graph",
        "extraction",
        "visualization",
        "kg"
      ],
      "id": 160
    },
    {
      "name": "RagaAI-Catalyst",
      "one_line_profile": "Agent AI observability and evaluation framework",
      "detailed_description": "A Python SDK for monitoring, tracing, and evaluating AI agents and LLMs. It provides tools for debugging multi-agent systems and analyzing execution graphs, supporting the development of reliable scientific AI agents.",
      "domains": [
        "G1-04",
        "AI Engineering"
      ],
      "subtask_category": [
        "agent_evaluation",
        "observability",
        "tracing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/raga-ai-hub/RagaAI-Catalyst",
      "help_website": [
        "https://docs.raga.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "observability",
        "agent-evaluation",
        "llm-ops",
        "debugging"
      ],
      "id": 161
    },
    {
      "name": "RagApp",
      "one_line_profile": "Enterprise-grade Agentic RAG platform",
      "detailed_description": "A platform designed to simplify the deployment of Agentic RAG (Retrieval-Augmented Generation) systems. It facilitates the creation of AI assistants that can retrieve and process internal data, applicable to scientific knowledge bases.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "rag",
        "agent_deployment",
        "knowledge_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/ragapp/ragapp",
      "help_website": [
        "https://ragapp.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "agent",
        "enterprise-ai",
        "retrieval"
      ],
      "id": 162
    },
    {
      "name": "Knowledge Graph RAG",
      "one_line_profile": "Local LLM Graph RAG pipeline",
      "detailed_description": "A tool implementing Graph RAG using local LLMs, converting PDFs to Neo4J graphs for enhanced retrieval. It enables structured querying of document collections using knowledge graph techniques.",
      "domains": [
        "G1-04",
        "Knowledge Graph"
      ],
      "subtask_category": [
        "graph_rag",
        "pdf_parsing",
        "knowledge_graph_construction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/rathcoding/knowledge-graph-rag",
      "help_website": [],
      "license": null,
      "tags": [
        "graph-rag",
        "neo4j",
        "langchain",
        "local-llm"
      ],
      "id": 163
    },
    {
      "name": "AgentGPT",
      "one_line_profile": "Autonomous AI Agent deployment platform",
      "detailed_description": "A platform to assemble, configure, and deploy autonomous AI agents in the browser. While general-purpose, it is widely used to create agents for complex workflows, including research tasks and data gathering.",
      "domains": [
        "G1-04",
        "AI Agents"
      ],
      "subtask_category": [
        "agent_orchestration",
        "workflow_automation",
        "autonomous_agents"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/reworkd/AgentGPT",
      "help_website": [
        "https://agentgpt.reworkd.ai"
      ],
      "license": "GPL-3.0",
      "tags": [
        "autonomous-agents",
        "ai-agent",
        "workflow",
        "browser-based"
      ],
      "id": 164
    },
    {
      "name": "Chain of Density",
      "one_line_profile": "Iterative text summarization tool",
      "detailed_description": "An implementation of the 'Chain of Density' prompting technique for generating increasingly concise and entity-dense summaries. Useful for compressing scientific literature while retaining key information.",
      "domains": [
        "G1",
        "NLP"
      ],
      "subtask_category": [
        "summarization",
        "prompt_engineering",
        "text_compression"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/richawo/chain-of-density",
      "help_website": [],
      "license": null,
      "tags": [
        "summarization",
        "chain-of-density",
        "nlp",
        "llm"
      ],
      "id": 165
    },
    {
      "name": "Llama-Researcher",
      "one_line_profile": "Autonomous online research assistant",
      "detailed_description": "A research assistant tool built with LlamaIndex Workflows and Tavily API. It performs online research on given topics, synthesizing information similar to GPT-Researcher, aiding in literature review and data gathering.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "web_research",
        "information_synthesis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/rsrohan99/Llama-Researcher",
      "help_website": [],
      "license": null,
      "tags": [
        "research-assistant",
        "llamaindex",
        "literature-review",
        "agent"
      ],
      "id": 166
    },
    {
      "name": "LlamaIndexTS",
      "one_line_profile": "Data framework for LLM applications (TypeScript)",
      "detailed_description": "The TypeScript version of LlamaIndex, a data framework for building LLM applications. It enables ingesting, structuring, and accessing private or domain-specific data for RAG pipelines.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "rag",
        "data_indexing",
        "retrieval"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/run-llama/LlamaIndexTS",
      "help_website": [
        "https://ts.llamaindex.ai/"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "typescript",
        "llm-framework",
        "data-indexing"
      ],
      "id": 167
    },
    {
      "name": "LlamaHub",
      "one_line_profile": "Library of data loaders for LLMs",
      "detailed_description": "A community-driven library of data loaders and plugins for LlamaIndex and LangChain. It provides connectors to various data sources (PDFs, APIs, databases), essential for building scientific RAG systems.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "data_loading",
        "integration",
        "connector"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/run-llama/llama-hub",
      "help_website": [
        "https://llamahub.ai"
      ],
      "license": "MIT",
      "tags": [
        "data-loaders",
        "integration",
        "rag",
        "connectors"
      ],
      "id": 168
    },
    {
      "name": "LlamaIndex",
      "one_line_profile": "Data framework for building LLM-powered agents",
      "detailed_description": "A leading framework for connecting LLMs with external data. It provides tools for data ingestion, indexing (vector, graph, tree), and retrieval, forming the backbone of many scientific RAG and agent applications.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "rag",
        "data_indexing",
        "agent_framework",
        "retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/run-llama/llama_index",
      "help_website": [
        "https://docs.llamaindex.ai"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "llm",
        "indexing",
        "agent"
      ],
      "id": 169
    },
    {
      "name": "Rags",
      "one_line_profile": "Natural language RAG builder",
      "detailed_description": "A tool to build RAG applications over data using natural language instructions. It simplifies the creation of chatbots and search tools for document collections.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "rag",
        "chatbot_creation",
        "no_code_ai"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/run-llama/rags",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "chatbot",
        "automation",
        "nlp"
      ],
      "id": 170
    },
    {
      "name": "PaperGPT",
      "one_line_profile": "Tool to chat with research papers",
      "detailed_description": "A tool designed to facilitate interaction with research papers via a chat interface. It allows researchers to query and extract information from scientific documents using LLMs.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_qa",
        "document_analysis",
        "rag"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ruogudu/PaperGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "research-assistant",
        "pdf-chat",
        "rag",
        "academic"
      ],
      "id": 171
    },
    {
      "name": "Claude-Flow",
      "one_line_profile": "Agent orchestration platform for Claude",
      "detailed_description": "An agent orchestration platform specifically for Claude models. It supports deploying multi-agent swarms and coordinating autonomous workflows, which can be applied to complex scientific reasoning and data processing tasks.",
      "domains": [
        "G1-04",
        "AI Agents"
      ],
      "subtask_category": [
        "agent_orchestration",
        "multi_agent_system",
        "workflow_automation"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/ruvnet/claude-flow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "claude",
        "agent-orchestration",
        "swarm-intelligence",
        "workflow"
      ],
      "id": 172
    },
    {
      "name": "GuardRail",
      "one_line_profile": "Data analysis and content generation tool",
      "detailed_description": "A tool for data analysis and AI content generation using OpenAI models. It includes features for sentiment analysis, content classification, and trend analysis, useful for analyzing scientific text or social data.",
      "domains": [
        "G1",
        "NLP"
      ],
      "subtask_category": [
        "text_analysis",
        "classification",
        "sentiment_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ruvnet/guardrail",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-analysis",
        "nlp",
        "classification",
        "openai"
      ],
      "id": 173
    },
    {
      "name": "PsiloQA",
      "one_line_profile": "Hallucination detection dataset construction pipeline",
      "detailed_description": "A pipeline that automates the construction of multilingual, span-level hallucination detection datasets. It aids in creating benchmarks for evaluating the faithfulness of RAG and generation models.",
      "domains": [
        "G1-04",
        "NLP"
      ],
      "subtask_category": [
        "dataset_construction",
        "hallucination_research",
        "evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/s-nlp/PsiloQA",
      "help_website": [],
      "license": null,
      "tags": [
        "hallucination",
        "dataset",
        "nlp",
        "multilingual"
      ],
      "id": 174
    },
    {
      "name": "Summary of a Haystack",
      "one_line_profile": "Benchmark for RAG context retrieval evaluation",
      "detailed_description": "The codebase for the 'Summary of a Haystack' paper, providing a benchmark to evaluate the ability of LLMs to retrieve and summarize information from long contexts (needle-in-a-haystack tests).",
      "domains": [
        "G1-04",
        "NLP"
      ],
      "subtask_category": [
        "model_evaluation",
        "context_retrieval",
        "benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/salesforce/summary-of-a-haystack",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "rag",
        "long-context",
        "evaluation"
      ],
      "id": 175
    },
    {
      "name": "Deep Research",
      "one_line_profile": "AI-powered iterative research assistant for deep topic exploration",
      "detailed_description": "An AI agent designed to perform deep, iterative research on any topic by combining search engines, web scraping, and LLMs to generate comprehensive reports.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_review",
        "information_retrieval",
        "knowledge_synthesis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/shibing624/deep-research",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "research-assistant",
        "agent",
        "web-scraping",
        "llm"
      ],
      "id": 176
    },
    {
      "name": "AIrXiv",
      "one_line_profile": "AI-powered research assistant specifically for arXiv papers",
      "detailed_description": "A prototype research assistant that leverages LLMs to search, retrieve, and answer questions based on scientific papers hosted on arXiv.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "literature_search",
        "paper_qa",
        "arxiv_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/smsharma/AIrXiv",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arxiv",
        "research-assistant",
        "rag"
      ],
      "id": 177
    },
    {
      "name": "Multi-Agent Medical Assistant",
      "one_line_profile": "GenAI powered multi-agent system for medical diagnostics and research",
      "detailed_description": "A multi-agent chatbot system designed for healthcare professionals and researchers to assist with medical diagnostics and healthcare research tasks.",
      "domains": [
        "G1",
        "G1-04",
        "Medicine"
      ],
      "subtask_category": [
        "medical_diagnosis",
        "clinical_research",
        "literature_review"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/souvikmajumder26/Multi-Agent-Medical-Assistant",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "healthcare",
        "medical-research",
        "multi-agent"
      ],
      "id": 178
    },
    {
      "name": "STORM",
      "one_line_profile": "LLM-powered knowledge curation system for generating cited research reports",
      "detailed_description": "A system that orchestrates LLMs to research a topic, ask clarifying questions, and generate full-length, Wikipedia-style reports with proper citations, automating the pre-writing stage of research.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "knowledge_curation",
        "report_generation",
        "citation_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanford-oval/storm",
      "help_website": [
        "https://storm.genie.stanford.edu/"
      ],
      "license": "MIT",
      "tags": [
        "knowledge-synthesis",
        "research-automation",
        "nlp"
      ],
      "id": 179
    },
    {
      "name": "DATAGEN",
      "one_line_profile": "AI-driven multi-agent research assistant for hypothesis generation and analysis",
      "detailed_description": "An automated research assistant that uses multi-agent systems to generate hypotheses, perform data analysis, and write reports, aiming to streamline the scientific research process.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "hypothesis_generation",
        "data_analysis",
        "report_writing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/starpig1129/DATAGEN",
      "help_website": [
        "https://datagen.digital/"
      ],
      "license": "MIT",
      "tags": [
        "research-automation",
        "multi-agent",
        "hypothesis-generation"
      ],
      "id": 180
    },
    {
      "name": "ChatGPT-Paper-Reader",
      "one_line_profile": "Interface for reading and summarizing research papers via OpenAI API",
      "detailed_description": "A tool designed to help researchers read and summarize PDF research papers, allowing for Q&A based on the paper's content using GPT models.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "paper_summarization",
        "literature_reading",
        "pdf_qa"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/talkingwallace/ChatGPT-Paper-Reader",
      "help_website": [],
      "license": null,
      "tags": [
        "pdf-reader",
        "research-papers",
        "summarization"
      ],
      "id": 181
    },
    {
      "name": "GPT Paper Assistant",
      "one_line_profile": "Personalized ArXiv paper assistant bot based on GPT-4",
      "detailed_description": "An automated bot that monitors ArXiv for new papers, summarizes them, and provides personalized recommendations and Q&A capabilities for researchers.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "arxiv_monitoring",
        "paper_recommendation",
        "summarization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tatsu-lab/gpt_paper_assistant",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "arxiv",
        "gpt-4",
        "research-assistant"
      ],
      "id": 182
    },
    {
      "name": "STORM Research Assistant",
      "one_line_profile": "Implementation of the STORM methodology for AI-driven research",
      "detailed_description": "An implementation of the STORM (Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking) methodology to generate comprehensive research articles.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "knowledge_synthesis",
        "report_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/teddynote-lab/STORM-Research-Assistant",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "storm",
        "research-assistant",
        "article-generation"
      ],
      "id": 183
    },
    {
      "name": "Retrieval Framework",
      "one_line_profile": "Tool for converting scientific PDFs into plain text for RAG applications",
      "detailed_description": "A specialized tool developed to convert complex scientific PDF documents into clean plain text, facilitating the creation of RAG systems or agents for academic knowledge.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "pdf_parsing",
        "data_preprocessing",
        "scientific_literature"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/tensorsense/Retrieval-Framework",
      "help_website": [],
      "license": null,
      "tags": [
        "pdf-to-text",
        "scientific-papers",
        "rag-preprocessing"
      ],
      "id": 184
    },
    {
      "name": "CityGPT",
      "one_line_profile": "LLM-based framework for urban spatial cognition and analysis",
      "detailed_description": "A research framework that empowers Large Language Models with urban spatial cognition capabilities, enabling advanced analysis and reasoning for urban science and planning tasks.",
      "domains": [
        "G1",
        "Urban Science"
      ],
      "subtask_category": [
        "scientific_modeling",
        "spatial_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tsinghua-fib-lab/CityGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "urban-computing",
        "llm-agent",
        "spatial-cognition"
      ],
      "id": 185
    },
    {
      "name": "hlb-gpt",
      "one_line_profile": "High-performance minimalistic toolbench for GPT model research",
      "detailed_description": "A highly optimized, minimalistic library designed for AI researchers to train and experiment with GPT models efficiently. It focuses on speed and hackability for scientific experimentation in deep learning.",
      "domains": [
        "G1",
        "AI Research"
      ],
      "subtask_category": [
        "model_training",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tysam-code/hlb-gpt",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpt",
        "deep-learning",
        "research-tool"
      ],
      "id": 186
    },
    {
      "name": "PodGPT",
      "one_line_profile": "Audio-augmented large language model for research applications",
      "detailed_description": "A multimodal large language model designed to integrate audio data, specifically tailored for research and educational applications, enabling analysis of audio-based scientific or educational content.",
      "domains": [
        "G1",
        "Multimodal Research"
      ],
      "subtask_category": [
        "scientific_modeling",
        "multimodal_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/vkola-lab/PodGPT",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "llm",
        "audio-processing",
        "multimodal"
      ],
      "id": 187
    },
    {
      "name": "MMGraphRAG",
      "one_line_profile": "Multi-modal knowledge graph-based RAG framework",
      "detailed_description": "A framework designed to enhance complex reasoning tasks in multi-modal document question-answering. It integrates text and image data into a structured knowledge graph, facilitating evidence extraction from scientific documents.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "document_analysis"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/wanxueyao/MMGraphRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "knowledge-graph",
        "multi-modal",
        "document-qa"
      ],
      "id": 188
    },
    {
      "name": "ragflow_ocr",
      "one_line_profile": "OCR module for RAG document processing",
      "detailed_description": "A specialized OCR component derived from RAGFlow, designed to extract text from documents (PDFs, images) to support Retrieval-Augmented Generation pipelines in scientific literature processing.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "data_processing",
        "ocr"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/xuxianren/ragflow_ocr",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ocr",
        "rag",
        "document-processing"
      ],
      "id": 189
    },
    {
      "name": "gpt_pdf_md",
      "one_line_profile": "PDF to Markdown converter with GPT-4V support",
      "detailed_description": "A tool for converting PDF documents into Markdown format, utilizing GPT-4V to extract and describe images. Essential for preprocessing scientific literature for downstream RAG or analysis tasks.",
      "domains": [
        "G1",
        "G1-04"
      ],
      "subtask_category": [
        "data_processing",
        "format_conversion"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/yachty66/gpt_pdf_md",
      "help_website": [],
      "license": null,
      "tags": [
        "pdf-parsing",
        "markdown",
        "gpt-4v"
      ],
      "id": 190
    },
    {
      "name": "SIFT",
      "one_line_profile": "Method for grounding LLM reasoning in contexts to reduce hallucinations",
      "detailed_description": "A framework/methodology designed to ground Large Language Model (LLM) reasoning within provided contexts using 'stickers', aiming to improve factual accuracy and reduce hallucinations in text generation tasks.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "reasoning_grounding",
        "hallucination_reduction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhijie-group/SIFT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "grounding",
        "reasoning",
        "hallucination"
      ],
      "id": 191
    },
    {
      "name": "EasyDetect",
      "one_line_profile": "An easy-to-use hallucination detection framework for LLMs",
      "detailed_description": "A comprehensive framework designed to detect hallucinations in Large Language Models, providing tools to evaluate and ensure the factual reliability of generated content, which is critical for scientific literature processing.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/EasyDetect",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination-detection",
        "llm-evaluation",
        "reliability"
      ],
      "id": 192
    },
    {
      "name": "FactCHD",
      "one_line_profile": "Benchmark and tool for fact-conflicting hallucination detection",
      "detailed_description": "A benchmark dataset and evaluation toolkit focused on detecting fact-conflicting hallucinations in LLMs, serving as a standard for assessing model faithfulness in knowledge-intensive tasks.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/FactCHD",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "hallucination",
        "fact-checking"
      ],
      "id": 193
    },
    {
      "name": "Ragflow-Plus",
      "one_line_profile": "Enhanced RAG engine focusing on document understanding",
      "detailed_description": "A secondary development version of Ragflow, providing a streamlined Retrieval-Augmented Generation (RAG) engine optimized for deep document understanding, parsing, and knowledge retrieval from scientific or technical literature.",
      "domains": [
        "G1-04"
      ],
      "subtask_category": [
        "rag_framework",
        "document_parsing",
        "knowledge_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/zstar1003/ragflow-plus",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "rag",
        "document-parsing",
        "knowledge-base",
        "nlp"
      ],
      "id": 194
    }
  ]
}