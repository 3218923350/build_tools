{
  "generated_at": "2025-12-16T04:58:53.775264+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "G1",
      "leaf_cluster_name": "科研文献-检索/解析/引用网络生态",
      "domain": "Sci Knowledge",
      "typical_objects": "PDFs/citations",
      "task_chain": "解析→抽取→索引→检索→评测",
      "tool_form": "解析器 + 检索 + 评测"
    },
    "unit": {
      "unit_id": "G1-06",
      "unit_name": "论文推荐与发现",
      "target_scale": "150–300",
      "coverage_tools": "recommender systems"
    },
    "search": {
      "target_candidates": 300,
      "queries": [
        "[GH] Elicit",
        "[GH] Paper-qa",
        "[GH] Scirate",
        "[GH] Inciteful",
        "[GH] Litmaps",
        "[GH] Semantic Scholar",
        "[GH] ResearchRabbit",
        "[GH] Connected Papers",
        "[GH] Arxiv Sanity Preserver",
        "[GH] paper recommendation",
        "[GH] citation graph",
        "[GH] academic recommender",
        "[GH] literature discovery",
        "[GH] arxiv daily",
        "[GH] research paper recommender",
        "[GH] citation network",
        "[GH] scientific literature",
        "[GH] personalized arxiv",
        "[GH] scholar graph",
        "[GH] paper discovery",
        "[GH] bibliographic coupling",
        "[GH] co-citation analysis",
        "[WEB] academic paper recommendation system github",
        "[WEB] arxiv daily recommender github",
        "[WEB] citation graph analysis tools github",
        "[WEB] scientific literature discovery github",
        "[WEB] open source paper recommender github",
        "[WEB] semantic scholar api wrapper github"
      ],
      "total_candidates": 939,
      "tool_candidates": 540,
      "final_tools": 121
    }
  },
  "tools": [
    {
      "name": "tetsuo-dox-agent",
      "one_line_profile": "Graph-based research assistant agent using LLMs",
      "detailed_description": "A research assistant agent that leverages Large Language Models and a graph-based architecture to draft answers, perform self-reflection, and conduct iterative research with robust citations.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_synthesis",
        "scientific_qa"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/7etsuo/tetsuo-dox-agent",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-agent",
        "research-assistant",
        "citation-graph"
      ],
      "id": 1
    },
    {
      "name": "semantic-zotero",
      "one_line_profile": "Zotero plugin for Semantic Scholar integration",
      "detailed_description": "A plugin for the Zotero reference manager that retrieves reference data and metadata from the Semantic Scholar API to enrich the user's library.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "data_retrieval",
        "reference_management"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/AgiNetz/semantic-zotero",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "zotero-plugin",
        "semantic-scholar",
        "bibliography"
      ],
      "id": 2
    },
    {
      "name": "OpenScholar",
      "one_line_profile": "Retrieval-augmented LM system for scientific literature synthesis",
      "detailed_description": "An open-source system for synthesizing scientific literature using retrieval-augmented language models, designed to answer scientific questions by retrieving and processing relevant papers.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_synthesis",
        "scientific_qa"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AkariAsai/OpenScholar",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "scientific-literature",
        "llm"
      ],
      "id": 3
    },
    {
      "name": "openai_tools",
      "one_line_profile": "Scripts for summarizing scientific literature using OpenAI models",
      "detailed_description": "A collection of scripts developed by the Allen Institute to summarize and analyze scientific literature using large language models like ChatGPT.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "summarization",
        "literature_mining"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/AllenInstitute/openai_tools",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "summarization",
        "allen-institute",
        "literature-analysis"
      ],
      "id": 4
    },
    {
      "name": "Scholarpy",
      "one_line_profile": "Python wrapper for Semantic Scholar API",
      "detailed_description": "A Python library designed to streamline academic research by providing a convenient wrapper around the Semantic Scholar APIs for data retrieval.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "data_retrieval",
        "api_wrapper"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AndreaBasile97/Scholarpy",
      "help_website": [],
      "license": null,
      "tags": [
        "semantic-scholar",
        "api-client",
        "python"
      ],
      "id": 5
    },
    {
      "name": "ArxivDigest",
      "one_line_profile": "Personalized arXiv paper recommendation system",
      "detailed_description": "A tool for generating personalized arXiv digests and recommendations using Large Language Models to filter and summarize daily papers.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "recommendation",
        "discovery"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AutoLLM/ArxivDigest",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arxiv",
        "recommendation",
        "llm"
      ],
      "id": 6
    },
    {
      "name": "citation-network-explorer",
      "one_line_profile": "Tool for exploring local citation networks",
      "detailed_description": "A visualization tool designed to explore local citation networks, helping researchers understand the connections between papers in a specific collection.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "visualization",
        "citation_network"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/CitationGecko/citation-network-explorer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "citation-network",
        "bibliometrics"
      ],
      "id": 7
    },
    {
      "name": "citegraph",
      "one_line_profile": "Web-based citation graph visualizer",
      "detailed_description": "A web visualizer for citation graphs, allowing users to interactively explore the relationships between scientific publications.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "visualization",
        "citation_network"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/Citegraph/citegraph",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "graph",
        "citation"
      ],
      "id": 8
    },
    {
      "name": "climsight",
      "one_line_profile": "LLM-based climate information system",
      "detailed_description": "A climate information system that combines Large Language Models with high-resolution climate model data and scientific literature to provide localized climate assessments.",
      "domains": [
        "G1",
        "Earth Science"
      ],
      "subtask_category": [
        "climate_analysis",
        "literature_synthesis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CliDyn/climsight",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "climate-change",
        "llm",
        "scientific-assessment"
      ],
      "id": 9
    },
    {
      "name": "SeleniumSemanticScraper",
      "one_line_profile": "Automated metadata crawler for Semantic Scholar papers based on key phrases",
      "detailed_description": "A tool that uses Selenium WebDriver to automatically crawl and extract metadata from research papers on Semantic Scholar based on user-defined key phrases, saving the results in Excel format.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "data_retrieval",
        "metadata_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/EvertonCa/SeleniumSemanticScraper",
      "help_website": [],
      "license": null,
      "tags": [
        "web-scraping",
        "semantic-scholar",
        "metadata",
        "automation"
      ],
      "id": 10
    },
    {
      "name": "citation-graph-builder",
      "one_line_profile": "Tool for creating and visualizing citation networks from PDFs and APIs",
      "detailed_description": "A tool designed to construct and visualize citation networks by combining citation data parsed from PDF files with metadata queried from bibliographic APIs.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "visualization",
        "citation_analysis"
      ],
      "application_level": "solver",
      "primary_language": "TeX",
      "repo_url": "https://github.com/FZJ-IEK3-VSA/citation-graph-builder",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "citation-network",
        "visualization",
        "bibliometrics",
        "pdf-parsing"
      ],
      "id": 11
    },
    {
      "name": "paper-qa",
      "one_line_profile": "High-accuracy RAG tool for answering questions from scientific documents",
      "detailed_description": "A Retrieval-Augmented Generation (RAG) library for answering questions based on scientific documents, providing high accuracy and citing sources from the text.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "question_answering",
        "literature_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Future-House/paper-qa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "llm",
        "scientific-qa",
        "citation-support"
      ],
      "id": 12
    },
    {
      "name": "CAiRE-COVID",
      "one_line_profile": "QA and summarization system for mining COVID-19 scientific literature",
      "detailed_description": "A machine learning-based system combining Question Answering (QA) and summarization techniques to mine and extract information from scientific literature, specifically tailored for COVID-19 research.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_mining",
        "question_answering",
        "summarization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/HLTCHKUST/CAiRE-COVID",
      "help_website": [],
      "license": null,
      "tags": [
        "covid-19",
        "nlp",
        "literature-mining",
        "qa"
      ],
      "id": 13
    },
    {
      "name": "Arxiv-NLP-Reporter",
      "one_line_profile": "Daily automated crawler and reporter for NLP research papers from arXiv",
      "detailed_description": "A tool that automatically crawls the latest Natural Language Processing (NLP) papers from arXiv daily and generates reports, facilitating efficient literature tracking.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "paper_discovery",
        "data_retrieval"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/JackHCC/Arxiv-NLP-Reporter",
      "help_website": [],
      "license": null,
      "tags": [
        "arxiv",
        "nlp",
        "crawler",
        "daily-report"
      ],
      "id": 14
    },
    {
      "name": "semanticscholar-MCP-Server",
      "one_line_profile": "Model Context Protocol server for Semantic Scholar API interaction",
      "detailed_description": "A Model Context Protocol (MCP) server implementation that enables AI agents and tools to interact with the Semantic Scholar API for searching papers, retrieving details, and fetching citations.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "data_retrieval",
        "api_adapter"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/JackKuo666/semanticscholar-MCP-Server",
      "help_website": [],
      "license": null,
      "tags": [
        "mcp",
        "semantic-scholar",
        "api",
        "agent-tool"
      ],
      "id": 15
    },
    {
      "name": "ArxivCVDigest",
      "one_line_profile": "Daily digest generator for Computer Vision papers from arXiv",
      "detailed_description": "A tool that generates a daily feed of the latest Computer Vision research papers from arXiv, helping researchers stay updated with new publications.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "paper_discovery",
        "recommendation"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/Jasmine66Bloom/ArxivCVDigest",
      "help_website": [],
      "license": null,
      "tags": [
        "computer-vision",
        "arxiv",
        "digest",
        "research-feed"
      ],
      "id": 16
    },
    {
      "name": "PaperHelper",
      "one_line_profile": "LLM-based paper reading assistant with reliable reference support",
      "detailed_description": "A knowledge-based QA tool that assists in reading scientific papers by using Large Language Models to answer questions while providing reliable references from the text.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_analysis",
        "reading_assistant"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/JerryYin777/PaperHelper",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "paper-reading",
        "qa",
        "research-assistant"
      ],
      "id": 17
    },
    {
      "name": "pubtrends",
      "one_line_profile": "Scientific literature explorer for visualizing search result structures",
      "detailed_description": "A tool that runs searches on Pubmed or Semantic Scholar and allows users to explore the high-level structure and trends of the resulting papers through visualization.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "visualization",
        "literature_discovery"
      ],
      "application_level": "application",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/JetBrains-Research/pubtrends",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bibliometrics",
        "visualization",
        "literature-search",
        "trends"
      ],
      "id": 18
    },
    {
      "name": "customize-arxiv-daily",
      "one_line_profile": "Tool for generating customized daily arXiv paper recommendations",
      "detailed_description": "A Python-based tool that allows users to customize and automate the retrieval of daily arXiv paper recommendations based on specific interests.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "paper_recommendation",
        "personalization"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/JoeLeelyf/customize-arxiv-daily",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arxiv",
        "recommendation",
        "daily-updates",
        "customization"
      ],
      "id": 19
    },
    {
      "name": "EmbodiedAI-Robotics-arXiv-Daily-Reporter",
      "one_line_profile": "Daily arXiv paper reporter for Embodied AI and Robotics",
      "detailed_description": "A specialized tool for filtering and reporting daily arXiv papers in the fields of Embodied AI and Robotics, aiding researchers in efficient literature discovery.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "paper_discovery",
        "filtering"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/KJaebye/EmbodiedAI-Robotics-arXiv-Daily-Reporter",
      "help_website": [],
      "license": null,
      "tags": [
        "embodied-ai",
        "robotics",
        "arxiv",
        "daily-report"
      ],
      "id": 20
    },
    {
      "name": "semanticscholar-R",
      "one_line_profile": "R package for accessing Semantic Scholar API data",
      "detailed_description": "An R package developed by KTH Library to provide programmatic access to the Semantic Scholar API, facilitating the retrieval of scientific literature data for analysis.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "data_retrieval",
        "api_client"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/KTH-Library/semanticscholar",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "r-package",
        "semantic-scholar",
        "bibliometrics",
        "api"
      ],
      "id": 21
    },
    {
      "name": "LocalCitationNetwork",
      "one_line_profile": "Web application for local citation network visualization and literature review",
      "detailed_description": "A web-based tool that helps scientists conduct literature reviews by visualizing local citation networks using metadata from OpenAlex, Semantic Scholar, and Crossref.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "visualization",
        "literature_review"
      ],
      "application_level": "service",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/LocalCitationNetwork/LocalCitationNetwork.github.io",
      "help_website": [
        "https://localcitationnetwork.github.io"
      ],
      "license": "GPL-3.0",
      "tags": [
        "citation-network",
        "visualization",
        "literature-review",
        "openalex"
      ],
      "id": 22
    },
    {
      "name": "SciQAG",
      "one_line_profile": "Framework for generating science question-answer pairs from scientific literature",
      "detailed_description": "A framework designed to automatically generate high-quality question-answer pairs from large corpora of scientific literature using large language models, facilitating scientific knowledge extraction and QA system training.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "text_mining",
        "data_generation",
        "question_answering"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/MasterAI-EAM/SciQAG",
      "help_website": [],
      "license": null,
      "tags": [
        "scientific-literature",
        "question-answering",
        "llm",
        "data-generation"
      ],
      "id": 23
    },
    {
      "name": "exsclaim",
      "one_line_profile": "Toolkit for constructing materials imaging datasets from scientific literature",
      "detailed_description": "A toolkit that automates the extraction and labeling of materials science images from scientific literature to construct large-scale, self-labeled imaging datasets for machine learning applications in materials science.",
      "domains": [
        "G1",
        "Materials Science"
      ],
      "subtask_category": [
        "image_mining",
        "dataset_construction",
        "literature_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MaterialEyes/exsclaim",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "materials-science",
        "image-extraction",
        "literature-mining",
        "dataset-creation"
      ],
      "id": 24
    },
    {
      "name": "zotero-connected-papers",
      "one_line_profile": "Zotero plugin for visualizing citation networks via Connected Papers",
      "detailed_description": "A plugin for the Zotero reference manager that integrates with the Connected Papers service, allowing researchers to visualize citation graphs and discover relevant scientific literature directly from their reference library.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_discovery",
        "visualization",
        "citation_analysis"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/MuiseDestiny/zotero-connected-papers",
      "help_website": [],
      "license": null,
      "tags": [
        "zotero-plugin",
        "literature-discovery",
        "citation-network",
        "connected-papers"
      ],
      "id": 25
    },
    {
      "name": "litstudy",
      "one_line_profile": "Python library for automated scientific literature analysis and bibliometrics",
      "detailed_description": "A Python library developed by the Netherlands eScience Center that enables automated retrieval, analysis, and visualization of scientific literature and bibliometric data from various sources (Scopus, Semantic Scholar, etc.) within Jupyter notebooks.",
      "domains": [
        "G1",
        "Scientometrics"
      ],
      "subtask_category": [
        "bibliometrics",
        "literature_analysis",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NLeSC/litstudy",
      "help_website": [
        "https://nlesc.github.io/litstudy/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "bibliometrics",
        "literature-analysis",
        "visualization",
        "python"
      ],
      "id": 26
    },
    {
      "name": "SHELF",
      "one_line_profile": "Tools supporting the Sheffield Elicitation Framework for expert judgment",
      "detailed_description": "An R package providing tools to support the Sheffield Elicitation Framework (SHELF), used for eliciting probability distributions from experts in scientific risk analysis and uncertainty quantification.",
      "domains": [
        "Statistics",
        "Risk Analysis"
      ],
      "subtask_category": [
        "expert_elicitation",
        "probability_estimation",
        "uncertainty_quantification"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/OakleyJ/SHELF",
      "help_website": [
        "http://www.tonyohagan.co.uk/shelf/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "expert-elicitation",
        "statistics",
        "risk-analysis",
        "r"
      ],
      "id": 27
    },
    {
      "name": "DeepLiterature",
      "one_line_profile": "Intelligent research assistant for scientific literature search and analysis",
      "detailed_description": "A fully open-source intelligent research assistant that integrates literature search, code execution, link resolution, and information expansion to facilitate scientific research workflows.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_search",
        "literature_parsing",
        "research_assistant"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ScienceOne-AI/DeepLiterature",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "research-assistant",
        "literature-search",
        "scientific-workflow",
        "llm"
      ],
      "id": 28
    },
    {
      "name": "zotero-arxiv-daily",
      "one_line_profile": "Automated tool to recommend and import arXiv papers into Zotero based on user interests",
      "detailed_description": "A Python-based tool that recommends new arXiv papers daily according to the user's existing Zotero library content and automatically updates the library with relevant findings.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_recommendation",
        "reference_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TideDra/zotero-arxiv-daily",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "arxiv",
        "zotero",
        "paper-recommendation"
      ],
      "id": 29
    },
    {
      "name": "metaknowledge",
      "one_line_profile": "Python library for bibliometric and network analysis in science policy research",
      "detailed_description": "A Python library designed for doing bibliometric and network analysis in science and health policy research, enabling the processing of citation data and generation of network metrics.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "bibliometrics",
        "network_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/UWNETLAB/metaknowledge",
      "help_website": [
        "https://metaknowledge.readthedocs.io"
      ],
      "license": "GPL-2.0",
      "tags": [
        "bibliometrics",
        "network-analysis",
        "scientometrics"
      ],
      "id": 30
    },
    {
      "name": "cv-arxiv-daily",
      "one_line_profile": "Automated workflow for daily Computer Vision paper updates from arXiv",
      "detailed_description": "A GitHub Actions-based tool that automatically fetches, filters, and updates a daily list of new arXiv papers in the field of Computer Vision, facilitating literature tracking.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_discovery",
        "alerting_system"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Vincentqyw/cv-arxiv-daily",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "computer-vision",
        "arxiv",
        "automation"
      ],
      "id": 31
    },
    {
      "name": "CCFrank4dblp",
      "one_line_profile": "Browser extension to display CCF rankings on academic search sites",
      "detailed_description": "A JavaScript-based browser extension that augments academic search results (dblp, Google Scholar, etc.) by displaying China Computer Federation (CCF) recommended rankings for conferences and journals.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_filtering",
        "metadata_augmentation"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/WenyanLiu/CCFrank4dblp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "browser-extension",
        "ccf-ranking",
        "dblp"
      ],
      "id": 32
    },
    {
      "name": "cv-arxiv-daily (Xuchen-Li)",
      "one_line_profile": "Automated arXiv paper tracking for SOT, VLT, and Video Understanding",
      "detailed_description": "An automated tool using GitHub Actions to update and track daily arXiv papers specifically for Single Object Tracking, Visual Language Tracking, and Video Understanding domains.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_discovery",
        "alerting_system"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Xuchen-Li/cv-arxiv-daily",
      "help_website": [],
      "license": null,
      "tags": [
        "video-understanding",
        "arxiv",
        "tracking"
      ],
      "id": 33
    },
    {
      "name": "llm-arxiv-daily",
      "one_line_profile": "Automated arXiv paper tracking for LLM Reasoning and Evaluation",
      "detailed_description": "An automated workflow tool to track and update daily arXiv papers focused on Large Language Model reasoning, evaluation, and multimodal learning.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_discovery",
        "alerting_system"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Xuchen-Li/llm-arxiv-daily",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "arxiv",
        "automation"
      ],
      "id": 34
    },
    {
      "name": "ro-arxiv-daily",
      "one_line_profile": "Automated arXiv paper tracking for Robotics and Path Planning",
      "detailed_description": "An automated tool using GitHub Actions to update daily arXiv papers related to Path Planning, LLMs in robotics, and Autonomous Driving.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_discovery",
        "alerting_system"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/XuzhaoLi/ro-arxiv-daily",
      "help_website": [],
      "license": null,
      "tags": [
        "robotics",
        "path-planning",
        "arxiv"
      ],
      "id": 35
    },
    {
      "name": "DelhiLM",
      "one_line_profile": "LLM-based pipeline for Delphi expert elicitation methodology",
      "detailed_description": "A pipeline tool that utilizes Large Language Models to automate and facilitate the Delphi expert elicitation process, a structured communication technique used in research for forecasting and decision making.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "survey_methodology",
        "expert_elicitation"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/YuzeHao2023/DelhiLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "delphi-method",
        "llm",
        "research-methodology"
      ],
      "id": 36
    },
    {
      "name": "Arxiv_daily",
      "one_line_profile": "Spider tool for fetching customized arXiv paper lists",
      "detailed_description": "A Python-based spider tool designed to help researchers automatically fetch and generate customized lists of papers from arXiv based on specific criteria.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_discovery",
        "web_scraping"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ZihaoZhao/Arxiv_daily",
      "help_website": [],
      "license": null,
      "tags": [
        "arxiv",
        "spider",
        "literature-tracking"
      ],
      "id": 37
    },
    {
      "name": "origami",
      "one_line_profile": "Interactive graph visualization tool for scholar articles",
      "detailed_description": "A web application that visualizes scholar articles as an interactive graph, helping researchers explore connections and citation networks between papers.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "scientific_visualization",
        "citation_analysis"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/aMarcireau/origami",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "citation-graph",
        "literature-mapping"
      ],
      "id": 38
    },
    {
      "name": "academic-search-mcp-server",
      "one_line_profile": "MCP Server for searching academic papers via Semantic Scholar and Crossref",
      "detailed_description": "A Model Context Protocol (MCP) server implementation that enables AI assistants (like Claude) to search for and retrieve academic paper data from Semantic Scholar and Crossref databases.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_discovery",
        "database_integration"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/afrise/academic-search-mcp-server",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "mcp",
        "semantic-scholar",
        "crossref"
      ],
      "id": 39
    },
    {
      "name": "PaperHunter",
      "one_line_profile": "Tool for fetching and filtering conference papers from DBLP",
      "detailed_description": "A tool designed to fetch research papers from top computer science conferences via DBLP, featuring advanced keyword logic filtering and multi-year query capabilities for precise literature discovery.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_discovery",
        "metadata_filtering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ahlien/PaperHunter",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dblp",
        "paper-search",
        "conference-papers"
      ],
      "id": 40
    },
    {
      "name": "S2AND",
      "one_line_profile": "Semantic Scholar's author disambiguation algorithm and evaluation suite",
      "detailed_description": "A library providing the algorithm used by Semantic Scholar for author disambiguation, enabling researchers to cluster and identify unique authors across bibliographic records.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "author_disambiguation",
        "metadata_cleaning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/S2AND",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "author-disambiguation",
        "semantic-scholar",
        "bibliometrics"
      ],
      "id": 41
    },
    {
      "name": "AutoDiscovery",
      "one_line_profile": "Bayesian surprise-based framework for open-ended scientific discovery",
      "detailed_description": "A computational framework implementing the 'AutoDiscovery' algorithm, which uses Bayesian surprise to guide open-ended scientific discovery processes. It serves as a solver for generating and prioritizing scientific hypotheses or experimental paths.",
      "domains": [
        "Sci Knowledge",
        "Scientific Discovery"
      ],
      "subtask_category": [
        "hypothesis_generation",
        "discovery_planning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/autodiscovery",
      "help_website": [],
      "license": null,
      "tags": [
        "bayesian-inference",
        "scientific-discovery",
        "hypothesis-generation"
      ],
      "id": 42
    },
    {
      "name": "Citeomatic",
      "one_line_profile": "Citation recommendation system for academic paper drafts",
      "detailed_description": "A tool that predicts relevant citations for a given scientific text or draft. It utilizes the Semantic Scholar OpenCorpus to provide context-aware citation suggestions, aiding in literature review and manuscript preparation.",
      "domains": [
        "G1-06",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "citation_recommendation",
        "literature_discovery"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/allenai/citeomatic",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "citation-recommendation",
        "nlp",
        "semantic-scholar"
      ],
      "id": 43
    },
    {
      "name": "S2ORC",
      "one_line_profile": "Large-scale corpus of English scientific papers for NLP research",
      "detailed_description": "The Semantic Scholar Open Research Corpus (S2ORC) is a large collection of academic papers with rich metadata and full text, structured for text mining and NLP tasks in the scientific domain.",
      "domains": [
        "Sci Knowledge",
        "NLP"
      ],
      "subtask_category": [
        "corpus_processing",
        "text_mining"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/s2orc",
      "help_website": [
        "https://www.aclweb.org/anthology/2020.acl-main.447/"
      ],
      "license": null,
      "tags": [
        "dataset",
        "scientific-literature",
        "nlp"
      ],
      "id": 44
    },
    {
      "name": "S2Search",
      "one_line_profile": "Reranking library for scientific literature search",
      "detailed_description": "A library implementing the search reranker used by Semantic Scholar. It provides tools to improve the relevance of search results in scientific databases.",
      "domains": [
        "G1-06",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "search_reranking",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/s2search",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "search",
        "reranking",
        "semantic-scholar"
      ],
      "id": 45
    },
    {
      "name": "Papermap",
      "one_line_profile": "Web-based visualization tool for scientific literature findings",
      "detailed_description": "A platform for mapping and visualizing scientific findings across literature, helping researchers gain an overview of answers to specific scientific questions.",
      "domains": [
        "G1-06",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "literature_visualization",
        "knowledge_mapping"
      ],
      "application_level": "platform",
      "primary_language": "Svelte",
      "repo_url": "https://github.com/angeluriot/Papermap",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "literature-review",
        "knowledge-graph"
      ],
      "id": 46
    },
    {
      "name": "Obsidian Reference Map",
      "one_line_profile": "Obsidian plugin for literature citation mapping",
      "detailed_description": "A plugin for the Obsidian knowledge base that generates interactive citation maps and reference visualizations to assist in literature review and discovery within a personal knowledge management workflow.",
      "domains": [
        "G1-06",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "literature_management",
        "citation_visualization"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/anoopkcn/obsidian-reference-map",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "obsidian",
        "citation-map",
        "literature-review"
      ],
      "id": 47
    },
    {
      "name": "Nexus Now",
      "one_line_profile": "IPFS-backed browser tool for scientific literature access",
      "detailed_description": "A decentralized web tool leveraging IPFS to facilitate access to scientific literature using standard template constructs, aiming to improve the accessibility of research papers.",
      "domains": [
        "Sci Knowledge"
      ],
      "subtask_category": [
        "literature_access",
        "decentralized_science"
      ],
      "application_level": "service",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/aokellermann/nexus-now",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ipfs",
        "open-access",
        "literature-search"
      ],
      "id": 48
    },
    {
      "name": "Zotero Nexus",
      "one_line_profile": "Zotero extension for decentralized literature access",
      "detailed_description": "An extension for the Zotero reference manager that integrates IPFS-backed search and access capabilities, streamlining the retrieval of scientific literature directly within the reference management workflow.",
      "domains": [
        "Sci Knowledge"
      ],
      "subtask_category": [
        "literature_management",
        "reference_retrieval"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/aokellermann/zotero-nexus",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "zotero",
        "plugin",
        "literature-access"
      ],
      "id": 49
    },
    {
      "name": "PreliZ",
      "one_line_profile": "Tool for eliciting and exploring prior probability distributions",
      "detailed_description": "A library designed to assist researchers in selecting and eliciting prior distributions for Bayesian statistical modeling. It provides visualization and interaction tools to translate expert knowledge into statistical priors.",
      "domains": [
        "Statistics",
        "Data Analysis"
      ],
      "subtask_category": [
        "prior_elicitation",
        "statistical_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/arviz-devs/preliz",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bayesian",
        "statistics",
        "visualization"
      ],
      "id": 50
    },
    {
      "name": "STONED-SELFIES",
      "one_line_profile": "Efficient algorithm for molecular generation and optimization",
      "detailed_description": "Implementation of the STONED (Superfast Traversal, Optimization, Novelty, Exploration and Discovery) algorithm. It uses SELFIES representation for efficient and robust molecular design and chemical space exploration.",
      "domains": [
        "Chemistry",
        "Drug Discovery"
      ],
      "subtask_category": [
        "molecular_generation",
        "chemical_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/aspuru-guzik-group/stoned-selfies",
      "help_website": [],
      "license": null,
      "tags": [
        "molecular-design",
        "selfies",
        "generative-models"
      ],
      "id": 51
    },
    {
      "name": "WP-Scholar",
      "one_line_profile": "WordPress plugin for scientific and technical writing",
      "detailed_description": "A publishing tool that enables researchers to write technical articles on WordPress with support for Markdown, LaTeX, Jupyter notebooks, and interactive charts (Plotly/Bokeh), facilitating scientific communication.",
      "domains": [
        "Sci Communication"
      ],
      "subtask_category": [
        "scientific_writing",
        "publishing"
      ],
      "application_level": "workflow",
      "primary_language": "PHP",
      "repo_url": "https://github.com/aurelienpierre/wp-scholar",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "wordpress",
        "latex",
        "scientific-publishing"
      ],
      "id": 52
    },
    {
      "name": "MCP Semantic Scholar Server",
      "one_line_profile": "Model Context Protocol server for Semantic Scholar integration",
      "detailed_description": "A server implementation of the Model Context Protocol (MCP) that connects Large Language Models (LLMs) with the Semantic Scholar API, enabling AI agents to search and retrieve scientific literature.",
      "domains": [
        "G1-06",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "literature_search",
        "llm_integration"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/benhaotang/mcp-semantic-scholar-server",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "semantic-scholar",
        "llm-agent"
      ],
      "id": 53
    },
    {
      "name": "ChemGAN Challenge",
      "one_line_profile": "Generative adversarial network framework for drug discovery",
      "detailed_description": "Codebase for the ChemGAN challenge, providing implementations of Generative Adversarial Networks (GANs) specifically tuned for generating chemical structures and exploring chemical diversity in drug discovery.",
      "domains": [
        "Chemistry",
        "Drug Discovery"
      ],
      "subtask_category": [
        "molecular_generation",
        "drug_design"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/benstaf/ChemGAN-challenge",
      "help_website": [],
      "license": null,
      "tags": [
        "gan",
        "cheminformatics",
        "drug-discovery"
      ],
      "id": 54
    },
    {
      "name": "HypothesisHub",
      "one_line_profile": "Automated research question and hypothesis generation tool",
      "detailed_description": "An AI-driven tool designed to analyze scientific literature and automatically generate potential research questions and hypotheses, aiding researchers in the ideation phase.",
      "domains": [
        "Sci Knowledge"
      ],
      "subtask_category": [
        "hypothesis_generation",
        "literature_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/bhaskatripathi/HypothesisHub",
      "help_website": [],
      "license": null,
      "tags": [
        "hypothesis-generation",
        "nlp",
        "research-automation"
      ],
      "id": 55
    },
    {
      "name": "PlatCOVID",
      "one_line_profile": "Web platform for COVID-19 literature analysis",
      "detailed_description": "A web-based platform designed to cluster, classify, and analyze the vast volume of scientific literature related to COVID-19, supporting rapid information retrieval and synthesis during the pandemic.",
      "domains": [
        "Biology",
        "Medicine"
      ],
      "subtask_category": [
        "literature_analysis",
        "text_mining"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/bio-hub/bio-hub.github.io",
      "help_website": [],
      "license": null,
      "tags": [
        "covid-19",
        "literature-mining",
        "web-platform"
      ],
      "id": 56
    },
    {
      "name": "BioAgents",
      "one_line_profile": "Multi-agent framework for autonomous biological research",
      "detailed_description": "An AI framework that orchestrates multiple agents (literature analysis, data science) to conduct autonomous deep research in biological sciences, integrating user feedback for iterative discovery.",
      "domains": [
        "Biology",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "autonomous_research",
        "literature_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/bio-xyz/BioAgents",
      "help_website": [],
      "license": null,
      "tags": [
        "agent-framework",
        "biology",
        "autonomous-science"
      ],
      "id": 57
    },
    {
      "name": "Cool Papers",
      "one_line_profile": "Immersive daily paper discovery platform",
      "detailed_description": "A popular web-based tool for discovering and browsing daily arXiv papers (Kexue Kongjian), featuring automated summaries and filtering to help researchers stay updated with the latest literature.",
      "domains": [
        "G1-06",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "paper_discovery",
        "literature_monitoring"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/bojone/papers.cool",
      "help_website": [],
      "license": null,
      "tags": [
        "arxiv",
        "paper-discovery",
        "daily-updates"
      ],
      "id": 58
    },
    {
      "name": "NN for LBD",
      "one_line_profile": "Neural network models for Literature-based Discovery",
      "detailed_description": "A library implementing neural network approaches for Literature-based Discovery (LBD), enabling the identification of implicit connections and hypotheses within scientific text corpora.",
      "domains": [
        "Sci Knowledge"
      ],
      "subtask_category": [
        "literature_based_discovery",
        "hypothesis_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cambridgeltl/nn_for_LBD",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lbd",
        "nlp",
        "discovery"
      ],
      "id": 59
    },
    {
      "name": "Paper Note Filler",
      "one_line_profile": "Obsidian plugin for automated paper note creation",
      "detailed_description": "An Obsidian plugin that automatically retrieves metadata from arXiv, ACL Anthology, and Semantic Scholar to create structured notes for scientific papers, streamlining the research note-taking process.",
      "domains": [
        "G1-06",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "literature_management",
        "note_taking"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/chauff/paper-note-filler",
      "help_website": [],
      "license": null,
      "tags": [
        "obsidian",
        "metadata-extraction",
        "productivity"
      ],
      "id": 60
    },
    {
      "name": "ArXiv Slack Bot",
      "one_line_profile": "Slack bot for daily top ML paper notifications",
      "detailed_description": "A bot service that monitors arXiv for top machine learning papers and posts daily updates to Slack, facilitating team-based literature tracking and discovery.",
      "domains": [
        "G1-06",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "paper_discovery",
        "alert_service"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/chintu619/citation-sorted-arxiv-slack-bot",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "slack-bot",
        "arxiv",
        "paper-alert"
      ],
      "id": 61
    },
    {
      "name": "zotero-markdb-connect",
      "one_line_profile": "Zotero plugin linking Markdown databases to Zotero items for integrated research note-taking",
      "detailed_description": "A Zotero plugin that establishes a link between a Zotero bibliography and a Markdown database (e.g., Obsidian). It allows researchers to jump directly from Zotero items to connected Markdown notes and automatically tags Zotero items to track which papers have associated notes.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "knowledge_management",
        "literature_annotation"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/daeh/zotero-markdb-connect",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "zotero",
        "markdown",
        "obsidian",
        "knowledge-base"
      ],
      "id": 62
    },
    {
      "name": "semanticscholar",
      "one_line_profile": "Unofficial Python client for the Semantic Scholar API",
      "detailed_description": "A Python client library that provides an interface to the Semantic Scholar API, enabling researchers to programmatically retrieve paper details, citations, references, and author information for bibliometric analysis and literature discovery.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_retrieval",
        "bibliometrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/danielnsilva/semanticscholar",
      "help_website": [
        "https://pypi.org/project/semanticscholar/"
      ],
      "license": "MIT",
      "tags": [
        "semantic-scholar",
        "api-client",
        "literature-search"
      ],
      "id": 63
    },
    {
      "name": "zotero2SemanticScholar",
      "one_line_profile": "Utility to synchronize Zotero libraries with Semantic Scholar",
      "detailed_description": "A Python tool that connects a local Zotero library to Semantic Scholar. It facilitates the creation of citation alerts and helps manage literature discovery by bridging personal bibliography management with external citation databases.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_discovery",
        "citation_alert"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/davidAlgis/zotero2SemanticScholar",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "zotero",
        "semantic-scholar",
        "automation"
      ],
      "id": 64
    },
    {
      "name": "paper-reviewer",
      "one_line_profile": "Automated pipeline for generating paper reviews and summaries using LLMs",
      "detailed_description": "A tool that leverages Large Language Models to generate comprehensive reviews and blog posts from arXiv papers. It powers the HuggingFace Daily Papers platform, automating the synthesis and dissemination of scientific literature.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_summarization",
        "automated_review"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/deep-diver/paper-reviewer",
      "help_website": [
        "https://huggingface.co/papers"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "arxiv",
        "summarization",
        "science-communication"
      ],
      "id": 65
    },
    {
      "name": "LLM-SR",
      "one_line_profile": "LLM-based solver for scientific equation discovery and symbolic regression",
      "detailed_description": "The official implementation of LLM-SR, a method utilizing Large Language Models for Scientific Equation Discovery and Symbolic Regression. It serves as a solver to infer mathematical laws and equations from scientific data.",
      "domains": [
        "Sci Knowledge",
        "Physics"
      ],
      "subtask_category": [
        "symbolic_regression",
        "equation_discovery"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/deep-symbolic-mathematics/LLM-SR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "symbolic-regression",
        "llm",
        "scientific-discovery"
      ],
      "id": 66
    },
    {
      "name": "SciAssess",
      "one_line_profile": "Benchmark for evaluating LLMs on scientific literature analysis",
      "detailed_description": "A comprehensive benchmark suite designed to evaluate the proficiency of Large Language Models in analyzing scientific literature. It covers tasks such as memorization, comprehension, and analysis across various scientific fields.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "model_evaluation",
        "literature_analysis"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepmodeling/SciAssess",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "benchmark",
        "llm",
        "scientific-literature"
      ],
      "id": 67
    },
    {
      "name": "papergraph",
      "one_line_profile": "Infrastructure for building and querying citation graphs",
      "detailed_description": "A platform for constructing and analyzing AI/ML citation graphs using Postgres and GraphQL. It provides infrastructure to ingest paper data and query citation relationships for bibliometric analysis.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "citation_network_analysis",
        "knowledge_graph_construction"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/dennybritz/papergraph",
      "help_website": [],
      "license": null,
      "tags": [
        "citation-graph",
        "postgres",
        "graphql",
        "bibliometrics"
      ],
      "id": 68
    },
    {
      "name": "daily-arXiv-ai-enhanced",
      "one_line_profile": "Automated workflow to crawl, summarize, and visualize daily arXiv papers",
      "detailed_description": "An automated tool that crawls arXiv for new papers daily, uses AI to generate summaries, and publishes the results to a website. It aids researchers in keeping up with the latest literature through AI-enhanced curation.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_monitoring",
        "automated_summarization"
      ],
      "application_level": "workflow",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/dw-dengwei/daily-arXiv-ai-enhanced",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "arxiv",
        "automation",
        "ai-summary"
      ],
      "id": 69
    },
    {
      "name": "etudier",
      "one_line_profile": "Command-line tool to extract citation networks from Google Scholar",
      "detailed_description": "A command-line utility that scrapes Google Scholar to extract citation networks for a given set of papers or authors. It outputs data in formats suitable for network analysis and visualization.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "citation_network_extraction",
        "web_scraping"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/edsu/etudier",
      "help_website": [],
      "license": null,
      "tags": [
        "google-scholar",
        "citation-network",
        "scraping"
      ],
      "id": 70
    },
    {
      "name": "openalexnet",
      "one_line_profile": "Python library for retrieving and analyzing OpenAlex citation networks",
      "detailed_description": "A helper library designed to process and obtain data from the OpenAlex dataset via its API. It provides functionality to generate and analyze citation and co-authorship networks from search queries.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "citation_network_analysis",
        "bibliometrics"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/filipinascimento/openalexnet",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "openalex",
        "bibliometrics",
        "network-analysis"
      ],
      "id": 71
    },
    {
      "name": "Valmont-F",
      "one_line_profile": "Literature Based Discovery (LBD) system implementing the Arrowsmith algorithm",
      "detailed_description": "A system for Literature Based Discovery (LBD) that re-implements the Arrowsmith algorithm to identify hidden connections between scientific concepts in literature.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_discovery",
        "hypothesis_generation"
      ],
      "application_level": "solver",
      "primary_language": "CSS",
      "repo_url": "https://github.com/fogbeam/Valmont-F",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "literature-based-discovery",
        "arrowsmith",
        "text-mining"
      ],
      "id": 72
    },
    {
      "name": "Daily-Arxiv-Tracking-Automation",
      "one_line_profile": "Automated pipeline for tracking and downloading daily ArXiv papers",
      "detailed_description": "A Python-based automation tool that monitors daily ArXiv RSS feeds and automatically downloads PDFs, facilitating literature tracking for researchers.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_tracking",
        "data_retrieval"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/gisbi-kim/Daily-Arxiv-Tracking-Automation",
      "help_website": [],
      "license": null,
      "tags": [
        "arxiv",
        "automation",
        "literature-tracking"
      ],
      "id": 73
    },
    {
      "name": "molminer",
      "one_line_profile": "Tool for extracting chemical compounds from scientific literature",
      "detailed_description": "A Python library and command-line tool designed to extract chemical compound names and structures from scientific text, aiding in chemical literature mining.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "entity_extraction",
        "text_mining"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gorgitko/molminer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chemistry",
        "nlp",
        "entity-extraction"
      ],
      "id": 74
    },
    {
      "name": "citation-graph-pubmed",
      "one_line_profile": "R script to generate citation graphs from PubMed data",
      "detailed_description": "A lightweight tool using R to construct and visualize citation networks specifically from PubMed bibliographic data.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "citation_analysis",
        "network_construction"
      ],
      "application_level": "solver",
      "primary_language": "R",
      "repo_url": "https://github.com/guillaumelobet/citation-graph-pubmed",
      "help_website": [],
      "license": null,
      "tags": [
        "pubmed",
        "citation-graph",
        "bibliometrics"
      ],
      "id": 75
    },
    {
      "name": "AIRA-SemanticScholar",
      "one_line_profile": "Model Context Protocol (MCP) server for Semantic Scholar",
      "detailed_description": "An integration tool implementing the Model Context Protocol to allow AI agents to query and retrieve data from the Semantic Scholar academic graph.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_retrieval",
        "agent_integration"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/hamid-vakilzadeh/AIRA-SemanticScholar",
      "help_website": [],
      "license": null,
      "tags": [
        "mcp",
        "semantic-scholar",
        "ai-agent"
      ],
      "id": 76
    },
    {
      "name": "text_mining_tools",
      "one_line_profile": "NLP utilities for scientific literature processing",
      "detailed_description": "A collection of Python tools designed to facilitate natural language processing tasks specifically for scientific literature.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "text_mining",
        "nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hjkgrp/text_mining_tools",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "nlp",
        "text-mining",
        "scientific-literature"
      ],
      "id": 77
    },
    {
      "name": "AI-Co-Scientist",
      "one_line_profile": "AI agent framework for automated research discovery",
      "detailed_description": "An advanced research assistant platform that utilizes AI agents (CrewAI) to generate research directions and analyze scientific literature.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "hypothesis_generation",
        "literature_analysis"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/iabheejit/AI-Co-Scientist",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ai-scientist",
        "agent",
        "research-assistant"
      ],
      "id": 78
    },
    {
      "name": "ScholarlyRecommender",
      "one_line_profile": "End-to-end academic paper recommendation feed generator",
      "detailed_description": "A tool that scrapes recent academic publications and prepares a personalized feed of recommended readings using content-based filtering.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "paper_recommendation",
        "literature_monitoring"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/iansnyder333/ScholarlyRecommender",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "recommender-system",
        "arxiv",
        "feed"
      ],
      "id": 79
    },
    {
      "name": "inciteful-zotero-plugin",
      "one_line_profile": "Zotero plugin for Inciteful.xyz literature discovery",
      "detailed_description": "A plugin for the Zotero reference manager that integrates Inciteful.xyz's citation graph based literature discovery features directly into the user's library.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_discovery",
        "reference_management"
      ],
      "application_level": "plugin",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/inciteful-xyz/inciteful-zotero-plugin",
      "help_website": [
        "https://inciteful.xyz"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "zotero",
        "citation-graph",
        "plugin"
      ],
      "id": 80
    },
    {
      "name": "infoLink",
      "one_line_profile": "Services for linking scientific literature and research datasets",
      "detailed_description": "A set of services designed to establish and manage links between scientific publications and their underlying research datasets.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "data_linking",
        "metadata_management"
      ],
      "application_level": "service",
      "primary_language": "Java",
      "repo_url": "https://github.com/infolis/infoLink",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "data-linking",
        "research-data",
        "infrastructure"
      ],
      "id": 81
    },
    {
      "name": "citation_map",
      "one_line_profile": "Tool to create Gephi citation graphs from Zotero PDFs",
      "detailed_description": "A Python tool that analyzes text from PDFs stored in Zotero to generate citation network files compatible with Gephi for visualization.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "citation_network_analysis",
        "visualization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jaks6/citation_map",
      "help_website": [],
      "license": null,
      "tags": [
        "zotero",
        "gephi",
        "citation-network"
      ],
      "id": 82
    },
    {
      "name": "ChemRxnExtractor",
      "one_line_profile": "Toolkit for chemical reaction extraction from literature",
      "detailed_description": "A toolkit designed to automatically extract chemical reaction information from scientific literature, supporting data mining in chemistry.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "reaction_extraction",
        "text_mining"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jiangfeng1124/ChemRxnExtractor",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chemistry",
        "reaction-extraction",
        "nlp"
      ],
      "id": 83
    },
    {
      "name": "Kosmos",
      "one_line_profile": "AI Scientist agent for autonomous discovery",
      "detailed_description": "An implementation of an AI Scientist agent capable of autonomous discovery, designed to be driven by LLM APIs for literature analysis and hypothesis generation.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "autonomous_discovery",
        "agent"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/jimmc414/Kosmos",
      "help_website": [],
      "license": null,
      "tags": [
        "ai-scientist",
        "autonomous-discovery",
        "llm"
      ],
      "id": 84
    },
    {
      "name": "ges",
      "one_line_profile": "Implementation of Greedy Equivalence Search (GES) for causal discovery",
      "detailed_description": "A Python implementation of the GES algorithm, a standard method for causal discovery (structure learning) from data, widely used in scientific modeling.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "causal_discovery",
        "structure_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/juangamella/ges",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "causal-inference",
        "causal-discovery",
        "ges"
      ],
      "id": 85
    },
    {
      "name": "ChatDailyPapers",
      "one_line_profile": "Automated daily academic paper subscription and summarization pipeline",
      "detailed_description": "A pipeline that automatically fetches daily ArXiv papers based on keywords and generates summaries using ChatGPT, deployed via GitHub Actions.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_tracking",
        "summarization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/justchenhao/ChatDailyPapers",
      "help_website": [],
      "license": null,
      "tags": [
        "arxiv",
        "chatgpt",
        "summarization"
      ],
      "id": 86
    },
    {
      "name": "Cogito",
      "one_line_profile": "Computational framework for literature analysis via LLMs",
      "detailed_description": "A framework employing synthesis and critique systems to autonomously accelerate expert research on scientific literature using LLMs and ArXiv data.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_analysis",
        "synthesis"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/justinlietz93/Cogito",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "research-assistant",
        "arxiv"
      ],
      "id": 87
    },
    {
      "name": "arxiv-sanity-lite",
      "one_line_profile": "Lightweight ArXiv paper recommendation and tagging system",
      "detailed_description": "A web-based tool for tagging ArXiv papers and receiving recommendations based on TF-IDF feature vectors of abstracts, designed to help researchers manage literature.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "paper_recommendation",
        "literature_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/karpathy/arxiv-sanity-lite",
      "help_website": [
        "https://arxiv-sanity-lite.com"
      ],
      "license": "MIT",
      "tags": [
        "arxiv",
        "recommender-system",
        "web-app"
      ],
      "id": 88
    },
    {
      "name": "arxiv-sanity-preserver",
      "one_line_profile": "Web interface for browsing and filtering ArXiv submissions",
      "detailed_description": "The original ArXiv Sanity web interface for browsing, searching, and filtering recent ArXiv submissions to facilitate research discovery.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_discovery",
        "browsing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/karpathy/arxiv-sanity-preserver",
      "help_website": [
        "http://www.arxiv-sanity.com"
      ],
      "license": "MIT",
      "tags": [
        "arxiv",
        "literature-discovery",
        "web-app"
      ],
      "id": 89
    },
    {
      "name": "researchpooler",
      "one_line_profile": "Automated research publication discovery and analysis tool",
      "detailed_description": "A tool designed to automate the discovery of similar papers and analysis of research publications, aiming to reimagine the literature review process.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_review",
        "similarity_search"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/karpathy/researchpooler",
      "help_website": [],
      "license": null,
      "tags": [
        "literature-review",
        "automation",
        "discovery"
      ],
      "id": 90
    },
    {
      "name": "cli-arxiv",
      "one_line_profile": "Command-line interface for exploring and downloading arXiv papers",
      "detailed_description": "A CLI tool inspired by ArXiv Sanity Preserver that allows users to search, explore, and download research papers from arXiv directly from the terminal.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_retrieval",
        "paper_discovery"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/knguyenanhoa/cli-arxiv",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "arxiv",
        "cli",
        "literature-search"
      ],
      "id": 91
    },
    {
      "name": "daily-arxiv-noti",
      "one_line_profile": "Automated daily arXiv notification system based on keywords",
      "detailed_description": "A workflow tool that sends daily notifications about new arXiv papers matching user-defined keywords, helping researchers stay updated with specific domains.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_monitoring",
        "alerting_system"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/kobiso/daily-arxiv-noti",
      "help_website": [],
      "license": null,
      "tags": [
        "arxiv",
        "notification",
        "automation"
      ],
      "id": 92
    },
    {
      "name": "get-daily-arxiv-noti",
      "one_line_profile": "Script to fetch daily arXiv notifications for specific keywords",
      "detailed_description": "A Python-based utility to retrieve and filter daily arXiv submissions based on pre-defined keywords, facilitating literature tracking.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_monitoring",
        "paper_discovery"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kobiso/get-daily-arxiv-noti",
      "help_website": [],
      "license": null,
      "tags": [
        "arxiv",
        "literature-tracking"
      ],
      "id": 93
    },
    {
      "name": "Citation-Graph-Python",
      "one_line_profile": "Tool to generate citation graphs from references",
      "detailed_description": "A Python utility that automatically generates citation graphs based on references, aiding in the visualization of citation networks and academic influence.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "citation_analysis",
        "network_visualization"
      ],
      "application_level": "solver",
      "primary_language": "TeX",
      "repo_url": "https://github.com/lanstonchu/Citation-Graph-Python",
      "help_website": [],
      "license": null,
      "tags": [
        "citation-graph",
        "visualization",
        "bibliometrics"
      ],
      "id": 94
    },
    {
      "name": "LISC",
      "one_line_profile": "Literature Scanner for automated collection and analysis of scientific literature",
      "detailed_description": "A Python library designed to collect and analyze scientific literature from databases like PubMed and OpenCitations, enabling automated meta-analysis and term co-occurrence studies.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_mining",
        "meta_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lisc-tools/lisc",
      "help_website": [
        "https://lisc-tools.github.io/lisc/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "literature-mining",
        "pubmed",
        "bibliometrics"
      ],
      "id": 95
    },
    {
      "name": "TTS-arxiv-daily",
      "one_line_profile": "Automated daily updates for Text-to-Speech research papers",
      "detailed_description": "A GitHub Action-based workflow tool that automatically tracks, filters, and updates a repository with the latest Text-to-Speech papers from arXiv.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_monitoring",
        "paper_discovery"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/liutaocode/TTS-arxiv-daily",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "arxiv",
        "tts",
        "automation"
      ],
      "id": 96
    },
    {
      "name": "draw-citation-graph",
      "one_line_profile": "Script to generate citation graphs from BibTeX and PDFs",
      "detailed_description": "A Python script that attempts to construct and visualize a citation graph by parsing a BibTeX file and a directory of PDF files.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "citation_analysis",
        "network_visualization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mhl/draw-citation-graph",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bibtex",
        "citation-graph",
        "visualization"
      ],
      "id": 97
    },
    {
      "name": "PyS2",
      "one_line_profile": "Python library for the Semantic Scholar API",
      "detailed_description": "A Python client library for the Semantic Scholar API, providing typed objects and utilities to facilitate access to scientific literature data.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_retrieval",
        "api_client"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mirandrom/PyS2",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-scholar",
        "api-client",
        "literature-mining"
      ],
      "id": 98
    },
    {
      "name": "SS-self-hosting",
      "one_line_profile": "Utilities for self-hosting Semantic Scholar data",
      "detailed_description": "A repository providing tools and scripts to enable researchers to download and self-host the Semantic Scholar Open Research Corpus (S2ORC) for local analysis.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "data_management",
        "literature_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/moaraio/SS-self-hosting",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-scholar",
        "dataset-tools",
        "self-hosting"
      ],
      "id": 99
    },
    {
      "name": "nlp-arxiv-daily",
      "one_line_profile": "Automated daily updates for NLP research papers",
      "detailed_description": "A GitHub Action-based workflow that automatically updates a repository with the latest Natural Language Processing papers from arXiv, serving as a literature tracking tool.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_monitoring",
        "paper_discovery"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/monologg/nlp-arxiv-daily",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "arxiv",
        "automation"
      ],
      "id": 100
    },
    {
      "name": "arxiv_daily_aigc",
      "one_line_profile": "AI-driven daily arXiv paper crawler, analyzer, and organizer focusing on AIGC",
      "detailed_description": "An automated tool that crawls arXiv for new papers in the AIGC domain, utilizes AI to analyze and summarize them, and organizes the results into daily reports for researchers.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_tracking",
        "summarization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/onion-liu/arxiv_daily_aigc",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arxiv",
        "crawler",
        "llm",
        "literature-discovery"
      ],
      "id": 101
    },
    {
      "name": "citegraph",
      "one_line_profile": "A citation network explorer and visualization tool",
      "detailed_description": "A Python-based tool designed to explore and visualize citation networks, helping researchers understand the connections and influence flow between scientific papers.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "citation_analysis",
        "network_visualization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/oowekyala/citegraph",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "citation-network",
        "visualization",
        "bibliometrics"
      ],
      "id": 102
    },
    {
      "name": "pandoc-scholar",
      "one_line_profile": "Pandoc extension for creating semantically meaningful scientific articles",
      "detailed_description": "A tool built on top of Pandoc that simplifies the process of writing scientific papers in Markdown, handling citations, metadata, and formatting for academic publishing.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "scientific_writing",
        "publishing"
      ],
      "application_level": "library",
      "primary_language": "Lua",
      "repo_url": "https://github.com/pandoc-scholar/pandoc-scholar",
      "help_website": [
        "https://github.com/pandoc-scholar/pandoc-scholar"
      ],
      "license": "GPL-2.0",
      "tags": [
        "pandoc",
        "academic-writing",
        "publishing"
      ],
      "id": 103
    },
    {
      "name": "LitSearch",
      "one_line_profile": "A retrieval benchmark dataset for scientific literature search",
      "detailed_description": "A benchmark suite designed to evaluate retrieval systems for scientific literature, providing datasets and evaluation scripts to measure performance in finding relevant papers.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "benchmarking",
        "retrieval_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/princeton-nlp/LitSearch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "information-retrieval",
        "scientific-literature"
      ],
      "id": 104
    },
    {
      "name": "DRIFT",
      "one_line_profile": "Tool for diachronic analysis of scientific literature to track evolution of ideas",
      "detailed_description": "A tool designed for the diachronic analysis of scientific literature, enabling researchers to track how scientific concepts and terminology evolve over time.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "trend_analysis",
        "bibliometrics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/rajaswa/DRIFT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bibliometrics",
        "text-analysis",
        "science-of-science"
      ],
      "id": 105
    },
    {
      "name": "sciencefair",
      "one_line_profile": "Desktop application for discovering, collecting, and reading scientific literature (P2P)",
      "detailed_description": "A desktop application that provides a peer-to-peer platform for discovering, collecting, and reading scientific papers, aiming to make access to scientific knowledge more open and user-friendly.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_management",
        "discovery"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/sciencefair-land/sciencefair",
      "help_website": [
        "http://sciencefair-land.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "p2p",
        "literature-manager",
        "open-science"
      ],
      "id": 106
    },
    {
      "name": "scirate",
      "one_line_profile": "Open source platform for arXiv preprint peer review and discovery",
      "detailed_description": "The source code for Scirate, an open platform that allows researchers to follow arXiv categories, read preprints, and participate in open peer review through voting and commenting.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "peer_review",
        "literature_discovery"
      ],
      "application_level": "platform",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/scirate/scirate",
      "help_website": [
        "https://scirate.com"
      ],
      "license": "MIT",
      "tags": [
        "arxiv",
        "peer-review",
        "open-access"
      ],
      "id": 107
    },
    {
      "name": "LitLLM",
      "one_line_profile": "Toolkit for scientific literature review using Large Language Models",
      "detailed_description": "A toolkit designed to assist in scientific literature reviews by leveraging Large Language Models (LLMs) to summarize papers, extract key information, and synthesize findings.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_review",
        "summarization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/shubhamagarwal92/LitLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "literature-review",
        "automation"
      ],
      "id": 108
    },
    {
      "name": "gpt_paper_assistant",
      "one_line_profile": "GPT-4 based personalized ArXiv paper assistant bot",
      "detailed_description": "A tool that utilizes GPT-4 to assist researchers in discovering, filtering, and summarizing ArXiv papers based on personalized research interests.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_discovery",
        "summarization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tatsu-lab/gpt_paper_assistant",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "arxiv",
        "gpt-4",
        "literature-review",
        "automation"
      ],
      "id": 109
    },
    {
      "name": "Summarxiv",
      "one_line_profile": "Daily latest arXiv paper summary digest generator",
      "detailed_description": "A Python tool that generates daily summaries of the latest ArXiv papers using AI models to help researchers efficiently monitor new literature.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "summarization",
        "literature_monitoring"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/theeluwin/Summarxiv",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arxiv",
        "summarization",
        "nlp",
        "digest"
      ],
      "id": 110
    },
    {
      "name": "ALIGNN",
      "one_line_profile": "Atomistic Line Graph Neural Network for materials property prediction",
      "detailed_description": "A library implementing Atomistic Line Graph Neural Networks (ALIGNN) for predicting material properties from atomic structures, developed by NIST.",
      "domains": [
        "Materials Science"
      ],
      "subtask_category": [
        "property_prediction",
        "molecular_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/usnistgov/alignn",
      "help_website": [
        "https://jarvis.nist.gov/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "gnn",
        "materials-science",
        "deep-learning",
        "atomistic-simulation"
      ],
      "id": 111
    },
    {
      "name": "PaperMemory",
      "one_line_profile": "Browser-based research paper management and discovery tool",
      "detailed_description": "A browser extension and tool that acts as a reference manager, providing automatic paper detection, venue matching, and code repository discovery for researchers.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "reference_management",
        "literature_discovery"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/vict0rsch/PaperMemory",
      "help_website": [
        "https://papermemory.org"
      ],
      "license": "MIT",
      "tags": [
        "reference-manager",
        "arxiv",
        "productivity",
        "browser-extension"
      ],
      "id": 112
    },
    {
      "name": "arxiv-sh",
      "one_line_profile": "CLI tool for querying new arXiv articles via RSS",
      "detailed_description": "A shell script that allows users to query and filter new arXiv articles in selected topics directly from the command line interface.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_monitoring"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/victoriastuart/arxiv-sh",
      "help_website": [],
      "license": null,
      "tags": [
        "arxiv",
        "cli",
        "rss",
        "automation"
      ],
      "id": 113
    },
    {
      "name": "arxiv_paper_downloader",
      "one_line_profile": "Automated ArXiv paper downloader and manager",
      "detailed_description": "A Python utility to automatically download daily papers from ArXiv and manage them with markdown previews for efficient reading.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "data_acquisition",
        "literature_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wbbeyourself/arxiv_paper_downloader",
      "help_website": [],
      "license": null,
      "tags": [
        "arxiv",
        "downloader",
        "automation",
        "markdown"
      ],
      "id": 114
    },
    {
      "name": "ArxivDailyOverview",
      "one_line_profile": "Tool to extract and crop key information from ArXiv papers",
      "detailed_description": "A utility that automatically downloads ArXiv papers and crops key figures or information to generate a daily overview for rapid literature scanning.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "data_processing",
        "visualization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wmpscc/ArxivDailyOverview",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "arxiv",
        "image-processing",
        "automation",
        "literature-review"
      ],
      "id": 115
    },
    {
      "name": "SciArena",
      "one_line_profile": "Open evaluation platform for foundation models in scientific literature tasks",
      "detailed_description": "A benchmarking and evaluation platform designed to assess the performance of foundation models on various scientific literature understanding tasks, facilitating standardized comparisons.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmark"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yale-nlp/SciArena",
      "help_website": [],
      "license": null,
      "tags": [
        "evaluation",
        "benchmark",
        "scientific-literature",
        "llm"
      ],
      "id": 116
    },
    {
      "name": "naimai",
      "one_line_profile": "Python package to assist with scientific literature research",
      "detailed_description": "A utility package designed to streamline scientific literature research processes, likely providing functions for retrieval or management of bibliographic data.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_search",
        "retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yassinekdi/naimai",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "literature-research",
        "utility",
        "python"
      ],
      "id": 117
    },
    {
      "name": "arxiv-daily",
      "one_line_profile": "Automated workflow for daily arXiv paper updates",
      "detailed_description": "A GitHub Actions workflow tool that automatically fetches and updates daily arXiv papers for specific fields, generating reports to assist researchers in tracking new literature.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_monitoring",
        "discovery"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/yyyanbj/arxiv-daily",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arxiv",
        "automation",
        "literature-tracking",
        "github-actions"
      ],
      "id": 118
    },
    {
      "name": "Paper-Daily-Notice",
      "one_line_profile": "Personalized daily arXiv paper notification tool",
      "detailed_description": "A tool designed to fetch and notify users of new arXiv papers based on user-defined interests, facilitating personalized scientific literature discovery.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_monitoring",
        "discovery"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhuhu00/Paper-Daily-Notice",
      "help_website": [],
      "license": null,
      "tags": [
        "arxiv",
        "notification",
        "personalization"
      ],
      "id": 119
    },
    {
      "name": "daily_arxiv",
      "one_line_profile": "Automated collection of daily arXiv papers with code",
      "detailed_description": "A GitHub Action-based tool that collects daily arXiv paper lists, specifically highlighting those with publicly available source code, to streamline literature and code discovery.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "literature_monitoring",
        "discovery"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhuwenxing/daily_arxiv",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "arxiv",
        "papers-with-code",
        "automation",
        "github-actions"
      ],
      "id": 120
    },
    {
      "name": "semantic-scholar-fastmcp-mcp-server",
      "one_line_profile": "FastMCP server for Semantic Scholar API access",
      "detailed_description": "A server implementation using the Model Context Protocol (MCP) to provide LLM agents and tools with structured access to the Semantic Scholar API for retrieving academic paper data and citation networks.",
      "domains": [
        "G1",
        "G1-06"
      ],
      "subtask_category": [
        "data_access",
        "api_connector"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/zongmin-yu/semantic-scholar-fastmcp-mcp-server",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-scholar",
        "mcp",
        "api",
        "llm-tool"
      ],
      "id": 121
    }
  ]
}