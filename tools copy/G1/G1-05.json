{
  "generated_at": "2025-12-16T04:24:55.604512+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "G1",
      "leaf_cluster_name": "科研文献-检索/解析/引用网络生态",
      "domain": "Sci Knowledge",
      "typical_objects": "PDFs/citations",
      "task_chain": "解析→抽取→索引→检索→评测",
      "tool_form": "解析器 + 检索 + 评测"
    },
    "unit": {
      "unit_id": "G1-05",
      "unit_name": "评测/事实核验/去幻觉",
      "target_scale": "150–300",
      "coverage_tools": "eval harness、fact checking"
    },
    "search": {
      "target_candidates": 300,
      "queries": [
        "[GH] ARES",
        "[GH] FacTool",
        "[GH] FActScore",
        "[GH] SelfCheckGPT",
        "[GH] HELM",
        "[GH] DeepEval",
        "[GH] TruLens",
        "[GH] Ragas",
        "[GH] LM-Evaluation-Harness",
        "[GH] llm evaluation",
        "[GH] rag evaluation",
        "[GH] hallucination detection",
        "[GH] fact checking",
        "[GH] citation verification",
        "[GH] eval harness",
        "[GH] benchmark framework",
        "[GH] truthfulness",
        "[GH] claim verification",
        "[GH] faithfulness metric",
        "[GH] factuality",
        "[GH] retrieval evaluation",
        "[WEB] llm evaluation framework github",
        "[WEB] rag evaluation metrics github",
        "[WEB] automated fact checking tools github",
        "[WEB] hallucination detection library github",
        "[WEB] scientific claim verification github"
      ],
      "total_candidates": 1039,
      "tool_candidates": 630,
      "final_tools": 187
    }
  },
  "tools": [
    {
      "name": "GraphRAG Agent",
      "one_line_profile": "Integrated framework combining GraphRAG, LightRAG, and Neo4j for knowledge graph construction and RAG",
      "detailed_description": "A comprehensive RAG solution that integrates GraphRAG, LightRAG, and Neo4j-llm-graph-builder to facilitate knowledge graph construction and search. It includes a custom evaluation framework for GraphRAG and integrates DeepSearch technology for private domain RAG reasoning.",
      "domains": [
        "Sci Knowledge",
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "retrieval_augmented_generation",
        "rag_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/1517005260/graph-rag-agent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "knowledge-graph",
        "neo4j",
        "evaluation"
      ],
      "id": 1
    },
    {
      "name": "ARES OS",
      "one_line_profile": "Research software for creating closed-loop autonomous experimentation systems",
      "detailed_description": "ARES OS is a research software platform designed to streamline the creation and management of systems for closed-loop, autonomous experimentation in scientific laboratories (Self-Driving Labs).",
      "domains": [
        "Lab Automation",
        "Autonomous Experimentation"
      ],
      "subtask_category": [
        "autonomous_experimentation",
        "lab_automation"
      ],
      "application_level": "platform",
      "primary_language": "C#",
      "repo_url": "https://github.com/AFRL-ARES/ARES_OS",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "autonomous-experimentation",
        "robotics",
        "lab-automation"
      ],
      "id": 2
    },
    {
      "name": "robosuite",
      "one_line_profile": "Modular simulation framework and benchmark for robot learning",
      "detailed_description": "A modular simulation framework and benchmark suite for robot learning, powered by the MuJoCo physics engine. It provides a suite of benchmark environments for robotic manipulation tasks, supporting research in reproducibility and standardization.",
      "domains": [
        "Robotics",
        "Simulation"
      ],
      "subtask_category": [
        "simulation",
        "robot_learning",
        "benchmark"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ARISE-Initiative/robosuite",
      "help_website": [
        "https://robosuite.ai"
      ],
      "license": "NOASSERTION",
      "tags": [
        "robotics",
        "simulation",
        "mujoco",
        "benchmark"
      ],
      "id": 3
    },
    {
      "name": "SenTrEv",
      "one_line_profile": "Evaluation tool for Sentence Transformers retrieval on PDFs",
      "detailed_description": "A simple and customizable evaluation tool designed to assess the text retrieval performance of Sentence Transformers embedders specifically on PDF documents, aiding in the selection of optimal embedding models for RAG systems.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "retrieval_evaluation",
        "embedding_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AstraBert/SenTrEv",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "retrieval",
        "evaluation",
        "sentence-transformers",
        "pdf"
      ],
      "id": 4
    },
    {
      "name": "ko-lm-evaluation-harness",
      "one_line_profile": "Evaluation harness for Korean Large Language Models",
      "detailed_description": "A fork of the EleutherAI lm-evaluation-harness specialized for evaluating Korean Large Language Models (LLMs) on various Korean datasets and benchmarks.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmark"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Beomi/ko-lm-evaluation-harness",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation",
        "llm",
        "korean",
        "benchmark"
      ],
      "id": 5
    },
    {
      "name": "ClaimeAI",
      "one_line_profile": "Automated fact-checking system using LangGraph",
      "detailed_description": "An AI-powered fact-checking system built with LangGraph that dissects text into verifiable claims, cross-references them with real-world evidence via web searches, and generates detailed accuracy reports.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "fact_checking",
        "claim_verification"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/BharathxD/ClaimeAI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fact-checking",
        "langgraph",
        "verification",
        "hallucination-detection"
      ],
      "id": 6
    },
    {
      "name": "RAGEval",
      "one_line_profile": "Automated evaluation system for RAG pipelines",
      "detailed_description": "A one-stop automated evaluation solution for Retrieval-Augmented Generation (RAG) systems, designed to assess the performance and quality of RAG pipelines.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "system_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/BytePioneer-AI/RAGEval",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "evaluation",
        "benchmark"
      ],
      "id": 7
    },
    {
      "name": "DeFactoNLP",
      "one_line_profile": "Automated fact-checking system using NER and attention models",
      "detailed_description": "An automated system designed for fact-checking claims by leveraging Named Entity Recognition (NER), TF-IDF vector comparison, and Decomposable Attention models to verify information against knowledge bases.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "fact_checking",
        "claim_verification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DeFacto/DeFactoNLP",
      "help_website": [],
      "license": null,
      "tags": [
        "fact-checking",
        "nlp",
        "automated-verification"
      ],
      "id": 8
    },
    {
      "name": "XRAG",
      "one_line_profile": "Benchmark framework for RAG component modules",
      "detailed_description": "A benchmarking framework designed to evaluate and examine the foundational component modules within Advanced Retrieval-Augmented Generation (RAG) systems, aiding in the optimization of retrieval and generation strategies.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DocAILab/XRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "benchmark",
        "evaluation"
      ],
      "id": 9
    },
    {
      "name": "evox",
      "one_line_profile": "Distributed GPU-accelerated framework for evolutionary computation",
      "detailed_description": "A comprehensive library and framework for evolutionary algorithms and benchmark problems, leveraging JAX for distributed GPU acceleration to solve complex optimization tasks in scientific modeling.",
      "domains": [
        "Scientific Computing",
        "Optimization"
      ],
      "subtask_category": [
        "evolutionary_computation",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EMI-Group/evox",
      "help_website": [
        "https://evox.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "evolutionary-algorithms",
        "gpu-acceleration",
        "optimization",
        "jax"
      ],
      "id": 10
    },
    {
      "name": "lm-evaluation-harness",
      "one_line_profile": "Standard framework for few-shot evaluation of language models",
      "detailed_description": "A widely used framework for evaluating autoregressive language models across a large number of tasks, providing a standardized interface for few-shot performance measurement and comparison.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EleutherAI/lm-evaluation-harness",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "evaluation",
        "few-shot",
        "nlp"
      ],
      "id": 11
    },
    {
      "name": "JamAIBase",
      "one_line_profile": "Collaborative platform for AI pipeline creation and evaluation",
      "detailed_description": "A 'spreadsheet for AI' platform that allows users to chain cells into pipelines, experiment with prompts and models, and evaluate LLM responses in real-time, facilitating collaborative development and testing of AI applications.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "pipeline_orchestration",
        "response_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/EmbeddedLLM/JamAIBase",
      "help_website": [
        "https://jamaibase.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-ops",
        "evaluation",
        "collaboration",
        "no-code"
      ],
      "id": 12
    },
    {
      "name": "LLMZoo",
      "one_line_profile": "Data, models, and evaluation benchmark for LLMs",
      "detailed_description": "A project providing a collection of instruction-tuned data, efficient models, and evaluation benchmarks to facilitate research and development in large language models.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "dataset_management"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/FreedomIntelligence/LLMZoo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "benchmark",
        "instruction-tuning"
      ],
      "id": 13
    },
    {
      "name": "DISC-MedLLM",
      "one_line_profile": "Medical LLM solution for conversational healthcare",
      "detailed_description": "A comprehensive solution leveraging Large Language Models to provide accurate and truthful medical responses, serving as a specialized tool for medical text generation and interaction.",
      "domains": [
        "G1",
        "Medical"
      ],
      "subtask_category": [
        "medical_inference",
        "domain_specific_llm"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FudanDISC/DISC-MedLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-ai",
        "llm",
        "healthcare"
      ],
      "id": 14
    },
    {
      "name": "FacTool",
      "one_line_profile": "Factuality detection framework for generative AI",
      "detailed_description": "A tool designed to detect factuality errors in texts generated by large language models, assessing claims across various domains including knowledge-based QA, code generation, and math reasoning.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "factuality_detection",
        "hallucination_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/GAIR-NLP/factool",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fact-checking",
        "generative-ai",
        "hallucination"
      ],
      "id": 15
    },
    {
      "name": "FEAT",
      "one_line_profile": "Factcheck Explorer Analysis Tool",
      "detailed_description": "A tool designed to facilitate the exploration, analysis, and visualization of fact-checking data, helping researchers and fact-checkers gain insights from large datasets of verified claims.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "data_visualization",
        "fact_checking_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GONZOsint/FEAT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fact-checking",
        "visualization",
        "osint"
      ],
      "id": 16
    },
    {
      "name": "Giskard",
      "one_line_profile": "Evaluation and testing library for LLM agents",
      "detailed_description": "An open-source testing framework dedicated to ensuring the quality, security, and reliability of AI models and LLM agents through automated tests for hallucinations, bias, and performance issues.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_testing",
        "quality_assurance"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Giskard-AI/giskard-oss",
      "help_website": [
        "https://docs.giskard.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "testing",
        "llm",
        "quality-control",
        "security"
      ],
      "id": 17
    },
    {
      "name": "GraphRAG-Benchmark",
      "one_line_profile": "Benchmark and dataset for evaluating GraphRAG models",
      "detailed_description": "A comprehensive benchmark suite designed to evaluate Retrieval-Augmented Generation (RAG) models that utilize knowledge graphs, providing metrics and datasets for performance assessment.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "graph_rag"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/GraphRAG-Bench/GraphRAG-Benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-rag",
        "benchmark",
        "evaluation"
      ],
      "id": 18
    },
    {
      "name": "Helicone",
      "one_line_profile": "Open source LLM observability and evaluation platform",
      "detailed_description": "A platform for monitoring, logging, and evaluating Large Language Model interactions, providing tools for tracking costs, latency, and quality metrics to improve AI applications.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "observability",
        "model_monitoring"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/Helicone/helicone",
      "help_website": [
        "https://docs.helicone.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "observability",
        "llm-ops",
        "monitoring"
      ],
      "id": 19
    },
    {
      "name": "FactSumm",
      "one_line_profile": "Factual consistency scorer for abstractive summarization",
      "detailed_description": "A tool designed to evaluate the factual consistency of abstractive summaries generated by NLP models, helping to detect hallucinations and ensure summary accuracy.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "consistency_scoring",
        "summarization_eval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Huffon/factsumm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "summarization",
        "factuality"
      ],
      "id": 20
    },
    {
      "name": "ARES",
      "one_line_profile": "AI Robustness Evaluation System",
      "detailed_description": "A system developed by IBM for evaluating the robustness of AI models, likely focusing on adversarial attacks and defense mechanisms (based on name and context, though description is brief).",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "robustness_evaluation",
        "adversarial_testing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/IBM/ares",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "robustness",
        "ai-safety",
        "evaluation"
      ],
      "id": 21
    },
    {
      "name": "Prophecies",
      "one_line_profile": "Self-hosted data validation platform for fact checking",
      "detailed_description": "A platform developed by ICIJ to assist in labor-intensive fact-checking processes, providing tools for data validation and verification in investigative journalism contexts.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "fact_checking",
        "data_validation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ICIJ/prophecies",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "fact-checking",
        "journalism",
        "verification"
      ],
      "id": 22
    },
    {
      "name": "Infosys Responsible AI Toolkit",
      "one_line_profile": "Toolkit for AI safety, explainability, and hallucination detection",
      "detailed_description": "A comprehensive toolkit designed to ensure AI solutions are trustworthy, incorporating features for safety, security, fairness, bias mitigation, and hallucination detection.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "responsible_ai",
        "hallucination_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Infosys/Infosys-Responsible-AI-Toolkit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "responsible-ai",
        "explainability",
        "bias-detection"
      ],
      "id": 23
    },
    {
      "name": "RAG-FiT",
      "one_line_profile": "Framework for enhancing LLMs for RAG tasks via fine-tuning",
      "detailed_description": "A framework developed by Intel Labs to improve Retrieval-Augmented Generation (RAG) performance by fine-tuning Large Language Models specifically for retrieval and generation integration.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "model_finetuning",
        "rag_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IntelLabs/RAG-FiT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "fine-tuning",
        "llm"
      ],
      "id": 24
    },
    {
      "name": "fastRAG",
      "one_line_profile": "Efficient Retrieval Augmentation and Generation Framework",
      "detailed_description": "A framework optimized for efficient and scalable Retrieval-Augmented Generation, providing components for building high-performance RAG pipelines.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "rag_pipeline",
        "retrieval_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IntelLabs/fastRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "efficiency",
        "retrieval"
      ],
      "id": 25
    },
    {
      "name": "Factorio Learning Environment",
      "one_line_profile": "Environment for evaluating LLMs in Factorio",
      "detailed_description": "A non-saturating, open-ended environment designed to evaluate the planning and problem-solving capabilities of Large Language Models within the game Factorio.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "agent_evaluation",
        "reinforcement_learning_env"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/JackHopkins/factorio-learning-environment",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "evaluation",
        "llm-agent",
        "environment"
      ],
      "id": 26
    },
    {
      "name": "LettuceDetect",
      "one_line_profile": "Hallucination detection framework for RAG applications",
      "detailed_description": "A framework designed to detect hallucinations in Retrieval-Augmented Generation (RAG) applications, ensuring the factual accuracy of generated content.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "fact_checking",
        "rag_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/KRLabsOrg/LettuceDetect",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination-detection",
        "rag",
        "llm-evaluation"
      ],
      "id": 27
    },
    {
      "name": "OpenFactVerification (Loki)",
      "one_line_profile": "Automated fact verification solution",
      "detailed_description": "Loki is an open-source solution designed to automate the process of verifying factuality in text, supporting fact-checking workflows.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "fact_verification",
        "fact_checking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Libr-AI/OpenFactVerification",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fact-checking",
        "nlp",
        "verification"
      ],
      "id": 28
    },
    {
      "name": "MiniCheck",
      "one_line_profile": "Efficient fact-checking of LLMs on grounding documents",
      "detailed_description": "A tool for efficient fact-checking of Large Language Models against grounding documents, enabling verification of generated claims.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "fact_checking",
        "hallucination_detection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Liyan06/MiniCheck",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fact-checking",
        "llm",
        "grounding"
      ],
      "id": 29
    },
    {
      "name": "AutoRAG",
      "one_line_profile": "Automated RAG evaluation and optimization framework",
      "detailed_description": "An open-source framework for evaluating and optimizing Retrieval-Augmented Generation (RAG) pipelines with AutoML-style automation.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "optimization",
        "pipeline_optimization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "automl"
      ],
      "id": 30
    },
    {
      "name": "summarization-eval",
      "one_line_profile": "Reference-free summarization evaluation and hallucination detection",
      "detailed_description": "A toolkit for reference-free automatic evaluation of text summarization, including features for detecting potential hallucinations.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "summarization_evaluation",
        "hallucination_detection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Muhtasham/summarization-eval",
      "help_website": [],
      "license": null,
      "tags": [
        "summarization",
        "evaluation",
        "hallucination"
      ],
      "id": 31
    },
    {
      "name": "EasyDetect",
      "one_line_profile": "Easy-to-use hallucination detection framework for LLMs",
      "detailed_description": "A framework designed to simplify the detection of hallucinations in Large Language Models, providing tools for evaluating model factuality.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "llm_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenKG-ORG/EasyDetect",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "llm",
        "evaluation"
      ],
      "id": 32
    },
    {
      "name": "KAG",
      "one_line_profile": "Logical form-guided reasoning and retrieval framework",
      "detailed_description": "A framework for building logical reasoning and factual Q&A solutions based on Knowledge Graphs and LLMs, designed to overcome limitations of traditional vector-based RAG.",
      "domains": [
        "G1",
        "G1-02",
        "G1-03"
      ],
      "subtask_category": [
        "knowledge_reasoning",
        "rag",
        "knowledge_graph"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenSPG/KAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "rag",
        "reasoning"
      ],
      "id": 33
    },
    {
      "name": "OmniSafe",
      "one_line_profile": "Framework for Safe Reinforcement Learning research",
      "detailed_description": "An infrastructural framework for accelerating research in Safe Reinforcement Learning (SafeRL), providing implementations of safety-constrained algorithms.",
      "domains": [
        "G1",
        "Scientific Modeling"
      ],
      "subtask_category": [
        "safe_rl",
        "reinforcement_learning",
        "safety_alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/PKU-Alignment/omnisafe",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "safe-rl",
        "reinforcement-learning",
        "safety"
      ],
      "id": 34
    },
    {
      "name": "OmniEval",
      "one_line_profile": "Omnidirectional and automatic RAG evaluation benchmark",
      "detailed_description": "A benchmark suite for evaluating Retrieval-Augmented Generation (RAG) systems, specifically tailored for the financial domain but applicable to general RAG evaluation.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RUC-NLPIR/OmniEval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "benchmark",
        "evaluation"
      ],
      "id": 35
    },
    {
      "name": "LLMBox",
      "one_line_profile": "Comprehensive library for LLM implementation and evaluation",
      "detailed_description": "A unified library for training and evaluating Large Language Models, providing pipelines for model assessment and implementation.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "llm_evaluation",
        "model_training",
        "pipeline"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/RUCAIBox/LLMBox",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "evaluation",
        "training"
      ],
      "id": 36
    },
    {
      "name": "RagView",
      "one_line_profile": "Unified evaluation platform for RAG benchmarking",
      "detailed_description": "A platform designed to benchmark different Retrieval-Augmented Generation (RAG) methods on custom datasets, facilitating comparative evaluation.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "benchmarking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/RagView/RagView",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "benchmark",
        "evaluation"
      ],
      "id": 37
    },
    {
      "name": "RAG-evaluation-harnesses",
      "one_line_profile": "Evaluation suite for Retrieval-Augmented Generation",
      "detailed_description": "A harness and evaluation suite designed to assess the performance of RAG systems.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RulinShao/RAG-evaluation-harnesses",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "harness"
      ],
      "id": 38
    },
    {
      "name": "FactGraph",
      "one_line_profile": "Graph-based factuality evaluation for summarization",
      "detailed_description": "Implements the FactGraph metric which uses semantic graph representations to evaluate the factuality of abstractive summarization models, improving correlation with human judgment compared to n-gram metrics.",
      "domains": [
        "Sci Knowledge",
        "NLP"
      ],
      "subtask_category": [
        "factuality_evaluation",
        "summarization_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/amazon-science/fact-graph",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "fact-checking",
        "summarization",
        "graph-representation",
        "nlp-evaluation"
      ],
      "id": 39
    },
    {
      "name": "fact-checking-rocks",
      "one_line_profile": "Baseline models for automated fact-checking",
      "detailed_description": "Provides a baseline implementation for fact-checking tasks, combining dense retrieval (using FAISS) and textual entailment models to verify claims against evidence.",
      "domains": [
        "Sci Knowledge",
        "NLP"
      ],
      "subtask_category": [
        "fact_checking",
        "claim_verification"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/anakin87/fact-checking-rocks",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fact-checking",
        "retrieval",
        "textual-entailment",
        "baseline"
      ],
      "id": 40
    },
    {
      "name": "LTI_Neural_Navigator",
      "one_line_profile": "RAG-based framework for enhancing LLM factuality",
      "detailed_description": "A framework designed to counter hallucinations in Large Language Models by integrating Retrieval-Augmented Generation (RAG) with specific focus on domain-specific queries in private knowledge bases.",
      "domains": [
        "Sci Knowledge",
        "NLP"
      ],
      "subtask_category": [
        "hallucination_reduction",
        "rag_optimization"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/anlp-team/LTI_Neural_Navigator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "hallucination",
        "factuality",
        "llm"
      ],
      "id": 41
    },
    {
      "name": "factuality-eval",
      "one_line_profile": "Evaluation harness for LLM factuality",
      "detailed_description": "A library and set of notebooks for evaluating the factual accuracy of Large Language Models, providing tools to measure hallucination rates and response quality.",
      "domains": [
        "Sci Knowledge",
        "NLP"
      ],
      "subtask_category": [
        "factuality_evaluation",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/anyscale/factuality-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "factuality",
        "llm",
        "hallucination"
      ],
      "id": 42
    },
    {
      "name": "ChatGPT-RetrievalQA-CIKM2023",
      "one_line_profile": "Dataset for evaluating Retrieval-QA models on ChatGPT responses",
      "detailed_description": "A dataset resource designed for training and evaluating Question Answering Retrieval models, featuring ChatGPT responses and human verifications to assess retrieval performance and generation quality.",
      "domains": [
        "Sci Knowledge",
        "NLP"
      ],
      "subtask_category": [
        "qa_evaluation",
        "retrieval_benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/arian-askari/ChatGPT-RetrievalQA-CIKM2023",
      "help_website": [],
      "license": null,
      "tags": [
        "dataset",
        "qa",
        "chatgpt",
        "retrieval-evaluation"
      ],
      "id": 43
    },
    {
      "name": "FRANK",
      "one_line_profile": "Benchmark for evaluating factuality in document summarization",
      "detailed_description": "The FRANK benchmark offers a diverse set of model generated summaries with human annotations of factual errors, enabling robust evaluation of factuality metrics in summarization tasks.",
      "domains": [
        "Sci Knowledge",
        "NLP"
      ],
      "subtask_category": [
        "factuality_benchmarking",
        "summarization_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/artidoro/frank",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "factuality",
        "summarization",
        "nlp"
      ],
      "id": 44
    },
    {
      "name": "COVID-Fact",
      "one_line_profile": "Dataset and tools for COVID-19 claim verification",
      "detailed_description": "Contains the COVID-Fact dataset and associated code for automated fact extraction and verification of real-world claims related to the COVID-19 pandemic.",
      "domains": [
        "Sci Knowledge",
        "Public Health"
      ],
      "subtask_category": [
        "fact_verification",
        "claim_extraction"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/asaakyan/covidfact",
      "help_website": [],
      "license": null,
      "tags": [
        "covid-19",
        "fact-checking",
        "dataset",
        "misinformation"
      ],
      "id": 45
    },
    {
      "name": "ArtiFact",
      "one_line_profile": "Large-scale dataset for synthetic image detection",
      "detailed_description": "The ArtiFact dataset provides a comprehensive collection of real and AI-generated images to support the development and evaluation of robust synthetic image detection models.",
      "domains": [
        "Computer Vision",
        "Forensics"
      ],
      "subtask_category": [
        "synthetic_detection",
        "fake_detection"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/awsaf49/artifact",
      "help_website": [],
      "license": null,
      "tags": [
        "synthetic-images",
        "deepfake-detection",
        "dataset",
        "forensics"
      ],
      "id": 46
    },
    {
      "name": "BEIR",
      "one_line_profile": "Heterogeneous benchmark for zero-shot information retrieval",
      "detailed_description": "A comprehensive framework for evaluating information retrieval models across diverse datasets and domains, serving as a standard for assessing retrieval capabilities in RAG and search systems.",
      "domains": [
        "Sci Knowledge",
        "Information Retrieval"
      ],
      "subtask_category": [
        "retrieval_benchmarking",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/beir-cellar/beir",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "information-retrieval",
        "benchmark",
        "rag",
        "zero-shot"
      ],
      "id": 47
    },
    {
      "name": "TypeTruth",
      "one_line_profile": "Tool for detecting AI-generated text",
      "detailed_description": "A library designed to distinguish between human-written and AI-generated text, aiding in content validation and fact-checking workflows to prevent the spread of AI hallucinations or misinformation.",
      "domains": [
        "Sci Knowledge",
        "NLP"
      ],
      "subtask_category": [
        "ai_detection",
        "content_validation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/bhaskatripathi/TypeTruth",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ai-detection",
        "fact-checking",
        "nlp",
        "validation"
      ],
      "id": 48
    },
    {
      "name": "BigCode Evaluation Harness",
      "one_line_profile": "Evaluation framework for code generation models",
      "detailed_description": "A specialized harness for evaluating autoregressive code generation models on various coding benchmarks, ensuring functional correctness and alignment of code LLMs.",
      "domains": [
        "Computer Science",
        "AI Evaluation"
      ],
      "subtask_category": [
        "code_evaluation",
        "model_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bigcode-project/bigcode-evaluation-harness",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "code-generation",
        "evaluation",
        "llm",
        "benchmark"
      ],
      "id": 49
    },
    {
      "name": "Yet Another Applied LLM Benchmark",
      "one_line_profile": "Applied benchmark for practical LLM problem solving",
      "detailed_description": "A benchmark suite designed to evaluate Large Language Models on complex, applied questions and tasks, moving beyond simple factoid QA to test reasoning and problem-solving capabilities.",
      "domains": [
        "Sci Knowledge",
        "AI Evaluation"
      ],
      "subtask_category": [
        "model_benchmarking",
        "reasoning_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/carlini/yet-another-applied-llm-benchmark",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "benchmark",
        "llm",
        "reasoning",
        "evaluation"
      ],
      "id": 50
    },
    {
      "name": "ExpertQA",
      "one_line_profile": "Expert-curated QA dataset with attributed answers",
      "detailed_description": "A high-quality dataset featuring questions curated by experts across various fields, with answers that include citations and attributions, used for evaluating the expertise and factuality of QA systems.",
      "domains": [
        "Sci Knowledge",
        "NLP"
      ],
      "subtask_category": [
        "qa_evaluation",
        "attribution_analysis"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/chaitanyamalaviya/ExpertQA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dataset",
        "qa",
        "expert-verification",
        "attribution"
      ],
      "id": 51
    },
    {
      "name": "mir_ref",
      "one_line_profile": "Evaluation framework for Music Information Retrieval",
      "detailed_description": "A Python-based framework for evaluating representation learning models in Music Information Retrieval (MIR) tasks, facilitating comparative analysis of audio feature extraction methods.",
      "domains": [
        "Signal Processing",
        "Music Information Retrieval"
      ],
      "subtask_category": [
        "representation_evaluation",
        "audio_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chrispla/mir_ref",
      "help_website": [],
      "license": null,
      "tags": [
        "mir",
        "evaluation",
        "audio",
        "representation-learning"
      ],
      "id": 52
    },
    {
      "name": "polygraphLLM",
      "one_line_profile": "Hallucination detection and factuality improvement tool",
      "detailed_description": "A library providing methods to detect hallucinations in LLM outputs and techniques to improve their factual consistency, essential for reliable deployment of generative AI in scientific contexts.",
      "domains": [
        "Sci Knowledge",
        "NLP"
      ],
      "subtask_category": [
        "hallucination_detection",
        "factuality_improvement"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cisco-open/polygraphLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "llm",
        "factuality",
        "detection"
      ],
      "id": 53
    },
    {
      "name": "CLEF2018 Fact Checking",
      "one_line_profile": "Evaluation resources for CLEF2018 Fact Checking Lab",
      "detailed_description": "Provides the official scorer, format checkers, and baseline systems for the CLEF2018 Fact Checking shared task, supporting research in automated claim verification.",
      "domains": [
        "Sci Knowledge",
        "NLP"
      ],
      "subtask_category": [
        "fact_checking_evaluation",
        "shared_task_scoring"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/clef2018-factchecking/clef2018-factchecking",
      "help_website": [],
      "license": null,
      "tags": [
        "clef",
        "fact-checking",
        "evaluation",
        "scorer"
      ],
      "id": 54
    },
    {
      "name": "BenchBase",
      "one_line_profile": "Multi-DBMS SQL benchmarking framework",
      "detailed_description": "A scalable framework for benchmarking various database management systems using standard workloads (TPC-C, TPC-E, etc.), supporting database research and performance analysis.",
      "domains": [
        "Computer Science",
        "Database Systems"
      ],
      "subtask_category": [
        "dbms_benchmarking",
        "performance_analysis"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/cmu-db/benchbase",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "benchmark",
        "database",
        "sql",
        "performance"
      ],
      "id": 55
    },
    {
      "name": "Cofacts Open Data",
      "one_line_profile": "Open dataset from the Cofacts collaborative fact-checking system",
      "detailed_description": "Provides access to the crowdsourced database of fact-checked messages and rumors from the Cofacts platform, serving as a resource for training and evaluating misinformation detection models.",
      "domains": [
        "Sci Knowledge",
        "Social Science"
      ],
      "subtask_category": [
        "misinformation_analysis",
        "fact_checking_data"
      ],
      "application_level": "dataset",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/cofacts/opendata",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fact-checking",
        "dataset",
        "misinformation",
        "crowdsourcing"
      ],
      "id": 56
    },
    {
      "name": "Opik",
      "one_line_profile": "Platform for evaluating, debugging, and monitoring LLM and RAG applications",
      "detailed_description": "Opik is a comprehensive platform designed to trace, evaluate, and monitor LLM applications, RAG systems, and agentic workflows. It provides automated evaluation metrics, tracing capabilities, and dashboards to ensure the reliability and factuality of AI systems.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "evaluation",
        "monitoring",
        "tracing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/comet-ml/opik",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "rag",
        "observability",
        "tracing"
      ],
      "id": 57
    },
    {
      "name": "LLM Multiagent Debate",
      "one_line_profile": "Method for improving LLM factuality and reasoning via multi-agent debate",
      "detailed_description": "Implementation of the ICML 2024 paper 'Improving Factuality and Reasoning in Language Models through Multiagent Debate'. It provides a framework where multiple LLM agents debate to reach a consensus, thereby reducing hallucinations and improving factual accuracy in responses.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "fact_checking",
        "reasoning_enhancement",
        "hallucination_reduction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/composable-models/llm_multiagent_debate",
      "help_website": [],
      "license": null,
      "tags": [
        "multi-agent",
        "factuality",
        "reasoning",
        "icml-2024"
      ],
      "id": 58
    },
    {
      "name": "DeepEval",
      "one_line_profile": "Comprehensive evaluation framework for LLMs",
      "detailed_description": "DeepEval is an open-source evaluation framework for Large Language Models. It offers a suite of metrics to measure hallucination, faithfulness, answer relevancy, and other performance indicators, facilitating the unit testing of LLM applications.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "evaluation",
        "unit_testing",
        "hallucination_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/confident-ai/deepeval",
      "help_website": [
        "https://docs.confident-ai.com"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "metrics",
        "testing",
        "rag"
      ],
      "id": 59
    },
    {
      "name": "pytrec_eval",
      "one_line_profile": "Python interface for the TREC information retrieval evaluation tool",
      "detailed_description": "pytrec_eval provides a Python interface to the standard trec_eval utility, allowing for the rigorous evaluation of information retrieval systems using standard metrics like MAP, NDCG, and Precision.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "ir_evaluation",
        "metrics_calculation"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/cvangysel/pytrec_eval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "information-retrieval",
        "evaluation",
        "trec",
        "metrics"
      ],
      "id": 60
    },
    {
      "name": "UQLM",
      "one_line_profile": "Uncertainty Quantification for LLM hallucination detection",
      "detailed_description": "UQLM (Uncertainty Quantification for Language Models) is a Python package specifically designed to detect hallucinations in Large Language Models by quantifying uncertainty in their outputs.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "uncertainty_quantification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cvs-health/uqlm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination-detection",
        "uncertainty-quantification",
        "llm"
      ],
      "id": 61
    },
    {
      "name": "Bisheng",
      "one_line_profile": "Open LLM DevOps platform for enterprise AI applications",
      "detailed_description": "Bisheng is a platform for developing next-generation enterprise AI applications. It includes features for GenAI workflows, RAG, agent management, and evaluation, supporting the lifecycle of knowledge-driven AI systems.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag",
        "workflow_management",
        "evaluation"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/dataelement/bisheng",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llmops",
        "rag",
        "agent",
        "evaluation"
      ],
      "id": 62
    },
    {
      "name": "HaloScope",
      "one_line_profile": "Hallucination detection using unlabeled LLM generations",
      "detailed_description": "Source code for the NeurIPS'24 paper 'HaloScope'. It implements a method for detecting hallucinations in LLMs by harnessing unlabeled generations, providing a tool for evaluating model faithfulness.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/deeplearning-wisc/haloscope",
      "help_website": [],
      "license": null,
      "tags": [
        "hallucination",
        "llm",
        "neurips-2024",
        "detection"
      ],
      "id": 63
    },
    {
      "name": "RAGbits",
      "one_line_profile": "Modular building blocks for RAG application development",
      "detailed_description": "RAGbits provides a set of components for building Retrieval-Augmented Generation (RAG) applications, facilitating the development of systems that require retrieval, parsing, and processing of knowledge bases.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "rag",
        "retrieval",
        "pipeline_construction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepsense-ai/ragbits",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "genai",
        "retrieval",
        "framework"
      ],
      "id": 64
    },
    {
      "name": "Ollama Grid Search",
      "one_line_profile": "Desktop application for evaluating and comparing LLM models",
      "detailed_description": "A multi-platform desktop tool designed to evaluate and compare different Large Language Models (LLMs) via grid search, helping researchers and developers assess model performance and suitability.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking",
        "comparison"
      ],
      "application_level": "application",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/dezoito/ollama-grid-search",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "evaluation",
        "grid-search",
        "ollama"
      ],
      "id": 65
    },
    {
      "name": "OLAPH",
      "one_line_profile": "Improving factuality in biomedical long-form QA",
      "detailed_description": "OLAPH is a framework designed to improve the factuality of biomedical long-form question answering systems. It addresses the specific needs of scientific knowledge retrieval and verification in the biomedical domain.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "factuality_improvement",
        "biomedical_qa",
        "hallucination_reduction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dmis-lab/OLAPH",
      "help_website": [],
      "license": null,
      "tags": [
        "biomedical",
        "qa",
        "factuality",
        "nlp"
      ],
      "id": 66
    },
    {
      "name": "MultiVerS",
      "one_line_profile": "Model for scientific claim verification",
      "detailed_description": "Code and model checkpoints for MultiVerS, a system designed for verifying scientific claims against evidence. It supports the task of fact-checking within scientific literature.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "claim_verification",
        "fact_checking",
        "scientific_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dwadden/multivers",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fact-checking",
        "scientific-claims",
        "nlp",
        "verification"
      ],
      "id": 67
    },
    {
      "name": "Text-to-Image Eval",
      "one_line_profile": "Evaluation metrics for text-to-image models",
      "detailed_description": "A toolkit to evaluate custom and HuggingFace text-to-image and zero-shot image classification models. It includes metrics like Zero-shot accuracy, Linear Probe, and Image retrieval accuracy, useful for assessing generative models in scientific visualization or data generation contexts.",
      "domains": [
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "image_generation_metrics"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/encord-team/text-to-image-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "text-to-image",
        "metrics",
        "clip"
      ],
      "id": 68
    },
    {
      "name": "ChatProtect",
      "one_line_profile": "Evaluation, detection, and mitigation of LLM self-contradictory hallucinations",
      "detailed_description": "Code for the paper 'Self-contradictory Hallucinations of Large Language Models'. It provides methods for evaluating, detecting, and mitigating hallucinations in LLM outputs, directly addressing factuality in AI systems.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "hallucination_mitigation",
        "evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/eth-sri/ChatProtect",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "llm",
        "safety",
        "factuality"
      ],
      "id": 69
    },
    {
      "name": "DSPy Micro Agent",
      "one_line_profile": "Minimal agent runtime with evaluation harness",
      "detailed_description": "A minimal agent runtime built with DSPy modules, including an evaluation harness with OpenAI/Ollama support. It facilitates the development and testing of agentic workflows, including those for scientific reasoning.",
      "domains": [
        "G1-05"
      ],
      "subtask_category": [
        "agent_evaluation",
        "workflow_automation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/evalops/dspy-micro-agent",
      "help_website": [],
      "license": null,
      "tags": [
        "dspy",
        "agent",
        "evaluation",
        "llm"
      ],
      "id": 70
    },
    {
      "name": "EvalPlus",
      "one_line_profile": "Rigorous evaluation framework for LLM-synthesized code",
      "detailed_description": "EvalPlus provides a rigorous evaluation framework for code generation models. While focused on code, it is a critical evaluation tool for AI4S applications where code generation (e.g., for simulation or data analysis) is a key component.",
      "domains": [
        "G1-05"
      ],
      "subtask_category": [
        "code_evaluation",
        "model_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/evalplus/evalplus",
      "help_website": [
        "https://evalplus.github.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "code-generation",
        "evaluation",
        "llm",
        "benchmarking"
      ],
      "id": 71
    },
    {
      "name": "Evidently",
      "one_line_profile": "Open-source ML and LLM observability and evaluation framework",
      "detailed_description": "Evidently is a framework for evaluating, testing, and monitoring ML models and LLMs. It supports tabular data and text, providing metrics for data drift, model performance, and LLM quality (e.g., hallucinations, bias), essential for reliable scientific AI.",
      "domains": [
        "G1-05"
      ],
      "subtask_category": [
        "model_monitoring",
        "evaluation",
        "observability",
        "data_drift"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/evidentlyai/evidently",
      "help_website": [
        "https://docs.evidentlyai.com"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "evaluation",
        "monitoring",
        "llm"
      ],
      "id": 72
    },
    {
      "name": "MLGym",
      "one_line_profile": "Framework and benchmark for advancing AI research agents",
      "detailed_description": "MLGym is a framework and benchmark designed to advance research in AI agents. It provides environments and metrics for evaluating agent performance, supporting the development of autonomous systems for scientific tasks.",
      "domains": [
        "G1-05"
      ],
      "subtask_category": [
        "agent_benchmarking",
        "reinforcement_learning_eval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/MLGym",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "agents",
        "benchmark",
        "reinforcement-learning"
      ],
      "id": 73
    },
    {
      "name": "TruthRL",
      "one_line_profile": "Incentivizing truthful LLMs via Reinforcement Learning",
      "detailed_description": "TruthRL implements methods for incentivizing truthfulness in Large Language Models using Reinforcement Learning. It addresses the critical scientific need for factual and reliable AI generation.",
      "domains": [
        "G1-05"
      ],
      "subtask_category": [
        "truthfulness_alignment",
        "reinforcement_learning",
        "factuality"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/TruthRL",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "truthfulness",
        "rlhf",
        "llm",
        "alignment"
      ],
      "id": 74
    },
    {
      "name": "LSS Eval",
      "one_line_profile": "Metric for evaluating faithfulness of LLM generated text",
      "detailed_description": "LSS Eval provides a new metric to evaluate the faithfulness of text generated by Large Language Models, supporting the verification of content generated in scientific or factual contexts.",
      "domains": [
        "G1-05"
      ],
      "subtask_category": [
        "faithfulness_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/lss_eval",
      "help_website": [],
      "license": "CC0-1.0",
      "tags": [
        "evaluation",
        "faithfulness",
        "llm",
        "nlp"
      ],
      "id": 75
    },
    {
      "name": "CNN Image Retrieval (MatConvNet)",
      "one_line_profile": "Training and evaluating CNNs for Image Retrieval in MatConvNet",
      "detailed_description": "A framework for training and evaluating Convolutional Neural Networks for image retrieval tasks using MatConvNet. Useful for scientific image database retrieval and analysis.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "image_retrieval",
        "model_training",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/filipradenovic/cnnimageretrieval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "image-retrieval",
        "cnn",
        "matconvnet",
        "computer-vision"
      ],
      "id": 76
    },
    {
      "name": "CNN Image Retrieval (PyTorch)",
      "one_line_profile": "Training and evaluating CNNs for Image Retrieval in PyTorch",
      "detailed_description": "A PyTorch implementation for training and evaluating CNNs for image retrieval. It supports the development of systems for retrieving visual data, applicable in scientific imaging contexts.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "image_retrieval",
        "model_training",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/filipradenovic/cnnimageretrieval-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "image-retrieval",
        "pytorch",
        "cnn",
        "computer-vision"
      ],
      "id": 77
    },
    {
      "name": "RAG Arena",
      "one_line_profile": "Open-source RAG evaluation through user feedback",
      "detailed_description": "RAG Arena is a tool for evaluating Retrieval-Augmented Generation systems based on user feedback. It helps in benchmarking and improving RAG pipelines used for knowledge retrieval.",
      "domains": [
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "benchmarking",
        "user_feedback"
      ],
      "application_level": "application",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/firecrawl/rag-arena",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "arena",
        "feedback"
      ],
      "id": 78
    },
    {
      "name": "Flow",
      "one_line_profile": "Computational framework for reinforcement learning in traffic control",
      "detailed_description": "Flow is a computational framework for deep reinforcement learning and control experiments for traffic microsimulation. It enables scientific modeling and optimization of complex traffic systems.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "simulation",
        "reinforcement_learning",
        "traffic_control"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/flow-project/flow",
      "help_website": [
        "https://flow-project.github.io"
      ],
      "license": "MIT",
      "tags": [
        "reinforcement-learning",
        "traffic-simulation",
        "control-theory",
        "microsimulation"
      ],
      "id": 79
    },
    {
      "name": "RAGEval",
      "one_line_profile": "Evaluation toolkit for Retrieval-Augmented Generation (RAG) methods",
      "detailed_description": "A framework designed to evaluate RAG pipelines, focusing on metrics relevant to retrieval accuracy and generation quality in scientific and general contexts.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "rag_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gomate-community/rageval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "llm",
        "benchmarking"
      ],
      "id": 80
    },
    {
      "name": "Long-form Factuality",
      "one_line_profile": "Benchmarking tool for long-form factuality in Large Language Models",
      "detailed_description": "A benchmarking suite from Google DeepMind for evaluating the factuality of long-form text generated by LLMs, using the SAFE (Search-Augmented Factuality Evaluator) method.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "fact_checking",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google-deepmind/long-form-factuality",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "factuality",
        "llm",
        "hallucination",
        "benchmarking"
      ],
      "id": 81
    },
    {
      "name": "TRUE",
      "one_line_profile": "Framework for re-evaluating factual consistency in text generation",
      "detailed_description": "A comprehensive evaluation framework that consolidates multiple existing factual consistency metrics and datasets to benchmark their performance on detecting hallucinations.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "fact_checking",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google-research/true",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "factual-consistency",
        "hallucination",
        "nlp",
        "evaluation"
      ],
      "id": 82
    },
    {
      "name": "ManiSkill",
      "one_line_profile": "GPU-parallelized robotics simulator and benchmark framework",
      "detailed_description": "A high-performance robotics simulation platform and benchmark for learning manipulation skills, supporting physics-based modeling and data generation for embodied AI.",
      "domains": [
        "Sci Knowledge"
      ],
      "subtask_category": [
        "simulation",
        "robotics_modeling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/haosulab/ManiSkill",
      "help_website": [
        "https://maniskill.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "robotics",
        "simulation",
        "physics-engine",
        "benchmark"
      ],
      "id": 83
    },
    {
      "name": "Big ANN Benchmarks",
      "one_line_profile": "Framework for evaluating approximate nearest neighbor search algorithms",
      "detailed_description": "A standard benchmarking framework for evaluating the performance and accuracy of billion-scale approximate nearest neighbor (ANN) search algorithms, critical for vector retrieval in science.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "algorithm_evaluation",
        "vector_search"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/harsha-simhadri/big-ann-benchmarks",
      "help_website": [
        "http://big-ann-benchmarks.com/"
      ],
      "license": "MIT",
      "tags": [
        "ann",
        "vector-search",
        "benchmarking",
        "information-retrieval"
      ],
      "id": 84
    },
    {
      "name": "FELM",
      "one_line_profile": "Benchmarking factuality evaluation of Large Language Models",
      "detailed_description": "A benchmark and toolkit for evaluating the factuality of LLMs across various domains, providing annotated datasets and evaluation scripts to detect hallucinations.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "fact_checking",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hkust-nlp/felm",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "factuality",
        "llm",
        "benchmark",
        "hallucination"
      ],
      "id": 85
    },
    {
      "name": "LRAGE",
      "one_line_profile": "Evaluation framework for RAG pipelines in the legal domain",
      "detailed_description": "A specialized framework for evaluating Retrieval-Augmented Generation systems, providing metrics and datasets tailored for high-precision domains like law, applicable to scientific regulation analysis.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_benchmarking",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hoorangyee/LRAGE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "legal-tech",
        "llm"
      ],
      "id": 86
    },
    {
      "name": "LightEval",
      "one_line_profile": "Comprehensive toolkit for evaluating LLMs across multiple backends",
      "detailed_description": "A lightweight yet powerful evaluation library from Hugging Face for assessing Large Language Models on various benchmarks, including reasoning and factuality tasks.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/lighteval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation",
        "llm",
        "huggingface",
        "nlp"
      ],
      "id": 87
    },
    {
      "name": "ChainForge",
      "one_line_profile": "Visual programming environment for prompt engineering and evaluation",
      "detailed_description": "An open-source visual tool for testing, evaluating, and comparing LLM prompts and responses, facilitating systematic analysis of model behavior and factuality.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "prompt_engineering",
        "model_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/ianarawjo/ChainForge",
      "help_website": [
        "https://chainforge.ai/"
      ],
      "license": "MIT",
      "tags": [
        "prompt-engineering",
        "visualization",
        "evaluation",
        "llm"
      ],
      "id": 88
    },
    {
      "name": "TruthX",
      "one_line_profile": "Tool for alleviating hallucinations by editing LLMs in truthful space",
      "detailed_description": "An implementation of a method to enhance LLM truthfulness by identifying and editing the internal representations (truthfulness hyperplane) to reduce hallucinations.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_editing",
        "hallucination_mitigation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ictnlp/TruthX",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "hallucination",
        "model-editing",
        "llm",
        "truthfulness"
      ],
      "id": 89
    },
    {
      "name": "ViDoRe Benchmark",
      "one_line_profile": "Benchmark for Vision Document Retrieval systems",
      "detailed_description": "Evaluation code and benchmark for the Vision Document Retrieval (ViDoRe) task, assessing the ability of models to retrieve visually rich documents (PDFs, charts).",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "document_retrieval",
        "multimodal_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/illuin-tech/vidore-benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "retrieval",
        "vision-language",
        "benchmark",
        "document-analysis"
      ],
      "id": 90
    },
    {
      "name": "DebateLLM",
      "one_line_profile": "Benchmarking multi-agent debate for truthfulness in Q&A",
      "detailed_description": "A framework for evaluating whether multi-agent debate protocols improve the truthfulness and accuracy of Large Language Models in Question Answering tasks.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "multi_agent_simulation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/instadeepai/DebateLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "truthfulness",
        "debate",
        "llm"
      ],
      "id": 91
    },
    {
      "name": "Metriks",
      "one_line_profile": "Metrics library for evaluating information retrieval models",
      "detailed_description": "A Python package implementing commonly used metrics (NDCG, Precision, Recall, etc.) for evaluating the performance of information retrieval and recommendation systems.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "metrics_calculation",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/intuit/metriks",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "information-retrieval",
        "metrics",
        "evaluation"
      ],
      "id": 92
    },
    {
      "name": "SAC3",
      "one_line_profile": "Semantic-aware cross-check consistency for hallucination detection",
      "detailed_description": "A tool for detecting hallucinations in black-box language models by checking semantic consistency across multiple generated samples (Self-Consistency Check).",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/intuit/sac3",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "consistency-check",
        "llm",
        "reliability"
      ],
      "id": 93
    },
    {
      "name": "RagRank",
      "one_line_profile": "Toolkit for evaluating RAG application performance",
      "detailed_description": "A lightweight library to evaluate Retrieval-Augmented Generation (RAG) pipelines, assessing metrics like factual accuracy, context relevance, and response tone.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_benchmarking",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/izam-mohammed/ragrank",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "metrics",
        "llm"
      ],
      "id": 94
    },
    {
      "name": "ARES (Robotics)",
      "one_line_profile": "Automatic Robot Evaluation System",
      "detailed_description": "A scalable framework for evaluating robotics research, providing tools for automated testing and performance metrics collection for robot control systems.",
      "domains": [
        "Sci Knowledge"
      ],
      "subtask_category": [
        "robotics_evaluation",
        "simulation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jacobphillips99/ares",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "robotics",
        "evaluation",
        "automation",
        "research-tool"
      ],
      "id": 95
    },
    {
      "name": "GraphRAG-Bench",
      "one_line_profile": "Benchmark for evaluating Graph Retrieval-Augmented Generation (RAG) systems",
      "detailed_description": "A dedicated benchmarking framework designed to evaluate the performance of Graph Retrieval-Augmented Generation systems, specifically focusing on challenging domain-specific reasoning tasks.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking",
        "rag_assessment"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/jeremycp3/GraphRAG-Bench",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "graph-rag",
        "evaluation",
        "retrieval"
      ],
      "id": 96
    },
    {
      "name": "llm-eval",
      "one_line_profile": "Evaluation platform for Large Language Models and RAG systems",
      "detailed_description": "A comprehensive evaluation platform for Large Language Models (LLMs) that supports multiple benchmarks, custom datasets, and performance testing, with specific support for RAG (Retrieval-Augmented Generation) evaluation.",
      "domains": [
        "G1-05"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking",
        "rag_assessment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/justplus/llm-eval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-evaluation",
        "rag",
        "benchmark",
        "testing"
      ],
      "id": 97
    },
    {
      "name": "cde",
      "one_line_profile": "Library for training and evaluating Contextual Document Embeddings",
      "detailed_description": "A codebase and toolkit for training and evaluating Contextual Document Embedding (CDE) models, which are used to improve information retrieval and document understanding tasks.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "embedding_training",
        "retrieval_evaluation",
        "document_embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jxmorris12/cde",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "embeddings",
        "information-retrieval",
        "contextual-embeddings"
      ],
      "id": 98
    },
    {
      "name": "InstructIR",
      "one_line_profile": "Benchmark for evaluating instruction-following capabilities in IR models",
      "detailed_description": "A novel benchmark specifically designed to evaluate the instruction-following ability of information retrieval models, focusing on user-aligned instructions tailored to query instances.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "ir_evaluation",
        "benchmarking",
        "instruction_following"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/kaistAI/InstructIR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "information-retrieval",
        "benchmark",
        "instruction-following"
      ],
      "id": 99
    },
    {
      "name": "SLM-Lab",
      "one_line_profile": "Modular Deep Reinforcement Learning framework in PyTorch",
      "detailed_description": "A modular framework for Deep Reinforcement Learning (DRL) implemented in PyTorch, designed for research in reinforcement learning algorithms and experiments.",
      "domains": [
        "AI_General"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "modeling",
        "algorithm_research"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kengz/SLM-Lab",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "reinforcement-learning",
        "pytorch",
        "deep-learning",
        "framework"
      ],
      "id": 100
    },
    {
      "name": "rome",
      "one_line_profile": "Implementation of Rank-One Model Editing for LLM factuality",
      "detailed_description": "The official implementation of Rank-One Model Editing (ROME), a method for locating and editing factual associations in Large Language Models (specifically GPT), used for studying and improving model factuality.",
      "domains": [
        "G1-05"
      ],
      "subtask_category": [
        "model_editing",
        "factuality_correction",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kmeng01/rome",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "model-editing",
        "factuality",
        "llm",
        "interpretability"
      ],
      "id": 101
    },
    {
      "name": "autoarena",
      "one_line_profile": "Automated head-to-head evaluation system for LLMs and RAG pipelines",
      "detailed_description": "A tool designed to rank Large Language Models (LLMs), RAG systems, and prompts using automated head-to-head evaluation methodologies, facilitating comparative analysis of model performance.",
      "domains": [
        "G1-05"
      ],
      "subtask_category": [
        "model_ranking",
        "evaluation",
        "benchmarking"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/kolenaIO/autoarena",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "llm-ranking",
        "rag",
        "automation"
      ],
      "id": 102
    },
    {
      "name": "vec4ir",
      "one_line_profile": "Library for generating and using word embeddings in information retrieval",
      "detailed_description": "A Python library that integrates word embeddings into information retrieval tasks, providing methods to train, evaluate, and utilize embeddings for document ranking and retrieval.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "information_retrieval",
        "embedding_generation",
        "ranking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lgalke/vec4ir",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "word-embeddings",
        "information-retrieval",
        "nlp"
      ],
      "id": 103
    },
    {
      "name": "jingwei",
      "one_line_profile": "Framework for evaluating image tag assignment and tag-based image retrieval",
      "detailed_description": "A framework designed for the evaluation of image tag assignment, tag refinement, and tag-based image retrieval systems, facilitating research in multimedia information retrieval.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "image_retrieval",
        "tagging_evaluation",
        "multimedia_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/li-xirong/jingwei",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "image-retrieval",
        "tagging",
        "evaluation",
        "multimedia"
      ],
      "id": 104
    },
    {
      "name": "honest_llama",
      "one_line_profile": "Inference-Time Intervention (ITI) method to elicit truthful answers from LLMs",
      "detailed_description": "Implementation of Inference-Time Intervention (ITI), a technique to improve the truthfulness of Large Language Models by intervening in their internal activations during inference, mitigating hallucinations.",
      "domains": [
        "G1-05"
      ],
      "subtask_category": [
        "truthfulness_intervention",
        "hallucination_mitigation",
        "model_steering"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/likenneth/honest_llama",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "truthfulness",
        "hallucination",
        "llm",
        "intervention"
      ],
      "id": 105
    },
    {
      "name": "LLaVA-RLHF",
      "one_line_profile": "Framework for aligning Large Multimodal Models (LMMs) using Factually Augmented RLHF",
      "detailed_description": "A codebase and framework for aligning Large Multimodal Models (specifically LLaVA) using Factually Augmented Reinforcement Learning from Human Feedback (RLHF) to reduce hallucinations and improve factual accuracy.",
      "domains": [
        "G1-05"
      ],
      "subtask_category": [
        "alignment",
        "factuality_enhancement",
        "rlhf",
        "multimodal_learning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/llava-rlhf/LLaVA-RLHF",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "rlhf",
        "llava",
        "alignment",
        "factuality"
      ],
      "id": 106
    },
    {
      "name": "RouteLLM",
      "one_line_profile": "Framework for serving and evaluating LLM routers to optimize cost and quality",
      "detailed_description": "A framework designed to serve and evaluate routers for Large Language Models, enabling researchers to develop and test strategies for routing queries between different models to balance cost and response quality.",
      "domains": [
        "G1-05"
      ],
      "subtask_category": [
        "model_routing",
        "evaluation",
        "inference_optimization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/lm-sys/RouteLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-routing",
        "evaluation",
        "cost-optimization",
        "serving"
      ],
      "id": 107
    },
    {
      "name": "Video-ChatGPT",
      "one_line_profile": "Video conversation model with quantitative evaluation benchmarking",
      "detailed_description": "A video conversation model capable of generating meaningful conversation about videos, combining LLMs with a pretrained visual encoder. It includes a rigorous quantitative evaluation benchmarking suite for video-based conversational models.",
      "domains": [
        "G1",
        "Computer Vision"
      ],
      "subtask_category": [
        "evaluation",
        "multimodal_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mbzuai-oryx/Video-ChatGPT",
      "help_website": [],
      "license": "CC-BY-4.0",
      "tags": [
        "video-llm",
        "benchmarking",
        "multimodal"
      ],
      "id": 108
    },
    {
      "name": "CoNLI",
      "one_line_profile": "Framework for ungrounded hallucination detection and reduction",
      "detailed_description": "A plug-and-play framework designed for detecting and reducing ungrounded hallucinations in Large Language Models (LLMs), focusing on improving factual consistency.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "fact_checking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/CoNLI_hallucination",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "llm",
        "fact-checking"
      ],
      "id": 109
    },
    {
      "name": "HaDes",
      "one_line_profile": "Token-level reference-free hallucination detection",
      "detailed_description": "A tool and benchmark for token-level, reference-free hallucination detection in Large Language Models, enabling fine-grained evaluation of model factuality.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/HaDes",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "benchmark",
        "token-level"
      ],
      "id": 110
    },
    {
      "name": "micronaire",
      "one_line_profile": "RAG evaluation pipeline for Semantic Kernel",
      "detailed_description": "An evaluation pipeline designed for Retrieval-Augmented Generation (RAG) systems, specifically integrated with Semantic Kernel to assess the quality and accuracy of retrieved information and generated responses.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "quality_control"
      ],
      "application_level": "workflow",
      "primary_language": "C#",
      "repo_url": "https://github.com/microsoft/micronaire",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "semantic-kernel"
      ],
      "id": 111
    },
    {
      "name": "PromptBench",
      "one_line_profile": "Unified evaluation framework for large language models",
      "detailed_description": "A comprehensive framework for evaluating Large Language Models (LLMs) across various tasks, including adversarial robustness, prompt engineering, and general performance metrics.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/promptbench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "evaluation",
        "robustness"
      ],
      "id": 112
    },
    {
      "name": "RAG Experiment Accelerator",
      "one_line_profile": "Tool for conducting RAG experiments and evaluations",
      "detailed_description": "A versatile tool designed to expedite the process of conducting experiments and evaluations for Retrieval-Augmented Generation (RAG) patterns, facilitating scientific assessment of RAG performance.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "experimentation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/rag-experiment-accelerator",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "experiment",
        "azure"
      ],
      "id": 113
    },
    {
      "name": "mir_eval",
      "one_line_profile": "Evaluation functions for music/audio information retrieval",
      "detailed_description": "A library providing standard evaluation metrics and functions for music and audio information retrieval (MIR) tasks, widely used for scientific benchmarking in audio signal processing.",
      "domains": [
        "Audio",
        "Signal Processing"
      ],
      "subtask_category": [
        "evaluation",
        "signal_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mir-evaluation/mir_eval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mir",
        "audio",
        "evaluation"
      ],
      "id": 114
    },
    {
      "name": "RAGTune",
      "one_line_profile": "Tuning and evaluation of RAG pipelines",
      "detailed_description": "A tool for tuning and evaluating Retrieval-Augmented Generation (RAG) pipelines, aiming to optimize retrieval accuracy and generation quality through automated metrics.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_optimization",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/misbahsy/RAGTune",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "tuning",
        "optimization"
      ],
      "id": 115
    },
    {
      "name": "EvalScope",
      "one_line_profile": "Framework for efficient large model evaluation and benchmarking",
      "detailed_description": "A streamlined and customizable framework for evaluating and benchmarking large models (LLM, VLM, AIGC), supporting various datasets and metrics for scientific performance assessment.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/modelscope/evalscope",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "evaluation",
        "benchmark"
      ],
      "id": 116
    },
    {
      "name": "MRAG-Bench",
      "one_line_profile": "Vision-centric evaluation for retrieval-augmented multimodal models",
      "detailed_description": "A benchmark suite for evaluating Retrieval-Augmented Multimodal Models, specifically focusing on vision-centric tasks and metrics to assess model capabilities in handling multimodal data.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "multimodal_evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/mragbench/MRAG-Bench",
      "help_website": [],
      "license": null,
      "tags": [
        "multimodal",
        "rag",
        "benchmark"
      ],
      "id": 117
    },
    {
      "name": "DEFAME",
      "one_line_profile": "Fact-checking system for textual and visual inputs",
      "detailed_description": "A multimodal fact-checking system designed to verify claims based on both textual and visual evidence, providing a framework for automated truthfulness assessment.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "fact_checking",
        "multimodal_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/multimodal-ai-lab/DEFAME",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fact-checking",
        "multimodal",
        "verification"
      ],
      "id": 118
    },
    {
      "name": "KnowledgeEditor",
      "one_line_profile": "Library for editing factual knowledge in Language Models",
      "detailed_description": "A Python library implementing hyper-network based knowledge editing methods (like KE and MEND) to modify factual knowledge stored in large language models without re-training.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_editing",
        "fact_correction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nicola-decao/KnowledgeEditor",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-editing",
        "llm",
        "factuality"
      ],
      "id": 119
    },
    {
      "name": "hallucination_probes",
      "one_line_profile": "Probes for real-time detection of hallucinated entities in LLMs",
      "detailed_description": "A toolkit for training and evaluating probes to detect hallucinations in long-form text generation from Large Language Models, specifically focusing on entity correctness.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_probing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/obalcells/hallucination_probes",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination-detection",
        "llm",
        "probing"
      ],
      "id": 120
    },
    {
      "name": "VLMEvalKit",
      "one_line_profile": "Evaluation toolkit for Large Multi-modality Models",
      "detailed_description": "An open-source evaluation toolkit designed for Large Multi-modality Models (LMMs), supporting evaluation of over 200 models across 80+ benchmarks, facilitating comprehensive performance analysis.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "multimodal_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/open-compass/VLMEvalKit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "vlm",
        "benchmark"
      ],
      "id": 121
    },
    {
      "name": "OpenCompass",
      "one_line_profile": "Comprehensive evaluation platform for Large Language Models",
      "detailed_description": "A one-stop platform for evaluating Large Language Models (LLMs) covering various capabilities including reasoning, language understanding, and coding, with support for distributed evaluation.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmark_harness"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/open-compass/opencompass",
      "help_website": [
        "https://opencompass.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "benchmark",
        "nlp"
      ],
      "id": 122
    },
    {
      "name": "OpenAI Evals",
      "one_line_profile": "Framework for evaluating LLMs and an open-source registry of benchmarks",
      "detailed_description": "A framework for evaluating OpenAI models and other LLMs, providing a registry of benchmarks to test model capabilities, factuality, and safety.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmark_registry"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/openai/evals",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation",
        "llm",
        "benchmark"
      ],
      "id": 123
    },
    {
      "name": "OHR-Bench",
      "one_line_profile": "Benchmark for evaluating OCR impact on RAG systems",
      "detailed_description": "A benchmarking tool and dataset designed to evaluate how Optical Character Recognition (OCR) errors cascade and affect the performance of Retrieval-Augmented Generation (RAG) systems.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "ocr_analysis"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/opendatalab/OHR-Bench",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "ocr",
        "evaluation"
      ],
      "id": 124
    },
    {
      "name": "AutoML Benchmark",
      "one_line_profile": "Benchmarking framework for AutoML systems",
      "detailed_description": "An open-source tool for benchmarking various Automated Machine Learning (AutoML) systems on a wide variety of datasets, facilitating comparative analysis of ML algorithms.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "automl_evaluation",
        "algorithm_benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/openml/automlbenchmark",
      "help_website": [
        "https://openml.github.io/automlbenchmark/"
      ],
      "license": "MIT",
      "tags": [
        "automl",
        "benchmark",
        "machine-learning"
      ],
      "id": 125
    },
    {
      "name": "Oumi",
      "one_line_profile": "Platform for fine-tuning, evaluating, and deploying open source LLMs",
      "detailed_description": "A comprehensive library for building, training, and evaluating Large Language Models (LLMs) and Vision Language Models (VLMs), including tools for data preparation and model assessment.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_training",
        "model_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/oumi-ai/oumi",
      "help_website": [
        "https://oumi.ai/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-finetuning",
        "evaluation",
        "inference"
      ],
      "id": 126
    },
    {
      "name": "SelfCheckGPT",
      "one_line_profile": "Zero-resource black-box hallucination detection for LLMs",
      "detailed_description": "A tool implementing the SelfCheckGPT method to detect hallucinations in Generative Large Language Models by checking the consistency of multiple sampled responses, without requiring external databases.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "consistency_check"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/potsawee/selfcheckgpt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "llm",
        "fact-checking"
      ],
      "id": 127
    },
    {
      "name": "Prometheus-Eval",
      "one_line_profile": "LLM evaluation tool using Prometheus and GPT-4",
      "detailed_description": "A library for evaluating Large Language Model responses using the Prometheus model or GPT-4, providing a mechanism for automated grading and feedback generation.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "automated_grading"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/prometheus-eval/prometheus-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "llm",
        "grading"
      ],
      "id": 128
    },
    {
      "name": "promptfoo",
      "one_line_profile": "CLI tool for evaluating LLM prompts, agents, and RAG pipelines",
      "detailed_description": "A tool for testing and evaluating LLM prompts, agents, and RAG systems. It supports red teaming, pentesting, and vulnerability scanning, allowing researchers to compare performance across different models (GPT, Claude, Llama) using declarative configurations.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "hallucination_detection",
        "security_scanning"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/promptfoo/promptfoo",
      "help_website": [
        "https://www.promptfoo.dev"
      ],
      "license": "MIT",
      "tags": [
        "llm-evaluation",
        "red-teaming",
        "rag-evaluation"
      ],
      "id": 129
    },
    {
      "name": "RagaAI-Catalyst",
      "one_line_profile": "Agent AI observability and evaluation framework",
      "detailed_description": "A Python SDK for monitoring, observing, and evaluating Agent AI systems. It includes features for tracing LLMs and tools, debugging multi-agent systems, and providing advanced analytics for model performance.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "observability",
        "agent_tracing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/raga-ai-hub/RagaAI-Catalyst",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent-evaluation",
        "observability",
        "llm-monitoring"
      ],
      "id": 130
    },
    {
      "name": "raga-llm-hub",
      "one_line_profile": "Framework for LLM evaluation and security guardrails",
      "detailed_description": "A framework designed for evaluating Large Language Models (LLMs), implementing guardrails, and ensuring security. It aids in assessing the reliability and safety of LLM outputs.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "security_guardrails"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/raga-ai-hub/raga-llm-hub",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm-evaluation",
        "guardrails",
        "security"
      ],
      "id": 131
    },
    {
      "name": "continuous-eval",
      "one_line_profile": "Data-driven evaluation framework for LLM applications",
      "detailed_description": "A framework for the continuous, data-driven evaluation of LLM-powered applications. It provides metrics and pipelines to assess the performance and reliability of language model outputs.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "continuous_testing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/relari-ai/continuous-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "data-driven",
        "metrics"
      ],
      "id": 132
    },
    {
      "name": "RULE",
      "one_line_profile": "Reliable Multimodal RAG for factuality in medical VLMs",
      "detailed_description": "Implementation of the RULE framework for ensuring factuality in Medical Vision Language Models (VLMs) via Multimodal Retrieval-Augmented Generation (RAG). It addresses hallucination in medical AI contexts.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "factuality_evaluation",
        "multimodal_rag",
        "medical_ai"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/richard-peng-xia/RULE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-vlm",
        "factuality",
        "multimodal-rag"
      ],
      "id": 133
    },
    {
      "name": "multimodal_rag_for_industry",
      "one_line_profile": "Implementation and evaluation of multimodal RAG for industrial applications",
      "detailed_description": "A repository containing the implementation and evaluation of a multimodal Retrieval-Augmented Generation (RAG) system, processing both text and image inputs, specifically tailored for industrial use cases.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_implementation",
        "multimodal_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/riedlerm/multimodal_rag_for_industry",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multimodal-rag",
        "industrial-ai",
        "evaluation"
      ],
      "id": 134
    },
    {
      "name": "auto-evaluator",
      "one_line_profile": "Evaluation tool for LLM QA chains",
      "detailed_description": "A tool designed to evaluate Question Answering (QA) chains powered by LLMs. It automates the assessment of response quality, helping to identify issues in QA pipelines.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "qa_evaluation",
        "llm_chain_testing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/rlancemartin/auto-evaluator",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-qa",
        "evaluation",
        "langchain"
      ],
      "id": 135
    },
    {
      "name": "hallucination-index",
      "one_line_profile": "Ranking of LLMs based on hallucination propensity",
      "detailed_description": "An initiative and framework to evaluate and rank popular Large Language Models (LLMs) across various task types based on their tendency to hallucinate, providing a benchmark for model reliability.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "hallucination_benchmarking",
        "model_ranking"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/rungalileo/hallucination-index",
      "help_website": [],
      "license": null,
      "tags": [
        "hallucination",
        "llm-benchmark",
        "reliability"
      ],
      "id": 136
    },
    {
      "name": "PsiloQA",
      "one_line_profile": "Pipeline for constructing hallucination detection datasets",
      "detailed_description": "A pipeline that automates the construction of multilingual, span-level hallucination detection datasets with contexts. It aids researchers in creating data to train and evaluate hallucination detection models.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "dataset_construction",
        "hallucination_detection"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/s-nlp/PsiloQA",
      "help_website": [],
      "license": null,
      "tags": [
        "hallucination",
        "dataset-generation",
        "multilingual"
      ],
      "id": 137
    },
    {
      "name": "factCC",
      "one_line_profile": "Evaluating factual consistency of text summarization",
      "detailed_description": "Resources and code for evaluating the factual consistency of abstractive text summarization, based on the FactCC paper. It provides models to check if summaries remain faithful to the source text.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "factuality_evaluation",
        "summarization_consistency"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/salesforce/factCC",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "fact-checking",
        "summarization",
        "nlp"
      ],
      "id": 138
    },
    {
      "name": "factualNLG",
      "one_line_profile": "Evaluating LLMs as factual reasoners",
      "detailed_description": "Code for the paper 'LLMs as Factual Reasoners', providing benchmarks and evaluation scripts to assess the factual reasoning capabilities of Large Language Models.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "factual_reasoning",
        "model_benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/salesforce/factualNLG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "factual-reasoning",
        "llm-benchmark",
        "nlg"
      ],
      "id": 139
    },
    {
      "name": "OpenCE",
      "one_line_profile": "Toolkit for evaluating LLM context strategies (RAG, ACE)",
      "detailed_description": "Open Context Engineering (OpenCE) is a community toolkit to implement, evaluate, and combine context strategies for LLMs, such as RAG, ACE, and compression, evolved from the ACE-open reproduction.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "context_engineering",
        "rag_evaluation",
        "context_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sci-m-wang/OpenCE",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "context-window",
        "llm-optimization"
      ],
      "id": 140
    },
    {
      "name": "matchmaker",
      "one_line_profile": "Training and evaluation library for neural re-ranking",
      "detailed_description": "A library for training and evaluating text-based neural re-ranking and dense retrieval models using PyTorch. It supports research in information retrieval and relevance matching.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "neural_ranking",
        "retrieval_evaluation",
        "dense_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sebastian-hofstaetter/matchmaker",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "neural-ir",
        "re-ranking",
        "dense-retrieval"
      ],
      "id": 141
    },
    {
      "name": "neural-ranking-drmm",
      "one_line_profile": "Implementation of Deep Relevance Matching Model (DRMM)",
      "detailed_description": "Implementation and evaluation framework for the Deep Relevance Matching Model (DRMM) for ad-hoc retrieval, facilitating research into neural ranking models.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "neural_ranking",
        "relevance_matching"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sebastian-hofstaetter/neural-ranking-drmm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "drmm",
        "neural-ir",
        "ad-hoc-retrieval"
      ],
      "id": 142
    },
    {
      "name": "frai",
      "one_line_profile": "Toolkit for responsible AI and model evaluation",
      "detailed_description": "An open-source toolkit for responsible AI that includes a CLI and SDK to scan code, collect evidence, and generate model cards, risk files, and evaluations for RAG indexes.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "responsible_ai",
        "model_evaluation",
        "risk_assessment"
      ],
      "application_level": "workflow",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/sebuzdugan/frai",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "responsible-ai",
        "model-cards",
        "rag-evaluation"
      ],
      "id": 143
    },
    {
      "name": "gnn-benchmark",
      "one_line_profile": "Framework for evaluating Graph Neural Networks",
      "detailed_description": "A framework for evaluating Graph Neural Network (GNN) models on semi-supervised node classification tasks, providing standardized benchmarks for graph learning research.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "gnn_evaluation",
        "node_classification",
        "graph_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shchur/gnn-benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gnn",
        "benchmarking",
        "graph-neural-networks"
      ],
      "id": 144
    },
    {
      "name": "knowledgestream",
      "one_line_profile": "Fact checking using knowledge graph streams",
      "detailed_description": "Code to reproduce results for finding streams in Knowledge Graphs to support fact checking. It provides methods for utilizing KG structures to verify facts.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "fact_checking",
        "knowledge_graph_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/shiralkarprashant/knowledgestream",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "fact-checking",
        "stream-mining"
      ],
      "id": 145
    },
    {
      "name": "FActScore",
      "one_line_profile": "Fine-grained atomic evaluation of factual precision",
      "detailed_description": "A package to evaluate the factuality of long-form text generation by breaking it down into atomic facts. It implements the FActScore metric for measuring factual precision in LLM outputs.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "factuality_evaluation",
        "long_form_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shmsw25/FActScore",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "factuality",
        "evaluation-metric",
        "nlp"
      ],
      "id": 146
    },
    {
      "name": "fever-transformers",
      "one_line_profile": "Evidence retrieval and claim verification for FEVER",
      "detailed_description": "A tool for Evidence Retrieval and Claim Verification using Transformer Networks, specifically designed for the FEVER (Fact Extraction and VERification) shared task.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "claim_verification",
        "evidence_retrieval",
        "fact_checking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/simonepri/fever-transformers",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fever",
        "fact-verification",
        "transformers"
      ],
      "id": 147
    },
    {
      "name": "SolarSystemSimulatorGame",
      "one_line_profile": "Solar system simulation with realistic orbital physics",
      "detailed_description": "A simulation of the Solar System that uses 4th-order Runge-Kutta and Leapfrog integrators to calculate realistic elliptical orbits for planets and spacecraft based on NASA data.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "orbital_simulation",
        "physics_simulation"
      ],
      "application_level": "solver",
      "primary_language": "C#",
      "repo_url": "https://github.com/sotos82/SolarSystemSimulatorGame",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "simulation",
        "astronomy",
        "orbital-mechanics"
      ],
      "id": 148
    },
    {
      "name": "HELM",
      "one_line_profile": "Holistic Evaluation of Language Models framework",
      "detailed_description": "A comprehensive framework for the holistic, reproducible, and transparent evaluation of foundation models (LLMs and multimodal models). It provides a standardized interface for benchmarking models across a wide range of scenarios and metrics.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking",
        "foundation_models"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanford-crfm/helm",
      "help_website": [
        "https://crfm.stanford.edu/helm/latest/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "benchmarking",
        "foundation-models"
      ],
      "id": 149
    },
    {
      "name": "ARES",
      "one_line_profile": "Automated Evaluation of RAG Systems",
      "detailed_description": "A framework for the Automated Evaluation of Retrieval-Augmented Generation (RAG) Systems. It provides methods to assess the quality and performance of RAG pipelines.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "automated_testing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanford-futuredata/ARES",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "automated-metrics"
      ],
      "id": 150
    },
    {
      "name": "WikiChat",
      "one_line_profile": "RAG system with hallucination reduction via Wikipedia retrieval",
      "detailed_description": "A robust Retrieval Augmented Generation (RAG) system designed to minimize hallucinations in Large Language Models by grounding responses in a verified corpus (Wikipedia). It serves as a pipeline for fact-checking and trustworthy text generation.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "hallucination_reduction",
        "fact_checking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanford-oval/WikiChat",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "hallucination",
        "fact-checking",
        "llm"
      ],
      "id": 151
    },
    {
      "name": "RAG Genie",
      "one_line_profile": "Prototype for evaluating RAG embeddings and chunking strategies",
      "detailed_description": "A tool designed to test and evaluate the components of RAG pipelines, specifically focusing on embedding quality and chunk splitting strategies through Q&A generation and automated evaluation.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "pipeline_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/stephanj/rag-genie",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "embeddings",
        "chunking"
      ],
      "id": 152
    },
    {
      "name": "llm-rag-eval",
      "one_line_profile": "LLM-powered evaluator for RAG pipelines",
      "detailed_description": "A Python library that utilizes Large Language Models to evaluate the performance of Retrieval Augmented Generation pipelines, providing metrics for retrieval quality and generation fidelity.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "metric_calculation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sujitpal/llm-rag-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "llm"
      ],
      "id": 153
    },
    {
      "name": "Question Generation",
      "one_line_profile": "Automatic factual question generation from sentences",
      "detailed_description": "A tool that generates reading comprehension style factual questions from input sentences. This is useful for creating synthetic datasets for evaluating fact-checking systems and QA models.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "data_generation",
        "synthetic_data"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sumehta/question-generation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "question-generation",
        "dataset-creation"
      ],
      "id": 154
    },
    {
      "name": "TARGET",
      "one_line_profile": "Benchmark for table retrieval in generative tasks",
      "detailed_description": "A benchmark suite designed to evaluate Table Retrieval methods for Generative Tasks, specifically focusing on Fact Verification and Text-to-SQL applications involving tabular data.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "fact_verification",
        "table_retrieval"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/target-benchmark/target",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "fact-verification",
        "table-retrieval"
      ],
      "id": 155
    },
    {
      "name": "Safety-Prompts",
      "one_line_profile": "Chinese safety prompts for evaluating LLM safety",
      "detailed_description": "A dataset and resource containing Chinese safety prompts designed to evaluate and improve the safety and robustness of Large Language Models against various types of attacks and harmful queries.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "safety_evaluation",
        "adversarial_testing"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-coai/Safety-Prompts",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-safety",
        "evaluation",
        "prompts"
      ],
      "id": 156
    },
    {
      "name": "MLA-Trust",
      "one_line_profile": "Benchmark toolbox for Multimodal LLM Agent trustworthiness",
      "detailed_description": "A comprehensive toolbox for benchmarking the trustworthiness of Multimodal LLM Agents. It evaluates dimensions such as truthfulness, controllability, safety, and privacy across interactive tasks.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "trustworthiness_evaluation",
        "multimodal_benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-ml/MLA-Trust",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multimodal",
        "agents",
        "trustworthiness",
        "benchmark"
      ],
      "id": 157
    },
    {
      "name": "MMTrustEval",
      "one_line_profile": "Toolbox for benchmarking trustworthiness of multimodal LLMs",
      "detailed_description": "A benchmarking toolbox designed to evaluate the trustworthiness of Multimodal Large Language Models (MLLMs), covering aspects like hallucination, safety, and fairness.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "trustworthiness_evaluation",
        "multimodal_benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-ml/MMTrustEval",
      "help_website": [],
      "license": "CC-BY-SA-4.0",
      "tags": [
        "multimodal",
        "evaluation",
        "trustworthiness"
      ],
      "id": 158
    },
    {
      "name": "ARES",
      "one_line_profile": "Library for benchmarking adversarial robustness in ML",
      "detailed_description": "A Python library focused on adversarial machine learning, providing tools and benchmarks to evaluate the adversarial robustness of models against various attack methods.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "adversarial_robustness",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-ml/ares",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "adversarial-ml",
        "robustness",
        "benchmarking"
      ],
      "id": 159
    },
    {
      "name": "TransformerLab",
      "one_line_profile": "Platform for LLM engineering, training, and evaluation",
      "detailed_description": "An open-source application that provides a comprehensive environment for interacting with, training, fine-tuning, and evaluating Large Language Models locally. It includes tools for experiment tracking and model assessment.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "llm_evaluation",
        "model_training"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/transformerlab/transformerlab-app",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "llm",
        "fine-tuning",
        "evaluation",
        "platform"
      ],
      "id": 160
    },
    {
      "name": "WikiCheck",
      "one_line_profile": "Wikipedia-based fact-checking API implementation",
      "detailed_description": "An implementation of a fact-checking API that leverages Wikipedia to verify claims. Developed in cooperation with the Wikimedia Foundation, it serves as a tool for automated fact verification.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "fact_checking",
        "claim_verification"
      ],
      "application_level": "service",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/trokhymovych/WikiCheck",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fact-checking",
        "wikipedia",
        "api"
      ],
      "id": 161
    },
    {
      "name": "TruLens",
      "one_line_profile": "Evaluation and tracking library for LLM experiments",
      "detailed_description": "A library for evaluating and tracking Large Language Model applications. It implements the 'RAG Triad' (Context Relevance, Groundedness, Answer Relevance) to assess the quality and truthfulness of AI agents and RAG systems.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "experiment_tracking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/truera/trulens",
      "help_website": [
        "https://www.trulens.org"
      ],
      "license": "MIT",
      "tags": [
        "evaluation",
        "rag",
        "observability",
        "llm"
      ],
      "id": 162
    },
    {
      "name": "trec_eval",
      "one_line_profile": "Standard evaluation software for Text Retrieval Conference",
      "detailed_description": "The standard software for evaluating information retrieval systems using test collections. It computes a wide range of standard IR metrics (precision, recall, MAP, etc.) used in scientific literature retrieval evaluation.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "ir_evaluation",
        "metric_calculation"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/usnistgov/trec_eval",
      "help_website": [
        "https://trec.nist.gov/trec_eval/"
      ],
      "license": null,
      "tags": [
        "information-retrieval",
        "evaluation",
        "metrics"
      ],
      "id": 163
    },
    {
      "name": "X-FACT",
      "one_line_profile": "Benchmark dataset for multilingual fact checking",
      "detailed_description": "A large-scale multilingual dataset and benchmark for fact-checking, enabling the evaluation of fact verification systems across multiple languages.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "fact_checking",
        "multilingual_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/utahnlp/x-fact",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fact-checking",
        "multilingual",
        "benchmark"
      ],
      "id": 164
    },
    {
      "name": "ClaimBuster Spotter",
      "one_line_profile": "Tool for identifying check-worthy factual claims",
      "detailed_description": "A tool that uses adversarial training on transformer networks to automatically identify sentences and claims in text that are worth fact-checking, serving as a preliminary step in automated fact verification pipelines.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "claim_detection",
        "fact_checking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/utaresearch/claimbuster-spotter",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "fact-checking",
        "claim-detection",
        "nlp"
      ],
      "id": 165
    },
    {
      "name": "open-rag-eval",
      "one_line_profile": "RAG evaluation framework without golden answers",
      "detailed_description": "A framework for evaluating Retrieval Augmented Generation systems that does not require ground truth 'golden answers', making it easier to assess RAG performance in dynamic or open-ended domains.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "reference_free_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vectara/open-rag-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "llm"
      ],
      "id": 166
    },
    {
      "name": "AI Facts",
      "one_line_profile": "Real-time fact checking tool for spoken statements",
      "detailed_description": "A tool that performs real-time fact-checking on spoken statements by integrating speech-to-text (DeepGram) with search and verification engines (Perplexity, AI SDK).",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "real_time_fact_checking",
        "speech_verification"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/vercel-labs/ai-facts",
      "help_website": [],
      "license": null,
      "tags": [
        "fact-checking",
        "real-time",
        "speech-processing"
      ],
      "id": 167
    },
    {
      "name": "Ragas",
      "one_line_profile": "Framework for evaluating RAG pipelines",
      "detailed_description": "A comprehensive framework for evaluating Retrieval Augmented Generation (RAG) pipelines. It provides metrics like faithfulness, answer relevance, and context precision to quantify the performance of LLM applications.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "metric_calculation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vibrantlabsai/ragas",
      "help_website": [
        "https://docs.ragas.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "metrics",
        "llm"
      ],
      "id": 168
    },
    {
      "name": "TabFact",
      "one_line_profile": "Large-scale dataset and code for table-based fact verification",
      "detailed_description": "A benchmark dataset and associated code for verifying facts based on tabular data. It serves as a standard resource for evaluating models on table-based reasoning and fact-checking tasks.",
      "domains": [
        "G1",
        "G1-05"
      ],
      "subtask_category": [
        "fact_verification",
        "table_reasoning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/wenhuchen/Table-Fact-Checking",
      "help_website": [
        "https://tabfact.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "fact-verification",
        "table-reasoning",
        "benchmark"
      ],
      "id": 169
    },
    {
      "name": "gymfc",
      "one_line_profile": "Universal flight control tuning framework based on OpenAI Gym",
      "detailed_description": "A flight control tuning framework that acts as an OpenAI Gym environment, allowing for the development and benchmarking of intelligent flight control systems using reinforcement learning.",
      "domains": [
        "Robotics",
        "Control Systems"
      ],
      "subtask_category": [
        "flight_control",
        "reinforcement_learning",
        "simulation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wil3/gymfc",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "flight-control",
        "reinforcement-learning",
        "uav",
        "simulation"
      ],
      "id": 170
    },
    {
      "name": "Caveman Compression",
      "one_line_profile": "Semantic compression method for LLM contexts",
      "detailed_description": "A tool for compressing context for Large Language Models by removing predictable grammar while preserving factual content, optimizing token usage without losing semantic meaning.",
      "domains": [
        "NLP",
        "AI"
      ],
      "subtask_category": [
        "context_compression",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wilpel/caveman-compression",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "compression",
        "context-optimization"
      ],
      "id": 171
    },
    {
      "name": "GraphEval",
      "one_line_profile": "Framework for evaluating LLM factuality using Knowledge Graphs",
      "detailed_description": "A framework designed to evaluate the factuality of Large Language Models by leveraging large-scale knowledge graphs to detect hallucinations and verify claims.",
      "domains": [
        "NLP",
        "G1-05"
      ],
      "subtask_category": [
        "factuality_evaluation",
        "hallucination_detection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/xz-liu/GraphEval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "hallucination",
        "evaluation",
        "llm"
      ],
      "id": 172
    },
    {
      "name": "MSRS",
      "one_line_profile": "Benchmark dataset and code for evaluating Multi-Source RAG",
      "detailed_description": "A resource containing data and evaluation code for assessing Multi-Source Retrieval-Augmented Generation systems, focusing on the integration and verification of information from diverse sources.",
      "domains": [
        "NLP",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "benchmark"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/yale-nlp/MSRS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "dataset",
        "multi-source"
      ],
      "id": 173
    },
    {
      "name": "RaLLe",
      "one_line_profile": "Framework for developing and evaluating RAG systems",
      "detailed_description": "A comprehensive framework facilitating the development and evaluation of Retrieval-Augmented Large Language Models, providing tools for testing retrieval accuracy and generation quality.",
      "domains": [
        "NLP",
        "G1-05"
      ],
      "subtask_category": [
        "rag_development",
        "evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/yhoshi3/RaLLe",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "llm",
        "framework",
        "evaluation"
      ],
      "id": 174
    },
    {
      "name": "MultiHop-RAG",
      "one_line_profile": "Dataset for evaluating RAG across multiple documents",
      "detailed_description": "A dataset designed to evaluate Retrieval-Augmented Generation systems specifically on multi-hop reasoning tasks across multiple documents, serving as a benchmark for RAG capabilities.",
      "domains": [
        "NLP",
        "G1-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "benchmark"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/yixuantt/MultiHop-RAG",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "multi-hop",
        "dataset",
        "evaluation"
      ],
      "id": 175
    },
    {
      "name": "VeriExCiting",
      "one_line_profile": "Tool for detecting AI-generated fake citations in academic papers",
      "detailed_description": "A verification tool designed to identify non-existent or hallucinated citations in academic texts generated by AI, ensuring the integrity of scientific references.",
      "domains": [
        "Sci Knowledge",
        "G1-05"
      ],
      "subtask_category": [
        "citation_verification",
        "fake_detection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ykangw/VeriExCiting",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "citation-check",
        "hallucination",
        "academic-integrity"
      ],
      "id": 176
    },
    {
      "name": "torchdistill",
      "one_line_profile": "Reproducible knowledge distillation framework for PyTorch",
      "detailed_description": "A coding-free framework built on PyTorch for deep learning studies, specifically focusing on knowledge distillation methods, enabling reproducible experiments and model compression.",
      "domains": [
        "Deep Learning",
        "Computer Vision"
      ],
      "subtask_category": [
        "knowledge_distillation",
        "model_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/yoshitomo-matsubara/torchdistill",
      "help_website": [
        "https://torchdistill.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "pytorch",
        "knowledge-distillation",
        "reproducibility"
      ],
      "id": 177
    },
    {
      "name": "EasyLM",
      "one_line_profile": "One-stop solution for LLM pre-training and serving in JAX/Flax",
      "detailed_description": "A scalable and easy-to-use framework for pre-training, fine-tuning, evaluating, and serving Large Language Models using JAX and Flax, designed for high-performance computing environments.",
      "domains": [
        "NLP",
        "AI"
      ],
      "subtask_category": [
        "model_training",
        "inference"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/young-geng/EasyLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jax",
        "flax",
        "llm",
        "distributed-training"
      ],
      "id": 178
    },
    {
      "name": "IFCC",
      "one_line_profile": "Improves factual completeness and consistency of radiology reports",
      "detailed_description": "A model implementation for generating radiology reports from images with a focus on improving factual completeness and consistency, aiding in medical image analysis.",
      "domains": [
        "Medical AI",
        "G1-05"
      ],
      "subtask_category": [
        "report_generation",
        "factual_consistency"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ysmiura/ifcc",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "radiology",
        "image-captioning",
        "medical-nlp"
      ],
      "id": 179
    },
    {
      "name": "AlignScore",
      "one_line_profile": "Metric for factual consistency evaluation in text generation",
      "detailed_description": "A comprehensive metric tool designed to evaluate the factual consistency between source text and generated text, addressing the alignment problem in natural language generation.",
      "domains": [
        "NLP",
        "G1-05"
      ],
      "subtask_category": [
        "factuality_evaluation",
        "metric"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yuh-zha/AlignScore",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation-metric",
        "factuality",
        "nlg"
      ],
      "id": 180
    },
    {
      "name": "Factcheck-GPT",
      "one_line_profile": "Tool for fact-checking LLM outputs via annotation and evaluation",
      "detailed_description": "A tool designed to facilitate the fact-checking of generative Large Language Model outputs, supporting both manual annotation processes and automated evaluation workflows.",
      "domains": [
        "NLP",
        "G1-05"
      ],
      "subtask_category": [
        "fact_checking",
        "annotation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/yuxiaw/Factcheck-GPT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fact-checking",
        "llm",
        "annotation"
      ],
      "id": 181
    },
    {
      "name": "ESCNet",
      "one_line_profile": "Entity-enhanced and Stance Checking Network for multi-modal fact-checking",
      "detailed_description": "A deep learning model implementation for multi-modal fact-checking that utilizes entity enhancement and stance checking to verify claims against evidence.",
      "domains": [
        "NLP",
        "G1-05"
      ],
      "subtask_category": [
        "fact_checking",
        "stance_detection"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/zfr00/ESCNet",
      "help_website": [],
      "license": null,
      "tags": [
        "multi-modal",
        "fact-checking",
        "stance-detection"
      ],
      "id": 182
    },
    {
      "name": "LLM-RG4",
      "one_line_profile": "Flexible and factual radiology report generation model",
      "detailed_description": "A Large Language Model based approach for generating factual radiology reports from diverse input contexts, aiming to improve the accuracy and utility of automated medical reporting.",
      "domains": [
        "Medical AI",
        "G1-05"
      ],
      "subtask_category": [
        "report_generation",
        "medical_imaging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zh-Wang-Med/LLM-RG4",
      "help_website": [],
      "license": null,
      "tags": [
        "radiology",
        "llm",
        "medical-report"
      ],
      "id": 183
    },
    {
      "name": "FactualSceneGraph",
      "one_line_profile": "Textual scene graph parser and FACTUAL dataset",
      "detailed_description": "A tool and dataset for parsing textual scene graphs, enabling the structured representation of factual information from text for downstream tasks like image generation or verification.",
      "domains": [
        "NLP",
        "CV"
      ],
      "subtask_category": [
        "scene_graph_parsing",
        "dataset"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhuang-li/FactualSceneGraph",
      "help_website": [],
      "license": null,
      "tags": [
        "scene-graph",
        "parsing",
        "dataset"
      ],
      "id": 184
    },
    {
      "name": "EasyDetect",
      "one_line_profile": "Easy-to-use hallucination detection framework for LLMs",
      "detailed_description": "A framework designed to simplify the process of detecting hallucinations in Large Language Models, providing a unified interface for various detection methods.",
      "domains": [
        "NLP",
        "G1-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/EasyDetect",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "llm",
        "detection"
      ],
      "id": 185
    },
    {
      "name": "FactCHD",
      "one_line_profile": "Benchmark for fact-conflicting hallucination detection",
      "detailed_description": "A benchmarking tool and dataset specifically focused on detecting fact-conflicting hallucinations in LLM outputs, aiding in the robust evaluation of factuality.",
      "domains": [
        "NLP",
        "G1-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "benchmark"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/FactCHD",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "hallucination",
        "factuality"
      ],
      "id": 186
    },
    {
      "name": "KnowRL",
      "one_line_profile": "Knowledgeable Reinforcement Learning for Factuality",
      "detailed_description": "A framework exploring the use of Reinforcement Learning integrated with knowledge bases to improve the factuality and truthfulness of language model generations.",
      "domains": [
        "NLP",
        "G1-05"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "factuality_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/KnowRL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rl",
        "knowledge-graph",
        "factuality"
      ],
      "id": 187
    }
  ]
}