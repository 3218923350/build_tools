{
  "generated_at": "2025-12-16T02:44:20.900858+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "G1",
      "leaf_cluster_name": "科研文献-检索/解析/引用网络生态",
      "domain": "Sci Knowledge",
      "typical_objects": "PDFs/citations",
      "task_chain": "解析→抽取→索引→检索→评测",
      "tool_form": "解析器 + 检索 + 评测"
    },
    "unit": {
      "unit_id": "G1-03",
      "unit_name": "学术检索/索引/向量检索",
      "target_scale": "200–450",
      "coverage_tools": "search engines、vector DB"
    },
    "search": {
      "target_candidates": 450,
      "queries": [
        "[GH] Weaviate",
        "[GH] Haystack",
        "[GH] Semantic Scholar",
        "[GH] OpenAlex",
        "[GH] Vespa",
        "[GH] Elasticsearch",
        "[GH] Milvus",
        "[GH] FAISS",
        "[GH] Pyserini",
        "[GH] Anserini",
        "[GH] academic search engine",
        "[GH] semantic search",
        "[GH] citation graph",
        "[GH] scientific literature retrieval",
        "[GH] paper recommendation system",
        "[GH] dense retrieval",
        "[GH] vector database",
        "[GH] bibliometric analysis",
        "[GH] scholarly data indexing",
        "[GH] neural information retrieval",
        "[GH] document ranking",
        "[GH] citation network analysis",
        "[GH] knowledge graph construction",
        "[WEB] academic search engine open source github",
        "[WEB] semantic search for research papers github",
        "[WEB] citation network analysis tools github",
        "[WEB] scientific literature retrieval system github",
        "[WEB] vector database for academic papers github"
      ],
      "total_candidates": 1234,
      "tool_candidates": 884,
      "final_tools": 164
    }
  },
  "tools": [
    {
      "name": "tetsuo-dox-agent",
      "one_line_profile": "AI research assistant agent with robust citation capabilities",
      "detailed_description": "A research assistant agent that leverages Large Language Models to draft technically-focused, well-researched answers with robust citations, supporting the literature review process.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_review",
        "citation_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/7etsuo/tetsuo-dox-agent",
      "help_website": [],
      "license": null,
      "tags": [
        "agent",
        "research-assistant",
        "llm",
        "citations"
      ],
      "id": 1
    },
    {
      "name": "Docs2KG",
      "one_line_profile": "Unified Knowledge Graph Construction from Heterogeneous Documents",
      "detailed_description": "A framework for constructing unified knowledge graphs from heterogeneous documents using a Human-LLM collaborative approach, facilitating information extraction from scientific or technical documentation.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "information_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/AI4WA/Docs2KG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "llm",
        "document-parsing",
        "rag"
      ],
      "id": 2
    },
    {
      "name": "semantic-zotero",
      "one_line_profile": "Zotero plugin for Semantic Scholar integration",
      "detailed_description": "A plugin for Zotero that retrieves reference data and metadata from the Semantic Scholar API, enhancing bibliography management for researchers.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_management",
        "metadata_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/AgiNetz/semantic-zotero",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "zotero-plugin",
        "semantic-scholar",
        "bibliography"
      ],
      "id": 3
    },
    {
      "name": "OpenScholar",
      "one_line_profile": "Retrieval-augmented LM for scientific literature synthesis",
      "detailed_description": "A retrieval-augmented language model system designed to synthesize scientific literature and answer scientific questions by retrieving relevant papers.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_synthesis",
        "question_answering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AkariAsai/OpenScholar",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "scientific-literature",
        "llm",
        "synthesis"
      ],
      "id": 4
    },
    {
      "name": "Scholarpy",
      "one_line_profile": "Python wrapper for Semantic Scholar API",
      "detailed_description": "A Python library that wraps Semantic Scholar APIs to streamline academic research, data retrieval, and literature analysis.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_retrieval",
        "api_wrapper"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AndreaBasile97/Scholarpy",
      "help_website": [],
      "license": null,
      "tags": [
        "semantic-scholar",
        "api-wrapper",
        "literature-search"
      ],
      "id": 5
    },
    {
      "name": "trove",
      "one_line_profile": "Flexible Toolkit for Dense Retrieval",
      "detailed_description": "A toolkit for dense retrieval research and implementation, developed by BatsResearch, facilitating information retrieval tasks which are foundational to scientific literature search.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "information_retrieval",
        "dense_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BatsResearch/trove",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dense-retrieval",
        "information-retrieval",
        "research-toolkit"
      ],
      "id": 6
    },
    {
      "name": "CWTS-Leiden-Ranking-Open-Edition",
      "one_line_profile": "Source code for generating CWTS Leiden Ranking indicators",
      "detailed_description": "Source code and SQL scripts for calculating the CWTS Leiden Ranking indicators for universities based on bibliometric data, enabling reproducible scientometric analysis.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "scientometrics",
        "bibliometric_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "TSQL",
      "repo_url": "https://github.com/CWTSLeiden/CWTS-Leiden-Ranking-Open-Edition",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scientometrics",
        "ranking",
        "bibliometrics",
        "reproducibility"
      ],
      "id": 7
    },
    {
      "name": "CWTS-OpenAlex-databases",
      "one_line_profile": "ETL pipeline for processing OpenAlex bibliographic data for scientometrics",
      "detailed_description": "A set of SQL scripts and documentation for creating a local version of the OpenAlex database, optimized for bibliometric analysis and science of science research. Developed by the Centre for Science and Technology Studies (CWTS).",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "data_ingestion",
        "bibliometrics"
      ],
      "application_level": "workflow",
      "primary_language": "TSQL",
      "repo_url": "https://github.com/CWTSLeiden/CWTS-OpenAlex-databases",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "openalex",
        "bibliometrics",
        "etl",
        "scientometrics"
      ],
      "id": 8
    },
    {
      "name": "CGSum",
      "one_line_profile": "Scientific paper summarization model using citation graphs",
      "detailed_description": "Implementation of a citation graph-based summarization framework for scientific papers. It leverages the citation network to enhance the quality of generated summaries, capturing the broader context of research impact.",
      "domains": [
        "G1",
        "G1-02"
      ],
      "subtask_category": [
        "summarization",
        "citation_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChenxinAn-fdu/CGSum",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "summarization",
        "citation-graph",
        "scientific-papers"
      ],
      "id": 9
    },
    {
      "name": "CiteGraph",
      "one_line_profile": "Web-based visualizer for academic citation networks",
      "detailed_description": "A tool to visualize citation graphs, helping researchers explore connections between scientific papers and understand the structure of citation networks.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "visualization",
        "citation_analysis"
      ],
      "application_level": "application",
      "primary_language": "Java",
      "repo_url": "https://github.com/Citegraph/citegraph",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "citation-network",
        "visualization",
        "bibliometrics"
      ],
      "id": 10
    },
    {
      "name": "wosis",
      "one_line_profile": "Python package for Web of Science bibliometric analysis",
      "detailed_description": "A library designed to support bibliometric analysis of Web of Science data, covering the workflow from querying the API to visualizing the results.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "bibliometrics",
        "data_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ConnectedSystems/wosis",
      "help_website": [],
      "license": null,
      "tags": [
        "web-of-science",
        "bibliometrics",
        "wos-api"
      ],
      "id": 11
    },
    {
      "name": "emvb",
      "one_line_profile": "Efficient Multi-vector Dense Retrieval with Bit Vectors",
      "detailed_description": "Implementation of a dense retrieval method using bit vectors for efficient multi-vector representation, applicable to information retrieval tasks including document ranking.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "information_retrieval",
        "indexing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/CosimoRulli/emvb",
      "help_website": [],
      "license": null,
      "tags": [
        "dense-retrieval",
        "vector-search",
        "ir"
      ],
      "id": 12
    },
    {
      "name": "SciKG",
      "one_line_profile": "Scientific Knowledge Graph Construction Framework",
      "detailed_description": "A framework for constructing knowledge graphs from scientific literature, facilitating the organization and retrieval of scientific knowledge.",
      "domains": [
        "G1",
        "G1-02"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "information_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DM2-ND/SciKG",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "scientific-literature",
        "kdd"
      ],
      "id": 13
    },
    {
      "name": "COCA",
      "one_line_profile": "Context-Aware Document Ranking with Contrastive Learning",
      "detailed_description": "Implementation of a contrastive learning framework for user behavior sequence modeling in context-aware document ranking, applicable to literature search and recommendation.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "document_ranking",
        "recommendation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DaoD/COCA",
      "help_website": [],
      "license": null,
      "tags": [
        "document-ranking",
        "contrastive-learning",
        "ir"
      ],
      "id": 14
    },
    {
      "name": "KRAGEN",
      "one_line_profile": "Knowledge Retrieval Augmented Generation Engine for biomedical research",
      "detailed_description": "Software to implement retrieval augmented generation (RAG) workflows using vectorized databases, specifically designed for biomedical knowledge discovery and integration.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "rag"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/EpistasisLab/KRAGEN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "biomedical",
        "knowledge-retrieval",
        "vector-database"
      ],
      "id": 15
    },
    {
      "name": "SeleniumSemanticScraper",
      "one_line_profile": "Scraper for retrieving paper metadata from Semantic Scholar",
      "detailed_description": "A tool to automatically crawl and extract metadata from scientific papers on Semantic Scholar based on key phrases, facilitating literature data collection.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "data_acquisition",
        "scraping"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/EvertonCa/SeleniumSemanticScraper",
      "help_website": [],
      "license": null,
      "tags": [
        "semantic-scholar",
        "scraping",
        "literature-review"
      ],
      "id": 16
    },
    {
      "name": "citation-graph-builder",
      "one_line_profile": "Tool for creating and visualizing citation networks from PDFs",
      "detailed_description": "A tool that parses scientific paper PDFs and queries bibliographic APIs to construct and visualize citation networks, aiding in the analysis of research impact and connections.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "citation_analysis",
        "visualization",
        "pdf_parsing"
      ],
      "application_level": "tool",
      "primary_language": "TeX",
      "repo_url": "https://github.com/FZJ-IEK3-VSA/citation-graph-builder",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "citation-graph",
        "bibliometrics",
        "visualization"
      ],
      "id": 17
    },
    {
      "name": "DPTDR",
      "one_line_profile": "Deep Prompt Tuning for Dense Passage Retrieval",
      "detailed_description": "Implementation of a deep prompt tuning method for dense passage retrieval, improving the efficiency and effectiveness of retrieving relevant scientific passages.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "information_retrieval",
        "dense_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FreedomIntelligence/DPTDR",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dense-retrieval",
        "prompt-tuning",
        "ir"
      ],
      "id": 18
    },
    {
      "name": "GR-as-MVDR",
      "one_line_profile": "Generative Retrieval as Multi-Vector Dense Retrieval",
      "detailed_description": "A retrieval framework that unifies generative retrieval and multi-vector dense retrieval, offering a novel approach to document ranking and retrieval.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "generative_retrieval",
        "dense_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Furyton/GR-as-MVDR",
      "help_website": [],
      "license": null,
      "tags": [
        "generative-retrieval",
        "ir",
        "sigir"
      ],
      "id": 19
    },
    {
      "name": "paper-qa",
      "one_line_profile": "High-accuracy RAG for scientific literature QA",
      "detailed_description": "A library for performing high-accuracy Retrieval Augmented Generation (RAG) on scientific papers. It retrieves relevant context and generates answers with precise citations to the source documents.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "question_answering",
        "rag",
        "literature_review"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Future-House/paper-qa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "scientific-qa",
        "citations",
        "llm"
      ],
      "id": 20
    },
    {
      "name": "oh-my-papers",
      "one_line_profile": "Hybrid Context-aware Paper Recommendation System",
      "detailed_description": "A recommendation system designed for scientific papers that utilizes hybrid context-aware techniques to suggest relevant literature to researchers.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "recommendation",
        "literature_discovery"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/Galaxies99/oh-my-papers",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "recommender-system",
        "scientific-papers",
        "context-aware"
      ],
      "id": 21
    },
    {
      "name": "cedr",
      "one_line_profile": "Contextualized Embeddings for Document Ranking",
      "detailed_description": "Implementation of the CEDR model, which utilizes contextualized embeddings (like BERT) for effective document ranking in information retrieval tasks.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "document_ranking",
        "neural_ir"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Georgetown-IR-Lab/cedr",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "document-ranking",
        "bert",
        "ir",
        "sigir"
      ],
      "id": 22
    },
    {
      "name": "AutoSchemaKG",
      "one_line_profile": "Framework for automatic knowledge graph construction with schema generation",
      "detailed_description": "A framework designed for automatic knowledge graph construction that combines schema generation via conceptualization, facilitating the structuring of unstructured text into knowledge graphs.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "schema_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUST-KnowComp/AutoSchemaKG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "schema-induction",
        "nlp"
      ],
      "id": 23
    },
    {
      "name": "OneCite",
      "one_line_profile": "Intelligent toolkit for parsing and formatting academic references",
      "detailed_description": "A toolkit designed to automatically parse, complete, and format academic references, supporting the Model Context Protocol (MCP) for integration with LLM workflows.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "citation_parsing",
        "reference_formatting"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HzaCode/OneCite",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "citation-management",
        "reference-parsing",
        "mcp"
      ],
      "id": 24
    },
    {
      "name": "pyalex",
      "one_line_profile": "Python library for accessing OpenAlex scientific database",
      "detailed_description": "A Python library that provides a convenient interface to the OpenAlex API, enabling researchers to retrieve and analyze scientific literature, authors, and institutions data.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_retrieval",
        "bibliometrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/J535D165/pyalex",
      "help_website": [
        "https://github.com/J535D165/pyalex"
      ],
      "license": "MIT",
      "tags": [
        "openalex",
        "bibliometrics",
        "api-wrapper"
      ],
      "id": 25
    },
    {
      "name": "semanticscholar-MCP-Server",
      "one_line_profile": "MCP server for interacting with Semantic Scholar API",
      "detailed_description": "Implements a Model Context Protocol (MCP) server to allow Large Language Models to search papers, retrieve details, and fetch citations from the Semantic Scholar database.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_retrieval",
        "citation_analysis"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/JackKuo666/semanticscholar-MCP-Server",
      "help_website": [],
      "license": null,
      "tags": [
        "semantic-scholar",
        "mcp",
        "llm-tool"
      ],
      "id": 26
    },
    {
      "name": "PubTrends",
      "one_line_profile": "Scientific literature explorer and visualization tool",
      "detailed_description": "A tool that runs searches on Pubmed or Semantic Scholar and visualizes the high-level structure of the result papers to help researchers explore scientific trends.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_visualization",
        "trend_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/JetBrains-Research/pubtrends",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bibliometrics",
        "visualization",
        "pubmed"
      ],
      "id": 27
    },
    {
      "name": "RAKG",
      "one_line_profile": "Retrieval Augmented Knowledge Graph Construction framework",
      "detailed_description": "A framework for document-level Retrieval Augmented Knowledge Graph Construction, designed to enhance KGC tasks using retrieval mechanisms.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/KnowledgeXLab/RAKG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "knowledge-graph",
        "nlp"
      ],
      "id": 28
    },
    {
      "name": "alex-paper-search-mcp",
      "one_line_profile": "MCP server for searching scientific papers via OpenAlex",
      "detailed_description": "Allows Large Language Models to search and retrieve scientific papers from the OpenAlex database using the Model Context Protocol (MCP).",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_retrieval",
        "paper_search"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/LeoGitGuy/alex-paper-search-mcp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "openalex",
        "mcp",
        "llm-tool"
      ],
      "id": 29
    },
    {
      "name": "LocalCitationNetwork",
      "one_line_profile": "Web tool for visualizing and analyzing local citation networks",
      "detailed_description": "A web application that helps scientists perform literature reviews by visualizing local citation networks using metadata from OpenAlex, Semantic Scholar, and Crossref.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "citation_analysis",
        "literature_review"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/LocalCitationNetwork/LocalCitationNetwork.github.io",
      "help_website": [
        "https://localcitationnetwork.github.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "citation-network",
        "visualization",
        "literature-review"
      ],
      "id": 30
    },
    {
      "name": "vicinity",
      "one_line_profile": "Lightweight nearest neighbor search library with flexible backends",
      "detailed_description": "A Python library that provides a unified interface for nearest neighbor search using various backends like PyTorch, Scikit-Learn, and Faiss, facilitating vector retrieval tasks in scientific data analysis.",
      "domains": [
        "G1-03",
        "Machine Learning"
      ],
      "subtask_category": [
        "vector_search",
        "nearest_neighbor_search"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MinishLab/vicinity",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nearest-neighbors",
        "vector-search",
        "pytorch"
      ],
      "id": 31
    },
    {
      "name": "AMG-RAG",
      "one_line_profile": "Agentic framework for Medical Knowledge Graph construction and QA",
      "detailed_description": "A comprehensive framework that automates the construction and continuous updating of Medical Knowledge Graphs (MKGs) and integrates reasoning for medical Question Answering (QA).",
      "domains": [
        "G1",
        "Medical AI"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "question_answering"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/MrRezaeiUofT/AMG-RAG",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "medical-qa",
        "knowledge-graph",
        "rag"
      ],
      "id": 32
    },
    {
      "name": "SGPT",
      "one_line_profile": "GPT-based sentence embeddings for semantic search",
      "detailed_description": "A library for generating sentence embeddings using GPT models, specifically optimized for semantic search tasks and asymmetric search scenarios.",
      "domains": [
        "G1-03",
        "NLP"
      ],
      "subtask_category": [
        "semantic_embedding",
        "dense_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Muennighoff/sgpt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sentence-embeddings",
        "semantic-search",
        "gpt"
      ],
      "id": 33
    },
    {
      "name": "vespa-seismic",
      "one_line_profile": "Seismic data analysis library for VESPA and FK analysis",
      "detailed_description": "Python code for performing VESPA (Velocity Spectral Analysis) and FK (Frequency-Wavenumber) analysis on seismic data, serving geophysics research.",
      "domains": [
        "Geophysics"
      ],
      "subtask_category": [
        "seismic_analysis",
        "signal_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NeilWilkins/vespa",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "seismology",
        "geophysics",
        "spectral-analysis"
      ],
      "id": 34
    },
    {
      "name": "NeumAI",
      "one_line_profile": "Framework for large-scale vector embedding management",
      "detailed_description": "A data engineering framework to manage the creation, synchronization, and governance of vector embeddings at scale, supporting RAG pipelines for scientific and general applications.",
      "domains": [
        "G1-03",
        "Data Engineering"
      ],
      "subtask_category": [
        "embedding_management",
        "data_pipeline"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/NeumTry/NeumAI",
      "help_website": [
        "https://docs.neum.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "embeddings",
        "rag"
      ],
      "id": 35
    },
    {
      "name": "MM-NIAH",
      "one_line_profile": "Benchmark for evaluating multimodal LLMs on long documents",
      "detailed_description": "A comprehensive benchmark suite designed to systematically evaluate the capability of Multimodal Large Language Models (MLLMs) to comprehend long multimodal documents (Needle In A Multimodal Haystack).",
      "domains": [
        "G1",
        "AI Evaluation"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/MM-NIAH",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "multimodal",
        "long-context"
      ],
      "id": 36
    },
    {
      "name": "RocketQA",
      "one_line_profile": "Dense retrieval toolkit for QA and IR",
      "detailed_description": "An optimized toolkit for dense retrieval in information retrieval and question answering scenarios, providing state-of-the-art models for English and Chinese.",
      "domains": [
        "G1-03",
        "NLP"
      ],
      "subtask_category": [
        "dense_retrieval",
        "question_answering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PaddlePaddle/RocketQA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dense-retrieval",
        "qa",
        "paddlepaddle"
      ],
      "id": 37
    },
    {
      "name": "PathwayCommons-semantic-search",
      "one_line_profile": "Semantic search engine for scientific papers",
      "detailed_description": "A simple semantic search engine specifically designed for indexing and retrieving scientific papers, likely leveraging biological pathway data context.",
      "domains": [
        "G1-03",
        "Bioinformatics"
      ],
      "subtask_category": [
        "literature_search",
        "semantic_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PathwayCommons/semantic-search",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-search",
        "scientific-literature",
        "bioinformatics"
      ],
      "id": 38
    },
    {
      "name": "Piazza-Updater",
      "one_line_profile": "Automation tool for Weaviate-based RAG updates",
      "detailed_description": "A tool that automates the updating of Weaviate vector databases with real-time data to enhance Retrieval-Augmented Generation (RAG) capabilities for knowledge applications.",
      "domains": [
        "G1-03",
        "Knowledge Management"
      ],
      "subtask_category": [
        "rag_pipeline",
        "database_update"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Piazza-tech/Piazza-Updater",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "weaviate",
        "automation"
      ],
      "id": 39
    },
    {
      "name": "Raphtory",
      "one_line_profile": "Scalable temporal graph analytics engine",
      "detailed_description": "A scalable graph analytics database and engine powered by Rust, designed for analyzing temporal networks and dynamic graph data.",
      "domains": [
        "G1",
        "Network Science"
      ],
      "subtask_category": [
        "graph_analytics",
        "temporal_network_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/Pometry/Raphtory",
      "help_website": [
        "https://raphtory.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "graph-analytics",
        "temporal-graphs",
        "rust"
      ],
      "id": 40
    },
    {
      "name": "VESPA-SAV",
      "one_line_profile": "Single Amino Acid Variant effect predictor",
      "detailed_description": "A predictor for Single Amino Acid Variant (SAV) effects based on embeddings from the Protein Language Model ProtT5.",
      "domains": [
        "Biology",
        "Bioinformatics"
      ],
      "subtask_category": [
        "variant_effect_prediction",
        "protein_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Rostlab/VESPA",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "protein-language-model",
        "variant-prediction",
        "prott5"
      ],
      "id": 41
    },
    {
      "name": "SDM-RDFizer",
      "one_line_profile": "RML-compliant engine for Knowledge Graph construction",
      "detailed_description": "An efficient engine for constructing Knowledge Graphs from structured data using RML (RDF Mapping Language) mappings, facilitating semantic data integration.",
      "domains": [
        "G1",
        "Semantic Web"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "data_integration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SDM-TIB/SDM-RDFizer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "rml",
        "rdf"
      ],
      "id": 42
    },
    {
      "name": "RaiseWikibase",
      "one_line_profile": "Fast bulk data insertion tool for Wikibase knowledge graphs",
      "detailed_description": "A Python tool designed to facilitate the construction of knowledge graphs by performing fast, batched inserts into Wikibase instances. It is particularly useful for library science and scientific knowledge graph management.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "data_ingestion"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/UB-Mannheim/RaiseWikibase",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wikibase",
        "knowledge-graph",
        "semantic-web"
      ],
      "id": 43
    },
    {
      "name": "GPL",
      "one_line_profile": "Generative Pseudo Labeling for unsupervised domain adaptation of dense retrieval",
      "detailed_description": "A library for training dense retrieval models on specific domains (e.g., scientific literature) using only unlabeled text. It uses a generative approach to create pseudo-labels, significantly improving retrieval performance in specialized scientific fields.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "retrieval_adaptation",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/UKPLab/gpl",
      "help_website": [
        "https://arxiv.org/abs/2112.07577"
      ],
      "license": "Apache-2.0",
      "tags": [
        "information-retrieval",
        "domain-adaptation",
        "dense-retrieval"
      ],
      "id": 44
    },
    {
      "name": "metaknowledge",
      "one_line_profile": "Python library for bibliometric and network analysis in science",
      "detailed_description": "A specialized library for quantitative research on science (bibliometrics/scientometrics). It parses data from Web of Science, Scopus, and other databases to construct and analyze citation, co-authorship, and co-citation networks.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "bibliometrics",
        "network_analysis",
        "citation_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/UWNETLAB/metaknowledge",
      "help_website": [
        "http://networkslab.org/metaknowledge/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "bibliometrics",
        "scientometrics",
        "network-analysis"
      ],
      "id": 45
    },
    {
      "name": "Deep Lake",
      "one_line_profile": "Database for AI optimized for deep learning and scientific data",
      "detailed_description": "A data lake for deep learning that stores complex data (images, videos, tensors) and connects them to LLMs and PyTorch/TensorFlow. It serves as critical infrastructure for AI4S applications requiring efficient storage and retrieval of multimodal scientific data.",
      "domains": [
        "G1-03"
      ],
      "subtask_category": [
        "data_storage",
        "vector_retrieval",
        "dataset_management"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/activeloopai/deeplake",
      "help_website": [
        "https://docs.deeplake.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "datalake",
        "multimodal"
      ],
      "id": 46
    },
    {
      "name": "Academic Search MCP Server",
      "one_line_profile": "Model Context Protocol server for scientific literature search",
      "detailed_description": "A tool that integrates Semantic Scholar and Crossref search capabilities into LLM environments (like Claude Desktop) via the Model Context Protocol, enabling AI agents to perform accurate scientific literature discovery.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_search",
        "paper_discovery"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/afrise/academic-search-mcp-server",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "semantic-scholar",
        "mcp",
        "literature-search"
      ],
      "id": 47
    },
    {
      "name": "DocumentGPT",
      "one_line_profile": "RAG-based web application for semantic search and chat with research documents",
      "detailed_description": "A web application that enables researchers to interact with their documents using a Retrieval-Augmented Generation (RAG) approach. It utilizes OpenAI's API and vector databases to perform semantic search and generate responses based on the content of uploaded research papers.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "document_qa",
        "semantic_search"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/aju22/DocumentGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "llm",
        "semantic-search",
        "research-assistant"
      ],
      "id": 48
    },
    {
      "name": "singleCellHaystack",
      "one_line_profile": "Method for finding differentially active genes in single-cell transcriptome data",
      "detailed_description": "A bioinformatics tool designed to identify genes with non-random spatial distributions or differential activity in single-cell transcriptome data without relying on prior clustering of cells. It uses a Kullback-Leibler divergence-based approach.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "differential_expression_analysis",
        "gene_selection"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/alexisvdb/singleCellHaystack",
      "help_website": [
        "https://github.com/alexisvdb/singleCellHaystack"
      ],
      "license": "NOASSERTION",
      "tags": [
        "single-cell",
        "transcriptomics",
        "gene-expression",
        "bioinformatics"
      ],
      "id": 49
    },
    {
      "name": "S2AND",
      "one_line_profile": "Author disambiguation algorithm and evaluation suite for bibliographic data",
      "detailed_description": "A system developed by Semantic Scholar for resolving author name ambiguities in academic literature. It provides a unified framework for training and evaluating author disambiguation models using a large-scale dataset.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "author_disambiguation",
        "data_cleaning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/S2AND",
      "help_website": [
        "https://github.com/allenai/S2AND"
      ],
      "license": "NOASSERTION",
      "tags": [
        "bibliometrics",
        "author-disambiguation",
        "semantic-scholar",
        "clustering"
      ],
      "id": 50
    },
    {
      "name": "citeomatic",
      "one_line_profile": "Citation recommendation system for academic paper drafts",
      "detailed_description": "A tool that predicts relevant citations for a given scientific manuscript. It uses a neural network model trained on the Semantic Scholar OpenCorpus to suggest missing references based on the text of the paper.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "citation_recommendation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/allenai/citeomatic",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "citation-prediction",
        "recommender-system",
        "academic-writing"
      ],
      "id": 51
    },
    {
      "name": "S2ORC",
      "one_line_profile": "The Semantic Scholar Open Research Corpus",
      "detailed_description": "A large-scale corpus of English-language academic papers spanning many disciplines. It provides rich metadata, abstracts, and full text (where available), serving as a foundational dataset for NLP and text mining research in science.",
      "domains": [
        "G1",
        "G1-01"
      ],
      "subtask_category": [
        "dataset_access",
        "text_mining"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/s2orc",
      "help_website": [
        "https://github.com/allenai/s2orc"
      ],
      "license": null,
      "tags": [
        "corpus",
        "academic-papers",
        "nlp",
        "dataset"
      ],
      "id": 52
    },
    {
      "name": "s2search",
      "one_line_profile": "Search reranking library for academic literature",
      "detailed_description": "A Python library implementing the search reranking algorithms used by Semantic Scholar. It allows researchers to improve the relevance of search results in academic retrieval tasks using linear and neural ranking models.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "search_reranking",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/s2search",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reranking",
        "search",
        "semantic-scholar",
        "ir"
      ],
      "id": 53
    },
    {
      "name": "obsidian-reference-map",
      "one_line_profile": "Citation visualization and management plugin for Obsidian",
      "detailed_description": "A plugin for the Obsidian knowledge base that creates interactive citation maps and manages references. It helps researchers visualize connections between papers and discover new literature within their personal knowledge management workflow.",
      "domains": [
        "G1",
        "G1-02"
      ],
      "subtask_category": [
        "literature_review",
        "citation_visualization"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/anoopkcn/obsidian-reference-map",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "obsidian",
        "citation-graph",
        "literature-review",
        "pkm"
      ],
      "id": 54
    },
    {
      "name": "Scientific-Papers-MCP",
      "one_line_profile": "MCP server for LLM access to arXiv and OpenAlex papers",
      "detailed_description": "A Model Context Protocol (MCP) server implementation that enables Large Language Models to search, retrieve, and read scientific papers directly from arXiv and OpenAlex APIs, facilitating AI-assisted literature review.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_retrieval",
        "llm_integration"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/benedict2310/Scientific-Papers-MCP",
      "help_website": [],
      "license": null,
      "tags": [
        "mcp",
        "arxiv",
        "openalex",
        "llm-agent"
      ],
      "id": 55
    },
    {
      "name": "Paperion",
      "one_line_profile": "Academic search engine interface",
      "detailed_description": "An open-source academic search engine platform designed to provide comprehensive access to scholarly articles. It serves as a tool for discovering and filtering scientific literature.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_search"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/blankresearch/Paperion",
      "help_website": [],
      "license": null,
      "tags": [
        "search-engine",
        "academic-search",
        "literature-discovery"
      ],
      "id": 56
    },
    {
      "name": "BABILong",
      "one_line_profile": "Benchmark for evaluating long-context LLMs on needle-in-a-haystack tasks",
      "detailed_description": "A benchmark suite designed to evaluate the performance of Large Language Models in processing extremely long contexts. It uses a 'needle-in-a-haystack' approach to test retrieval and reasoning capabilities, which is critical for analyzing long scientific texts.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmark"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/booydar/babilong",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "llm",
        "long-context",
        "evaluation"
      ],
      "id": 57
    },
    {
      "name": "Anserini",
      "one_line_profile": "Reproducible information retrieval toolkit based on Lucene",
      "detailed_description": "A comprehensive toolkit for information retrieval research that supports both sparse (BM25) and dense (vector) retrieval. It is widely used for building academic search engines and reproducing IR baselines in scientific literature tasks.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "information_retrieval",
        "indexing"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/castorini/anserini",
      "help_website": [
        "http://anserini.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "information-retrieval",
        "lucene",
        "search-engine",
        "bm25"
      ],
      "id": 58
    },
    {
      "name": "anserini-tools",
      "one_line_profile": "Evaluation and utility scripts for the Anserini ecosystem",
      "detailed_description": "A collection of shared utilities and evaluation scripts used across the Anserini, Pyserini, and PyGaggle projects. It facilitates the standardized evaluation of information retrieval models.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "evaluation",
        "utility"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/castorini/anserini-tools",
      "help_website": [],
      "license": null,
      "tags": [
        "evaluation",
        "ir",
        "metrics"
      ],
      "id": 59
    },
    {
      "name": "Birch",
      "one_line_profile": "BERT-based document ranking model",
      "detailed_description": "A document ranking tool that utilizes BERT for sentence-level modeling to improve retrieval effectiveness. It aggregates sentence scores to rank documents, often used in high-precision academic search tasks.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "document_ranking",
        "information_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/castorini/birch",
      "help_website": [],
      "license": null,
      "tags": [
        "bert",
        "ranking",
        "ir",
        "document-retrieval"
      ],
      "id": 60
    },
    {
      "name": "DHR",
      "one_line_profile": "Dense Hybrid Representations for text retrieval",
      "detailed_description": "A retrieval model that combines dense and sparse representations to achieve efficient and effective text retrieval. It is designed to handle the trade-off between retrieval speed and accuracy in large-scale document collections.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "text_retrieval",
        "embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/castorini/dhr",
      "help_website": [],
      "license": null,
      "tags": [
        "dense-retrieval",
        "hybrid-search",
        "ir"
      ],
      "id": 61
    },
    {
      "name": "hf-spacerini",
      "one_line_profile": "Search interface builder for Pyserini and Hugging Face models",
      "detailed_description": "A toolkit designed to facilitate reproducible information retrieval research by providing plug-and-play search interfaces that integrate Pyserini's retrieval capabilities with Hugging Face's models, enabling researchers to visualize and interact with search results.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "information_retrieval",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/castorini/hf-spacerini",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "search-interface",
        "pyserini",
        "huggingface",
        "ir-research"
      ],
      "id": 62
    },
    {
      "name": "PyGaggle",
      "one_line_profile": "Neural ranking library for text ranking and question answering",
      "detailed_description": "A library containing various deep neural architectures for text ranking and question answering, specifically designed to work in conjunction with Pyserini for information retrieval tasks.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "ranking",
        "question_answering"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/castorini/pygaggle",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "neural-ranking",
        "text-ranking",
        "qa",
        "pyserini"
      ],
      "id": 63
    },
    {
      "name": "Pyserini",
      "one_line_profile": "Toolkit for reproducible information retrieval research",
      "detailed_description": "A Python toolkit that supports reproducible information retrieval research, offering sparse and dense retrieval representations, and integrating with the Anserini IR toolkit.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "information_retrieval",
        "indexing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/castorini/pyserini",
      "help_website": [
        "https://pyserini.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "information-retrieval",
        "bm25",
        "dense-retrieval",
        "lucene"
      ],
      "id": 64
    },
    {
      "name": "dspy-neo4j-knowledge-graph",
      "one_line_profile": "Automated knowledge graph construction tool using LLMs",
      "detailed_description": "A tool leveraging DSPy and Neo4j to automate the construction of knowledge graphs from unstructured text, facilitating the structuring of scientific knowledge.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "information_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/chrisammon3000/dspy-neo4j-knowledge-graph",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "neo4j",
        "dspy",
        "llm"
      ],
      "id": 65
    },
    {
      "name": "Rektor",
      "one_line_profile": "Lightweight vector database",
      "detailed_description": "A vector database designed for storing and retrieving high-dimensional vectors, serving as infrastructure for semantic search and RAG applications in scientific domains.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "vector_storage",
        "similarity_search"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/codediodeio/rektor-db",
      "help_website": [],
      "license": null,
      "tags": [
        "vector-database",
        "search",
        "embeddings"
      ],
      "id": 66
    },
    {
      "name": "Adaptive Classifier",
      "one_line_profile": "Flexible system for dynamic text classification",
      "detailed_description": "A classification system designed to adaptively classify text data, suitable for organizing and filtering scientific literature or textual data.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "text_classification",
        "filtering"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/codelion/adaptive-classifier",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "classification",
        "nlp",
        "text-mining"
      ],
      "id": 67
    },
    {
      "name": "HNSW (Go)",
      "one_line_profile": "In-memory vector index library for Go",
      "detailed_description": "A Go implementation of the Hierarchical Navigable Small World (HNSW) algorithm for efficient approximate nearest neighbor search, a core component for vector retrieval systems.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "vector_indexing",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/coder/hnsw",
      "help_website": [],
      "license": "CC0-1.0",
      "tags": [
        "hnsw",
        "vector-search",
        "ann"
      ],
      "id": 68
    },
    {
      "name": "Abstracts Search",
      "one_line_profile": "Semantic search engine for academic publications",
      "detailed_description": "A semantic search engine implementation capable of indexing and retrieving from a large corpus of academic publications (110 million abstracts), facilitating literature discovery.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "semantic_search",
        "literature_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/colonelwatch/abstracts-search",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "semantic-search",
        "academic-search",
        "nlp"
      ],
      "id": 69
    },
    {
      "name": "Cosdata",
      "one_line_profile": "AI data platform for search pipelines",
      "detailed_description": "A data platform designed for next-generation search pipelines, featuring semantic search, hybrid capabilities, and ML integration, suitable for managing scientific data retrieval.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "semantic_search",
        "data_management"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/cosdata/cosdata",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-search",
        "data-platform",
        "rust"
      ],
      "id": 70
    },
    {
      "name": "CozoDB",
      "one_line_profile": "Transactional relational-graph-vector database",
      "detailed_description": "A hybrid database system combining relational, graph, and vector capabilities with Datalog query support, enabling complex knowledge representation and retrieval for AI applications.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "graph_storage",
        "vector_storage",
        "knowledge_representation"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/cozodb/cozo",
      "help_website": [
        "https://docs.cozodb.org/"
      ],
      "license": "MPL-2.0",
      "tags": [
        "graph-database",
        "vector-database",
        "datalog"
      ],
      "id": 71
    },
    {
      "name": "CrateDB",
      "one_line_profile": "Distributed SQL database for real-time analytics",
      "detailed_description": "A distributed SQL database based on Lucene, optimized for storing and analyzing massive amounts of data, including vector search capabilities relevant for scientific data retrieval.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "data_storage",
        "analytics",
        "vector_search"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/crate/crate",
      "help_website": [
        "https://crate.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "sql",
        "distributed-database",
        "lucene",
        "vector-search"
      ],
      "id": 72
    },
    {
      "name": "Autofaiss",
      "one_line_profile": "Tool for automatic Faiss index creation",
      "detailed_description": "A tool that automatically creates and optimizes Faiss k-nearest neighbor indices, simplifying the deployment of efficient vector search systems for large datasets.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "vector_indexing",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/criteo/autofaiss",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "faiss",
        "vector-search",
        "knn"
      ],
      "id": 73
    },
    {
      "name": "Semantic Scholar Client",
      "one_line_profile": "Unofficial Python client for Semantic Scholar API",
      "detailed_description": "A Python library that provides an interface to the Semantic Scholar API, enabling researchers to programmatically retrieve and analyze scientific literature data.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_retrieval",
        "data_access"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/danielnsilva/semanticscholar",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-scholar",
        "api-client",
        "bibliometrics"
      ],
      "id": 74
    },
    {
      "name": "Databend",
      "one_line_profile": "AI-native cloud data warehouse",
      "detailed_description": "A modern cloud data warehouse that supports vector search and AI capabilities, providing infrastructure for storing and analyzing large-scale scientific and multimodal data.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "data_warehouse",
        "analytics",
        "vector_search"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/databendlabs/databend",
      "help_website": [
        "https://databend.com"
      ],
      "license": "NOASSERTION",
      "tags": [
        "data-warehouse",
        "olap",
        "vector-search",
        "rust"
      ],
      "id": 75
    },
    {
      "name": "Bolt",
      "one_line_profile": "High-performance matrix and vector operations library",
      "detailed_description": "A C++ library optimized for extremely fast matrix and vector operations, serving as a foundational building block for efficient vector retrieval and scientific computing tasks.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "linear_algebra",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/dblalock/bolt",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "matrix-operations",
        "simd",
        "performance",
        "cpp"
      ],
      "id": 76
    },
    {
      "name": "Haystack",
      "one_line_profile": "Orchestration framework for LLM and search applications",
      "detailed_description": "An open-source framework for building production-ready LLM applications, retrieval-augmented generation (RAG), and semantic search systems, widely used for processing and querying scientific knowledge bases.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "semantic_search",
        "rag",
        "question_answering"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepset-ai/haystack",
      "help_website": [
        "https://haystack.deepset.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "rag",
        "llm",
        "search-framework"
      ],
      "id": 77
    },
    {
      "name": "OpenAlexAPI",
      "one_line_profile": "Python wrapper library for the OpenAlex scientific database API",
      "detailed_description": "A Python library designed to interact with the OpenAlex API, enabling researchers to programmatically retrieve and analyze scientific metadata, citations, and author networks.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "metadata_retrieval",
        "citation_analysis",
        "scientific_data_access"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dpriskorn/OpenAlexAPI",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "openalex",
        "bibliometrics",
        "citation-analysis",
        "api-wrapper"
      ],
      "id": 78
    },
    {
      "name": "alex-mcp",
      "one_line_profile": "Model Context Protocol (MCP) server for OpenAlex integration",
      "detailed_description": "An MCP server implementation that connects Large Language Models (LLMs) with the OpenAlex database, allowing AI agents to query scientific literature and citation data directly.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_retrieval",
        "llm_integration",
        "scientific_knowledge_access"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/drAbreu/alex-mcp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "openalex",
        "llm-agent",
        "literature-search"
      ],
      "id": 79
    },
    {
      "name": "Anserini Solr Plugin",
      "one_line_profile": "Solr plugin for Anserini-style query expansion and reranking",
      "detailed_description": "A Solr plugin developed by Elsevier Labs that enables Anserini-style query expansion and reranking techniques directly within Solr indexes, facilitating advanced information retrieval research and applications.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "information_retrieval",
        "query_expansion"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/elsevierlabs-os/anserini-solr-plugin",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "solr",
        "anserini",
        "information-retrieval",
        "reranking"
      ],
      "id": 80
    },
    {
      "name": "JSTOR Workset Browser",
      "one_line_profile": "Tool suite for indexing and analyzing JSTOR citation datasets",
      "detailed_description": "A suite of software tools designed to cache, index, analyze, and visualize content from JSTOR Data For Research citations.xml files, supporting 'distant reading' and bibliometric analysis of scholarly journal articles.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "text_mining",
        "bibliometrics",
        "visualization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ericleasemorgan/JSTOR-Workset-Browser",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "jstor",
        "digital-humanities",
        "text-analysis",
        "bibliometrics"
      ],
      "id": 81
    },
    {
      "name": "Contriever",
      "one_line_profile": "Unsupervised dense information retrieval model with contrastive learning",
      "detailed_description": "A dense information retrieval model and library developed by Facebook Research that uses contrastive learning for unsupervised training, widely used in scientific document retrieval and RAG pipelines.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "information_retrieval",
        "embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/contriever",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "dense-retrieval",
        "contrastive-learning",
        "information-retrieval"
      ],
      "id": 82
    },
    {
      "name": "Distributed Faiss",
      "one_line_profile": "Library for building and serving multi-node distributed Faiss indices",
      "detailed_description": "An extension of the Faiss library enabling the construction and serving of vector similarity search indices across multiple nodes, essential for handling large-scale scientific embedding datasets.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "vector_search",
        "indexing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/distributed-faiss",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "faiss",
        "distributed-computing",
        "vector-search"
      ],
      "id": 83
    },
    {
      "name": "DPR Scale",
      "one_line_profile": "Scalable training framework for dense retrieval models",
      "detailed_description": "A library for scalable training of Dense Passage Retrieval (DPR) models, facilitating the development of high-performance neural search systems for scientific literature and open-domain QA.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "model_training",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/dpr-scale",
      "help_website": [],
      "license": null,
      "tags": [
        "dpr",
        "dense-retrieval",
        "training-framework"
      ],
      "id": 84
    },
    {
      "name": "Faiss",
      "one_line_profile": "Library for efficient similarity search and clustering of dense vectors",
      "detailed_description": "A standard library for efficient similarity search and clustering of dense vectors, serving as the computational backbone for modern scientific information retrieval, molecule similarity search, and genomic sequence embedding analysis.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "vector_search",
        "clustering",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/facebookresearch/faiss",
      "help_website": [
        "https://github.com/facebookresearch/faiss/wiki"
      ],
      "license": "MIT",
      "tags": [
        "vector-search",
        "similarity-search",
        "clustering",
        "gpu-accelerated"
      ],
      "id": 85
    },
    {
      "name": "Multi-hop Dense Retrieval",
      "one_line_profile": "Multi-hop dense retrieval system for complex question answering",
      "detailed_description": "A library implementing multi-hop dense retrieval techniques, enabling the answering of complex questions that require reasoning over multiple documents, applicable to scientific question answering tasks.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "question_answering",
        "information_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/multihop_dense_retrieval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "multi-hop-qa",
        "dense-retrieval",
        "question-answering"
      ],
      "id": 86
    },
    {
      "name": "OpenAlex Raw Tools",
      "one_line_profile": "Tools to process OpenAlex raw snapshot files",
      "detailed_description": "A set of utilities for parsing and processing the raw data snapshots from OpenAlex, a massive open catalog of the global research system, enabling large-scale bibliometric analysis.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "data_parsing",
        "bibliometrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/filipinascimento/openalex-raw",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "openalex",
        "bibliometrics",
        "data-processing"
      ],
      "id": 87
    },
    {
      "name": "OpenAlexNet",
      "one_line_profile": "Library for generating citation and co-authorship networks from OpenAlex",
      "detailed_description": "A helper library to interface with the OpenAlex API, specifically designed to generate and analyze citation and co-authorship networks for scientometric research.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "network_analysis",
        "bibliometrics",
        "data_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/filipinascimento/openalexnet",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "openalex",
        "citation-network",
        "co-authorship",
        "scientometrics"
      ],
      "id": 88
    },
    {
      "name": "Zotero Citation Counts Agent",
      "one_line_profile": "Zotero plugin to fetch citation counts from academic APIs",
      "detailed_description": "A plugin for the Zotero reference manager that automatically fetches and displays citation counts from sources like Crossref, Semantic Scholar, INSPIRE-HEP, and NASA ADS.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "bibliometrics",
        "reference_management"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/flychen50/ZoteroCitationCountsAgent",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "zotero-plugin",
        "citation-count",
        "bibliometrics"
      ],
      "id": 89
    },
    {
      "name": "Semantra",
      "one_line_profile": "Local semantic search tool for documents",
      "detailed_description": "A multi-tool for performing semantic search on local document collections (PDFs, text files), useful for researchers conducting literature reviews or exploring large text corpora.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "semantic_search",
        "literature_review"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/freedmand/semantra",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-search",
        "local-search",
        "embeddings"
      ],
      "id": 90
    },
    {
      "name": "ScholarLensViz",
      "one_line_profile": "Visualization tool for semantic user profiles in academia",
      "detailed_description": "A visualization tool developed by the University of Jena for displaying and exploring semantic user profiles, supporting research in expert finding and academic profiling.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "visualization",
        "profiling"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/fusion-jena/ScholarLensViz",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "visualization",
        "semantic-web",
        "academic-profiling"
      ],
      "id": 91
    },
    {
      "name": "Automatic KG Creation with LLM",
      "one_line_profile": "Framework for constructing knowledge graphs using LLMs",
      "detailed_description": "A Python framework for the automatic construction of ontologies and knowledge graphs from text using Large Language Models, applicable to scientific knowledge extraction and organization.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "information_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/fusion-jena/automatic-KG-creation-with-LLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "llm",
        "ontology-construction"
      ],
      "id": 92
    },
    {
      "name": "CODEC Dataset",
      "one_line_profile": "Document and entity ranking dataset for complex topics",
      "detailed_description": "A dataset for document and entity ranking focusing on complex essay-style topics, serving as a benchmark for information retrieval and ranking algorithms in the social sciences and humanities.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "benchmarking",
        "information_retrieval"
      ],
      "application_level": "dataset",
      "primary_language": "Shell",
      "repo_url": "https://github.com/grill-lab/CODEC",
      "help_website": [],
      "license": null,
      "tags": [
        "dataset",
        "information-retrieval",
        "ranking",
        "complex-topics"
      ],
      "id": 93
    },
    {
      "name": "PromptReps",
      "one_line_profile": "Prompting LLMs to generate dense/sparse representations for document retrieval",
      "detailed_description": "A tool that leverages Large Language Models to generate high-quality dense and sparse vector representations for zero-shot document retrieval tasks, enhancing retrieval performance without extensive training data.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "dense_retrieval",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ielab/PromptReps",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "dense-retrieval",
        "zero-shot",
        "information-retrieval"
      ],
      "id": 94
    },
    {
      "name": "llm-rankers",
      "one_line_profile": "Document ranking library using Large Language Models",
      "detailed_description": "A library for implementing and evaluating various document ranking and re-ranking strategies using Large Language Models (LLMs), supporting point-wise, pair-wise, and list-wise ranking approaches.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "ranking",
        "reranking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ielab/llm-rankers",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ranking",
        "llm",
        "information-retrieval",
        "reranking"
      ],
      "id": 95
    },
    {
      "name": "Infinity",
      "one_line_profile": "AI-native database for hybrid search and LLM applications",
      "detailed_description": "A high-performance database designed for LLM applications, offering hybrid search capabilities that combine dense vector, sparse vector, tensor, and full-text search for efficient information retrieval.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "vector_search",
        "retrieval",
        "hybrid_search"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/infiniflow/infinity",
      "help_website": [
        "https://infiniflow.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "hybrid-search",
        "llm",
        "retrieval"
      ],
      "id": 96
    },
    {
      "name": "analysis-ik",
      "one_line_profile": "IK Analysis plugin for Elasticsearch/OpenSearch",
      "detailed_description": "A widely used Chinese text analysis plugin for Elasticsearch and OpenSearch, providing customized dictionary support and segmentation for accurate text indexing and retrieval.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "text_processing",
        "tokenization"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/infinilabs/analysis-ik",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "elasticsearch",
        "text-analysis",
        "tokenization",
        "search"
      ],
      "id": 97
    },
    {
      "name": "citation_map",
      "one_line_profile": "Tool to create Gephi citation graphs from Zotero PDFs",
      "detailed_description": "A Python tool that analyzes text from PDFs stored in Zotero to generate citation networks compatible with Gephi, facilitating bibliometric analysis and visualization of research literature.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "citation_analysis",
        "visualization",
        "bibliometrics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/jaks6/citation_map",
      "help_website": [],
      "license": null,
      "tags": [
        "bibliometrics",
        "citation-graph",
        "zotero",
        "gephi"
      ],
      "id": 98
    },
    {
      "name": "hyperDB",
      "one_line_profile": "Hyper-fast local vector database for LLM Agents",
      "detailed_description": "A lightweight, local vector database designed for use with LLM agents, enabling fast semantic search and memory storage without the need for external server infrastructure.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "vector_search",
        "retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jdagdelen/hyperDB",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vector-database",
        "local-search",
        "llm-agents"
      ],
      "id": 99
    },
    {
      "name": "vectordb",
      "one_line_profile": "Minimalist Python vector database",
      "detailed_description": "A simple and efficient Python vector database library for managing and searching vector embeddings, suitable for lightweight semantic search applications.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "vector_search",
        "retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jina-ai/vectordb",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "semantic-search",
        "embeddings"
      ],
      "id": 100
    },
    {
      "name": "kelindar/search",
      "one_line_profile": "High-performance embedded vector search library for Go",
      "detailed_description": "A lightweight Go library designed for embedded vector search and semantic embeddings, enabling efficient similarity search and retrieval capabilities within applications without external dependencies.",
      "domains": [
        "G1-03"
      ],
      "subtask_category": [
        "vector_search",
        "semantic_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/kelindar/search",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vector-search",
        "embedding",
        "go",
        "semantic-search"
      ],
      "id": 101
    },
    {
      "name": "Resin",
      "one_line_profile": "Embedded NoSQL search engine with vector support",
      "detailed_description": "A language model search engine built on a vector database and key/value store, designed to facilitate semantic search and retrieval operations in .NET applications.",
      "domains": [
        "G1-03"
      ],
      "subtask_category": [
        "vector_search",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/kreeben/resin",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "search-engine",
        "vector-database",
        "dotnet"
      ],
      "id": 102
    },
    {
      "name": "Kùzu",
      "one_line_profile": "Embedded property graph database with vector search capabilities",
      "detailed_description": "An embedded property graph database management system built for speed, featuring built-in vector search and full-text search capabilities, optimized for handling complex relationships in scientific and knowledge graph data.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "graph_database",
        "vector_search",
        "knowledge_graph"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/kuzudb/kuzu",
      "help_website": [
        "https://kuzudb.com"
      ],
      "license": "MIT",
      "tags": [
        "graph-database",
        "vector-search",
        "cypher",
        "embedded-db"
      ],
      "id": 103
    },
    {
      "name": "LangChain4j",
      "one_line_profile": "Java library for integrating LLMs and vector databases",
      "detailed_description": "A Java library that simplifies the integration of Large Language Models (LLMs) into applications, providing unified APIs for accessing vector databases and implementing Retrieval-Augmented Generation (RAG) workflows for scientific text analysis.",
      "domains": [
        "G1-03"
      ],
      "subtask_category": [
        "rag",
        "llm_integration",
        "vector_store_connector"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/langchain4j/langchain4j",
      "help_website": [
        "https://docs.langchain4j.dev"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "llm",
        "java",
        "vector-database"
      ],
      "id": 104
    },
    {
      "name": "Lantern",
      "one_line_profile": "PostgreSQL extension for vector similarity search",
      "detailed_description": "A PostgreSQL extension that adds vector database capabilities, enabling efficient vector similarity search and embedding management directly within the relational database environment, suitable for scientific data indexing.",
      "domains": [
        "G1-03"
      ],
      "subtask_category": [
        "vector_search",
        "database_extension"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/lanterndata/lantern",
      "help_website": [
        "https://lantern.dev"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "postgresql",
        "vector-search",
        "embedding",
        "database"
      ],
      "id": 105
    },
    {
      "name": "Manticore Search",
      "one_line_profile": "High-performance database for full-text and vector search",
      "detailed_description": "An open-source database designed for fast full-text search and vector search, serving as a drop-in replacement for Elasticsearch in scientific data retrieval and indexing pipelines.",
      "domains": [
        "G1-03"
      ],
      "subtask_category": [
        "fulltext_search",
        "vector_search",
        "indexing"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/manticoresoftware/manticoresearch",
      "help_website": [
        "https://manticoresearch.com"
      ],
      "license": "GPL-3.0",
      "tags": [
        "search-engine",
        "vector-search",
        "database",
        "elasticsearch-alternative"
      ],
      "id": 106
    },
    {
      "name": "bibliometrix",
      "one_line_profile": "R-tool for comprehensive science mapping analysis",
      "detailed_description": "An R package for quantitative research in scientometrics and bibliometrics, providing tools for parsing bibliographic data, constructing citation networks, and visualizing scientific knowledge structures.",
      "domains": [
        "G1"
      ],
      "subtask_category": [
        "bibliometrics",
        "citation_analysis",
        "science_mapping"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/massimoaria/bibliometrix",
      "help_website": [
        "https://www.bibliometrix.org"
      ],
      "license": "GPL-3.0",
      "tags": [
        "bibliometrics",
        "scientometrics",
        "citation-analysis",
        "r-package"
      ],
      "id": 107
    },
    {
      "name": "MatrixOne",
      "one_line_profile": "Hyper-converged cloud-edge native database with vector search",
      "detailed_description": "A MySQL-compatible HTAP database that integrates vector search and full-text search capabilities, supporting AI-driven data applications and scientific data management.",
      "domains": [
        "G1-03"
      ],
      "subtask_category": [
        "vector_search",
        "htap_database",
        "data_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/matrixorigin/matrixone",
      "help_website": [
        "https://matrixorigin.cn"
      ],
      "license": "Apache-2.0",
      "tags": [
        "database",
        "vector-search",
        "htap",
        "mysql-compatible"
      ],
      "id": 108
    },
    {
      "name": "draw-citation-graph",
      "one_line_profile": "Script to generate citation graphs from BibTeX and PDFs",
      "detailed_description": "A tool that parses BibTeX files and PDF directories to construct and visualize citation networks, aiding in the analysis of bibliographic relationships.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "citation_analysis",
        "visualization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mhl/draw-citation-graph",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "citation-graph",
        "bibtex",
        "visualization"
      ],
      "id": 109
    },
    {
      "name": "OpenKP",
      "one_line_profile": "Keyphrase extraction toolkit and dataset for scientific documents",
      "detailed_description": "A toolkit and dataset for extracting salient keyphrases from documents, specifically optimized for scientific papers and diverse document structures using neural seq2seq models.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "keyphrase_extraction",
        "document_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/OpenKP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "keyphrase-extraction",
        "nlp",
        "scientific-documents"
      ],
      "id": 110
    },
    {
      "name": "SDR",
      "one_line_profile": "Self-Supervised Document-to-Document Similarity Ranking",
      "detailed_description": "A library implementing self-supervised methods for document-to-document similarity ranking using contextualized language models and hierarchical inference, applicable to scientific literature retrieval.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "document_ranking",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/SDR",
      "help_website": [],
      "license": null,
      "tags": [
        "ranking",
        "similarity",
        "nlp"
      ],
      "id": 111
    },
    {
      "name": "Knowhere",
      "one_line_profile": "Core vector search engine library for Milvus",
      "detailed_description": "The core vector search engine library that powers Milvus, integrating various vector indexing algorithms like FAISS and HNSW for high-performance similarity search.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "vector_search",
        "indexing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/milvus-io/knowhere",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-search",
        "ann",
        "indexing"
      ],
      "id": 112
    },
    {
      "name": "Milvus",
      "one_line_profile": "High-performance vector database for scalable similarity search",
      "detailed_description": "A cloud-native vector database designed for scalable vector ANN search, serving as critical infrastructure for scientific literature retrieval and embedding management.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "vector_database",
        "retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/milvus-io/milvus",
      "help_website": [
        "https://milvus.io/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "embedding-store",
        "search-engine"
      ],
      "id": 113
    },
    {
      "name": "Milvus Lite",
      "one_line_profile": "Lightweight embedded version of Milvus vector database",
      "detailed_description": "A lightweight, embedded version of the Milvus vector database that can be integrated directly into Python applications for local vector search and retrieval tasks.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "vector_search",
        "local_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/milvus-io/milvus-lite",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-search",
        "embedded-db",
        "python"
      ],
      "id": 114
    },
    {
      "name": "Milvus Model",
      "one_line_profile": "Embedding and reranking model integration library",
      "detailed_description": "A library for integrating embedding generation and reranking models, facilitating the processing of scientific text into vectors for semantic search.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "embedding_generation",
        "reranking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/milvus-io/milvus-model",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "embeddings",
        "reranking",
        "semantic-search"
      ],
      "id": 115
    },
    {
      "name": "PyS2",
      "one_line_profile": "Python library for Semantic Scholar API",
      "detailed_description": "A Python library providing typed objects and functionalities to interact with the Semantic Scholar API, facilitating the retrieval of scientific literature data.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_retrieval",
        "api_client"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mirandrom/PyS2",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-scholar",
        "literature-search",
        "api-wrapper"
      ],
      "id": 116
    },
    {
      "name": "Baguetter",
      "one_line_profile": "Flexible search engine library for sparse, dense, and hybrid retrieval",
      "detailed_description": "A search engine library designed for benchmarking and implementing sparse, dense, and hybrid retrieval methods, applicable to scientific document search systems.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "retrieval",
        "search_engine"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mixedbread-ai/baguetter",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "search-engine",
        "hybrid-retrieval",
        "dense-retrieval"
      ],
      "id": 117
    },
    {
      "name": "Dense-Homolog-Retrieval",
      "one_line_profile": "Deep dense retrieval for protein remote homolog detection",
      "detailed_description": "A tool implementing deep dense retrieval methods for the ultra-fast and sensitive detection of protein remote homologs, aiding in bioinformatics analysis.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "homolog_detection",
        "protein_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ml4bio/Dense-Homolog-Retrieval",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "bioinformatics",
        "protein-homology",
        "dense-retrieval"
      ],
      "id": 118
    },
    {
      "name": "SS-self-hosting",
      "one_line_profile": "Tools for self-hosting Semantic Scholar data",
      "detailed_description": "A repository providing scripts and tools to enable researchers to self-host and manage data from the Semantic Scholar dataset for local analysis.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "data_management",
        "literature_hosting"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/moaraio/SS-self-hosting",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-scholar",
        "data-hosting",
        "scientific-literature"
      ],
      "id": 119
    },
    {
      "name": "MULTICOM",
      "one_line_profile": "Protein structure prediction system",
      "detailed_description": "A comprehensive protein structure prediction system including template-based and template-free modeling, 1D feature prediction, and model ranking.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "structure_prediction",
        "protein_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Perl",
      "repo_url": "https://github.com/multicom-toolbox/multicom",
      "help_website": [],
      "license": null,
      "tags": [
        "protein-structure",
        "bioinformatics",
        "modeling"
      ],
      "id": 120
    },
    {
      "name": "QuickGraph",
      "one_line_profile": "Collaborative annotation tool for knowledge graph information extraction",
      "detailed_description": "A web-based annotation tool designed for rapid, multi-task collaborative information extraction, specifically facilitating the construction of knowledge graphs from text data.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "annotation",
        "information_extraction",
        "knowledge_graph_construction"
      ],
      "application_level": "tool",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/nlp-tlp/quickgraph",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "annotation-tool",
        "knowledge-graph",
        "nlp"
      ],
      "id": 121
    },
    {
      "name": "Open Semantic ETL",
      "one_line_profile": "ETL pipeline for processing and enriching document collections for semantic search",
      "detailed_description": "A Python-based ETL toolset for file crawling, document processing (OCR, text extraction), and content analysis (NER), designed to ingest data into Solr/Elasticsearch or Knowledge Graphs.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "data_ingestion",
        "text_extraction",
        "named_entity_recognition"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/opensemanticsearch/open-semantic-etl",
      "help_website": [
        "https://www.opensemanticsearch.org/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "etl",
        "ocr",
        "ner",
        "semantic-search"
      ],
      "id": 122
    },
    {
      "name": "Open Semantic Search",
      "one_line_profile": "Integrated research tool for searching and analyzing large document collections",
      "detailed_description": "An open-source research platform combining a semantic search engine with text mining and analytics capabilities, enabling exploration of document collections via full-text search, faceted search, and knowledge graphs.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "semantic_search",
        "document_analysis",
        "knowledge_discovery"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/opensemanticsearch/open-semantic-search",
      "help_website": [
        "https://www.opensemanticsearch.org/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "search-engine",
        "text-mining",
        "knowledge-graph"
      ],
      "id": 123
    },
    {
      "name": "OpenAlex PDF Parser",
      "one_line_profile": "Utility to parse scientific PDFs using Grobid",
      "detailed_description": "A Python utility used by OpenAlex to parse PDF documents of scientific papers, leveraging Grobid for structure extraction.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "pdf_parsing",
        "text_extraction"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/ourresearch/openalex-pdf-parser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-parsing",
        "grobid",
        "scientific-literature"
      ],
      "id": 124
    },
    {
      "name": "pandoc-scholar",
      "one_line_profile": "Pandoc extension for authoring semantic scientific publications",
      "detailed_description": "A tool that enables the creation of semantically meaningful scientific articles using Pandoc, supporting metadata enrichment and conversion to various scientific formats.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "scientific_writing",
        "metadata_enrichment"
      ],
      "application_level": "tool",
      "primary_language": "Lua",
      "repo_url": "https://github.com/pandoc-scholar/pandoc-scholar",
      "help_website": [
        "https://github.com/pandoc-scholar/pandoc-scholar"
      ],
      "license": "GPL-2.0",
      "tags": [
        "pandoc",
        "publishing",
        "semantic-publishing"
      ],
      "id": 125
    },
    {
      "name": "LitSearch",
      "one_line_profile": "A retrieval benchmark and evaluation suite for scientific literature search",
      "detailed_description": "A comprehensive benchmark dataset and evaluation framework designed to test and improve retrieval systems specifically for scientific literature, addressing the unique challenges of complex queries and domain-specific terminology in science.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "benchmarking",
        "retrieval_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/princeton-nlp/LitSearch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scientific-retrieval",
        "benchmark",
        "evaluation",
        "nlp"
      ],
      "id": 126
    },
    {
      "name": "openalexR",
      "one_line_profile": "R interface to the OpenAlex bibliographic database",
      "detailed_description": "An R package provided by rOpenSci that facilitates querying, retrieving, and analyzing bibliographic data from the OpenAlex database, enabling bibliometric studies and scientific literature analysis.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_retrieval",
        "bibliometrics"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/ropensci/openalexR",
      "help_website": [
        "https://docs.ropensci.org/openalexR/"
      ],
      "license": "MIT",
      "tags": [
        "bibliometrics",
        "openalex",
        "literature-mining",
        "r-package"
      ],
      "id": 127
    },
    {
      "name": "HypEx",
      "one_line_profile": "Framework for automatic causal inference and hypothesis testing",
      "detailed_description": "A fast and customizable Python framework designed for causal inference, enabling researchers to estimate treatment effects and validate hypotheses using statistical methods.",
      "domains": [
        "Sci Knowledge",
        "Data Analysis"
      ],
      "subtask_category": [
        "causal_inference",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sb-ai-lab/HypEx",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "causal-inference",
        "statistics",
        "hypothesis-testing"
      ],
      "id": 128
    },
    {
      "name": "vlite",
      "one_line_profile": "Lightweight vector database built on NumPy",
      "detailed_description": "A simple and fast vector database implementation using NumPy, suitable for lightweight semantic search and embedding retrieval tasks in scientific workflows.",
      "domains": [
        "G1-03",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "vector_search",
        "embedding_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sdan/vlite",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vector-database",
        "numpy",
        "semantic-search"
      ],
      "id": 129
    },
    {
      "name": "matchmaker",
      "one_line_profile": "Library for training and evaluating neural re-ranking models",
      "detailed_description": "A PyTorch-based library designed for the training, evaluation, and analysis of dense retrieval and neural re-ranking models in information retrieval research.",
      "domains": [
        "G1-03",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "information_retrieval",
        "model_training",
        "re-ranking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sebastian-hofstaetter/matchmaker",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "information-retrieval",
        "neural-ranking",
        "pytorch"
      ],
      "id": 130
    },
    {
      "name": "GCMex",
      "one_line_profile": "Matlab wrapper for Graph Cut image segmentation algorithm",
      "detailed_description": "A Matlab wrapper for the Graph Cut algorithm, enabling efficient image segmentation and energy minimization for computer vision and image analysis tasks.",
      "domains": [
        "Image Analysis",
        "Computer Vision"
      ],
      "subtask_category": [
        "image_segmentation",
        "graph_cut"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/shaibagon/GCMex",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "image-segmentation",
        "matlab",
        "graph-cut"
      ],
      "id": 131
    },
    {
      "name": "similarities",
      "one_line_profile": "Toolkit for similarity calculation and semantic search",
      "detailed_description": "A comprehensive toolkit for calculating text and image similarities, supporting semantic search, duplicate detection, and retrieval tasks often used in scientific text mining.",
      "domains": [
        "G1-03",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "semantic_search",
        "similarity_calculation",
        "text_mining"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shibing624/similarities",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "semantic-search",
        "similarity",
        "nlp"
      ],
      "id": 132
    },
    {
      "name": "diophila",
      "one_line_profile": "Python API wrapper for OpenAlex scientific database",
      "detailed_description": "A Python library for querying the OpenAlex database, facilitating the retrieval and analysis of scientific metadata, authors, and citation networks.",
      "domains": [
        "G1",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "literature_retrieval",
        "bibliometrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/smierz/diophila",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "openalex",
        "bibliometrics",
        "api-wrapper"
      ],
      "id": 133
    },
    {
      "name": "sqlite-vector",
      "one_line_profile": "Vector search extension for SQLite",
      "detailed_description": "A lightweight SQLite extension that adds vector search capabilities, enabling local embedding storage and retrieval for scientific applications and edge computing.",
      "domains": [
        "G1-03",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "vector_search",
        "database_extension"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/sqliteai/sqlite-vector",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "sqlite",
        "vector-search",
        "embeddings"
      ],
      "id": 134
    },
    {
      "name": "NOUS",
      "one_line_profile": "Platform for Knowledge Graph construction and reasoning",
      "detailed_description": "A system for the construction, querying, and reasoning of knowledge graphs, supporting streaming data and complex relationship modeling in scientific domains.",
      "domains": [
        "Sci Knowledge",
        "G1"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "reasoning"
      ],
      "application_level": "platform",
      "primary_language": "Scala",
      "repo_url": "https://github.com/streaming-graphs/NOUS",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "streaming",
        "reasoning"
      ],
      "id": 135
    },
    {
      "name": "t-rex",
      "one_line_profile": "Vector tile server for geospatial data",
      "detailed_description": "A high-performance vector tile server specialized in publishing MVT tiles from geospatial data, supporting scientific mapping and geographic information system (GIS) visualization.",
      "domains": [
        "Earth Science",
        "Visualization"
      ],
      "subtask_category": [
        "geospatial_visualization",
        "map_serving"
      ],
      "application_level": "service",
      "primary_language": "Rust",
      "repo_url": "https://github.com/t-rex-tileserver/t-rex",
      "help_website": [
        "https://t-rex.tileserver.ch/"
      ],
      "license": "MIT",
      "tags": [
        "gis",
        "vector-tiles",
        "mapping"
      ],
      "id": 136
    },
    {
      "name": "semantic_research_engine",
      "one_line_profile": "Semantic search engine for scientific papers",
      "detailed_description": "A research tool that leverages semantic search and large language models to retrieve and synthesize relevant scientific papers based on user queries.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_search",
        "paper_retrieval"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/tahreemrasul/semantic_research_engine",
      "help_website": [],
      "license": null,
      "tags": [
        "semantic-search",
        "rag",
        "literature-review"
      ],
      "id": 137
    },
    {
      "name": "raggo",
      "one_line_profile": "Lightweight RAG library for Go",
      "detailed_description": "A production-ready library for Retrieval Augmented Generation (RAG) in Go, facilitating the creation of semantic search and question-answering systems for knowledge bases.",
      "domains": [
        "G1-03",
        "Sci Knowledge"
      ],
      "subtask_category": [
        "rag",
        "retrieval",
        "question_answering"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/teilomillet/raggo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "go",
        "retrieval"
      ],
      "id": 138
    },
    {
      "name": "pgvecto.rs",
      "one_line_profile": "Scalable vector search extension for PostgreSQL",
      "detailed_description": "A PostgreSQL extension that adds vector similarity search capabilities, enabling the database to be used for AI applications like semantic search and RAG (Retrieval-Augmented Generation) within the scientific literature ecosystem.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "vector_search",
        "indexing"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/tensorchord/pgvecto.rs",
      "help_website": [
        "https://docs.pgvecto.rs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "postgres",
        "vector-search",
        "rag",
        "embeddings"
      ],
      "id": 139
    },
    {
      "name": "HyDE",
      "one_line_profile": "Zero-shot dense retrieval method using hypothetical document embeddings",
      "detailed_description": "An implementation of Hypothetical Document Embeddings (HyDE), a method for precise zero-shot dense retrieval that generates hypothetical documents from queries to improve retrieval accuracy without relevance labels.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "information_retrieval",
        "query_expansion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/texttron/hyde",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dense-retrieval",
        "zero-shot",
        "nlp",
        "search"
      ],
      "id": 140
    },
    {
      "name": "pgai",
      "one_line_profile": "PostgreSQL extension suite for AI and RAG application development",
      "detailed_description": "A suite of tools designed to facilitate the development of RAG (Retrieval-Augmented Generation) and semantic search applications directly within PostgreSQL, integrating vector search and embedding workflows.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "rag",
        "semantic_search"
      ],
      "application_level": "solver",
      "primary_language": "PLpgSQL",
      "repo_url": "https://github.com/timescale/pgai",
      "help_website": [
        "https://github.com/timescale/pgai"
      ],
      "license": "PostgreSQL",
      "tags": [
        "postgresql",
        "rag",
        "ai-engineering",
        "vector-search"
      ],
      "id": 141
    },
    {
      "name": "VESPA (Exoplanet)",
      "one_line_profile": "Probabilistic algorithm for validating exoplanet transit signals",
      "detailed_description": "A tool for calculating false positive probabilities for transiting planet candidates, used in astronomy to validate exoplanet signals from photometric data.",
      "domains": [
        "Astronomy"
      ],
      "subtask_category": [
        "signal_validation",
        "statistical_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/timothydmorton/VESPA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "exoplanets",
        "astronomy",
        "probability",
        "validation"
      ],
      "id": 142
    },
    {
      "name": "Towhee",
      "one_line_profile": "Framework for building neural data processing pipelines",
      "detailed_description": "A framework dedicated to making neural data processing pipelines simple and fast, specifically for generating embeddings and processing unstructured data like text and images for retrieval tasks.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "embedding_generation",
        "pipeline_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/towhee-io/towhee",
      "help_website": [
        "https://towhee.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "embeddings",
        "neural-search",
        "pipeline",
        "etl"
      ],
      "id": 143
    },
    {
      "name": "USearch",
      "one_line_profile": "High-performance vector search and clustering engine",
      "detailed_description": "A fast, open-source search and clustering engine for vectors and arbitrary objects, supporting multiple languages. It is used for similarity search in large-scale scientific datasets and embeddings.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "vector_search",
        "clustering"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/unum-cloud/USearch",
      "help_website": [
        "https://unum-cloud.github.io/usearch/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vector-search",
        "clustering",
        "similarity-search",
        "cpp"
      ],
      "id": 144
    },
    {
      "name": "UrbanKGent",
      "one_line_profile": "Agent for urban knowledge graph construction",
      "detailed_description": "An agent-based tool designed for the construction of urban knowledge graphs, facilitating the organization and analysis of urban science data.",
      "domains": [
        "Urban Science"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "data_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/usail-hkust/UrbanKGent",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "urban-computing",
        "agent"
      ],
      "id": 145
    },
    {
      "name": "ALIGNN",
      "one_line_profile": "Atomistic Line Graph Neural Network for materials property prediction",
      "detailed_description": "A deep learning framework based on Atomistic Line Graph Neural Networks, used for predicting material properties and analyzing atomic structures in materials science.",
      "domains": [
        "Materials Science"
      ],
      "subtask_category": [
        "property_prediction",
        "structure_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/usnistgov/alignn",
      "help_website": [
        "https://jarvis.nist.gov/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "gnn",
        "materials-science",
        "deep-learning",
        "atomistic"
      ],
      "id": 146
    },
    {
      "name": "Vespa",
      "one_line_profile": "Big data serving engine for AI and vector search",
      "detailed_description": "A platform for low-latency computation over large datasets, specializing in vector search, recommendation, and real-time AI inference. It is widely used for building large-scale scientific literature retrieval and ranking systems.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "search_platform",
        "vector_search"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/vespa-engine/vespa",
      "help_website": [
        "https://vespa.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "search-engine",
        "vector-database",
        "big-data",
        "ai-serving"
      ],
      "id": 147
    },
    {
      "name": "Vespa-MRS",
      "one_line_profile": "Python tools for Magnetic Resonance Spectroscopy (MRS) simulation and analysis",
      "detailed_description": "A suite of Python tools for Magnetic Resonance Spectroscopy (MRS), including pulse simulation, spectral simulation, and data analysis. It supports processing and visualization of MRS data.",
      "domains": [
        "Physics",
        "Spectroscopy"
      ],
      "subtask_category": [
        "simulation",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vespa-mrs/vespa",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "mrs",
        "spectroscopy",
        "simulation",
        "magnetic-resonance"
      ],
      "id": 148
    },
    {
      "name": "GeneticFlow",
      "one_line_profile": "Graph signatures for scholar impact evaluation using self-citations",
      "detailed_description": "A tool for evaluating scholar impact by analyzing citation graphs, specifically focusing on self-citation patterns to generate graph signatures for scientometric analysis.",
      "domains": [
        "G1",
        "Scientometrics"
      ],
      "subtask_category": [
        "network_analysis",
        "impact_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/visdata/GeneticFlow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scientometrics",
        "citation-graph",
        "impact-evaluation"
      ],
      "id": 149
    },
    {
      "name": "open-hummingbird-eval",
      "one_line_profile": "Dense NN retrieval evaluation for vision encoders",
      "detailed_description": "Implements the Dense NN Retrieval Evaluation framework used for assessing the In-Context Learning capabilities of Vision Encoders, facilitating benchmarking of retrieval models.",
      "domains": [
        "G1-03",
        "Computer Vision"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vpariza/open-hummingbird-eval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "retrieval",
        "evaluation",
        "vision-encoder",
        "neural-network"
      ],
      "id": 150
    },
    {
      "name": "context_attentive_ir",
      "one_line_profile": "Implementation of Context-aware Neural Information Retrieval models",
      "detailed_description": "Provides implementations for Context-aware Neural Information Retrieval models, supporting research in neural IR and document ranking.",
      "domains": [
        "G1-03",
        "Information Retrieval"
      ],
      "subtask_category": [
        "modeling",
        "information_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wasiahmad/context_attentive_ir",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "neural-ir",
        "information-retrieval",
        "context-aware"
      ],
      "id": 151
    },
    {
      "name": "Weaviate",
      "one_line_profile": "Open-source vector database for AI-native search",
      "detailed_description": "A cloud-native vector database that stores both objects and vectors, enabling semantic search, vector search, and combination with structured filtering. It is a foundational tool for scientific literature retrieval and knowledge graph applications.",
      "domains": [
        "G1-03",
        "Database"
      ],
      "subtask_category": [
        "vector_search",
        "indexing",
        "storage"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/weaviate/weaviate",
      "help_website": [
        "https://weaviate.io/developers/weaviate"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "vector-database",
        "semantic-search",
        "knn",
        "ann"
      ],
      "id": 152
    },
    {
      "name": "ir_axioms",
      "one_line_profile": "Framework for axiomatic retrieval experimentation",
      "detailed_description": "A framework for conducting axiomatic retrieval experimentation, allowing researchers to define and test retrieval axioms and diagnostics for information retrieval models.",
      "domains": [
        "G1-03",
        "Information Retrieval"
      ],
      "subtask_category": [
        "experimentation",
        "retrieval_analysis"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/webis-de/ir_axioms",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "information-retrieval",
        "axiomatic-retrieval",
        "experimentation"
      ],
      "id": 153
    },
    {
      "name": "weggli",
      "one_line_profile": "Semantic search tool for C and C++ codebases",
      "detailed_description": "A fast and robust semantic search tool designed for security researchers to identify interesting functionality and vulnerabilities in large C and C++ codebases using structural patterns.",
      "domains": [
        "Computer Science",
        "Security"
      ],
      "subtask_category": [
        "static_analysis",
        "code_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/weggli-rs/weggli",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "static-analysis",
        "security",
        "semantic-search",
        "code-analysis"
      ],
      "id": 154
    },
    {
      "name": "rule-based-retrieval",
      "one_line_profile": "Rule-based retrieval package for RAG applications",
      "detailed_description": "A Python package that enables the creation and management of Retrieval Augmented Generation (RAG) applications with advanced filtering capabilities, integrating with vector databases.",
      "domains": [
        "G1-03",
        "Information Retrieval"
      ],
      "subtask_category": [
        "retrieval",
        "filtering",
        "rag"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/whyhow-ai/rule-based-retrieval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "retrieval",
        "filtering",
        "vector-database"
      ],
      "id": 155
    },
    {
      "name": "tinkerbird",
      "one_line_profile": "Client-side vector database",
      "detailed_description": "A lightweight client-side vector database designed for efficient vector storage and similarity search directly in the browser or client environment.",
      "domains": [
        "G1-03",
        "Database"
      ],
      "subtask_category": [
        "vector_search",
        "storage"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/wizenheimer/tinkerbird",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vector-database",
        "client-side",
        "similarity-search"
      ],
      "id": 156
    },
    {
      "name": "ProQA",
      "one_line_profile": "Progressively Pretrained Dense Corpus Index for Open-Domain QA",
      "detailed_description": "Implements a progressively pretrained dense corpus index for Open-Domain Question Answering and Information Retrieval, enhancing retrieval accuracy for QA tasks.",
      "domains": [
        "G1-03",
        "Information Retrieval"
      ],
      "subtask_category": [
        "question_answering",
        "indexing",
        "retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/xwhan/ProQA",
      "help_website": [],
      "license": null,
      "tags": [
        "qa",
        "information-retrieval",
        "dense-retrieval"
      ],
      "id": 157
    },
    {
      "name": "STAN-POI-Recommendation",
      "one_line_profile": "Spatial-Temporal Attention Network for POI Recommendation",
      "detailed_description": "Implementation of a Spatial-Temporal Attention Network for Point-of-Interest (POI) recommendation, used for location and trajectory prediction in recommender systems research.",
      "domains": [
        "G1",
        "Recommender Systems"
      ],
      "subtask_category": [
        "recommendation",
        "modeling",
        "trajectory_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yingtaoluo/Spatial-Temporal-Attention-Network-for-POI-Recommendation",
      "help_website": [],
      "license": null,
      "tags": [
        "recommender-system",
        "poi",
        "spatial-temporal",
        "attention-network"
      ],
      "id": 158
    },
    {
      "name": "Medical-RAG",
      "one_line_profile": "A medical domain-specific RAG system for retrieving and answering medical queries",
      "detailed_description": "A Retrieval-Augmented Generation (RAG) project specifically designed for the medical domain, utilizing LangChain and Milvus. It supports rapid deployment and domain migration, enabling efficient retrieval and question answering from medical literature or knowledge bases.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "medical_question_answering",
        "information_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yolo-hyl/medical-rag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "medical-nlp",
        "langchain",
        "milvus"
      ],
      "id": 159
    },
    {
      "name": "ubib",
      "one_line_profile": "CLI tool for managing BibTeX citations and researching academic literature",
      "detailed_description": "A command-line interface tool designed to assist researchers in managing BibTeX citations and conducting research. It provides functionalities to handle bibliographic data, making it easier to organize and retrieve scientific references.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "citation_management",
        "literature_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zeitlings/ubib",
      "help_website": [],
      "license": null,
      "tags": [
        "bibtex",
        "citation",
        "research-tool",
        "cli"
      ],
      "id": 160
    },
    {
      "name": "DeepSearcher",
      "one_line_profile": "Agentic framework for deep research and information retrieval from private data",
      "detailed_description": "An open-source deep research agent that combines Large Language Models (LLMs) with vector databases to perform deep information retrieval and reasoning. It is designed to automate the process of gathering and synthesizing information from private data or the web, suitable for scientific literature review and data gathering.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_review",
        "information_retrieval",
        "knowledge_discovery"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zilliztech/deep-searcher",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent",
        "rag",
        "deep-research",
        "retrieval"
      ],
      "id": 161
    },
    {
      "name": "Phantoscope",
      "one_line_profile": "Cloud-native search engine platform powered by neural networks",
      "detailed_description": "A platform for building search engines using neural networks and vector databases. It enables the creation of applications for retrieving unstructured data (images, text) which can be applied to scientific data retrieval tasks.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "image_search",
        "vector_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/zilliztech/phantoscope",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "search-engine",
        "vector-search",
        "neural-network"
      ],
      "id": 162
    },
    {
      "name": "DeepKE",
      "one_line_profile": "Open toolkit for knowledge graph extraction and construction",
      "detailed_description": "A deep learning-based knowledge extraction toolkit designed for knowledge graph construction. It supports various tasks including named entity recognition, relation extraction, and attribute extraction from unstructured text, facilitating the organization of scientific knowledge.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "information_extraction",
        "relation_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/DeepKE",
      "help_website": [
        "https://zjunlp.github.io/DeepKE/"
      ],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "ie",
        "nlp",
        "relation-extraction"
      ],
      "id": 163
    },
    {
      "name": "semantic-scholar-mcp-server",
      "one_line_profile": "MCP server interface for accessing Semantic Scholar academic data",
      "detailed_description": "A FastMCP server implementation that provides an interface to the Semantic Scholar API. It allows AI agents and tools to programmatically access academic paper data, author information, and citation networks, directly supporting scientific literature retrieval tasks.",
      "domains": [
        "G1",
        "G1-03"
      ],
      "subtask_category": [
        "literature_retrieval",
        "citation_analysis"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/zongmin-yu/semantic-scholar-fastmcp-mcp-server",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-scholar",
        "mcp",
        "literature-search",
        "api-wrapper"
      ],
      "id": 164
    }
  ]
}