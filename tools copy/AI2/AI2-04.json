{
  "generated_at": "2025-12-16T03:48:32.950135+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "AI2",
      "leaf_cluster_name": "科研表示学习与 embedding 生态",
      "domain": "AI Toolchain",
      "typical_objects": "embeddings/index",
      "task_chain": "表示→索引→检索→探针评测→更新",
      "tool_form": "表示库 + 向量检索 + 评测"
    },
    "unit": {
      "unit_id": "AI2-04",
      "unit_name": "表示评测与探针任务",
      "target_scale": "150–300",
      "coverage_tools": "benchmarks、probing"
    },
    "search": {
      "target_candidates": 300,
      "queries": [
        "[GH] jiant",
        "[GH] NetRep",
        "[GH] Probe-Ably",
        "[GH] BEIR",
        "[GH] ProteinGym",
        "[GH] MoleculeNet",
        "[GH] SentEval",
        "[GH] MTEB",
        "[GH] embedding evaluation",
        "[GH] representation learning benchmark",
        "[GH] probing tasks",
        "[GH] linear probe",
        "[GH] diagnostic classifier",
        "[GH] representational similarity analysis",
        "[GH] embedding analysis",
        "[GH] latent space evaluation",
        "[GH] embedding quality metrics",
        "[GH] manifold analysis",
        "[GH] scientific benchmarks",
        "[WEB] embedding evaluation framework github",
        "[WEB] representation learning probing tasks github",
        "[WEB] massive text embedding benchmark github",
        "[WEB] scientific representation benchmarks github",
        "[WEB] linear probing tools github"
      ],
      "total_candidates": 943,
      "tool_candidates": 382,
      "final_tools": 131
    }
  },
  "tools": [
    {
      "name": "MoverScore",
      "one_line_profile": "Text generation evaluation metric using contextualized embeddings and Earth Mover Distance",
      "detailed_description": "MoverScore is a metric for evaluating text generation that combines contextualized embeddings (like BERT) with Earth Mover Distance to measure semantic similarity. It provides a more robust evaluation than n-gram based metrics by capturing soft semantic alignments.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "evaluation",
        "metric"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AIPHES/emnlp19-moverscore",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "evaluation-metric",
        "earth-mover-distance",
        "bert-embeddings"
      ],
      "id": 1
    },
    {
      "name": "Probing_framework",
      "one_line_profile": "Framework for conducting probing tasks on language model embeddings",
      "detailed_description": "A framework designed to facilitate probing tasks, which are used to analyze the linguistic properties encoded in the representations (embeddings) of language models. It supports various probing setups to interpret model internals.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "probing",
        "interpretability"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/AIRI-Institute/Probing_framework",
      "help_website": [],
      "license": null,
      "tags": [
        "probing",
        "nlp",
        "embeddings",
        "interpretability"
      ],
      "id": 2
    },
    {
      "name": "CEBRA",
      "one_line_profile": "Learnable latent embeddings for joint behavioral and neural analysis",
      "detailed_description": "CEBRA is a machine learning method for obtaining consistent and interpretable embeddings from joint behavioral and neural data. It uses contrastive learning to uncover latent structures in time-series data, particularly for neuroscience applications.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "representation_learning",
        "neural_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AdaptiveMotorControlLab/CEBRA",
      "help_website": [
        "https://cebra.ai"
      ],
      "license": "NOASSERTION",
      "tags": [
        "neuroscience",
        "contrastive-learning",
        "embeddings",
        "behavioral-analysis"
      ],
      "id": 3
    },
    {
      "name": "ETAB",
      "one_line_profile": "Benchmark suite for visual representation learning in echocardiography",
      "detailed_description": "ETAB is a comprehensive benchmark suite designed to evaluate visual representation learning methods specifically for echocardiography data. It provides standardized tasks and datasets to assess model performance in medical imaging contexts.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "medical_imaging"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/AlaaLab/ETAB",
      "help_website": [],
      "license": null,
      "tags": [
        "echocardiography",
        "medical-imaging",
        "representation-learning",
        "benchmark"
      ],
      "id": 4
    },
    {
      "name": "benchmarking_representations",
      "one_line_profile": "Benchmarking methods for unsupervised representation extraction from cell images",
      "detailed_description": "A repository from the Allen Institute for Cell Science for benchmarking various methods of extracting unsupervised representations from biological images. It facilitates the comparison of different embedding techniques for cellular data.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "bioimage_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/AllenCell/benchmarking_representations",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "cell-biology",
        "representation-learning",
        "benchmarking",
        "microscopy"
      ],
      "id": 5
    },
    {
      "name": "DocGenome",
      "one_line_profile": "Large-scale scientific document benchmark for multi-modal large models",
      "detailed_description": "DocGenome is an open, large-scale benchmark designed for training and testing multi-modal large models on scientific documents. It serves as a resource for evaluating how well models understand and process scientific literature structure and content.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "document_analysis"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Alpha-Innovator/DocGenome",
      "help_website": [],
      "license": "CC-BY-4.0",
      "tags": [
        "scientific-documents",
        "multi-modal",
        "benchmark",
        "llm"
      ],
      "id": 6
    },
    {
      "name": "ROME",
      "one_line_profile": "Machine learning based system for cryo-EM structure determination and analysis",
      "detailed_description": "ROME (Refinement and Optimization via Machine lEarning) is a parallel computing software package for high-resolution cryo-EM structure determination. It implements statistical manifold learning for deep classification and image alignment in HPC environments.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "structure_determination",
        "image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/AlphaCryo4D/ROME",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "cryo-em",
        "manifold-learning",
        "structural-biology",
        "hpc"
      ],
      "id": 7
    },
    {
      "name": "Chain-of-Embedding",
      "one_line_profile": "Latent space method for output-free LLM self-evaluation",
      "detailed_description": "Implements the 'Chain-of-Embedding' technique, which enables Large Language Models to perform self-evaluation directly in the latent space without generating output text. This serves as a tool for efficient model evaluation and internal representation analysis.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "evaluation",
        "model_interpretation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Alsace08/Chain-of-Embedding",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "self-evaluation",
        "latent-space",
        "embeddings"
      ],
      "id": 8
    },
    {
      "name": "Korean-MTEB-Retrieval-Evaluators",
      "one_line_profile": "Retrieval evaluators for Korean MTEB benchmark",
      "detailed_description": "A specific extension of the MTEB (Massive Text Embedding Benchmark) focused on Korean language retrieval tasks. It provides tools to evaluate SPLADE, Dense, and Reranking models within the Korean embedding ecosystem.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BM-K/Korean-MTEB-Retrieval-Evaluators",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mteb",
        "korean",
        "retrieval",
        "embedding-evaluation"
      ],
      "id": 9
    },
    {
      "name": "EvalRank",
      "one_line_profile": "Embedding evaluation framework based on word and sentence similarities",
      "detailed_description": "EvalRank provides a framework for evaluating word and sentence embeddings by rethinking evaluation metrics. It focuses on ranking-based evaluation to assess the quality of representation models.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "evaluation",
        "metric"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BinWang28/EvalRank-Embedding-Evaluation",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "embedding-evaluation",
        "nlp",
        "similarity",
        "ranking"
      ],
      "id": 10
    },
    {
      "name": "cheese",
      "one_line_profile": "Adaptive human-in-the-loop evaluation for language and embedding models",
      "detailed_description": "Cheese is a library designed to facilitate adaptive human-in-the-loop evaluation of language models and embeddings. It helps in collecting human feedback efficiently to evaluate and improve model representations.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "evaluation",
        "human_feedback"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CarperAI/cheese",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "human-in-the-loop",
        "evaluation",
        "nlp",
        "embeddings"
      ],
      "id": 11
    },
    {
      "name": "CausalVerseBenchmark",
      "one_line_profile": "Benchmark for Causal Representation Learning",
      "detailed_description": "CausalVerse is a benchmark suite specifically designed for Causal Representation Learning (CRL). It aims to evaluate methods on their ability to recover the underlying data-generating process and causal variables.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "causal_inference"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/CausalVerse/CausalVerseBenchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "causal-representation-learning",
        "benchmark",
        "causality"
      ],
      "id": 12
    },
    {
      "name": "pyrsa",
      "one_line_profile": "Python library for Representational Similarity Analysis (RSA)",
      "detailed_description": "A Python library for performing Representational Similarity Analysis (RSA), a computational technique used in neuroscience and cognitive science to compare activity patterns (representations) across different measurement modalities and models.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "analysis",
        "neuroscience"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Charestlab/pyrsa",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "rsa",
        "neuroscience",
        "similarity-analysis",
        "representation"
      ],
      "id": 13
    },
    {
      "name": "GritLM",
      "one_line_profile": "Generative Representational Instruction Tuning models and tools",
      "detailed_description": "GritLM provides models and tools for Generative Representational Instruction Tuning, enabling the training and usage of models that can handle both generative tasks and embedding/representation tasks effectively.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "modeling",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ContextualAI/gritlm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "instruction-tuning",
        "embeddings",
        "llm",
        "representation-learning"
      ],
      "id": 14
    },
    {
      "name": "jetson-orin-matmul-analysis",
      "one_line_profile": "Scientific CUDA benchmarking framework for Jetson Orin",
      "detailed_description": "A benchmarking framework designed for scientific matrix multiplication workloads on Jetson Orin hardware. It evaluates performance across different power modes and matrix sizes, useful for edge AI optimization.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "benchmarking",
        "hpc"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Cre4T3Tiv3/jetson-orin-matmul-analysis",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cuda",
        "benchmarking",
        "edge-ai",
        "matrix-multiplication"
      ],
      "id": 15
    },
    {
      "name": "DeepClustering",
      "one_line_profile": "Implementation of Unsupervised Deep Embedding for Clustering Analysis",
      "detailed_description": "A PyTorch implementation of Deep Embedding Clustering (DEC) and related methods. It serves as a tool for performing unsupervised clustering analysis on high-dimensional data using deep neural networks.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "clustering",
        "analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Deepayan137/DeepClustering",
      "help_website": [],
      "license": null,
      "tags": [
        "clustering",
        "deep-learning",
        "unsupervised-learning",
        "embeddings"
      ],
      "id": 16
    },
    {
      "name": "EvalNE",
      "one_line_profile": "Python library for evaluating Network Embedding methods",
      "detailed_description": "EvalNE is a Python library designed to evaluate and compare network embedding (graph representation learning) methods. It provides a unified framework for assessing the quality of node embeddings on various downstream tasks.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Dru-Mara/EvalNE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "network-embedding",
        "graph-learning",
        "evaluation",
        "benchmarking"
      ],
      "id": 17
    },
    {
      "name": "RVGP",
      "one_line_profile": "Riemannian Vector Gaussian Process for learning vector fields on manifolds",
      "detailed_description": "A generalized Gaussian process method for learning vector fields over non-Euclidean domains (manifolds). It is particularly useful for analyzing scientific data like EEG signals or other manifold-structured data.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "modeling",
        "analysis"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/Dynamics-of-Neural-Systems-Lab/RVGP",
      "help_website": [],
      "license": null,
      "tags": [
        "gaussian-processes",
        "manifold-learning",
        "eeg-analysis",
        "vector-fields"
      ],
      "id": 18
    },
    {
      "name": "attention-probes",
      "one_line_profile": "Linear probes with attention weighting for model interpretability",
      "detailed_description": "A tool for training linear probes with attention weighting mechanisms. This is used in the analysis and interpretation of large language models to understand how information is encoded in their representations.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "probing",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EleutherAI/attention-probes",
      "help_website": [],
      "license": null,
      "tags": [
        "probing",
        "attention",
        "interpretability",
        "llm"
      ],
      "id": 19
    },
    {
      "name": "embedding_evaluation",
      "one_line_profile": "Toolkit for evaluating word embeddings",
      "detailed_description": "A Python toolkit designed to evaluate the quality of word embeddings through various intrinsic and extrinsic tasks. It helps researchers assess the semantic properties captured by their embedding models.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EloiZ/embedding_evaluation",
      "help_website": [],
      "license": null,
      "tags": [
        "word-embeddings",
        "evaluation",
        "nlp",
        "benchmarking"
      ],
      "id": 20
    },
    {
      "name": "FluxBench.jl",
      "one_line_profile": "Benchmarks for the FluxML ecosystem",
      "detailed_description": "A benchmarking suite for the FluxML ecosystem in Julia. It evaluates the performance of deep learning and scientific machine learning workloads, including automatic differentiation and CUDA acceleration.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Julia",
      "repo_url": "https://github.com/FluxML/FluxBench.jl",
      "help_website": [],
      "license": null,
      "tags": [
        "julia",
        "fluxml",
        "benchmarking",
        "scientific-machine-learning"
      ],
      "id": 21
    },
    {
      "name": "VR-Bench",
      "one_line_profile": "Benchmark for multimodal reasoning via video generation",
      "detailed_description": "VR-Bench (Reasoning via Video) is a benchmark designed to probe multimodal reasoning capabilities of AI models. It uses tasks like maze-solving video generation to evaluate spatial planning and reasoning in video models.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "reasoning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/FoundationAgents/VR-Bench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "video-generation",
        "multimodal-reasoning",
        "benchmark",
        "spatial-planning"
      ],
      "id": 22
    },
    {
      "name": "sbnltk",
      "one_line_profile": "Bangla Natural Language Processing Toolkit",
      "detailed_description": "A comprehensive toolkit for Bangla language processing, including modules for Named Entity Recognition (NER), POS tagging, stemming, and word/sentence embeddings. It supports NLP research and application development for Bangla.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "processing",
        "nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Foysal87/sbnltk",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "bangla",
        "embeddings",
        "ner"
      ],
      "id": 23
    },
    {
      "name": "compositional-scene-representation-toolbox",
      "one_line_profile": "Toolbox for compositional scene representation learning methods",
      "detailed_description": "A toolbox providing implementations and benchmarks for compositional scene representation learning. It aims to support research in computer vision where understanding the compositional nature of scenes is critical.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "modeling",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/FudanVI/compositional-scene-representation-toolbox",
      "help_website": [],
      "license": null,
      "tags": [
        "computer-vision",
        "scene-representation",
        "compositionality",
        "toolbox"
      ],
      "id": 24
    },
    {
      "name": "LAB-Bench",
      "one_line_profile": "Benchmark for AI systems in biological research capabilities",
      "detailed_description": "LAB-Bench is an evaluation dataset and benchmark designed to assess the capabilities of AI systems in performing tasks foundational to scientific research in biology. It tests models on retrieval, reasoning, and data interpretation in biological contexts.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "biology"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Future-House/LAB-Bench",
      "help_website": [],
      "license": "CC-BY-SA-4.0",
      "tags": [
        "biology",
        "ai4science",
        "benchmark",
        "reasoning"
      ],
      "id": 25
    },
    {
      "name": "GTaxoGym",
      "one_line_profile": "Taxonomy and benchmark suite for Graph Representation Learning",
      "detailed_description": "GTaxoGym provides a taxonomy and a collection of benchmarks for Graph Representation Learning. It helps researchers categorize and evaluate different graph learning methods systematically.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "graph_learning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/G-Taxonomy-Workgroup/GTaxoGym",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-representation-learning",
        "benchmark",
        "taxonomy",
        "gnn"
      ],
      "id": 26
    },
    {
      "name": "TractLearn-WholeBrain",
      "one_line_profile": "Manifold learning toolbox for precision medicine and MRI analysis",
      "detailed_description": "TractLearn is a toolbox leveraging manifold learning techniques for the quantitative analysis of Diffusion-Weighted MRI data. It is designed for applications in precision medicine to detect anomalies and analyze brain structures.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "analysis",
        "medical_imaging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/GeodAIsics/TractLearn-WholeBrain",
      "help_website": [],
      "license": null,
      "tags": [
        "mri",
        "manifold-learning",
        "precision-medicine",
        "neuroimaging"
      ],
      "id": 27
    },
    {
      "name": "GeSS",
      "one_line_profile": "Benchmark for Geometric Deep Learning under scientific distribution shifts",
      "detailed_description": "A benchmark suite designed to evaluate Geometric Deep Learning (GDL) models in scientific applications, specifically focusing on robustness against distribution shifts in geometric data structures common in science.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "model_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Graph-COM/GESS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "geometric-deep-learning",
        "benchmark",
        "distribution-shift",
        "scientific-data"
      ],
      "id": 28
    },
    {
      "name": "NewtonBench",
      "one_line_profile": "Benchmark for scientific law discovery in LLM agents",
      "detailed_description": "A comprehensive benchmark designed to evaluate the capability of Large Language Model (LLM) agents in discovering scientific laws and performing generalizable scientific reasoning across physics and other domains.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "scientific_reasoning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUST-KnowComp/NewtonBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-agent",
        "scientific-discovery",
        "benchmark",
        "physics"
      ],
      "id": 29
    },
    {
      "name": "BubbleML",
      "one_line_profile": "Multiphase multiphysics dataset and benchmark for scientific machine learning",
      "detailed_description": "A dataset and benchmark suite for Scientific Machine Learning (SciML), focusing on multiphase and multiphysics phenomena to evaluate model performance in simulating complex physical dynamics.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "scientific_simulation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/HPCForge/BubbleML",
      "help_website": [],
      "license": null,
      "tags": [
        "sciml",
        "multiphysics",
        "fluid-dynamics",
        "benchmark"
      ],
      "id": 30
    },
    {
      "name": "Fin-Fact",
      "one_line_profile": "Benchmark dataset for multimodal scientific fact-checking",
      "detailed_description": "A benchmark dataset designed for evaluating multimodal scientific fact-checking systems, enabling the assessment of models in verifying scientific claims against evidence.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "fact_checking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/IIT-DM/Fin-Fact",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fact-checking",
        "multimodal",
        "scientific-claims",
        "benchmark"
      ],
      "id": 31
    },
    {
      "name": "VLM4Bio",
      "one_line_profile": "Benchmark for trait discovery from biological images using VLMs",
      "detailed_description": "A benchmark dataset consisting of scientific question-answer pairs aimed at evaluating Pretrained Vision-Language Models (VLMs) for biological trait discovery and image understanding.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "trait_discovery"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Imageomics/VLM4Bio",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "biology",
        "vlm",
        "benchmark",
        "imageomics"
      ],
      "id": 32
    },
    {
      "name": "FLIP",
      "one_line_profile": "Benchmark tasks for protein sequence representation learning",
      "detailed_description": "A collection of probing tasks and benchmarks designed to evaluate the effectiveness of protein sequence representations in modeling various aspects of protein design and function.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "probing",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/J-SNACKKB/FLIP",
      "help_website": [],
      "license": "AFL-3.0",
      "tags": [
        "protein-design",
        "representation-learning",
        "benchmark",
        "biology"
      ],
      "id": 33
    },
    {
      "name": "BiomedSQL",
      "one_line_profile": "Text-to-SQL benchmark for scientific reasoning in biomedicine",
      "detailed_description": "A benchmark dataset for evaluating Text-to-SQL models specifically within the domain of biomedical scientific reasoning and database querying, developed by NIH-CARD.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "scientific_reasoning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/NIH-CARD/biomedsql",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "biomedicine",
        "text-to-sql",
        "benchmark",
        "nlp"
      ],
      "id": 34
    },
    {
      "name": "ProteinGym",
      "one_line_profile": "Comprehensive benchmark for protein variant effect prediction",
      "detailed_description": "An extensive set of deep mutational scanning (DMS) assays and benchmarks used to evaluate the performance of zero-shot and supervised models in predicting the effects of protein variants.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "variant_prediction"
      ],
      "application_level": "dataset",
      "primary_language": "HTML",
      "repo_url": "https://github.com/OATML-Markslab/ProteinGym",
      "help_website": [
        "https://proteingym.org"
      ],
      "license": "MIT",
      "tags": [
        "protein-engineering",
        "variant-effect",
        "benchmark",
        "biology"
      ],
      "id": 35
    },
    {
      "name": "ScienceBoard",
      "one_line_profile": "Benchmark for multimodal autonomous agents in scientific workflows",
      "detailed_description": "An evaluation framework and benchmark designed to assess the performance of multimodal autonomous agents in executing realistic and complex scientific research workflows.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "scientific_agent"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/OS-Copilot/ScienceBoard",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "autonomous-agents",
        "scientific-workflow",
        "benchmark",
        "multimodal"
      ],
      "id": 36
    },
    {
      "name": "OlympiadBench",
      "one_line_profile": "Benchmark for AGI with Olympiad-level scientific problems",
      "detailed_description": "A challenging benchmark dataset featuring Olympiad-level bilingual multimodal scientific problems to evaluate the advanced reasoning capabilities of Artificial General Intelligence (AGI) models.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "scientific_reasoning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenBMB/OlympiadBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agi",
        "scientific-reasoning",
        "benchmark",
        "olympiad"
      ],
      "id": 37
    },
    {
      "name": "SciEval",
      "one_line_profile": "Multi-level LLM evaluation benchmark for scientific research",
      "detailed_description": "A comprehensive benchmark suite for evaluating Large Language Models (LLMs) across multiple levels of scientific research tasks, assessing their capability in scientific reasoning and knowledge application.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "model_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenDFM/SciEval",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-evaluation",
        "scientific-research",
        "benchmark"
      ],
      "id": 38
    },
    {
      "name": "proteingym-base",
      "one_line_profile": "Infrastructure library for ProteinGym variant effect prediction",
      "detailed_description": "The core infrastructure and data handling library for the ProteinGym ecosystem, facilitating the management of assay data, sequences, and structures for variant effect prediction tasks.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "data_processing",
        "infrastructure"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ProteinGym/proteingym-base",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-gym",
        "infrastructure",
        "variant-prediction"
      ],
      "id": 39
    },
    {
      "name": "proteingym-benchmark",
      "one_line_profile": "Model collection and benchmarking pipeline for ProteinGym",
      "detailed_description": "A collection of variant effect prediction models and a DVC-based pipeline designed to execute benchmarking experiments against the ProteinGym datasets.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "workflow"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ProteinGym/proteingym-benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmarking-pipeline",
        "protein-gym",
        "model-evaluation"
      ],
      "id": 40
    },
    {
      "name": "TOTEM",
      "one_line_profile": "Tokenized Time Series Embeddings for General Time Series Analysis",
      "detailed_description": "A method and tool for generating tokenized embeddings for time series data, applicable to general time series analysis tasks in scientific domains.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "time_series_embedding",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SaberaTalukder/TOTEM",
      "help_website": [],
      "license": null,
      "tags": [
        "time-series",
        "embeddings",
        "tokenization"
      ],
      "id": 41
    },
    {
      "name": "SceMQA",
      "one_line_profile": "Scientific College Entrance Level Multimodal Question Answering Benchmark",
      "detailed_description": "A benchmark dataset and evaluation code for assessing multimodal question answering capabilities in scientific contexts.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "scientific_qa",
        "benchmark"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/SceMQA/SceMQA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "multimodal",
        "qa",
        "science"
      ],
      "id": 42
    },
    {
      "name": "DiffEqDevTools.jl",
      "one_line_profile": "Benchmarking and testing tools for differential equations and SciML",
      "detailed_description": "A Julia library providing tools for benchmarking, testing, and developing differential equation solvers and scientific machine learning methods.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "solver_benchmarking",
        "performance_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/SciML/DiffEqDevTools.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "differential-equations",
        "sciml",
        "benchmarking",
        "julia"
      ],
      "id": 43
    },
    {
      "name": "SciMLBenchmarks.jl",
      "one_line_profile": "Scientific machine learning and differential equation solver benchmarks",
      "detailed_description": "A comprehensive collection of benchmarks for scientific machine learning (SciML) and differential equation solvers across multiple languages.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "sciml_benchmarking",
        "solver_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/SciML/SciMLBenchmarks.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sciml",
        "benchmark",
        "differential-equations"
      ],
      "id": 44
    },
    {
      "name": "AstroVisBench",
      "one_line_profile": "Benchmark for scientific computing and visualization in astronomy",
      "detailed_description": "A benchmark suite designed for evaluating scientific computing and visualization techniques specifically within the astronomy domain.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "visualization_benchmark",
        "astronomy_computing"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/SebaJoe/AstroVisBench",
      "help_website": [],
      "license": null,
      "tags": [
        "astronomy",
        "visualization",
        "benchmark"
      ],
      "id": 45
    },
    {
      "name": "CSVQA",
      "one_line_profile": "Multimodal Benchmark for Evaluating Scientific Reasoning Capabilities",
      "detailed_description": "A benchmark designed to evaluate the scientific reasoning capabilities of Vision-Language Models (VLMs).",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "scientific_reasoning",
        "benchmark"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/SkyworkAI/CSVQA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vlm",
        "scientific-reasoning",
        "benchmark"
      ],
      "id": 46
    },
    {
      "name": "BioKEEN",
      "one_line_profile": "Library for learning and evaluating biological knowledge graph embeddings",
      "detailed_description": "A computational library specifically designed for training and evaluating embeddings on biological knowledge graphs.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "bioinformatics"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/SmartDataAnalytics/BioKEEN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "embeddings",
        "biology"
      ],
      "id": 47
    },
    {
      "name": "UCoCoS-Software-Package",
      "one_line_profile": "Tools for analysis and control of complex systems and networks",
      "detailed_description": "A software package for the analysis and control of complex systems, including detection of oscillatory patterns and synchronization in delay-coupled networks.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "complex_system_analysis",
        "control_theory"
      ],
      "application_level": "library",
      "primary_language": null,
      "repo_url": "https://github.com/UCoCoSH2020/UCoCoS-Software-Package",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "complex-systems",
        "control-theory",
        "network-analysis"
      ],
      "id": 48
    },
    {
      "name": "frrsa",
      "one_line_profile": "Feature-reweighted representational similarity analysis package",
      "detailed_description": "A Python package to conduct feature-reweighted representational similarity analysis (RSA), often used in neuroscience and cognitive science.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "representation_similarity_analysis",
        "neuroscience"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ViCCo-Group/frrsa",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "rsa",
        "neuroscience",
        "representation-analysis"
      ],
      "id": 49
    },
    {
      "name": "SciTab",
      "one_line_profile": "Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables",
      "detailed_description": "A benchmark dataset designed for evaluating compositional reasoning and claim verification capabilities on scientific tabular data.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "table_reasoning",
        "scientific_verification"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/XinyuanLu00/SciTab",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scientific-tables",
        "reasoning",
        "benchmark"
      ],
      "id": 50
    },
    {
      "name": "torchange",
      "one_line_profile": "Unified Change Representation Learning Benchmark Library for remote sensing",
      "detailed_description": "A library and benchmark for change representation learning, primarily applicable to remote sensing and earth observation tasks.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "change_detection",
        "remote_sensing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Z-Zheng/pytorch-change-models",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "remote-sensing",
        "change-detection",
        "benchmark"
      ],
      "id": 51
    },
    {
      "name": "NeuroRA",
      "one_line_profile": "Python Toolbox for Multimode Neural Data Representation Analysis",
      "detailed_description": "A toolbox for representational analysis in neuroscience, including Neural Pattern Similarity (NPS), RSA, and Inter-Subject Correlation (ISC).",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "neural_data_analysis",
        "representation_similarity_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ZitongLu1996/NeuroRA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "neuroscience",
        "rsa",
        "neural-data"
      ],
      "id": 52
    },
    {
      "name": "PyCTRSA",
      "one_line_profile": "Toolbox for Cross-Temporal Representational Similarity Analysis on EEG/MEG",
      "detailed_description": "A Python toolbox specifically for conducting Cross-Temporal Representational Similarity Analysis (CTRSA) decoding on EEG and MEG data.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "neural_decoding",
        "eeg_meg_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ZitongLu1996/PyCTRSA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "eeg",
        "meg",
        "neuroscience",
        "rsa"
      ],
      "id": 53
    },
    {
      "name": "ProteinWorkshop",
      "one_line_profile": "Benchmarking framework for protein representation learning",
      "detailed_description": "A comprehensive benchmarking framework for protein representation learning, including datasets, models, and training utilities.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "protein_representation_learning",
        "benchmark"
      ],
      "application_level": "benchmark",
      "primary_language": "Python",
      "repo_url": "https://github.com/a-r-j/ProteinWorkshop",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein",
        "representation-learning",
        "benchmark"
      ],
      "id": 54
    },
    {
      "name": "netrep",
      "one_line_profile": "Methods for comparing network representations in deep learning and neuroscience",
      "detailed_description": "A library implementing methods for comparing neural network representations, applicable in both deep learning research and neuroscience.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "representation_comparison",
        "neuroscience"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ahwillia/netrep",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "neuroscience",
        "representation-comparison",
        "neural-networks"
      ],
      "id": 55
    },
    {
      "name": "grace",
      "one_line_profile": "Graph Representation Analysis for Connected Embeddings",
      "detailed_description": "A library for analyzing graph representations and embeddings, developed by the Alan Turing Institute.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "graph_representation_analysis",
        "embedding_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/alan-turing-institute/grace",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "graph",
        "embeddings",
        "network-analysis"
      ],
      "id": 56
    },
    {
      "name": "SciRepEval",
      "one_line_profile": "Benchmark for scientific representation learning evaluation",
      "detailed_description": "A comprehensive benchmark suite for evaluating scientific document representations across various tasks.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "representation_evaluation",
        "scientific_nlp"
      ],
      "application_level": "benchmark",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/scirepeval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "scientific-representation",
        "benchmark",
        "nlp"
      ],
      "id": 57
    },
    {
      "name": "uncovec",
      "one_line_profile": "Tool for uncovering divergent linguistic information in word embeddings",
      "detailed_description": "A Python library designed to probe and evaluate word embeddings by uncovering divergent linguistic information. It provides methodologies for both intrinsic and extrinsic evaluation of embedding models, focusing on linguistic properties.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "probing",
        "embedding_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/artetxem/uncovec",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "word-embeddings",
        "probing",
        "linguistic-evaluation"
      ],
      "id": 58
    },
    {
      "name": "BEIR",
      "one_line_profile": "Heterogeneous benchmark for zero-shot information retrieval",
      "detailed_description": "A heterogeneous benchmark for Information Retrieval (IR) that allows evaluation of retrieval models across a diverse set of datasets and tasks. It is widely used to assess the generalization capabilities of embedding models in zero-shot settings.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "information_retrieval",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/beir-cellar/beir",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "information-retrieval",
        "benchmark",
        "zero-shot"
      ],
      "id": 59
    },
    {
      "name": "CiteME",
      "one_line_profile": "Benchmark for citation recommendation and retrieval in scientific texts",
      "detailed_description": "A benchmark designed to evaluate the capability of language models to identify and retrieve relevant scientific papers cited within a text. It focuses on the specific task of citation recommendation in scientific literature.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "citation_recommendation",
        "scientific_retrieval"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/bethgelab/CiteME",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "citation-recommendation",
        "scientific-literature",
        "benchmark"
      ],
      "id": 60
    },
    {
      "name": "BytevalKit-Emb",
      "one_line_profile": "Modular framework for embedding model evaluation",
      "detailed_description": "A modular evaluation framework for embedding models that automates performance assessment through standardized processes. It supports configuration-driven evaluation across multiple task types and model architectures.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "embedding_evaluation",
        "model_assessment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bytedance/BytevalKit-Emb",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "embedding-evaluation",
        "benchmark-framework",
        "automated-testing"
      ],
      "id": 61
    },
    {
      "name": "pdf-text-extraction-benchmark",
      "one_line_profile": "Benchmark for PDF text extraction tools in scientific articles",
      "detailed_description": "A benchmarking tool to evaluate the semantic capabilities of various PDF extraction tools, specifically focused on extracting body text from scientific articles. It aids in selecting the best tools for scientific literature mining pipelines.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "pdf_extraction",
        "scientific_literature_mining"
      ],
      "application_level": "workflow",
      "primary_language": "TeX",
      "repo_url": "https://github.com/ckorzen/pdf-text-extraction-benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-extraction",
        "benchmark",
        "scientific-articles"
      ],
      "id": 62
    },
    {
      "name": "WEFE",
      "one_line_profile": "Word Embeddings Fairness Evaluation Framework",
      "detailed_description": "An open-source library for measuring and mitigating bias in word embedding models. It standardizes fairness evaluation metrics, making it essential for assessing the societal impact and reliability of embeddings used in scientific and general contexts.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "fairness_evaluation",
        "bias_measurement"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dccuchile/wefe",
      "help_website": [
        "https://wefe.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "fairness",
        "bias",
        "word-embeddings"
      ],
      "id": 63
    },
    {
      "name": "LLM-SRBench",
      "one_line_profile": "Benchmark for scientific equation discovery with LLMs",
      "detailed_description": "A benchmark designed to evaluate Large Language Models on the task of Scientific Equation Discovery (Symbolic Regression). It assesses the ability of models to recover physical laws and mathematical relationships from data.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "symbolic_regression",
        "equation_discovery"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/deep-symbolic-mathematics/llm-srbench",
      "help_website": [],
      "license": null,
      "tags": [
        "symbolic-regression",
        "scientific-discovery",
        "llm-benchmark"
      ],
      "id": 64
    },
    {
      "name": "MoleculeNet",
      "one_line_profile": "Benchmark datasets and splits for molecular machine learning",
      "detailed_description": "A collection of benchmark datasets and splitting mechanisms for molecular machine learning. It serves as a standard for evaluating molecular property prediction models and representation learning methods in chemistry and drug discovery.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "molecular_property_prediction",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/deepchem/moleculenet",
      "help_website": [
        "https://moleculenet.org/"
      ],
      "license": "MIT",
      "tags": [
        "molecular-machine-learning",
        "benchmark",
        "drug-discovery"
      ],
      "id": 65
    },
    {
      "name": "SciAssess",
      "one_line_profile": "Benchmark for LLM proficiency in scientific literature analysis",
      "detailed_description": "A comprehensive benchmark for evaluating Large Language Models' capabilities in analyzing scientific literature. It tests memorization, comprehension, and analysis skills across various scientific fields.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "scientific_literature_analysis",
        "llm_evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepmodeling/SciAssess",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "scientific-literature",
        "llm-benchmark",
        "comprehension"
      ],
      "id": 66
    },
    {
      "name": "EasyGraph",
      "one_line_profile": "Open-source network analysis and embedding library",
      "detailed_description": "A comprehensive library for network analysis that includes advanced methods for network embedding, structural hole detection, and other graph processing techniques. Applicable to systems biology and social network analysis.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "network_embedding",
        "graph_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/easy-graph/Easy-Graph",
      "help_website": [
        "https://easy-graph.github.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "network-analysis",
        "graph-embedding",
        "structural-hole"
      ],
      "id": 67
    },
    {
      "name": "MTEB",
      "one_line_profile": "Massive Text Embedding Benchmark",
      "detailed_description": "The standard library for benchmarking text embedding models. It covers a massive range of tasks including retrieval, clustering, classification, and semantic textual similarity, providing a unified interface for evaluation.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "embedding_benchmarking",
        "representation_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/embeddings-benchmark/mteb",
      "help_website": [
        "https://huggingface.co/mteb"
      ],
      "license": "Apache-2.0",
      "tags": [
        "text-embedding",
        "benchmark",
        "nlp"
      ],
      "id": 68
    },
    {
      "name": "EmbedStore",
      "one_line_profile": "Hosted platform for embedding discovery and evaluation",
      "detailed_description": "A platform designed to help users discover, evaluate, and retrieve embeddings. It provides tools for managing embedding models and assessing their quality for specific tasks.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "embedding_management",
        "evaluation_platform"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/embeddingstore/embedstore",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "embedding-store",
        "evaluation",
        "retrieval"
      ],
      "id": 69
    },
    {
      "name": "text-to-image-eval",
      "one_line_profile": "Evaluation toolkit for text-to-image and zero-shot models",
      "detailed_description": "A toolkit to evaluate custom and HuggingFace text-to-image or zero-shot image classification models (like CLIP). It includes metrics such as Zero-shot accuracy, Linear Probe, and Image retrieval accuracy.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "multimodal_evaluation",
        "linear_probe"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/encord-team/text-to-image-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "text-to-image",
        "evaluation",
        "clip"
      ],
      "id": 70
    },
    {
      "name": "PDFM Embeddings",
      "one_line_profile": "Location-based embedding generation tool for geo-spatial analysis and population dynamics",
      "detailed_description": "A library providing tools to generate and analyze Probabilistic Deep Feature Modeling (PDFM) embeddings for geo-spatial locations. It facilitates the modeling of population dynamics and other spatial phenomena by converting location data into dense vector representations suitable for machine learning tasks in earth and social sciences.",
      "domains": [
        "Earth Science",
        "Social Science"
      ],
      "subtask_category": [
        "geo_embedding",
        "population_modeling",
        "spatial_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/google-research/population-dynamics",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "geo-spatial",
        "embeddings",
        "population-dynamics"
      ],
      "id": 71
    },
    {
      "name": "MolGraphEval",
      "one_line_profile": "Benchmark suite for evaluating self-supervised molecular graph embeddings",
      "detailed_description": "A benchmarking tool designed to evaluate the quality of molecular graph embeddings generated by self-supervised learning methods. It provides a standardized framework for assessing how well these embeddings capture chemical properties and structural information relevant to drug discovery and material science.",
      "domains": [
        "Chemistry",
        "Drug Discovery"
      ],
      "subtask_category": [
        "representation_evaluation",
        "molecular_modeling",
        "graph_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hansen7/MolGraphEval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "molecular-graphs",
        "self-supervised-learning",
        "benchmarking"
      ],
      "id": 72
    },
    {
      "name": "SeisFlowBench",
      "one_line_profile": "Reproducible benchmarking framework for seismic wave propagation simulations",
      "detailed_description": "A scientific project and toolset built with Julia for benchmarking seismic wave propagation and fluid flow simulations in porous media. It aims to provide reproducible environments for evaluating numerical solvers and simulation methods in geophysics.",
      "domains": [
        "Geophysics",
        "Earth Science"
      ],
      "subtask_category": [
        "simulation_benchmarking",
        "seismic_modeling",
        "fluid_flow"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/haoyunl2/SeisFlowBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "seismology",
        "simulation",
        "benchmarking"
      ],
      "id": 73
    },
    {
      "name": "DLIO Benchmark",
      "one_line_profile": "I/O benchmarking tool for scientific deep learning workloads",
      "detailed_description": "A benchmark suite specifically designed to represent and evaluate the I/O patterns of modern scientific deep learning applications. It helps researchers and HPC engineers optimize storage systems and data pipelines for large-scale scientific AI training.",
      "domains": [
        "Scientific Computing",
        "HPC"
      ],
      "subtask_category": [
        "io_benchmarking",
        "hpc_optimization",
        "infrastructure_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hariharan-devarajan/dlio_benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hpc",
        "io-benchmark",
        "scientific-deep-learning"
      ],
      "id": 74
    },
    {
      "name": "ZADU",
      "one_line_profile": "Library for evaluating the reliability of dimensionality reduction embeddings",
      "detailed_description": "A Python library designed to quantitatively evaluate the quality and reliability of lower-dimensional embeddings produced by dimensionality reduction techniques (like t-SNE, UMAP). It is essential for validating visualizations in single-cell biology and other high-dimensional scientific data analysis.",
      "domains": [
        "Data Science",
        "Biology"
      ],
      "subtask_category": [
        "embedding_evaluation",
        "dimensionality_reduction",
        "visualization_validation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hj-n/zadu",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dimensionality-reduction",
        "evaluation",
        "visualization"
      ],
      "id": 75
    },
    {
      "name": "cellxgene VIP",
      "one_line_profile": "Visualization and analysis plugin for single-cell genomics data in cellxgene",
      "detailed_description": "A plugin for the popular cellxgene platform that extends its capabilities with advanced visualization tools (violin plots, heatmaps, volcano plots) and differential gene expression analysis. It serves as a bridge between interactive exploration and deep statistical analysis for single-cell researchers.",
      "domains": [
        "Biology",
        "Genomics"
      ],
      "subtask_category": [
        "visualization",
        "differential_expression",
        "single_cell_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/interactivereport/cellxgene_VIP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "single-cell",
        "visualization",
        "genomics"
      ],
      "id": 76
    },
    {
      "name": "MicroVQA",
      "one_line_profile": "Benchmark and evaluation tool for multimodal reasoning on microscopy images",
      "detailed_description": "A benchmark and evaluation framework designed for Visual Question Answering (VQA) tasks specifically in the domain of microscopy-based scientific research. It includes tools for evaluating multimodal models' ability to reason about biological structures and experiments.",
      "domains": [
        "Biology",
        "Microscopy"
      ],
      "subtask_category": [
        "visual_question_answering",
        "microscopy_analysis",
        "multimodal_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jmhb0/microvqa",
      "help_website": [],
      "license": null,
      "tags": [
        "microscopy",
        "vqa",
        "benchmark"
      ],
      "id": 77
    },
    {
      "name": "SciFIBench",
      "one_line_profile": "Benchmark for evaluating Large Multimodal Models on scientific figure interpretation",
      "detailed_description": "A benchmarking tool designed to assess the performance of Large Multimodal Models (LMMs) in interpreting and reasoning about scientific figures. It addresses the specific challenges of scientific data visualization and extraction.",
      "domains": [
        "Scientific Literature",
        "Data Science"
      ],
      "subtask_category": [
        "figure_interpretation",
        "multimodal_benchmarking",
        "scientific_visualization_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jonathan-roberts1/SciFIBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scientific-figures",
        "multimodal-models",
        "benchmarking"
      ],
      "id": 78
    },
    {
      "name": "Word Embeddings Benchmarks",
      "one_line_profile": "Package for evaluating word embeddings on various tasks",
      "detailed_description": "A Python package designed to evaluate word embeddings on a variety of tasks including analogy, similarity, and categorization, serving as a foundational tool for representation evaluation.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "representation_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kudkudak/word-embeddings-benchmarks",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "word-embeddings",
        "evaluation",
        "benchmark",
        "nlp"
      ],
      "id": 79
    },
    {
      "name": "vec4ir",
      "one_line_profile": "Word Embeddings for Information Retrieval",
      "detailed_description": "A Python library that integrates word embeddings into information retrieval tasks, providing methods to evaluate and utilize embeddings for document ranking and retrieval.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "information_retrieval",
        "embedding_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lgalke/vec4ir",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "information-retrieval",
        "word-embeddings",
        "ranking"
      ],
      "id": 80
    },
    {
      "name": "CAMELYON-PLUS-BENCHMARK",
      "one_line_profile": "Benchmark datasets for Multiple Instance Learning on pathology images",
      "detailed_description": "A benchmark dataset designed to evaluate Multiple Instance Learning (MIL) methods on CAMELYON pathology images, facilitating the development of algorithms for medical image analysis.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "medical_image_analysis",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/lingxitong/CAMELYON-PLUS-BENCHMARK",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pathology",
        "mil",
        "benchmark",
        "medical-imaging"
      ],
      "id": 81
    },
    {
      "name": "xgboost-survival-embeddings",
      "one_line_profile": "XGBoost survival analysis with embeddings",
      "detailed_description": "A library that enhances XGBoost survival analysis by incorporating embeddings and debiased estimators, useful for medical and biological time-to-event analysis.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "survival_analysis",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/loft-br/xgboost-survival-embeddings",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "survival-analysis",
        "xgboost",
        "embeddings",
        "statistics"
      ],
      "id": 82
    },
    {
      "name": "ChemTable",
      "one_line_profile": "Benchmark for multimodal LLMs on chemical tables",
      "detailed_description": "A large-scale benchmark designed to test the capabilities of multimodal large language models in understanding complex chemical tables from scientific literature.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "chemistry",
        "benchmarking",
        "table_understanding"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/lqzxt/ChemTable",
      "help_website": [],
      "license": null,
      "tags": [
        "chemistry",
        "mllm",
        "benchmark",
        "scientific-tables"
      ],
      "id": 83
    },
    {
      "name": "RealScene-ISTD",
      "one_line_profile": "Benchmark for Infrared Small Target Detection",
      "detailed_description": "A real-scene benchmark and cross-view representation learning framework for generalized infrared small target detection, applicable in remote sensing and physics.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "remote_sensing",
        "target_detection",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/luy0222/RealScene-ISTD",
      "help_website": [],
      "license": null,
      "tags": [
        "infrared",
        "target-detection",
        "benchmark",
        "remote-sensing"
      ],
      "id": 84
    },
    {
      "name": "SCI-CQA",
      "one_line_profile": "Benchmark for scientific chart understanding",
      "detailed_description": "A comprehensive benchmark for evaluating chart understanding capabilities specifically within the context of scientific literature.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "scientific_chart_understanding",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/lydonShen/SCI-CQA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "scientific-charts",
        "vqa",
        "benchmark"
      ],
      "id": 85
    },
    {
      "name": "semantic-search-eval",
      "one_line_profile": "Framework for evaluating semantic search",
      "detailed_description": "A framework designed to evaluate semantic search performance across custom datasets, metrics, and embedding backends, facilitating the optimization of retrieval systems.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "semantic_search",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/machinelearningZH/semantic-search-eval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-search",
        "evaluation",
        "embeddings"
      ],
      "id": 86
    },
    {
      "name": "TaskTracker",
      "one_line_profile": "Tool for detecting task drift in LLMs via activation analysis",
      "detailed_description": "An approach and toolset for detecting task drift in Large Language Models by analyzing internal activations using linear probes and metric learning, contributing to AI safety and interpretability.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "model_probing",
        "interpretability",
        "safety"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/microsoft/TaskTracker",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "probing",
        "activations",
        "ai-safety"
      ],
      "id": 87
    },
    {
      "name": "rag-experiment-accelerator",
      "one_line_profile": "Tool for conducting RAG experiments and evaluations",
      "detailed_description": "A tool designed to expedite the process of conducting experiments and evaluations for Retrieval-Augmented Generation (RAG) patterns, facilitating the development of scientific QA systems.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "experiment_tracking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/rag-experiment-accelerator",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "evaluation",
        "azure",
        "experimentation"
      ],
      "id": 88
    },
    {
      "name": "URL Benchmark",
      "one_line_profile": "Uncertainty-aware representation learning benchmark",
      "detailed_description": "A benchmark for evaluating uncertainty-aware representation learning methods, critical for reliable scientific machine learning applications.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "uncertainty_quantification",
        "representation_learning",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mkirchhof/url",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "uncertainty",
        "representation-learning",
        "benchmark"
      ],
      "id": 89
    },
    {
      "name": "mne-rsa",
      "one_line_profile": "Representational Similarity Analysis for MEG/EEG",
      "detailed_description": "A Python library for performing Representational Similarity Analysis (RSA) on MEG and EEG data, enabling comparison of neural data with computational models.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "neuroscience",
        "rsa",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mne-tools/mne-rsa",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "neuroscience",
        "eeg",
        "meg",
        "rsa"
      ],
      "id": 90
    },
    {
      "name": "EvalScope",
      "one_line_profile": "Framework for large model evaluation and benchmarking",
      "detailed_description": "A streamlined framework for evaluating and benchmarking large models (LLMs, VLMs), essential for assessing models used in scientific discovery.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/modelscope/evalscope",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "evaluation",
        "benchmark",
        "modelscope"
      ],
      "id": 91
    },
    {
      "name": "SciREX",
      "one_line_profile": "Scientific reasoning benchmark",
      "detailed_description": "A benchmark dataset for document-level information extraction and scientific reasoning, designed to evaluate models on complex scientific tasks.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "scientific_reasoning",
        "information_extraction",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/n0w0f/scirex",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scientific-reasoning",
        "benchmark",
        "nlp"
      ],
      "id": 92
    },
    {
      "name": "Nonlinear Time Series Analysis Toolbox",
      "one_line_profile": "Toolbox for nonlinear time series analysis",
      "detailed_description": "A MATLAB toolbox for performing nonlinear time series analysis, including phase space reconstruction (Taken's embedding) and recurrence network analysis, applicable in physics and complex systems.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "time_series_analysis",
        "nonlinear_dynamics",
        "phase_space_embedding"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/narayanps/NolinearTimeSeriesAnalysis",
      "help_website": [],
      "license": null,
      "tags": [
        "time-series",
        "nonlinear-analysis",
        "chaos-theory",
        "matlab"
      ],
      "id": 93
    },
    {
      "name": "jiant",
      "one_line_profile": "NLP toolkit for probing and multitask learning",
      "detailed_description": "A comprehensive NLP toolkit designed for conducting probing tasks and multitask learning experiments, widely used for evaluating and understanding language model representations.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "model_probing",
        "representation_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nyu-mll/jiant",
      "help_website": [
        "https://jiant.info/"
      ],
      "license": "MIT",
      "tags": [
        "nlp",
        "probing",
        "multitask-learning",
        "evaluation"
      ],
      "id": 94
    },
    {
      "name": "SRSD Benchmark",
      "one_line_profile": "Benchmark for Symbolic Regression in Scientific Discovery",
      "detailed_description": "A benchmark dataset and framework for evaluating symbolic regression methods specifically in the context of scientific discovery and physical law recovery.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "symbolic_regression",
        "scientific_discovery",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/omron-sinicx/srsd-benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "symbolic-regression",
        "scientific-discovery",
        "benchmark"
      ],
      "id": 95
    },
    {
      "name": "ATLAS",
      "one_line_profile": "Benchmark for frontier scientific reasoning",
      "detailed_description": "A high-difficulty, multidisciplinary benchmark designed to evaluate the scientific reasoning capabilities of AI models across various scientific domains.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "scientific_reasoning",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/open-compass/ATLAS",
      "help_website": [],
      "license": null,
      "tags": [
        "scientific-reasoning",
        "benchmark",
        "multidisciplinary"
      ],
      "id": 96
    },
    {
      "name": "PDEBench",
      "one_line_profile": "Benchmark for Scientific Machine Learning on PDEs",
      "detailed_description": "An extensive benchmark suite for evaluating machine learning methods on Partial Differential Equations (PDEs), covering a wide range of physical problems.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "pde_solving",
        "sciml",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/pdebench/PDEBench",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "pde",
        "sciml",
        "benchmark",
        "physics"
      ],
      "id": 97
    },
    {
      "name": "MultiBench",
      "one_line_profile": "Multiscale benchmarks for multimodal representation learning",
      "detailed_description": "A comprehensive benchmark suite for evaluating multimodal representation learning models across diverse modalities and tasks, including scientific domains like robotics and healthcare.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "multimodal_learning"
      ],
      "application_level": "dataset",
      "primary_language": "HTML",
      "repo_url": "https://github.com/pliang279/MultiBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multimodal",
        "benchmark",
        "representation-learning"
      ],
      "id": 98
    },
    {
      "name": "baosa",
      "one_line_profile": "Benchmark suite for active optimisation in scientific discovery",
      "detailed_description": "A benchmark suite designed for evaluating active optimization algorithms in scientific discovery contexts, specifically featuring standardized tasks in materials science and biology.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "active_optimization",
        "scientific_discovery"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/poyentung/baosa",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "active-learning",
        "optimization",
        "materials-science",
        "biology"
      ],
      "id": 99
    },
    {
      "name": "LitSearch",
      "one_line_profile": "Retrieval benchmark for scientific literature search",
      "detailed_description": "A benchmark specifically designed to evaluate information retrieval models on scientific literature, facilitating the development of better search tools for researchers.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "information_retrieval"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/princeton-nlp/LitSearch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scientific-literature",
        "retrieval",
        "benchmark"
      ],
      "id": 100
    },
    {
      "name": "PhysGym",
      "one_line_profile": "Benchmark suite for LLM-based scientific reasoning",
      "detailed_description": "A benchmark suite for evaluating the capabilities of Large Language Models in interactive scientific reasoning and physics problem solving.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "scientific_reasoning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/principia-ai/PhysGym",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "physics",
        "reasoning",
        "llm-benchmark"
      ],
      "id": 101
    },
    {
      "name": "scanning-drift-corr",
      "one_line_profile": "Correction of scanning probe artifacts",
      "detailed_description": "A tool for correcting nonlinear and linear scanning probe artifacts using orthogonal scan pairs, essential for accurate processing of microscopy data.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "image_processing",
        "artifact_correction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ptim0626/scanning-drift-corr",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "microscopy",
        "scanning-probe",
        "image-correction"
      ],
      "id": 102
    },
    {
      "name": "PyKEEN",
      "one_line_profile": "Library for learning and evaluating knowledge graph embeddings",
      "detailed_description": "A comprehensive Python library for training and evaluating knowledge graph embedding models, providing a unified pipeline for dataset loading, training, and evaluation.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "embedding_learning",
        "knowledge_graph"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pykeen/pykeen",
      "help_website": [
        "https://pykeen.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "embeddings",
        "link-prediction"
      ],
      "id": 103
    },
    {
      "name": "rsatoolbox",
      "one_line_profile": "Python library for Representational Similarity Analysis",
      "detailed_description": "A Python library for performing Representational Similarity Analysis (RSA), a technique used in computational neuroscience and psychology to compare activity patterns.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "representation_analysis",
        "similarity_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rsagroup/rsatoolbox",
      "help_website": [
        "https://rsatoolbox.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "neuroscience",
        "rsa",
        "representation-learning"
      ],
      "id": 104
    },
    {
      "name": "rsatoolbox_matlab",
      "one_line_profile": "Matlab toolbox for Representational Similarity Analysis",
      "detailed_description": "The MATLAB implementation of the Representational Similarity Analysis (RSA) toolbox, enabling comparison of computational models and brain activity patterns.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "representation_analysis",
        "similarity_analysis"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/rsagroup/rsatoolbox_matlab",
      "help_website": [],
      "license": null,
      "tags": [
        "neuroscience",
        "rsa",
        "matlab"
      ],
      "id": 105
    },
    {
      "name": "EA_for_KG",
      "one_line_profile": "Benchmark for Knowledge Graph Entity Alignment",
      "detailed_description": "A benchmark suite and collection of state-of-the-art algorithms for Entity Alignment in Knowledge Graphs, supporting representation learning research.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "entity_alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ruizhang-ai/EA_for_KG",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "knowledge-graph",
        "entity-alignment",
        "benchmark"
      ],
      "id": 106
    },
    {
      "name": "Neural_Manifolds",
      "one_line_profile": "Techniques for neural manifold analysis",
      "detailed_description": "A repository of techniques and tools for analyzing neural manifolds and brain circuit dynamics, useful for neuroscience research.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "manifold_learning",
        "neural_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/schultzlab/Neural_Manifolds",
      "help_website": [],
      "license": null,
      "tags": [
        "neuroscience",
        "manifold-learning",
        "brain-dynamics"
      ],
      "id": 107
    },
    {
      "name": "SciCode",
      "one_line_profile": "Benchmark for coding solutions to scientific problems",
      "detailed_description": "A benchmark designed to challenge language models to generate code solutions for authentic scientific problems, evaluating their reasoning and coding capabilities in science.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "code_generation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/scicode-bench/SciCode",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "scientific-coding",
        "llm-benchmark",
        "reasoning"
      ],
      "id": 108
    },
    {
      "name": "benchmarking_molecular_models",
      "one_line_profile": "Benchmark for pretrained molecular embedding models",
      "detailed_description": "A benchmarking suite for evaluating various pretrained molecular embedding models on molecular representation learning tasks.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "molecular_representation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/scikit-fingerprints/benchmarking_molecular_models",
      "help_website": [],
      "license": null,
      "tags": [
        "molecular-embeddings",
        "cheminformatics",
        "benchmark"
      ],
      "id": 109
    },
    {
      "name": "TorchSpatial",
      "one_line_profile": "Framework and benchmark for Spatial Representation Learning",
      "detailed_description": "A comprehensive framework and benchmark suite designed to advance Spatial Representation Learning (SRL), providing tools for modeling spatial data.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "spatial_representation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/seai-lab/TorchSpatial",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "spatial-data",
        "representation-learning",
        "gis"
      ],
      "id": 110
    },
    {
      "name": "ChemBench",
      "one_line_profile": "Benchmark datasets for molecular machine learning",
      "detailed_description": "A collection of benchmark datasets including MoleculeNet and MolMapNet for evaluating machine learning models in chemistry.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "dataset_loader"
      ],
      "application_level": "dataset",
      "primary_language": "HTML",
      "repo_url": "https://github.com/shenwanxiang/ChemBench",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "cheminformatics",
        "moleculenet",
        "benchmark"
      ],
      "id": 111
    },
    {
      "name": "DADApy",
      "one_line_profile": "Distance-based Analysis of Data-manifolds",
      "detailed_description": "A Python package for distance-based analysis of data manifolds, including intrinsic dimension estimation and density peak clustering, often used in physics and chemistry.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "manifold_analysis",
        "dimensionality_estimation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sissa-data-science/DADApy",
      "help_website": [
        "https://dadapy.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "manifold-learning",
        "intrinsic-dimension",
        "clustering"
      ],
      "id": 112
    },
    {
      "name": "montlake",
      "one_line_profile": "Tools for geometric data analysis and manifold learning",
      "detailed_description": "A toolkit for geometric data analysis, including vector field group lasso and basis pursuit methods for parametric manifold learning and shape space analysis.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "manifold_learning",
        "geometric_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/sjkoelle/montlake",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "geometric-analysis",
        "manifold-learning",
        "shape-analysis"
      ],
      "id": 113
    },
    {
      "name": "crnpy",
      "one_line_profile": "Toolbox for cosmic-ray neutron probes",
      "detailed_description": "A Python toolbox for processing and handling data from cosmic-ray neutron probes, used in environmental science and soil physics.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "data_processing",
        "environmental_sensing"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/soilwater/crnpy",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "cosmic-ray",
        "soil-moisture",
        "environmental-science"
      ],
      "id": 114
    },
    {
      "name": "MEGENA",
      "one_line_profile": "Multiscale embedded gene co-expression network analysis",
      "detailed_description": "A tool for performing multiscale embedded gene co-expression network analysis, useful for identifying functional modules in genomic data.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "network_analysis",
        "genomics"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/songw01/MEGENA",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "genomics",
        "network-analysis",
        "co-expression"
      ],
      "id": 115
    },
    {
      "name": "NetRep",
      "one_line_profile": "Network topology replication assessment tool",
      "detailed_description": "An R package for assessing the replication and preservation of network topology for weighted gene coexpression network modules across datasets.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "network_analysis",
        "statistical_validation"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/sritchie73/NetRep",
      "help_website": [],
      "license": null,
      "tags": [
        "genomics",
        "network-topology",
        "permutation-test"
      ],
      "id": 116
    },
    {
      "name": "SPRINT Toolkit",
      "one_line_profile": "Evaluation toolkit for neural sparse retrieval models on IR datasets",
      "detailed_description": "A toolkit designed to evaluate diverse neural sparse models (like SPLADE) on Information Retrieval datasets with minimal configuration.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "information_retrieval"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/thakur-nandan/sprint",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sparse-retrieval",
        "evaluation",
        "neural-search"
      ],
      "id": 117
    },
    {
      "name": "GraphEmbeddingRecommendationSystem",
      "one_line_profile": "Graph propagation algorithm implementation for evaluating recommendation systems",
      "detailed_description": "A Python-based implementation of DeepWalk and graph propagation algorithms to evaluate and compare preference propagation in heterogeneous information networks.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "graph_embedding",
        "recommendation_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/triandicAnt/GraphEmbeddingRecommendationSystem",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-embedding",
        "deepwalk",
        "recommendation"
      ],
      "id": 118
    },
    {
      "name": "Video Embeddings Evaluation Framework",
      "one_line_profile": "Evaluation framework for video foundation model embeddings",
      "detailed_description": "A PyTorch implementation of an evaluation framework for assessing the quality and performance of video foundation model embeddings.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "embedding_evaluation",
        "video_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/twelvelabs-io/video-embeddings-evaluation-framework",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "video-embedding",
        "evaluation-framework",
        "foundation-models"
      ],
      "id": 119
    },
    {
      "name": "UpTrain",
      "one_line_profile": "Unified platform to evaluate and improve Generative AI and embedding applications",
      "detailed_description": "An open-source platform providing preconfigured checks and root cause analysis for evaluating LLMs, code generation, and embedding-based use cases.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "probing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/uptrain-ai/uptrain",
      "help_website": [
        "https://uptrain.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "observability",
        "embeddings"
      ],
      "id": 120
    },
    {
      "name": "Latent Space Cartography",
      "one_line_profile": "Visual analysis tool for vector space embeddings",
      "detailed_description": "A tool for the visual analysis and exploration of vector space embeddings, aiding in the interpretation of latent spaces.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "visualization",
        "embedding_analysis"
      ],
      "application_level": "tool",
      "primary_language": "HTML",
      "repo_url": "https://github.com/uwdata/latent-space-cartography",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "visualization",
        "latent-space",
        "embeddings"
      ],
      "id": 121
    },
    {
      "name": "Word Benchmarks",
      "one_line_profile": "Benchmarks for intrinsic word embeddings evaluation",
      "detailed_description": "A collection of benchmarks and datasets designed for the intrinsic evaluation of word embedding models.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "embedding_evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/vecto-ai/word-benchmarks",
      "help_website": [],
      "license": null,
      "tags": [
        "word-embeddings",
        "benchmark",
        "nlp"
      ],
      "id": 122
    },
    {
      "name": "ETNLP",
      "one_line_profile": "Toolkit to evaluate, extract, and visualize multiple embeddings",
      "detailed_description": "A Python toolkit designed to assist in the evaluation, extraction, and visualization of various embedding models for NLP tasks.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "embedding_evaluation",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vietnlp/etnlp",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "embeddings",
        "evaluation-toolkit"
      ],
      "id": 123
    },
    {
      "name": "GISTEmbed",
      "one_line_profile": "Guided In-sample Selection of Training Negatives for Text Embeddings",
      "detailed_description": "Implementation of the GISTEmbed method for improving text embeddings through guided selection of training negatives.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "embedding_training",
        "optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/worldbank/GISTEmbed",
      "help_website": [],
      "license": null,
      "tags": [
        "text-embeddings",
        "contrastive-learning",
        "training-strategy"
      ],
      "id": 124
    },
    {
      "name": "repsim",
      "one_line_profile": "Library for representational similarity analysis (RSA)",
      "detailed_description": "A PyTorch-based library for performing various kinds of representational-similarity analysis (RSA) to compare neural network representations.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "representation_analysis",
        "probing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wrongu/repsim",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rsa",
        "representational-similarity",
        "pytorch"
      ],
      "id": 125
    },
    {
      "name": "BioNEV",
      "one_line_profile": "Graph Embedding Evaluation on Biomedical Networks",
      "detailed_description": "A toolkit and benchmark suite for evaluating graph embedding methods specifically on biomedical networks.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "graph_embedding",
        "biomedical_network",
        "benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/xiangyue9607/BioNEV",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-embedding",
        "bioinformatics",
        "network-analysis"
      ],
      "id": 126
    },
    {
      "name": "Multiphysics Bench",
      "one_line_profile": "Benchmark for Scientific Machine Learning on multiphysics PDEs",
      "detailed_description": "A benchmark suite for investigating and evaluating Scientific Machine Learning (SciML) methods for solving multiphysics Partial Differential Equations (PDEs).",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "sciml_benchmarking",
        "pde_solving"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/xie-lab-ml/multiphysics-bench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sciml",
        "pde",
        "multiphysics"
      ],
      "id": 127
    },
    {
      "name": "HNE",
      "one_line_profile": "Heterogeneous Network Embedding Benchmark and Evaluation",
      "detailed_description": "A repository providing benchmarks, evaluation scripts, and resources for Heterogeneous Network Embedding (HNE) methods.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "network_embedding",
        "benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/yangji9181/HNE",
      "help_website": [],
      "license": null,
      "tags": [
        "heterogeneous-networks",
        "graph-embedding",
        "benchmark"
      ],
      "id": 128
    },
    {
      "name": "FinMTEB",
      "one_line_profile": "Finance Massive Text Embedding Benchmark",
      "detailed_description": "A specialized benchmark suite for evaluating text embedding models within the financial domain (FinMTEB).",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "embedding_benchmarking",
        "financial_nlp"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/yixuantt/FinMTEB",
      "help_website": [],
      "license": null,
      "tags": [
        "finance",
        "text-embedding",
        "benchmark"
      ],
      "id": 129
    },
    {
      "name": "dec-pytorch",
      "one_line_profile": "Implementation of Unsupervised Deep Embedding for Clustering Analysis (DEC)",
      "detailed_description": "A PyTorch implementation of the Deep Embedding for Clustering (DEC) algorithm, used for unsupervised clustering of data representations.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "clustering",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/youngerous/dec-pytorch",
      "help_website": [],
      "license": null,
      "tags": [
        "clustering",
        "deep-embedding",
        "pytorch"
      ],
      "id": 130
    },
    {
      "name": "pwesuite",
      "one_line_profile": "Suite for phonetic word embeddings evaluation",
      "detailed_description": "A suite designed for the evaluation of phonetic word embeddings, including baseline models and datasets.",
      "domains": [
        "AI2",
        "AI2-04"
      ],
      "subtask_category": [
        "embedding_evaluation",
        "phonetics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/zouharvi/pwesuite",
      "help_website": [],
      "license": null,
      "tags": [
        "phonetic-embeddings",
        "evaluation",
        "nlp"
      ],
      "id": 131
    }
  ]
}