{
  "generated_at": "2025-12-16T01:18:14.870084+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "AI2",
      "leaf_cluster_name": "科研表示学习与 embedding 生态",
      "domain": "AI Toolchain",
      "typical_objects": "embeddings/index",
      "task_chain": "表示→索引→检索→探针评测→更新",
      "tool_form": "表示库 + 向量检索 + 评测"
    },
    "unit": {
      "unit_id": "AI2-01",
      "unit_name": "单模态 embedding（文本/序列/图）",
      "target_scale": "250–600",
      "coverage_tools": "embedding models、toolkits"
    },
    "search": {
      "target_candidates": 600,
      "queries": [
        "[GH] Nucleotide Transformer",
        "[GH] ChemBERTa",
        "[GH] GROVER",
        "[GH] Mol2Vec",
        "[GH] BioBERT",
        "[GH] SPECTER",
        "[GH] DNABERT",
        "[GH] ProtTrans",
        "[GH] SciBERT",
        "[GH] ESM-2",
        "[GH] protein language model",
        "[GH] molecular embedding",
        "[GH] scientific text embedding",
        "[GH] graph representation learning",
        "[GH] dna sequence embedding",
        "[GH] scibert",
        "[GH] protein encoder",
        "[GH] smiles transformer",
        "[GH] biomedical embedding",
        "[GH] graph neural network chemistry",
        "[GH] sequence representation",
        "[GH] single-cell embedding",
        "[GH] pretrained scientific model",
        "[WEB] protein language models github",
        "[WEB] scientific representation learning tools github",
        "[WEB] molecular graph embedding models github",
        "[WEB] biomedical text embedding benchmarks github",
        "[WEB] dna sequence embedding models github",
        "[WEB] pretrained transformers for science github"
      ],
      "total_candidates": 1056,
      "tool_candidates": 523,
      "final_tools": 181
    }
  },
  "tools": [
    {
      "name": "AmpliGraph",
      "one_line_profile": "Python library for Representation Learning on Knowledge Graphs",
      "detailed_description": "A library for graph representation learning that provides a suite of neural machine learning models for relational learning on knowledge graphs, widely used in scientific knowledge discovery.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "link_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Accenture/AmpliGraph",
      "help_website": [
        "https://docs.ampligraph.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "embedding",
        "tensorflow",
        "graph-neural-networks"
      ],
      "id": 1
    },
    {
      "name": "GRAPE",
      "one_line_profile": "High-performance graph representation learning library for biological networks",
      "detailed_description": "A Rust/Python library optimized for graph representation learning, specifically designed to handle large-scale biological networks for predictions and evaluations.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_representation_learning",
        "link_prediction",
        "node_classification"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/AnacletoLAB/grape",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-neural-networks",
        "bioinformatics",
        "rust",
        "graph-embedding"
      ],
      "id": 2
    },
    {
      "name": "BioELMo",
      "one_line_profile": "Biomedical version of ELMo embeddings pre-trained on PubMed",
      "detailed_description": "A biomedical language model providing contextualized word embeddings, pre-trained on 10 million PubMed abstracts to improve performance on biomedical NLP tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "biomedical_text_embedding",
        "named_entity_recognition"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/Andy-jqa/bioelmo",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "biomedical",
        "elmo",
        "embeddings"
      ],
      "id": 3
    },
    {
      "name": "Evo2",
      "one_line_profile": "Foundation model for genome modeling and design across domains",
      "detailed_description": "A genomic foundation model capable of modeling and design tasks across all domains of life, enabling zero-shot function prediction and generation of DNA sequences.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "genome_modeling",
        "sequence_generation",
        "variant_effect_prediction"
      ],
      "application_level": "model",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ArcInstitute/evo2",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "genomics",
        "foundation-model",
        "dna",
        "evolution"
      ],
      "id": 4
    },
    {
      "name": "TMbed",
      "one_line_profile": "Transmembrane protein prediction using Language Model embeddings",
      "detailed_description": "A tool for predicting transmembrane proteins and their features using embeddings from protein language models, offering high accuracy and speed.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_embedding",
        "transmembrane_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/BernhoferM/TMbed",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "protein-language-model",
        "transmembrane",
        "embeddings"
      ],
      "id": 5
    },
    {
      "name": "MMELON",
      "one_line_profile": "Multi-view Molecular Embedding with Late Fusion",
      "detailed_description": "An architecture that combines molecular representations from image, graph, and text views to learn a joint embedding for downstream chemical and biological property prediction.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "molecular_embedding",
        "property_prediction"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/BiomedSciAI/biomed-multi-view",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multi-modal",
        "molecular-graph",
        "chemical-structure"
      ],
      "id": 6
    },
    {
      "name": "PST",
      "one_line_profile": "Protein Structure Transformer for endowing PLMs with structural knowledge",
      "detailed_description": "A model that integrates structural knowledge into pre-trained protein language models to improve representation learning for protein tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_representation_learning",
        "structure_encoding"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/BorgwardtLab/PST",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "protein-structure",
        "transformer",
        "embeddings"
      ],
      "id": 7
    },
    {
      "name": "PCMol",
      "one_line_profile": "Multi-target de novo molecular generator conditioned on protein embeddings",
      "detailed_description": "A deep learning model for de novo drug design that generates molecules conditioned on AlphaFold's latent protein embeddings to target specific protein structures.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "de_novo_drug_design",
        "molecular_generation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/CDDLeiden/PCMol",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "drug-discovery",
        "generative-model",
        "alphafold"
      ],
      "id": 8
    },
    {
      "name": "MULAN",
      "one_line_profile": "Multimodal Protein Language Model for Sequence and Structure Encoding",
      "detailed_description": "A multimodal protein language model that jointly encodes protein sequence and structure information for enhanced representation learning.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_embedding",
        "structure_prediction"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/DFrolova/MULAN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multimodal",
        "protein-language-model",
        "structure-encoding"
      ],
      "id": 9
    },
    {
      "name": "SMILES Transformer",
      "one_line_profile": "Pre-trained SMILES Transformer for molecular fingerprinting",
      "detailed_description": "A transformer-based model pre-trained on SMILES strings to generate molecular fingerprints, useful for low-data drug discovery tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "molecular_fingerprinting",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/DSPsleeporg/smiles-transformer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "smiles",
        "transformer",
        "drug-discovery",
        "fingerprint"
      ],
      "id": 10
    },
    {
      "name": "SiamDiff",
      "one_line_profile": "Pre-training Protein Encoder via Siamese Sequence-Structure Diffusion",
      "detailed_description": "A pre-training framework for protein encoders that utilizes Siamese sequence-structure diffusion trajectory prediction to learn robust protein representations.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_embedding",
        "pre_training"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/DeepGraphLearning/SiamDiff",
      "help_website": [],
      "license": null,
      "tags": [
        "diffusion-model",
        "protein-encoder",
        "self-supervised-learning"
      ],
      "id": 11
    },
    {
      "name": "esm-s",
      "one_line_profile": "Structure-informed protein language model for protein representation learning",
      "detailed_description": "A protein language model that incorporates structural information to improve protein representation learning, useful for downstream tasks in protein engineering and biology.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_language_modeling",
        "structure_prediction"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/DeepGraphLearning/esm-s",
      "help_website": [],
      "license": null,
      "tags": [
        "protein-language-model",
        "structure-informed",
        "representation-learning"
      ],
      "id": 12
    },
    {
      "name": "SpikeNet",
      "one_line_profile": "Dynamic graph representation learning framework using Spiking Neural Networks",
      "detailed_description": "A framework for scaling up dynamic graph representation learning by leveraging Spiking Neural Networks (SNNs), offering energy-efficient processing for temporal graph data.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_representation_learning",
        "dynamic_graph_embedding"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/EdisonLeeeee/SpikeNet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snn",
        "dynamic-graphs",
        "representation-learning"
      ],
      "id": 13
    },
    {
      "name": "InstructPLM",
      "one_line_profile": "Protein language model trained with structure-based instructions",
      "detailed_description": "A large protein language model trained to follow structure instructions, enhancing its ability to generate and analyze proteins with specific structural properties.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_language_modeling",
        "protein_design"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/Eikor/InstructPLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "protein-language-model",
        "instruction-tuning",
        "structural-biology"
      ],
      "id": 14
    },
    {
      "name": "InterPLM",
      "one_line_profile": "Tool for discovering interpretable features in protein language models",
      "detailed_description": "A toolkit utilizing sparse autoencoders to extract and analyze interpretable features from Protein Language Models (PLMs), aiding in the understanding of black-box biological models.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "interpretability",
        "feature_extraction"
      ],
      "application_level": "toolkit",
      "primary_language": "Python",
      "repo_url": "https://github.com/ElanaPearl/InterPLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-language-model",
        "interpretability",
        "sparse-autoencoder"
      ],
      "id": 15
    },
    {
      "name": "eICU-GNN-LSTM",
      "one_line_profile": "Graph representation learning model for predicting patient outcomes in ICU",
      "detailed_description": "A hybrid GNN-LSTM model designed to predict patient outcomes using data from the eICU database, leveraging graph representation learning to model patient states.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "clinical_prediction",
        "graph_representation_learning"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/EmmaRocheteau/eICU-GNN-LSTM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "healthcare",
        "gnn",
        "patient-outcome"
      ],
      "id": 16
    },
    {
      "name": "MAGIC",
      "one_line_profile": "Masked graph representation learning for APT detection",
      "detailed_description": "A security tool that utilizes masked graph representation learning to detect Advanced Persistent Threats (APTs) by modeling system entity interactions.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "anomaly_detection",
        "graph_representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FDUDSDE/MAGIC",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cybersecurity",
        "graph-learning",
        "apt-detection"
      ],
      "id": 17
    },
    {
      "name": "DySAT_pytorch",
      "one_line_profile": "PyTorch implementation of DySAT for dynamic graph representation learning",
      "detailed_description": "An implementation of Deep Neural Representation Learning on Dynamic Graphs via Self-Attention Networks (DySAT), enabling embedding learning on temporal graph data.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "dynamic_graph_embedding",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/FeiGSSS/DySAT_pytorch",
      "help_website": [],
      "license": null,
      "tags": [
        "dynamic-graph",
        "self-attention",
        "pytorch"
      ],
      "id": 18
    },
    {
      "name": "GTR",
      "one_line_profile": "Graph representation learning for complex table retrieval",
      "detailed_description": "A model for retrieving complex tables using multi-granular graph representation learning, useful for structured data information retrieval.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "information_retrieval",
        "graph_representation_learning"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/FeiWang96/GTR",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "table-retrieval",
        "gnn",
        "sigir"
      ],
      "id": 19
    },
    {
      "name": "TinyDNABERT",
      "one_line_profile": "Lightweight genomic language model for DNA sequence analysis",
      "detailed_description": "A compact genomic language model based on RoBERTa architecture and BPE tokenization, designed for efficient DNA sequence embedding and analysis.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "genomic_language_modeling",
        "sequence_embedding"
      ],
      "application_level": "model",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ForestsKing/TinyDNABERT",
      "help_website": [],
      "license": null,
      "tags": [
        "dna",
        "bert",
        "genomics"
      ],
      "id": 20
    },
    {
      "name": "MatDeepLearn",
      "one_line_profile": "Graph neural networks package for materials chemistry",
      "detailed_description": "A Python package designed for applying graph neural networks to materials chemistry tasks, facilitating property prediction and materials discovery.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "materials_property_prediction",
        "graph_neural_networks"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Fung-Lab/MatDeepLearn",
      "help_website": [],
      "license": null,
      "tags": [
        "materials-science",
        "gnn",
        "chemistry"
      ],
      "id": 21
    },
    {
      "name": "wxECGAnalyzer",
      "one_line_profile": "ECG signal analysis and algorithm validation tool",
      "detailed_description": "A tool for designing and validating Electrocardiogram (ECG) signal algorithms, including preprocessing, QRS detection, and segmentation.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "signal_processing",
        "biomedical_analysis"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/GCY/wxECGAnalyzer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ecg",
        "signal-processing",
        "medical"
      ],
      "id": 22
    },
    {
      "name": "REGAL",
      "one_line_profile": "Representation learning-based graph alignment tool",
      "detailed_description": "A framework for graph alignment using representation learning based on implicit matrix factorization and structural embeddings.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_alignment",
        "network_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GemsLab/REGAL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-alignment",
        "matrix-factorization",
        "embedding"
      ],
      "id": 23
    },
    {
      "name": "QSoME",
      "one_line_profile": "Quantum Solid and Molecular Embedding library",
      "detailed_description": "A Python library for Quantum Solid and Molecular Embedding, facilitating quantum chemical calculations and simulations.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "quantum_chemistry",
        "molecular_embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Goodpaster/QSoME",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantum-chemistry",
        "embedding",
        "molecular-simulation"
      ],
      "id": 24
    },
    {
      "name": "BioBERTpt",
      "one_line_profile": "Biomedical and Clinical BERT model for Portuguese",
      "detailed_description": "A pre-trained BERT model adapted for biomedical and clinical text in the Portuguese language, enabling NLP tasks in this specific domain.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "biomedical_nlp",
        "language_modeling"
      ],
      "application_level": "model",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/HAILab-PUCPR/BioBERTpt",
      "help_website": [],
      "license": null,
      "tags": [
        "bert",
        "biomedical-nlp",
        "portuguese"
      ],
      "id": 25
    },
    {
      "name": "WSI-HGNN",
      "one_line_profile": "Heterogeneous graph learning for whole slide image analysis",
      "detailed_description": "A heterogeneous graph neural network framework for analyzing histopathology whole slide images (WSI), capturing complex tissue structures.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "medical_imaging",
        "graph_representation_learning"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKU-MedAI/WSI-HGNN",
      "help_website": [],
      "license": null,
      "tags": [
        "histopathology",
        "wsi",
        "hgnn"
      ],
      "id": 26
    },
    {
      "name": "SELFormer",
      "one_line_profile": "Molecular representation learning using SELFIES language models",
      "detailed_description": "A chemical language model leveraging SELFIES strings for molecular representation learning, suitable for various cheminformatics tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "molecular_representation",
        "chemical_language_model"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/HUBioDataLab/SELFormer",
      "help_website": [],
      "license": null,
      "tags": [
        "selfies",
        "transformer",
        "cheminformatics"
      ],
      "id": 27
    },
    {
      "name": "scELMo",
      "one_line_profile": "Language model embeddings for single-cell data analysis",
      "detailed_description": "A method applying embeddings from language models (ELMo) to single-cell data, facilitating analysis and learning from scRNA-seq data.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "single_cell_analysis",
        "embedding"
      ],
      "application_level": "model",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/HelloWorldLTY/scELMo",
      "help_website": [],
      "license": null,
      "tags": [
        "single-cell",
        "elmo",
        "scrna-seq"
      ],
      "id": 28
    },
    {
      "name": "Ligand_Generation",
      "one_line_profile": "Target-aware ligand generation using multimodal protein representation",
      "detailed_description": "A framework using target-aware Variational Auto-encoders (VAEs) and multimodal protein representation learning for generating novel ligands.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "drug_discovery",
        "ligand_generation"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/HySonLab/Ligand_Generation",
      "help_website": [],
      "license": null,
      "tags": [
        "drug-design",
        "vae",
        "multimodal"
      ],
      "id": 29
    },
    {
      "name": "otter-knowledge",
      "one_line_profile": "Knowledge-enhanced representation learning for drug target binding",
      "detailed_description": "A library that enriches protein and drug representations with knowledge graphs to improve drug-target binding affinity predictions.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "drug_target_interaction",
        "knowledge_graph_embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IBM/otter-knowledge",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "drug-discovery",
        "binding-affinity"
      ],
      "id": 30
    },
    {
      "name": "ProtFlash",
      "one_line_profile": "Lightweight protein language model",
      "detailed_description": "A lightweight and efficient protein language model designed for protein sequence analysis and representation learning.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_language_modeling",
        "sequence_analysis"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/ISYSLAB-HUST/ProtFlash",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-language-model",
        "efficient-learning",
        "bioinformatics"
      ],
      "id": 31
    },
    {
      "name": "scDEED",
      "one_line_profile": "Statistical method for detecting dubious single-cell embeddings",
      "detailed_description": "A statistical tool (scDED) for evaluating the quality of non-linear embeddings in single-cell data analysis by detecting dubious representations.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "single_cell_qc",
        "embedding_evaluation"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/JSB-UCLA/scDEED",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "single-cell",
        "embedding-quality",
        "r"
      ],
      "id": 32
    },
    {
      "name": "agatha",
      "one_line_profile": "Transformer-based hypothesis generation from graphs",
      "detailed_description": "An automatic graph-mining and Transformer-based approach for generating scientific hypotheses from large-scale literature-derived graphs.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "hypothesis_generation",
        "graph_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JSybrandt/agatha",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "hypothesis-generation",
        "transformer",
        "graph-mining"
      ],
      "id": 33
    },
    {
      "name": "CLAPE-SMB",
      "one_line_profile": "Contrastive learning for protein-small molecule binding prediction",
      "detailed_description": "A framework utilizing contrastive learning and pre-trained encoders to predict binding sites between proteins and small molecules.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "binding_site_prediction",
        "contrastive_learning"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/JueWangTHU/CLAPE-SMB",
      "help_website": [],
      "license": null,
      "tags": [
        "drug-discovery",
        "binding-sites",
        "contrastive-learning"
      ],
      "id": 34
    },
    {
      "name": "Facial-Graph-Representation-Learning",
      "one_line_profile": "Graph representation learning for micro-expression recognition",
      "detailed_description": "A PyTorch implementation for recognizing micro-expressions using facial graph representation learning and action unit fusion.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "computer_vision",
        "graph_representation_learning"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/Justin900429/Facial-Graph-Representation-Learning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "micro-expression",
        "gnn",
        "facial-analysis"
      ],
      "id": 35
    },
    {
      "name": "Neural-Temporal-Walks",
      "one_line_profile": "Motif-aware representation learning on continuous-time dynamic graphs",
      "detailed_description": "A PyTorch implementation of Neural Temporal Walks for learning representations on continuous-time dynamic graphs, incorporating motif awareness.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "dynamic_graph_embedding",
        "temporal_networks"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/KimMeen/Neural-Temporal-Walks",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dynamic-graph",
        "temporal-walks",
        "representation-learning"
      ],
      "id": 36
    },
    {
      "name": "DECIMER-Image_Transformer",
      "one_line_profile": "Transformer for chemical structure image to SMILES conversion",
      "detailed_description": "A deep learning tool that uses transformer architectures to convert images of chemical structures into SMILES strings, enabling digitization of chemical literature.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "optical_chemical_structure_recognition",
        "image_to_text"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Kohulan/DECIMER-Image_Transformer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cheminformatics",
        "ocr",
        "smiles"
      ],
      "id": 37
    },
    {
      "name": "PHATE",
      "one_line_profile": "Visualizing high dimensional biological data via potential of heat-diffusion",
      "detailed_description": "A dimensionality reduction and visualization tool designed to preserve both local and global structures in high-dimensional biological data using heat-diffusion potentials.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "dimensionality_reduction",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KrishnaswamyLab/PHATE",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "visualization",
        "dimensionality-reduction",
        "bioinformatics"
      ],
      "id": 38
    },
    {
      "name": "Compound_Protein_Interac_Pred",
      "one_line_profile": "Enzyme activity prediction using substrate encodings",
      "detailed_description": "A tool for predicting enzyme activity on novel substrates using improved substrate encodings and convolutional pooling techniques.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "enzyme_activity_prediction",
        "biochemical_modeling"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/LMSE/Compound_Protein_Interac_Pred",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "enzyme-activity",
        "deep-learning",
        "biochemistry"
      ],
      "id": 39
    },
    {
      "name": "scGraph2Vec",
      "one_line_profile": "Deep generative model for gene embedding in single-cell data",
      "detailed_description": "A deep generative model that learns gene embeddings from single-cell omics data (scRNA-seq or scATAC-seq) using a variational graph autoencoder.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "single_cell_embedding",
        "gene_embedding"
      ],
      "application_level": "model",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/LPH-BIG/scGraph2Vec",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "single-cell",
        "graph2vec",
        "gene-embedding"
      ],
      "id": 40
    },
    {
      "name": "TransE-Knowledge-Graph-Embedding",
      "one_line_profile": "TensorFlow implementation of TransE for knowledge graph embedding",
      "detailed_description": "A TensorFlow implementation of the TransE algorithm and its extensions for learning low-dimensional representations of entities and relationships in knowledge graphs.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lapis-Hong/TransE-Knowledge-Graph-Embedding",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "transe",
        "embedding"
      ],
      "id": 41
    },
    {
      "name": "RE-GCN",
      "one_line_profile": "Evolutional representation learning for temporal knowledge graph reasoning",
      "detailed_description": "A recurrent evolution network based on GCN (RE-GCN) for reasoning on temporal knowledge graphs by modeling the evolution of entity and relation representations.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "temporal_knowledge_graph",
        "reasoning"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lee-zix/RE-GCN",
      "help_website": [],
      "license": null,
      "tags": [
        "temporal-kg",
        "gcn",
        "reasoning"
      ],
      "id": 42
    },
    {
      "name": "XAMP",
      "one_line_profile": "Dual-engine framework for antimicrobial peptide discovery",
      "detailed_description": "A framework combining ESM-2 and Transformer models to discover antimicrobial peptides, specifically applied to deciphering the deep-sea antimicrobial peptidome.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "peptide_discovery",
        "protein_language_modeling"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Li-Lab-SJTU/XAMP",
      "help_website": [],
      "license": null,
      "tags": [
        "antimicrobial-peptides",
        "esm-2",
        "deep-sea"
      ],
      "id": 43
    },
    {
      "name": "LD-Net",
      "one_line_profile": "Efficient contextualized representation for sequence labeling",
      "detailed_description": "A framework for efficient contextualized representation learning through language model pruning, optimized for sequence labeling tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "sequence_labeling",
        "model_compression"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/LiyuanLucasLiu/LD-Net",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "sequence-labeling",
        "efficiency"
      ],
      "id": 44
    },
    {
      "name": "LucaVirus",
      "one_line_profile": "Unified genome-protein language model for virus analysis",
      "detailed_description": "A unified language model for modeling the evolutionary and functional landscape of viruses by integrating genomic and protein data.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "viral_genomics",
        "language_modeling"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/LucaOne/LucaVirus",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "virology",
        "genomics",
        "language-model"
      ],
      "id": 45
    },
    {
      "name": "DNABERT-2",
      "one_line_profile": "Efficient foundation model for multi-species genome embedding and analysis",
      "detailed_description": "A foundation model for genomics that replaces tokenization with BPE and uses Flash Attention to handle long DNA sequences efficiently. It provides pre-trained embeddings for various genomic tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "genomic_embedding",
        "sequence_classification",
        "variant_effect_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/MAGICS-LAB/DNABERT_2",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "genomics",
        "foundation-model",
        "dna-embedding",
        "transformers"
      ],
      "id": 46
    },
    {
      "name": "DNABERT-S",
      "one_line_profile": "Species-aware DNA embedding model using contrastive learning",
      "detailed_description": "A genome foundation model designed to generate discriminative DNA embeddings that capture species-specific information, useful for metagenomics and species identification tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "genomic_embedding",
        "species_identification",
        "metagenomics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MAGICS-LAB/DNABERT_S",
      "help_website": [],
      "license": null,
      "tags": [
        "dna-embedding",
        "contrastive-learning",
        "metagenomics"
      ],
      "id": 47
    },
    {
      "name": "CodonFM",
      "one_line_profile": "Codon-resolution protein language model for diverse species",
      "detailed_description": "A family of language models trained on 130 million protein-coding sequences across over 20,000 species, operating at codon resolution to capture biological information.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_language_model",
        "sequence_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA-Digital-Bio/CodonFM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "protein-language-model",
        "codon",
        "nvidia-bio"
      ],
      "id": 48
    },
    {
      "name": "biobert_embedding",
      "one_line_profile": "Toolkit for extracting embeddings from BioBERT models",
      "detailed_description": "A Python library designed to simplify the extraction of token and sentence-level embeddings from pre-trained BioBERT models for biomedical NLP tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "text_embedding",
        "biomedical_nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Overfitter/biobert_embedding",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "biobert",
        "embeddings",
        "nlp"
      ],
      "id": 49
    },
    {
      "name": "ProLLaMA",
      "one_line_profile": "Protein Large Language Model for multi-task processing",
      "detailed_description": "A Large Language Model specifically adapted for protein sequences, capable of handling multiple protein language processing tasks including generation and property prediction.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_language_model",
        "protein_design",
        "property_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PKU-YuanGroup/ProLLaMA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "protein-llm",
        "llama",
        "protein-engineering"
      ],
      "id": 50
    },
    {
      "name": "Snekmer",
      "one_line_profile": "Kmer-based protein sequence analysis pipeline",
      "detailed_description": "A pipeline tool for applying encoded Kmer analysis to protein sequences, useful for motif discovery and sequence classification, developed by PNNL.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "sequence_analysis",
        "kmer_counting",
        "feature_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PNNL-CompBio/Snekmer",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "kmer",
        "protein-analysis",
        "pnnl"
      ],
      "id": 51
    },
    {
      "name": "PaccMann Proteomics",
      "one_line_profile": "Protein language modeling tools for drug discovery",
      "detailed_description": "Part of the PaccMann framework, this repository provides models and tools for protein language modeling, specifically geared towards drug discovery and proteomics applications.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_language_model",
        "drug_discovery",
        "proteomics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PaccMann/paccmann_proteomics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "drug-discovery",
        "protein-modeling",
        "paccmann"
      ],
      "id": 52
    },
    {
      "name": "scTAG",
      "one_line_profile": "ZINB-based graph embedding autoencoder for scRNA-seq",
      "detailed_description": "A deep learning tool that combines Zero-Inflated Negative Binomial (ZINB) models with graph embedding autoencoders for interpreting single-cell RNA-seq data.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "single_cell_embedding",
        "dimensionality_reduction",
        "scrna-seq"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Philyzh8/scTAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "single-cell",
        "autoencoder",
        "graph-embedding"
      ],
      "id": 53
    },
    {
      "name": "Profluent-E1",
      "one_line_profile": "Protein encoder models for representation learning",
      "detailed_description": "A family of protein encoder models developed by Profluent, designed to generate high-quality representations of protein sequences for downstream prediction tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_embedding",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Profluent-AI/E1",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "protein-encoder",
        "profluent",
        "foundation-model"
      ],
      "id": 54
    },
    {
      "name": "proseLM",
      "one_line_profile": "Structure-conditioned protein language model",
      "detailed_description": "A protein language model adapted for structure-conditioned design, allowing for the generation of protein sequences that fold into specific structures.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_design",
        "structure_prediction",
        "conditional_generation"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/Profluent-AI/proseLM-public",
      "help_website": [],
      "license": null,
      "tags": [
        "protein-design",
        "structure-conditioned",
        "profluent"
      ],
      "id": 55
    },
    {
      "name": "SeqDance",
      "one_line_profile": "Biophysics-informed protein language models for sequence analysis",
      "detailed_description": "SeqDance and ESMDance are biophysics-informed protein language models designed to capture evolutionary and structural information from protein sequences for downstream prediction tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_language_model",
        "sequence_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ShenLab/SeqDance",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "protein-language-model",
        "biophysics",
        "embedding"
      ],
      "id": 56
    },
    {
      "name": "Content-Aware-Node2Vec",
      "one_line_profile": "Embedding method for biomedical ontologies combining structure and text",
      "detailed_description": "A tool for embedding biomedical ontologies by jointly encoding network structure and textual node descriptors, useful for biomedical knowledge graph analysis.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_embedding",
        "ontology_alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SotirisKot/Content-Aware-Node2Vec",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "biomedical-ontology",
        "node2vec",
        "graph-embedding"
      ],
      "id": 57
    },
    {
      "name": "pykg2vec",
      "one_line_profile": "Comprehensive Python library for knowledge graph embedding",
      "detailed_description": "A Python library for knowledge graph embedding and representation learning, providing implementations of state-of-the-art algorithms for research and application in scientific knowledge graphs.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "link_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Sujit-O/pykg2vec",
      "help_website": [
        "https://pykg2vec.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "embedding",
        "representation-learning"
      ],
      "id": 58
    },
    {
      "name": "iFeature",
      "one_line_profile": "Toolkit for generating numerical feature representations from protein sequences",
      "detailed_description": "A comprehensive Python-based toolkit for generating various numerical feature representation schemes from protein or peptide sequences, including feature clustering, selection, and dimensionality reduction.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "feature_extraction",
        "sequence_encoding"
      ],
      "application_level": "toolkit",
      "primary_language": "Python",
      "repo_url": "https://github.com/Superzchen/iFeature",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "protein-sequence",
        "feature-engineering",
        "bioinformatics"
      ],
      "id": 59
    },
    {
      "name": "MCNS",
      "one_line_profile": "Graph representation learning with advanced negative sampling",
      "detailed_description": "Implementation of 'Understanding Negative Sampling in Graph Representation Learning', providing a solver for training graph embeddings with improved negative sampling strategies.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_embedding",
        "negative_sampling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/THUDM/MCNS",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "graph-representation-learning",
        "network-embedding"
      ],
      "id": 60
    },
    {
      "name": "ProteinLM",
      "one_line_profile": "Pre-trained protein language models for sequence representation",
      "detailed_description": "A repository for Protein Language Models developed by THUDM, enabling the generation of embeddings for protein sequences to support downstream bioinformatics tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_language_model",
        "sequence_embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/THUDM/ProteinLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "protein-language-model",
        "deep-learning",
        "bioinformatics"
      ],
      "id": 61
    },
    {
      "name": "SGGRL",
      "one_line_profile": "Multi-modal representation learning for molecular property prediction",
      "detailed_description": "Implementation of a multi-modal representation learning framework combining sequence, graph, and geometry information for accurate molecular property prediction.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "molecular_representation_learning",
        "property_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Vencent-Won/SGGRL",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "molecular-graph",
        "multi-modal",
        "drug-discovery"
      ],
      "id": 62
    },
    {
      "name": "OpenBioSeq",
      "one_line_profile": "Toolkit for bio-sequence representation learning",
      "detailed_description": "A repository focusing on supervised and self-supervised biological sequence representation learning, providing models and tools for analyzing DNA/protein sequences.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "sequence_embedding",
        "representation_learning"
      ],
      "application_level": "toolkit",
      "primary_language": "Python",
      "repo_url": "https://github.com/Westlake-AI/OpenBioSeq",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bio-sequence",
        "self-supervised-learning",
        "genomics"
      ],
      "id": 63
    },
    {
      "name": "seq2seq-fingerprint",
      "one_line_profile": "Unsupervised deep molecular embedding for drug discovery",
      "detailed_description": "Implementation of 'Seq2seq Fingerprint', an unsupervised deep learning method to generate molecular embeddings (fingerprints) for drug discovery applications.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "molecular_embedding",
        "fingerprint_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/XericZephyr/seq2seq-fingerprint",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "drug-discovery",
        "molecular-fingerprint",
        "seq2seq"
      ],
      "id": 64
    },
    {
      "name": "TAPE",
      "one_line_profile": "LLM-to-LM interpreter for text-attributed graph representation learning",
      "detailed_description": "A framework harnessing explanations from Large Language Models (LLMs) to enhance text-attributed graph representation learning, useful for knowledge graphs and scientific networks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_representation_learning",
        "llm_integration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/XiaoxinHe/TAPE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-neural-networks",
        "llm",
        "text-attributed-graph"
      ],
      "id": 65
    },
    {
      "name": "DeepGS",
      "one_line_profile": "Deep representation learning for drug-target binding affinity",
      "detailed_description": "A deep learning tool combining graph and sequence representations to predict drug-target binding affinity.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "binding_affinity_prediction",
        "molecular_interaction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/XuanLin1991/DeepGS",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "drug-target",
        "binding-affinity",
        "deep-learning"
      ],
      "id": 66
    },
    {
      "name": "CLAPE",
      "one_line_profile": "Contrastive learning for protein-ligand binding site prediction",
      "detailed_description": "A tool utilizing contrastive learning and pre-trained encoders to predict protein-ligand binding sites.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "binding_site_prediction",
        "contrastive_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/YAndrewL/CLAPE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-ligand",
        "binding-site",
        "contrastive-learning"
      ],
      "id": 67
    },
    {
      "name": "SigmaCCS",
      "one_line_profile": "Collision cross section prediction using Graph Neural Networks",
      "detailed_description": "A deep learning tool for highly accurate and large-scale collision cross section (CCS) prediction to aid in compound identification in mass spectrometry.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "property_prediction",
        "mass_spectrometry"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/YoujiaZhang/SigmaCCS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "collision-cross-section",
        "gnn",
        "metabolomics"
      ],
      "id": 68
    },
    {
      "name": "SmileCode",
      "one_line_profile": "Deformable image registration via Motion Decomposition Transformer",
      "detailed_description": "Implementation of ModeT for deformable medical image registration, utilizing transformers to decompose motion fields.",
      "domains": [
        "AI4S",
        "Medical_Imaging"
      ],
      "subtask_category": [
        "image_registration",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ZAX130/SmileCode",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "medical-imaging",
        "image-registration",
        "transformer"
      ],
      "id": 69
    },
    {
      "name": "STC-GS",
      "one_line_profile": "Radar sequence prediction for weather nowcasting",
      "detailed_description": "A deep learning model for high-dynamic radar sequence prediction in weather nowcasting using Spatiotemporal Coherent Gaussian Representation.",
      "domains": [
        "AI4S",
        "Earth_Science"
      ],
      "subtask_category": [
        "weather_forecasting",
        "spatiotemporal_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Ziyeeee/STC-GS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "weather-nowcasting",
        "radar-prediction",
        "spatiotemporal"
      ],
      "id": 70
    },
    {
      "name": "Explainable-Automated-Medical-Coding",
      "one_line_profile": "Explainable automated coding of clinical notes",
      "detailed_description": "Implementation of Hierarchical Label-wise Attention Networks (HLAN) for automated and explainable medical coding from clinical text.",
      "domains": [
        "AI4S",
        "Healthcare_Informatics"
      ],
      "subtask_category": [
        "medical_coding",
        "clinical_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/acadTags/Explainable-Automated-Medical-Coding",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "medical-coding",
        "nlp",
        "explainable-ai"
      ],
      "id": 71
    },
    {
      "name": "Ankh",
      "one_line_profile": "Optimized protein language model for biological tasks",
      "detailed_description": "Ankh is an optimized protein language model designed to learn efficient representations of protein sequences for various downstream biological prediction tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_language_model",
        "sequence_embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/agemagician/Ankh",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "protein-language-model",
        "transformers",
        "bioinformatics"
      ],
      "id": 72
    },
    {
      "name": "ProtTrans",
      "one_line_profile": "State-of-the-art pre-trained language models for proteins",
      "detailed_description": "ProtTrans provides a collection of state-of-the-art pre-trained language models (ProtBert, ProtT5, etc.) for generating protein sequence embeddings.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_language_model",
        "sequence_embedding"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/agemagician/ProtTrans",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-language-model",
        "protbert",
        "prott5"
      ],
      "id": 73
    },
    {
      "name": "ProSST",
      "one_line_profile": "Hybrid language model for directed protein evolution",
      "detailed_description": "An advanced hybrid language model designed to assist in directed protein evolution by learning protein sequence-structure relationships.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_engineering",
        "directed_evolution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ai4protein/ProSST",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "protein-evolution",
        "language-model",
        "protein-engineering"
      ],
      "id": 74
    },
    {
      "name": "KDDCUP_2020_AutoGraph_1st_Place",
      "one_line_profile": "Winning solution for Automatic Graph Representation Learning",
      "detailed_description": "The 1st place solution for KDD CUP 2020, providing an automated framework for graph representation learning, useful as a baseline or reference implementation.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_representation_learning",
        "automl"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aister2020/KDDCUP_2020_AutoGraph_1st_Place",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "graph-neural-networks",
        "automl",
        "kdd-cup"
      ],
      "id": 75
    },
    {
      "name": "SciBERT",
      "one_line_profile": "A pretrained BERT model specifically for scientific text processing",
      "detailed_description": "A BERT model trained on a large corpus of scientific text (semantics, computer science, biomedical), designed to improve performance on downstream scientific NLP tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "text_embedding",
        "scientific_nlp"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/scibert",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bert",
        "nlp",
        "scientific-text",
        "embedding"
      ],
      "id": 76
    },
    {
      "name": "SPECTER",
      "one_line_profile": "Document-level representation learning using citation-informed transformers",
      "detailed_description": "A model for generating document-level embeddings of scientific papers by leveraging citation information as a supervision signal, enabling effective downstream tasks like recommendation and classification.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "document_embedding",
        "citation_analysis"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/specter",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "embedding",
        "citation",
        "transformer",
        "scientific-papers"
      ],
      "id": 77
    },
    {
      "name": "mini3di",
      "one_line_profile": "Port of Foldseek code for encoding protein structures to 3di sequences",
      "detailed_description": "A NumPy implementation for converting protein tertiary structures into 3di sequences (structure-based sequences), facilitating structure-aware protein analysis and embedding.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "structure_encoding",
        "protein_folding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/althonos/mini3di",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "protein-structure",
        "foldseek",
        "3di",
        "encoding"
      ],
      "id": 78
    },
    {
      "name": "Earthformer",
      "one_line_profile": "Space-time Transformer for earth system forecasting",
      "detailed_description": "A deep learning model (Earthformer) designed for earth system forecasting problems, such as precipitation nowcasting, using a space-time transformer architecture.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "forecasting",
        "earth_science"
      ],
      "application_level": "model",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/amazon-science/earth-forecasting-transformer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "earth-science",
        "transformer",
        "forecasting",
        "spatiotemporal"
      ],
      "id": 79
    },
    {
      "name": "DySAT",
      "one_line_profile": "Dynamic Graph Representation Learning via Self-Attention",
      "detailed_description": "An implementation of DySAT (Dynamic Self-Attention Network), a model for learning node representations in dynamic graphs, applicable to evolving scientific networks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_embedding",
        "dynamic_graphs"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aravindsankar28/DySAT",
      "help_website": [],
      "license": null,
      "tags": [
        "dynamic-graph",
        "representation-learning",
        "self-attention",
        "gnn"
      ],
      "id": 80
    },
    {
      "name": "DGL-LifeSci",
      "one_line_profile": "Graph neural networks package for chemistry and biology",
      "detailed_description": "A DGL-based package for applying graph neural networks to tasks in chemistry and biology, including molecular property prediction and generative models.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "molecular_graph",
        "property_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/awslabs/dgl-lifesci",
      "help_website": [
        "https://lifesci.dgl.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "gnn",
        "chemistry",
        "biology",
        "drug-discovery"
      ],
      "id": 81
    },
    {
      "name": "Context_Aware_SSL",
      "one_line_profile": "Graph-based Self-supervised Representation Learning for Medical Images",
      "detailed_description": "PyTorch implementation of context-aware self-supervised learning for medical image representation, utilizing graph structures to capture relationships.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "medical_imaging",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/batmanlab/Context_Aware_SSL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-imaging",
        "ssl",
        "graph-learning",
        "representation"
      ],
      "id": 82
    },
    {
      "name": "ntEmbd",
      "one_line_profile": "Deep learning embedding for nucleotide sequences",
      "detailed_description": "A tool for generating embeddings for nucleotide sequences using deep learning, developed by the Michael Smith Genome Sciences Centre.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "sequence_embedding",
        "genomics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bcgsc/ntEmbd",
      "help_website": [],
      "license": null,
      "tags": [
        "nucleotide",
        "embedding",
        "genomics",
        "deep-learning"
      ],
      "id": 83
    },
    {
      "name": "MolRep",
      "one_line_profile": "Deep Representation Learning Library for Molecular Property Prediction",
      "detailed_description": "A comprehensive library for molecular representation learning, providing various models and benchmarks for molecular property prediction.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "molecular_representation",
        "property_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/biomed-AI/MolRep",
      "help_website": [],
      "license": null,
      "tags": [
        "molecular-embedding",
        "drug-discovery",
        "representation-learning"
      ],
      "id": 84
    },
    {
      "name": "SPROF-GO",
      "one_line_profile": "Protein function prediction using pretrained language models",
      "detailed_description": "A tool for predicting protein functions (GO terms) from sequences using pretrained protein language models and homology-based label diffusion.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "function_prediction",
        "protein_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/biomed-AI/SPROF-GO",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-function",
        "go-prediction",
        "language-model"
      ],
      "id": 85
    },
    {
      "name": "pytorch-graphsage",
      "one_line_profile": "PyTorch implementation of GraphSAGE for graph representation learning",
      "detailed_description": "A widely used PyTorch implementation of GraphSAGE, a framework for inductive representation learning on large graphs, applicable to scientific networks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_embedding",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bkj/pytorch-graphsage",
      "help_website": [],
      "license": null,
      "tags": [
        "graphsage",
        "gnn",
        "embedding",
        "pytorch"
      ],
      "id": 86
    },
    {
      "name": "efficient-evolution",
      "one_line_profile": "Efficient evolution from protein language models",
      "detailed_description": "Algorithms for efficient directed evolution of proteins using protein language models to guide the search in sequence space.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_evolution",
        "sequence_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/brianhie/efficient-evolution",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-evolution",
        "language-model",
        "directed-evolution"
      ],
      "id": 87
    },
    {
      "name": "Evolocity",
      "one_line_profile": "Evolutionary velocity with protein language models",
      "detailed_description": "A tool for estimating evolutionary velocity of proteins using language models, enabling analysis of evolutionary trends and dynamics.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "evolutionary_analysis",
        "protein_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/brianhie/evolocity",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evolutionary-velocity",
        "protein-language-model",
        "evolution"
      ],
      "id": 88
    },
    {
      "name": "DPLM",
      "one_line_profile": "Diffusion Protein Language Models",
      "detailed_description": "Implementation of Diffusion Protein Language Models (DPLM) for generative modeling of protein sequences and structures.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_generation",
        "diffusion_model"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/bytedance/dplm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "protein-generation",
        "diffusion",
        "language-model"
      ],
      "id": 89
    },
    {
      "name": "GEMS",
      "one_line_profile": "Protein-Ligand Binding Affinity Prediction with GNN and PLMs",
      "detailed_description": "A framework for predicting protein-ligand binding affinity using Graph Neural Networks and transfer learning from pre-trained Protein Language Models.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "binding_affinity",
        "drug_discovery"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/camlab-ethz/GEMS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "binding-affinity",
        "gnn",
        "protein-language-model",
        "drug-discovery"
      ],
      "id": 90
    },
    {
      "name": "Chainer Chemistry",
      "one_line_profile": "Deep Learning Library for Biology and Chemistry",
      "detailed_description": "A library based on Chainer for deep learning applications in biology and chemistry, specifically focusing on graph convolutional networks for molecules.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "molecular_graph",
        "deep_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chainer/chainer-chemistry",
      "help_website": [
        "https://chainer-chemistry.readthedocs.io/en/latest/"
      ],
      "license": "MIT",
      "tags": [
        "chemistry",
        "biology",
        "gnn",
        "chainer"
      ],
      "id": 91
    },
    {
      "name": "N-Gram Graph",
      "one_line_profile": "Simple Unsupervised Representation for Graphs",
      "detailed_description": "Implementation of N-Gram Graph, a simple and effective unsupervised method for learning graph representations.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_embedding",
        "unsupervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chao1224/n_gram_graph",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-embedding",
        "n-gram",
        "representation-learning"
      ],
      "id": 92
    },
    {
      "name": "METL",
      "one_line_profile": "Framework for pretraining and finetuning biophysics-informed protein language models",
      "detailed_description": "A framework designed for Mutational Effect Transfer Learning (METL) that enables the pretraining and finetuning of protein language models with a focus on biophysical information, aiding in the prediction of mutational effects.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_language_model",
        "mutation_effect_prediction"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/gitter-lab/metl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-engineering",
        "biophysics",
        "transfer-learning"
      ],
      "id": 93
    },
    {
      "name": "S3V2_IDEAS_ESMP",
      "one_line_profile": "Epigenetic data normalization and state calling tool",
      "detailed_description": "A tool implementing S3norm version 2 and IDEAS for epigenetic state modeling and master peak list generation, used in genomics to normalize and analyze epigenetic signals.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "normalization",
        "epigenetic_state_calling"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/guanjue/S3V2_IDEAS_ESMP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "epigenetics",
        "genomics",
        "normalization"
      ],
      "id": 94
    },
    {
      "name": "Specter",
      "one_line_profile": "C++ library for plotting nuclear data analysis",
      "detailed_description": "A C++ library designed for visualizing nuclear data analysis results, utilizing Dear ImGui and ImPlot for rendering.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "visualization",
        "nuclear_physics_analysis"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/gwm17/Specter",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nuclear-physics",
        "plotting",
        "visualization"
      ],
      "id": 95
    },
    {
      "name": "MolGraphEval",
      "one_line_profile": "Benchmark for evaluating self-supervised molecular graph embeddings",
      "detailed_description": "A framework for evaluating self-supervised learning methods applied to molecular graph embeddings, providing benchmarks for representation quality in chemistry tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "model_evaluation",
        "molecular_embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hansen7/MolGraphEval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "molecular-graphs",
        "self-supervised-learning",
        "benchmarking"
      ],
      "id": 96
    },
    {
      "name": "MVGRL",
      "one_line_profile": "Contrastive Multi-View Representation Learning on Graphs implementation",
      "detailed_description": "A DGL-based implementation of Contrastive Multi-View Representation Learning on Graphs (MVGRL), a method for generating node and graph embeddings via contrastive learning.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_embedding",
        "contrastive_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hengruizhang98/mvgrl",
      "help_website": [],
      "license": null,
      "tags": [
        "graph-neural-networks",
        "representation-learning",
        "dgl"
      ],
      "id": 97
    },
    {
      "name": "MolReactGen",
      "one_line_profile": "Auto-regressive model for molecule and reaction template generation",
      "detailed_description": "An auto-regressive causal language model based on GPT-2 for generating molecules (SMILES) and reaction templates (SMARTS), facilitating chemical synthesis planning.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "molecule_generation",
        "reaction_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/hogru/MolReactGen",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "generative-model",
        "chemistry",
        "smiles"
      ],
      "id": 98
    },
    {
      "name": "Transformers",
      "one_line_profile": "State-of-the-art machine learning framework for sequence models",
      "detailed_description": "The de facto standard library for transformer models, widely used in AI for Science for implementing and using protein (ProtBERT), DNA (DNABERT), and chemical (ChemBERTa) language models.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "model_training",
        "inference",
        "embedding_generation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/transformers",
      "help_website": [
        "https://huggingface.co/docs/transformers/index"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "foundation-models",
        "deep-learning"
      ],
      "id": 99
    },
    {
      "name": "ProGen2-finetuning",
      "one_line_profile": "Toolkit for finetuning ProGen2 protein language models",
      "detailed_description": "A set of tools and scripts for finetuning the ProGen2 protein language model to generate protein sequences for specific families or properties.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_design",
        "model_finetuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/hugohrban/ProGen2-finetuning",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "protein-generation",
        "llm",
        "biology"
      ],
      "id": 100
    },
    {
      "name": "SIMBA",
      "one_line_profile": "Single-cell embedding method using features",
      "detailed_description": "SIMBA (SIngle-cell eMBedding Along with features) is a tool for joint embedding of single cells and their features (genes, peaks) into a shared latent space.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "single_cell_embedding",
        "dimensionality_reduction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huidongchen/simba",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "single-cell",
        "genomics",
        "embedding"
      ],
      "id": 101
    },
    {
      "name": "GraphGAN",
      "one_line_profile": "Graph representation learning with Generative Adversarial Nets",
      "detailed_description": "A TensorFlow implementation of GraphGAN, a framework that unifies generative and discriminative methods for graph representation learning.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_embedding",
        "generative_model"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hwwang55/GraphGAN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-embedding",
        "gan",
        "network-analysis"
      ],
      "id": 102
    },
    {
      "name": "TemStaPro",
      "one_line_profile": "Protein thermostability prediction using language model embeddings",
      "detailed_description": "A software tool that predicts protein thermostability by leveraging sequence representations derived from protein language models.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "property_prediction",
        "protein_stability"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ievapudz/TemStaPro",
      "help_website": [
        "https://temstapro.protosthetics.com/"
      ],
      "license": "MIT",
      "tags": [
        "protein-engineering",
        "thermostability",
        "plm"
      ],
      "id": 103
    },
    {
      "name": "GNNs for Quantum Chemistry",
      "one_line_profile": "Graph Neural Networks implementations for Quantum Chemistry",
      "detailed_description": "A collection of Graph Neural Network implementations specifically tailored for quantum chemistry tasks, serving as a library for molecular property prediction.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "molecular_property_prediction",
        "graph_neural_networks"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ifding/graph-neural-networks",
      "help_website": [],
      "license": null,
      "tags": [
        "quantum-chemistry",
        "gnn",
        "molecular-modeling"
      ],
      "id": 104
    },
    {
      "name": "Nucleotide Transformer",
      "one_line_profile": "Foundation models for genomics and transcriptomics",
      "detailed_description": "A suite of large-scale foundation models trained on nucleotide sequences, enabling downstream tasks in genomics and transcriptomics via embeddings.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "genomic_embedding",
        "sequence_modeling"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/instadeepai/nucleotide-transformer",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "genomics",
        "foundation-model",
        "dna"
      ],
      "id": 105
    },
    {
      "name": "DNABERT",
      "one_line_profile": "Pre-trained BERT model for DNA sequences",
      "detailed_description": "A pre-trained Bidirectional Encoder Representations from Transformers (BERT) model specifically designed for DNA sequences to capture genomic features.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "genomic_embedding",
        "sequence_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jerryji1993/DNABERT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "genomics",
        "bert",
        "dna-sequence"
      ],
      "id": 106
    },
    {
      "name": "FamPlex",
      "one_line_profile": "Resource for grounding protein families and complexes",
      "detailed_description": "A namespace and resource for encoding hierarchical relationships between proteins, families, and complexes, widely used for entity resolution and grounding in biomedical text mining.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "entity_normalization",
        "ontology_mapping"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/johnbachman/famplex",
      "help_website": [],
      "license": "CC0-1.0",
      "tags": [
        "bioinformatics",
        "ontology",
        "text-mining"
      ],
      "id": 107
    },
    {
      "name": "ProteinClusterTools",
      "one_line_profile": "Pipeline for clustering protein families using embeddings",
      "detailed_description": "A pipeline designed to explore protein families by generating clusters in sequence space using homology-based or vector representation-based methods.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_clustering",
        "sequence_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/johnchen93/ProteinClusterTools",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-families",
        "clustering",
        "bioinformatics"
      ],
      "id": 108
    },
    {
      "name": "SCALEX",
      "one_line_profile": "Online single-cell data integration tool",
      "detailed_description": "A deep learning tool for online integration of single-cell data by projecting heterogeneous datasets into a common cell-embedding space.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "single_cell_integration",
        "embedding_projection"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/jsxlei/SCALEX",
      "help_website": [
        "https://scalex.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "single-cell",
        "data-integration",
        "deep-learning"
      ],
      "id": 109
    },
    {
      "name": "Retrosynthesis-Prediction",
      "one_line_profile": "Transformer-based retrosynthesis prediction tool",
      "detailed_description": "A tool utilizing Transformer sequence-to-sequence models and SMILES-based data augmentation for predicting retrosynthetic reaction pathways.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "retrosynthesis",
        "reaction_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/kheyer/Retrosynthesis-Prediction",
      "help_website": [],
      "license": null,
      "tags": [
        "chemistry",
        "retrosynthesis",
        "transformer"
      ],
      "id": 110
    },
    {
      "name": "pLM-BLAST",
      "one_line_profile": "Remote homology detection using protein language models",
      "detailed_description": "A tool that detects remote homology between proteins by comparing representations derived from protein language models, serving as an alternative to sequence alignment methods like BLAST.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "homology_search",
        "protein_comparison"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/labstructbioinf/pLM-BLAST",
      "help_website": [
        "https://toolkit.tuebingen.mpg.de/tools/plm-blast"
      ],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "homology-detection",
        "plm"
      ],
      "id": 111
    },
    {
      "name": "PLM-interact",
      "one_line_profile": "Protein language model extension for predicting protein-protein interactions",
      "detailed_description": "A tool that extends protein language models (PLMs) to predict protein-protein interactions (PPI), leveraging pre-trained representations for biological interaction tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_interaction_prediction",
        "embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liudan111/PLM-interact",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-language-model",
        "ppi",
        "bioinformatics"
      ],
      "id": 112
    },
    {
      "name": "LanczosNetwork",
      "one_line_profile": "Graph Neural Network based on Lanczos algorithm for quantum chemistry",
      "detailed_description": "Implementation of Lanczos Network, a deep graph convolutional network designed for learning on graph-structured data, specifically benchmarked on QM8 quantum chemistry datasets.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "molecular_property_prediction",
        "quantum_chemistry"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lrjconan/LanczosNetwork",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gnn",
        "quantum-chemistry",
        "molecular-graph"
      ],
      "id": 113
    },
    {
      "name": "ProGen (Jax)",
      "one_line_profile": "Jax implementation of ProGen for protein sequence generation",
      "detailed_description": "An implementation of ProGen, a controllable protein language model for generating protein sequences with specific properties, written in Jax.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_generation",
        "sequence_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucidrains/progen",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-generation",
        "jax",
        "language-model"
      ],
      "id": 114
    },
    {
      "name": "esmdiff",
      "one_line_profile": "Structure language models for protein conformation generation",
      "detailed_description": "Codebase for generating protein conformations using structure language models, implementing diffusion-based approaches for protein structure tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "structure_prediction",
        "conformation_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lujiarui/esmdiff",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "protein-structure",
        "diffusion-model",
        "generative-model"
      ],
      "id": 115
    },
    {
      "name": "ConFit",
      "one_line_profile": "Contrastive fitness learning for protein fitness landscape prediction",
      "detailed_description": "A tool for reprogramming protein language models using contrastive fitness learning to predict protein fitness landscapes with low-N data.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "fitness_prediction",
        "protein_engineering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/luo-group/ConFit",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "protein-fitness",
        "contrastive-learning",
        "plm"
      ],
      "id": 116
    },
    {
      "name": "SciBERT_CN",
      "one_line_profile": "Pretrained BERT model for Chinese scientific text",
      "detailed_description": "A pre-trained language model specifically designed for processing and embedding Chinese scientific text, enabling downstream scientific NLP tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "scientific_nlp",
        "text_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lvyufeng/SciBERT_CN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "chinese-science",
        "bert"
      ],
      "id": 117
    },
    {
      "name": "biofm-eval",
      "one_line_profile": "Embedding extraction library for BioFM genomics foundation model",
      "detailed_description": "A library designed to extract embeddings for DNA sequences using the BioFM genomics foundation model, facilitating genomic analysis tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "genomics_embedding",
        "dna_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/m42-health/biofm-eval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "genomics",
        "foundation-model",
        "dna-embedding"
      ],
      "id": 118
    },
    {
      "name": "Hyper-SAGNN",
      "one_line_profile": "Self-attention based graph neural network for hypergraphs",
      "detailed_description": "A hypergraph representation learning tool using self-attention graph neural networks, applicable to complex biological networks and systems biology.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_representation_learning",
        "network_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ma-compbio/Hyper-SAGNN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hypergraph",
        "gnn",
        "systems-biology"
      ],
      "id": 119
    },
    {
      "name": "GCP-VQVAE",
      "one_line_profile": "Geometry-complete VQ-VAE for protein 3D structure",
      "detailed_description": "Implementation of GCP-VQVAE, a geometry-complete language model for encoding and decoding protein 3D structures using vector quantization.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "structure_representation",
        "protein_design"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mahdip72/vq_encoder_decoder",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-structure",
        "vq-vae",
        "geometric-deep-learning"
      ],
      "id": 120
    },
    {
      "name": "OChemR",
      "one_line_profile": "Optical chemical structure recognition and reaction interpretation",
      "detailed_description": "A tool that uses Vision Transformers (DETR) to detect and classify molecules, text, and arrows in chemical reaction images, translating them into SMILES or text.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "optical_chemical_structure_recognition",
        "image_to_text"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/markmartorilopez/OChemR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ocsr",
        "chemistry",
        "computer-vision"
      ],
      "id": 121
    },
    {
      "name": "EndoFM-LV",
      "one_line_profile": "Foundation model for endoscopy video analysis",
      "detailed_description": "A foundation model for analyzing endoscopy videos via representation learning on long sequences, improving medical video analysis tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "medical_imaging",
        "video_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/med-air/EndoFM-LV",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "endoscopy",
        "foundation-model",
        "medical-ai"
      ],
      "id": 122
    },
    {
      "name": "TopoDiff",
      "one_line_profile": "Diffusion-based protein backbone generation with global geometry",
      "detailed_description": "A diffusion-based model for generating protein backbones that incorporates global-geometry-aware latent encoding to improve structure quality.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_design",
        "structure_generation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/meneshail/TopoDiff",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "diffusion-model",
        "protein-structure",
        "generative-biology"
      ],
      "id": 123
    },
    {
      "name": "ProstT5",
      "one_line_profile": "Bilingual language model for protein sequence and structure",
      "detailed_description": "A protein language model capable of translating between protein sequences and 3D structures (Foldseek sequences), enabling structure-aware sequence analysis.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_language_model",
        "structure_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mheinzinger/ProstT5",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "plm",
        "t5",
        "protein-structure"
      ],
      "id": 124
    },
    {
      "name": "SeqVec",
      "one_line_profile": "Deep learning embeddings for protein sequences",
      "detailed_description": "A tool for generating continuous vector representations (embeddings) for protein sequences using deep learning (ELMo-based), capturing biophysical properties.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_embedding",
        "sequence_representation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mheinzinger/SeqVec",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-embedding",
        "nlp-for-bio",
        "elmo"
      ],
      "id": 125
    },
    {
      "name": "peft_proteomics",
      "one_line_profile": "LoRA adapters for protein language models",
      "detailed_description": "A toolkit for applying Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA to protein language models, facilitating efficient adaptation to downstream tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "model_finetuning",
        "protein_engineering"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/microsoft/peft_proteomics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lora",
        "peft",
        "protein-language-model"
      ],
      "id": 126
    },
    {
      "name": "apetokenizer",
      "one_line_profile": "Tokenizer for chemical SMILES and SELFIES",
      "detailed_description": "A tokenizer specifically designed for chemical representations like SMILES and SELFIES, enabling their use in Transformer-based models.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "chemical_nlp",
        "tokenization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mikemayuare/apetokenizer",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "smiles",
        "selfies",
        "chemistry"
      ],
      "id": 127
    },
    {
      "name": "OhmNet",
      "one_line_profile": "Representation learning in multi-layer tissue networks",
      "detailed_description": "A tool for learning node representations in multi-layer graphs, specifically designed for modeling tissue-specific protein-protein interaction networks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "network_embedding",
        "systems_biology"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mims-harvard/ohmnet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "network-biology",
        "embedding",
        "multi-layer-graph"
      ],
      "id": 128
    },
    {
      "name": "USPNet",
      "one_line_profile": "Signal peptide predictor with deep protein language model",
      "detailed_description": "An unbiased, organism-agnostic, and highly sensitive signal peptide predictor leveraging deep protein language models for sequence analysis.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "signal_peptide_prediction",
        "sequence_classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ml4bio/USPNet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "signal-peptide",
        "plm",
        "bioinformatics"
      ],
      "id": 129
    },
    {
      "name": "MolecularTransformerEmbeddings",
      "one_line_profile": "Transformer for molecular text representation translation and embedding",
      "detailed_description": "A Transformer neural network trained to translate between different molecular text representations (e.g., SMILES, IUPAC) and generate molecular embeddings.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "molecular_embedding",
        "chemical_translation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mpcrlab/MolecularTransformerEmbeddings",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "molecular-translation",
        "transformer",
        "cheminformatics"
      ],
      "id": 130
    },
    {
      "name": "BioBERT",
      "one_line_profile": "Pre-trained biomedical language representation model",
      "detailed_description": "A pre-trained biomedical language representation model designed for biomedical text mining tasks such as named entity recognition, relation extraction, and question answering.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "biomedical_nlp",
        "text_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/naver/biobert-pretrained",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "biobert",
        "nlp",
        "biomedical-text-mining"
      ],
      "id": 131
    },
    {
      "name": "BLUE Benchmark",
      "one_line_profile": "Biomedical Language Understanding Evaluation benchmark",
      "detailed_description": "A benchmark suite consisting of five different biomedicine text-mining tasks with ten corpora, used to evaluate biomedical language models.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "benchmark",
        "biomedical_nlp"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/ncbi-nlp/BLUE_Benchmark",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "benchmark",
        "nlp",
        "evaluation"
      ],
      "id": 132
    },
    {
      "name": "BioSentVec",
      "one_line_profile": "Pre-trained embeddings for biomedical words and sentences",
      "detailed_description": "A set of pre-trained embeddings (BioWordVec and BioSentVec) for biomedical words and sentences, trained on PubMed and MIMIC-III clinical notes.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "text_embedding",
        "biomedical_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ncbi-nlp/BioSentVec",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "word-embedding",
        "sentence-embedding",
        "pubmed"
      ],
      "id": 133
    },
    {
      "name": "text2brain",
      "one_line_profile": "Generating brain activation maps from free-form text queries",
      "detailed_description": "A deep learning model that synthesizes brain activation maps (e.g., fMRI) from text descriptions, bridging natural language and neuroscience to visualize brain responses to semantic inputs.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "brain_map_generation",
        "cross_modal_synthesis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ngohgia/text2brain",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "neuroscience",
        "fmri",
        "text-to-image",
        "deep-learning"
      ],
      "id": 134
    },
    {
      "name": "CaLM",
      "one_line_profile": "Protein language model trained on coding DNA sequences",
      "detailed_description": "A language model (Codon adaptation Language Model) trained on DNA sequences to learn protein representations, optimized for codon usage bias and expression prediction.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_representation",
        "sequence_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/oxpig/CaLM",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "protein-language-model",
        "dna",
        "codon-usage",
        "bioinformatics"
      ],
      "id": 135
    },
    {
      "name": "esm2quinox",
      "one_line_profile": "ESM2 protein language model implementation in Equinox/JAX",
      "detailed_description": "A JAX/Equinox implementation of the ESM2 protein language model, enabling efficient training and inference on TPUs/GPUs for biological sequence analysis.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_representation",
        "model_implementation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/patrick-kidger/esm2quinox",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jax",
        "equinox",
        "esm2",
        "protein-folding"
      ],
      "id": 136
    },
    {
      "name": "FAPLM",
      "one_line_profile": "Fast and efficient PyTorch implementation of Protein Language Models",
      "detailed_description": "An optimized implementation of protein language models (like ESM) in PyTorch, focusing on training efficiency and drop-in replacement capabilities for bio-NLP tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_representation",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pengzhangzhi/faplm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "protein-language-model",
        "efficiency",
        "nlp-for-bio"
      ],
      "id": 137
    },
    {
      "name": "SIMBA",
      "one_line_profile": "Single-cell embedding method using graph embeddings",
      "detailed_description": "A tool for single-cell embedding that jointly embeds cells and features (genes, peaks) into a shared latent space using graph-based methods to capture cellular heterogeneity.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "single_cell_embedding",
        "dimensionality_reduction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/pinellolab/simba",
      "help_website": [
        "https://simba-bio.readthedocs.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "single-cell",
        "graph-embedding",
        "genomics",
        "bioinformatics"
      ],
      "id": 138
    },
    {
      "name": "Lobster",
      "one_line_profile": "Language model for biological sequence transformation and evolution",
      "detailed_description": "A protein language model designed to learn evolutionary landscapes and predict fitness effects, useful for protein engineering and design tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_design",
        "evolutionary_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/prescient-design/lobster",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "protein-language-model",
        "evolution",
        "protein-engineering"
      ],
      "id": 139
    },
    {
      "name": "cytoself",
      "one_line_profile": "Self-supervised learning for protein localization from images",
      "detailed_description": "A deep learning framework for learning protein localization representations from microscopy images in a self-supervised manner, enabling automated phenotypic analysis.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "image_embedding",
        "protein_localization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/royerlab/cytoself",
      "help_website": [
        "https://cytoself.readthedocs.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "microscopy",
        "self-supervised-learning",
        "cell-biology"
      ],
      "id": 140
    },
    {
      "name": "Specter",
      "one_line_profile": "Linear deconvolution for DIA mass spectrometry proteomics",
      "detailed_description": "A tool for the targeted analysis of data-independent acquisition (DIA) mass spectrometry data using linear deconvolution to quantify proteins from complex mixtures.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "proteomics_quantification",
        "deconvolution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/rpeckner-broad/Specter",
      "help_website": [],
      "license": null,
      "tags": [
        "mass-spectrometry",
        "proteomics",
        "dia",
        "deconvolution"
      ],
      "id": 141
    },
    {
      "name": "AbMap",
      "one_line_profile": "Protein language model customized for antibody representation",
      "detailed_description": "A transfer-learning based protein language model specifically fine-tuned for antibody sequences to predict functional properties and embed antibody space.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "antibody_embedding",
        "property_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/rs239/abmap",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "antibody",
        "immunology",
        "protein-language-model"
      ],
      "id": 142
    },
    {
      "name": "GNSS_IMU",
      "one_line_profile": "Loosely coupled GNSS/IMU sensor fusion implementation",
      "detailed_description": "A Python implementation of GNSS and IMU sensor fusion algorithms for precise navigation and positioning, utilizing Kalman filtering techniques.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "sensor_fusion",
        "navigation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rtklibexplorer/GNSS_IMU",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "gnss",
        "imu",
        "kalman-filter",
        "geodesy"
      ],
      "id": 143
    },
    {
      "name": "RXNMapper",
      "one_line_profile": "Attention-guided atom-mapping for chemical reactions",
      "detailed_description": "A transformer-based model that extracts atom-mapping information from chemical reactions using attention weights, aiding in reaction mechanism understanding and pathway prediction.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "atom_mapping",
        "reaction_informatics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/rxn4chemistry/rxnmapper",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chemistry",
        "transformers",
        "atom-mapping",
        "reaction-prediction"
      ],
      "id": 144
    },
    {
      "name": "ProVis",
      "one_line_profile": "Visualization and interpretation of protein language models",
      "detailed_description": "A tool for interpreting the attention mechanisms of protein language models (like BERT trained on proteins) to understand captured biological features and structural information.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "model_interpretability",
        "protein_structure_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/salesforce/provis",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "bertology",
        "protein-language-model",
        "visualization",
        "explainable-ai"
      ],
      "id": 145
    },
    {
      "name": "Mol2vec",
      "one_line_profile": "Vector representations of molecular substructures",
      "detailed_description": "An unsupervised machine learning approach to learn vector representations of molecular substructures, inspired by Word2Vec, for cheminformatics and drug discovery tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "molecular_embedding",
        "cheminformatics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/samoturk/mol2vec",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "word2vec",
        "molecular-fingerprints",
        "drug-discovery"
      ],
      "id": 146
    },
    {
      "name": "ConPLex",
      "one_line_profile": "Contrastive learning for drug-target interaction prediction",
      "detailed_description": "A model predicting drug-target interactions by aligning protein and molecule representations using contrastive learning and language models to achieve high accuracy.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "dti_prediction",
        "contrastive_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/samsledje/ConPLex",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "drug-target-interaction",
        "protein-language-model",
        "drug-discovery"
      ],
      "id": 147
    },
    {
      "name": "esmologs",
      "one_line_profile": "Local homology search tool integrating ESM-2 embeddings with Foldseek and HMMER",
      "detailed_description": "A tool for performing local homology searches by leveraging the ESM-2 protein language model in conjunction with structural search tools like Foldseek, HHsuite, and HMMER. It facilitates the identification of remote homologs using protein embeddings.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "homology_search",
        "protein_embedding"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/seanrjohnson/esmologs",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-language-model",
        "homology-search",
        "bioinformatics",
        "esm-2"
      ],
      "id": 148
    },
    {
      "name": "BioFLAIR",
      "one_line_profile": "Pretrained contextualized embeddings for biomedical sequence labeling",
      "detailed_description": "A biomedical NLP tool providing pretrained pooled contextualized embeddings specifically designed for biomedical sequence labeling tasks such as Named Entity Recognition (NER) and Part-of-Speech (POS) tagging.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "sequence_labeling",
        "biomedical_embedding"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/shreyashub/BioFLAIR",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "biomedical",
        "embeddings",
        "ner"
      ],
      "id": 149
    },
    {
      "name": "ehr-relation-extraction",
      "one_line_profile": "NER and relation extraction pipeline for Electronic Health Records",
      "detailed_description": "A toolkit for extracting entities and their relations from Electronic Health Records (EHR) using deep learning models. It supports tasks like clinical named entity recognition and relation extraction.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "named_entity_recognition",
        "clinical_nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/smitkiri/ehr-relation-extraction",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ehr",
        "nlp",
        "relation-extraction",
        "healthcare"
      ],
      "id": 150
    },
    {
      "name": "SPECTER",
      "one_line_profile": "High-performance spectral PDE solver for Navier-Stokes equations",
      "detailed_description": "A parallelized PDE solver focused on Navier-Stokes and related equations with arbitrary boundary conditions. It employs Fourier (FC-Gram) expansions and utilizes MPI-OpenMP-CUDA for high-performance fluid dynamics simulations.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "simulation",
        "fluid_dynamics",
        "pde_solver"
      ],
      "application_level": "solver",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/specter-cfd/SPECTER",
      "help_website": [],
      "license": null,
      "tags": [
        "cfd",
        "navier-stokes",
        "spectral-methods",
        "hpc"
      ],
      "id": 151
    },
    {
      "name": "MIL-RBERT",
      "one_line_profile": "Noise reduction model for distantly supervised biomedical relation extraction",
      "detailed_description": "An implementation of a data-driven approach for noise reduction in distantly supervised biomedical relation extraction, utilizing Multi-Instance Learning and BERT (MIL-RBERT).",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "biomedical_nlp",
        "noise_reduction"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/suamin/MIL-RBERT",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "relation-extraction",
        "bert",
        "biomedical",
        "nlp"
      ],
      "id": 152
    },
    {
      "name": "InfoGraph",
      "one_line_profile": "Unsupervised graph-level representation learning via mutual information maximization",
      "detailed_description": "A graph representation learning tool that learns graph-level representations by maximizing the mutual information between graph-level and substructure-level representations. Widely applicable to molecular graph analysis.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_representation_learning",
        "molecular_graph"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sunfanyunn/InfoGraph",
      "help_website": [],
      "license": null,
      "tags": [
        "graph-neural-networks",
        "representation-learning",
        "unsupervised-learning"
      ],
      "id": 153
    },
    {
      "name": "prose",
      "one_line_profile": "Protein sequence embedding models using multi-task and masked language modeling",
      "detailed_description": "A library for generating protein sequence embeddings using models trained with multi-task learning and masked language modeling objectives. Useful for downstream protein structure and function prediction tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_embedding",
        "sequence_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tbepler/prose",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "protein-language-model",
        "embeddings",
        "bioinformatics"
      ],
      "id": 154
    },
    {
      "name": "NetSolP",
      "one_line_profile": "Protein solubility and usability prediction using language models",
      "detailed_description": "A tool that predicts the solubility and usability for purification of proteins expressed in E. coli, leveraging protein language models for feature extraction and prediction.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "property_prediction",
        "protein_solubility",
        "protein_engineering"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/teevee112/NetSolP-1.0",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "protein-solubility",
        "deep-learning",
        "biotechnology"
      ],
      "id": 155
    },
    {
      "name": "grover",
      "one_line_profile": "Self-supervised graph transformer for large-scale molecular representation learning",
      "detailed_description": "A state-of-the-art graph transformer framework for learning molecular representations from large-scale unlabeled molecular data using self-supervised learning tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "molecular_representation_learning",
        "graph_transformer",
        "property_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tencent-ailab/grover",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "molecular-graph",
        "transformer",
        "self-supervised-learning",
        "drug-discovery"
      ],
      "id": 156
    },
    {
      "name": "seq2tens",
      "one_line_profile": "Sequence representation learning via low-rank tensor projections",
      "detailed_description": "A library for efficient sequence representation learning that utilizes low-rank tensor projections to capture long-range dependencies and structural features in sequences.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "sequence_representation",
        "tensor_decomposition"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/tgcsaba/seq2tens",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "representation-learning",
        "tensor",
        "sequence-modeling"
      ],
      "id": 157
    },
    {
      "name": "cpa",
      "one_line_profile": "Compositional Perturbation Autoencoder for single-cell drug response prediction",
      "detailed_description": "A deep generative framework (Compositional Perturbation Autoencoder) designed to learn and predict the effects of perturbations (e.g., drugs) at the single-cell level, enabling out-of-distribution predictions of drug combinations.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "single_cell_analysis",
        "perturbation_prediction",
        "drug_response"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/theislab/cpa",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "single-cell",
        "generative-model",
        "drug-discovery",
        "perturbation"
      ],
      "id": 158
    },
    {
      "name": "JointGT",
      "one_line_profile": "Graph-Text joint representation learning for knowledge graphs",
      "detailed_description": "A framework for learning joint representations of knowledge graphs and text, specifically designed to enhance text generation tasks grounded in knowledge graph data.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "text_generation",
        "representation_learning"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-coai/JointGT",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "nlp",
        "representation-learning"
      ],
      "id": 159
    },
    {
      "name": "DKRL",
      "one_line_profile": "Knowledge graph representation learning with entity descriptions",
      "detailed_description": "A tool for learning representations of knowledge graphs by incorporating entity descriptions, enhancing the embeddings of entities, especially for those with few relational facts.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/thunlp/DKRL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "embedding",
        "nlp"
      ],
      "id": 160
    },
    {
      "name": "TKRL",
      "one_line_profile": "Knowledge graph representation learning with hierarchical types",
      "detailed_description": "A representation learning framework for knowledge graphs that incorporates hierarchical type information of entities to improve embedding quality and reasoning capabilities.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/thunlp/TKRL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "embedding",
        "hierarchical-types"
      ],
      "id": 161
    },
    {
      "name": "graph-representation-learning",
      "one_line_profile": "Collection of graph representation learning models including autoencoders",
      "detailed_description": "A repository implementing various graph representation learning methods, including autoencoders for link prediction and semi-supervised node classification, serving as a reference library for graph embedding techniques.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_embedding",
        "link_prediction",
        "node_classification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vuptran/graph-representation-learning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-neural-networks",
        "embedding",
        "link-prediction"
      ],
      "id": 162
    },
    {
      "name": "WellcomeML",
      "one_line_profile": "Machine learning utility library for biomedical and health research",
      "detailed_description": "A utility library developed by the Wellcome Trust Data Labs to facilitate machine learning tasks in biomedical and health research, including NLP and data processing utilities.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "biomedical_nlp",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wellcometrust/WellcomeML",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "health-data",
        "machine-learning"
      ],
      "id": 163
    },
    {
      "name": "Evolla",
      "one_line_profile": "ProteinChat: Generative protein language model",
      "detailed_description": "Implements ProteinChat, a frontier protein-language generative model designed to decode the molecular language of proteins and facilitate interactive protein analysis.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_language_model",
        "generative_model",
        "protein_design"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/westlake-repl/Evolla",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-language-model",
        "generative-ai",
        "bioinformatics"
      ],
      "id": 164
    },
    {
      "name": "ProTrek",
      "one_line_profile": "Trimodal protein language model for illuminating the protein universe",
      "detailed_description": "A trimodal protein language model that integrates sequence, structure, and text descriptions to learn comprehensive protein representations for various downstream tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_embedding",
        "multimodal_learning",
        "protein_function_prediction"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/westlake-repl/ProTrek",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-language-model",
        "multimodal",
        "bioinformatics"
      ],
      "id": 165
    },
    {
      "name": "SaProt",
      "one_line_profile": "Structure-aware protein language model using Foldseek alphabet",
      "detailed_description": "A protein language model that incorporates structural information using a structural alphabet (AA+3Di) derived from Foldseek, enabling structure-aware protein representation learning.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_embedding",
        "structure_prediction",
        "protein_design"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/westlake-repl/SaProt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-language-model",
        "structural-biology",
        "foldseek"
      ],
      "id": 166
    },
    {
      "name": "SaprotHub",
      "one_line_profile": "Accessible platform for protein language modeling",
      "detailed_description": "A toolkit and platform designed to make protein language modeling accessible to biologists, providing easy-to-use interfaces for training and inference with models like SaProt.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_modeling_platform",
        "model_training",
        "inference"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/westlake-repl/SaprotHub",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-language-model",
        "bioinformatics",
        "user-friendly"
      ],
      "id": 167
    },
    {
      "name": "GraphSAGE",
      "one_line_profile": "Inductive representation learning on large graphs",
      "detailed_description": "A reference implementation of GraphSAGE, a framework for inductive representation learning on large graphs. It generates embeddings by sampling and aggregating features from a node's local neighborhood.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_embedding",
        "inductive_learning",
        "node_classification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/williamleif/GraphSAGE",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "graph-neural-networks",
        "embedding",
        "machine-learning"
      ],
      "id": 168
    },
    {
      "name": "proteinclip",
      "one_line_profile": "Contrastive learning for protein and natural language models",
      "detailed_description": "A model that harmonizes protein language models and natural language models using contrastive learning, enabling cross-modal tasks like text-to-protein retrieval.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "protein_embedding",
        "contrastive_learning",
        "multimodal_learning"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/wukevin/proteinclip",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-language-model",
        "clip",
        "bioinformatics"
      ],
      "id": 169
    },
    {
      "name": "BioNEV",
      "one_line_profile": "Evaluation framework for graph embedding on biomedical networks",
      "detailed_description": "A comprehensive toolkit for evaluating graph embedding methods specifically on biomedical networks. It includes implementations of various embedding algorithms and datasets for tasks like link prediction and node classification in biology.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_embedding",
        "biomedical_network",
        "benchmark"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/xiangyue9607/BioNEV",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-embedding",
        "bioinformatics",
        "network-analysis"
      ],
      "id": 170
    },
    {
      "name": "DKRL",
      "one_line_profile": "Representation learning model for knowledge graphs incorporating entity descriptions",
      "detailed_description": "An implementation of the DKRL (Description-embodied Knowledge Representation Learning) model, which learns representations of knowledge graphs by integrating entity descriptions with structure-based embeddings.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/xrb92/DKRL",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "embedding",
        "entity-description",
        "representation-learning"
      ],
      "id": 171
    },
    {
      "name": "EpiAnno",
      "one_line_profile": "Single-cell epigenomic data annotation via supervised non-linear embedding",
      "detailed_description": "A computational tool for annotating cell types in single-cell epigenomic data (such as scATAC-seq) using a supervised non-linear embedding approach to capture cell-type specific features.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "cell_type_annotation",
        "single_cell_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/xy-chen16/EpiAnno",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "single-cell",
        "epigenomics",
        "annotation",
        "embedding",
        "scatac-seq"
      ],
      "id": 172
    },
    {
      "name": "gLM",
      "one_line_profile": "Genomic language model for predicting protein co-regulation and function",
      "detailed_description": "A genomic language model trained on metagenomic data to learn representations of gene contexts, enabling the prediction of protein co-regulation and functional associations.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "function_prediction",
        "genomic_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/y-hwang/gLM",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "genomics",
        "language-model",
        "protein-function",
        "metagenomics",
        "embedding"
      ],
      "id": 173
    },
    {
      "name": "gmvae",
      "one_line_profile": "Interpretable embeddings from molecular simulations using Gaussian Mixture VAEs",
      "detailed_description": "A tool for generating interpretable low-dimensional embeddings from molecular simulation trajectories using Gaussian Mixture Variational Autoencoders (GMVAE), aiding in the analysis of molecular dynamics.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "molecular_dynamics_analysis",
        "embedding"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/yabozkurt/gmvae",
      "help_website": [],
      "license": null,
      "tags": [
        "molecular-dynamics",
        "vae",
        "embedding",
        "simulation-analysis"
      ],
      "id": 174
    },
    {
      "name": "GREET",
      "one_line_profile": "Unsupervised graph representation learning for edge heterophily discrimination",
      "detailed_description": "A graph representation learning method designed to handle graphs with edge heterophily by discriminating between homophilic and heterophilic edges, applicable to various scientific graph data.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_embedding",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yixinliu233/GREET",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-neural-network",
        "heterophily",
        "embedding",
        "unsupervised-learning"
      ],
      "id": 175
    },
    {
      "name": "gene-embedding-benchmarks",
      "one_line_profile": "Benchmarking suite for gene embeddings on biological tasks",
      "detailed_description": "A repository for benchmarking various gene embedding methods across single, paired, and gene set tasks, providing a framework for evaluating representation quality in bioinformatics.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "benchmarking",
        "gene_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ylaboratory/gene-embedding-benchmarks",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "gene-embedding",
        "benchmark",
        "bioinformatics",
        "evaluation"
      ],
      "id": 176
    },
    {
      "name": "CellSpace",
      "one_line_profile": "Scalable sequence-informed embedding for single-cell ATAC-seq data",
      "detailed_description": "A tool for learning sequence-informed embeddings of single-cell ATAC-seq data, enabling scalable analysis and integration of chromatin accessibility profiles.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "single_cell_embedding",
        "atac_seq_analysis"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/zakieh-tayyebi/CellSpace",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "single-cell",
        "atac-seq",
        "embedding",
        "chromatin-accessibility"
      ],
      "id": 177
    },
    {
      "name": "R-Predictor",
      "one_line_profile": "Pipeline for annotating plant disease resistance genes using protein language models",
      "detailed_description": "A pipeline that utilizes deep protein language models and machine learning to predict and annotate plant disease resistance genes (R-genes) from protein sequences.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "gene_annotation",
        "protein_function_prediction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhouyflab/R-Predictor",
      "help_website": [],
      "license": null,
      "tags": [
        "plant-science",
        "disease-resistance",
        "protein-language-model",
        "annotation"
      ],
      "id": 178
    },
    {
      "name": "NeuralKG",
      "one_line_profile": "Open-source toolkit for knowledge graph representation learning",
      "detailed_description": "A comprehensive Python toolkit for knowledge graph representation learning, supporting various embedding models (TransE, RotatE, etc.) and GNN-based methods for scientific and general knowledge graphs.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjukg/NeuralKG",
      "help_website": [
        "https://zjukg.github.io/NeuralKG/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "toolkit",
        "embedding",
        "gnn"
      ],
      "id": 179
    },
    {
      "name": "Mol-Instructions",
      "one_line_profile": "Large-scale biomolecular instruction dataset for LLMs",
      "detailed_description": "A large-scale dataset of biomolecular instructions designed to tune Large Language Models (LLMs) for tasks in biology and chemistry, facilitating the application of LLMs in scientific discovery.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "instruction_tuning",
        "biomolecular_modeling"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/Mol-Instructions",
      "help_website": [
        "https://huggingface.co/datasets/zjunlp/Mol-Instructions"
      ],
      "license": "MIT",
      "tags": [
        "dataset",
        "llm",
        "biomolecule",
        "instruction-tuning",
        "chemistry"
      ],
      "id": 180
    },
    {
      "name": "GMI",
      "one_line_profile": "Graph representation learning via graphical mutual information maximization",
      "detailed_description": "An implementation of Graphical Mutual Information (GMI) maximization for graph representation learning, providing a method to learn node embeddings by maximizing the mutual information between input and output of a graph encoder.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "graph_embedding",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zpeng27/GMI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-neural-network",
        "mutual-information",
        "embedding",
        "unsupervised-learning"
      ],
      "id": 181
    }
  ]
}