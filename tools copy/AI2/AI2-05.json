{
  "generated_at": "2025-12-16T04:25:41.714856+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "AI2",
      "leaf_cluster_name": "科研表示学习与 embedding 生态",
      "domain": "AI Toolchain",
      "typical_objects": "embeddings/index",
      "task_chain": "表示→索引→检索→探针评测→更新",
      "tool_form": "表示库 + 向量检索 + 评测"
    },
    "unit": {
      "unit_id": "AI2-05",
      "unit_name": "生产化：缓存/更新/监控",
      "target_scale": "100–250",
      "coverage_tools": "embedding pipelines"
    },
    "search": {
      "target_candidates": 250,
      "queries": [
        "[GH] Pathway",
        "[GH] Haystack",
        "[GH] Vectorflow",
        "[GH] WhyLogs",
        "[GH] LangSmith",
        "[GH] Arize Phoenix",
        "[GH] Unstructured",
        "[GH] Towhee",
        "[GH] GPTCache",
        "[GH] semantic cache",
        "[GH] embedding pipeline",
        "[GH] vector etl",
        "[GH] vectorops",
        "[GH] embedding monitoring",
        "[GH] rag observability",
        "[GH] vector database management",
        "[GH] embedding drift detection",
        "[GH] incremental indexing",
        "[GH] llm caching",
        "[GH] unstructured data pipeline",
        "[GH] vector store abstraction",
        "[WEB] semantic cache for embeddings github",
        "[WEB] vector database monitoring tools github",
        "[WEB] unstructured data etl pipeline github",
        "[WEB] rag observability open source github",
        "[WEB] embedding drift detection github"
      ],
      "total_candidates": 1043,
      "tool_candidates": 582,
      "final_tools": 156
    }
  },
  "tools": [
    {
      "name": "M2PT",
      "one_line_profile": "Multimodal Pathway Transformer for improving transformers with irrelevant data from other modalities",
      "detailed_description": "A multimodal learning framework that improves Transformer performance by utilizing irrelevant data from other modalities. It implements a specific pathway mechanism for cross-modal interaction, serving as a solver for representation learning tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "model_optimization",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AILab-CVC/M2PT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "transformer",
        "computer-vision",
        "representation-learning"
      ],
      "id": 1
    },
    {
      "name": "AgentField",
      "one_line_profile": "Kubernetes-native platform for orchestrating AI Agents as microservices",
      "detailed_description": "A platform designed to build, run, and scale AI agents like microservices on Kubernetes. It provides infrastructure for agent identity, scalability, and observability, facilitating the deployment of multi-agent systems in scientific workflows.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "agent_orchestration",
        "infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/Agent-Field/agentfield",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "ai-agents",
        "microservices",
        "orchestration"
      ],
      "id": 2
    },
    {
      "name": "Flash-LLM",
      "one_line_profile": "High-efficiency inference engine for large generative models using unstructured sparsity",
      "detailed_description": "An inference library optimized for large language models (LLMs) that leverages unstructured sparsity to enable cost-effective and high-throughput generation. It addresses computational bottlenecks in model serving.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "model_serving"
      ],
      "application_level": "solver",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/AlibabaResearch/flash-llm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "inference",
        "sparsity",
        "cuda",
        "optimization"
      ],
      "id": 3
    },
    {
      "name": "Datagen",
      "one_line_profile": "Pipeline for converting unstructured data into structured training data via API calls",
      "detailed_description": "A data processing pipeline designed to agnostically convert unstructured data sources into structured formats suitable for training machine learning models, facilitating data alignment and preparation.",
      "domains": [
        "AI2",
        "AI2-03"
      ],
      "subtask_category": [
        "data_processing",
        "data_structuring"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Alignment-Lab-AI/datagen",
      "help_website": [],
      "license": null,
      "tags": [
        "data-pipeline",
        "synthetic-data",
        "training-data"
      ],
      "id": 4
    },
    {
      "name": "Cold Compress",
      "one_line_profile": "Toolkit for creating and benchmarking KV cache compression methods",
      "detailed_description": "A lightweight toolkit built on GPT-Fast for developing, testing, and benchmarking various cache compression techniques to optimize memory usage during LLM inference.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "cache_compression",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AnswerDotAI/cold-compress",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "kv-cache",
        "compression",
        "llm",
        "optimization"
      ],
      "id": 5
    },
    {
      "name": "OpenInference",
      "one_line_profile": "OpenTelemetry instrumentation for AI observability and monitoring",
      "detailed_description": "Provides standard OpenTelemetry instrumentation for AI applications, enabling the capture of traces and metrics from LLMs and vector databases to monitor performance and behavior in production pipelines.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "observability",
        "monitoring"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Arize-ai/openinference",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "opentelemetry",
        "observability",
        "llm",
        "monitoring"
      ],
      "id": 6
    },
    {
      "name": "Phoenix",
      "one_line_profile": "AI observability and evaluation platform for LLM pipelines",
      "detailed_description": "A tool for AI observability and evaluation, offering visualization and analysis of trace data, retrieval metrics, and embedding quality to monitor and improve RAG and LLM applications.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "observability",
        "evaluation",
        "monitoring"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Arize-ai/phoenix",
      "help_website": [
        "https://docs.arize.com/phoenix/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "observability",
        "evaluation",
        "rag",
        "visualization"
      ],
      "id": 7
    },
    {
      "name": "RAGmatic",
      "one_line_profile": "Tool to continuously vectorize PostgreSQL tables for embedding pipelines",
      "detailed_description": "A utility to automate the vectorization of data stored in PostgreSQL tables, facilitating the creation and maintenance of embedding pipelines for retrieval-augmented generation systems.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "embedding_pipeline",
        "data_vectorization"
      ],
      "application_level": "tool",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/BarnacleLabs/RAGmatic",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "postgresql",
        "vectorization",
        "embeddings",
        "rag"
      ],
      "id": 8
    },
    {
      "name": "RWKV-LM",
      "one_line_profile": "RNN-based large language model with Transformer-level performance",
      "detailed_description": "An implementation of the RWKV architecture, which combines the parallelizable training of Transformers with the efficient inference of RNNs (linear time, constant space), serving as a foundational model for representation learning.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "model_architecture",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BlinkDL/RWKV-LM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rnn",
        "llm",
        "transformer",
        "deep-learning"
      ],
      "id": 9
    },
    {
      "name": "RAG-logger",
      "one_line_profile": "Lightweight logging tool specifically for RAG applications",
      "detailed_description": "An open-source logging utility tailored for Retrieval-Augmented Generation (RAG) pipelines, providing visibility into retrieval and generation steps for debugging and monitoring.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "logging",
        "monitoring"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Brandon-c-tech/RAG-logger",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "logging",
        "observability"
      ],
      "id": 10
    },
    {
      "name": "ShadowKV",
      "one_line_profile": "High-throughput long-context LLM inference via KV cache optimization",
      "detailed_description": "A system for optimizing Large Language Model inference, specifically targeting high-throughput and long-context scenarios by managing Key-Value (KV) caches more efficiently.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "cache_optimization",
        "inference_acceleration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ByteDance-Seed/ShadowKV",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kv-cache",
        "llm",
        "inference",
        "optimization"
      ],
      "id": 11
    },
    {
      "name": "Uniflow",
      "one_line_profile": "LLM-based unstructured data extraction, cleaning, and clustering tool",
      "detailed_description": "A library for processing unstructured data (PDFs, HTML, Word) using LLMs. It handles text extraction, cleaning, and clustering to transform raw data into structured formats for downstream analysis.",
      "domains": [
        "AI2",
        "AI2-03"
      ],
      "subtask_category": [
        "data_extraction",
        "data_cleaning",
        "clustering"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "etl",
        "llm",
        "pdf-extraction",
        "data-cleaning"
      ],
      "id": 12
    },
    {
      "name": "Canonical",
      "one_line_profile": "Context-aware semantic cache for conversational AI",
      "detailed_description": "A semantic caching solution designed to optimize conversational AI by caching responses based on semantic similarity and context, reducing latency and computational costs.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "semantic_caching",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Canonical-AI-Inc/canonical",
      "help_website": [],
      "license": null,
      "tags": [
        "semantic-cache",
        "caching",
        "conversational-ai"
      ],
      "id": 13
    },
    {
      "name": "Pyhaystack",
      "one_line_profile": "Python library to connect to Project Haystack servers for building data",
      "detailed_description": "A module enabling Python programs to connect to Project Haystack servers (Niagara, Skyspark, etc.) to retrieve and manipulate semantic data from building automation and IoT systems, useful for energy and building science research.",
      "domains": [
        "AI2",
        "AI2-03"
      ],
      "subtask_category": [
        "data_acquisition",
        "iot_interface"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChristianTremblay/pyhaystack",
      "help_website": [
        "https://pyhaystack.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "project-haystack",
        "iot",
        "building-automation",
        "data-acquisition"
      ],
      "id": 14
    },
    {
      "name": "Clarifai-PySpark",
      "one_line_profile": "Interface for unstructured data and ML pipelines with Databricks and Clarifai",
      "detailed_description": "A connector library that facilitates the integration of Clarifai's computer vision and AI capabilities with PySpark and Databricks workflows, enabling scalable processing of unstructured data.",
      "domains": [
        "AI2",
        "AI2-03"
      ],
      "subtask_category": [
        "data_integration",
        "pipeline_orchestration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Clarifai/clarifai-pyspark",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pyspark",
        "databricks",
        "clarifai",
        "ml-pipeline"
      ],
      "id": 15
    },
    {
      "name": "QAQ",
      "one_line_profile": "Quality Adaptive Quantization for LLM KV Cache",
      "detailed_description": "An implementation of a quality-adaptive quantization strategy for the Key-Value (KV) cache in Large Language Models, aiming to reduce memory footprint while maintaining generation quality.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "cache_quantization",
        "memory_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ClubieDong/QAQ-KVCacheQuantization",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "kv-cache",
        "llm",
        "optimization"
      ],
      "id": 16
    },
    {
      "name": "VectorETL",
      "one_line_profile": "End-to-end ETL pipelines for vector databases",
      "detailed_description": "A tool designed to streamline the Extract, Transform, Load (ETL) process specifically for vector databases, facilitating the ingestion and embedding of data for Generative AI applications.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "etl",
        "embedding_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ContextData/VectorETL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "etl",
        "vector-database",
        "embeddings",
        "data-pipeline"
      ],
      "id": 17
    },
    {
      "name": "dsRAG",
      "one_line_profile": "High-performance retrieval engine for unstructured data",
      "detailed_description": "A retrieval engine designed to handle unstructured data efficiently, providing capabilities for indexing and searching to support Retrieval-Augmented Generation (RAG) workflows.",
      "domains": [
        "AI2",
        "AI2-02"
      ],
      "subtask_category": [
        "retrieval",
        "indexing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/D-Star-AI/dsRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "retrieval",
        "rag",
        "unstructured-data",
        "search-engine"
      ],
      "id": 18
    },
    {
      "name": "Strwythura",
      "one_line_profile": "Pipeline to construct knowledge graphs from unstructured data using GraphRAG",
      "detailed_description": "A tool for constructing knowledge graphs from unstructured data sources. It implements an enhanced GraphRAG approach, incorporating entity resolution and ontology pipelines to optimize AI application context.",
      "domains": [
        "AI2",
        "AI2-02"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "graph_rag"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/DerwenAI/strwythura",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "graphrag",
        "unstructured-data",
        "ontology"
      ],
      "id": 19
    },
    {
      "name": "KVCOMM",
      "one_line_profile": "Online cross-context KV-cache communication for multi-agent systems",
      "detailed_description": "A library implementing efficient KV-cache communication strategies for LLM-based multi-agent systems, optimizing memory usage and inference speed in distributed agent contexts.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "kv_cache_optimization",
        "multi_agent_inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/FastMAS/KVCOMM",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "kv-cache",
        "multi-agent",
        "optimization"
      ],
      "id": 20
    },
    {
      "name": "RAGonite",
      "one_line_profile": "Flexible RAG pipeline for heterogeneous data and knowledge graphs",
      "detailed_description": "A comprehensive RAG pipeline supporting conversational QA over structured and unstructured sources, automated database induction from knowledge graphs, and iterative retrieval, developed by Fraunhofer IIS.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "retrieval_augmented_generation",
        "knowledge_graph_induction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Fraunhofer-IIS/RAGonite",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "knowledge-graph",
        "nlp",
        "qa"
      ],
      "id": 21
    },
    {
      "name": "BloomFilterTrie",
      "one_line_profile": "Data structure for colored de Bruijn graph and pan-genome indexing",
      "detailed_description": "An alignment-free, reference-free, and incremental data structure implementation for colored de Bruijn graphs, specifically designed for efficient pan-genome indexing applications.",
      "domains": [
        "Bioinformatics"
      ],
      "subtask_category": [
        "pangenome_indexing",
        "de_bruijn_graph_construction"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/GuillaumeHolley/BloomFilterTrie",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "genomics",
        "data-structure",
        "indexing"
      ],
      "id": 22
    },
    {
      "name": "LightRAG",
      "one_line_profile": "Simple and fast Retrieval-Augmented Generation framework",
      "detailed_description": "A lightweight and efficient framework for Retrieval-Augmented Generation (RAG), optimizing the retrieval process for speed and simplicity in LLM pipelines.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "retrieval_augmented_generation",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUDS/LightRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "llm",
        "retrieval",
        "nlp"
      ],
      "id": 23
    },
    {
      "name": "pathpy",
      "one_line_profile": "Analysis of pathways and temporal networks using higher-order models",
      "detailed_description": "A Python package for the modeling and analysis of pathways and temporal networks using higher-order and multi-order graphical models, applicable in social and biological network analysis.",
      "domains": [
        "Network Science",
        "Complex Systems"
      ],
      "subtask_category": [
        "temporal_network_analysis",
        "pathway_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IngoScholtes/pathpy",
      "help_website": [
        "https://www.pathpy.net"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "network-analysis",
        "graph-theory",
        "temporal-networks",
        "higher-order-models"
      ],
      "id": 24
    },
    {
      "name": "vllm-kvcompress",
      "one_line_profile": "KV cache compression for high-throughput LLM inference",
      "detailed_description": "A library providing KV cache compression techniques to enhance the throughput of Large Language Model inference, addressing memory bottlenecks in production pipelines.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "kv_cache_compression",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IsaacRe/vllm-kvcompress",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "compression",
        "kv-cache",
        "inference"
      ],
      "id": 25
    },
    {
      "name": "TopOpt.jl",
      "one_line_profile": "Topology optimization on unstructured meshes in Julia",
      "detailed_description": "A Julia package for performing binary and continuous topology optimization on unstructured meshes, supporting 2D/3D truss and continuum problems using automatic differentiation.",
      "domains": [
        "Physics",
        "Materials Science"
      ],
      "subtask_category": [
        "topology_optimization",
        "structural_analysis"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaTopOpt/TopOpt.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "optimization",
        "topology",
        "julia",
        "fem"
      ],
      "id": 26
    },
    {
      "name": "d2Cache",
      "one_line_profile": "Dual Adaptive Caching for accelerating diffusion-based LLMs",
      "detailed_description": "Implementation of the d2Cache mechanism to accelerate diffusion-based Large Language Models through a dual adaptive caching strategy, optimizing inference latency.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "kv_cache_optimization",
        "diffusion_model_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Kamichanw/d2Cache",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "diffusion-models",
        "caching",
        "acceleration"
      ],
      "id": 27
    },
    {
      "name": "LMCache",
      "one_line_profile": "High-performance KV Cache layer for LLMs",
      "detailed_description": "A specialized caching layer designed to persist and reuse Key-Value (KV) caches across LLM inference requests, significantly reducing latency and improving throughput in production environments.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "kv_cache_management",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/LMCache/LMCache",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "kv-cache",
        "performance",
        "serving"
      ],
      "id": 28
    },
    {
      "name": "cache-steering",
      "one_line_profile": "KV Cache Steering for inducing reasoning in SLMs",
      "detailed_description": "A tool implementing KV Cache Steering techniques to guide and induce reasoning capabilities in Small Language Models (SLMs) by manipulating the cache during inference.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "model_steering",
        "inference_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MaxBelitsky/cache-steering",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "reasoning",
        "steering",
        "kv-cache"
      ],
      "id": 29
    },
    {
      "name": "ProLLM",
      "one_line_profile": "Protein Chain of Thought (ProCoT) for signaling pathway analysis",
      "detailed_description": "A framework that models biological signaling pathways as protein reasoning processes using Large Language Models, implementing a 'Protein Chain of Thought' approach to predict downstream signaling.",
      "domains": [
        "Biology",
        "Bioinformatics"
      ],
      "subtask_category": [
        "protein_pathway_analysis",
        "biological_reasoning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MingyuJ666/ProLLM",
      "help_website": [],
      "license": null,
      "tags": [
        "protein",
        "llm",
        "signaling-pathway",
        "chain-of-thought"
      ],
      "id": 30
    },
    {
      "name": "unified-cache-management",
      "one_line_profile": "Unified KV Cache management for LLM speedup",
      "detailed_description": "A system to persist and reuse KV caches for Large Language Models, providing a unified interface for cache management to accelerate inference tasks.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "kv_cache_management",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ModelEngine-Group/unified-cache-management",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "caching",
        "optimization",
        "kv-cache"
      ],
      "id": 31
    },
    {
      "name": "n8loom",
      "one_line_profile": "Tree-based prefix cache library for LLM generation pathways",
      "detailed_description": "A library implementing a tree-based prefix cache to enable rapid creation and management of hierarchical branching pathways in LLM generations, useful for exploring generation trees.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "generation_tree_caching",
        "prefix_caching"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/N8python/n8loom",
      "help_website": [],
      "license": "CC0-1.0",
      "tags": [
        "llm",
        "caching",
        "tree-search",
        "generation"
      ],
      "id": 32
    },
    {
      "name": "word2vec_pipeline",
      "one_line_profile": "NLP pipeline for word2vec embedding and clustering",
      "detailed_description": "A complete pipeline for Natural Language Processing tasks involving word2vec, including preprocessing, embedding generation, prediction, and clustering of text data.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "embedding_generation",
        "text_clustering"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/NIHOPA/word2vec_pipeline",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "word2vec",
        "embedding",
        "clustering"
      ],
      "id": 33
    },
    {
      "name": "DiVE",
      "one_line_profile": "Interactive 3D web viewer for high-dimensional data",
      "detailed_description": "A web-based interactive viewer for visualizing large-scale high-dimensional data (up to millions of points) embedded in 2D or 3D, developed by the Netherlands eScience Center.",
      "domains": [
        "AI2",
        "Visualization"
      ],
      "subtask_category": [
        "high_dimensional_visualization",
        "embedding_visualization"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/NLeSC/DiVE",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "visualization",
        "3d",
        "embedding",
        "web-viewer"
      ],
      "id": 34
    },
    {
      "name": "ReaSyn",
      "one_line_profile": "Synthesis pathway prediction using Chain-of-Reaction",
      "detailed_description": "A Transformer-based model for predicting molecular synthesis pathways, utilizing a Chain-of-Reaction (CoR) notation to map building blocks to final products.",
      "domains": [
        "Chemistry",
        "AI4S"
      ],
      "subtask_category": [
        "synthesis_pathway_prediction",
        "retrosynthesis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA-Digital-Bio/ReaSyn",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "chemistry",
        "synthesis",
        "transformer",
        "pathway-prediction"
      ],
      "id": 35
    },
    {
      "name": "kvpress",
      "one_line_profile": "Library for compressing Key-Value (KV) caches in Large Language Models",
      "detailed_description": "kvpress is a Python library designed to optimize the inference of Large Language Models (LLMs) by compressing the KV cache. It addresses the memory bottleneck in long-context generation, directly supporting the productionization and efficiency of AI models in scientific workflows.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/kvpress",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "kv-cache",
        "compression",
        "inference"
      ],
      "id": 36
    },
    {
      "name": "Fast-dLLM",
      "one_line_profile": "Training-free acceleration framework for Diffusion LLMs",
      "detailed_description": "Fast-dLLM implements a training-free acceleration method for Diffusion Language Models by enabling KV cache and parallel decoding. It serves as a solver for optimizing the generation speed of diffusion-based generative models.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVlabs/Fast-dLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-models",
        "llm",
        "acceleration",
        "kv-cache"
      ],
      "id": 37
    },
    {
      "name": "docext",
      "one_line_profile": "Toolkit for OCR-free unstructured data extraction and markdown conversion",
      "detailed_description": "docext is an on-premises toolkit for extracting structured data from unstructured documents (PDFs, etc.) without OCR. It facilitates the preprocessing of scientific literature and documents for downstream analysis or embedding generation.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "data_extraction",
        "preprocessing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NanoNets/docext",
      "help_website": [
        "https://idp-leaderboard.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-extraction",
        "pdf-parsing",
        "unstructured-data"
      ],
      "id": 38
    },
    {
      "name": "Neum AI",
      "one_line_profile": "Framework for managing large-scale vector embedding creation and synchronization",
      "detailed_description": "Neum AI is a framework designed to manage the lifecycle of vector embeddings, including creation, synchronization, and updating. It addresses the data pipeline needs for RAG and semantic search applications in scientific knowledge management.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "embedding_management",
        "pipeline_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/NeumTry/NeumAI",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-embeddings",
        "rag",
        "data-pipeline"
      ],
      "id": 39
    },
    {
      "name": "UltraRAG",
      "one_line_profile": "Low-code framework for building complex RAG pipelines",
      "detailed_description": "UltraRAG is a framework for constructing Retrieval-Augmented Generation (RAG) pipelines. It supports the development of knowledge retrieval systems, which are essential for scientific literature review and knowledge discovery.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "rag_pipeline",
        "information_retrieval"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenBMB/UltraRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "llm",
        "knowledge-retrieval"
      ],
      "id": 40
    },
    {
      "name": "BitDecoding",
      "one_line_profile": "GPU-optimized system for efficient long-context LLM decoding",
      "detailed_description": "BitDecoding is a system designed to accelerate long-context LLM decoding using low-bit KV cache quantization. It optimizes the computational resources required for running large models, relevant to AI4S infrastructure.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "quantization"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/OpenBitSys/BitDecoding",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu-optimization",
        "llm",
        "quantization"
      ],
      "id": 41
    },
    {
      "name": "MM-NIAH",
      "one_line_profile": "Benchmark for evaluating multimodal LLMs on long documents",
      "detailed_description": "Needle In A Multimodal Haystack (MM-NIAH) is a comprehensive benchmark designed to evaluate the capability of Multimodal Large Language Models (MLLMs) to comprehend long multimodal documents, serving as an evaluation tool for AI models.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/MM-NIAH",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "mllm",
        "multimodal"
      ],
      "id": 42
    },
    {
      "name": "SDLM",
      "one_line_profile": "Sequential Diffusion Language Model implementation",
      "detailed_description": "Sequential Diffusion Language Model (SDLM) is a model implementation that enhances pre-trained autoregressive language models with diffusion mechanisms, optimizing generation length and efficiency.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "generative_modeling",
        "sequence_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/SDLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "diffusion-model",
        "language-model",
        "generation"
      ],
      "id": 43
    },
    {
      "name": "MyScaleDB",
      "one_line_profile": "Unified SQL and vector database for scalable AI applications",
      "detailed_description": "MyScaleDB is an AI-native database that integrates SQL with vector management, search, and analytics. It provides the infrastructure for managing high-dimensional scientific data and embeddings.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "vector_database",
        "data_management"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/OriginHubAI/MyScaleDB",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "sql",
        "analytics"
      ],
      "id": 44
    },
    {
      "name": "Oxen",
      "one_line_profile": "Data version control system for machine learning datasets",
      "detailed_description": "Oxen is a fast data version control system optimized for structured and unstructured machine learning datasets. It ensures reproducibility and management of scientific data versions.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "data_versioning",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/Oxen-AI/Oxen",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-version-control",
        "machine-learning",
        "dataset-management"
      ],
      "id": 45
    },
    {
      "name": "PREP-SHOT",
      "one_line_profile": "Renewable energy planning and hydropower operation model",
      "detailed_description": "PREP-SHOT is a tool for Pathways for Renewable Energy Planning coupled with Short-term Hydropower OperaTion. It performs scientific modeling for energy systems analysis.",
      "domains": [],
      "subtask_category": [
        "energy_modeling",
        "simulation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/PREP-NexT/PREP-SHOT",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "energy-planning",
        "hydropower",
        "simulation"
      ],
      "id": 46
    },
    {
      "name": "LoLLMsVectorDB",
      "one_line_profile": "Modular text-based vector database manager for RAG",
      "detailed_description": "LoLLMsVectorDB is a database manager designed for Retrieval-Augmented Generation (RAG) within the LoLLMs ecosystem. It handles vectorization and directory bindings for text data management.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "vector_database_management",
        "rag_support"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ParisNeo/LoLLMsVectorDB",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-db",
        "rag",
        "text-retrieval"
      ],
      "id": 47
    },
    {
      "name": "CETI Data Ingest",
      "one_line_profile": "Data ingestion pipeline for marine biology sensors",
      "detailed_description": "Source code for the data pipeline that ingests data from embedded data collection devices (whale tags, moorings) for Project CETI, facilitating marine biology research.",
      "domains": [],
      "subtask_category": [
        "data_ingestion",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Project-CETI/data-ingest",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "marine-biology",
        "data-pipeline",
        "iot"
      ],
      "id": 48
    },
    {
      "name": "Haystack Defs",
      "one_line_profile": "Standard definitions and ontology for modeling built environment data",
      "detailed_description": "Project Haystack definitions provide a standardized ontology for modeling data from smart devices and building systems, essential for data normalization and analysis in building science.",
      "domains": [],
      "subtask_category": [
        "data_modeling",
        "ontology"
      ],
      "application_level": "dataset",
      "primary_language": "Fantom",
      "repo_url": "https://github.com/Project-Haystack/haystack-defs",
      "help_website": [],
      "license": "AFL-3.0",
      "tags": [
        "ontology",
        "iot",
        "building-science"
      ],
      "id": 49
    },
    {
      "name": "MUFFIN",
      "one_line_profile": "Hybrid assembly and differential binning workflow for metagenomics",
      "detailed_description": "MUFFIN is a bioinformatics workflow for hybrid assembly and differential binning in metagenomics, transcriptomics, and pathway analysis.",
      "domains": [],
      "subtask_category": [
        "metagenomics_assembly",
        "binning"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/RVanDamme/MUFFIN",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bioinformatics",
        "metagenomics",
        "workflow"
      ],
      "id": 50
    },
    {
      "name": "Renumics Spotlight",
      "one_line_profile": "Interactive visualization tool for unstructured ML datasets",
      "detailed_description": "Spotlight allows for interactive exploration of unstructured datasets (images, audio, text) directly from dataframes, aiding in data quality control and analysis for machine learning.",
      "domains": [
        "AI2"
      ],
      "subtask_category": [
        "data_visualization",
        "exploratory_analysis"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/Renumics/spotlight",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "unstructured-data",
        "eda"
      ],
      "id": 51
    },
    {
      "name": "SCOREC Core",
      "one_line_profile": "Library for parallel finite element unstructured meshes",
      "detailed_description": "SCOREC core is a C++ library for managing parallel finite element unstructured meshes, supporting scientific computing and simulation tasks.",
      "domains": [],
      "subtask_category": [
        "mesh_generation",
        "finite_element_method"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/SCOREC/core",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "fem",
        "mesh",
        "scientific-computing"
      ],
      "id": 52
    },
    {
      "name": "SPECFEM3D",
      "one_line_profile": "Seismic wave propagation simulation software",
      "detailed_description": "SPECFEM3D Cartesian simulates acoustic, elastic, coupled acoustic/elastic, or poroelastic seismic wave propagation using the spectral element method.",
      "domains": [],
      "subtask_category": [
        "seismic_simulation",
        "wave_propagation"
      ],
      "application_level": "solver",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/SPECFEM/specfem3d",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "geophysics",
        "seismology",
        "simulation"
      ],
      "id": 53
    },
    {
      "name": "YiShape-VecDB",
      "one_line_profile": "Vector database management system for AI applications",
      "detailed_description": "YiShape Vector Database is a specialized system for managing vector embeddings, supporting large language models and image retrieval tasks.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "vector_database",
        "embedding_management"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/ScaleFree-Tech/YiShape-VecDB",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "vector-database",
        "embeddings",
        "retrieval"
      ],
      "id": 54
    },
    {
      "name": "alibi-detect",
      "one_line_profile": "Algorithms for outlier, adversarial, and drift detection",
      "detailed_description": "Alibi Detect is a library for monitoring machine learning models, providing algorithms for outlier detection, adversarial detection, and concept drift detection, which are critical for maintaining the reliability of scientific AI models.",
      "domains": [
        "AI2-05"
      ],
      "subtask_category": [
        "model_monitoring",
        "drift_detection"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/SeldonIO/alibi-detect",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ml-monitoring",
        "outlier-detection",
        "drift-detection"
      ],
      "id": 55
    },
    {
      "name": "Embedded_Fibers_UEL",
      "one_line_profile": "Matlab-Abaqus pipeline for modeling embedded fibers in hyperelastic materials",
      "detailed_description": "A pipeline and User Element Subroutine (UEL) for modeling embedded fibers in hyperelastic solid base materials within Abaqus, developed by the Soft Tissue Biomechanics Lab.",
      "domains": [],
      "subtask_category": [
        "biomechanics_modeling",
        "finite_element_analysis"
      ],
      "application_level": "solver",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/SoftTissueBiomechanicsLab/Embedded_Fibers_UEL",
      "help_website": [],
      "license": "CC0-1.0",
      "tags": [
        "biomechanics",
        "abaqus",
        "fem"
      ],
      "id": 56
    },
    {
      "name": "KVQuant",
      "one_line_profile": "KV Cache Quantization for efficient LLM inference",
      "detailed_description": "KVQuant enables efficient inference for large language models with very long context lengths (up to 10 million tokens) by quantizing the Key-Value (KV) cache, reducing memory requirements.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "quantization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SqueezeAILab/KVQuant",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "quantization",
        "kv-cache"
      ],
      "id": 57
    },
    {
      "name": "Merlin",
      "one_line_profile": "3D Vision-Language Model for Computed Tomography analysis",
      "detailed_description": "Merlin is a 3D Vision-Language Model (VLM) specifically designed for computed tomography (CT) scans. It leverages structured electronic health records (EHR) and unstructured radiology reports for pretraining, enabling advanced medical imaging analysis and interpretation.",
      "domains": [
        "AI4S",
        "Medical Imaging"
      ],
      "subtask_category": [
        "medical_imaging_analysis",
        "vision_language_modeling"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/StanfordMIMI/Merlin",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-imaging",
        "ct-scan",
        "vlm",
        "multimodal"
      ],
      "id": 58
    },
    {
      "name": "uxarray",
      "one_line_profile": "Xarray extension for unstructured climate and weather data analysis",
      "detailed_description": "UXARRAY is an extension to Xarray that provides support for unstructured grid data, specifically tailored for climate and global weather data analysis and visualization. It enables handling of complex grid topologies common in earth system modeling.",
      "domains": [
        "AI4S",
        "Climate Science"
      ],
      "subtask_category": [
        "data_analysis",
        "visualization",
        "unstructured_grids"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/UXARRAY/uxarray",
      "help_website": [
        "https://uxarray.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "climate-science",
        "weather-data",
        "xarray",
        "unstructured-grids"
      ],
      "id": 59
    },
    {
      "name": "unstructured",
      "one_line_profile": "ETL library for processing unstructured documents for LLMs",
      "detailed_description": "Unstructured is an open-source ETL library designed to ingest and process unstructured documents (PDFs, HTML, Word, etc.) into clean, structured formats suitable for Large Language Models (LLMs). It is a critical upstream tool for scientific literature mining and RAG pipelines.",
      "domains": [
        "AI2",
        "NLP"
      ],
      "subtask_category": [
        "data_ingestion",
        "document_parsing",
        "etl"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/Unstructured-IO/unstructured",
      "help_website": [
        "https://unstructured-io.github.io/unstructured/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "etl",
        "nlp",
        "pdf-parsing",
        "llm-preprocessing"
      ],
      "id": 60
    },
    {
      "name": "MMNeedle",
      "one_line_profile": "Benchmark for long-context capability of Multimodal LLMs",
      "detailed_description": "Multimodal Needle in a Haystack (MMNeedle) is a benchmarking tool designed to evaluate the long-context capabilities of Multimodal Large Language Models (MLLMs). It provides a rigorous framework for testing model performance on retrieving information from large multimodal contexts.",
      "domains": [
        "AI2",
        "AI Evaluation"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Wang-ML-Lab/multimodal-needle-in-a-haystack",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "mllm",
        "long-context",
        "evaluation"
      ],
      "id": 61
    },
    {
      "name": "IvyGPT",
      "one_line_profile": "Interactive Chinese pathway language model in medical domain",
      "detailed_description": "IvyGPT is a specialized Large Language Model (LLM) for the medical domain, specifically trained for interactive Chinese medical QA and pathway reasoning. It serves as a tool for medical NLP research and application.",
      "domains": [
        "AI4S",
        "Medical Informatics"
      ],
      "subtask_category": [
        "medical_qa",
        "clinical_reasoning"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/WangRongsheng/IvyGPT",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-llm",
        "nlp",
        "chinese-medical-qa"
      ],
      "id": 62
    },
    {
      "name": "pydoxtools",
      "one_line_profile": "Library for extracting information from unstructured documents",
      "detailed_description": "pydoxtools is a Python library designed to extract information and structure from unstructured data sources (documents, text). It supports building customizable AI pipelines for data ingestion and processing, relevant for scientific knowledge extraction.",
      "domains": [
        "AI2",
        "NLP"
      ],
      "subtask_category": [
        "data_extraction",
        "document_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Xyntopia/pydoxtools",
      "help_website": [
        "https://pydoxtools.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "nlp",
        "data-extraction",
        "unstructured-data"
      ],
      "id": 63
    },
    {
      "name": "LLaVA-3D",
      "one_line_profile": "Multimodal model for 3D world understanding and interaction",
      "detailed_description": "LLaVA-3D is a multimodal AI model that extends LLaVA to understand and interact with 3D environments. It serves as a tool for research in 3D computer vision and embodied AI.",
      "domains": [
        "AI4S",
        "Computer Vision"
      ],
      "subtask_category": [
        "3d_understanding",
        "vision_language_modeling"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/ZCMax/LLaVA-3D",
      "help_website": [],
      "license": null,
      "tags": [
        "3d-vision",
        "multimodal",
        "llava"
      ],
      "id": 64
    },
    {
      "name": "GEM",
      "one_line_profile": "Globally consistent dense elevation mapping for unstructured terrain",
      "detailed_description": "GEM is a robotics tool for online, globally consistent dense elevation mapping, specifically designed for unstructured terrain. It is used in field robotics and autonomous navigation research.",
      "domains": [
        "AI4S",
        "Robotics"
      ],
      "subtask_category": [
        "mapping",
        "terrain_analysis"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ZJU-Robotics-Lab/GEM",
      "help_website": [],
      "license": null,
      "tags": [
        "robotics",
        "mapping",
        "elevation-map"
      ],
      "id": 65
    },
    {
      "name": "KVCache-Factory",
      "one_line_profile": "Unified KV Cache Compression Methods for LLMs",
      "detailed_description": "KVCache-Factory is a toolkit that provides unified implementations of various Key-Value (KV) cache compression methods for auto-regressive models. It is a research tool for optimizing Large Language Model inference and memory usage.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "kv_cache_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zefan-Cai/KVCache-Factory",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-optimization",
        "kv-cache",
        "inference"
      ],
      "id": 66
    },
    {
      "name": "R-KV",
      "one_line_profile": "Redundancy-aware KV Cache Compression for Reasoning Models",
      "detailed_description": "R-KV is a tool implementing redundancy-aware KV cache compression specifically for reasoning models. It addresses the memory bottlenecks in deploying large reasoning models by optimizing cache usage.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "kv_cache_compression"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zefan-Cai/R-KV",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "kv-cache",
        "optimization"
      ],
      "id": 67
    },
    {
      "name": "unstract",
      "one_line_profile": "Platform for structuring unstructured documents via LLM pipelines",
      "detailed_description": "Unstract is a no-code platform designed to launch APIs and ETL pipelines that convert unstructured documents into structured data using LLMs. It facilitates the creation of scientific knowledge bases from raw literature.",
      "domains": [
        "AI2",
        "Data Engineering"
      ],
      "subtask_category": [
        "etl",
        "document_structuring",
        "pipeline_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zipstack/unstract",
      "help_website": [
        "https://docs.unstract.com"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "etl",
        "llm-pipeline",
        "unstructured-data"
      ],
      "id": 68
    },
    {
      "name": "PrisKV",
      "one_line_profile": "High Performance KV Cache Store for LLM Inference",
      "detailed_description": "PrisKV is a high-performance Key-Value (KV) cache store designed specifically for Large Language Models (LLMs). It optimizes the storage and retrieval of KV pairs during inference, addressing memory and latency bottlenecks in AI production environments.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "caching",
        "inference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/aibrix/PrisKV",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kv-cache",
        "llm-inference",
        "high-performance"
      ],
      "id": 69
    },
    {
      "name": "Rce-KGQA",
      "one_line_profile": "Framework for multi-hop complex Knowledge Graph Question Answering",
      "detailed_description": "Rce-KGQA is a pipeline framework designed to improve multi-hop complex Knowledge Graph Question Answering (KGQA) by introducing Relational Chain Reasoning. It is a tool for research in AI reasoning and knowledge representation.",
      "domains": [
        "AI2",
        "Knowledge Representation"
      ],
      "subtask_category": [
        "kgqa",
        "reasoning",
        "knowledge_graph"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/albert-jin/Rce-KGQA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "qa",
        "reasoning"
      ],
      "id": 70
    },
    {
      "name": "singleCellHaystack",
      "one_line_profile": "Tool for finding differentially expressed genes in single-cell data",
      "detailed_description": "singleCellHaystack is a bioinformatics tool for finding surprising 'needles' (genes with non-random distribution) in 'haystacks' (single-cell transcriptome data). It uses Kullback-Leibler divergence to identify differentially expressed genes without relying on clustering.",
      "domains": [
        "AI4S",
        "Bioinformatics"
      ],
      "subtask_category": [
        "gene_expression_analysis",
        "single_cell_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/alexisvdb/singleCellHaystack",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "single-cell",
        "transcriptomics",
        "gene-expression"
      ],
      "id": 71
    },
    {
      "name": "amphi-etl",
      "one_line_profile": "Low-code visual ETL tool for data preparation",
      "detailed_description": "Amphi ETL is a visual, low-code data preparation and transformation tool based on Python. It allows users to build ETL pipelines for structured and unstructured data, facilitating the data cleaning and preprocessing steps essential for scientific data analysis.",
      "domains": [
        "AI2",
        "Data Engineering"
      ],
      "subtask_category": [
        "etl",
        "data_preparation",
        "pipeline_design"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/amphi-ai/amphi-etl",
      "help_website": [
        "https://docs.amphi.ai"
      ],
      "license": "NOASSERTION",
      "tags": [
        "etl",
        "low-code",
        "data-preparation"
      ],
      "id": 72
    },
    {
      "name": "ROSGPT",
      "one_line_profile": "Interface for controlling ROS robots using natural language via ChatGPT",
      "detailed_description": "ROSGPT is a tool that bridges Large Language Models (like ChatGPT) with the Robot Operating System (ROS). It converts unstructured human language commands into actionable robotic commands, enabling natural language interaction with robots.",
      "domains": [
        "AI4S",
        "Robotics"
      ],
      "subtask_category": [
        "human_robot_interaction",
        "command_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aniskoubaa/rosgpt",
      "help_website": [],
      "license": null,
      "tags": [
        "robotics",
        "ros",
        "llm",
        "chatgpt"
      ],
      "id": 73
    },
    {
      "name": "Sycamore",
      "one_line_profile": "LLM-powered platform for processing and searching unstructured data into semantic embeddings",
      "detailed_description": "Sycamore is a search and analytics platform designed to handle unstructured data by leveraging Large Language Models (LLMs). It provides an ETL pipeline to clean, chunk, and embed data for RAG applications, supporting complex data processing workflows.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "data_processing",
        "embedding_generation",
        "etl"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/aryn-ai/sycamore",
      "help_website": [
        "https://sycamore.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "etl",
        "rag",
        "unstructured-data",
        "embeddings"
      ],
      "id": 74
    },
    {
      "name": "BIRD-CRITIC (SWE-SQL)",
      "one_line_profile": "Evaluation benchmark and framework for Text-to-SQL LLM performance",
      "detailed_description": "A benchmarking tool and dataset designed to evaluate Large Language Models on real-world SQL generation tasks (Text-to-SQL). It focuses on solving user SQL issues in software engineering contexts, providing metrics and evaluation pathways.",
      "domains": [
        "AI2",
        "NLP"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking",
        "text-to-sql"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/bird-bench/BIRD-CRITIC-1",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "text-to-sql",
        "llm-evaluation"
      ],
      "id": 75
    },
    {
      "name": "GeoVista",
      "one_line_profile": "Cartographic rendering and mesh analytics library for geoscience data visualization",
      "detailed_description": "GeoVista is a Python library for 3D cartographic rendering and mesh analysis, built on top of PyVista and VTK. It is specifically designed for handling unstructured grids and geospatial data visualization in scientific research.",
      "domains": [
        "Geoscience",
        "Visualization"
      ],
      "subtask_category": [
        "visualization",
        "mesh_analytics",
        "cartography"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bjlittle/geovista",
      "help_website": [
        "https://geovista.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "geoscience",
        "visualization",
        "vtk",
        "pyvista"
      ],
      "id": 76
    },
    {
      "name": "BABILong",
      "one_line_profile": "Benchmark suite for evaluating Long-Context LLMs using needle-in-a-haystack tasks",
      "detailed_description": "BABILong is a benchmark designed to evaluate the performance of Large Language Models in processing long contexts. It utilizes 'needle-in-a-haystack' style tasks to test retrieval and reasoning capabilities over extended text sequences.",
      "domains": [
        "AI2",
        "NLP"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking",
        "long-context"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/booydar/babilong",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "llm",
        "long-context",
        "evaluation"
      ],
      "id": 77
    },
    {
      "name": "SemanticCache (Go)",
      "one_line_profile": "Go library for semantic caching with vector-based similarity search",
      "detailed_description": "A Go library implementing semantic caching strategies using LRU eviction and vector similarity search. It supports pluggable embedding backends and is designed to optimize LLM application latency and costs.",
      "domains": [
        "AI2-05"
      ],
      "subtask_category": [
        "semantic_caching",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/botirk38/semanticcache",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "caching",
        "vector-search",
        "go",
        "llm-optimization"
      ],
      "id": 78
    },
    {
      "name": "Contextualise",
      "one_line_profile": "Knowledge management application based on Topic Maps for organizing unstructured information",
      "detailed_description": "Contextualise is a tool for organizing information-heavy projects using the Topic Maps standard. It helps in structuring unstructured data and visualizing relationships, suitable for knowledge management in research contexts.",
      "domains": [
        "Knowledge Management"
      ],
      "subtask_category": [
        "knowledge_organization",
        "data_structuring"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/brettkromkamp/contextualise",
      "help_website": [
        "https://contextualise.dev/"
      ],
      "license": "MIT",
      "tags": [
        "topic-maps",
        "knowledge-graph",
        "information-architecture"
      ],
      "id": 79
    },
    {
      "name": "InfiniStore",
      "one_line_profile": "High-performance distributed Key-Value cache store designed for LLM inference",
      "detailed_description": "InfiniStore is a specialized Key-Value cache storage system optimized for distributed Large Language Model (LLM) inference. It addresses the memory bottlenecks in serving large models by providing efficient caching mechanisms.",
      "domains": [
        "AI2-05",
        "HPC"
      ],
      "subtask_category": [
        "caching",
        "inference_optimization",
        "distributed_storage"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/bytedance/InfiniStore",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kv-cache",
        "llm-inference",
        "distributed-systems"
      ],
      "id": 80
    },
    {
      "name": "Annotated-AST-For-LLM",
      "one_line_profile": "Pre-processing tool to generate Annotated Abstract Syntax Trees (AST) for LLM code context",
      "detailed_description": "A utility that processes code repositories to generate an Annotated Abstract Syntax Tree (AST) in JSON format. This structured representation is designed to provide better context for LLMs when analyzing or generating code.",
      "domains": [
        "AI2",
        "Code Analysis"
      ],
      "subtask_category": [
        "data_preprocessing",
        "code_analysis",
        "context_generation"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/cameronking4/Annotated-AST-For-LLM",
      "help_website": [],
      "license": null,
      "tags": [
        "ast",
        "llm-context",
        "code-analysis"
      ],
      "id": 81
    },
    {
      "name": "processing-text-data",
      "one_line_profile": "Apache Beam pipeline for generating sentence embeddings at scale",
      "detailed_description": "An optimized Apache Beam pipeline designed to process large-scale text data and generate sentence embeddings. It is runnable on Cloud Dataflow and serves as a production-ready reference for embedding pipelines.",
      "domains": [
        "AI2-05"
      ],
      "subtask_category": [
        "embedding_generation",
        "data_pipeline",
        "batch_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/carted/processing-text-data",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "apache-beam",
        "embeddings",
        "pipeline",
        "nlp"
      ],
      "id": 82
    },
    {
      "name": "CLIPort",
      "one_line_profile": "Robotic manipulation framework combining language and vision for precise placement tasks",
      "detailed_description": "CLIPort is a robotics framework that integrates CLIP-based semantic understanding with transporter networks for geometric precision. It enables robots to follow natural language instructions for manipulation tasks.",
      "domains": [
        "Robotics",
        "AI2"
      ],
      "subtask_category": [
        "robotic_manipulation",
        "visual_motor_control",
        "spatial_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/cliport/cliport",
      "help_website": [
        "https://cliport.github.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "robotics",
        "clip",
        "manipulation",
        "computer-vision"
      ],
      "id": 83
    },
    {
      "name": "CocoIndex",
      "one_line_profile": "High-performance incremental data transformation and indexing framework for AI applications",
      "detailed_description": "CocoIndex is a data framework designed for AI applications, offering high-performance, incremental processing for data transformation and indexing. It supports building efficient data pipelines for RAG and other AI workflows.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "data_indexing",
        "etl_pipeline",
        "incremental_processing"
      ],
      "application_level": "framework",
      "primary_language": "Rust",
      "repo_url": "https://github.com/cocoindex-io/cocoindex",
      "help_website": [
        "https://www.cocoindex.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-pipeline",
        "indexing",
        "rust",
        "ai-infrastructure"
      ],
      "id": 84
    },
    {
      "name": "ModelCache",
      "one_line_profile": "Semantic caching system for LLMs to reduce latency by caching query-result pairs",
      "detailed_description": "ModelCache is a semantic caching library designed to optimize Large Language Model (LLM) serving. It caches query results based on semantic similarity, reducing API costs and improving response latency for similar queries.",
      "domains": [
        "AI2-05"
      ],
      "subtask_category": [
        "semantic_caching",
        "latency_reduction",
        "cost_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/codefuse-ai/ModelCache",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "semantic-cache",
        "llm",
        "optimization"
      ],
      "id": 85
    },
    {
      "name": "Haystack",
      "one_line_profile": "End-to-end framework for building production-ready NLP and retrieval pipelines",
      "detailed_description": "An orchestration framework that connects models, vector databases, and file converters into pipelines. It is widely used in scientific literature mining (SciRAG) and knowledge retrieval systems to process and query large-scale scientific text data.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "pipeline_orchestration",
        "retrieval",
        "semantic_search"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepset-ai/haystack",
      "help_website": [
        "https://haystack.deepset.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "nlp",
        "pipeline",
        "retrieval",
        "orchestration"
      ],
      "id": 86
    },
    {
      "name": "CacheLM",
      "one_line_profile": "Semantic caching layer for LLM applications to optimize inference",
      "detailed_description": "A library that implements semantic caching using embeddings to reduce redundant API calls and latency in LLM-based applications. In scientific workflows, it helps optimize repetitive queries against large language models.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "caching",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/devanmolsharma/cachelm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-cache",
        "llm",
        "optimization",
        "embeddings"
      ],
      "id": 87
    },
    {
      "name": "VectorFlow",
      "one_line_profile": "High-volume vector embedding pipeline for unstructured data ingestion",
      "detailed_description": "A pipeline tool designed to ingest raw data, transform it into vector embeddings, and write to vector databases. It facilitates the creation of large-scale embedding indices for scientific data retrieval.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "embedding_generation",
        "data_ingestion",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/dgarnitz/vectorflow",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "embedding-pipeline",
        "vector-database",
        "etl",
        "unstructured-data"
      ],
      "id": 88
    },
    {
      "name": "DingoDB",
      "one_line_profile": "Multi-modal vector database with unified SQL support",
      "detailed_description": "A distributed multi-modal vector database that supports high-concurrency vector queries and upserts. It serves as critical infrastructure for storing and retrieving scientific embeddings (e.g., molecular or textual vectors).",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "vector_storage",
        "indexing",
        "retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/dingodb/dingo",
      "help_website": [
        "https://dingodb.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "sql",
        "multi-modal",
        "embeddings"
      ],
      "id": 89
    },
    {
      "name": "KVSplit",
      "one_line_profile": "KV cache quantization for efficient LLM inference on Apple Silicon",
      "detailed_description": "A tool for optimizing Large Language Model inference by using differentiated precision for Key-Value (KV) cache quantization. It enables running larger scientific models with longer contexts on consumer hardware.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "quantization",
        "memory_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dipampaul17/KVSplit",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "quantization",
        "kv-cache",
        "optimization"
      ],
      "id": 90
    },
    {
      "name": "Gate",
      "one_line_profile": "Drift detection module for machine learning pipelines",
      "detailed_description": "A library for detecting data drift in machine learning pipelines. In scientific AI, it ensures the reliability of models (e.g., embedding models) by monitoring distribution shifts in incoming data.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "drift_detection",
        "monitoring",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dm4ml/gate",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "drift-detection",
        "mlops",
        "monitoring",
        "data-quality"
      ],
      "id": 91
    },
    {
      "name": "SPECTRA",
      "one_line_profile": "Supervised Pathway Deconvolution of Interpretable Gene Programs",
      "detailed_description": "A tool for analyzing single-cell gene expression data by deconvolving it into interpretable gene programs guided by pathway information. It uses factor analysis techniques relevant to representation learning in biology.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "deconvolution",
        "factor_analysis",
        "gene_expression_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dpeerlab/spectra",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "single-cell",
        "gene-programs",
        "factor-analysis",
        "bioinformatics"
      ],
      "id": 92
    },
    {
      "name": "OasysDB",
      "one_line_profile": "In-memory vector store for semantic caching and retrieval",
      "detailed_description": "An efficient in-memory vector store designed for semantic caching and retrieval systems. It supports the management of embeddings for fast similarity search in scientific applications.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "vector_storage",
        "caching",
        "retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/edwinkys/oasysdb",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "rust",
        "semantic-cache",
        "embeddings"
      ],
      "id": 93
    },
    {
      "name": "pathfindR",
      "one_line_profile": "Enrichment analysis utilizing active subnetworks",
      "detailed_description": "A tool for pathway enrichment analysis that utilizes active subnetworks in protein-protein interaction networks. It helps identify biological mechanisms from omics data.",
      "domains": [
        "Bioinformatics",
        "Systems Biology"
      ],
      "subtask_category": [
        "enrichment_analysis",
        "network_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/egeulgen/pathfindR",
      "help_website": [
        "https://egeulgen.github.io/pathfindR/"
      ],
      "license": null,
      "tags": [
        "enrichment-analysis",
        "ppi-network",
        "bioinformatics",
        "r"
      ],
      "id": 94
    },
    {
      "name": "Epsilla",
      "one_line_profile": "High-performance Vector Database Management System",
      "detailed_description": "A vector database designed for high performance and scalability. It is used to store and query vector embeddings generated from scientific data, supporting RAG and semantic search workflows.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "vector_storage",
        "retrieval",
        "indexing"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/epsilla-cloud/vectordb",
      "help_website": [
        "https://epsilla.com/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "vector-database",
        "cpp",
        "embeddings",
        "retrieval"
      ],
      "id": 95
    },
    {
      "name": "Hogwild LLM",
      "one_line_profile": "Parallel LLM generation with concurrent attention cache",
      "detailed_description": "An inference engine implementation that enables parallel LLM generation using a concurrent attention cache. This optimization is relevant for high-throughput scientific text generation or analysis tasks.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "parallel_generation",
        "caching"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/eqimp/hogwild_llm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "inference",
        "parallel-computing",
        "attention-cache"
      ],
      "id": 96
    },
    {
      "name": "bitext-lexind",
      "one_line_profile": "Unsupervised bitext mining and bilingual lexicon induction",
      "detailed_description": "A tool for inducing bilingual lexicons and mining bitexts by aligning monolingual word embedding spaces. It combines unsupervised bitext mining with word alignment to produce high-quality cross-lingual representations.",
      "domains": [
        "AI2",
        "NLP"
      ],
      "subtask_category": [
        "alignment",
        "embedding_alignment",
        "lexicon_induction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/bitext-lexind",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "embeddings",
        "alignment",
        "multilingual"
      ],
      "id": 97
    },
    {
      "name": "gapseq",
      "one_line_profile": "Tool for pathway prediction and metabolic network reconstruction",
      "detailed_description": "Informed prediction and analysis of bacterial metabolic pathways and genome-scale networks. It combines database-based pathway prediction with the reconstruction of metabolic networks.",
      "domains": [
        "Bioinformatics",
        "Systems Biology"
      ],
      "subtask_category": [
        "metabolic_pathway_prediction",
        "genome_scale_network_reconstruction"
      ],
      "application_level": "solver",
      "primary_language": "R",
      "repo_url": "https://github.com/jotech/gapseq",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "metabolism",
        "bacteria",
        "pathway-analysis",
        "genome-scale-models"
      ],
      "id": 98
    },
    {
      "name": "KIVI",
      "one_line_profile": "Tuning-free asymmetric 2-bit quantization for KV cache",
      "detailed_description": "A plug-and-play 2-bit KV cache quantization algorithm that enables asymmetric quantization for Large Language Models (LLMs) without fine-tuning, optimizing memory usage during inference.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "model_optimization",
        "quantization",
        "inference_acceleration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jy-yuan/KIVI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "quantization",
        "kv-cache",
        "inference"
      ],
      "id": 99
    },
    {
      "name": "aPEAR",
      "one_line_profile": "Visualization tool for pathway enrichment analysis results",
      "detailed_description": "An R package that creates enrichment networks for pathway enrichment analysis, helping to visualize clusters of similar pathways and simplify interpretation of enrichment results.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "pathway_enrichment_analysis",
        "scientific_visualization"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/kerseviciute/aPEAR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "enrichment-analysis",
        "visualization",
        "network-graph",
        "r-package"
      ],
      "id": 100
    },
    {
      "name": "embetter",
      "one_line_profile": "Scikit-learn compatible embeddings for ML pipelines",
      "detailed_description": "A collection of scikit-learn compatible embedding components that simplifies the integration of text and image embeddings into machine learning pipelines.",
      "domains": [
        "AI2",
        "Machine Learning"
      ],
      "subtask_category": [
        "feature_extraction",
        "embedding_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/koaning/embetter",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scikit-learn",
        "embeddings",
        "nlp",
        "computer-vision"
      ],
      "id": 101
    },
    {
      "name": "ropebwt2",
      "one_line_profile": "Incremental construction of FM-index for DNA sequences",
      "detailed_description": "A tool for constructing the FM-index for large collections of DNA sequences incrementally, enabling efficient storage and search of genomic data.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "sequence_indexing",
        "data_compression"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/lh3/ropebwt2",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fm-index",
        "dna-sequencing",
        "bwt",
        "indexing"
      ],
      "id": 102
    },
    {
      "name": "llm-d-kv-cache",
      "one_line_profile": "Distributed KV cache coordinator for LLMs",
      "detailed_description": "A distributed key-value cache coordinator designed to optimize the inference of Large Language Models (LLMs) by managing cache states across distributed systems.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "caching"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/llm-d/llm-d-kv-cache",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "kv-cache",
        "distributed-systems",
        "inference"
      ],
      "id": 103
    },
    {
      "name": "PaLM-jax",
      "one_line_profile": "PaLM architecture implementation in Jax",
      "detailed_description": "An implementation of the PaLM (Pathways Language Model) architecture using Jax and Equinox, facilitating research and experimentation with large scale language models.",
      "domains": [
        "AI2",
        "Deep Learning"
      ],
      "subtask_category": [
        "model_implementation",
        "language_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucidrains/PaLM-jax",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "jax",
        "transformer",
        "palm",
        "llm"
      ],
      "id": 104
    },
    {
      "name": "PaLM-pytorch",
      "one_line_profile": "PaLM architecture implementation in PyTorch",
      "detailed_description": "An open-source implementation of the PaLM (Pathways Language Model) Transformer architecture in PyTorch, enabling researchers to train and study scaling properties of language models.",
      "domains": [
        "AI2",
        "Deep Learning"
      ],
      "subtask_category": [
        "model_implementation",
        "language_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucidrains/PaLM-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "transformer",
        "palm",
        "llm"
      ],
      "id": 105
    },
    {
      "name": "iFEM",
      "one_line_profile": "Adaptive finite element methods package for MATLAB",
      "detailed_description": "A MATLAB software package containing robust and efficient codes for adaptive finite element methods (AFEM) on unstructured simplicial grids in 2D and 3D.",
      "domains": [
        "Scientific Computing",
        "Physics"
      ],
      "subtask_category": [
        "finite_element_analysis",
        "numerical_simulation"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/lyc102/ifem",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "fem",
        "matlab",
        "pde",
        "mesh-generation"
      ],
      "id": 106
    },
    {
      "name": "FastGen",
      "one_line_profile": "Adaptive KV cache compression for LLMs",
      "detailed_description": "Source code for 'Model Tells You What to Discard', implementing adaptive KV cache compression techniques to accelerate Large Language Model inference while maintaining performance.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "model_compression",
        "inference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/machilusZ/FastGen",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "kv-cache",
        "compression",
        "inference"
      ],
      "id": 107
    },
    {
      "name": "alexandria-pipeline",
      "one_line_profile": "Pipeline for computing embeddings using InstructorXL",
      "detailed_description": "A data processing pipeline that utilizes the InstructorXL model to compute and generate embeddings from Parquet files, facilitating large-scale representation learning.",
      "domains": [
        "AI2",
        "Data Processing"
      ],
      "subtask_category": [
        "embedding_generation",
        "data_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/macrocosmcorp/alexandria-pipeline",
      "help_website": [],
      "license": null,
      "tags": [
        "embeddings",
        "instructor-xl",
        "parquet",
        "pipeline"
      ],
      "id": 108
    },
    {
      "name": "SurvPath",
      "one_line_profile": "Multimodal survival prediction using pathways and histology",
      "detailed_description": "A deep learning framework for modeling dense multimodal interactions between biological pathways and histology images to improve patient survival prediction.",
      "domains": [
        "Computational Biology",
        "Medical AI"
      ],
      "subtask_category": [
        "survival_prediction",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mahmoodlab/SurvPath",
      "help_website": [],
      "license": null,
      "tags": [
        "pathology",
        "survival-analysis",
        "multimodal",
        "deep-learning"
      ],
      "id": 109
    },
    {
      "name": "dLLM-Cache",
      "one_line_profile": "Adaptive caching for Diffusion LLMs",
      "detailed_description": "Implementation of dLLM-Cache, a method to accelerate Diffusion Large Language Models through adaptive caching mechanisms, optimizing generation speed.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "inference_acceleration",
        "caching"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/maomaocun/dLLM-cache",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-models",
        "llm",
        "caching",
        "acceleration"
      ],
      "id": 110
    },
    {
      "name": "Reaction Network",
      "one_line_profile": "Predicting likely inorganic chemical reaction pathways using graph theoretical methods",
      "detailed_description": "A Python package that uses graph theory to predict likely inorganic chemical reaction pathways. It models reaction networks to analyze synthesis routes and stability in materials science.",
      "domains": [
        "Materials Science",
        "Chemistry"
      ],
      "subtask_category": [
        "reaction_prediction",
        "pathway_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/materialsproject/reaction-network",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "materials-science",
        "reaction-network",
        "graph-theory"
      ],
      "id": 111
    },
    {
      "name": "torchcache",
      "one_line_profile": "On-the-fly caching utility for PyTorch module outputs",
      "detailed_description": "A lightweight utility to cache the outputs of PyTorch modules during experimentation. It helps in optimizing iterative research workflows by avoiding redundant computations of heavy model layers.",
      "domains": [
        "AI2-05"
      ],
      "subtask_category": [
        "caching",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/meakbiyik/torchcache",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "caching",
        "optimization"
      ],
      "id": 112
    },
    {
      "name": "LLMLingua",
      "one_line_profile": "Coarse-to-fine prompt compression for accelerating LLM inference",
      "detailed_description": "A library for compressing prompts and KV-caches to speed up Large Language Model (LLM) inference and reduce costs. It uses a coarse-to-fine approach to retain key information while significantly reducing token count, useful for processing long scientific documents.",
      "domains": [
        "AI2-05",
        "NLP"
      ],
      "subtask_category": [
        "compression",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/LLMLingua",
      "help_website": [
        "https://llmlingua.com/"
      ],
      "license": "MIT",
      "tags": [
        "prompt-compression",
        "llm",
        "inference-optimization"
      ],
      "id": 113
    },
    {
      "name": "Table Transformer",
      "one_line_profile": "Deep learning model for extracting tables from unstructured documents",
      "detailed_description": "A deep learning model (TATR) designed to extract and structure tables from unstructured documents such as PDFs and images. It is essential for mining structured data from scientific literature and reports.",
      "domains": [
        "Data Mining",
        "Document Understanding"
      ],
      "subtask_category": [
        "table_extraction",
        "structure_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/table-transformer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "table-extraction",
        "deep-learning",
        "pdf-mining"
      ],
      "id": 114
    },
    {
      "name": "LLM Graph Builder",
      "one_line_profile": "Constructs knowledge graphs from unstructured data using LLMs",
      "detailed_description": "A tool that leverages Large Language Models to extract nodes and relationships from unstructured text and construct Neo4j knowledge graphs. It facilitates the conversion of scientific literature into structured knowledge bases.",
      "domains": [
        "Knowledge Engineering",
        "AI2"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "entity_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/neo4j-labs/llm-graph-builder",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "neo4j",
        "unstructured-data"
      ],
      "id": 115
    },
    {
      "name": "Zeugma",
      "one_line_profile": "NLP utility for unified word embedding handling",
      "detailed_description": "A natural language processing utility that provides a unified interface for using various word embeddings (Word2Vec, GloVe, FastText) and preprocessing transformers, compatible with scikit-learn pipelines.",
      "domains": [
        "AI2",
        "NLP"
      ],
      "subtask_category": [
        "embedding_generation",
        "preprocessing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nkthiebaut/zeugma",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "embeddings",
        "nlp",
        "scikit-learn"
      ],
      "id": 116
    },
    {
      "name": "ggkegg",
      "one_line_profile": "Visualization of KEGG pathways using grammar of graphics",
      "detailed_description": "An R package for analyzing and visualizing KEGG (Kyoto Encyclopedia of Genes and Genomes) pathway information using the grammar of graphics (ggplot2). It allows for complex biological data visualization.",
      "domains": [
        "Bioinformatics",
        "Visualization"
      ],
      "subtask_category": [
        "pathway_visualization",
        "biological_data_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/noriakis/ggkegg",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kegg",
        "bioinformatics",
        "visualization"
      ],
      "id": 117
    },
    {
      "name": "kvcached",
      "one_line_profile": "Virtualized elastic KV cache for dynamic GPU memory sharing",
      "detailed_description": "A system for managing Key-Value (KV) caches in Large Language Model inference. It enables dynamic GPU memory sharing and virtualization, optimizing the serving of large models often used in scientific AI applications.",
      "domains": [
        "AI2-05",
        "AI Systems"
      ],
      "subtask_category": [
        "memory_management",
        "caching"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ovg-project/kvcached",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kv-cache",
        "gpu-optimization",
        "llm-serving"
      ],
      "id": 118
    },
    {
      "name": "Pathway",
      "one_line_profile": "High-performance data processing framework for AI pipelines and RAG",
      "detailed_description": "A Python ETL framework designed for stream processing, real-time analytics, and building LLM/RAG pipelines. It supports handling live data streams and embeddings, making it suitable for dynamic scientific data processing workflows.",
      "domains": [
        "AI2",
        "Data Engineering"
      ],
      "subtask_category": [
        "stream_processing",
        "rag_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/pathwaycom/pathway",
      "help_website": [
        "https://pathway.com/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "etl",
        "stream-processing",
        "rag"
      ],
      "id": 119
    },
    {
      "name": "geodict",
      "one_line_profile": "Library for extracting location information from unstructured text",
      "detailed_description": "A Python library for identifying and extracting location names from unstructured text. Useful for geospatial data processing and enriching scientific datasets with location metadata.",
      "domains": [
        "NLP",
        "Geospatial"
      ],
      "subtask_category": [
        "entity_extraction",
        "geocoding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/petewarden/geodict",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "geospatial",
        "nlp",
        "location-extraction"
      ],
      "id": 120
    },
    {
      "name": "Vector DB Benchmark",
      "one_line_profile": "Framework for benchmarking vector search engines",
      "detailed_description": "A framework designed to test and compare the performance of various vector database engines, essential for evaluating infrastructure in embedding-based scientific workflows.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/qdrant/vector-db-benchmark",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "benchmarking",
        "performance"
      ],
      "id": 121
    },
    {
      "name": "QMiner",
      "one_line_profile": "Analytic platform for real-time large-scale data streams",
      "detailed_description": "A platform for processing and analyzing large-scale real-time streams containing structured and unstructured data, suitable for sensor data mining and complex event processing.",
      "domains": [
        "Data Mining",
        "Stream Processing"
      ],
      "subtask_category": [
        "data_mining",
        "stream_analytics"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/qminer/qminer",
      "help_website": [
        "http://qminer.github.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "data-mining",
        "stream-processing",
        "analytics"
      ],
      "id": 122
    },
    {
      "name": "RagaAI Catalyst",
      "one_line_profile": "Agent AI Observability, Monitoring and Evaluation Framework",
      "detailed_description": "A comprehensive SDK for tracing, debugging, and evaluating agentic AI systems and LLMs, providing analytics for execution graphs and timelines.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "observability",
        "monitoring",
        "evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/raga-ai-hub/RagaAI-Catalyst",
      "help_website": [
        "https://docs.raga.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "observability",
        "llm-monitoring",
        "agent-evaluation"
      ],
      "id": 123
    },
    {
      "name": "Agent-o-rama",
      "one_line_profile": "End-to-end LLM agent platform for Java and Clojure",
      "detailed_description": "A platform for building, tracing, testing, and monitoring LLM agents with integrated storage, inspired by LangGraph/LangSmith.",
      "domains": [
        "AI2",
        "AI Agents"
      ],
      "subtask_category": [
        "agent_orchestration",
        "monitoring"
      ],
      "application_level": "platform",
      "primary_language": "Clojure",
      "repo_url": "https://github.com/redplanetlabs/agent-o-rama",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-agent",
        "clojure",
        "workflow"
      ],
      "id": 124
    },
    {
      "name": "ActivePathways",
      "one_line_profile": "Integrative pathway enrichment analysis of multivariate omics data",
      "detailed_description": "A tool for integrative pathway enrichment analysis that combines p-values from multiple omics datasets to identify enriched pathways.",
      "domains": [
        "Bioinformatics",
        "Omics"
      ],
      "subtask_category": [
        "pathway_analysis",
        "enrichment_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/reimandlab/ActivePathways",
      "help_website": [],
      "license": null,
      "tags": [
        "omics",
        "pathway-analysis",
        "bioinformatics"
      ],
      "id": 125
    },
    {
      "name": "Agent Cloud",
      "one_line_profile": "RAG pipeline and Multi-Agent process automation platform",
      "detailed_description": "A platform featuring a RAG pipeline capable of embedding multiple datasources and creating conversational or multi-agent process automation apps.",
      "domains": [
        "AI2",
        "AI Agents"
      ],
      "subtask_category": [
        "rag_pipeline",
        "agent_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/rnadigital/agentcloud",
      "help_website": [
        "https://docs.agentcloud.dev"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "rag",
        "multi-agent",
        "automation"
      ],
      "id": 126
    },
    {
      "name": "BotanicGarden",
      "one_line_profile": "Dataset for robot navigation in unstructured natural environments",
      "detailed_description": "A high-quality dataset designed for training and evaluating robot navigation systems in unstructured natural environments.",
      "domains": [
        "Robotics",
        "Datasets"
      ],
      "subtask_category": [
        "navigation",
        "dataset"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/robot-pesg/BotanicGarden",
      "help_website": [],
      "license": null,
      "tags": [
        "robotics",
        "navigation",
        "dataset"
      ],
      "id": 127
    },
    {
      "name": "bio_embeddings",
      "one_line_profile": "Pipeline for generating protein embeddings from sequences",
      "detailed_description": "A pipeline and library to generate protein embeddings from protein sequences using various language models, facilitating downstream bioinformatics tasks.",
      "domains": [
        "Bioinformatics",
        "AI2"
      ],
      "subtask_category": [
        "embedding_generation",
        "protein_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sacdallago/bio_embeddings",
      "help_website": [
        "https://docs.bioembeddings.com"
      ],
      "license": "MIT",
      "tags": [
        "protein-embeddings",
        "bioinformatics",
        "language-models"
      ],
      "id": 128
    },
    {
      "name": "PROGENy",
      "one_line_profile": "Pathway RespOnsive GENe activity inference",
      "detailed_description": "An R package to infer pathway activity from gene expression data using a consensus model of pathway responsive genes.",
      "domains": [
        "Bioinformatics"
      ],
      "subtask_category": [
        "pathway_inference",
        "gene_expression_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/saezlab/progeny",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gene-expression",
        "pathway-activity",
        "inference"
      ],
      "id": 129
    },
    {
      "name": "Pypath",
      "one_line_profile": "Python module for biological prior knowledge integration",
      "detailed_description": "A Python module for integrating prior knowledge, building databases of signaling pathways, enzyme-substrate interactions, and intercellular communication roles.",
      "domains": [
        "Bioinformatics"
      ],
      "subtask_category": [
        "knowledge_integration",
        "network_biology"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/saezlab/pypath",
      "help_website": [
        "https://pypath.omnipathdb.org/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "signaling-pathways",
        "omics",
        "knowledge-graph"
      ],
      "id": 130
    },
    {
      "name": "SemCache",
      "one_line_profile": "Semantic caching layer for LLM applications",
      "detailed_description": "A semantic caching layer designed to reuse LLM responses and reduce token usage by matching semantically similar queries.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "caching",
        "optimization"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/sensoris/semcache",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-cache",
        "llm-optimization",
        "rust"
      ],
      "id": 131
    },
    {
      "name": "Ragswift",
      "one_line_profile": "Scalable centralized embeddings management platform",
      "detailed_description": "A platform for managing embeddings in RAG pipelines, facilitating the scaling of retrieval-augmented generation systems.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "embedding_management",
        "pipeline_scaling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/shivamsanju/ragswift",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "embeddings",
        "management"
      ],
      "id": 132
    },
    {
      "name": "Vector Cache",
      "one_line_profile": "Simple semantic cache implementation for LLMs",
      "detailed_description": "A lightweight implementation of semantic caching to store and retrieve LLM responses based on semantic similarity.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "caching",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shivendrasoni/vector-cache",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-cache",
        "llm",
        "optimization"
      ],
      "id": 133
    },
    {
      "name": "FuncChain",
      "one_line_profile": "Pythonic library for building cognitive systems",
      "detailed_description": "A library for building cognitive systems and AI chains in a Pythonic way, facilitating the creation of complex AI workflows.",
      "domains": [
        "AI2",
        "AI Workflow"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "cognitive_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shroominic/funcchain",
      "help_website": [
        "https://docs.funcchain.io"
      ],
      "license": "MIT",
      "tags": [
        "ai-chains",
        "workflow",
        "pythonic"
      ],
      "id": 134
    },
    {
      "name": "scPagwas",
      "one_line_profile": "Integrative analysis tool for scRNA-seq and GWAS data to identify trait-relevant cell subpopulations",
      "detailed_description": "A computational tool that integrates single-cell RNA sequencing (scRNA-seq) data with Genome-Wide Association Studies (GWAS) summary statistics. It transforms scRNA-seq data into pathway activity scores to discover trait-relevant cell subpopulations and uncover cellular mechanisms underlying complex traits.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "data_integration",
        "pathway_analysis",
        "scRNA-seq_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/sulab-wmu/scPagwas",
      "help_website": [
        "https://github.com/sulab-wmu/scPagwas"
      ],
      "license": "NOASSERTION",
      "tags": [
        "scRNA-seq",
        "GWAS",
        "pathway-analysis",
        "genetics"
      ],
      "id": 135
    },
    {
      "name": "Superlinked",
      "one_line_profile": "Framework for building high-performance vector embedding pipelines for structured and unstructured data",
      "detailed_description": "A Python framework designed to simplify the creation of complex vector embedding pipelines. It allows users to transform structured and unstructured data into vector embeddings, manage the schema, and integrate with vector databases, serving as a foundational infrastructure for scientific information retrieval and recommendation systems.",
      "domains": [
        "AI2",
        "AI Toolchain"
      ],
      "subtask_category": [
        "embedding_generation",
        "data_processing",
        "vector_indexing"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/superlinked/superlinked",
      "help_website": [
        "https://superlinked.com/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "embeddings",
        "vector-search",
        "information-retrieval",
        "infrastructure"
      ],
      "id": 136
    },
    {
      "name": "C2C",
      "one_line_profile": "Direct semantic communication framework for LLMs via KV cache transfer",
      "detailed_description": "The official implementation of 'Cache-to-Cache', a mechanism enabling direct semantic communication between Large Language Models (LLMs) by transferring Key-Value (KV) caches. This optimizes distributed inference and collaboration between models, relevant for high-performance AI computing in scientific workflows.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "model_communication",
        "inference_optimization",
        "kv_cache_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-nics/C2C",
      "help_website": [
        "https://github.com/thu-nics/C2C"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "kv-cache",
        "distributed-inference",
        "semantic-communication"
      ],
      "id": 137
    },
    {
      "name": "VDTuner",
      "one_line_profile": "Automated performance tuning system for vector databases",
      "detailed_description": "An automated tuning tool designed to optimize the performance of Vector Data Management Systems (Vector Databases). It adjusts configuration parameters to improve throughput and latency, supporting the efficient operation of large-scale embedding indices in scientific applications.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "database_tuning",
        "performance_optimization",
        "vector_database_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tiannuo-yang/VDTuner",
      "help_website": [
        "https://github.com/tiannuo-yang/VDTuner"
      ],
      "license": "MIT",
      "tags": [
        "vector-database",
        "auto-tuning",
        "performance-optimization"
      ],
      "id": 138
    },
    {
      "name": "QBRC-Neoantigen-Pipeline",
      "one_line_profile": "Neoantigen calling pipeline with CSiN calculation",
      "detailed_description": "A bioinformatics pipeline for identifying neoantigens from sequencing data. It includes the calculation of Cauchy-Schwarz index of Neoantigens (CSiN) to predict immunogenicity, aiding in cancer immunotherapy research.",
      "domains": [
        "Bioinformatics",
        "Immunology"
      ],
      "subtask_category": [
        "neoantigen_prediction",
        "variant_calling",
        "immunogenicity_prediction"
      ],
      "application_level": "workflow",
      "primary_language": "Perl",
      "repo_url": "https://github.com/tianshilu/QBRC-Neoantigen-Pipeline",
      "help_website": [
        "https://github.com/tianshilu/QBRC-Neoantigen-Pipeline"
      ],
      "license": "NOASSERTION",
      "tags": [
        "neoantigen",
        "cancer-immunotherapy",
        "pipeline",
        "bioinformatics"
      ],
      "id": 139
    },
    {
      "name": "Towhee",
      "one_line_profile": "Framework for building neural data processing pipelines",
      "detailed_description": "A framework dedicated to making neural data processing pipelines simple and fast. It supports various unstructured data tasks including molecular search, image retrieval, and audio classification, serving as a key component in the embedding and representation learning ecosystem.",
      "domains": [
        "AI2",
        "AI Toolchain"
      ],
      "subtask_category": [
        "embedding_pipeline",
        "molecular_search",
        "unstructured_data_processing"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/towhee-io/towhee",
      "help_website": [
        "https://towhee.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "pipeline",
        "embeddings",
        "neural-search",
        "molecular-search"
      ],
      "id": 140
    },
    {
      "name": "UCCL",
      "one_line_profile": "Unified Collective Communication Library for GPU-centric AI workloads",
      "detailed_description": "An efficient communication library designed for GPUs, supporting collectives, peer-to-peer (P2P) transfers (e.g., KV cache transfer), and GPU-driven execution. It optimizes data movement in large-scale AI models, essential for scientific computing and distributed inference.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "gpu_communication",
        "kv_cache_transfer",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/uccl-project/uccl",
      "help_website": [
        "https://github.com/uccl-project/uccl"
      ],
      "license": "Apache-2.0",
      "tags": [
        "gpu",
        "communication-library",
        "hpc",
        "kv-cache"
      ],
      "id": 141
    },
    {
      "name": "UCNS3D",
      "one_line_profile": "Unstructured Compressible Navier-Stokes 3D solver",
      "detailed_description": "A high-order accurate Computational Fluid Dynamics (CFD) code for solving the Unstructured Compressible Navier-Stokes equations in 3D. It is used for simulating complex fluid flows in scientific and engineering research.",
      "domains": [
        "Physics",
        "CFD"
      ],
      "subtask_category": [
        "fluid_dynamics_simulation",
        "navier_stokes_solver",
        "scientific_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/ucns3d-team/UCNS3D",
      "help_website": [
        "https://www.ucns3d.com/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "cfd",
        "fluid-dynamics",
        "fortran",
        "simulation"
      ],
      "id": 142
    },
    {
      "name": "UpTrain",
      "one_line_profile": "Evaluation and observability platform for Generative AI and RAG pipelines",
      "detailed_description": "An open-source platform for evaluating, monitoring, and improving Generative AI applications. It provides metrics for embedding usage, retrieval quality, and root cause analysis, supporting the reliability of AI models used in scientific research (e.g., RAG for literature).",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "observability",
        "rag_monitoring"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/uptrain-ai/uptrain",
      "help_website": [
        "https://docs.uptrain.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "observability",
        "rag",
        "llm-ops"
      ],
      "id": 143
    },
    {
      "name": "vCache",
      "one_line_profile": "System for reliable and efficient semantic prompt caching",
      "detailed_description": "A library and system for semantic prompt caching in Large Language Models. It optimizes inference by caching and retrieving prompt-response pairs based on semantic similarity, enhancing the efficiency of AI-driven scientific workflows.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "prompt_caching",
        "inference_optimization",
        "semantic_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vcache-project/vCache",
      "help_website": [
        "https://github.com/vcache-project/vCache"
      ],
      "license": "Apache-2.0",
      "tags": [
        "caching",
        "llm",
        "semantic-search",
        "optimization"
      ],
      "id": 144
    },
    {
      "name": "Weaviate",
      "one_line_profile": "Cloud-native vector database for scalable embedding storage and retrieval",
      "detailed_description": "An open-source vector database that stores both objects and vectors, enabling semantic search combined with structured filtering. It serves as critical infrastructure for managing large-scale scientific embedding indices and knowledge graphs.",
      "domains": [
        "AI2",
        "AI Toolchain"
      ],
      "subtask_category": [
        "vector_storage",
        "semantic_search",
        "embedding_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/weaviate/weaviate",
      "help_website": [
        "https://weaviate.io/developers/weaviate"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "vector-database",
        "semantic-search",
        "embeddings",
        "infrastructure"
      ],
      "id": 145
    },
    {
      "name": "PLIER",
      "one_line_profile": "Pathway-Level Information Extractor for gene expression data",
      "detailed_description": "A generative model and software tool for analyzing gene expression data. It decomposes expression data into pathway-level information, facilitating the discovery of biological mechanisms and regulatory networks.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "gene_expression_analysis",
        "pathway_extraction",
        "dimensionality_reduction"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/wgmao/PLIER",
      "help_website": [
        "https://github.com/wgmao/PLIER"
      ],
      "license": "NOASSERTION",
      "tags": [
        "gene-expression",
        "pathway-analysis",
        "generative-model",
        "bioinformatics"
      ],
      "id": 146
    },
    {
      "name": "Knowledge Table",
      "one_line_profile": "Tool for extracting and exploring structured data from unstructured documents",
      "detailed_description": "A Python package designed to simplify the process of extracting structured data from unstructured documents and exploring it, facilitating knowledge base construction and retrieval tasks.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "data_extraction",
        "knowledge_representation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/whyhow-ai/knowledge-table",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "unstructured-data",
        "knowledge-extraction",
        "rag"
      ],
      "id": 147
    },
    {
      "name": "Rule-based Retrieval",
      "one_line_profile": "Management package for Retrieval Augmented Generation (RAG) applications",
      "detailed_description": "A Python package that enables the creation and management of RAG applications with advanced filtering capabilities, integrating with OpenAI and vector databases like Pinecone or Milvus.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "retrieval_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/whyhow-ai/rule-based-retrieval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "retrieval",
        "vector-database"
      ],
      "id": 148
    },
    {
      "name": "whylogs",
      "one_line_profile": "Data logging and quality monitoring library for ML pipelines",
      "detailed_description": "An open-source library for logging data quality and model performance statistics in machine learning pipelines, supporting privacy-preserving data collection and drift detection.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "data_logging",
        "data_quality_control",
        "model_monitoring"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/whylabs/whylogs",
      "help_website": [
        "https://whylogs.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-quality",
        "ml-monitoring",
        "logging"
      ],
      "id": 149
    },
    {
      "name": "whylogs-java",
      "one_line_profile": "Java implementation of the whylogs data logging library",
      "detailed_description": "The Java version of the whylogs library, enabling data profiling and monitoring for machine learning pipelines within Java environments.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "data_logging",
        "data_quality_control"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/whylabs/whylogs-java",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "java",
        "data-quality",
        "ml-monitoring"
      ],
      "id": 150
    },
    {
      "name": "prompt-cache",
      "one_line_profile": "Modular prompt caching library for low-latency LLM inference",
      "detailed_description": "A library providing modular and structured prompt caching mechanisms to optimize Large Language Model (LLM) inference latency and efficiency.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "kv_caching"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yale-sys/prompt-cache",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "caching",
        "optimization"
      ],
      "id": 151
    },
    {
      "name": "Extractous",
      "one_line_profile": "High-performance unstructured data extraction library",
      "detailed_description": "A fast and efficient library written in Rust for extracting content from unstructured data sources, supporting bindings for multiple languages, essential for data preprocessing in scientific RAG pipelines.",
      "domains": [
        "AI2",
        "AI2-01"
      ],
      "subtask_category": [
        "unstructured_data_extraction",
        "document_processing"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/yobix-ai/extractous",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "etl",
        "data-extraction",
        "rust"
      ],
      "id": 152
    },
    {
      "name": "KinBot",
      "one_line_profile": "Automated reaction pathway search for gas-phase molecules",
      "detailed_description": "A tool for automatically searching and characterizing potential chemical reaction pathways for gas-phase molecules, aiding in chemical kinetics modeling.",
      "domains": [
        "Chemistry",
        "Chemical_Kinetics"
      ],
      "subtask_category": [
        "reaction_pathway_search",
        "molecular_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zadorlab/KinBot",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "chemistry",
        "reaction-pathways",
        "kinetics"
      ],
      "id": 153
    },
    {
      "name": "Escher",
      "one_line_profile": "Visualization tool for metabolic pathways",
      "detailed_description": "A web-based tool for building, sharing, and embedding visualizations of metabolic pathways, widely used in systems biology and metabolomics.",
      "domains": [
        "Biology",
        "Systems_Biology"
      ],
      "subtask_category": [
        "pathway_visualization",
        "metabolic_modeling"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/zakandrewking/escher",
      "help_website": [
        "https://escher.github.io"
      ],
      "license": "NOASSERTION",
      "tags": [
        "visualization",
        "metabolism",
        "biology"
      ],
      "id": 154
    },
    {
      "name": "GPTCache",
      "one_line_profile": "Semantic cache for Large Language Model inference",
      "detailed_description": "A library designed to create semantic caches for LLM queries, reducing latency and API costs by storing and retrieving similar queries using vector embeddings.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "semantic_caching",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zilliztech/GPTCache",
      "help_website": [
        "https://gptcache.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "llm",
        "caching",
        "semantic-search"
      ],
      "id": 155
    },
    {
      "name": "VectorDBBench",
      "one_line_profile": "Benchmarking tool for vector databases",
      "detailed_description": "A comprehensive benchmark tool designed to evaluate the performance of various vector databases, critical for selecting infrastructure in embedding-based scientific workflows.",
      "domains": [
        "AI2",
        "AI2-05"
      ],
      "subtask_category": [
        "vector_db_benchmarking",
        "performance_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zilliztech/VectorDBBench",
      "help_website": [
        "https://vectordbbench.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "benchmark",
        "vector-database",
        "performance"
      ],
      "id": 156
    }
  ]
}