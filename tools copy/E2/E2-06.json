{
  "generated_at": "2025-12-16T07:40:49.179060+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "E2",
      "leaf_cluster_name": "气候-数值模式与数据同化生态",
      "domain": "Climate",
      "typical_objects": "NetCDF/GRIB grids",
      "task_chain": "模式→同化→评估→后处理→复现",
      "tool_form": "模式组件 + 同化库 + 评测"
    },
    "unit": {
      "unit_id": "E2-06",
      "unit_name": "Benchmark与复现",
      "target_scale": "100–250",
      "coverage_tools": "metrics、harness"
    },
    "search": {
      "target_candidates": 250,
      "queries": [
        "[GH] MDTF-diagnostics",
        "[GH] Freva",
        "[GH] WeatherBench",
        "[GH] xskillscore",
        "[GH] climpred",
        "[GH] ILAMB",
        "[GH] METplus",
        "[GH] PCMDI Metrics Package",
        "[GH] ESMValTool",
        "[GH] climate model benchmark",
        "[GH] weather forecast verification",
        "[GH] model evaluation metrics",
        "[GH] ESM evaluation tool",
        "[GH] CMIP analysis",
        "[GH] climate diagnostics",
        "[GH] forecast skill scores",
        "[GH] model intercomparison",
        "[GH] climate reproducibility",
        "[GH] weatherbench",
        "[GH] climate metrics",
        "[GH] verification framework",
        "[WEB] climate model benchmarking tools github",
        "[WEB] weather forecast verification metrics github",
        "[WEB] earth system model evaluation framework github",
        "[WEB] CMIP6 model analysis tools github",
        "[WEB] climate prediction skill scores github"
      ],
      "total_candidates": 727,
      "tool_candidates": 211,
      "final_tools": 64
    }
  },
  "tools": [
    {
      "name": "arm-gcm-diagnostics",
      "one_line_profile": "Diagnostics package for ARM data-oriented climate model evaluation",
      "detailed_description": "A Python-based package developed by ARM-DOE for diagnosing and evaluating General Circulation Models (GCMs) using ARM observational data.",
      "domains": [
        "Climate",
        "E2-06"
      ],
      "subtask_category": [
        "diagnostics",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ARM-DOE/arm-gcm-diagnostics",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "climate",
        "diagnostics",
        "ARM",
        "evaluation"
      ],
      "id": 1
    },
    {
      "name": "COSPv2.0",
      "one_line_profile": "The CFMIP Observation Simulator Package",
      "detailed_description": "A software package that simulates satellite observations from climate model output, enabling direct comparison between models and satellite data.",
      "domains": [
        "Climate",
        "E2-06"
      ],
      "subtask_category": [
        "observation_simulation",
        "model_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/CFMIP/COSPv2.0",
      "help_website": [],
      "license": "Unknown",
      "tags": [
        "satellite-simulator",
        "clouds",
        "cfmip"
      ],
      "id": 2
    },
    {
      "name": "ctf4science",
      "one_line_profile": "Benchmarking framework for dynamic system modeling methods",
      "detailed_description": "A modular framework designed for benchmarking modeling methods on dynamic systems like ODEs and PDEs using standardized datasets and metrics.",
      "domains": [
        "Scientific Computing",
        "E2-06"
      ],
      "subtask_category": [
        "benchmarking",
        "model_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/CTF-for-Science/ctf4science",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "ode",
        "pde",
        "dynamic-systems"
      ],
      "id": 3
    },
    {
      "name": "ClimaDiagnostics.jl",
      "one_line_profile": "Diagnostics framework for CliMA simulations",
      "detailed_description": "A Julia framework to define, calculate, and output observables and statistics from Climate Modeling Alliance (CliMA) simulations.",
      "domains": [
        "Climate",
        "E2-06"
      ],
      "subtask_category": [
        "diagnostics",
        "statistics"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/CliMA/ClimaDiagnostics.jl",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "julia",
        "climate",
        "diagnostics"
      ],
      "id": 4
    },
    {
      "name": "UNSEEN-open",
      "one_line_profile": "Workflow for assessing climate extremes",
      "detailed_description": "An open, reproducible workflow to assess and anticipate climate extremes beyond the observed record using large ensemble simulations.",
      "domains": [
        "Climate",
        "E2-06"
      ],
      "subtask_category": [
        "risk_assessment",
        "extreme_events"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/ECMWFCode4Earth/UNSEEN-open",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "climate-extremes",
        "reproducible-research",
        "unseen"
      ],
      "id": 5
    },
    {
      "name": "ESMValCore",
      "one_line_profile": "Pre-processing engine for ESMValTool",
      "detailed_description": "A community tool for pre-processing data from Earth system models in CMIP and running analysis scripts, serving as the core engine for ESMValTool.",
      "domains": [
        "Climate",
        "E2-06"
      ],
      "subtask_category": [
        "data_preprocessing",
        "cmip_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ESMValGroup/ESMValCore",
      "help_website": [
        "https://docs.esmvaltool.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "cmip",
        "earth-system-models",
        "preprocessing"
      ],
      "id": 6
    },
    {
      "name": "ESMValTool",
      "one_line_profile": "Earth System Model Evaluation Tool",
      "detailed_description": "A community diagnostic and performance metrics tool for routine evaluation of Earth system models in CMIP, allowing for comparison against observations and other models.",
      "domains": [
        "Climate",
        "E2-06"
      ],
      "subtask_category": [
        "diagnostics",
        "benchmarking",
        "model_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "NCL",
      "repo_url": "https://github.com/ESMValGroup/ESMValTool",
      "help_website": [
        "https://esmvaltool.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "diagnostics",
        "metrics",
        "cmip",
        "climate-models"
      ],
      "id": 7
    },
    {
      "name": "HiRAM",
      "one_line_profile": "GFDL High Resolution Atmospheric Model",
      "detailed_description": "The GFDL global High Resolution Atmospheric Model (HiRAM), designed to provide improved representation of significant weather events like tropical storms in a global climate model.",
      "domains": [
        "Climate",
        "E2"
      ],
      "subtask_category": [
        "atmospheric_modeling",
        "simulation"
      ],
      "application_level": "solver",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/FMS-ESM/HiRAM",
      "help_website": [
        "http://www.gfdl.noaa.gov/hiram"
      ],
      "license": "Unknown",
      "tags": [
        "atmospheric-model",
        "gfdl",
        "tropical-storms"
      ],
      "id": 8
    },
    {
      "name": "ClimateTools.jl",
      "one_line_profile": "Climate science analysis package for Julia",
      "detailed_description": "A Julia package providing tools for the analysis and visualization of climate science data, including NetCDF handling and common climate indices.",
      "domains": [
        "Climate",
        "E2"
      ],
      "subtask_category": [
        "data_analysis",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaClimate/ClimateTools.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "julia",
        "climate-analysis",
        "netcdf"
      ],
      "id": 9
    },
    {
      "name": "CSET",
      "one_line_profile": "Convective Scale Evaluation Tool",
      "detailed_description": "A toolkit developed by the Met Office for the evaluation of weather and climate models, specifically focusing on convective scale diagnostics.",
      "domains": [
        "Climate",
        "Weather",
        "E2-06"
      ],
      "subtask_category": [
        "model_evaluation",
        "diagnostics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/MetOffice/CSET",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "metoffice",
        "evaluation",
        "weather-models"
      ],
      "id": 10
    },
    {
      "name": "CVDP-LE",
      "one_line_profile": "Climate Variability Diagnostics Package for Large Ensembles",
      "detailed_description": "An automated analysis tool and data repository for exploring internal and forced contributions to climate variability and change in coupled model Large Ensembles.",
      "domains": [
        "Climate",
        "E2-06"
      ],
      "subtask_category": [
        "diagnostics",
        "variability_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "NCL",
      "repo_url": "https://github.com/NCAR/CVDP-LE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ncar",
        "large-ensemble",
        "climate-variability"
      ],
      "id": 11
    },
    {
      "name": "CVDP-ncl",
      "one_line_profile": "Climate Variability Diagnostics Package",
      "detailed_description": "An analysis tool developed by NCAR that documents the major modes of climate variability in models and observations.",
      "domains": [
        "Climate",
        "E2-06"
      ],
      "subtask_category": [
        "diagnostics",
        "climate_modes"
      ],
      "application_level": "workflow",
      "primary_language": "NCL",
      "repo_url": "https://github.com/NCAR/CVDP-ncl",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ncar",
        "diagnostics",
        "climate-variability"
      ],
      "id": 12
    },
    {
      "name": "EMC_verif-global",
      "one_line_profile": "GFS verification package",
      "detailed_description": "Global Forecast System (GFS) verification package using MET and METplus, developed by NOAA-EMC.",
      "domains": [
        "Weather",
        "E2-06"
      ],
      "subtask_category": [
        "verification",
        "forecast_evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/NOAA-EMC/EMC_verif-global",
      "help_website": [],
      "license": "Unknown",
      "tags": [
        "gfs",
        "verification",
        "noaa"
      ],
      "id": 13
    },
    {
      "name": "MDTF-diagnostics",
      "one_line_profile": "Process-oriented diagnostics framework",
      "detailed_description": "A framework and collection of process-oriented diagnostics for weather and climate simulations, developed by NOAA-GFDL.",
      "domains": [
        "Climate",
        "E2-06"
      ],
      "subtask_category": [
        "diagnostics",
        "process_evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/NOAA-GFDL/MDTF-diagnostics",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "gfdl",
        "diagnostics",
        "climate-process"
      ],
      "id": 14
    },
    {
      "name": "gval",
      "one_line_profile": "Geospatial dataset evaluation framework",
      "detailed_description": "A high-level Python framework to evaluate the skill of geospatial datasets by comparing candidates to benchmark maps producing agreement maps and metrics.",
      "domains": [
        "Earth Science",
        "E2-06"
      ],
      "subtask_category": [
        "spatial_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/NOAA-OWP/gval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "geospatial",
        "evaluation",
        "noaa"
      ],
      "id": 15
    },
    {
      "name": "earth2mip",
      "one_line_profile": "Earth-2 Model Intercomparison Project Framework",
      "detailed_description": "A python framework that enables climate researchers and scientists to inter-compare AI models for weather and climate, facilitating standardized inference and scoring.",
      "domains": [
        "Climate",
        "AI4S",
        "E2-06"
      ],
      "subtask_category": [
        "benchmarking",
        "model_intercomparison",
        "ai_inference"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/earth2mip",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-weather",
        "intercomparison",
        "nvidia",
        "earth-2"
      ],
      "id": 16
    },
    {
      "name": "ARMP",
      "one_line_profile": "Atmospheric River Metrics Package",
      "detailed_description": "A package developed by PCMDI for detecting and computing metrics related to Atmospheric Rivers in climate model data.",
      "domains": [
        "Climate",
        "E2-06"
      ],
      "subtask_category": [
        "feature_detection",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PCMDI/ARMP",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "atmospheric-rivers",
        "metrics",
        "pcmdi"
      ],
      "id": 17
    },
    {
      "name": "pcmdi_metrics",
      "one_line_profile": "Climate Model Evaluation Metrics Package",
      "detailed_description": "An open-source Python package for the collective and systematic evaluation of Climate and Earth System Models, providing a suite of standard metrics.",
      "domains": [
        "Climate",
        "E2-06"
      ],
      "subtask_category": [
        "metrics",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PCMDI/pcmdi_metrics",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "metrics",
        "pcmdi",
        "climate-evaluation"
      ],
      "id": 18
    },
    {
      "name": "ClimART",
      "one_line_profile": "Benchmark dataset for ML emulation of atmospheric radiative transfer",
      "detailed_description": "A benchmark dataset designed for Machine Learning emulation of atmospheric radiative transfer in weather and climate models, including data loaders and evaluation protocols.",
      "domains": [
        "Climate",
        "AI4S"
      ],
      "subtask_category": [
        "benchmark",
        "radiative_transfer_emulation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/RolnickLab/climart",
      "help_website": [],
      "license": "CC-BY-4.0",
      "tags": [
        "benchmark",
        "climate",
        "radiative-transfer"
      ],
      "id": 19
    },
    {
      "name": "Stable Audio Metrics",
      "one_line_profile": "Metrics for evaluating music and audio generative models",
      "detailed_description": "A library providing metrics for evaluating music and audio generative models, specifically focusing on long-form, full-band, and stereo generations.",
      "domains": [
        "Audio",
        "AI"
      ],
      "subtask_category": [
        "evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Stability-AI/stable-audio-metrics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "audio",
        "metrics",
        "generative-ai"
      ],
      "id": 20
    },
    {
      "name": "EasyVVUQ",
      "one_line_profile": "Framework for verification, validation and uncertainty quantification",
      "detailed_description": "A Python framework designed to facilitate verification, validation, and uncertainty quantification (VVUQ) for a wide variety of scientific simulations.",
      "domains": [
        "Scientific Computing"
      ],
      "subtask_category": [
        "vvuq",
        "uncertainty_quantification"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/UCL-CCS/EasyVVUQ",
      "help_website": [
        "https://easyvvuq.readthedocs.io"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "vvuq",
        "simulation",
        "uncertainty"
      ],
      "id": 21
    },
    {
      "name": "NWCCompare",
      "one_line_profile": "Hydrologic model comparison functions",
      "detailed_description": "A collection of R functions for comparing hydrologic models, developed by the USGS-R community for hydrological research.",
      "domains": [
        "Hydrology"
      ],
      "subtask_category": [
        "model_comparison",
        "hydrology"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/USGS-R/NWCCompare",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hydrology",
        "model-comparison",
        "usgs"
      ],
      "id": 22
    },
    {
      "name": "TheDiaTo",
      "one_line_profile": "Diagnostics for climate system thermodynamics",
      "detailed_description": "A collection of diagnostics tools for the study of the thermodynamics of the climate system, enabling analysis of energy and entropy budgets.",
      "domains": [
        "Climate"
      ],
      "subtask_category": [
        "diagnostics",
        "thermodynamics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ValerioLembo/TheDiaTo_v1.0",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "climate",
        "thermodynamics",
        "diagnostics"
      ],
      "id": 23
    },
    {
      "name": "Verif",
      "one_line_profile": "Graphical tool for weather forecast verification plots",
      "detailed_description": "A graphical tool and library for creating verification plots of weather forecasts, supporting various metrics and data formats.",
      "domains": [
        "Meteorology"
      ],
      "subtask_category": [
        "verification",
        "visualization"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/WFRT/verif",
      "help_website": [
        "https://verif.readthedocs.io"
      ],
      "license": "NOASSERTION",
      "tags": [
        "weather",
        "verification",
        "visualization"
      ],
      "id": 24
    },
    {
      "name": "Weather-typing",
      "one_line_profile": "Tools for flow-dependent model diagnostics and weather typing",
      "detailed_description": "A set of tools for flow-dependent model diagnostics and general weather typing, developed as part of the NOAA Model Diagnostics Task Force (MDTF).",
      "domains": [
        "Climate",
        "Meteorology"
      ],
      "subtask_category": [
        "diagnostics",
        "weather_typing"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/agmunozs/Weather-typing",
      "help_website": [],
      "license": null,
      "tags": [
        "diagnostics",
        "weather-typing",
        "noaa"
      ],
      "id": 25
    },
    {
      "name": "Distilabel",
      "one_line_profile": "Framework for synthetic data and AI feedback",
      "detailed_description": "A framework for generating synthetic data and creating AI feedback pipelines based on verified research papers, facilitating AI model training and evaluation.",
      "domains": [
        "AI"
      ],
      "subtask_category": [
        "synthetic_data",
        "data_generation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/argilla-io/distilabel",
      "help_website": [
        "https://distilabel.argilla.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "synthetic-data",
        "llm",
        "rlhf"
      ],
      "id": 26
    },
    {
      "name": "BARK",
      "one_line_profile": "Framework for autonomous driving behavior planning simulation",
      "detailed_description": "An open-source framework for the development, simulation, and benchmarking of behavior planning algorithms for autonomous driving systems.",
      "domains": [
        "Robotics",
        "Autonomous Driving"
      ],
      "subtask_category": [
        "simulation",
        "benchmarking"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/bark-simulator/bark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "autonomous-driving",
        "simulation",
        "benchmarking"
      ],
      "id": 27
    },
    {
      "name": "Energym",
      "one_line_profile": "Building simulation library for climate control testing",
      "detailed_description": "A building simulation library designed to test climate control and energy management strategies in a systematic and reproducible way.",
      "domains": [
        "Energy",
        "Engineering"
      ],
      "subtask_category": [
        "simulation",
        "energy_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bsl546/energym",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "simulation",
        "energy",
        "reinforcement-learning"
      ],
      "id": 28
    },
    {
      "name": "wxbtool",
      "one_line_profile": "Toolkit for WeatherBench",
      "detailed_description": "A toolkit based on PyTorch designed to facilitate research, data loading, and benchmarking on the WeatherBench dataset.",
      "domains": [
        "Climate",
        "Meteorology"
      ],
      "subtask_category": [
        "benchmarking",
        "data_loading"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/caiyunapp/wxbtool",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "weatherbench",
        "climate",
        "pytorch"
      ],
      "id": 29
    },
    {
      "name": "fiction",
      "one_line_profile": "Design automation framework for Field-coupled Nanotechnologies",
      "detailed_description": "An open-source design automation framework for Field-coupled Nanotechnologies, enabling physical simulation and design of nanotech circuits.",
      "domains": [
        "Nanotechnology",
        "Physics"
      ],
      "subtask_category": [
        "design_automation",
        "simulation"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/cda-tum/fiction",
      "help_website": [
        "https://fiction.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "nanotechnology",
        "design-automation",
        "fcn"
      ],
      "id": 30
    },
    {
      "name": "climateforcing",
      "one_line_profile": "Tools for analysis of climate model data",
      "detailed_description": "A set of tools for the analysis of climate model data, specifically focusing on calculating and analyzing climate forcing agents.",
      "domains": [
        "Climate"
      ],
      "subtask_category": [
        "data_analysis",
        "climate_forcing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chrisroadmap/climateforcing",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "climate",
        "analysis",
        "forcing"
      ],
      "id": 31
    },
    {
      "name": "Cloud Carbon Footprint",
      "one_line_profile": "Tool to estimate energy use and carbon emissions from cloud usage",
      "detailed_description": "A tool to estimate energy use and carbon emissions from public cloud usage, widely used in sustainable computing research to measure environmental impact.",
      "domains": [
        "Sustainability",
        "Computing"
      ],
      "subtask_category": [
        "carbon_estimation",
        "metrics"
      ],
      "application_level": "application",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/cloud-carbon-footprint/cloud-carbon-footprint",
      "help_website": [
        "https://www.cloudcarbonfootprint.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "sustainability",
        "carbon-footprint",
        "cloud"
      ],
      "id": 32
    },
    {
      "name": "generative-evaluation-prdc",
      "one_line_profile": "Metrics for generative models (Precision, Recall, Density, Coverage)",
      "detailed_description": "A library providing implementations of precision, recall, density, and coverage metrics for evaluating the quality and diversity of generative models.",
      "domains": [
        "AI"
      ],
      "subtask_category": [
        "evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/clovaai/generative-evaluation-prdc",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "generative-models",
        "metrics",
        "evaluation"
      ],
      "id": 33
    },
    {
      "name": "hn2016_falwa",
      "one_line_profile": "Finite-Amplitude Local Wave Activity Diagnostics",
      "detailed_description": "A Python library for computing Finite-Amplitude Local Wave Activity (FALWA) diagnostics from climate data, used for studying atmospheric dynamics.",
      "domains": [
        "Climate"
      ],
      "subtask_category": [
        "diagnostics",
        "wave_activity"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/csyhuang/hn2016_falwa",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "climate",
        "diagnostics",
        "falwa"
      ],
      "id": 34
    },
    {
      "name": "ML Interactive Visualization",
      "one_line_profile": "Interactive visualization of ML model evaluation metrics",
      "detailed_description": "A tool for the interactive visualization of machine learning model evaluation metrics, facilitating model analysis and comparison.",
      "domains": [
        "AI"
      ],
      "subtask_category": [
        "visualization",
        "evaluation"
      ],
      "application_level": "application",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/dhaitz/machine-learning-interactive-visualization",
      "help_website": [],
      "license": null,
      "tags": [
        "visualization",
        "metrics",
        "machine-learning"
      ],
      "id": 35
    },
    {
      "name": "DNNV",
      "one_line_profile": "Framework for Deep Neural Network Verification",
      "detailed_description": "A framework for the formal verification of deep neural networks, allowing researchers to verify properties of neural networks used in scientific applications.",
      "domains": [
        "AI"
      ],
      "subtask_category": [
        "verification",
        "formal_methods"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/dlshriver/dnnv",
      "help_website": [
        "https://dnnv.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "verification",
        "neural-networks",
        "formal-methods"
      ],
      "id": 36
    },
    {
      "name": "Open LLM Leaderboard Report",
      "one_line_profile": "Visualization report of Open LLM model performance",
      "detailed_description": "A tool to generate visualization reports of Open LLM model performance based on various metrics, aiding in the benchmarking and analysis of large language models.",
      "domains": [
        "AI"
      ],
      "subtask_category": [
        "reporting",
        "visualization"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/dsdanielpark/open-llm-leaderboard-report",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "leaderboard",
        "visualization"
      ],
      "id": 37
    },
    {
      "name": "METplus",
      "one_line_profile": "Scripting infrastructure for Model Evaluation Tools",
      "detailed_description": "Python scripting infrastructure for the Model Evaluation Tools (MET) suite, providing a framework for verification and validation of meteorological models.",
      "domains": [
        "Meteorology"
      ],
      "subtask_category": [
        "verification",
        "validation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/dtcenter/METplus",
      "help_website": [
        "https://dtcenter.github.io/METplus"
      ],
      "license": "Apache-2.0",
      "tags": [
        "meteorology",
        "verification",
        "met"
      ],
      "id": 38
    },
    {
      "name": "text-to-image-eval",
      "one_line_profile": "Evaluation metrics for text-to-image and zero-shot classification models",
      "detailed_description": "A library to evaluate custom and HuggingFace text-to-image and zero-shot image classification models using metrics like Zero-shot accuracy, Linear Probe, and Image retrieval.",
      "domains": [
        "Computer Vision",
        "Machine Learning"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/encord-team/text-to-image-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "text-to-image",
        "metrics",
        "clip"
      ],
      "id": 39
    },
    {
      "name": "torch-metrics",
      "one_line_profile": "Metrics for model evaluation in PyTorch",
      "detailed_description": "A collection of metrics for evaluating machine learning models implemented in PyTorch, facilitating standardized performance measurement.",
      "domains": [
        "Machine Learning"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/enochkan/torch-metrics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "metrics",
        "evaluation"
      ],
      "id": 40
    },
    {
      "name": "ESMF",
      "one_line_profile": "Earth System Modeling Framework for high-performance modeling",
      "detailed_description": "The Earth System Modeling Framework (ESMF) is a suite of software tools for developing high-performance, multi-component Earth science modeling applications.",
      "domains": [
        "E2",
        "Climate"
      ],
      "subtask_category": [
        "modeling",
        "simulation"
      ],
      "application_level": "workflow",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/esmf-org/esmf",
      "help_website": [
        "https://earthsystemmodeling.org/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "earth-system-modeling",
        "climate",
        "hpc"
      ],
      "id": 41
    },
    {
      "name": "EvalGIM",
      "one_line_profile": "Evaluation library for generative image models",
      "detailed_description": "EvalGIM enables easy-to-use, reproducible automatic evaluations of text-to-image models and supports customization with user-defined metrics, datasets, and visualizations.",
      "domains": [
        "Computer Vision",
        "Machine Learning"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/EvalGIM",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "generative-models",
        "evaluation",
        "metrics"
      ],
      "id": 42
    },
    {
      "name": "Freva",
      "one_line_profile": "Framework for Exascale Validation of climate models",
      "detailed_description": "The Free Evaluation System Framework (FreVa) is a software infrastructure for standardized evaluation of climate models, facilitating data analysis and result sharing.",
      "domains": [
        "E2",
        "E2-06",
        "Climate"
      ],
      "subtask_category": [
        "model_evaluation",
        "validation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/freva-org/freva-legacy",
      "help_website": [
        "https://www-freva.klimacampus-hamburg.de/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "climate",
        "evaluation",
        "validation",
        "framework"
      ],
      "id": 43
    },
    {
      "name": "long-form-factuality",
      "one_line_profile": "Benchmark for long-form factuality in large language models",
      "detailed_description": "A tool and benchmark for evaluating the long-form factuality of large language models, providing metrics to assess the accuracy of generated content.",
      "domains": [
        "Natural Language Processing",
        "Machine Learning"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/google-deepmind/long-form-factuality",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "factuality",
        "benchmark"
      ],
      "id": 44
    },
    {
      "name": "WeatherBench 2",
      "one_line_profile": "Benchmark for next-generation data-driven global weather models",
      "detailed_description": "A benchmark dataset and evaluation framework for assessing the performance of data-driven global weather forecasting models.",
      "domains": [
        "E2",
        "E2-06",
        "Climate"
      ],
      "subtask_category": [
        "benchmarking",
        "model_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/google-research/weatherbench2",
      "help_website": [
        "https://weatherbench2.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "weather",
        "benchmark",
        "forecasting",
        "metrics"
      ],
      "id": 45
    },
    {
      "name": "WeatherBenchX",
      "one_line_profile": "Modular framework for evaluating weather forecasts",
      "detailed_description": "A modular framework designed for the evaluation of weather forecasts, supporting various metrics and data sources for comprehensive model assessment.",
      "domains": [
        "E2",
        "E2-06",
        "Climate"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google-research/weatherbenchX",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "weather",
        "evaluation",
        "metrics",
        "framework"
      ],
      "id": 46
    },
    {
      "name": "metriks",
      "one_line_profile": "Metrics for evaluating information retrieval models",
      "detailed_description": "A Python package providing commonly used metrics for evaluating the performance of information retrieval models.",
      "domains": [
        "Information Retrieval",
        "Data Science"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/intuit/metriks",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "information-retrieval",
        "metrics",
        "evaluation"
      ],
      "id": 47
    },
    {
      "name": "ATS",
      "one_line_profile": "Spectral modeling system for sound analysis and synthesis",
      "detailed_description": "ATS is a spectral modeling system based on a sinusoidal plus critical-band noise decomposition, using psychoacoustic processing for perceptually accurate sound analysis and synthesis.",
      "domains": [
        "Acoustics",
        "Signal Processing"
      ],
      "subtask_category": [
        "modeling",
        "signal_analysis"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/jamezilla/ats",
      "help_website": [],
      "license": null,
      "tags": [
        "spectral-modeling",
        "psychoacoustics",
        "audio-analysis"
      ],
      "id": 48
    },
    {
      "name": "Hera",
      "one_line_profile": "Keras model training evaluation and dashboard streaming",
      "detailed_description": "A tool to train and evaluate Keras models, streaming metrics to a dashboard in the browser for real-time monitoring and analysis.",
      "domains": [
        "Machine Learning"
      ],
      "subtask_category": [
        "model_evaluation",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/keplr-io/hera",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "keras",
        "dashboard",
        "metrics",
        "evaluation"
      ],
      "id": 49
    },
    {
      "name": "dgm-eval",
      "one_line_profile": "Evaluation metrics for deep generative models",
      "detailed_description": "Codebase for evaluating deep generative models, focusing on exposing flaws in existing metrics and providing fairer treatment for diffusion models.",
      "domains": [
        "Machine Learning",
        "Generative AI"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/layer6ai-labs/dgm-eval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "generative-models",
        "evaluation",
        "metrics"
      ],
      "id": 50
    },
    {
      "name": "Deception Benchmark",
      "one_line_profile": "Benchmark for evaluating LLMs on disinformation creation and resistance",
      "detailed_description": "A benchmark tool for evaluating Large Language Models (LLMs) on their ability to create and resist disinformation, including standardized evaluation metrics.",
      "domains": [
        "AI Safety",
        "Natural Language Processing"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/lechmazur/deception",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "benchmark",
        "disinformation",
        "safety"
      ],
      "id": 51
    },
    {
      "name": "t2v_metrics",
      "one_line_profile": "VQAScore for evaluating text-to-image/video/3D models",
      "detailed_description": "A library for evaluating text-to-image, text-to-video, and text-to-3D models using VQAScore, a metric based on Visual Question Answering.",
      "domains": [
        "Computer Vision",
        "Machine Learning"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/linzhiqiu/t2v_metrics",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "metrics",
        "text-to-video",
        "vqascore"
      ],
      "id": 52
    },
    {
      "name": "torcheval",
      "one_line_profile": "Performant model metrics and evaluation tools for PyTorch",
      "detailed_description": "A library containing a rich collection of performant PyTorch model metrics, a simple interface to create new metrics, and tools for distributed training evaluation.",
      "domains": [
        "Machine Learning"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/meta-pytorch/torcheval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "pytorch",
        "metrics",
        "evaluation"
      ],
      "id": 53
    },
    {
      "name": "WeatherReal-Benchmark",
      "one_line_profile": "Evaluation pipelines for WeatherReal benchmark dataset",
      "detailed_description": "Evaluation pipelines and components to support the WeatherReal benchmark dataset for verifying weather forecasts.",
      "domains": [
        "E2",
        "E2-06",
        "Climate"
      ],
      "subtask_category": [
        "benchmarking",
        "verification"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/WeatherReal-Benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "weather",
        "benchmark",
        "verification"
      ],
      "id": 54
    },
    {
      "name": "ai-agent-evals",
      "one_line_profile": "Evaluation of AI agent applications using model-as-judge",
      "detailed_description": "A tool to evaluate AI agent applications using model-as-a-judge, content safety, and mathematical metrics.",
      "domains": [
        "Artificial Intelligence"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/ai-agent-evals",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ai-agents",
        "evaluation",
        "metrics"
      ],
      "id": 55
    },
    {
      "name": "Table Transformer",
      "one_line_profile": "Deep learning model for extracting tables from unstructured documents",
      "detailed_description": "Table Transformer (TATR) is a deep learning model for extracting tables from unstructured documents (PDFs and images), including the GriTS evaluation metric.",
      "domains": [
        "Data Science",
        "Document Analysis"
      ],
      "subtask_category": [
        "data_extraction",
        "structure_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/table-transformer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "table-extraction",
        "deep-learning",
        "pdf-processing"
      ],
      "id": 56
    },
    {
      "name": "scores",
      "one_line_profile": "Metrics for verification and evaluation of forecasts and models",
      "detailed_description": "A library of metrics for the verification, evaluation, and optimisation of forecasts, predictions, or models, particularly in climate and weather domains.",
      "domains": [
        "E2",
        "E2-06",
        "Climate"
      ],
      "subtask_category": [
        "model_evaluation",
        "verification"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/nci/scores",
      "help_website": [
        "https://scores.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "verification",
        "metrics",
        "forecasting",
        "climate"
      ],
      "id": 57
    },
    {
      "name": "WeatherBench",
      "one_line_profile": "Benchmark dataset and baseline models for data-driven weather forecasting",
      "detailed_description": "A benchmark dataset for evaluating data-driven weather forecasting models, providing regridded ERA5 data and baseline evaluation metrics to facilitate model comparison.",
      "domains": [
        "Climate",
        "Meteorology"
      ],
      "subtask_category": [
        "weather_forecasting",
        "benchmarking",
        "model_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/pangeo-data/WeatherBench",
      "help_website": [
        "https://github.com/pangeo-data/WeatherBench"
      ],
      "license": "MIT",
      "tags": [
        "weather-forecasting",
        "benchmark",
        "era5",
        "deep-learning"
      ],
      "id": 58
    },
    {
      "name": "climpred",
      "one_line_profile": "Verification and analysis framework for weather and climate forecasts",
      "detailed_description": "A python package for the verification of weather and climate forecasts, offering a comprehensive set of metrics and alignment tools for comparing prediction ensembles with observations.",
      "domains": [
        "Climate",
        "Meteorology"
      ],
      "subtask_category": [
        "forecast_verification",
        "metrics_calculation",
        "prediction_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pangeo-data/climpred",
      "help_website": [
        "https://climpred.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "verification",
        "climate-prediction",
        "metrics",
        "xarray"
      ],
      "id": 59
    },
    {
      "name": "CliMT",
      "one_line_profile": "Climate modelling and diagnostics toolkit (Legacy)",
      "detailed_description": "A toolkit for climate modeling and diagnostics, providing a Python interface to various climate codes and radiation models. (Note: This is the legacy version).",
      "domains": [
        "Climate"
      ],
      "subtask_category": [
        "climate_modeling",
        "radiation_transfer",
        "diagnostics"
      ],
      "application_level": "library",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/rodrigo-caballero/CliMT-legacy",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "climate-models",
        "radiation",
        "convection",
        "python-wrapper"
      ],
      "id": 60
    },
    {
      "name": "ILAMB",
      "one_line_profile": "International Land Model Benchmarking package",
      "detailed_description": "A python package for the International Land Model Benchmarking (ILAMB) project, used to evaluate and benchmark land surface models against observational data.",
      "domains": [
        "Climate",
        "Ecology"
      ],
      "subtask_category": [
        "model_benchmarking",
        "land_surface_modeling",
        "model_evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/rubisco-sfa/ILAMB",
      "help_website": [
        "https://www.ilamb.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "benchmarking",
        "land-model",
        "cmip",
        "evaluation"
      ],
      "id": 61
    },
    {
      "name": "climetrics",
      "one_line_profile": "R package for calculating climate change metrics",
      "detailed_description": "An R package designed to calculate various climate change metrics and indices to support climate analysis and impact assessment.",
      "domains": [
        "Climate"
      ],
      "subtask_category": [
        "metrics_calculation",
        "climate_indices"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/shirintaheri/climetrics",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "climate-change",
        "metrics",
        "r-package"
      ],
      "id": 62
    },
    {
      "name": "xCDAT",
      "one_line_profile": "Xarray extension for climate data analysis on structured grids",
      "detailed_description": "xCDAT (Xarray Climate Data Analysis Tools) is an extension of xarray designed for climate data analysis on structured grids. It serves as a modern successor to the Community Data Analysis Tools (CDAT), providing optimized functions for spatial and temporal averaging, climatology calculation, and regridding, fully integrated with the Pangeo ecosystem.",
      "domains": [
        "E2",
        "E2-06"
      ],
      "subtask_category": [
        "climate_analysis",
        "regridding",
        "spatial_averaging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/xCDAT/xcdat",
      "help_website": [
        "https://xcdat.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "climate-data",
        "xarray",
        "geoscience",
        "pangeo"
      ],
      "id": 63
    },
    {
      "name": "xskillscore",
      "one_line_profile": "Metrics for verifying weather and climate forecasts using xarray",
      "detailed_description": "xskillscore is a Python package for verifying forecasts and hindcasts against observations. It provides a comprehensive suite of deterministic and probabilistic metrics (e.g., RMSE, Pearson correlation, CRPS) specifically designed to work with xarray DataArrays and Datasets, enabling efficient, parallelized verification of high-dimensional weather and climate model outputs.",
      "domains": [
        "E2",
        "E2-06"
      ],
      "subtask_category": [
        "forecast_verification",
        "metrics_calculation",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/xarray-contrib/xskillscore",
      "help_website": [
        "https://xskillscore.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "verification",
        "metrics",
        "weather-forecast",
        "climate-models"
      ],
      "id": 64
    }
  ]
}