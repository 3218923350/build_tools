{
  "generated_at": "2025-12-16T02:13:14.871989+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "C1",
      "leaf_cluster_name": "化学信息-分子表示与检索生态",
      "domain": "Chemistry",
      "typical_objects": "SMILES/InChI, graphs",
      "task_chain": "标准化→指纹/embedding→检索→评测",
      "tool_form": "表示库 + 向量检索 + index"
    },
    "unit": {
      "unit_id": "C1-05",
      "unit_name": "AI分子表示（foundation/SSL）",
      "target_scale": "200–450",
      "coverage_tools": "graph transformers、pretraining kits"
    },
    "search": {
      "target_candidates": 450,
      "queries": [
        "[GH] Dig",
        "[GH] MolFormer",
        "[GH] DGL-LifeSci",
        "[GH] GraphMVP",
        "[GH] Uni-Mol",
        "[GH] MolCLR",
        "[GH] GROVER",
        "[GH] ChemBERTa",
        "[GH] DeepChem",
        "[GH] molecular representation learning",
        "[GH] graph transformer molecule",
        "[GH] molecular pretraining",
        "[GH] self-supervised molecular graphs",
        "[GH] smiles transformer",
        "[GH] chemical language model",
        "[GH] molecular embedding",
        "[GH] graph contrastive learning chemistry",
        "[GH] molecular foundation model",
        "[GH] geometric deep learning molecule",
        "[GH] molecular graph encoder",
        "[GH] masked graph modeling",
        "[WEB] molecular representation learning framework github",
        "[WEB] self-supervised learning molecular graphs github",
        "[WEB] graph transformer for chemistry github",
        "[WEB] molecular foundation models survey github",
        "[WEB] pretrained molecular models github"
      ],
      "total_candidates": 689,
      "tool_candidates": 294,
      "final_tools": 78
    }
  },
  "tools": [
    {
      "name": "SigDigger",
      "one_line_profile": "Qt-based digital signal analyzer for signal processing and reverse engineering",
      "detailed_description": "A digital signal analyzer that allows users to inspect, analyze, and reverse engineer digital signals. It supports various DSP operations and visualization of signal data.",
      "domains": [
        "Signal Processing",
        "Physics"
      ],
      "subtask_category": [
        "signal_analysis",
        "visualization"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/BatchDrake/SigDigger",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "dsp",
        "signal-analysis",
        "sdr"
      ],
      "id": 1
    },
    {
      "name": "SMILES2PropertiesTransformer",
      "one_line_profile": "Transformer-based model for predicting chemical properties from SMILES",
      "detailed_description": "An implementation of a transformer model designed to predict limiting activity coefficients and other properties directly from SMILES strings using natural language processing techniques.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "property_prediction",
        "molecular_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Bene94/SMILES2PropertiesTransformer",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "smiles",
        "transformer",
        "property-prediction"
      ],
      "id": 2
    },
    {
      "name": "MMELON",
      "one_line_profile": "Multi-view Molecular Embedding with Late Fusion architecture",
      "detailed_description": "Implementation of the MMELON architecture which combines molecular representations from image, graph, and text views to learn a joint embedding for downstream chemical and biological property prediction.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "property_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/BiomedSciAI/biomed-multi-view",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "molecular-embedding",
        "deep-learning"
      ],
      "id": 3
    },
    {
      "name": "PCMol",
      "one_line_profile": "Multi-target de novo molecular generator conditioned on protein embeddings",
      "detailed_description": "A deep learning tool for de novo molecular generation that conditions the generation process on AlphaFold's latent protein embeddings to target specific protein structures.",
      "domains": [
        "C1",
        "C1-05",
        "Bioinformatics"
      ],
      "subtask_category": [
        "de_novo_design",
        "molecular_generation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/CDDLeiden/PCMol",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "drug-design",
        "generative-model",
        "alphafold"
      ],
      "id": 4
    },
    {
      "name": "RxnIM",
      "one_line_profile": "Multimodal Large Language Model for chemical reaction image parsing",
      "detailed_description": "A tool leveraging a multimodal Large Language Model to parse chemical reaction images and convert them into structured data formats.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "image_parsing",
        "reaction_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CYF2000127/RxnIM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "optical-chemical-structure-recognition",
        "llm",
        "reaction-parsing"
      ],
      "id": 5
    },
    {
      "name": "SMILES Transformer",
      "one_line_profile": "Pre-trained molecular fingerprinting using SMILES transformers",
      "detailed_description": "Implementation of a transformer-based model for unsupervised learning of molecular representations from SMILES strings, useful for low-data drug discovery tasks.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "fingerprinting"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/DSPsleeporg/smiles-transformer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "smiles",
        "transformer",
        "representation-learning"
      ],
      "id": 6
    },
    {
      "name": "u-signal3D",
      "one_line_profile": "Computational platform for analyzing molecular organization at the cell surface",
      "detailed_description": "A computational tool that defines shape-invariant representations of spatial scales of molecular organization, enabling comparison and machine learning of signaling across diverse cell populations.",
      "domains": [
        "Biology",
        "Bioinformatics"
      ],
      "subtask_category": [
        "image_analysis",
        "molecular_organization"
      ],
      "application_level": "platform",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/DanuserLab/u-signal3D",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "microscopy",
        "cell-signaling",
        "3d-analysis"
      ],
      "id": 7
    },
    {
      "name": "MaskGAE",
      "one_line_profile": "Masked Graph Modeling for Graph Autoencoders",
      "detailed_description": "A self-supervised learning framework for graph data that uses masked graph modeling to improve graph autoencoders, applicable to molecular graph representation learning.",
      "domains": [
        "C1",
        "C1-05",
        "Machine Learning"
      ],
      "subtask_category": [
        "graph_learning",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/EdisonLeeeee/MaskGAE",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "graph-neural-networks",
        "self-supervised-learning",
        "masked-modeling"
      ],
      "id": 8
    },
    {
      "name": "MolFlux",
      "one_line_profile": "Foundational package for molecular predictive modelling",
      "detailed_description": "A library developed by Exscientia for building, training, and evaluating molecular predictive models, serving as a foundation for drug discovery workflows.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "predictive_modeling",
        "drug_discovery"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Exscientia/molflux",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "drug-discovery",
        "machine-learning",
        "molecular-modeling"
      ],
      "id": 9
    },
    {
      "name": "iMoLD",
      "one_line_profile": "Learning Invariant Molecular Representation in Latent Discrete Space",
      "detailed_description": "A framework for learning invariant molecular representations using a latent discrete space, designed to improve molecular property prediction and generation tasks.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "representation_learning",
        "molecular_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HICAI-ZJU/iMoLD",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "molecular-representation",
        "invariant-learning",
        "neurips"
      ],
      "id": 10
    },
    {
      "name": "DrugGEN",
      "one_line_profile": "Target Specific De Novo Design of Drug Candidate Molecules",
      "detailed_description": "A graph transformer-based generative adversarial network for the target-specific de novo design of drug candidate molecules.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "de_novo_design",
        "molecular_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HUBioDataLab/DrugGEN",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "drug-design",
        "generative-adversarial-network",
        "graph-transformer"
      ],
      "id": 11
    },
    {
      "name": "SELFormer",
      "one_line_profile": "Molecular Representation Learning via SELFIES Language Models",
      "detailed_description": "A chemical language model based on SELFIES representation for molecular representation learning, enabling effective downstream property prediction.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "representation_learning",
        "language_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HUBioDataLab/SELFormer",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "selfies",
        "chemical-language-model",
        "transformer"
      ],
      "id": 12
    },
    {
      "name": "EquiBind",
      "one_line_profile": "Geometric deep learning for fast 3D molecular docking",
      "detailed_description": "A geometric deep learning model for fast and accurate prediction of the 3D structure of small molecule-protein complexes (docking).",
      "domains": [
        "C1",
        "Bioinformatics"
      ],
      "subtask_category": [
        "molecular_docking",
        "structure_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HannesStark/EquiBind",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "docking",
        "geometric-deep-learning",
        "protein-ligand"
      ],
      "id": 13
    },
    {
      "name": "VideoMol",
      "one_line_profile": "Molecular Video-derived Foundation Model for Drug Discovery",
      "detailed_description": "A foundation model that leverages molecular videos to learn representations for scientific drug discovery tasks.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "foundation_model",
        "drug_discovery"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HongxinXiang/VideoMol",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "foundation-model",
        "molecular-video",
        "drug-discovery"
      ],
      "id": 14
    },
    {
      "name": "MolFormer",
      "one_line_profile": "Large-scale chemical language model for molecular representation",
      "detailed_description": "A large-scale chemical language model developed by IBM designed to learn molecular representations from SMILES strings for various downstream tasks.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "foundation_model",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/IBM/molformer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "chemical-language-model",
        "transformer",
        "ibm"
      ],
      "id": 15
    },
    {
      "name": "DECIMER Image Transformer",
      "one_line_profile": "Automated recognition of chemical structure images to SMILES",
      "detailed_description": "A deep learning tool that converts images of chemical structures into SMILES strings, enabling the digitization of chemical data from literature and patents.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "optical_chemical_structure_recognition",
        "image_to_smiles"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Kohulan/DECIMER-Image_Transformer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ocsr",
        "image-recognition",
        "smiles"
      ],
      "id": 16
    },
    {
      "name": "UnityMol",
      "one_line_profile": "Molecular viewer and visualization software for biological macromolecules",
      "detailed_description": "UnityMol is a molecular viewer and visualization prototyping platform developed using the Unity game engine. It supports high-quality rendering of molecular structures, electrostatic potential maps, and other chemical data, providing immersive visualization capabilities for structural biology and chemistry.",
      "domains": [
        "C1"
      ],
      "subtask_category": [
        "molecular_visualization",
        "structural_analysis"
      ],
      "application_level": "solver",
      "primary_language": "C#",
      "repo_url": "https://github.com/LBT-CNRS/UnityMol-Releases",
      "help_website": [
        "http://unitymol.sourceforge.net"
      ],
      "license": "NOASSERTION",
      "tags": [
        "visualization",
        "molecular-graphics",
        "unity3d",
        "structural-biology"
      ],
      "id": 17
    },
    {
      "name": "MolBART",
      "one_line_profile": "Transformer-based molecular representation model for SMILES transformation",
      "detailed_description": "MolBART is a pre-trained sequence-to-sequence transformer model designed for molecular SMILES transformation tasks. Developed by MolecularAI (AstraZeneca), it utilizes the BART architecture to learn continuous molecular representations, enabling fine-tuning for diverse downstream tasks in drug discovery such as property prediction and reaction prediction.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "property_prediction",
        "smiles_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MolecularAI/MolBART",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "transformer",
        "smiles",
        "drug-discovery",
        "pretraining"
      ],
      "id": 18
    },
    {
      "name": "KERMT",
      "one_line_profile": "Pretrained graph neural network for molecular property prediction",
      "detailed_description": "KERMT is a deep learning model developed by NVIDIA Digital Bio that utilizes graph neural networks (GNNs) for molecular representation learning. It is pre-trained on large-scale molecular datasets to provide high-quality embeddings for downstream molecular property prediction tasks.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "property_prediction",
        "molecular_representation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA-Digital-Bio/KERMT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gnn",
        "molecular-property",
        "nvidia",
        "deep-learning"
      ],
      "id": 19
    },
    {
      "name": "ChemDFM",
      "one_line_profile": "Dialogue foundation model for chemistry and molecular science",
      "detailed_description": "ChemDFM is an open-source large language model (LLM) specifically fine-tuned for the chemistry domain. It is designed to handle dialogue-based tasks involving chemical knowledge, molecular understanding, and scientific reasoning, bridging the gap between general LLMs and specialized chemical tasks.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "text_generation",
        "molecular_reasoning",
        "knowledge_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenDFM/ChemDFM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "chemistry",
        "foundation-model",
        "nlp"
      ],
      "id": 20
    },
    {
      "name": "CD-GPT",
      "one_line_profile": "Biological foundation model bridging molecular sequences via Central Dogma",
      "detailed_description": "CD-GPT is a biological foundation model developed by Tencent AI4S that aims to bridge the gap between different molecular sequences (DNA, RNA, Protein) following the Central Dogma of biology. It facilitates cross-modal representation learning and generation tasks in bioinformatics and molecular biology.",
      "domains": [
        "C1-05"
      ],
      "subtask_category": [
        "sequence_modeling",
        "molecular_generation",
        "cross_modal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TencentAI4S/CD-GPT",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "foundation-model",
        "central-dogma",
        "bioinformatics",
        "tencent"
      ],
      "id": 21
    },
    {
      "name": "GeminiMol",
      "one_line_profile": "Conformational space-aware molecular representation learning tool",
      "detailed_description": "GeminiMol is a molecular representation learning tool that incorporates conformational space profiles into the embedding process. It is designed to support various drug discovery tasks, including virtual screening, target identification, and QSAR modeling, by providing geometrically aware molecular descriptors.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "virtual_screening",
        "qsar"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Wang-Lin-boop/GeminiMol",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "conformation",
        "drug-discovery",
        "representation-learning"
      ],
      "id": 22
    },
    {
      "name": "HiMolformer",
      "one_line_profile": "Hybrid GNN and Transformer model for predicting liver microsome stability using SMILES",
      "detailed_description": "A hybrid deep learning model that combines Graph Neural Networks (GNN) and Transformer architectures to process molecular representations (SMILES) for predicting liver microsome stability, a key pharmacokinetic property.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "property_prediction",
        "molecular_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/YUNSEOKWOO/HiMolformer",
      "help_website": [],
      "license": null,
      "tags": [
        "gnn",
        "transformer",
        "smiles",
        "admet"
      ],
      "id": 23
    },
    {
      "name": "MoleBlend",
      "one_line_profile": "Multimodal molecular pretraining framework via modality blending",
      "detailed_description": "Implementation of the ICLR 2024 paper 'Multimodal Molecular Pretraining via Modality Blending'. It provides a framework for pretraining molecular representations by blending different modalities (e.g., graphs, text) to enhance downstream task performance.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/YudiZh/MoleBlend",
      "help_website": [
        "https://openreview.net/forum?id=..."
      ],
      "license": null,
      "tags": [
        "multimodal",
        "pretraining",
        "molecular-graph"
      ],
      "id": 24
    },
    {
      "name": "SmileCode",
      "one_line_profile": "Deformable image registration tool using Motion Decomposition Transformer",
      "detailed_description": "Code for the MICCAI 2023 paper 'ModeT', focusing on learning deformable image registration via a Motion Decomposition Transformer. While the lab name contains 'SMILE', the tool is for medical image analysis.",
      "domains": [
        "Medical Imaging"
      ],
      "subtask_category": [
        "image_registration",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ZAX130/SmileCode",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-imaging",
        "transformer",
        "registration"
      ],
      "id": 25
    },
    {
      "name": "MSformer",
      "one_line_profile": "Molecular representation framework via meta structures",
      "detailed_description": "A deep learning framework for molecular representation learning that utilizes meta-structures to capture complex molecular patterns and dependencies.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "graph_learning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ZJUFanLab/MSformer",
      "help_website": [],
      "license": null,
      "tags": [
        "molecular-graph",
        "transformer",
        "representation-learning"
      ],
      "id": 26
    },
    {
      "name": "HM-GNN",
      "one_line_profile": "Molecular representation learning via Heterogeneous Motif Graph Neural Networks",
      "detailed_description": "Official PyTorch implementation of HM-GNN, a method for learning molecular representations by leveraging heterogeneous motif graphs to capture multi-scale structural information.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "graph_neural_networks"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ZhaoningYu1996/HM-GNN",
      "help_website": [],
      "license": null,
      "tags": [
        "gnn",
        "motif",
        "molecular-graph"
      ],
      "id": 27
    },
    {
      "name": "bertify-umls",
      "one_line_profile": "Toolkit for training BERT models on UMLS knowledge graph and corpora",
      "detailed_description": "A toolkit designed to jointly train BERT encoder models on the UMLS metathesaurus knowledge graph and free-text corpora, enabling graph-based reasoning tasks alongside masked language modeling for biomedical informatics.",
      "domains": [
        "Biomedical Informatics"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/a-mannion/bertify-umls",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bert",
        "umls",
        "knowledge-graph"
      ],
      "id": 28
    },
    {
      "name": "MCGLPPI",
      "one_line_profile": "Protein-protein complex property prediction using coarse-grained models",
      "detailed_description": "Integration of molecular coarse-grained models into a geometric representation learning framework for predicting properties of protein-protein complexes.",
      "domains": [
        "Biology",
        "C1"
      ],
      "subtask_category": [
        "property_prediction",
        "protein_interaction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/arantir123/MCGLPPI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-protein-interaction",
        "geometric-deep-learning",
        "coarse-grained"
      ],
      "id": 29
    },
    {
      "name": "WebPlotDigitizer",
      "one_line_profile": "Tool to extract numerical data from plot images",
      "detailed_description": "A web-based tool that uses computer vision techniques to extract underlying numerical data from images of plots and charts, widely used for data recovery in scientific research.",
      "domains": [
        "General Science"
      ],
      "subtask_category": [
        "data_extraction",
        "digitization"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/automeris-io/WebPlotDigitizer",
      "help_website": [
        "https://automeris.io/WebPlotDigitizer"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "data-extraction",
        "computer-vision",
        "plots"
      ],
      "id": 30
    },
    {
      "name": "DGL-LifeSci",
      "one_line_profile": "Graph neural networks package for chemistry and biology",
      "detailed_description": "A DGL-based package for applying graph neural networks to tasks in chemistry and biology, including molecular property prediction, generative models, and reaction prediction.",
      "domains": [
        "C1",
        "C1-05",
        "Biology"
      ],
      "subtask_category": [
        "molecular_modeling",
        "graph_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/awslabs/dgl-lifesci",
      "help_website": [
        "https://lifesci.dgl.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "gnn",
        "drug-discovery",
        "bioinformatics"
      ],
      "id": 31
    },
    {
      "name": "MolRep",
      "one_line_profile": "Deep representation learning library for molecular property prediction",
      "detailed_description": "A comprehensive library for deep molecular representation learning, providing various state-of-the-art models for predicting molecular properties.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "property_prediction",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/biomed-AI/MolRep",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "molecular-representation",
        "deep-learning",
        "qsar"
      ],
      "id": 32
    },
    {
      "name": "Carmen",
      "one_line_profile": "Context-aware safe medication recommendation system",
      "detailed_description": "Implementation of the AAAI-23 paper 'Carmen', a system for safe medication recommendations that utilizes molecular graph and drug-drug interaction (DDI) graph embeddings.",
      "domains": [
        "Healthcare",
        "C1"
      ],
      "subtask_category": [
        "medication_recommendation",
        "interaction_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bit1029public/Carmen",
      "help_website": [],
      "license": null,
      "tags": [
        "healthcare",
        "graph-embedding",
        "drug-interaction"
      ],
      "id": 33
    },
    {
      "name": "virtues",
      "one_line_profile": "Foundation model framework for multiplexed tissue imaging data",
      "detailed_description": "A framework for analyzing multiplexed tissue imaging data across molecular, cellular, and tissue scales, facilitating clinical diagnostics and biological discovery.",
      "domains": [
        "Biology",
        "Bioimaging"
      ],
      "subtask_category": [
        "image_analysis",
        "tissue_modeling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/bunnelab/virtues",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "spatial-biology",
        "tissue-imaging",
        "foundation-model"
      ],
      "id": 34
    },
    {
      "name": "Dendriform.jl",
      "one_line_profile": "Algorithms for dendriform di-algebras and planar binary trees",
      "detailed_description": "A Julia library for computing with Loday's arithmetic on groves of planar binary trees using dendriform di-algebra algorithms, useful in algebraic combinatorics and related mathematical fields.",
      "domains": [
        "Mathematics"
      ],
      "subtask_category": [
        "algebraic_computation",
        "combinatorics"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/chakravala/Dendriform.jl",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "algebra",
        "julia",
        "combinatorics"
      ],
      "id": 35
    },
    {
      "name": "NovoMolGen",
      "one_line_profile": "Molecular language model pretraining framework",
      "detailed_description": "Code for the paper 'NovoMolGen: Rethinking Molecular Language Model Pretraining', providing methods for generative pretraining of molecular language models.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_generation",
        "pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chandar-lab/NovoMolGen",
      "help_website": [],
      "license": null,
      "tags": [
        "language-model",
        "generative-model",
        "drug-design"
      ],
      "id": 36
    },
    {
      "name": "GeoSSL",
      "one_line_profile": "Molecular geometry pretraining with SE(3)-invariant denoising",
      "detailed_description": "Implementation of GeoSSL (ICLR'23), a self-supervised learning framework for molecular geometry pretraining using SE(3)-invariant denoising distance matching.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "pretraining",
        "geometric_deep_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chao1224/GeoSSL",
      "help_website": [
        "https://openreview.net/forum?id=CjTHVo1dvR"
      ],
      "license": "MIT",
      "tags": [
        "self-supervised-learning",
        "molecular-geometry",
        "se3-invariance"
      ],
      "id": 37
    },
    {
      "name": "GraphMVP",
      "one_line_profile": "Pre-training molecular graph representation with 3D geometry",
      "detailed_description": "Implementation of GraphMVP (ICLR'22), a framework for pre-training molecular graph representations by incorporating 3D geometric information.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "pretraining",
        "molecular_representation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chao1224/GraphMVP",
      "help_website": [
        "https://openreview.net/forum?id=xQUe1pOKPam"
      ],
      "license": "MIT",
      "tags": [
        "graph-neural-networks",
        "3d-geometry",
        "pretraining"
      ],
      "id": 38
    },
    {
      "name": "qcf",
      "one_line_profile": "Quantum computing functions toolbox for Octave/Matlab",
      "detailed_description": "A toolbox for simulating quantum computing algorithms (e.g., Grover, Deutsch) based on Nielsen & Chuang's textbook, compatible with Octave and Matlab.",
      "domains": [
        "Physics",
        "Quantum Computing"
      ],
      "subtask_category": [
        "quantum_simulation",
        "algorithm_simulation"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/charles-fox/qcf",
      "help_website": [],
      "license": null,
      "tags": [
        "quantum-computing",
        "simulation",
        "matlab"
      ],
      "id": 39
    },
    {
      "name": "CombinatorialAuctions",
      "one_line_profile": "Implementation of combinatorial auction protocols (VCG, Groves)",
      "detailed_description": "A library implementing and evaluating combinatorial auction protocols such as VCG and Groves mechanisms, useful for economic modeling and algorithmic game theory research.",
      "domains": [
        "Economics",
        "Computer Science"
      ],
      "subtask_category": [
        "economic_modeling",
        "mechanism_design"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/clu8/CombinatorialAuctions",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "auction-theory",
        "mechanism-design",
        "algorithms"
      ],
      "id": 40
    },
    {
      "name": "PromptSMILES",
      "one_line_profile": "Scaffold decoration and fragment linking with chemical language models",
      "detailed_description": "A tool for controlled molecular generation, specifically scaffold decoration and fragment linking, using chemical language models and reinforcement learning.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_generation",
        "fragment_linking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/compsciencelab/PromptSMILES",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reinforcement-learning",
        "drug-design",
        "smiles"
      ],
      "id": 41
    },
    {
      "name": "ePMV",
      "one_line_profile": "Embedded Python Molecular Viewer for 3D animation hosts",
      "detailed_description": "Runs molecular modeling software directly inside professional 3D animation applications (like Blender, Maya) to visualize and manipulate molecular structures.",
      "domains": [
        "Biology",
        "Chemistry"
      ],
      "subtask_category": [
        "molecular_visualization",
        "structural_biology"
      ],
      "application_level": "plugin",
      "primary_language": "Python",
      "repo_url": "https://github.com/corredD/ePMV",
      "help_website": [
        "http://epmv.scripps.edu"
      ],
      "license": "GPL-3.0",
      "tags": [
        "visualization",
        "molecular-modeling",
        "3d-animation"
      ],
      "id": 42
    },
    {
      "name": "molsetrep",
      "one_line_profile": "Molecular set representation learning library",
      "detailed_description": "A library for learning representations of sets of molecules, enabling tasks that involve analyzing collections or distributions of chemical structures.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "representation_learning",
        "set_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/daenuprobst/molsetrep",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "molecular-set",
        "deep-learning",
        "cheminformatics"
      ],
      "id": 43
    },
    {
      "name": "TreeExtra",
      "one_line_profile": "Additive Groves and Bagged Trees implementation",
      "detailed_description": "Implementation of Additive Groves and Bagged Trees algorithms, including tools for feature evaluation, interaction detection, and visualization of feature effects in statistical learning.",
      "domains": [
        "Data Science"
      ],
      "subtask_category": [
        "statistical_learning",
        "feature_analysis"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/dariasor/TreeExtra",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "machine-learning",
        "decision-trees",
        "feature-interaction"
      ],
      "id": 44
    },
    {
      "name": "DeepChem",
      "one_line_profile": "Deep learning library for drug discovery, materials science, and biology",
      "detailed_description": "A comprehensive deep learning library specifically designed for life sciences, providing tools for molecular machine learning, drug discovery, quantum chemistry, and materials science.",
      "domains": [
        "C1",
        "C1-05",
        "Materials Science",
        "Biology"
      ],
      "subtask_category": [
        "molecular_modeling",
        "property_prediction",
        "drug_discovery"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepchem/deepchem",
      "help_website": [
        "https://deepchem.io"
      ],
      "license": "MIT",
      "tags": [
        "deep-learning",
        "drug-discovery",
        "cheminformatics"
      ],
      "id": 45
    },
    {
      "name": "DeepChem GUI",
      "one_line_profile": "Web-based graphical user interface for DeepChem",
      "detailed_description": "A simple web-based graphical user interface to facilitate the use of DeepChem models and tools without extensive coding.",
      "domains": [
        "C1"
      ],
      "subtask_category": [
        "gui",
        "molecular_modeling"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/deepchem/deepchem-gui",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gui",
        "deepchem",
        "web-interface"
      ],
      "id": 46
    },
    {
      "name": "ChemBERTa-3",
      "one_line_profile": "ChemBERTa-3 molecular language model repository",
      "detailed_description": "Repository for ChemBERTa-3, a transformer-based molecular language model for chemical representation learning and property prediction.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepforestsci/chemberta3",
      "help_website": [],
      "license": null,
      "tags": [
        "transformer",
        "smiles",
        "language-model"
      ],
      "id": 47
    },
    {
      "name": "Uni-Mol",
      "one_line_profile": "Universal 3D molecular representation learning framework",
      "detailed_description": "Official repository for Uni-Mol, a universal 3D molecular representation learning framework that can be applied to various tasks in drug design and materials science.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "3d_structure_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepmodeling/Uni-Mol",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "3d-representation",
        "pretraining",
        "molecular-modeling"
      ],
      "id": 48
    },
    {
      "name": "DeepMD-kit",
      "one_line_profile": "Deep learning package for many-body potential energy and MD",
      "detailed_description": "A deep learning package for generating accurate many-body potential energy surfaces and performing molecular dynamics simulations, bridging quantum mechanics accuracy with classical MD efficiency.",
      "domains": [
        "Physics",
        "Chemistry",
        "Materials Science"
      ],
      "subtask_category": [
        "molecular_dynamics",
        "potential_energy_surface"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepmodeling/deepmd-kit",
      "help_website": [
        "http://www.deepmd.org/"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "molecular-dynamics",
        "deep-potential",
        "simulation"
      ],
      "id": 49
    },
    {
      "name": "DIG",
      "one_line_profile": "Library for graph deep learning research",
      "detailed_description": "A comprehensive library for graph deep learning research, including modules for graph generation, explanation, and 3D graph learning, widely applicable in scientific domains like chemistry.",
      "domains": [
        "C1",
        "C1-05",
        "Computer Science"
      ],
      "subtask_category": [
        "graph_learning",
        "explainable_ai"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/divelab/DIG",
      "help_website": [
        "https://diveintographs.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "graph-neural-networks",
        "xai",
        "research-library"
      ],
      "id": 50
    },
    {
      "name": "Evo",
      "one_line_profile": "Biological foundation modeling from molecular to genome scale",
      "detailed_description": "A genomic foundation model capable of generating DNA, RNA, and protein sequences, enabling prediction and design tasks across molecular biology scales.",
      "domains": [
        "Biology",
        "Genomics",
        "C1-05"
      ],
      "subtask_category": [
        "sequence_generation",
        "structure_prediction",
        "foundation_model"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/evo-design/evo",
      "help_website": [
        "https://github.com/evo-design/evo"
      ],
      "license": "Apache-2.0",
      "tags": [
        "genomics",
        "foundation-model",
        "dna-sequence"
      ],
      "id": 51
    },
    {
      "name": "FFiNet",
      "one_line_profile": "Force field-inspired molecular representation learning model",
      "detailed_description": "A molecular representation learning framework that incorporates force field principles to improve molecular embeddings for property prediction.",
      "domains": [
        "Chemistry",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "property_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/fate1997/FFiNet",
      "help_website": [
        "https://github.com/fate1997/FFiNet"
      ],
      "license": "GPL-3.0",
      "tags": [
        "molecular-representation",
        "force-field",
        "gnn"
      ],
      "id": 52
    },
    {
      "name": "ChemAgent",
      "one_line_profile": "Self-updating Library in Large Language Models for Chemical Reasoning",
      "detailed_description": "An LLM-based agentic framework capable of chemical reasoning and self-updating its knowledge base to improve performance on chemistry tasks.",
      "domains": [
        "Chemistry",
        "C1"
      ],
      "subtask_category": [
        "chemical_reasoning",
        "agent",
        "llm"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gersteinlab/ChemAgent",
      "help_website": [
        "https://arxiv.org/abs/2501.06590"
      ],
      "license": null,
      "tags": [
        "llm",
        "agent",
        "chemical-reasoning"
      ],
      "id": 53
    },
    {
      "name": "MolGraphEval",
      "one_line_profile": "Evaluating Self-supervised Learning for Molecular Graph Embeddings",
      "detailed_description": "A benchmarking framework for evaluating the quality and performance of self-supervised learning methods on molecular graph embeddings.",
      "domains": [
        "Chemistry",
        "C1-05"
      ],
      "subtask_category": [
        "benchmarking",
        "evaluation",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hansen7/MolGraphEval",
      "help_website": [
        "https://github.com/hansen7/MolGraphEval"
      ],
      "license": "MIT",
      "tags": [
        "benchmark",
        "self-supervised-learning",
        "graph-neural-networks"
      ],
      "id": 54
    },
    {
      "name": "FG-BERT",
      "one_line_profile": "Self-Supervised Molecular Representation Learning Based on Functional Groups",
      "detailed_description": "A BERT-based molecular representation learning model that leverages functional group information to enhance molecular embeddings.",
      "domains": [
        "Chemistry",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/idrugLab/FG-BERT",
      "help_website": [
        "https://github.com/idrugLab/FG-BERT"
      ],
      "license": null,
      "tags": [
        "bert",
        "functional-groups",
        "molecular-embedding"
      ],
      "id": 55
    },
    {
      "name": "3D-EMGP",
      "one_line_profile": "Energy-Motivated Equivariant Pretraining for 3D Molecular Graphs",
      "detailed_description": "An implementation of energy-motivated equivariant pretraining for 3D molecular graphs, designed to improve molecular property prediction and representation.",
      "domains": [
        "Chemistry",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "pretraining",
        "3d_structure"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jiaor17/3D-EMGP",
      "help_website": [
        "https://github.com/jiaor17/3D-EMGP"
      ],
      "license": "MIT",
      "tags": [
        "equivariant-gnn",
        "3d-molecule",
        "pretraining"
      ],
      "id": 56
    },
    {
      "name": "DeePhase",
      "one_line_profile": "Predictor of homotypic liquid-liquid phase separation of proteins",
      "detailed_description": "A tool for predicting liquid-liquid phase separation (LLPS) of proteins based on sequence determinants and embeddings, associated with PNAS publication.",
      "domains": [
        "Biology",
        "Chemistry"
      ],
      "subtask_category": [
        "property_prediction",
        "phase_separation",
        "protein_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/kadiliissaar/DeePhase",
      "help_website": [
        "https://github.com/kadiliissaar/DeePhase"
      ],
      "license": "NOASSERTION",
      "tags": [
        "llps",
        "protein",
        "phase-separation"
      ],
      "id": 57
    },
    {
      "name": "Retrosynthesis-Prediction",
      "one_line_profile": "Retrosynthesis reaction prediction using Transformer models",
      "detailed_description": "A sequence-to-sequence transformer model implementation for predicting retrosynthetic routes from chemical products.",
      "domains": [
        "Chemistry",
        "C1"
      ],
      "subtask_category": [
        "retrosynthesis",
        "reaction_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/kheyer/Retrosynthesis-Prediction",
      "help_website": [
        "https://github.com/kheyer/Retrosynthesis-Prediction"
      ],
      "license": null,
      "tags": [
        "retrosynthesis",
        "transformer",
        "reaction-prediction"
      ],
      "id": 58
    },
    {
      "name": "Graph-DiT",
      "one_line_profile": "Graph Diffusion Transformer for Multi-Conditional Molecular Generation",
      "detailed_description": "A diffusion transformer model specifically designed for generating molecular graphs under multiple conditional constraints.",
      "domains": [
        "Chemistry",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_generation",
        "diffusion_model"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liugangcode/Graph-DiT",
      "help_website": [
        "https://github.com/liugangcode/Graph-DiT"
      ],
      "license": null,
      "tags": [
        "diffusion",
        "molecular-generation",
        "transformer"
      ],
      "id": 59
    },
    {
      "name": "InfoAlign",
      "one_line_profile": "Learning Molecular Representation in a Cell",
      "detailed_description": "A framework for learning molecular representations by aligning molecular structures with cellular context or information.",
      "domains": [
        "Chemistry",
        "Biology",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liugangcode/InfoAlign",
      "help_website": [
        "https://github.com/liugangcode/InfoAlign"
      ],
      "license": null,
      "tags": [
        "representation-learning",
        "cellular-context",
        "molecule"
      ],
      "id": 60
    },
    {
      "name": "torch-molecule",
      "one_line_profile": "Deep learning package for molecular discovery with sklearn-style interface",
      "detailed_description": "A comprehensive deep learning library for molecular discovery, offering an easy-to-use sklearn-style interface for property prediction, inverse design, and representation learning.",
      "domains": [
        "Chemistry",
        "C1-05"
      ],
      "subtask_category": [
        "property_prediction",
        "inverse_design",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/liugangcode/torch-molecule",
      "help_website": [
        "https://github.com/liugangcode/torch-molecule"
      ],
      "license": "MIT",
      "tags": [
        "molecular-discovery",
        "deep-learning",
        "library"
      ],
      "id": 61
    },
    {
      "name": "Molecule Attention Transformer (MAT)",
      "one_line_profile": "PyTorch implementation of Molecule Attention Transformer for molecular graph representation",
      "detailed_description": "A PyTorch reimplementation of the Molecule Attention Transformer (MAT), which utilizes a transformer architecture to process and learn from the graph-like structure of molecules for various chemical tasks.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "graph_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucidrains/molecule-attention-transformer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "transformer",
        "molecular-graph",
        "deep-learning",
        "pytorch"
      ],
      "id": 62
    },
    {
      "name": "GraphFP",
      "one_line_profile": "Implementation of fragment-based pretraining and finetuning on molecular graphs",
      "detailed_description": "A codebase implementing Fragment-based Pretraining and Finetuning on Molecular Graphs (NeurIPS 2023), providing tools for self-supervised learning on molecular structures.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_pretraining",
        "self_supervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lvkd84/GraphFP",
      "help_website": [],
      "license": null,
      "tags": [
        "molecular-graphs",
        "pretraining",
        "neurips-2023"
      ],
      "id": 63
    },
    {
      "name": "OChemR",
      "one_line_profile": "Vision Transformer based tool for detecting and classifying molecules from chemical reaction images",
      "detailed_description": "A tool that uses Vision Transformer (DETR) to detect and classify molecules, text, and arrows from chemical reaction images, translating detections into SMILES and preserving reaction direction.",
      "domains": [
        "C1"
      ],
      "subtask_category": [
        "optical_chemical_structure_recognition",
        "image_to_smiles"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/markmartorilopez/OChemR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ocsr",
        "vision-transformer",
        "chemical-reaction",
        "smiles"
      ],
      "id": 64
    },
    {
      "name": "keras-molecules",
      "one_line_profile": "Autoencoder network for learning continuous representations of molecular structures",
      "detailed_description": "An autoencoder implementation designed to convert discrete molecular representations (SMILES) into a continuous vector space, facilitating molecular generation and optimization tasks.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "autoencoder"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/maxhodak/keras-molecules",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "autoencoder",
        "smiles",
        "molecular-generation",
        "keras"
      ],
      "id": 65
    },
    {
      "name": "OneQMC",
      "one_line_profile": "Pretrained model and library for molecular wavefunction simulations using Quantum Monte Carlo",
      "detailed_description": "A library providing pretrained models and tools for simulating molecular wavefunctions, leveraging Quantum Monte Carlo methods for high-accuracy quantum chemistry calculations.",
      "domains": [
        "C1"
      ],
      "subtask_category": [
        "quantum_chemistry_simulation",
        "wavefunction_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/oneqmc",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "quantum-monte-carlo",
        "wavefunction",
        "quantum-chemistry"
      ],
      "id": 66
    },
    {
      "name": "ApeTokenizer",
      "one_line_profile": "Tokenizer for chemical SMILES and SELFIES strings for use in transformer models",
      "detailed_description": "A specialized tokenizer designed to handle chemical string representations like SMILES and SELFIES, facilitating the training of transformer-based chemical language models.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "chemical_tokenization",
        "data_preprocessing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mikemayuare/apetokenizer",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "tokenizer",
        "smiles",
        "selfies",
        "transformers"
      ],
      "id": 67
    },
    {
      "name": "S4-DeNovo",
      "one_line_profile": "Chemical language modeling with structured state space sequence models for drug design",
      "detailed_description": "The official implementation of chemical language modeling using Structured State Space Sequence (S4) models, applied to de novo drug design and molecular generation tasks.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "de_novo_drug_design",
        "molecular_generation"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/molML/s4-for-de-novo-drug-design",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "s4-model",
        "drug-design",
        "generative-model"
      ],
      "id": 68
    },
    {
      "name": "MolecularTransformerEmbeddings",
      "one_line_profile": "Transformer neural network for translating between molecular text representations and creating embeddings",
      "detailed_description": "A tool providing a Transformer-based model trained to translate between different molecular text representations (e.g., IUPAC to SMILES) and generate dense molecular embeddings.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_embedding",
        "text_translation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mpcrlab/MolecularTransformerEmbeddings",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "embeddings",
        "transformer",
        "iupac",
        "smiles"
      ],
      "id": 69
    },
    {
      "name": "PocketXMol",
      "one_line_profile": "Pocket-interacting molecular generative foundation model for structure-based drug design",
      "detailed_description": "Implementation of PocketXMol, a foundation model designed to generate molecules that interact with specific protein pockets, facilitating structure-based drug design.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "structure_based_drug_design",
        "molecular_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/pengxingang/PocketXMol",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "generative-model",
        "sbdd",
        "protein-pocket"
      ],
      "id": 70
    },
    {
      "name": "MolE (Recursion)",
      "one_line_profile": "Recursion's molecular foundation model for representation learning",
      "detailed_description": "A molecular foundation model developed by Recursion Pharmaceuticals, designed to learn general-purpose molecular representations for various downstream drug discovery tasks.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "foundation_model"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/recursionpharma/mole_public",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "foundation-model",
        "drug-discovery",
        "representation-learning"
      ],
      "id": 71
    },
    {
      "name": "RXN Standardization",
      "one_line_profile": "Tool for standardizing chemical compounds using language models",
      "detailed_description": "A library from IBM Research for standardizing chemical compound representations using language models, ensuring consistency in chemical datasets.",
      "domains": [
        "C1"
      ],
      "subtask_category": [
        "chemical_standardization",
        "data_cleaning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rxn4chemistry/rxn-standardization",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "standardization",
        "chemical-language-model",
        "ibm-rxn"
      ],
      "id": 72
    },
    {
      "name": "RXNMapper",
      "one_line_profile": "Unsupervised attention-guided atom-mapping tool for chemical reactions",
      "detailed_description": "A tool that extracts atom-mapping information from chemical reactions using unsupervised learning and attention mechanisms, useful for understanding reaction mechanisms and grammar.",
      "domains": [
        "C1"
      ],
      "subtask_category": [
        "atom_mapping",
        "reaction_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rxn4chemistry/rxnmapper",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "atom-mapping",
        "chemical-reaction",
        "attention-mechanism"
      ],
      "id": 73
    },
    {
      "name": "GROVER",
      "one_line_profile": "Self-supervised graph transformer for molecular representation learning",
      "detailed_description": "A PyTorch implementation of the Self-Supervised Graph Transformer on Large-Scale Molecular Data. It provides a foundation model for molecular representation, enabling downstream tasks such as property prediction and molecular generation.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "self_supervised_learning",
        "property_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tencent-ailab/grover",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "graph-transformer",
        "molecular-embedding",
        "self-supervised-learning",
        "foundation-model"
      ],
      "id": 74
    },
    {
      "name": "MoleRec",
      "one_line_profile": "Combinatorial drug recommendation with substructure-aware molecular representation",
      "detailed_description": "The official implementation of MoleRec, a framework for combinatorial drug recommendation that utilizes substructure-aware molecular representation learning to predict effective drug combinations.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "drug_recommendation",
        "molecular_representation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yangnianzu0515/MoleRec",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "drug-recommendation",
        "molecular-representation",
        "substructure-aware"
      ],
      "id": 75
    },
    {
      "name": "MolCLR",
      "one_line_profile": "Molecular contrastive learning of representations via GNNs",
      "detailed_description": "A framework for Molecular Contrastive Learning of Representations (MolCLR) via Graph Neural Networks. It provides self-supervised pre-training strategies for molecular graphs to improve performance on downstream molecular property prediction tasks.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "contrastive_learning",
        "property_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yuyangw/MolCLR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "contrastive-learning",
        "gnn",
        "molecular-representation",
        "self-supervised"
      ],
      "id": 76
    },
    {
      "name": "TrimNet",
      "one_line_profile": "Molecular representation learning from triplet messages",
      "detailed_description": "Implementation of TrimNet, a deep learning architecture for learning molecular representations using triplet messages, designed for biomedical applications such as property prediction.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "property_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yvquanli/TrimNet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "molecular-representation",
        "triplet-message",
        "biomedicine",
        "deep-learning"
      ],
      "id": 77
    },
    {
      "name": "MGSSL",
      "one_line_profile": "Motif-based graph self-supervised learning for molecules",
      "detailed_description": "Official implementation of Motif-based Graph Self-Supervised Learning (MGSSL) for Molecular Property Prediction. It leverages motif-level information to enhance graph neural networks for molecular tasks.",
      "domains": [
        "C1",
        "C1-05"
      ],
      "subtask_category": [
        "molecular_representation",
        "self_supervised_learning",
        "property_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zaixizhang/MGSSL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "motif-based",
        "self-supervised-learning",
        "molecular-property-prediction",
        "gnn"
      ],
      "id": 78
    }
  ]
}