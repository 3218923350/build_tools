{
  "generated_at": "2025-12-16T06:21:50.517010+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "AI3",
      "leaf_cluster_name": "科研领域模型训练与微调生态",
      "domain": "AI Toolchain",
      "typical_objects": "domain corpora",
      "task_chain": "数据→训练→微调→对齐→评测→发布",
      "tool_form": "训练栈 + 数据管线 + serving"
    },
    "unit": {
      "unit_id": "AI3-02",
      "unit_name": "PEFT/对齐/指令微调",
      "target_scale": "200–450",
      "coverage_tools": "LoRA/QLoRA、alignment"
    },
    "search": {
      "target_candidates": 450,
      "queries": [
        "[GH] Firefly",
        "[GH] XTuner",
        "[GH] DeepSpeed-Chat",
        "[GH] Swift",
        "[GH] LLaMA-Factory",
        "[GH] Unsloth",
        "[GH] Axolotl",
        "[GH] TRL",
        "[GH] PEFT",
        "[GH] LoRA",
        "[GH] QLoRA",
        "[GH] instruction-tuning",
        "[GH] RLHF",
        "[GH] DPO",
        "[GH] LLM-alignment",
        "[GH] supervised-fine-tuning",
        "[GH] adapter-transformers",
        "[GH] prefix-tuning",
        "[GH] prompt-tuning",
        "[GH] preference-optimization",
        "[GH] parameter-efficient-fine-tuning",
        "[WEB] PEFT parameter efficient fine tuning library github",
        "[WEB] LLM instruction tuning framework github",
        "[WEB] RLHF DPO alignment tools github",
        "[WEB] LoRA QLoRA fine-tuning implementation github",
        "[WEB] LLM supervised fine-tuning SFT github"
      ],
      "total_candidates": 1158,
      "tool_candidates": 946,
      "final_tools": 306
    }
  },
  "tools": [
    {
      "name": "LLM-Adapters",
      "one_line_profile": "A framework for Parameter-Efficient Fine-Tuning (PEFT) of Large Language Models",
      "detailed_description": "A library integrating various adapter-based methods for parameter-efficient fine-tuning of Large Language Models (LLMs), enabling researchers to fine-tune models with limited compute resources.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AGI-Edgerunners/LLM-Adapters",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "peft",
        "llm",
        "adapters",
        "fine-tuning"
      ],
      "id": 1
    },
    {
      "name": "fsdp_qlora",
      "one_line_profile": "Efficient LLM training pipeline combining FSDP and QLoRA",
      "detailed_description": "A training workflow and library that combines Fully Sharded Data Parallel (FSDP) with QLoRA quantization to enable efficient, large-scale fine-tuning of Large Language Models on consumer or research hardware.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "distributed_training"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/AnswerDotAI/fsdp_qlora",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fsdp",
        "qlora",
        "llm-training",
        "quantization"
      ],
      "id": 2
    },
    {
      "name": "KG_RAG",
      "one_line_profile": "Knowledge Graph based Retrieval-Augmented Generation framework for biomedicine",
      "detailed_description": "A framework designed to empower Large Language Models (LLMs) with Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG), specifically optimized for knowledge-intensive scientific tasks such as biomedical information retrieval.",
      "domains": [
        "AI4",
        "AI3"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "rag",
        "biomedical_inference"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/BaranziniLab/KG_RAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "rag",
        "biomedicine",
        "llm"
      ],
      "id": 3
    },
    {
      "name": "bonito",
      "one_line_profile": "Synthetic instruction tuning dataset generator",
      "detailed_description": "A lightweight library for generating synthetic instruction tuning datasets from unannotated text, facilitating the creation of domain-specific training data for aligning Large Language Models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_generation",
        "instruction_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BatsResearch/bonito",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "synthetic-data",
        "instruction-tuning",
        "dataset-generation"
      ],
      "id": 4
    },
    {
      "name": "EmotionBench",
      "one_line_profile": "Benchmark suite for evaluating Large Language Models' emotional alignment with humans",
      "detailed_description": "A benchmarking tool designed to assess the emotional alignment of Large Language Models (LLMs) with human emotional responses. It provides datasets and evaluation metrics to measure how well models understand and generate emotionally appropriate content.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/CUHK-ARISE/EmotionBench",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "llm",
        "alignment",
        "benchmark",
        "emotion-recognition"
      ],
      "id": 5
    },
    {
      "name": "pykoi",
      "one_line_profile": "Unified interface for active learning and RLHF fine-tuning of LLMs",
      "detailed_description": "An open-source library for training and fine-tuning Large Language Models (LLMs) using Reinforcement Learning from Human Feedback (RLHF). It provides a unified interface for active learning, model comparison, and data collection to improve model alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "fine-tuning",
        "active_learning"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/CambioML/pykoi-rlhf-finetuned-transformers",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "llm",
        "fine-tuning",
        "active-learning"
      ],
      "id": 6
    },
    {
      "name": "BiPO",
      "one_line_profile": "Bi-directional Preference Optimization for personalized steering of LLMs",
      "detailed_description": "Implementation of Bi-directional Preference Optimization (BiPO) for creating versatile steering vectors to personalize Large Language Models. It focuses on aligning models with specific user preferences through efficient optimization techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization",
        "steering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CaoYuanpu/BiPO",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "alignment",
        "preference-optimization",
        "steering-vectors"
      ],
      "id": 7
    },
    {
      "name": "trlx",
      "one_line_profile": "Distributed training framework for RLHF fine-tuning of language models",
      "detailed_description": "A library for distributed training of Large Language Models (LLMs) using Reinforcement Learning via Human Feedback (RLHF). It supports various RL algorithms like PPO and ILQL and integrates with Hugging Face transformers for efficient alignment training.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "fine-tuning",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CarperAI/trlx",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rlhf",
        "ppo",
        "distributed-training",
        "llm"
      ],
      "id": 8
    },
    {
      "name": "MELoRA",
      "one_line_profile": "Mini-Ensemble Low-Rank Adapter for parameter-efficient fine-tuning",
      "detailed_description": "Implementation of MELoRA, a parameter-efficient fine-tuning (PEFT) method that uses a mini-ensemble of low-rank adapters to improve model performance with minimal parameter overhead. It is designed for efficient adaptation of large pre-trained models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "fine-tuning",
        "lora"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChasonShi/MELoRA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "peft",
        "lora",
        "fine-tuning",
        "ensemble"
      ],
      "id": 9
    },
    {
      "name": "TimeCMA",
      "one_line_profile": "Cross-modality alignment for LLM-empowered time series forecasting",
      "detailed_description": "A framework for multivariate time series forecasting that leverages Large Language Models (LLMs) through cross-modality alignment. It aligns time series data with the semantic space of LLMs to enhance forecasting capabilities.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "time_series_forecasting",
        "cross_modality"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChenxiLiu-HNU/TimeCMA",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "time-series",
        "llm",
        "alignment",
        "forecasting"
      ],
      "id": 10
    },
    {
      "name": "Subspace-Tuning",
      "one_line_profile": "Generalized framework for subspace tuning in parameter-efficient fine-tuning",
      "detailed_description": "A unified framework for subspace tuning methods in Parameter-Efficient Fine-Tuning (PEFT). It generalizes various PEFT approaches by projecting optimization into lower-dimensional subspaces, facilitating research and application of efficient tuning techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "fine-tuning",
        "subspace_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Chongjie-Si/Subspace-Tuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "peft",
        "fine-tuning",
        "subspace",
        "llm"
      ],
      "id": 11
    },
    {
      "name": "Osprey",
      "one_line_profile": "Pixel-level visual instruction tuning for fine-grained visual understanding",
      "detailed_description": "A multimodal model and training framework for pixel-level visual understanding via visual instruction tuning. It enables fine-grained alignment between visual regions and textual instructions, supporting tasks like detailed image description and region-based QA.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "multimodal_alignment",
        "visual_understanding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CircleRadon/Osprey",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "instruction-tuning",
        "visual-understanding",
        "pixel-level"
      ],
      "id": 12
    },
    {
      "name": "CLAIR_and_APO",
      "one_line_profile": "Anchored Preference Optimization for addressing underspecification in alignment",
      "detailed_description": "Implementation of Anchored Preference Optimization (APO) and Contrastive Revisions (CLAIR) to improve the alignment of Large Language Models. These methods address underspecification in human preferences to produce more robustly aligned models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization",
        "rlhf"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ContextualAI/CLAIR_and_APO",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "alignment",
        "preference-optimization",
        "llm",
        "apo"
      ],
      "id": 13
    },
    {
      "name": "HALOs",
      "one_line_profile": "Library for Human-Aware Loss Functions (DPO, KTO, PPO) in LLM alignment",
      "detailed_description": "A comprehensive library providing implementations of various human-aware loss functions (HALOs) such as Direct Preference Optimization (DPO), Kahneman-Tversky Optimization (KTO), and PPO. It facilitates the alignment of LLMs with human preferences.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "loss_functions",
        "dpo",
        "kto"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ContextualAI/HALOs",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "dpo",
        "kto",
        "loss-functions"
      ],
      "id": 14
    },
    {
      "name": "GritLM",
      "one_line_profile": "Generative Representational Instruction Tuning for unified text embedding and generation",
      "detailed_description": "Implementation of Generative Representational Instruction Tuning (GRIT), a method that unifies text embedding and generative capabilities in a single Large Language Model. It enables models to handle both representation learning and instruction following tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "representation_learning",
        "embedding"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ContextualAI/gritlm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "instruction-tuning",
        "embedding",
        "llm",
        "representation"
      ],
      "id": 15
    },
    {
      "name": "Unsloth LLaMA-3 Pipeline",
      "one_line_profile": "Optimized 4-bit QLoRA fine-tuning pipeline for LLaMA 3",
      "detailed_description": "A production-grade fine-tuning pipeline leveraging Unsloth and QLoRA for efficient 4-bit training of LLaMA 3 models. It focuses on memory efficiency and speed for instruction-following specialization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine-tuning",
        "qlora",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Cre4T3Tiv3/unsloth-llama3-alpaca-lora",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fine-tuning",
        "qlora",
        "llama-3",
        "unsloth"
      ],
      "id": 16
    },
    {
      "name": "LongPO",
      "one_line_profile": "Long context self-evolution via short-to-long preference optimization",
      "detailed_description": "A framework for extending the context window of Large Language Models through self-evolution and preference optimization. It utilizes short-to-long preference learning to align models for long-context understanding and generation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "long_context",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DAMO-NLP-SG/LongPO",
      "help_website": [],
      "license": null,
      "tags": [
        "long-context",
        "alignment",
        "preference-optimization",
        "llm"
      ],
      "id": 17
    },
    {
      "name": "Video-LLaMA",
      "one_line_profile": "Instruction-tuned audio-visual language model for video understanding",
      "detailed_description": "A multi-modal framework that empowers Large Language Models with video and audio understanding capabilities through instruction tuning. It aligns visual and audio encoders with the LLM embedding space to support video-based Q&A and dialogue.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "multimodal_alignment",
        "video_understanding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DAMO-NLP-SG/Video-LLaMA",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "multimodal",
        "video-llm",
        "instruction-tuning",
        "alignment"
      ],
      "id": 18
    },
    {
      "name": "DISTRE",
      "one_line_profile": "Fine-tuning transformer models for distantly supervised relation extraction",
      "detailed_description": "A tool for fine-tuning pre-trained transformer language models specifically for the task of distantly supervised relation extraction. It adapts general-purpose models to extract semantic relations from text using distant supervision signals.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine-tuning",
        "relation_extraction",
        "nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DFKI-NLP/DISTRE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "relation-extraction",
        "fine-tuning",
        "transformer",
        "nlp"
      ],
      "id": 19
    },
    {
      "name": "General-Visual-Quality-RL",
      "one_line_profile": "Reinforcement learning for image quality assessment via preference optimization",
      "detailed_description": "Implementation of PreResQ-R1, a method using Reinforcement Learning and Preference-Response Disentangled Policy Optimization to align models for fine-grained image quality assessment. It focuses on rank-and-score capabilities.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "reinforcement_learning",
        "image_quality_assessment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DanceSkyCode/General-Visual-Quality-RL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rl",
        "alignment",
        "image-quality",
        "preference-optimization"
      ],
      "id": 20
    },
    {
      "name": "Docta",
      "one_line_profile": "Data-centric AI tool for detecting data errors and improving dataset quality",
      "detailed_description": "A data-centric AI tool designed to diagnose and cure data issues such as label errors and outliers. It helps improve the quality of training data, which is a critical step before model training and alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_quality",
        "data_cleaning",
        "preprocessing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Docta-ai/docta",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "data-centric-ai",
        "data-cleaning",
        "quality-control"
      ],
      "id": 21
    },
    {
      "name": "3dpose_gan",
      "one_line_profile": "Unsupervised adversarial learning for 3D human pose estimation",
      "detailed_description": "Implementation of a GAN-based approach for unsupervised learning of 3D human pose from 2D joint locations. It serves as a scientific modeling tool for converting 2D visual data into 3D structural information.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "modeling",
        "pose_estimation",
        "gan"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DwangoMediaVillage/3dpose_gan",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "3d-pose",
        "gan",
        "computer-vision",
        "modeling"
      ],
      "id": 22
    },
    {
      "name": "AutoPrompt",
      "one_line_profile": "Framework for intent-based prompt calibration and tuning",
      "detailed_description": "A framework for prompt tuning that utilizes Intent-based Prompt Calibration to automatically optimize prompts for Large Language Models. It helps in aligning model outputs with user intent without extensive fine-tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "prompt_tuning",
        "alignment",
        "calibration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Eladlev/AutoPrompt",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prompt-tuning",
        "llm",
        "alignment",
        "calibration"
      ],
      "id": 23
    },
    {
      "name": "UVQA",
      "one_line_profile": "Alignment framework for answerability in Video LLMs",
      "detailed_description": "Code and dataset for aligning Video Large Language Models to refuse unanswerable questions. It focuses on improving the reliability and safety of multimodal models by teaching them to recognize the limits of visual information.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "multimodal",
        "evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/EsYoon7/UVQA",
      "help_website": [],
      "license": null,
      "tags": [
        "video-llm",
        "alignment",
        "safety",
        "multimodal"
      ],
      "id": 24
    },
    {
      "name": "Otter",
      "one_line_profile": "Multi-modal model for in-context learning and instruction following",
      "detailed_description": "A multi-modal model based on OpenFlamingo, designed for improved instruction-following and in-context learning capabilities. It is trained on the MIMIC-IT dataset to align visual and textual understanding.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "multimodal_alignment",
        "in_context_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/EvolvingLMMs-Lab/Otter",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multimodal",
        "instruction-tuning",
        "openflamingo",
        "llm"
      ],
      "id": 25
    },
    {
      "name": "ComfyUI_ELLA",
      "one_line_profile": "Enhanced semantic alignment for diffusion models via LLM integration",
      "detailed_description": "A ComfyUI implementation of ELLA, a method that equips diffusion models with Large Language Models to improve semantic alignment between text prompts and generated images. It serves as a tool for enhanced generative modeling.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "generative_modeling",
        "diffusion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ExponentialML/ComfyUI_ELLA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion",
        "alignment",
        "llm",
        "comfyui"
      ],
      "id": 26
    },
    {
      "name": "SplitFM",
      "one_line_profile": "Split parameter-efficient fine-tuning and inference framework",
      "detailed_description": "A framework for split parameter-efficient fine-tuning (PEFT) and inference of foundation models. It enables efficient model adaptation and deployment by splitting computational loads or parameters.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "fine-tuning",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/FDU-INC/SplitFM",
      "help_website": [],
      "license": null,
      "tags": [
        "peft",
        "fine-tuning",
        "foundation-models"
      ],
      "id": 27
    },
    {
      "name": "Chinese-Vicuna",
      "one_line_profile": "Chinese instruction-following LLaMA model with LoRA fine-tuning",
      "detailed_description": "A low-resource solution for fine-tuning LLaMA models on Chinese instruction datasets using LoRA. It provides tools for training, inference, and deployment of Chinese-aligned LLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "lora",
        "fine-tuning"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/Facico/Chinese-Vicuna",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llama",
        "lora",
        "chinese-llm",
        "instruction-tuning"
      ],
      "id": 28
    },
    {
      "name": "GOAT-PEFT",
      "one_line_profile": "Adaptive singular value optimization for boosting LoRA alignment",
      "detailed_description": "Implementation of a method to boost LoRA performance using adaptive singular values and Mixture-of-Experts optimization. It aims to improve the alignment and efficiency of parameter-efficient fine-tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "lora",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Facico/GOAT-PEFT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "lora",
        "alignment",
        "optimization"
      ],
      "id": 29
    },
    {
      "name": "FantasyTalking2",
      "one_line_profile": "Timestep-layer adaptive preference optimization for audio-driven animation",
      "detailed_description": "A framework for audio-driven portrait animation that utilizes timestep-layer adaptive preference optimization. It aligns generated animations with audio inputs using advanced preference learning techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization",
        "generative_modeling"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/Fantasy-AMAP/fantasy-talking2",
      "help_website": [],
      "license": null,
      "tags": [
        "alignment",
        "audio-driven",
        "animation",
        "preference-optimization"
      ],
      "id": 30
    },
    {
      "name": "GPS",
      "one_line_profile": "Gradient-based parameter selection for efficient fine-tuning",
      "detailed_description": "A method for selecting the most important parameters for fine-tuning based on gradients. It optimizes the fine-tuning process by focusing on a subset of parameters, enhancing efficiency.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "fine-tuning",
        "parameter_selection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FightingFighting/GPS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "fine-tuning",
        "gradient-based",
        "efficiency"
      ],
      "id": 31
    },
    {
      "name": "MultilingualSIFT",
      "one_line_profile": "Multilingual supervised instruction fine-tuning framework",
      "detailed_description": "A framework for multilingual supervised instruction fine-tuning (SIFT) of large language models, enabling adaptation to multiple languages.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "fine_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/FreedomIntelligence/MultilingualSIFT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sift",
        "multilingual",
        "llm-training"
      ],
      "id": 32
    },
    {
      "name": "Diffusion-NPO",
      "one_line_profile": "Negative Preference Optimization for diffusion model alignment",
      "detailed_description": "Implementation of Negative Preference Optimization (NPO) to align diffusion models with human preferences by minimizing the likelihood of generating negative samples.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/G-U-N/Diffusion-NPO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-models",
        "alignment",
        "npo"
      ],
      "id": 33
    },
    {
      "name": "vlm-grpo",
      "one_line_profile": "GRPO implementation for Vision-Language Model training",
      "detailed_description": "An implementation of the GRPO (Group Relative Policy Optimization) algorithm specifically designed for training Vision-Language Models (VLMs) within the Unsloth framework.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "reinforcement_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GAD-cell/vlm-grpo",
      "help_website": [],
      "license": null,
      "tags": [
        "vlm",
        "grpo",
        "unsloth"
      ],
      "id": 34
    },
    {
      "name": "IISAN",
      "one_line_profile": "Efficient multimodal foundation model adaptation method",
      "detailed_description": "Implementation of IISAN for efficient adaptation of multimodal foundation models, specifically targeting recommendation systems.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_adaptation",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GAIR-Lab/IISAN",
      "help_website": [],
      "license": null,
      "tags": [
        "multimodal",
        "recommendation",
        "adaptation"
      ],
      "id": 35
    },
    {
      "name": "ChapTER",
      "one_line_profile": "Contrastive historical modeling with prefix-tuning for temporal KGs",
      "detailed_description": "A tool for temporal knowledge graph reasoning using contrastive historical modeling and prefix-tuning techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "prefix_tuning",
        "knowledge_graph_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GKNL/ChapTER",
      "help_website": [],
      "license": null,
      "tags": [
        "temporal-knowledge-graph",
        "prefix-tuning",
        "reasoning"
      ],
      "id": 36
    },
    {
      "name": "FineSSL",
      "one_line_profile": "Fine-tuning foundation models for semi-supervised learning",
      "detailed_description": "Implementation of a method to erase bias and fine-tune foundation models specifically for semi-supervised learning tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "semi_supervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Gank0078/FineSSL",
      "help_website": [],
      "license": null,
      "tags": [
        "ssl",
        "bias-mitigation",
        "foundation-models"
      ],
      "id": 37
    },
    {
      "name": "Beyond-Log-Likelihood",
      "one_line_profile": "Alternative objectives for supervised fine-tuning",
      "detailed_description": "Explores and implements alternative objective functions beyond log-likelihood for the supervised fine-tuning of language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "objective_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GaotangLi/Beyond-Log-Likelihood",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sft",
        "loss-functions",
        "llm"
      ],
      "id": 38
    },
    {
      "name": "ScoreFlow",
      "one_line_profile": "Score-based preference optimization for LLM agent workflows",
      "detailed_description": "A framework for optimizing LLM agent workflows using score-based preference optimization techniques to master complex tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "preference_optimization",
        "agent_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Gen-Verse/ScoreFlow",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-agent",
        "preference-optimization",
        "workflow"
      ],
      "id": 39
    },
    {
      "name": "dLLM-RL",
      "one_line_profile": "Reinforcement learning framework for Diffusion LLMs",
      "detailed_description": "TraceRL and TraDo-8B implementation, providing a reinforcement learning framework specifically tailored for Diffusion Large Language Models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Gen-Verse/dLLM-RL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-llm",
        "rlhf",
        "reinforcement-learning"
      ],
      "id": 40
    },
    {
      "name": "cognify",
      "one_line_profile": "Auto-tuning tool for AI agents and workflows",
      "detailed_description": "A tool for automatically optimizing LangChain, LangGraph, and DSPy programs to improve quality, latency, and cost of AI agent workflows.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "workflow_optimization",
        "auto_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/GenseeAI/cognify",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent-optimization",
        "langchain",
        "dspy"
      ],
      "id": 41
    },
    {
      "name": "mlx-lm-lora",
      "one_line_profile": "LoRA fine-tuning for LLMs on Apple MLX",
      "detailed_description": "A library for training and fine-tuning Large Language Models using LoRA on Apple Silicon via the MLX framework.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "lora"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Goekdeniz-Guelmez/mlx-lm-lora",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mlx",
        "lora",
        "apple-silicon"
      ],
      "id": 42
    },
    {
      "name": "PiSSA",
      "one_line_profile": "Principal Singular Values and Singular Vectors Adaptation for LLMs",
      "detailed_description": "Implementation of PiSSA, a parameter-efficient fine-tuning method that adapts principal singular values and vectors of Large Language Models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/GraphPKU/PiSSA",
      "help_website": [],
      "license": null,
      "tags": [
        "peft",
        "svd",
        "llm-adaptation"
      ],
      "id": 43
    },
    {
      "name": "relora",
      "one_line_profile": "High-rank training through low-rank updates",
      "detailed_description": "Official implementation of ReLoRA, a method for high-rank training of neural networks using low-rank updates.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Guitaricet/relora",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lora",
        "training-efficiency",
        "peft"
      ],
      "id": 44
    },
    {
      "name": "ffrecord",
      "one_line_profile": "High-performance file format for DL training samples",
      "detailed_description": "FireFlyer Record (ffrecord) is a file format and library designed for efficient reading and writing of deep learning training samples.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "data_io",
        "training_infrastructure"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HFAiLab/ffrecord",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-format",
        "io",
        "deep-learning"
      ],
      "id": 45
    },
    {
      "name": "GraphGPT",
      "one_line_profile": "Graph instruction tuning for Large Language Models",
      "detailed_description": "A framework for graph instruction tuning, enabling Large Language Models to understand and process graph-structured data.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "graph_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUDS/GraphGPT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "graph-neural-networks",
        "instruction-tuning",
        "llm"
      ],
      "id": 46
    },
    {
      "name": "UrbanGPT",
      "one_line_profile": "Spatio-temporal Large Language Models",
      "detailed_description": "A model and toolkit for spatio-temporal prediction tasks using Large Language Models, tailored for urban computing scenarios.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "spatio_temporal_modeling",
        "scientific_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUDS/UrbanGPT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "urban-computing",
        "spatio-temporal",
        "llm"
      ],
      "id": 47
    },
    {
      "name": "swarmlib",
      "one_line_profile": "Library for swarm optimization algorithms",
      "detailed_description": "A library implementing various swarm optimization algorithms including Particle Swarm Optimization, Firefly Algorithm, and Ant Colony Optimization.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "optimization",
        "scientific_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HaaLeo/swarmlib",
      "help_website": [
        "https://swarmlib.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "optimization",
        "swarm-intelligence",
        "algorithms"
      ],
      "id": 48
    },
    {
      "name": "transformers_tasks",
      "one_line_profile": "Collection of NLP task implementations with Transformers",
      "detailed_description": "A comprehensive library of scripts and implementations for various NLP tasks (classification, generation, extraction, RLHF, SFT) using the Transformers library.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "rlhf",
        "nlp_tasks"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/HarderThenHarder/transformers_tasks",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "transformers",
        "rlhf"
      ],
      "id": 49
    },
    {
      "name": "VistaDPO",
      "one_line_profile": "Video hierarchical spatial-temporal Direct Preference Optimization",
      "detailed_description": "Implementation of VistaDPO for aligning large video models using hierarchical spatial-temporal direct preference optimization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "dpo",
        "video_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HaroldChen19/VistaDPO",
      "help_website": [],
      "license": null,
      "tags": [
        "video-models",
        "dpo",
        "alignment"
      ],
      "id": 50
    },
    {
      "name": "HugNLP",
      "one_line_profile": "Unified NLP library based on HuggingFace Transformers",
      "detailed_description": "A comprehensive NLP library designed to simplify the development and training of NLP models, built on top of HuggingFace Transformers.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HugAILab/HugNLP",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "transformers",
        "framework"
      ],
      "id": 51
    },
    {
      "name": "DiffuseKronA",
      "one_line_profile": "Parameter efficient fine-tuning for personalized diffusion models",
      "detailed_description": "A parameter-efficient fine-tuning method (KronA) specifically designed for personalizing diffusion models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "diffusion_personalization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/IBM/DiffuseKronA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion",
        "peft",
        "personalization"
      ],
      "id": 52
    },
    {
      "name": "VTAGML",
      "one_line_profile": "Vision Transformer Adapters for generalizable multitask learning",
      "detailed_description": "Implementation of adapters for Vision Transformers to enable generalizable multitask learning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "multitask_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/IVRL/VTAGML",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vision-transformer",
        "adapters",
        "multitask-learning"
      ],
      "id": 53
    },
    {
      "name": "rulm",
      "one_line_profile": "Russian language modeling and instruction tuning toolkit",
      "detailed_description": "A toolkit for language modeling and instruction tuning specifically for the Russian language, including datasets and training scripts.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "language_modeling"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/IlyaGusev/rulm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "russian-nlp",
        "instruction-tuning",
        "llm"
      ],
      "id": 54
    },
    {
      "name": "GPT-4-LLM",
      "one_line_profile": "Instruction tuning data generation with GPT-4",
      "detailed_description": "A workflow and dataset collection for using GPT-4 to generate instruction-following data for fine-tuning LLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_synthesis",
        "instruction_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "instruction-tuning",
        "synthetic-data",
        "gpt-4"
      ],
      "id": 55
    },
    {
      "name": "Condor",
      "one_line_profile": "Knowledge-driven data synthesis for LLM alignment",
      "detailed_description": "A tool to enhance LLM alignment through knowledge-driven data synthesis and refinement.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "data_synthesis"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/InternLM/Condor",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "synthetic-data",
        "llm"
      ],
      "id": 56
    },
    {
      "name": "InternLM",
      "one_line_profile": "Comprehensive Large Language Model training and inference suite",
      "detailed_description": "The official codebase for the InternLM series, providing a complete toolchain for pre-training, fine-tuning, and deploying large language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "fine_tuning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/InternLM/InternLM",
      "help_website": [
        "https://internlm.intern-ai.org.cn/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "training-framework",
        "internlm"
      ],
      "id": 57
    },
    {
      "name": "InternLM-XComposer",
      "one_line_profile": "Multimodal LLM system for advanced interactions",
      "detailed_description": "A comprehensive multimodal system based on InternLM for long-term streaming video and audio interactions, including training and inference tools.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "multimodal_training",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/InternLM/InternLM-XComposer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "vlm",
        "internlm"
      ],
      "id": 58
    },
    {
      "name": "xtuner",
      "one_line_profile": "High-efficiency fine-tuning toolkit for LLMs",
      "detailed_description": "A next-generation training engine designed for efficient fine-tuning of Large Language Models, supporting various PEFT methods and ultra-large MoE models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/InternLM/xtuner",
      "help_website": [
        "https://xtuner.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "fine-tuning",
        "peft",
        "lora"
      ],
      "id": 59
    },
    {
      "name": "GraphGen",
      "one_line_profile": "Knowledge-driven synthetic data generation for SFT",
      "detailed_description": "A tool for enhancing Supervised Fine-Tuning (SFT) of LLMs by generating knowledge-driven synthetic data.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_synthesis",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/InternScience/GraphGen",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "synthetic-data",
        "sft",
        "knowledge-graph"
      ],
      "id": 60
    },
    {
      "name": "DreamArtist-stable-diffusion",
      "one_line_profile": "Stable Diffusion webui extension for contrastive prompt tuning",
      "detailed_description": "A Stable Diffusion WebUI extension that implements the DreamArtist algorithm for contrastive prompt tuning, allowing for high-quality style and object learning with parameter efficiency.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "parameter_efficient_fine_tuning",
        "generative_model_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IrisRainbowNeko/DreamArtist-stable-diffusion",
      "help_website": [],
      "license": null,
      "tags": [
        "stable-diffusion",
        "prompt-tuning",
        "peft"
      ],
      "id": 61
    },
    {
      "name": "Point-PEFT",
      "one_line_profile": "Parameter-Efficient Fine-Tuning for 3D Pre-trained Models",
      "detailed_description": "Implementation of Point-PEFT (AAAI 2024), a method for parameter-efficient fine-tuning specifically designed for 3D pre-trained models, enabling adaptation to downstream 3D tasks with minimal trainable parameters.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "parameter_efficient_fine_tuning",
        "3d_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Ivan-Tang-3D/Point-PEFT",
      "help_website": [],
      "license": null,
      "tags": [
        "3d-deep-learning",
        "peft",
        "aaai-2024"
      ],
      "id": 62
    },
    {
      "name": "MiniHF",
      "one_line_profile": "Local tool for inference, human preference data collection, and fine-tuning",
      "detailed_description": "A comprehensive tool for local language model development, facilitating inference, collection of human preference data (RLHF), and fine-tuning workflows to develop prompts into full models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf_data_collection",
        "fine_tuning",
        "inference"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/JD-P/minihf",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "fine-tuning",
        "data-collection"
      ],
      "id": 63
    },
    {
      "name": "AMoPO",
      "one_line_profile": "Adaptive Multi-objective Preference Optimization for LLMs",
      "detailed_description": "Implementation of AMoPO, an alignment algorithm that performs adaptive multi-objective preference optimization without requiring reward models or reference models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Javkonline/AMoPO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dpo",
        "alignment",
        "llm"
      ],
      "id": 64
    },
    {
      "name": "InPO",
      "one_line_profile": "Inversion Preference Optimization for Diffusion Model Alignment",
      "detailed_description": "Implementation of InPO (CVPR 2025), a method for efficient diffusion model alignment using inversion preference optimization with reparametrized DDIM.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "diffusion_model_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JaydenLyh/InPO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-models",
        "alignment",
        "cvpr-2025"
      ],
      "id": 65
    },
    {
      "name": "AIDoctor",
      "one_line_profile": "Medical GPT model training pipeline including SFT, RLHF, and DPO",
      "detailed_description": "A complete training pipeline for medical domain LLMs, implementing Pretraining, Supervised Fine-tuning (SFT), Reward Modeling, Reinforcement Learning (RLHF), and Direct Preference Optimization (DPO).",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "domain_adaptation",
        "rlhf",
        "sft"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Jerry-XDL/AIDoctor",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-llm",
        "rlhf",
        "dpo"
      ],
      "id": 66
    },
    {
      "name": "LLM-RLHF-Tuning",
      "one_line_profile": "LLM Tuning pipeline with PEFT, SFT, RM, PPO, and DPO",
      "detailed_description": "A comprehensive library for Large Language Model tuning, integrating Parameter-Efficient Fine-Tuning (PEFT) with LoRA, Supervised Fine-Tuning (SFT), Reward Modeling, PPO, and DPO algorithms.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "peft",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Joyce94/LLM-RLHF-Tuning",
      "help_website": [],
      "license": null,
      "tags": [
        "rlhf",
        "lora",
        "ppo"
      ],
      "id": 67
    },
    {
      "name": "VPT",
      "one_line_profile": "Visual Prompt Tuning for vision models",
      "detailed_description": "Implementation of Visual Prompt Tuning (ECCV 2022), a parameter-efficient fine-tuning method for large-scale vision models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "visual_prompt_tuning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/KMnP/vpt",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "computer-vision",
        "prompt-tuning",
        "eccv-2022"
      ],
      "id": 68
    },
    {
      "name": "Kiln",
      "one_line_profile": "Platform for building AI systems with fine-tuning and synthetic data",
      "detailed_description": "A development platform for building AI systems that integrates evaluations, RAG, agents, fine-tuning, and synthetic data generation workflows.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "synthetic_data_generation",
        "evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Kiln-AI/Kiln",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "fine-tuning",
        "synthetic-data",
        "rag"
      ],
      "id": 69
    },
    {
      "name": "Time-LLM",
      "one_line_profile": "Time Series Forecasting by Reprogramming Large Language Models",
      "detailed_description": "Official implementation of Time-LLM (ICLR 2024), a framework for reprogramming large language models to perform time series forecasting tasks.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "time_series_forecasting",
        "model_reprogramming"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/KimMeen/Time-LLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "time-series",
        "llm",
        "iclr-2024"
      ],
      "id": 70
    },
    {
      "name": "LyCORIS",
      "one_line_profile": "Parameter-efficient fine-tuning library for Stable Diffusion",
      "detailed_description": "A library implementing various parameter-efficient fine-tuning methods (LoRA, LoCon, LoHa, etc.) specifically optimized for Stable Diffusion and other generative models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "parameter_efficient_fine_tuning",
        "generative_model_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KohakuBlueleaf/LyCORIS",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lora",
        "stable-diffusion",
        "peft"
      ],
      "id": 71
    },
    {
      "name": "LPO",
      "one_line_profile": "Latent Preference Optimization for Diffusion Models",
      "detailed_description": "Implementation of Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level Preference Optimization, enabling alignment of diffusion models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Kwai-Kolors/LPO",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "diffusion-models",
        "alignment",
        "rlhf"
      ],
      "id": 72
    },
    {
      "name": "MM-RLHF",
      "one_line_profile": "Multimodal LLM Alignment Framework",
      "detailed_description": "A framework for multimodal large language model alignment, implementing RLHF techniques adapted for multimodal contexts.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "multimodal_learning",
        "rlhf"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Kwai-YuanQi/MM-RLHF",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "rlhf",
        "alignment"
      ],
      "id": 73
    },
    {
      "name": "Open-Assistant",
      "one_line_profile": "Open source chat-based assistant and data collection platform",
      "detailed_description": "A massive open-source project providing tools for data collection, RLHF, and training of chat-based AI assistants.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_collection",
        "rlhf",
        "model_training"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/LAION-AI/Open-Assistant",
      "help_website": [
        "https://open-assistant.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "chatbot",
        "open-source"
      ],
      "id": 74
    },
    {
      "name": "CHiP",
      "one_line_profile": "Cross-modal Hierarchical Direct Preference Optimization",
      "detailed_description": "Implementation of CHiP (ICLR 2025), a method for cross-modal hierarchical direct preference optimization for aligning multimodal LLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "dpo",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LVUGAI/CHiP",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dpo",
        "multimodal",
        "iclr-2025"
      ],
      "id": 75
    },
    {
      "name": "BELLE",
      "one_line_profile": "Open-source Chinese dialogue model engine and training codebase",
      "detailed_description": "An open-source project for Chinese dialogue large language models, providing training code, data, and model checkpoints for instruction tuning and alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/LianjiaTech/BELLE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "chinese-nlp",
        "instruction-tuning"
      ],
      "id": 76
    },
    {
      "name": "Lit-LLaMA",
      "one_line_profile": "Implementation of LLaMA for pre-training and fine-tuning",
      "detailed_description": "A clean, hackable implementation of the LLaMA language model, supporting pre-training, fine-tuning (LoRA, Adapter), and quantization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "pre_training",
        "fine_tuning",
        "peft"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lightning-AI/lit-llama",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llama",
        "fine-tuning",
        "lora"
      ],
      "id": 77
    },
    {
      "name": "APO",
      "one_line_profile": "Adversarial Preference Optimization for LLM alignment",
      "detailed_description": "Implementation of Adversarial Preference Optimization (ACL 2024), a method for aligning large language models using adversarial training techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Linear95/APO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "acl-2024",
        "adversarial-training"
      ],
      "id": 78
    },
    {
      "name": "CTune-MLX",
      "one_line_profile": "Fine-tuning tool for Apple Silicon (MLX)",
      "detailed_description": "A fine-tuning tool based on the MLX framework, designed to enable efficient model tuning on Apple Silicon devices.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "on_device_training"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/Lt2023/CTune-MLX",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "mlx",
        "fine-tuning",
        "apple-silicon"
      ],
      "id": 79
    },
    {
      "name": "DGPO",
      "one_line_profile": "Direct Group Preference Optimization for Diffusion Models",
      "detailed_description": "Implementation of Direct Group Preference Optimization for reinforcing diffusion models, enabling efficient alignment with human preferences.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "diffusion_model_tuning"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/Luo-Yihong/DGPO",
      "help_website": [],
      "license": null,
      "tags": [
        "diffusion-models",
        "alignment",
        "rl"
      ],
      "id": 80
    },
    {
      "name": "Genome_Factory",
      "one_line_profile": "Library for Tuning, Deploying and Interpreting Genomic Models",
      "detailed_description": "An integrated library designed for the development, fine-tuning, deployment, and interpretation of deep learning models in genomics.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "genomics_modeling",
        "fine_tuning",
        "interpretation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MAGICS-LAB/Genome_Factory",
      "help_website": [],
      "license": null,
      "tags": [
        "genomics",
        "bioinformatics",
        "deep-learning"
      ],
      "id": 81
    },
    {
      "name": "DPO-Shift",
      "one_line_profile": "Shifting the Distribution of Direct Preference Optimization",
      "detailed_description": "Implementation of DPO-Shift, an algorithm that improves Direct Preference Optimization by shifting the distribution of preference data.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "dpo"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Meaquadddd/DPO-Shift",
      "help_website": [],
      "license": null,
      "tags": [
        "dpo",
        "alignment",
        "llm"
      ],
      "id": 82
    },
    {
      "name": "SAN",
      "one_line_profile": "Open-vocabulary Semantic Segmentation",
      "detailed_description": "Implementation of Side Adapter Network (SAN) for open-vocabulary semantic segmentation, allowing models to segment objects based on arbitrary text descriptions.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "semantic_segmentation",
        "computer_vision"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MendelXu/SAN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-segmentation",
        "open-vocabulary",
        "vision"
      ],
      "id": 83
    },
    {
      "name": "Shimmy",
      "one_line_profile": "Rust inference server for GGUF/SafeTensors models",
      "detailed_description": "A high-performance, Python-free inference server written in Rust, supporting GGUF and SafeTensors models with OpenAI-API compatibility.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "inference",
        "model_serving"
      ],
      "application_level": "service",
      "primary_language": "Rust",
      "repo_url": "https://github.com/Michael-A-Kuykendall/shimmy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "inference-server",
        "rust",
        "gguf"
      ],
      "id": 84
    },
    {
      "name": "VLA0-TRL",
      "one_line_profile": "Reimplementation of VLA-0 using TRL",
      "detailed_description": "An unofficial reimplementation of the VLA-0 (Vision-Language-Action) model training using the TRL (Transformer Reinforcement Learning) library.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "robotics",
        "fine_tuning",
        "vla"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MilkClouds/vla0-trl",
      "help_website": [],
      "license": null,
      "tags": [
        "robotics",
        "trl",
        "vla"
      ],
      "id": 85
    },
    {
      "name": "GPTQModel",
      "one_line_profile": "LLM model quantization toolkit with hardware acceleration",
      "detailed_description": "A toolkit for LLM model quantization (compression) supporting hardware acceleration for Nvidia CUDA, AMD ROCm, and Intel XPU, facilitating efficient model deployment.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ModelCloud/GPTQModel",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "quantization",
        "gptq",
        "model-compression"
      ],
      "id": 86
    },
    {
      "name": "NExT-GPT",
      "one_line_profile": "Any-to-Any Multimodal Large Language Model",
      "detailed_description": "Code and models for NExT-GPT (ICML 2024), an any-to-any multimodal large language model capable of processing and generating various modalities.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "multimodal_learning",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NExT-GPT/NExT-GPT",
      "help_website": [
        "https://next-gpt.github.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "multimodal-llm",
        "icml-2024",
        "generative-ai"
      ],
      "id": 87
    },
    {
      "name": "MAPO",
      "one_line_profile": "Multilingual alignment-as-preference optimization implementation",
      "detailed_description": "An implementation of the MAPO algorithm designed to advance multilingual reasoning capabilities in large language models through preference optimization techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NJUNLP/MAPO",
      "help_website": [],
      "license": null,
      "tags": [
        "multilingual",
        "alignment",
        "dpo",
        "reasoning"
      ],
      "id": 88
    },
    {
      "name": "DoRA",
      "one_line_profile": "Weight-decomposed low-rank adaptation for parameter-efficient fine-tuning",
      "detailed_description": "The official PyTorch implementation of DoRA, a PEFT method that decomposes weights into magnitude and direction components to improve fine-tuning performance and stability.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "model_adaptation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVlabs/DoRA",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "peft",
        "lora",
        "weight-decomposition",
        "fine-tuning"
      ],
      "id": 89
    },
    {
      "name": "catk",
      "one_line_profile": "Closed-loop supervised fine-tuning toolkit for traffic models",
      "detailed_description": "A toolkit for the closed-loop supervised fine-tuning of tokenized traffic models, enabling the generation and refinement of realistic traffic simulations.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "simulation_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVlabs/catk",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "traffic-simulation",
        "sft",
        "closed-loop"
      ],
      "id": 90
    },
    {
      "name": "OneTrainer",
      "one_line_profile": "Comprehensive training platform for Stable Diffusion models",
      "detailed_description": "A one-stop GUI and backend solution for training Stable Diffusion models, supporting various fine-tuning methods like LoRA and embeddings for generative modeling.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "image_synthesis"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Nerogar/OneTrainer",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "stable-diffusion",
        "training-gui",
        "lora"
      ],
      "id": 91
    },
    {
      "name": "Vision-LLM-Alignment",
      "one_line_profile": "Alignment toolkit for vision-based Large Language Models",
      "detailed_description": "A codebase providing SFT, RLHF, and DPO implementations specifically designed for aligning vision-based LLMs such as LLaVA and LLaMA-Vision.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NiuTrans/Vision-LLM-Alignment",
      "help_website": [],
      "license": null,
      "tags": [
        "vllm",
        "dpo",
        "rlhf",
        "sft"
      ],
      "id": 92
    },
    {
      "name": "InsTag",
      "one_line_profile": "Data analysis tool for LLM supervised fine-tuning",
      "detailed_description": "A tool designed to analyze and tag data used in Large Language Model supervised fine-tuning, helping researchers understand data distribution and quality.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_analysis",
        "data_tagging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OFA-Sys/InsTag",
      "help_website": [],
      "license": null,
      "tags": [
        "sft",
        "data-analysis",
        "instruction-tuning"
      ],
      "id": 93
    },
    {
      "name": "OFA",
      "one_line_profile": "Unified sequence-to-sequence framework for multimodal tasks",
      "detailed_description": "A framework unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning paradigm, supporting pretraining and fine-tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "multimodal_learning",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OFA-Sys/OFA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "seq2seq",
        "unified-architecture"
      ],
      "id": 94
    },
    {
      "name": "Unlearn-Simple",
      "one_line_profile": "Negative preference optimization for LLM unlearning",
      "detailed_description": "An implementation of negative preference optimization techniques designed for efficient and effective unlearning in Large Language Models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "unlearning",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OPTML-Group/Unlearn-Simple",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "unlearning",
        "preference-optimization",
        "safety"
      ],
      "id": 95
    },
    {
      "name": "ViT_PEFT_Vision",
      "one_line_profile": "Parameter-efficient fine-tuning library for Vision Transformers",
      "detailed_description": "A codebase providing implementations and insights for applying Parameter-Efficient Fine-Tuning (PEFT) methods specifically to Vision Transformers (ViT) in visual recognition tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "computer_vision"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/OSU-MLB/ViT_PEFT_Vision",
      "help_website": [],
      "license": null,
      "tags": [
        "vit",
        "peft",
        "visual-recognition"
      ],
      "id": 96
    },
    {
      "name": "InternVideo",
      "one_line_profile": "Video foundation models for multimodal understanding",
      "detailed_description": "A comprehensive library containing video foundation models and tools for multimodal video understanding, supporting various downstream tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "video_understanding",
        "multimodal_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/InternVideo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "video-foundation-model",
        "multimodal",
        "computer-vision"
      ],
      "id": 97
    },
    {
      "name": "LLaMA-Adapter",
      "one_line_profile": "Efficient fine-tuning method for LLaMA models",
      "detailed_description": "An implementation of LLaMA-Adapter, a lightweight adaptation method for fine-tuning LLaMA models to follow instructions with minimal parameter overhead.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "instruction_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/LLaMA-Adapter",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "adapter",
        "llama",
        "efficient-tuning"
      ],
      "id": 98
    },
    {
      "name": "TPO",
      "one_line_profile": "Task preference optimization for multimodal LLMs",
      "detailed_description": "A tool for Task Preference Optimization, designed to improve Multimodal Large Language Models by aligning them with vision tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "multimodal_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/OpenGVLab/TPO",
      "help_website": [],
      "license": null,
      "tags": [
        "preference-optimization",
        "mllm",
        "vision-alignment"
      ],
      "id": 99
    },
    {
      "name": "MOSS-RLHF",
      "one_line_profile": "PPO-based RLHF implementation for LLMs",
      "detailed_description": "A codebase revealing the implementation details of Reinforcement Learning from Human Feedback (RLHF), specifically focusing on the PPO algorithm for large language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenLMLab/MOSS-RLHF",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ppo",
        "rlhf",
        "alignment"
      ],
      "id": 100
    },
    {
      "name": "ART",
      "one_line_profile": "Agent Reinforcement Trainer for multi-step tasks",
      "detailed_description": "A reinforcement learning training framework (Agent Reinforcement Trainer) designed for training multi-step agents using GRPO on models like Qwen and Llama.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "agent_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenPipe/ART",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "grpo",
        "agent-training",
        "rl"
      ],
      "id": 101
    },
    {
      "name": "OpenPipe",
      "one_line_profile": "Platform for converting prompts into fine-tuned models",
      "detailed_description": "A developer tool and platform that facilitates the collection of prompt data and the creation of fine-tuned models to optimize cost and latency.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_distillation"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/OpenPipe/OpenPipe",
      "help_website": [
        "https://openpipe.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "fine-tuning",
        "distillation",
        "prompt-engineering"
      ],
      "id": 102
    },
    {
      "name": "OpenRLHF",
      "one_line_profile": "Scalable and high-performance RLHF framework",
      "detailed_description": "An easy-to-use, scalable, and high-performance framework for Reinforcement Learning from Human Feedback (RLHF), built on Ray and supporting PPO, GRPO, and other algorithms.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenRLHF/OpenRLHF",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "ray",
        "ppo",
        "distributed-training"
      ],
      "id": 103
    },
    {
      "name": "align-anything",
      "one_line_profile": "Framework for training all-modality models with feedback",
      "detailed_description": "A comprehensive framework for aligning models across various modalities (text, image, video, audio) using feedback mechanisms.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "multimodal_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PKU-Alignment/align-anything",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "multimodal",
        "feedback-learning"
      ],
      "id": 104
    },
    {
      "name": "safe-rlhf",
      "one_line_profile": "Constrained value alignment via safe RLHF",
      "detailed_description": "A library implementing Safe RLHF, which decouples helpfulness and harmlessness training to achieve constrained value alignment in large language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "safety_alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PKU-Alignment/safe-rlhf",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "safety",
        "rlhf",
        "alignment"
      ],
      "id": 105
    },
    {
      "name": "Video-LLaVA",
      "one_line_profile": "Unified visual representation learning by alignment",
      "detailed_description": "An implementation of Video-LLaVA that learns united visual representations for images and videos through alignment before projection, enhancing multimodal understanding.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "multimodal_alignment",
        "video_understanding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PKU-YuanGroup/Video-LLaVA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "video-llm",
        "alignment",
        "multimodal"
      ],
      "id": 106
    },
    {
      "name": "UniPT",
      "one_line_profile": "Universal parallel tuning for transfer learning",
      "detailed_description": "A tool implementing Universal Parallel Tuning (UniPT), designed for efficient parameter and memory usage during transfer learning across various modalities.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "transfer_learning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Paranioar/UniPT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "parallel-tuning",
        "transfer-learning",
        "efficiency"
      ],
      "id": 107
    },
    {
      "name": "Alpaca-CoT",
      "one_line_profile": "Unified interface for instruction tuning and PEFT",
      "detailed_description": "A platform that unifies interfaces for instruction-tuning data (including CoT), multiple LLMs, and parameter-efficient fine-tuning methods to facilitate research.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "peft"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/PhoebusSi/Alpaca-CoT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "instruction-tuning",
        "cot",
        "peft"
      ],
      "id": 108
    },
    {
      "name": "tabpfn-time-series",
      "one_line_profile": "Zero-shot time series forecasting with TabPFN",
      "detailed_description": "An extension of TabPFN specifically designed for zero-shot time series forecasting, enabling high-quality predictions without task-specific training.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "time_series_forecasting",
        "zero_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/PriorLabs/tabpfn-time-series",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "time-series",
        "forecasting",
        "tabpfn"
      ],
      "id": 109
    },
    {
      "name": "AdaLoRA",
      "one_line_profile": "Adaptive budget allocation for PEFT",
      "detailed_description": "The official implementation of AdaLoRA, a parameter-efficient fine-tuning method that adaptively allocates parameter budgets based on importance.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "model_compression"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/QingruZhang/AdaLoRA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "lora",
        "adaptive-tuning"
      ],
      "id": 110
    },
    {
      "name": "RLHF-V",
      "one_line_profile": "Behavior alignment for multimodal LLMs via RLHF",
      "detailed_description": "A tool for aligning Multimodal Large Language Models (MLLMs) using fine-grained correctional human feedback to improve trustworthiness and reduce hallucinations.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "multimodal_alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RLHF-V/RLHF-V",
      "help_website": [],
      "license": null,
      "tags": [
        "rlhf",
        "mllm",
        "alignment"
      ],
      "id": 111
    },
    {
      "name": "Directional-Preference-Alignment",
      "one_line_profile": "Directional preference alignment for LLMs",
      "detailed_description": "An implementation of Directional Preference Alignment, a method to align language models with user preferences by considering the direction of improvement.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/RLHFlow/Directional-Preference-Alignment",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dpo",
        "alignment",
        "preference-learning"
      ],
      "id": 112
    },
    {
      "name": "Online-DPO-R1",
      "one_line_profile": "Iterative DPO using rule-based rewards",
      "detailed_description": "A codebase for Online Direct Preference Optimization (DPO), facilitating iterative alignment of models using rule-based reward systems.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "dpo",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RLHFlow/Online-DPO-R1",
      "help_website": [],
      "license": null,
      "tags": [
        "online-dpo",
        "alignment",
        "iterative-training"
      ],
      "id": 113
    },
    {
      "name": "Online-RLHF",
      "one_line_profile": "A recipe and pipeline for online RLHF and online iterative DPO training",
      "detailed_description": "This repository provides a comprehensive recipe and implementation for Online Reinforcement Learning from Human Feedback (RLHF) and Online Iterative Direct Preference Optimization (DPO), enabling efficient alignment of Large Language Models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "dpo"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/RLHFlow/Online-RLHF",
      "help_website": [],
      "license": null,
      "tags": [
        "rlhf",
        "dpo",
        "alignment",
        "llm-training"
      ],
      "id": 114
    },
    {
      "name": "RLHF-Reward-Modeling",
      "one_line_profile": "Recipes and tools to train reward models for RLHF",
      "detailed_description": "A collection of recipes and scripts designed to train reward models, a critical component in the Reinforcement Learning from Human Feedback (RLHF) pipeline for aligning Large Language Models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "reward_modeling",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RLHFlow/RLHF-Reward-Modeling",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reward-model",
        "rlhf",
        "alignment"
      ],
      "id": 115
    },
    {
      "name": "APT",
      "one_line_profile": "Adaptive Pruning and Tuning for efficient Pretrained Language Models",
      "detailed_description": "Implementation of APT (Adaptive Pruning and Tuning), a method for efficient training and inference of Pretrained Language Models by dynamically pruning and tuning parameters.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "model_compression",
        "pruning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ROIM1998/APT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "pruning",
        "efficient-training"
      ],
      "id": 116
    },
    {
      "name": "gpu_poor",
      "one_line_profile": "Calculator for LLM token generation speed and GPU memory requirements",
      "detailed_description": "A utility tool to calculate expected token/s and GPU memory requirements for various Large Language Models, supporting different quantization methods like llama.cpp, ggml, bnb, and QLoRA.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "resource_estimation",
        "inference_planning"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/RahulSChand/gpu_poor",
      "help_website": [],
      "license": null,
      "tags": [
        "gpu-memory",
        "llm-calculator",
        "quantization"
      ],
      "id": 117
    },
    {
      "name": "ICEdit",
      "one_line_profile": "Efficient image editing using a single LoRA",
      "detailed_description": "A tool for fantastic image editing using only a single LoRA and minimal training data (0.1%), surpassing larger models in ID persistence and running on low VRAM.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "image_editing",
        "generation",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/River-Zhang/ICEdit",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "lora",
        "image-editing",
        "generative-ai"
      ],
      "id": 118
    },
    {
      "name": "CipherChat",
      "one_line_profile": "Framework to evaluate safety alignment generalization in LLMs",
      "detailed_description": "A framework designed to evaluate the generalization capability of safety alignment for Large Language Models, specifically testing robustness against cipher-based attacks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "safety_evaluation",
        "alignment_evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/RobustNLP/CipherChat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "safety",
        "alignment",
        "evaluation"
      ],
      "id": 119
    },
    {
      "name": "SPO",
      "one_line_profile": "Step-by-step Preference Optimization for diffusion models",
      "detailed_description": "Implementation of Step-by-step Preference Optimization (SPO) to align aesthetic post-training diffusion models with generic preferences.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization",
        "diffusion_models"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RockeyCoss/SPO",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dpo",
        "diffusion",
        "alignment"
      ],
      "id": 120
    },
    {
      "name": "S-LoRA",
      "one_line_profile": "Scalable serving system for concurrent LoRA adapters",
      "detailed_description": "A serving system designed to efficiently serve thousands of concurrent LoRA adapters, optimizing memory and throughput for multi-tenant LLM serving.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_serving",
        "peft_serving"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/S-LoRA/S-LoRA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lora",
        "serving",
        "inference"
      ],
      "id": 121
    },
    {
      "name": "ADHMR",
      "one_line_profile": "Aligning Diffusion-based Human Mesh Recovery via DPO",
      "detailed_description": "Official code for ADHMR, a method to align diffusion-based human mesh recovery models using Direct Preference Optimization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "human_mesh_recovery",
        "dpo"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SMPLCap/ADHMR",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "diffusion",
        "dpo",
        "human-mesh"
      ],
      "id": 122
    },
    {
      "name": "DiffusionDPO",
      "one_line_profile": "Direct Preference Optimization for Diffusion Model Alignment",
      "detailed_description": "Implementation of Direct Preference Optimization (DPO) specifically adapted for aligning diffusion models to human preferences.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "dpo",
        "diffusion_models"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SalesforceAIResearch/DiffusionDPO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dpo",
        "diffusion",
        "alignment"
      ],
      "id": 123
    },
    {
      "name": "TapeAgents",
      "one_line_profile": "Framework for LLM Agent development lifecycle",
      "detailed_description": "A framework that facilitates all stages of the Large Language Model (LLM) Agent development lifecycle, enabling the creation and management of intelligent agents.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "agent_development",
        "modeling"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/ServiceNow/TapeAgents",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-agent",
        "framework",
        "ai-agents"
      ],
      "id": 124
    },
    {
      "name": "DePT",
      "one_line_profile": "Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning",
      "detailed_description": "Implementation of DePT (Decomposed Prompt Tuning), a parameter-efficient fine-tuning method for large language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "prompt_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ShiZhengyan/DePT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "prompt-tuning",
        "llm"
      ],
      "id": 125
    },
    {
      "name": "SparseAdapter",
      "one_line_profile": "Sparse Adapter for Parameter-Efficient Fine-Tuning",
      "detailed_description": "Source code for SparseAdapter, an approach to improve the parameter efficiency of adapters in fine-tuning pre-trained language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "adapter_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Shwai-He/SparseAdapter",
      "help_website": [],
      "license": null,
      "tags": [
        "peft",
        "adapter",
        "sparse-tuning"
      ],
      "id": 126
    },
    {
      "name": "Simplifine",
      "one_line_profile": "Easy open-source LLM finetuning tool",
      "detailed_description": "A user-friendly tool for LLM fine-tuning offering one-line commands, cloud integration, and support for popular optimization frameworks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Simplifine-gamedev/Simplifine",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "fine-tuning",
        "llm",
        "simplification"
      ],
      "id": 127
    },
    {
      "name": "DRPO",
      "one_line_profile": "Dynamic Rewarding with Prompt Optimization for self-alignment",
      "detailed_description": "Implementation of DRPO (Dynamic Rewarding with Prompt Optimization), a tuning-free approach for self-alignment of LLMs using search-based optimization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "prompt_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Singla17/dynamic-alignment-optimization",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "prompt-optimization",
        "self-improvement"
      ],
      "id": 128
    },
    {
      "name": "SwanLab",
      "one_line_profile": "AI training tracking and visualization tool",
      "detailed_description": "An open-source, modern AI training tracking and visualization tool that integrates with popular frameworks like PyTorch, Transformers, and LLaMA Factory to monitor experiments.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "experiment_tracking",
        "visualization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/SwanHubX/SwanLab",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "experiment-tracking",
        "visualization",
        "mlops"
      ],
      "id": 129
    },
    {
      "name": "LongAlign",
      "one_line_profile": "Recipe for Long Context Alignment of LLMs",
      "detailed_description": "A comprehensive recipe and toolset for aligning Large Language Models to handle long contexts effectively, including data processing and training strategies.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "long_context"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/THUDM/LongAlign",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "long-context",
        "llm"
      ],
      "id": 130
    },
    {
      "name": "P-tuning",
      "one_line_profile": "Method for prompt tuning language models",
      "detailed_description": "Implementation of P-tuning, a novel method to tune language models using continuous prompt embeddings, enabling GPT models to understand prompts better.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "prompt_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/THUDM/P-tuning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "prompt-tuning",
        "p-tuning"
      ],
      "id": 131
    },
    {
      "name": "P-tuning-v2",
      "one_line_profile": "Optimized deep prompt tuning strategy",
      "detailed_description": "An optimized deep prompt tuning strategy (P-tuning v2) that achieves comparable performance to fine-tuning across various scales and tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "prompt_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/THUDM/P-tuning-v2",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "peft",
        "prompt-tuning",
        "deep-tuning"
      ],
      "id": 132
    },
    {
      "name": "MoE-PEFT",
      "one_line_profile": "Efficient fine-tuning factory optimized for Mixture-of-Experts (MoE) models",
      "detailed_description": "A specialized framework designed for parameter-efficient fine-tuning (PEFT) of Mixture-of-Experts (MoE) large language models, supporting methods like LoRA and QLoRA specifically adapted for MoE architectures.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft",
        "moe_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TUDB-Labs/MoE-PEFT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "moe",
        "peft",
        "llm-training",
        "lora"
      ],
      "id": 133
    },
    {
      "name": "mLoRA",
      "one_line_profile": "High-efficiency factory for building and training multiple LoRA adapters",
      "detailed_description": "An efficient framework for fine-tuning Large Language Models (LLMs) using LoRA (Low-Rank Adaptation) and its variants. It supports training multiple adapters concurrently and is optimized for throughput and memory usage.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft",
        "adapter_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TUDB-Labs/mLoRA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lora",
        "multi-adapter",
        "fine-tuning",
        "llm"
      ],
      "id": 134
    },
    {
      "name": "PIXIU",
      "one_line_profile": "Comprehensive benchmark and instruction tuning suite for financial LLMs",
      "detailed_description": "An open-source resource featuring financial large language models (LLMs), instruction tuning datasets, and evaluation benchmarks designed to holistically assess the performance of financial AI models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "benchmarking",
        "instruction_tuning",
        "evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/The-FinAI/PIXIU",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "financial-llm",
        "benchmark",
        "instruction-tuning",
        "evaluation"
      ],
      "id": 135
    },
    {
      "name": "VL-RLHF",
      "one_line_profile": "RLHF infrastructure for fine-tuning Vision-Language Models",
      "detailed_description": "A specialized infrastructure and codebase for performing Reinforcement Learning from Human Feedback (RLHF) on Vision-Language Models (VLMs), facilitating alignment and optimization of multimodal AI.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "multimodal_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TideDra/VL-RLHF",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "vlm",
        "alignment",
        "multimodal"
      ],
      "id": 136
    },
    {
      "name": "Effective LLM Alignment",
      "one_line_profile": "Toolkit for efficient Large Language Model alignment",
      "detailed_description": "A toolkit designed to streamline the process of aligning Large Language Models (LLMs), likely providing implementations of various alignment algorithms and utilities for training pipelines.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/VikhrModels/effective_llm_alignment",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "llm",
        "toolkit"
      ],
      "id": 137
    },
    {
      "name": "SLAM-LLM",
      "one_line_profile": "Framework for speech, audio, and music processing using LLMs",
      "detailed_description": "A comprehensive framework leveraging Large Language Models for processing and understanding speech, language, audio, and music, enabling multimodal tasks and research.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "multimodal_processing",
        "audio_analysis",
        "speech_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/X-LANCE/SLAM-LLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "audio",
        "speech",
        "music",
        "llm",
        "multimodal"
      ],
      "id": 138
    },
    {
      "name": "grpo-flat",
      "one_line_profile": "Lightweight training tool for GRPO with low resource requirements",
      "detailed_description": "A training tool designed to facilitate GRPO (Generative Reward Policy Optimization) training with minimal dataset requirements and support for low-resource environments, including 8bit/4bit quantization and LoRA/QLoRA.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "fine_tuning",
        "quantization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/XU-YIJIE/grpo-flat",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "grpo",
        "low-resource",
        "quantization",
        "lora"
      ],
      "id": 139
    },
    {
      "name": "TRLO",
      "one_line_profile": "Efficient LiDAR Odometry with 3D dynamic object tracking",
      "detailed_description": "A LiDAR odometry system that integrates 3D dynamic object tracking and removal, providing a robust solution for simultaneous localization and mapping (SLAM) in dynamic environments.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "slam",
        "lidar_processing",
        "tracking"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/Yaepiii/TRLO",
      "help_website": [],
      "license": null,
      "tags": [
        "lidar",
        "odometry",
        "slam",
        "robotics"
      ],
      "id": 140
    },
    {
      "name": "YiVal",
      "one_line_profile": "Automatic prompt engineering and evaluation assistant for GenAI",
      "detailed_description": "A tool designed to automate the prompt engineering process, providing evaluation and optimization capabilities for Generative AI applications to improve model performance and alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "prompt_engineering",
        "evaluation",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/YiVal/YiVal",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prompt-engineering",
        "genai",
        "automation",
        "evaluation"
      ],
      "id": 141
    },
    {
      "name": "Adapters",
      "one_line_profile": "A unified library for parameter-efficient and modular transfer learning",
      "detailed_description": "Adapters is a library that integrates adapter modules into pre-trained language models, enabling efficient fine-tuning and modular transfer learning. It supports various PEFT methods and composition of adapters.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "transfer_learning",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/adapter-hub/adapters",
      "help_website": [
        "https://docs.adapterhub.ml/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "peft",
        "adapters",
        "transfer-learning",
        "nlp"
      ],
      "id": 142
    },
    {
      "name": "Firefly",
      "one_line_profile": "A WebGL interactive particle viewer for scientific data",
      "detailed_description": "Firefly is a browser-based interactive visualization tool designed for exploring particle-based scientific datasets, such as those from astronomical simulations.",
      "domains": [
        "Scientific Visualization"
      ],
      "subtask_category": [
        "visualization",
        "particle_viewing",
        "data_exploration"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ageller/Firefly",
      "help_website": [
        "http://ageller.github.io/Firefly/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "visualization",
        "astronomy",
        "webgl",
        "particles"
      ],
      "id": 143
    },
    {
      "name": "ROLL",
      "one_line_profile": "Efficient scaling library for Reinforcement Learning with Large Language Models",
      "detailed_description": "ROLL is a library designed to scale reinforcement learning with large language models (RLHF), focusing on efficiency and user-friendliness for aligning LLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "alignment",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/alibaba/ROLL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "llm",
        "alignment",
        "reinforcement-learning"
      ],
      "id": 144
    },
    {
      "name": "RewardBench",
      "one_line_profile": "Evaluation tool and benchmark for reward models",
      "detailed_description": "RewardBench is a toolkit and benchmark designed to evaluate the performance and capabilities of reward models used in RLHF pipelines.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking",
        "reward_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/reward-bench",
      "help_website": [
        "https://huggingface.co/spaces/allenai/reward-bench"
      ],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "rlhf",
        "reward-model",
        "benchmark"
      ],
      "id": 145
    },
    {
      "name": "SMASHED",
      "one_line_profile": "Toolkit for applying transformations to dataset samples in NLP pipelines",
      "detailed_description": "SMASHED is a data processing toolkit designed to handle tokenization, prompting, batching, and field extraction for NLP datasets, supporting various data sources.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "data_processing",
        "tokenization",
        "pipeline"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/smashed",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-processing",
        "nlp",
        "pipeline"
      ],
      "id": 146
    },
    {
      "name": "Aphrodite Engine",
      "one_line_profile": "Large-scale LLM inference engine",
      "detailed_description": "Aphrodite Engine is a high-performance inference engine for Large Language Models, designed to serve thousands of users with fast throughput and low latency.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "inference",
        "serving",
        "model_deployment"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/aphrodite-engine/aphrodite-engine",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "inference",
        "llm",
        "serving",
        "vllm"
      ],
      "id": 147
    },
    {
      "name": "Argilla",
      "one_line_profile": "Collaboration tool for data annotation and dataset management",
      "detailed_description": "Argilla is an open-source platform for data-centric AI, enabling collaboration between engineers and domain experts to label, validate, and refine datasets for LLM training and alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_annotation",
        "rlhf",
        "data_management",
        "quality_control"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/argilla-io/argilla",
      "help_website": [
        "https://docs.argilla.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-annotation",
        "rlhf",
        "dataset",
        "nlp"
      ],
      "id": 148
    },
    {
      "name": "Distilabel",
      "one_line_profile": "Framework for synthetic data generation and AI feedback",
      "detailed_description": "Distilabel is a framework designed to build scalable pipelines for generating synthetic data and collecting AI feedback, facilitating the creation of high-quality datasets for model training and alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "synthetic_data_generation",
        "ai_feedback",
        "alignment",
        "data_augmentation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/argilla-io/distilabel",
      "help_website": [
        "https://distilabel.argilla.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "synthetic-data",
        "rlhf",
        "dpo",
        "feedback"
      ],
      "id": 149
    },
    {
      "name": "SiLLM",
      "one_line_profile": "Tool for training and running LLMs on Apple Silicon",
      "detailed_description": "SiLLM simplifies the process of fine-tuning and running inference for Large Language Models on Apple Silicon hardware by leveraging the MLX framework.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "fine_tuning",
        "inference",
        "local_deployment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/armbues/SiLLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mlx",
        "apple-silicon",
        "llm",
        "fine-tuning"
      ],
      "id": 150
    },
    {
      "name": "Axolotl",
      "one_line_profile": "A comprehensive post-training framework for fine-tuning Large Language Models (LLMs)",
      "detailed_description": "Axolotl is a tool designed to streamline the fine-tuning of various AI models, offering support for multiple training methods including full fine-tuning, LoRA, QLoRA, and ReLoRA. It provides a unified configuration interface (YAML) to manage datasets, model architectures, and training hyperparameters, widely used in the open-source AI community for customizing models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "instruction_tuning",
        "peft"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/axolotl-ai-cloud/axolotl",
      "help_website": [
        "https://axolotl-ai-cloud.github.io/axolotl/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "fine-tuning",
        "lora",
        "qlora",
        "automation"
      ],
      "id": 151
    },
    {
      "name": "Curator",
      "one_line_profile": "Library for synthetic data curation and structured data extraction using LLMs",
      "detailed_description": "Curator is a Python library designed to automate the creation and curation of high-quality synthetic datasets for post-training and fine-tuning AI models. It leverages Large Language Models to generate, filter, and structure data, facilitating the data preparation phase of model alignment and instruction tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_curation",
        "synthetic_data_generation",
        "alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bespokelabsai/curator",
      "help_website": [
        "https://github.com/bespokelabsai/curator"
      ],
      "license": "Apache-2.0",
      "tags": [
        "synthetic-data",
        "data-curation",
        "llm",
        "alignment"
      ],
      "id": 152
    },
    {
      "name": "bitsandbytes",
      "one_line_profile": "Lightweight wrapper for CUDA custom functions focusing on 8-bit optimizers and quantization",
      "detailed_description": "bitsandbytes is a library that provides efficient CUDA implementations for 8-bit optimizers, matrix multiplication (LLM.int8()), and quantization functions. It is a critical dependency for QLoRA and other parameter-efficient fine-tuning methods, enabling the training of large language models on consumer-grade hardware.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "quantization",
        "optimization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bitsandbytes-foundation/bitsandbytes",
      "help_website": [
        "https://huggingface.co/docs/bitsandbytes/index"
      ],
      "license": "MIT",
      "tags": [
        "quantization",
        "cuda",
        "optimization",
        "qlora"
      ],
      "id": 153
    },
    {
      "name": "Prompt Poet",
      "one_line_profile": "Tool for designing and managing prompts for LLMs",
      "detailed_description": "Prompt Poet is a library that simplifies and streamlines the design of prompts for Large Language Models. It provides a low-code approach to constructing complex prompt contexts, managing templates, and integrating dynamic data, which is essential for instruction tuning and in-context learning workflows.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "prompt_engineering",
        "instruction_tuning",
        "context_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/character-ai/prompt-poet",
      "help_website": [
        "https://github.com/character-ai/prompt-poet"
      ],
      "license": "MIT",
      "tags": [
        "prompt-engineering",
        "llm",
        "templating",
        "low-code"
      ],
      "id": 154
    },
    {
      "name": "LoRA (cloneofsimo)",
      "one_line_profile": "Implementation of Low-rank adaptation for fine-tuning diffusion models",
      "detailed_description": "This repository provides a widely used implementation of Low-Rank Adaptation (LoRA) specifically tailored for fine-tuning diffusion models. It allows for parameter-efficient adaptation of large generative models, enabling users to train models on new concepts or styles with significantly reduced computational resources.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "fine_tuning",
        "diffusion_models"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/cloneofsimo/lora",
      "help_website": [
        "https://github.com/cloneofsimo/lora"
      ],
      "license": "Apache-2.0",
      "tags": [
        "lora",
        "stable-diffusion",
        "peft",
        "fine-tuning"
      ],
      "id": 155
    },
    {
      "name": "Fluxgym",
      "one_line_profile": "Simple UI for training FLUX LoRA models with low VRAM support",
      "detailed_description": "A lightweight user interface designed to simplify the training of LoRA (Low-Rank Adaptation) models for the FLUX image generation architecture. It lowers the barrier for fine-tuning foundation models by providing a streamlined workflow that supports low VRAM environments, making it accessible for researchers and developers working on generative model adaptation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "fine_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/cocktailpeanut/fluxgym",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lora",
        "flux",
        "fine-tuning",
        "ui",
        "generative-ai"
      ],
      "id": 156
    },
    {
      "name": "PEFT-SAM",
      "one_line_profile": "Parameter Efficient Fine-Tuning for Segment Anything Model (SAM)",
      "detailed_description": "A specialized library for applying Parameter Efficient Fine-Tuning (PEFT) techniques to the Segment Anything Model (SAM), specifically tailored for computational cell analytics and biological image segmentation tasks. It enables the adaptation of the powerful SAM foundation model to specific scientific domains with limited data and computational resources.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "image_segmentation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/computational-cell-analytics/peft-sam",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sam",
        "peft",
        "bioimaging",
        "segmentation",
        "fine-tuning"
      ],
      "id": 157
    },
    {
      "name": "LaMDA-rlhf-pytorch",
      "one_line_profile": "PyTorch implementation of LaMDA with RLHF alignment",
      "detailed_description": "An open-source implementation of Google's LaMDA architecture in PyTorch, incorporating Reinforcement Learning from Human Feedback (RLHF) for model alignment. It serves as a research framework for studying and developing large language models and alignment techniques similar to those used in ChatGPT.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/conceptofmind/LaMDA-rlhf-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rlhf",
        "lamda",
        "alignment",
        "llm",
        "pytorch"
      ],
      "id": 158
    },
    {
      "name": "ViT-Adapter",
      "one_line_profile": "Vision Transformer Adapter for dense prediction tasks",
      "detailed_description": "A framework that adapts plain Vision Transformers (ViT) for dense prediction tasks such as object detection and semantic segmentation. It introduces an adapter mechanism that injects inductive biases into the ViT architecture, enabling efficient fine-tuning and improved performance on downstream vision tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "dense_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/czczup/ViT-Adapter",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "vision-transformer",
        "adapter",
        "peft",
        "object-detection",
        "segmentation"
      ],
      "id": 159
    },
    {
      "name": "DataDreamer",
      "one_line_profile": "Library for synthetic data generation and model alignment",
      "detailed_description": "A comprehensive library for prompting, generating synthetic data, and training/aligning Large Language Models (LLMs). It automates the workflow of creating high-quality datasets from LLMs and using them to fine-tune or align models, facilitating research in data-centric AI and model adaptation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_generation",
        "alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/datadreamer-dev/DataDreamer",
      "help_website": [
        "https://datadreamer.dev"
      ],
      "license": "MIT",
      "tags": [
        "synthetic-data",
        "alignment",
        "llm",
        "fine-tuning",
        "prompt-engineering"
      ],
      "id": 160
    },
    {
      "name": "Data-Juicer",
      "one_line_profile": "Data processing system for foundation models",
      "detailed_description": "A robust data processing system designed for Large Language Models (LLMs). It provides a wide range of operators for data filtering, cleaning, deduplication, and formatting, ensuring high-quality data input for pre-training and fine-tuning foundation models.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "data_processing",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/datajuicer/data-juicer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-processing",
        "llm",
        "etl",
        "data-cleaning",
        "foundation-models"
      ],
      "id": 161
    },
    {
      "name": "EPOSearch",
      "one_line_profile": "Solver for preference-based multi-objective optimization",
      "detailed_description": "A Python library implementing the Exact Pareto Optimal Search algorithm for preference-based Multi-Objective Optimization (MOO). It is designed to find solutions that align with user preferences in complex optimization landscapes, applicable in scientific modeling and decision-making processes.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "optimization",
        "scientific_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dbmptr/EPOSearch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "optimization",
        "multi-objective",
        "pareto",
        "preference-learning"
      ],
      "id": 162
    },
    {
      "name": "Instruct-Eval",
      "one_line_profile": "Evaluation suite for instruction-tuned models",
      "detailed_description": "A framework for quantitatively evaluating instruction-tuned Large Language Models (LLMs) such as Alpaca and Flan-T5. It provides a standardized set of tasks and metrics to assess the performance of models on held-out instructions, facilitating the comparison and validation of alignment techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/declare-lab/instruct-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "instruction-tuning",
        "llm",
        "benchmarking"
      ],
      "id": 163
    },
    {
      "name": "LoRA Easy Training Scripts",
      "one_line_profile": "GUI and scripts for training LoRA/LoCon models",
      "detailed_description": "A user interface and collection of scripts designed to simplify the training of LoRA (Low-Rank Adaptation) and LoCon models using `sd-scripts`. It provides an accessible workflow for fine-tuning generative models, managing configuration, and executing training jobs without deep command-line expertise.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_training"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/derrian-distro/LoRA_Easy_Training_Scripts",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "lora",
        "gui",
        "fine-tuning",
        "stable-diffusion",
        "training-scripts"
      ],
      "id": 164
    },
    {
      "name": "ControlNeXt",
      "one_line_profile": "Library for controllable image and video generation",
      "detailed_description": "A comprehensive library for controllable generation in image and video models. It implements advanced techniques like ControlNet and ControlNeXt, allowing for precise spatial and temporal control over the generation process, which is essential for scientific visualization and synthetic data generation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "generation",
        "control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dvlab-research/ControlNeXt",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "controlnet",
        "generation",
        "video-generation",
        "lora",
        "controllable-ai"
      ],
      "id": 165
    },
    {
      "name": "LongLoRA",
      "one_line_profile": "Efficient fine-tuning for long-context LLMs",
      "detailed_description": "A tool and method for extending the context window of Large Language Models (LLMs) through efficient fine-tuning. It utilizes shifted sparse attention (S2-Attn) to enable training on long sequences with reduced computational overhead, facilitating the processing of long scientific texts and data sequences.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "context_extension"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dvlab-research/LongLoRA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "long-context",
        "lora",
        "fine-tuning",
        "llm",
        "efficiency"
      ],
      "id": 166
    },
    {
      "name": "TuneAI",
      "one_line_profile": "Automation tool for OpenAI model fine-tuning",
      "detailed_description": "A utility tool that automates the process of fine-tuning OpenAI models. It handles transcript cleaning, prompt-completion pair generation, and dataset preparation, streamlining the workflow for creating custom models from raw text or video inputs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_preparation",
        "fine_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/emmethalm/tuneAI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "openai",
        "fine-tuning",
        "automation",
        "dataset-creation"
      ],
      "id": 167
    },
    {
      "name": "DPO (Direct Preference Optimization)",
      "one_line_profile": "Reference implementation of Direct Preference Optimization for LLM alignment",
      "detailed_description": "The official reference implementation for Direct Preference Optimization (DPO), a stable and computationally lightweight alternative to RLHF for aligning language models with human preferences. It provides the core loss functions and training loops required to fine-tune models directly on preference data.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization",
        "rlhf_alternative"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/eric-mitchell/direct-preference-optimization",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dpo",
        "alignment",
        "llm",
        "preference-learning"
      ],
      "id": 168
    },
    {
      "name": "GAST-Net",
      "one_line_profile": "Graph Attention Spatio-temporal Convolutional Networks for 3D Human Pose Estimation",
      "detailed_description": "A deep learning framework for 3D human pose estimation in video. It utilizes Graph Attention Spatio-temporal Convolutional Networks (GAST-Net) to model the spatial and temporal dependencies of human joints, serving as a solver for computer vision tasks related to human dynamics.",
      "domains": [
        "Computer Vision",
        "AI3"
      ],
      "subtask_category": [
        "pose_estimation",
        "3d_reconstruction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/fabro66/GAST-Net-3DPoseEstimation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pose-estimation",
        "computer-vision",
        "graph-neural-networks"
      ],
      "id": 169
    },
    {
      "name": "SecAlign",
      "one_line_profile": "Safety alignment framework defending against prompt injection via preference optimization",
      "detailed_description": "A research tool from Facebook Research that implements safety alignment techniques to defend Large Language Models (LLMs) against prompt injection attacks. It utilizes preference optimization methods to enhance model robustness.",
      "domains": [
        "AI3",
        "AI3-02",
        "AI Safety"
      ],
      "subtask_category": [
        "safety_alignment",
        "defense",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/SecAlign",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "safety",
        "alignment",
        "prompt-injection",
        "llm"
      ],
      "id": 170
    },
    {
      "name": "C3DPO",
      "one_line_profile": "Canonical 3D Pose Networks for Non-rigid Structure From Motion",
      "detailed_description": "A computer vision tool for Non-rigid Structure From Motion (NRSfM). It implements Canonical 3D Pose Networks to reconstruct 3D shape and motion from 2D landmarks, serving as a solver for 3D geometric reconstruction tasks.",
      "domains": [
        "Computer Vision",
        "AI3"
      ],
      "subtask_category": [
        "structure_from_motion",
        "3d_reconstruction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/c3dpo_nrsfm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nrsfm",
        "3d-reconstruction",
        "computer-vision"
      ],
      "id": 171
    },
    {
      "name": "trlib",
      "one_line_profile": "Library for solving trust region subproblems in optimization",
      "detailed_description": "A C library dedicated to solving the trust region subproblem, a core component in many nonlinear optimization algorithms. It is used in scientific computing for numerical optimization tasks.",
      "domains": [
        "Mathematics",
        "Scientific Computing"
      ],
      "subtask_category": [
        "optimization",
        "numerical_solver"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/felixlen/trlib",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "optimization",
        "trust-region",
        "numerical-methods"
      ],
      "id": 172
    },
    {
      "name": "finetune-whisper-lora",
      "one_line_profile": "Workflow for fine-tuning Whisper models using LoRA and PEFT",
      "detailed_description": "A specialized tool for fine-tuning OpenAI's Whisper speech recognition models using Low-Rank Adaptation (LoRA) and Parameter-Efficient Fine-Tuning (PEFT) techniques. It enables efficient adaptation of ASR models on consumer hardware.",
      "domains": [
        "AI3",
        "AI3-02",
        "Audio"
      ],
      "subtask_category": [
        "speech_recognition",
        "fine_tuning",
        "peft"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/fengredrum/finetune-whisper-lora",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "whisper",
        "lora",
        "peft",
        "asr"
      ],
      "id": 173
    },
    {
      "name": "CoPEFT",
      "one_line_profile": "Parameter-efficient fine-tuning framework for multi-agent collaborative perception",
      "detailed_description": "An implementation of the CoPEFT framework (AAAI 2025) designed for fast adaptation in multi-agent collaborative perception tasks. It applies parameter-efficient fine-tuning strategies to optimize communication and perception in multi-agent systems.",
      "domains": [
        "AI3",
        "AI3-02",
        "Robotics"
      ],
      "subtask_category": [
        "multi_agent_perception",
        "fine_tuning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/fengxueguiren/CoPEFT",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "multi-agent",
        "perception",
        "peft",
        "aaai-2025"
      ],
      "id": 174
    },
    {
      "name": "Atlas",
      "one_line_profile": "Method for knowledge composition using task vectors with learned anisotropic scaling",
      "detailed_description": "The official implementation of the Atlas method (NeurIPS 2024) for composing knowledge from different models using task vectors. It provides a solver for merging model capabilities through learned anisotropic scaling.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_merging",
        "task_vectors",
        "knowledge_composition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/fredzzhang/atlas",
      "help_website": [],
      "license": null,
      "tags": [
        "model-merging",
        "neurips-2024",
        "task-vectors"
      ],
      "id": 175
    },
    {
      "name": "General Preference Model",
      "one_line_profile": "General preference model for language model alignment beyond Bradley-Terry",
      "detailed_description": "Implementation of a general preference model (ICML 2025) for LLM alignment that extends beyond the standard Bradley-Terry model. It serves as a solver for more complex preference learning scenarios in model alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_modeling",
        "rlhf"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/general-preference/general-preference-model",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "preference-model",
        "icml-2025"
      ],
      "id": 176
    },
    {
      "name": "llm_qlora",
      "one_line_profile": "Workflow scripts for fine-tuning LLMs using QLoRA",
      "detailed_description": "A widely used collection of scripts and workflows for fine-tuning Large Language Models using Quantized LoRA (QLoRA). It facilitates the efficient adaptation of LLMs on consumer-grade GPUs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "qlora",
        "peft"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/georgesung/llm_qlora",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "qlora",
        "fine-tuning",
        "llm"
      ],
      "id": 177
    },
    {
      "name": "LLM-Finetuning-Toolkit",
      "one_line_profile": "Toolkit for fine-tuning, ablating, and testing open-source LLMs",
      "detailed_description": "A comprehensive toolkit developed by Georgian for fine-tuning, ablation studies, and unit testing of open-source Large Language Models. It provides a structured workflow for adapting LLMs to specific domains.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_evaluation",
        "ablation_study"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/georgian-io/LLM-Finetuning-Toolkit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fine-tuning",
        "llm",
        "toolkit"
      ],
      "id": 178
    },
    {
      "name": "UDS",
      "one_line_profile": "Utility-Diversity Aware Online Batch Selection for LLM SFT",
      "detailed_description": "Implementation of the UDS algorithm for online batch selection during Supervised Fine-Tuning (SFT) of LLMs. It acts as a solver to optimize data efficiency by balancing utility and diversity in training batches.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_selection",
        "sft",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gfyddha/UDS",
      "help_website": [],
      "license": null,
      "tags": [
        "data-selection",
        "sft",
        "llm"
      ],
      "id": 179
    },
    {
      "name": "SelectiveDPO",
      "one_line_profile": "Principled data selection method for DPO alignment",
      "detailed_description": "A tool implementing a principled data selection strategy for Direct Preference Optimization (DPO). It helps in identifying and filtering difficult or noisy examples to improve the stability and performance of model alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_selection",
        "alignment",
        "dpo"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/glorgao/SelectiveDPO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-selection",
        "dpo",
        "alignment"
      ],
      "id": 180
    },
    {
      "name": "prompt-tuning",
      "one_line_profile": "Original implementation of Prompt Tuning for parameter-efficient adaptation",
      "detailed_description": "The original implementation of 'The Power of Scale for Parameter-Efficient Prompt Tuning' by Google Research. It provides the solver and methodology for adapting large pre-trained models using soft prompts, a key PEFT technique.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "prompt_tuning",
        "model_adaptation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/google-research/prompt-tuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prompt-tuning",
        "peft",
        "google-research"
      ],
      "id": 181
    },
    {
      "name": "LLaVA",
      "one_line_profile": "Visual Instruction Tuning framework for large multimodal models",
      "detailed_description": "The official repository for LLaVA (Large Language-and-Vision Assistant), providing the codebase for visual instruction tuning. It serves as a platform for training and evaluating multimodal models that connect vision encoders with LLMs.",
      "domains": [
        "AI3",
        "AI3-02",
        "Computer Vision"
      ],
      "subtask_category": [
        "visual_instruction_tuning",
        "multimodal_training",
        "vlm"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/haotian-liu/LLaVA",
      "help_website": [
        "https://llava-vl.github.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vlm",
        "multimodal",
        "instruction-tuning",
        "llava"
      ],
      "id": 182
    },
    {
      "name": "ChatGLM-Efficient-Tuning",
      "one_line_profile": "Efficient fine-tuning framework for ChatGLM models based on PEFT",
      "detailed_description": "A comprehensive framework for fine-tuning ChatGLM-6B and related models using PEFT techniques (LoRA, P-Tuning, etc.). It is the predecessor to LLaMA-Factory and serves as a workflow tool for adapting ChatGLM models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft",
        "chatglm"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/hiyouga/ChatGLM-Efficient-Tuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "chatglm",
        "peft",
        "fine-tuning"
      ],
      "id": 183
    },
    {
      "name": "LLaMA-Factory",
      "one_line_profile": "Unified efficient fine-tuning platform for 100+ LLMs and VLMs",
      "detailed_description": "A widely adopted platform for the efficient fine-tuning of over 100 large language and vision-language models. It integrates various PEFT methods, training strategies (SFT, RLHF, DPO), and provides a web UI and CLI for the entire model adaptation lifecycle.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft",
        "rlhf",
        "dpo",
        "training_platform"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/hiyouga/LLaMA-Factory",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fine-tuning",
        "llm",
        "peft",
        "rlhf",
        "gui"
      ],
      "id": 184
    },
    {
      "name": "visual_prompting",
      "one_line_profile": "Visual prompting methods for adapting large-scale vision models",
      "detailed_description": "Research code implementing visual prompting techniques to adapt large-scale pre-trained vision models to downstream tasks without fine-tuning the model weights. It serves as a solver for pixel-level PEFT in computer vision.",
      "domains": [
        "Computer Vision",
        "AI3-02"
      ],
      "subtask_category": [
        "visual_prompting",
        "model_adaptation",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hjbahng/visual_prompting",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visual-prompting",
        "adaptation",
        "computer-vision"
      ],
      "id": 185
    },
    {
      "name": "Deita",
      "one_line_profile": "Data-Efficient Instruction Tuning for Alignment",
      "detailed_description": "A tool for selecting high-quality instruction tuning data to align Large Language Models efficiently. It implements the Deita approach (ICLR 2024) to automatically filter and select data samples that maximize alignment performance.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_selection",
        "instruction_tuning",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hkust-nlp/deita",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-selection",
        "instruction-tuning",
        "alignment"
      ],
      "id": 186
    },
    {
      "name": "IR-QLoRA",
      "one_line_profile": "Accurate LoRA-Finetuning Quantization via Information Retention",
      "detailed_description": "Implementation of IR-QLoRA (ICML 2024), a method for accurate quantization of LLMs during LoRA fine-tuning. It serves as a solver for creating high-performance quantized models with parameter-efficient fine-tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "quantization",
        "peft",
        "qlora"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/htqin/IR-QLoRA",
      "help_website": [],
      "license": null,
      "tags": [
        "quantization",
        "lora",
        "peft",
        "icml-2024"
      ],
      "id": 187
    },
    {
      "name": "Alignment Handbook",
      "one_line_profile": "Recipes and workflows for aligning language models with human preferences",
      "detailed_description": "A collection of robust recipes and scripts from Hugging Face for aligning language models using methods like DPO, IPO, and KTO. It serves as a standard workflow reference for the community to perform model alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "dpo",
        "workflow_recipes"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/alignment-handbook",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "huggingface",
        "recipes",
        "dpo"
      ],
      "id": 188
    },
    {
      "name": "Optimum Benchmark",
      "one_line_profile": "Unified multi-backend benchmarking utility for Transformers and PEFT",
      "detailed_description": "A utility tool for benchmarking the performance of Transformers, PEFT, and other models across different backends and hardware. It supports measuring latency, throughput, and memory usage, essential for optimizing scientific model inference and training.",
      "domains": [
        "AI3",
        "AI3-02",
        "HPC"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_analysis",
        "optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/optimum-benchmark",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmarking",
        "optimization",
        "transformers"
      ],
      "id": 189
    },
    {
      "name": "PEFT",
      "one_line_profile": "State-of-the-art Parameter-Efficient Fine-Tuning (PEFT) library for adapting large pre-trained models",
      "detailed_description": "A library that enables efficient adaptation of pre-trained language models to various downstream applications without fine-tuning all the model's parameters. It supports methods like LoRA, Prefix Tuning, P-Tuning, and Prompt Tuning, significantly reducing computational and storage costs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "parameter_efficiency",
        "model_adaptation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/peft",
      "help_website": [
        "https://huggingface.co/docs/peft"
      ],
      "license": "Apache-2.0",
      "tags": [
        "lora",
        "qlora",
        "fine-tuning",
        "llm"
      ],
      "id": 190
    },
    {
      "name": "TRL",
      "one_line_profile": "Transformer Reinforcement Learning library for training and aligning language models",
      "detailed_description": "A full-stack library for training transformer language models with Reinforcement Learning (RL). It supports the entire pipeline from Supervised Fine-Tuning (SFT), Reward Modeling (RM), to Proximal Policy Optimization (PPO) and Direct Preference Optimization (DPO) for model alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "dpo",
        "ppo",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/trl",
      "help_website": [
        "https://huggingface.co/docs/trl"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "alignment",
        "ppo",
        "dpo"
      ],
      "id": 191
    },
    {
      "name": "IPEX-LLM",
      "one_line_profile": "Library for accelerating LLM inference and fine-tuning on Intel hardware",
      "detailed_description": "A library designed to accelerate local Large Language Model (LLM) inference and fine-tuning on Intel XPU (CPUs, GPUs, NPUs). It integrates seamlessly with popular frameworks like Hugging Face, LangChain, and vLLM to provide low-latency and high-throughput performance for scientific AI workloads.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "inference_acceleration",
        "fine_tuning",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/intel/ipex-llm",
      "help_website": [
        "https://ipex-llm.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "intel",
        "acceleration",
        "inference",
        "fine-tuning"
      ],
      "id": 192
    },
    {
      "name": "LLamaTuner",
      "one_line_profile": "GUI and CLI tool for efficient fine-tuning and quantization of Large Language Models",
      "detailed_description": "A comprehensive tool designed to simplify the fine-tuning and quantization of various Large Language Models (LLMs) such as Llama, Qwen, and Baichuan. It provides both a graphical user interface and command-line tools to facilitate parameter-efficient fine-tuning (PEFT) and model deployment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "quantization",
        "workflow_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jianzhnie/LLamaTuner",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gui",
        "fine-tuning",
        "quantization",
        "llm"
      ],
      "id": 193
    },
    {
      "name": "MoRA",
      "one_line_profile": "High-rank updating method for parameter-efficient fine-tuning (PEFT)",
      "detailed_description": "An implementation of MoRA, a PEFT method that employs a square matrix for high-rank updating to achieve parameter efficiency while maintaining high capacity, serving as an alternative to LoRA.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kongds/MoRA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "peft",
        "fine-tuning",
        "llm"
      ],
      "id": 194
    },
    {
      "name": "CM3Leon",
      "one_line_profile": "Open source implementation of the CM3Leon multimodal model",
      "detailed_description": "An implementation of the CM3Leon architecture, an autoregressive multi-modal model capable of generating both text and images, facilitating research in multi-modal pretraining and instruction tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "multimodal_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kyegomez/CM3Leon",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multimodal",
        "transformer",
        "generative-ai"
      ],
      "id": 195
    },
    {
      "name": "Finetuning-Suite",
      "one_line_profile": "Streamlined suite for fine-tuning Hugging Face models",
      "detailed_description": "A tool designed to simplify and accelerate the fine-tuning process for various models available on Hugging Face, providing a quick setup for model adaptation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_adaptation"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/kyegomez/Finetuning-Suite",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fine-tuning",
        "huggingface",
        "productivity"
      ],
      "id": 196
    },
    {
      "name": "swarms-pytorch",
      "one_line_profile": "PyTorch implementation of swarm intelligence algorithms",
      "detailed_description": "A library implementing various swarm intelligence algorithms such as Particle Swarm Optimization (PSO) and Ant Colony Optimization in PyTorch, useful for scientific optimization tasks.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "optimization",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kyegomez/swarms-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "optimization",
        "swarm-intelligence",
        "pytorch"
      ],
      "id": 197
    },
    {
      "name": "tree-of-thoughts",
      "one_line_profile": "Framework for Tree of Thoughts reasoning in LLMs",
      "detailed_description": "An implementation of the Tree of Thoughts (ToT) framework, enabling large language models to perform deliberate problem solving and enhanced reasoning by exploring multiple thought paths.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "inference",
        "reasoning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kyegomez/tree-of-thoughts",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reasoning",
        "llm",
        "inference-optimization"
      ],
      "id": 198
    },
    {
      "name": "PRefLexOR",
      "one_line_profile": "Preference-based recursive language modeling for reasoning optimization",
      "detailed_description": "A framework for exploratory optimization of reasoning capabilities in language models using preference-based recursive modeling, useful for enhancing model performance on complex tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "optimization",
        "reasoning",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/lamm-mit/PRefLexOR",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reasoning",
        "preference-learning",
        "llm"
      ],
      "id": 199
    },
    {
      "name": "VB-LoRA",
      "one_line_profile": "Extreme parameter-efficient fine-tuning using Vector Banks",
      "detailed_description": "An implementation of VB-LoRA, a method for parameter-efficient fine-tuning that utilizes vector banks to further reduce trainable parameters compared to standard LoRA.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/leo-yangli/VB-LoRA",
      "help_website": [],
      "license": null,
      "tags": [
        "peft",
        "lora",
        "efficiency"
      ],
      "id": 200
    },
    {
      "name": "flash-preference",
      "one_line_profile": "Accelerated LLM preference tuning via prefix sharing",
      "detailed_description": "A library to accelerate preference tuning (alignment) of Large Language Models by implementing efficient prefix sharing mechanisms.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/li-plus/flash-preference",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "alignment",
        "preference-tuning",
        "acceleration"
      ],
      "id": 201
    },
    {
      "name": "prompt-optimizer",
      "one_line_profile": "Tool for optimizing prompts to improve LLM outputs",
      "detailed_description": "A tool designed to assist in writing and optimizing high-quality prompts, which is a critical part of the workflow for aligning and utilizing Large Language Models effectively.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "prompt_engineering",
        "alignment"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/linshenkx/prompt-optimizer",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "prompt-engineering",
        "optimization",
        "llm"
      ],
      "id": 202
    },
    {
      "name": "ChatGLM-Finetuning",
      "one_line_profile": "Comprehensive fine-tuning workflow for ChatGLM models",
      "detailed_description": "A widely used collection of scripts and workflows for fine-tuning ChatGLM series models, supporting various methods like Freeze, LoRA, P-tuning, and full parameter fine-tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/liucongg/ChatGLM-Finetuning",
      "help_website": [],
      "license": null,
      "tags": [
        "chatglm",
        "fine-tuning",
        "lora"
      ],
      "id": 203
    },
    {
      "name": "MOELoRA-peft",
      "one_line_profile": "Mixture-of-Experts based LoRA for PEFT",
      "detailed_description": "Implementation of MOELoRA, a parameter-efficient fine-tuning method that combines Mixture of Experts (MoE) with LoRA to enhance model adaptation capabilities.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liuqidong07/MOELoRA-peft",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "moe",
        "lora"
      ],
      "id": 204
    },
    {
      "name": "LLaVA-RLHF",
      "one_line_profile": "Factually augmented RLHF for aligning Large Multimodal Models",
      "detailed_description": "A tool/framework for aligning Large Multimodal Models (LMMs) using Reinforcement Learning with Human Feedback (RLHF), specifically focusing on reducing hallucinations and improving factual alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "multimodal"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/llava-rlhf/LLaVA-RLHF",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "rlhf",
        "multimodal",
        "alignment"
      ],
      "id": 205
    },
    {
      "name": "PSEC",
      "one_line_profile": "Framework for skill expansion and composition in parameter space",
      "detailed_description": "Implementation of PSEC, a framework designed to facilitate efficient and flexible skill expansion and composition for agents by operating in the parameter space.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_adaptation",
        "skill_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ltlhuuu/PSEC",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "skill-expansion",
        "parameter-space",
        "agents"
      ],
      "id": 206
    },
    {
      "name": "trlda",
      "one_line_profile": "Online inference algorithms for Latent Dirichlet Allocation (LDA)",
      "detailed_description": "A C++ library with Python bindings providing implementations of various online inference algorithms for Latent Dirichlet Allocation, useful for statistical topic modeling.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "statistical_inference",
        "topic_modeling"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/lucastheis/trlda",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lda",
        "topic-modeling",
        "inference"
      ],
      "id": 207
    },
    {
      "name": "DiscoPOP",
      "one_line_profile": "Algorithm for discovering preference optimization methods",
      "detailed_description": "Code and framework for discovering new preference optimization algorithms for Large Language Models, enabling the development of better alignment techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/luchris429/DiscoPOP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "alignment",
        "preference-optimization",
        "llm"
      ],
      "id": 208
    },
    {
      "name": "PaLM-rlhf-pytorch",
      "one_line_profile": "PyTorch implementation of RLHF for PaLM architecture",
      "detailed_description": "A complete implementation of Reinforcement Learning with Human Feedback (RLHF) on top of the PaLM architecture, serving as a reference library for training aligned LLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucidrains/PaLM-rlhf-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rlhf",
        "palm",
        "pytorch"
      ],
      "id": 209
    },
    {
      "name": "mDPO",
      "one_line_profile": "Conditional Preference Optimization for Multimodal LLMs",
      "detailed_description": "Implementation of mDPO, a method for aligning Multimodal Large Language Models using conditional preference optimization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "multimodal",
        "dpo"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/luka-group/mDPO",
      "help_website": [],
      "license": null,
      "tags": [
        "dpo",
        "multimodal",
        "alignment"
      ],
      "id": 210
    },
    {
      "name": "RobustFT",
      "one_line_profile": "Robust Supervised Fine-tuning for LLMs under noisy response",
      "detailed_description": "A method and tool for performing robust supervised fine-tuning of Large Language Models, specifically designed to handle noisy training data effectively.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "robustness"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/luo-junyu/RobustFT",
      "help_website": [],
      "license": null,
      "tags": [
        "fine-tuning",
        "robustness",
        "noise-handling"
      ],
      "id": 211
    },
    {
      "name": "SemiEvol",
      "one_line_profile": "Semi-supervised Fine-tuning for LLM Adaptation",
      "detailed_description": "A framework for semi-supervised fine-tuning, enabling the adaptation of Large Language Models using both labeled and unlabeled data.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "semi_supervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/luo-junyu/SemiEvol",
      "help_website": [],
      "license": null,
      "tags": [
        "fine-tuning",
        "semi-supervised",
        "adaptation"
      ],
      "id": 212
    },
    {
      "name": "LaVIN",
      "one_line_profile": "Efficient Vision-Language Instruction Tuning",
      "detailed_description": "Implementation of LaVIN, a method for cheap and quick vision-language instruction tuning for Large Language Models, facilitating efficient multimodal adaptation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "multimodal"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/luogen1996/LaVIN",
      "help_website": [],
      "license": null,
      "tags": [
        "instruction-tuning",
        "multimodal",
        "efficiency"
      ],
      "id": 213
    },
    {
      "name": "LangCode",
      "one_line_profile": "Improving alignment and reasoning with natural language embedded programs",
      "detailed_description": "A tool/method for improving the alignment and reasoning capabilities of LLMs by utilizing natural language embedded programs (NLEP).",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/luohongyin/LangCode",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "alignment",
        "reasoning",
        "code-generation"
      ],
      "id": 214
    },
    {
      "name": "simple-llm-finetuner",
      "one_line_profile": "Simple UI for LLM Model Finetuning",
      "detailed_description": "A user-friendly interface and workflow tool for fine-tuning Large Language Models, designed to make the process accessible without deep coding requirements.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_training"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/lxe/simple-llm-finetuner",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ui",
        "fine-tuning",
        "low-code"
      ],
      "id": 215
    },
    {
      "name": "AirLLM",
      "one_line_profile": "Memory-efficient inference for large models on consumer GPUs",
      "detailed_description": "A library enabling the inference of very large language models (e.g., 70B) on hardware with limited memory (e.g., single 4GB GPU) through layered execution and optimization.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "inference",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/lyogavin/airllm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "memory-optimization",
        "consumer-hardware"
      ],
      "id": 216
    },
    {
      "name": "memprompt",
      "one_line_profile": "Method to fix LLMs after deployment with user feedback",
      "detailed_description": "A tool implementing MemPrompt, a method that allows fixing errors in deployed GPT-3 style models using user feedback without requiring full re-training.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "feedback_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/madaan/memprompt",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "human-feedback",
        "memory"
      ],
      "id": 217
    },
    {
      "name": "Magpie",
      "one_line_profile": "Alignment Data Synthesis from Scratch",
      "detailed_description": "A pipeline and tool for synthesizing high-quality alignment data by prompting aligned LLMs, facilitating efficient data generation for model training.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_synthesis",
        "alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/magpie-align/magpie",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "synthetic-data",
        "alignment",
        "data-generation"
      ],
      "id": 218
    },
    {
      "name": "Pruning-Weights-Biobjective",
      "one_line_profile": "Biobjective optimization strategy for neural network weight pruning in Keras",
      "detailed_description": "A pruning strategy integrated into the training process that uses multiobjective optimization to reduce network complexity and inference time without requiring extensive hyperparameter search or retraining.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_compression",
        "pruning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/malena1906/Pruning-Weights-with-Biobjective-Optimization-Keras",
      "help_website": [],
      "license": null,
      "tags": [
        "pruning",
        "optimization",
        "keras",
        "neural-networks"
      ],
      "id": 219
    },
    {
      "name": "MaPO",
      "one_line_profile": "Margin-aware Preference Optimization for aligning diffusion models",
      "detailed_description": "Official codebase for MaPO, a method to align diffusion models without requiring reference images, utilizing margin-aware preference optimization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "diffusion_model_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mapo-t2i/mapo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-models",
        "alignment",
        "preference-optimization"
      ],
      "id": 220
    },
    {
      "name": "6DPose",
      "one_line_profile": "Implementation of 6D pose estimation algorithms",
      "detailed_description": "A collection of algorithms and implementations for 6D pose estimation, useful for computer vision and robotics tasks involving spatial analysis.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "pose_estimation",
        "image_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/meiqua/6DPose",
      "help_website": [],
      "license": null,
      "tags": [
        "6d-pose",
        "computer-vision",
        "pose-estimation"
      ],
      "id": 221
    },
    {
      "name": "PromptCBLUE",
      "one_line_profile": "Large-scale Chinese medical instruction-tuning dataset",
      "detailed_description": "A large-scale instruction-tuning dataset designed for multi-task and few-shot learning in the medical domain, facilitating the training of medical LLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "dataset_preparation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/michael-wzhu/PromptCBLUE",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-ai",
        "instruction-tuning",
        "dataset",
        "chinese-nlp"
      ],
      "id": 222
    },
    {
      "name": "InstructLLaMA",
      "one_line_profile": "Pipeline for pre-training, SFT, and RLHF of LLaMA models",
      "detailed_description": "A comprehensive implementation for pre-training, supervised fine-tuning (SFT), and reinforcement learning from human feedback (RLHF) to align LLaMA models with human instructions.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "supervised_fine_tuning",
        "alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/michaelnny/InstructLLaMA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llama",
        "rlhf",
        "sft",
        "instruction-following"
      ],
      "id": 223
    },
    {
      "name": "CoMOLA",
      "one_line_profile": "Constrained Multi-objective Optimization of Land use Allocation",
      "detailed_description": "A generic Python tool for optimizing land use allocation considering ecosystem services and biodiversity, using constrained multi-objective optimization techniques.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "optimization",
        "simulation",
        "spatial_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/michstrauch/CoMOLA",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "optimization",
        "land-use",
        "multi-objective",
        "spatial-planning"
      ],
      "id": 224
    },
    {
      "name": "LoRA",
      "one_line_profile": "Reference implementation of Low-Rank Adaptation for LLMs",
      "detailed_description": "The official implementation of LoRA (Low-Rank Adaptation), a widely used parameter-efficient fine-tuning technique for large language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/LoRA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lora",
        "peft",
        "llm",
        "fine-tuning"
      ],
      "id": 225
    },
    {
      "name": "mttl",
      "one_line_profile": "Library for modular LLMs with parameter-efficient fine-tuning",
      "detailed_description": "A library for building modular language models using parameter-efficient fine-tuning (PEFT) techniques, facilitating flexible model adaptation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "modular_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/mttl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "modular-ai",
        "llm"
      ],
      "id": 226
    },
    {
      "name": "PEFT Proteomics",
      "one_line_profile": "LoRA implementation for protein language models",
      "detailed_description": "A specialized implementation of Low-Rank Adaptation (LoRA) tailored for fine-tuning protein language models in proteomics research.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "protein_modeling",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/microsoft/peft_proteomics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "proteomics",
        "protein-language-models",
        "lora",
        "bio-ai"
      ],
      "id": 227
    },
    {
      "name": "SAMMO",
      "one_line_profile": "Structure-aware Multi-Objective Metaprompt Optimization library",
      "detailed_description": "A library for prompt engineering and optimization that uses structure-aware multi-objective techniques to improve the performance of large language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "prompt_optimization",
        "prompt_engineering"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/sammo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-engineering",
        "optimization",
        "llm"
      ],
      "id": 228
    },
    {
      "name": "VADER",
      "one_line_profile": "Video Diffusion Alignment via Reward Gradients",
      "detailed_description": "A tool for aligning video diffusion models using reward gradients, supporting fine-tuning with various reward models like HPS, PickScore, and VideoMAE.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "video_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mihirp1998/VADER",
      "help_website": [],
      "license": null,
      "tags": [
        "video-diffusion",
        "alignment",
        "reward-gradients"
      ],
      "id": 229
    },
    {
      "name": "UniTS",
      "one_line_profile": "Unified multi-task time series model",
      "detailed_description": "A unified model and library for multi-task time series analysis, capable of handling forecasting, classification, and other temporal data tasks.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "time_series_analysis",
        "forecasting"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mims-harvard/UniTS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "time-series",
        "multi-task-learning",
        "forecasting"
      ],
      "id": 230
    },
    {
      "name": "DiffFit",
      "one_line_profile": "Parameter-Efficient Fine-Tuning for Diffusion Models",
      "detailed_description": "Implementation of DiffFit, a method for parameter-efficient fine-tuning of large diffusion models to unlock their transferability.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "diffusion_model_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mkshing/DiffFit-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "diffusion-models",
        "peft",
        "fine-tuning"
      ],
      "id": 231
    },
    {
      "name": "Trinity-RFT",
      "one_line_profile": "Framework for reinforcement fine-tuning of LLMs",
      "detailed_description": "A general-purpose, flexible, and scalable framework designed for reinforcement fine-tuning (RFT) of large language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "fine_tuning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/modelscope/Trinity-RFT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "fine-tuning",
        "llm",
        "reinforcement-learning"
      ],
      "id": 232
    },
    {
      "name": "SWIFT",
      "one_line_profile": "Comprehensive framework for LLM/MLLM fine-tuning and alignment",
      "detailed_description": "A scalable framework supporting PEFT, full-parameter fine-tuning, and alignment (DPO/GRPO) for a wide range of LLMs and MLLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "alignment",
        "peft"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/modelscope/ms-swift",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "peft",
        "llm",
        "mllm",
        "alignment",
        "fine-tuning"
      ],
      "id": 233
    },
    {
      "name": "DPoser-X",
      "one_line_profile": "Diffusion Model as Robust 3D Whole-body Human Pose Prior",
      "detailed_description": "A tool utilizing diffusion models as a robust prior for 3D whole-body human pose estimation tasks.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "pose_estimation",
        "structure_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/moonbow721/DPoser-X",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "3d-pose",
        "diffusion-models",
        "human-pose-estimation"
      ],
      "id": 234
    },
    {
      "name": "LLM-Dojo",
      "one_line_profile": "Open source LLM training and RLHF framework",
      "detailed_description": "A framework for building model training pipelines and RLHF workflows (DPO/CPO/KTO/PPO), supporting various mainstream models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "fine_tuning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/mst272/LLM-Dojo",
      "help_website": [],
      "license": null,
      "tags": [
        "rlhf",
        "llm-training",
        "dpo",
        "ppo"
      ],
      "id": 235
    },
    {
      "name": "ChatGLM-Tuning",
      "one_line_profile": "LoRA fine-tuning solution for ChatGLM-6B",
      "detailed_description": "A widely used fine-tuning solution based on LoRA specifically designed for the ChatGLM-6B model.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/mymusise/ChatGLM-Tuning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chatglm",
        "lora",
        "fine-tuning"
      ],
      "id": 236
    },
    {
      "name": "llama2-fine-tune",
      "one_line_profile": "Scripts for fine-tuning Llama2 via SFT and DPO",
      "detailed_description": "A collection of scripts and workflows for fine-tuning Llama2 models using Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO).",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/mzbac/llama2-fine-tune",
      "help_website": [],
      "license": null,
      "tags": [
        "llama2",
        "sft",
        "dpo",
        "fine-tuning"
      ],
      "id": 237
    },
    {
      "name": "Nunchaku",
      "one_line_profile": "Inference engine and quantization library for 4-bit diffusion models",
      "detailed_description": "Nunchaku (SVDQuant) is a library designed for the quantization and efficient inference of diffusion models. It implements the SVDQuant algorithm to absorb outliers using low-rank components, enabling high-quality 4-bit quantization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "quantization",
        "inference",
        "diffusion_models"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nunchaku-tech/nunchaku",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "diffusion",
        "inference-engine"
      ],
      "id": 238
    },
    {
      "name": "ReaLHF",
      "one_line_profile": "Efficient RLHF training framework for Large Language Models",
      "detailed_description": "ReaLHF is a framework for Reinforcement Learning from Human Feedback (RLHF) training of LLMs. It features parameter reallocation techniques to enable super-efficient training and supports various alignment algorithms.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "alignment",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/openpsi-project/ReaLHF",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "llm-training",
        "alignment"
      ],
      "id": 239
    },
    {
      "name": "Oumi",
      "one_line_profile": "Framework for fine-tuning, evaluating, and deploying open-source LLMs",
      "detailed_description": "Oumi is a comprehensive library that simplifies the lifecycle of Large Language Models (LLMs) and Vision Language Models (VLMs), providing tools for fine-tuning, evaluation, and deployment of models like Llama, Qwen, and DeepSeek.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine-tuning",
        "evaluation",
        "deployment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/oumi-ai/oumi",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "fine-tuning",
        "inference"
      ],
      "id": 240
    },
    {
      "name": "LoRAX",
      "one_line_profile": "Multi-LoRA inference server for scaling fine-tuned LLMs",
      "detailed_description": "LoRAX is an inference server designed to serve thousands of fine-tuned models on a single GPU using Low-Rank Adaptation (LoRA). It optimizes resource usage for multi-tenant LLM serving.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "inference",
        "serving",
        "lora"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/predibase/lorax",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference-server",
        "lora",
        "llm-serving"
      ],
      "id": 241
    },
    {
      "name": "LESS",
      "one_line_profile": "Data selection tool for targeted instruction tuning",
      "detailed_description": "LESS is a tool and method for selecting influential data for targeted instruction tuning of Large Language Models. It helps in optimizing training data to improve model performance on specific tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_selection",
        "instruction_tuning",
        "data_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/princeton-nlp/LESS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-selection",
        "instruction-tuning",
        "llm"
      ],
      "id": 242
    },
    {
      "name": "SimPO",
      "one_line_profile": "Simple Preference Optimization algorithm implementation",
      "detailed_description": "SimPO provides the reference implementation for Simple Preference Optimization, a reference-free reward optimization method for aligning Large Language Models. It serves as a solver for applying this alignment technique.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "preference_optimization",
        "alignment",
        "rlhf"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/princeton-nlp/SimPO",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "alignment",
        "dpo",
        "preference-optimization"
      ],
      "id": 243
    },
    {
      "name": "Promptify",
      "one_line_profile": "Library for structured output generation using LLMs",
      "detailed_description": "Promptify is a library that simplifies prompt engineering to obtain structured outputs (like JSON) from Large Language Models. It is used for NLP tasks such as Named Entity Recognition (NER) and classification.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "prompt_engineering",
        "information_extraction",
        "nlp"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/promptslab/Promptify",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prompt-engineering",
        "nlp",
        "structured-output"
      ],
      "id": 244
    },
    {
      "name": "T-Few",
      "one_line_profile": "Implementation of Few-Shot Parameter-Efficient Fine-Tuning",
      "detailed_description": "T-Few provides the code and implementation for the T-Few method, enabling few-shot parameter-efficient fine-tuning of language models. It serves as a solver/baseline for PEFT research.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "few_shot_learning",
        "fine-tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/r-three/t-few",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "few-shot",
        "fine-tuning"
      ],
      "id": 245
    },
    {
      "name": "LLM-RLHF-Tuning-with-PPO-and-DPO",
      "one_line_profile": "Toolkit for RLHF training using PPO and DPO",
      "detailed_description": "A comprehensive toolkit for Reinforcement Learning from Human Feedback (RLHF) training. It integrates instruction fine-tuning and reward modeling, supporting algorithms like PPO and DPO for models such as LLaMA.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "fine-tuning",
        "alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/raghavc/LLM-RLHF-Tuning-with-PPO-and-DPO",
      "help_website": [],
      "license": null,
      "tags": [
        "rlhf",
        "ppo",
        "dpo"
      ],
      "id": 246
    },
    {
      "name": "Crater",
      "one_line_profile": "Cloud-native AI training and inference platform",
      "detailed_description": "Crater is a platform designed for cloud-native AI training and inference, providing infrastructure management for AI workloads.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "model_training",
        "inference",
        "infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/raids-lab/crater",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-platform",
        "training",
        "inference"
      ],
      "id": 247
    },
    {
      "name": "TRLC-DK1",
      "one_line_profile": "Development kit for robot learning and control",
      "detailed_description": "A development kit provided by The Robot Learning Company, likely containing software interfaces and tools for controlling robotic hardware for learning tasks.",
      "domains": [
        "AI4",
        "Robotics"
      ],
      "subtask_category": [
        "robot_control",
        "reinforcement_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/robot-learning-co/trlc-dk1",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "robotics",
        "robot-learning",
        "sdk"
      ],
      "id": 248
    },
    {
      "name": "OAT",
      "one_line_profile": "Research-friendly framework for LLM online alignment",
      "detailed_description": "A framework designed for online alignment of Large Language Models, supporting reinforcement learning and preference learning techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "preference_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sail-sg/oat",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-alignment",
        "rlhf",
        "preference-optimization"
      ],
      "id": 249
    },
    {
      "name": "DialogStudio",
      "one_line_profile": "Unified dataset collection and loader for conversational AI",
      "detailed_description": "A library providing access to a diverse collection of unified datasets and instruction-aware models for conversational AI research.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "data_loading",
        "dataset_collection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/salesforce/DialogStudio",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "conversational-ai",
        "datasets",
        "instruction-tuning"
      ],
      "id": 250
    },
    {
      "name": "Finetune-Qwen2.5-VL",
      "one_line_profile": "Fine-tuning toolkit for Qwen2.5-VL vision-language models",
      "detailed_description": "A specialized toolkit for fine-tuning the Qwen2.5-VL model, optimized for vision understanding tasks with support for LoRA and PEFT.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft",
        "vision_language_modeling"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/sandy1990418/Finetune-Qwen2.5-VL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "qwen",
        "vlm",
        "lora",
        "fine-tuning"
      ],
      "id": 251
    },
    {
      "name": "XtunerGUI",
      "one_line_profile": "Graphical User Interface for Xtuner fine-tuning toolkit",
      "detailed_description": "A GUI wrapper for the Xtuner library, facilitating the fine-tuning process of Large Language Models for users who prefer a visual interface.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "gui"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/scchy/XtunerGUI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "xtuner",
        "gui",
        "fine-tuning"
      ],
      "id": 252
    },
    {
      "name": "GraphRAG-Local-UI",
      "one_line_profile": "Local platform for GraphRAG with LLMs",
      "detailed_description": "A comprehensive tool for running GraphRAG (Retrieval Augmented Generation with Knowledge Graphs) locally, including indexing, prompt tuning, and querying capabilities.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "rag",
        "knowledge_graph",
        "information_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/severian42/GraphRAG-Local-UI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graphrag",
        "rag",
        "local-llm"
      ],
      "id": 253
    },
    {
      "name": "Vodalus-Expert-LLM-Forge",
      "one_line_profile": "Toolkit for dataset crafting and efficient LLM fine-tuning",
      "detailed_description": "A tool suite for creating datasets using RAG/Wikipedia ground truth and performing efficient fine-tuning using MLX and Unsloth.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "dataset_creation",
        "fine_tuning",
        "rag"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/severian42/Vodalus-Expert-LLM-Forge",
      "help_website": [],
      "license": null,
      "tags": [
        "dataset-generation",
        "fine-tuning",
        "mlx",
        "unsloth"
      ],
      "id": 254
    },
    {
      "name": "MedicalGPT",
      "one_line_profile": "Comprehensive pipeline for training medical LLMs",
      "detailed_description": "A complete workflow for training medical large language models, including incremental pre-training, supervised fine-tuning (SFT), RLHF, DPO, and other alignment techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "fine_tuning",
        "rlhf",
        "medical_ai"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/shibing624/MedicalGPT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-llm",
        "rlhf",
        "dpo",
        "sft"
      ],
      "id": 255
    },
    {
      "name": "promptimal",
      "one_line_profile": "Minimalist prompt optimizer for LLMs",
      "detailed_description": "A tool designed to optimize prompts for large language models, improving response quality and efficiency.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_optimization",
        "prompt_engineering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/shobrook/promptimal",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-optimization",
        "llm"
      ],
      "id": 256
    },
    {
      "name": "chatGLM-6B-QLoRA",
      "one_line_profile": "QLoRA fine-tuning implementation for ChatGLM-6B",
      "detailed_description": "A tool implementing 4-bit QLoRA efficient fine-tuning for ChatGLM-6B/ChatGLM2-6B models, including model merging and quantization utilities.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "qlora",
        "quantization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/shuxueslpi/chatGLM-6B-QLoRA",
      "help_website": [],
      "license": null,
      "tags": [
        "chatglm",
        "qlora",
        "peft"
      ],
      "id": 257
    },
    {
      "name": "OneDiff",
      "one_line_profile": "Acceleration library for diffusion models",
      "detailed_description": "An out-of-the-box acceleration library designed to optimize the inference speed of diffusion models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_acceleration",
        "diffusion_models"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/siliconflow/onediff",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion",
        "acceleration",
        "inference"
      ],
      "id": 258
    },
    {
      "name": "baichuan_finetuning",
      "one_line_profile": "Fine-tuning scripts for Baichuan models",
      "detailed_description": "A collection of scripts and tools for fine-tuning Baichuan and Baichuan2 models, supporting Alpaca-style instruction tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "instruction_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssbuild/baichuan_finetuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "baichuan",
        "fine-tuning",
        "llm"
      ],
      "id": 259
    },
    {
      "name": "chatglm_finetuning",
      "one_line_profile": "Fine-tuning toolkit for ChatGLM models",
      "detailed_description": "A widely used toolkit for fine-tuning ChatGLM-6B and related models, supporting various fine-tuning methods including Alpaca-style instruction tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "instruction_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssbuild/chatglm_finetuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "chatglm",
        "fine-tuning",
        "llm"
      ],
      "id": 260
    },
    {
      "name": "chatglm_rlhf",
      "one_line_profile": "RLHF fine-tuning implementation for ChatGLM",
      "detailed_description": "A specialized tool for performing Reinforcement Learning from Human Feedback (RLHF) fine-tuning on ChatGLM models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "alignment",
        "fine_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssbuild/chatglm_rlhf",
      "help_website": [],
      "license": null,
      "tags": [
        "chatglm",
        "rlhf",
        "alignment"
      ],
      "id": 261
    },
    {
      "name": "llm_finetuning",
      "one_line_profile": "Fine-tuning scripts for various Large Language Models (Bloom, OPT, GPT, LLaMA, etc.)",
      "detailed_description": "A collection of scripts and tools for fine-tuning multiple open-source Large Language Models including Bloom, OPT, GPT-2, LLaMA, and CPM-Ant, supporting various training configurations.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssbuild/llm_finetuning",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "fine-tuning",
        "llama",
        "bloom"
      ],
      "id": 262
    },
    {
      "name": "llm_rlhf",
      "one_line_profile": "Reinforcement Learning from Human Feedback (RLHF) implementation for LLMs",
      "detailed_description": "Implements reinforcement learning training pipelines (RLHF) for large language models such as GPT-2, LLaMA, and Bloom, facilitating alignment with human preferences.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssbuild/llm_rlhf",
      "help_website": [],
      "license": null,
      "tags": [
        "rlhf",
        "alignment",
        "llm"
      ],
      "id": 263
    },
    {
      "name": "moss_finetuning",
      "one_line_profile": "Fine-tuning tools specifically for the MOSS chat model",
      "detailed_description": "Provides scripts and utilities tailored for fine-tuning the MOSS conversational model, enabling domain adaptation and instruction tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssbuild/moss_finetuning",
      "help_website": [],
      "license": null,
      "tags": [
        "moss",
        "fine-tuning",
        "chat-model"
      ],
      "id": 264
    },
    {
      "name": "qwen_finetuning",
      "one_line_profile": "Fine-tuning framework for Qwen series models",
      "detailed_description": "A dedicated toolkit for fine-tuning Qwen (Tongyi Qianwen) models, supporting instruction tuning and domain adaptation workflows.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssbuild/qwen_finetuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "qwen",
        "fine-tuning",
        "llm"
      ],
      "id": 265
    },
    {
      "name": "rwkv_finetuning",
      "one_line_profile": "Fine-tuning scripts for RWKV RNN models",
      "detailed_description": "Tools designed for fine-tuning RWKV models, a type of RNN-based large language model, enabling customization and performance improvement on specific tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssbuild/rwkv_finetuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rwkv",
        "rnn",
        "fine-tuning"
      ],
      "id": 266
    },
    {
      "name": "SNELL",
      "one_line_profile": "Sparse tuning method for low-memory LLM adaptation",
      "detailed_description": "Implementation of the SNELL method (NeurIPS 2024) for expanding sparse tuning to reduce memory usage during Large Language Model fine-tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssfgunner/SNELL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sparse-tuning",
        "memory-efficient",
        "peft"
      ],
      "id": 267
    },
    {
      "name": "llms_tool",
      "one_line_profile": "Comprehensive toolkit for LLM training, testing, and deployment",
      "detailed_description": "A HuggingFace-based toolchain supporting WebUI, terminal prediction, low-parameter and full-parameter training (Pre-training, SFT, RM, PPO, DPO), model merging, and quantization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "alignment",
        "quantization",
        "evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanleylsx/llms_tool",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sft",
        "rlhf",
        "dpo",
        "quantization"
      ],
      "id": 268
    },
    {
      "name": "xTuring",
      "one_line_profile": "Framework for building and personalizing LLMs",
      "detailed_description": "An easy-to-use framework for building, personalizing, and controlling LLMs, covering the pipeline from data pre-processing to fine-tuning open-source models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "data_processing"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/stochasticai/xTuring",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-personalization",
        "fine-tuning",
        "framework"
      ],
      "id": 269
    },
    {
      "name": "Simple-Trl-Training",
      "one_line_profile": "Simplified DPO training wrapper for LLMs",
      "detailed_description": "A lightweight tool based on the DPO (Direct Preference Optimization) algorithm for fine-tuning large language models, designed for ease of use.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "dpo"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sugarandgugu/Simple-Trl-Training",
      "help_website": [],
      "license": null,
      "tags": [
        "dpo",
        "alignment",
        "fine-tuning"
      ],
      "id": 270
    },
    {
      "name": "ChiMed-GPT",
      "one_line_profile": "Chinese medical LLM training and alignment implementation",
      "detailed_description": "Implementation for ChiMed-GPT, a Chinese medical large language model, including pipelines for pre-training, supervised fine-tuning (SFT), and RLHF on medical data.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "alignment",
        "domain_adaptation"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/synlp/ChiMed-GPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-llm",
        "sft",
        "rlhf"
      ],
      "id": 271
    },
    {
      "name": "Llama3.1-Finetuning",
      "one_line_profile": "Fine-tuning toolkit for Llama 3.1 models",
      "detailed_description": "Provides tools for full-parameter fine-tuning, LoRA, and QLoRA fine-tuning specifically optimized for the Llama 3.1 model family.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/taishan1994/Llama3.1-Finetuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llama-3",
        "lora",
        "qlora"
      ],
      "id": 272
    },
    {
      "name": "qlora-chinese-LLM",
      "one_line_profile": "QLoRA fine-tuning for Chinese LLMs",
      "detailed_description": "A tool for fine-tuning Chinese large language models (ChatGLM, Chinese-LLaMA-Alpaca, BELLE) using QLoRA (Quantized LoRA) for efficient adaptation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/taishan1994/qlora-chinese-LLM",
      "help_website": [],
      "license": null,
      "tags": [
        "qlora",
        "chinese-llm",
        "fine-tuning"
      ],
      "id": 273
    },
    {
      "name": "alpaca_eval",
      "one_line_profile": "Automatic evaluator for instruction-following models",
      "detailed_description": "A framework for automatic evaluation of instruction-following language models, providing a fast, cheap, and human-validated metric for model quality.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "evaluation",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/tatsu-lab/alpaca_eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "llm-benchmark",
        "instruction-following"
      ],
      "id": 274
    },
    {
      "name": "alpaca_farm",
      "one_line_profile": "Simulation framework for RLHF research",
      "detailed_description": "A simulation framework designed to facilitate research in Reinforcement Learning from Human Feedback (RLHF) and alternatives by simulating human feedback, enabling method development without expensive data collection.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "simulation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/tatsu-lab/alpaca_farm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "simulation",
        "alignment"
      ],
      "id": 275
    },
    {
      "name": "qlora-pipe",
      "one_line_profile": "Pipeline parallel training script for QLoRA",
      "detailed_description": "A training script enabling pipeline parallelism for Large Language Models, specifically optimized for QLoRA workflows to handle large models on limited hardware.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tdrussell/qlora-pipe",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pipeline-parallelism",
        "qlora",
        "training"
      ],
      "id": 276
    },
    {
      "name": "unsloth-5090-multiple",
      "one_line_profile": "Configuration and scripts for Unsloth on RTX 5090",
      "detailed_description": "Utilities and configuration scripts for running Unsloth (LLM training optimization tool) on multi-GPU setups involving RTX 5090 hardware.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/thad0ctor/unsloth-5090-multiple",
      "help_website": [],
      "license": null,
      "tags": [
        "unsloth",
        "hardware-optimization",
        "fine-tuning"
      ],
      "id": 277
    },
    {
      "name": "FinetuneGLMWithPeft",
      "one_line_profile": "Simple LoRA fine-tuning implementation for ChatGLM-6B",
      "detailed_description": "A lightweight implementation using the PEFT library to fine-tune the ChatGLM-6B model with LoRA, serving as a straightforward solver for this specific model.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/thaumstrial/FinetuneGLMWithPeft",
      "help_website": [],
      "license": null,
      "tags": [
        "chatglm",
        "lora",
        "peft"
      ],
      "id": 278
    },
    {
      "name": "LoRD",
      "one_line_profile": "Low-Rank adapter extraction tool",
      "detailed_description": "A utility for extracting Low-Rank adapters (LoRA) from fully fine-tuned transformer models, enabling the conversion of full weights back into modular adapters.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_processing",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/thomasgauthier/LoRD",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lora-extraction",
        "adapter",
        "transformers"
      ],
      "id": 279
    },
    {
      "name": "KnowledgeablePromptTuning",
      "one_line_profile": "Knowledgeable Prompt Tuning (KPT) implementation",
      "detailed_description": "Implementation of Knowledgeable Prompt Tuning, a method to optimize prompts for pre-trained language models by incorporating external knowledge.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "prompt_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/thunlp/KnowledgeablePromptTuning",
      "help_website": [],
      "license": null,
      "tags": [
        "prompt-tuning",
        "kpt",
        "nlp"
      ],
      "id": 280
    },
    {
      "name": "Cherry_LLM",
      "one_line_profile": "Self-data filtering tool for LLM instruction tuning",
      "detailed_description": "A tool for filtering LLM instruction-tuning data using a perplexity-based difficulty score (Cherry Score), enabling data quality improvement without external models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_processing",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tianyi-lab/Cherry_LLM",
      "help_website": [],
      "license": null,
      "tags": [
        "data-filtering",
        "instruction-tuning",
        "data-quality"
      ],
      "id": 281
    },
    {
      "name": "Reflection_Tuning",
      "one_line_profile": "Selective Reflection-Tuning implementation",
      "detailed_description": "Implementation of Selective Reflection-Tuning, a method for recycling student-selected data to improve LLM instruction tuning performance.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "data_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tianyi-lab/Reflection_Tuning",
      "help_website": [],
      "license": null,
      "tags": [
        "instruction-tuning",
        "reflection-tuning",
        "llm"
      ],
      "id": 282
    },
    {
      "name": "alpaca-lora",
      "one_line_profile": "Instruct-tune LLaMA on consumer hardware using LoRA",
      "detailed_description": "A seminal tool for fine-tuning LLaMA models on consumer-grade hardware using Low-Rank Adaptation (LoRA), enabling widespread access to LLM instruction tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/tloen/alpaca-lora",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lora",
        "llama",
        "fine-tuning"
      ],
      "id": 283
    },
    {
      "name": "ICLR25-FSCA",
      "one_line_profile": "Context-Alignment method for Time Series LLMs",
      "detailed_description": "Implementation of the Context-Alignment (FSCA) method to activate and enhance Large Language Model capabilities specifically for time series analysis tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "domain_adaptation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tokaka22/ICLR25-FSCA",
      "help_website": [],
      "license": null,
      "tags": [
        "time-series",
        "alignment",
        "llm"
      ],
      "id": 284
    },
    {
      "name": "axolotl-mobile-sensing",
      "one_line_profile": "Framework for mobile sensor data extraction and ML",
      "detailed_description": "A machine learning framework designed to extract and process accelerometric and gyroscopic data from mobile phones. (Note: Name collision with the popular LLM fine-tuning tool 'axolotl', but this is a distinct tool for sensor data).",
      "domains": [
        "IoT",
        "Sensor_Analysis"
      ],
      "subtask_category": [
        "data_processing",
        "feature_extraction"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/tomasreimers/axolotl",
      "help_website": [],
      "license": null,
      "tags": [
        "sensor-data",
        "mobile-sensing",
        "machine-learning"
      ],
      "id": 285
    },
    {
      "name": "transformerlab-app",
      "one_line_profile": "Desktop application for LLM and Diffusion model engineering",
      "detailed_description": "An open-source desktop application that allows users to interact with, train, fine-tune, and evaluate large language models and diffusion models locally.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "evaluation",
        "inference"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/transformerlab/transformerlab-app",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "gui",
        "llm-training",
        "local-inference"
      ],
      "id": 286
    },
    {
      "name": "Unsloth",
      "one_line_profile": "Optimized fine-tuning library for LLMs with significantly reduced VRAM usage and faster training speeds",
      "detailed_description": "Unsloth is a lightweight and highly optimized library for fine-tuning Large Language Models (LLMs). It implements custom kernels and backpropagation logic to achieve up to 2x faster training and 70% less memory usage compared to standard Hugging Face implementations, supporting models like Llama, Mistral, and Qwen.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "peft",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/unslothai/unsloth",
      "help_website": [
        "https://github.com/unslothai/unsloth"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "fine-tuning",
        "optimization",
        "peft",
        "lora"
      ],
      "id": 287
    },
    {
      "name": "Unsloth Zoo",
      "one_line_profile": "Utility library and dataset collection for the Unsloth fine-tuning ecosystem",
      "detailed_description": "Unsloth Zoo provides supplementary utilities, data collators, and dataset preparation scripts designed to work seamlessly with the Unsloth library. It facilitates the setup of training pipelines for various LLM fine-tuning tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_processing",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/unslothai/unsloth-zoo",
      "help_website": [
        "https://github.com/unslothai/unsloth-zoo"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "utils",
        "datasets",
        "fine-tuning"
      ],
      "id": 288
    },
    {
      "name": "GLiNER",
      "one_line_profile": "Generalist and lightweight model/library for zero-shot Named Entity Recognition",
      "detailed_description": "GLiNER is a model and library capable of identifying any entity type using a bidirectional transformer encoder (BERT-like). It provides a practical alternative to traditional LLMs for information extraction tasks, offering high performance with lower resource requirements.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "information_extraction",
        "ner",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/urchade/GLiNER",
      "help_website": [
        "https://github.com/urchade/GLiNER"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ner",
        "nlp",
        "information-extraction",
        "zero-shot"
      ],
      "id": 289
    },
    {
      "name": "TextRL",
      "one_line_profile": "Library for Reinforcement Learning with Human Feedback (RLHF) on text generation models",
      "detailed_description": "TextRL is a Python library that implements RLHF pipelines compatible with Hugging Face Transformers. It allows users to fine-tune any text generation model using reinforcement learning techniques, supporting various reward models and environments.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/voidful/TextRL",
      "help_website": [
        "https://github.com/voidful/TextRL"
      ],
      "license": "MIT",
      "tags": [
        "rlhf",
        "reinforcement-learning",
        "nlp",
        "alignment"
      ],
      "id": 290
    },
    {
      "name": "transformers-qwen3-moe-fused",
      "one_line_profile": "Fused Mixture-of-Experts (MoE) layer implementation for accelerated Qwen3 training",
      "detailed_description": "This repository provides a highly optimized, fused implementation of the MoE layer for Qwen3 models. It is designed to be compatible with Hugging Face Transformers, LoRA, and Unsloth, enabling faster training and inference for MoE-based architectures.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "optimization",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/woct0rdho/transformers-qwen3-moe-fused",
      "help_website": [
        "https://github.com/woct0rdho/transformers-qwen3-moe-fused"
      ],
      "license": "Apache-2.0",
      "tags": [
        "moe",
        "optimization",
        "cuda",
        "qwen"
      ],
      "id": 291
    },
    {
      "name": "cycleformers",
      "one_line_profile": "Library for cycle-consistency training of transformer models",
      "detailed_description": "Cycleformers is a Python library that enables efficient cycle-consistency training (back-translation) for transformer models. It incorporates memory-efficient techniques like PEFT adapter switching, allowing for the training of larger models on limited hardware.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "alignment",
        "peft"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wrmthorne/cycleformers",
      "help_website": [
        "https://github.com/wrmthorne/cycleformers"
      ],
      "license": "CC-BY-4.0",
      "tags": [
        "transformers",
        "cycle-consistency",
        "peft",
        "training"
      ],
      "id": 292
    },
    {
      "name": "Xtreme1",
      "one_line_profile": "Multimodal data labeling and annotation platform for AI training",
      "detailed_description": "Xtreme1 is an open-source platform for multimodal training data annotation. It supports 3D LiDAR point clouds, images, and LLM data, providing tools for data visualization, labeling, and management to accelerate AI model development.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_processing",
        "annotation",
        "visualization"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/xtreme1-io/xtreme1",
      "help_website": [
        "https://docs.xtreme1.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "annotation",
        "labeling",
        "lidar",
        "multimodal",
        "llm"
      ],
      "id": 293
    },
    {
      "name": "Firefly",
      "one_line_profile": "Comprehensive large language model training and fine-tuning framework",
      "detailed_description": "Firefly is a full-stack tool for training large language models (LLMs). It supports various training stages including pre-training, supervised fine-tuning (SFT), and reinforcement learning (DPO), compatible with a wide range of open-source models like Qwen, Llama, and Baichuan.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "fine-tuning",
        "alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/yangjianxin1/Firefly",
      "help_website": [
        "https://github.com/yangjianxin1/Firefly"
      ],
      "license": null,
      "tags": [
        "llm",
        "training",
        "sft",
        "dpo",
        "framework"
      ],
      "id": 294
    },
    {
      "name": "LongQLoRA",
      "one_line_profile": "Efficient context extension tool for Large Language Models using QLoRA",
      "detailed_description": "A parameter-efficient fine-tuning tool designed to extend the context length of Large Language Models (LLMs) such as LLaMA. It utilizes QLoRA to reduce memory usage while maintaining performance, enabling the training of long-context models on consumer-grade hardware.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "context_extension",
        "fine_tuning",
        "qlora"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yangjianxin1/LongQLoRA",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "context-window",
        "qlora",
        "fine-tuning"
      ],
      "id": 295
    },
    {
      "name": "Self-Instruct",
      "one_line_profile": "Framework for aligning language models with self-generated instructions",
      "detailed_description": "A seminal framework for generating synthetic instruction-following data by bootstrapping off a pre-trained language model. It enables the creation of large-scale instruction tuning datasets with minimal human annotation, widely used for aligning LLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_generation",
        "instruction_tuning",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yizhongw/self-instruct",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "synthetic-data",
        "instruction-tuning",
        "alignment",
        "llm"
      ],
      "id": 296
    },
    {
      "name": "Chinese-LLaMA-Alpaca",
      "one_line_profile": "Chinese-adapted LLaMA and Alpaca LLM training and deployment suite",
      "detailed_description": "A comprehensive project providing Chinese vocabulary expansion, LoRA fine-tuning scripts, and merged model weights for LLaMA and Alpaca. It serves as a foundational platform for training and deploying Chinese-capable LLMs in research and industry.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "vocabulary_expansion",
        "fine_tuning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ymcui/Chinese-LLaMA-Alpaca",
      "help_website": [
        "https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki"
      ],
      "license": "Apache-2.0",
      "tags": [
        "chinese-llm",
        "llama",
        "lora",
        "fine-tuning"
      ],
      "id": 297
    },
    {
      "name": "Chinese-LLaMA-Alpaca-2",
      "one_line_profile": "Second generation Chinese LLaMA-2 & Alpaca-2 training suite with long context support",
      "detailed_description": "The successor to Chinese-LLaMA-Alpaca, targeting LLaMA-2. It includes tools for training, quantization, and inference, with specific support for 64K long-context models, serving as a key toolchain for Chinese LLM research.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "long_context",
        "fine_tuning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ymcui/Chinese-LLaMA-Alpaca-2",
      "help_website": [
        "https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llama-2",
        "long-context",
        "chinese-llm",
        "peft"
      ],
      "id": 298
    },
    {
      "name": "LLM-SFT",
      "one_line_profile": "Unified supervised fine-tuning framework for multiple LLM architectures",
      "detailed_description": "A versatile fine-tuning framework supporting various Large Language Models (ChatGLM, LLaMA, Bloom, Baichuan) and techniques (LoRA, QLoRA, DeepSpeed). It provides a unified interface for SFT, inference, and evaluation, facilitating efficient model adaptation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "supervised_fine_tuning",
        "model_evaluation",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yongzhuo/LLM-SFT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sft",
        "lora",
        "qlora",
        "deepspeed",
        "llm"
      ],
      "id": 299
    },
    {
      "name": "qwen2-sft",
      "one_line_profile": "Fine-tuning and inference toolkit specifically for Qwen model family",
      "detailed_description": "A specialized toolkit for Supervised Fine-Tuning (SFT) and LoRA adaptation of the Qwen (Qwen1.5/Qwen2) model series. It streamlines the process of adapting Qwen models for downstream tasks using transformers and peft libraries.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "inference",
        "model_adaptation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yongzhuo/qwen2-sft",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "qwen",
        "sft",
        "lora",
        "fine-tuning"
      ],
      "id": 300
    },
    {
      "name": "Olympus",
      "one_line_profile": "Universal task routing model for computer vision tasks",
      "detailed_description": "A universal task router that directs input queries to appropriate vision experts or models. It serves as a meta-tool for managing and orchestrating diverse computer vision tasks, facilitating multi-task learning and model composition.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "task_routing",
        "model_orchestration",
        "computer_vision"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yuanze-lin/Olympus",
      "help_website": [],
      "license": null,
      "tags": [
        "task-routing",
        "computer-vision",
        "model-composition"
      ],
      "id": 301
    },
    {
      "name": "ImageReward",
      "one_line_profile": "Human preference evaluation metric for text-to-image generation",
      "detailed_description": "A comprehensive text-to-image human preference reward model. It serves as a scientific metric tool to evaluate and align generative models with human aesthetics and instruction following, addressing the lack of robust evaluation metrics in visual generation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "evaluation",
        "reward_modeling",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zai-org/ImageReward",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reward-model",
        "rlhf",
        "evaluation-metric",
        "text-to-image"
      ],
      "id": 302
    },
    {
      "name": "VisionReward",
      "one_line_profile": "Fine-grained multi-dimensional preference learning for visual generation",
      "detailed_description": "An advanced reward modeling tool for image and video generation that evaluates outputs across multiple dimensions. It enables fine-grained alignment of visual generative models, supporting research in multimodal preference optimization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "evaluation",
        "reward_modeling",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zai-org/VisionReward",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reward-model",
        "video-generation",
        "preference-learning"
      ],
      "id": 303
    },
    {
      "name": "LLaMA-LoRA-Tuner",
      "one_line_profile": "GUI tool for fine-tuning LLaMA models using LoRA",
      "detailed_description": "A user-friendly interface (UI) for fine-tuning LLaMA and other LLMs using LoRA. It simplifies the parameter configuration and training process, making advanced fine-tuning techniques accessible for research and experimentation without deep coding requirements.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "workflow_management",
        "ui_tool"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/zetavg/LLaMA-LoRA-Tuner",
      "help_website": [],
      "license": null,
      "tags": [
        "gui",
        "lora",
        "fine-tuning",
        "llama"
      ],
      "id": 304
    },
    {
      "name": "KnowLM",
      "one_line_profile": "Knowledgeable Large Language Model Framework",
      "detailed_description": "An open-source framework designed to enhance Large Language Models with knowledge graph integration and knowledge extraction capabilities. It provides tools for training, extraction, and alignment of knowledge-aware LLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "model_training",
        "alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/KnowLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "llm",
        "information-extraction",
        "framework"
      ],
      "id": 305
    },
    {
      "name": "lmms-finetune",
      "one_line_profile": "Minimalist codebase for fine-tuning Large Multimodal Models",
      "detailed_description": "A streamlined and extensible codebase for fine-tuning various Large Multimodal Models (LMMs) such as LLaVA, Qwen-VL, and Phi3-V. It supports multiple architectures and provides a unified interface for multimodal instruction tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "multimodal_fine_tuning",
        "instruction_tuning",
        "model_adaptation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjysteven/lmms-finetune",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "fine-tuning",
        "llava",
        "qwen-vl"
      ],
      "id": 306
    }
  ]
}