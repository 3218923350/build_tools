{
  "generated_at": "2025-12-16T14:51:08.287713+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "X1",
      "leaf_cluster_name": "可信与不确定性量化生态",
      "domain": "Cross-domain",
      "typical_objects": "predictions",
      "task_chain": "UQ→校准→监控→审计→评测",
      "tool_form": "UQ/监控 + 评测"
    },
    "unit": {
      "unit_id": "X1-04",
      "unit_name": "可解释性/归因/反事实",
      "target_scale": "200–450",
      "coverage_tools": "XAI toolkits"
    },
    "search": {
      "target_candidates": 450,
      "queries": [
        "[GH] ELI5",
        "[GH] DiCE",
        "[GH] OmniXAI",
        "[GH] InterpretML",
        "[GH] Alibi Explain",
        "[GH] Captum",
        "[GH] LIME",
        "[GH] SHAP",
        "[GH] explainable ai toolkit",
        "[GH] interpretability library",
        "[GH] feature attribution",
        "[GH] counterfactual explanations",
        "[GH] shapley values",
        "[GH] saliency maps",
        "[GH] model debugging",
        "[GH] integrated gradients",
        "[GH] concept activation vectors",
        "[GH] neural network visualization",
        "[GH] interpretable machine learning",
        "[GH] causal interpretation",
        "[WEB] explainable ai toolkit python github",
        "[WEB] model interpretability attribution methods github",
        "[WEB] counterfactual explanation library github",
        "[WEB] deep learning visualization tools github",
        "[WEB] shapley value feature importance github"
      ],
      "total_candidates": 995,
      "tool_candidates": 708,
      "final_tools": 216
    }
  },
  "tools": [
    {
      "name": "KERMIT",
      "one_line_profile": "Lightweight library to encode and interpret Universal Syntactic Embeddings",
      "detailed_description": "A JavaScript library designed to encode and interpret Universal Syntactic Embeddings, facilitating the analysis of syntactic structures in natural language processing research.",
      "domains": [
        "NLP",
        "Linguistics"
      ],
      "subtask_category": [
        "embedding_interpretation",
        "syntactic_analysis"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/ART-Group-it/KERMIT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "embeddings",
        "syntax",
        "interpretability"
      ],
      "id": 1
    },
    {
      "name": "shparkley",
      "one_line_profile": "Spark implementation of Shapley Values using Monte-Carlo approximation",
      "detailed_description": "A PySpark library for computing Shapley values to explain machine learning model predictions at scale, utilizing Monte-Carlo approximation for efficiency.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "feature_attribution",
        "shapley_value_estimation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Affirm/shparkley",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "shapley-values",
        "pyspark",
        "model-interpretability",
        "xai"
      ],
      "id": 2
    },
    {
      "name": "splinecam",
      "one_line_profile": "Exact method for visualizing partitions of a Deep Neural Network",
      "detailed_description": "A tool for visualizing the decision boundaries and partitions of deep neural networks, providing exact visualizations to aid in understanding model behavior.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "model_visualization",
        "decision_boundary_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AhmedImtiazPrio/splinecam",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "neural-networks",
        "interpretability",
        "cvpr"
      ],
      "id": 3
    },
    {
      "name": "bvh-parser",
      "one_line_profile": "C++ library for parsing and interpreting BVH motion capture files",
      "detailed_description": "A library for parsing BioVision Hierarchy (BVH) files, commonly used in biomechanics and computer graphics for storing motion capture data.",
      "domains": [
        "Biomechanics",
        "Computer_Graphics"
      ],
      "subtask_category": [
        "data_parsing",
        "motion_capture_processing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/BartekkPL/bvh-parser",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bvh",
        "motion-capture",
        "parser",
        "cpp"
      ],
      "id": 4
    },
    {
      "name": "Style-CheXplain",
      "one_line_profile": "GAN-based method for counterfactual explanations in chest X-rays",
      "detailed_description": "A tool implementing a GAN-based approach to generate counterfactual explanations for chest X-ray classifiers, aiding in the interpretability of medical imaging models.",
      "domains": [
        "X1",
        "X1-04",
        "Medical_Imaging"
      ],
      "subtask_category": [
        "counterfactual_generation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CAMP-eXplain-AI/Style-CheXplain",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gan",
        "counterfactuals",
        "chest-x-ray",
        "medical-ai"
      ],
      "id": 5
    },
    {
      "name": "XBrainLab",
      "one_line_profile": "Software for interpretation of neural patterns from EEG data",
      "detailed_description": "An open-source software platform designed for the accelerated interpretation and analysis of neural patterns derived from EEG data, supporting neuroscience research.",
      "domains": [
        "Neuroscience",
        "X1-04"
      ],
      "subtask_category": [
        "eeg_analysis",
        "neural_pattern_interpretation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/CECNL/XBrainLab",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "eeg",
        "neuroscience",
        "interpretability",
        "brain-computer-interface"
      ],
      "id": 6
    },
    {
      "name": "IntegratedGradientsPytorch",
      "one_line_profile": "PyTorch implementation of Integrated Gradients attribution method",
      "detailed_description": "A PyTorch library implementing the Integrated Gradients method for feature attribution, allowing users to explain the predictions of deep learning models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "feature_attribution",
        "model_explanation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CVxTz/IntegratedGradientsPytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "integrated-gradients",
        "pytorch",
        "xai",
        "feature-attribution"
      ],
      "id": 7
    },
    {
      "name": "ICAM",
      "one_line_profile": "Interpretable Classification via Disentangled Representations",
      "detailed_description": "An implementation of ICAM, a method for interpretable classification that utilizes disentangled representations and feature attribution mapping to provide model explanations.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretable_classification",
        "feature_attribution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CherBass/ICAM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "disentangled-representation",
        "interpretability",
        "classification",
        "xai"
      ],
      "id": 8
    },
    {
      "name": "CLEAR",
      "one_line_profile": "Counterfactual Local Explanations of AI systems",
      "detailed_description": "A tool for generating counterfactual local explanations for AI systems, helping to understand individual predictions by identifying minimal changes required to alter the outcome.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "counterfactual_explanation",
        "local_explanation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ClearExplanationsAI/CLEAR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "counterfactuals",
        "xai",
        "explanation",
        "machine-learning"
      ],
      "id": 9
    },
    {
      "name": "thermostat",
      "one_line_profile": "Collection of NLP model explanations and analysis tools",
      "detailed_description": "A toolkit and dataset for generating, storing, and analyzing explanations for NLP models, facilitating research into the interpretability of language models.",
      "domains": [
        "X1",
        "X1-04",
        "NLP"
      ],
      "subtask_category": [
        "model_explanation",
        "nlp_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jsonnet",
      "repo_url": "https://github.com/DFKI-NLP/thermostat",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "xai",
        "explanations",
        "dataset"
      ],
      "id": 10
    },
    {
      "name": "sliceline",
      "one_line_profile": "Fast slice finding for Machine Learning model debugging",
      "detailed_description": "A tool for identifying data slices where a machine learning model performs poorly, aiding in model debugging and error analysis.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "model_debugging",
        "slice_finding"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/DataDome/sliceline",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "debugging",
        "ml-ops",
        "slice-finding",
        "error-analysis"
      ],
      "id": 11
    },
    {
      "name": "E-measure",
      "one_line_profile": "Enhanced-alignment Measure for Binary Foreground Map Evaluation",
      "detailed_description": "A MATLAB tool implementing the Enhanced-alignment Measure (E-measure) for evaluating binary foreground maps, commonly used in saliency detection and segmentation tasks.",
      "domains": [
        "Computer_Vision",
        "X1-04"
      ],
      "subtask_category": [
        "evaluation_metric",
        "saliency_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/DengPingFan/E-measure",
      "help_website": [],
      "license": null,
      "tags": [
        "evaluation",
        "metrics",
        "saliency",
        "computer-vision"
      ],
      "id": 12
    },
    {
      "name": "S-measure",
      "one_line_profile": "Structure-measure for evaluating foreground maps",
      "detailed_description": "A MATLAB tool implementing the Structure-measure (S-measure) for evaluating foreground maps, focusing on structural similarity in tasks like saliency detection.",
      "domains": [
        "Computer_Vision",
        "X1-04"
      ],
      "subtask_category": [
        "evaluation_metric",
        "saliency_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/DengPingFan/S-measure",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "evaluation",
        "metrics",
        "saliency",
        "computer-vision"
      ],
      "id": 13
    },
    {
      "name": "Boruta-Shap",
      "one_line_profile": "Tree-based feature selection tool combining Boruta algorithm with Shapley values",
      "detailed_description": "A Python tool that combines the Boruta feature selection algorithm with SHAP (SHapley Additive exPlanations) values to identify the most important features in a dataset. It provides a robust method for feature selection in scientific modeling and data analysis.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "feature_selection",
        "attribution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Ekeany/Boruta-Shap",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "feature-selection",
        "shap",
        "boruta",
        "xai"
      ],
      "id": 14
    },
    {
      "name": "delphi",
      "one_line_profile": "Automated interpretability library for language models",
      "detailed_description": "A library designed to help language models 'know themselves' through automated interpretability techniques. It provides tools for analyzing model behaviors and internal representations, contributing to the understanding of large language models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "model_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EleutherAI/delphi",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "interpretability",
        "llm",
        "mechanistic-interpretability"
      ],
      "id": 15
    },
    {
      "name": "knowledge-neurons",
      "one_line_profile": "Library for finding knowledge neurons in pretrained transformer models",
      "detailed_description": "A Python library specifically designed to locate and analyze 'knowledge neurons' within pretrained transformer models. It facilitates mechanistic interpretability research by linking specific model weights to factual knowledge.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "mechanistic_interpretability",
        "model_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EleutherAI/knowledge-neurons",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "transformer",
        "knowledge-neurons",
        "interpretability"
      ],
      "id": 16
    },
    {
      "name": "FAST",
      "one_line_profile": "High-performance framework for medical image processing and visualization",
      "detailed_description": "A cross-platform framework for high-performance medical image processing, neural network inference, and visualization. It is designed to handle large medical datasets and provides tools for real-time processing and analysis.",
      "domains": [
        "Medical Imaging",
        "X1-04"
      ],
      "subtask_category": [
        "image_processing",
        "visualization",
        "inference"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/FAST-Imaging/FAST",
      "help_website": [
        "https://fast.eriksmistad.no"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "medical-imaging",
        "visualization",
        "deep-learning"
      ],
      "id": 17
    },
    {
      "name": "LLMDebugger",
      "one_line_profile": "Debugging tool for Large Language Models via runtime execution verification",
      "detailed_description": "LDB (LLM Debugger) is a tool that enables debugging of Large Language Models by verifying runtime execution step-by-step. It helps in understanding model reasoning and identifying errors in generated code or logic, enhancing interpretability and reliability.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "debugging",
        "interpretability",
        "verification"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/FloridSleeves/LLMDebugger",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "debugging",
        "interpretability"
      ],
      "id": 18
    },
    {
      "name": "gReLU",
      "one_line_profile": "Library to train and interpret deep learning models for DNA sequences",
      "detailed_description": "gReLU is a Python library designed for training, interpreting, and applying deep learning models to DNA sequences. It provides functionalities for genomic data analysis and model interpretation, specifically tailored for bioinformatics applications.",
      "domains": [
        "Biology",
        "Genomics",
        "X1-04"
      ],
      "subtask_category": [
        "modeling",
        "interpretation",
        "sequence_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Genentech/gReLU",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "genomics",
        "dna",
        "deep-learning",
        "interpretability"
      ],
      "id": 19
    },
    {
      "name": "explainable_ai_sdk",
      "one_line_profile": "SDK for Google Cloud Explainable AI service",
      "detailed_description": "The Explainable AI SDK helps users build explanation metadata for their models and visualize feature attributions returned from Google Cloud's Explainable AI service. It facilitates the integration of interpretability features into machine learning workflows.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "visualization",
        "attribution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/GoogleCloudPlatform/explainable_ai_sdk",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "xai",
        "cloud",
        "attribution",
        "visualization"
      ],
      "id": 20
    },
    {
      "name": "Seq2Seq-Vis",
      "one_line_profile": "Visualization tool for Sequential Neural Networks with Attention",
      "detailed_description": "A visual debugging and interpretation tool for sequence-to-sequence models, particularly those using attention mechanisms. It allows users to explore the internal state and attention dynamics of models used in translation and other sequential tasks.",
      "domains": [
        "X1",
        "X1-04",
        "NLP"
      ],
      "subtask_category": [
        "visualization",
        "interpretability",
        "debugging"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/HendrikStrobelt/Seq2Seq-Vis",
      "help_website": [
        "http://seq2seq-vis.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "seq2seq",
        "attention",
        "nlp"
      ],
      "id": 21
    },
    {
      "name": "Infosys-Responsible-AI-Toolkit",
      "one_line_profile": "Toolkit for ensuring AI solutions are trustworthy and transparent",
      "detailed_description": "A comprehensive toolkit incorporating features for safety, security, explainability, fairness, bias detection, and hallucination detection. It aims to ensure that AI models are responsible and transparent, suitable for enterprise and scientific applications.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "fairness",
        "safety_check"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Infosys/Infosys-Responsible-AI-Toolkit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "responsible-ai",
        "explainability",
        "fairness",
        "security"
      ],
      "id": 22
    },
    {
      "name": "segmentation_metrics",
      "one_line_profile": "Package to compute medical segmentation metrics",
      "detailed_description": "A Python package dedicated to computing various metrics for evaluating medical image segmentation results. It provides a standardized way to assess the performance of segmentation models in medical imaging.",
      "domains": [
        "Medical Imaging",
        "X1-04"
      ],
      "subtask_category": [
        "evaluation",
        "metrics",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Jingnan-Jia/segmentation_metrics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-imaging",
        "segmentation",
        "metrics"
      ],
      "id": 23
    },
    {
      "name": "CounterfactualExplanations.jl",
      "one_line_profile": "Counterfactual Explanations and Algorithmic Recourse in Julia",
      "detailed_description": "A Julia package for generating counterfactual explanations and algorithmic recourse for machine learning models. It allows users to understand how changes in input features would affect model predictions, a key aspect of explainable AI.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "counterfactuals",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl",
      "help_website": [
        "https://www.patalt.org/CounterfactualExplanations.jl/dev/"
      ],
      "license": "MIT",
      "tags": [
        "julia",
        "counterfactuals",
        "xai",
        "interpretability"
      ],
      "id": 24
    },
    {
      "name": "Gcam",
      "one_line_profile": "PyTorch library for generating attention maps (Grad-CAM, etc.)",
      "detailed_description": "An easy-to-use PyTorch library for making model predictions interpretable. It supports generating attention maps using methods like Guided Backpropagation, Grad-CAM, Guided Grad-CAM, and Grad-CAM++, aiding in the visualization of CNN decisions.",
      "domains": [
        "X1",
        "X1-04",
        "Computer Vision"
      ],
      "subtask_category": [
        "visualization",
        "attribution",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Karol-G/Gcam",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "grad-cam",
        "pytorch",
        "visualization",
        "xai"
      ],
      "id": 25
    },
    {
      "name": "asent",
      "one_line_profile": "Efficient and transparent sentiment analysis library using spaCy",
      "detailed_description": "A Python library for performing efficient and transparent sentiment analysis. It emphasizes interpretability in sentiment scoring, making it useful for social science research or analyzing scientific text data where transparency is required.",
      "domains": [
        "X1",
        "X1-04",
        "NLP"
      ],
      "subtask_category": [
        "sentiment_analysis",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KennethEnevoldsen/asent",
      "help_website": [
        "https://kennethenevoldsen.github.io/asent/"
      ],
      "license": "MIT",
      "tags": [
        "sentiment-analysis",
        "spacy",
        "interpretability",
        "nlp"
      ],
      "id": 26
    },
    {
      "name": "fastcam",
      "one_line_profile": "Efficient computation of saliency maps for explainable AI attribution",
      "detailed_description": "A toolkit developed at Lawrence Livermore National Laboratory for generating saliency maps to explain AI model predictions, focusing on efficient computation for attribution tasks.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "saliency_maps",
        "attribution"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/LLNL/fastcam",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "xai",
        "saliency-map",
        "attribution",
        "computer-vision"
      ],
      "id": 27
    },
    {
      "name": "Genome_Factory",
      "one_line_profile": "Integrated library for tuning, deploying, and interpreting genomic models",
      "detailed_description": "A comprehensive library designed for the genomics domain to facilitate the tuning, deployment, and interpretation of machine learning models applied to genomic data.",
      "domains": [
        "X1",
        "X1-04",
        "B2"
      ],
      "subtask_category": [
        "genomics",
        "model_interpretation",
        "model_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MAGICS-LAB/Genome_Factory",
      "help_website": [],
      "license": null,
      "tags": [
        "genomics",
        "interpretability",
        "bioinformatics",
        "machine-learning"
      ],
      "id": 28
    },
    {
      "name": "Shapash",
      "one_line_profile": "User-friendly explainability and interpretability library for ML models",
      "detailed_description": "A Python library that provides visualization and interpretability tools to make machine learning models transparent and understandable for everyone.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "visualization",
        "model_audit"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/MAIF/shapash",
      "help_website": [
        "https://shapash.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "xai",
        "visualization",
        "shap",
        "interpretability"
      ],
      "id": 29
    },
    {
      "name": "SurvSHAP(t)",
      "one_line_profile": "Time-dependent explanations for survival analysis models",
      "detailed_description": "A library for explaining machine learning survival models using time-dependent Shapley values, allowing for interpretation of predictions over time.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "survival_analysis",
        "interpretability",
        "shapley_values"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/MI2DataLab/survshap",
      "help_website": [
        "https://mi2datalab.github.io/survshap/"
      ],
      "license": "MIT",
      "tags": [
        "survival-analysis",
        "xai",
        "shap",
        "time-series"
      ],
      "id": 30
    },
    {
      "name": "Receptive Field Analysis Toolbox",
      "one_line_profile": "Toolbox for analyzing and visualizing neural network receptive fields",
      "detailed_description": "A Python toolbox designed to analyze and visualize the receptive fields of neural network architectures, aiding in model understanding and design.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "model_analysis",
        "visualization",
        "receptive_field"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MLRichter/receptive_field_analysis_toolbox",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "neural-networks",
        "visualization",
        "analysis",
        "deep-learning"
      ],
      "id": 31
    },
    {
      "name": "GRETEL",
      "one_line_profile": "Graph Counterfactual Explanation Evaluation Framework",
      "detailed_description": "A framework for evaluating counterfactual explanation methods specifically for graph neural networks and graph data.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "counterfactuals",
        "graph_neural_networks",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/MarioTheOne/GRETEL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-learning",
        "counterfactuals",
        "xai",
        "evaluation"
      ],
      "id": 32
    },
    {
      "name": "FlashTorch",
      "one_line_profile": "Visualization toolkit for neural networks in PyTorch",
      "detailed_description": "A visualization toolkit for PyTorch that helps users visualize feature maps and saliency maps to understand what neural networks have learned.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "saliency_maps",
        "feature_visualization"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/MisaOgura/flashtorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "visualization",
        "xai",
        "computer-vision"
      ],
      "id": 33
    },
    {
      "name": "modelStudio",
      "one_line_profile": "Interactive Studio for Explanatory Model Analysis",
      "detailed_description": "An R package that generates interactive dashboards for explanatory model analysis, allowing users to explore model explanations and feature importance.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "model_analysis",
        "interactive_dashboard"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/ModelOriented/modelStudio",
      "help_website": [
        "https://modeloriented.github.io/modelStudio/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "r",
        "xai",
        "visualization",
        "dashboard"
      ],
      "id": 34
    },
    {
      "name": "shapr",
      "one_line_profile": "Accurate Shapley value estimation for machine learning models",
      "detailed_description": "An R package for explaining the output of machine learning models by computing estimated Shapley values, handling dependent features more accurately.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "shapley_values",
        "feature_importance"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/NorskRegnesentral/shapr",
      "help_website": [
        "https://norskregnesentral.github.io/shapr/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "r",
        "shap",
        "xai",
        "statistics"
      ],
      "id": 35
    },
    {
      "name": "InterpretDL",
      "one_line_profile": "Interpretation toolkit for Deep Learning models based on PaddlePaddle",
      "detailed_description": "A comprehensive interpretation toolkit for deep learning models built on the PaddlePaddle framework, offering various algorithms for model explanation.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "attribution",
        "model_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PaddlePaddle/InterpretDL",
      "help_website": [
        "https://interpretdl.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "paddlepaddle",
        "xai",
        "deep-learning",
        "interpretability"
      ],
      "id": 36
    },
    {
      "name": "VisualDL",
      "one_line_profile": "Deep Learning Visualization Toolkit for PaddlePaddle",
      "detailed_description": "A visualization tool for deep learning models, supporting scalar, image, audio, and graph visualization to assist in model training and debugging.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "training_monitoring",
        "model_graph"
      ],
      "application_level": "platform",
      "primary_language": "HTML",
      "repo_url": "https://github.com/PaddlePaddle/VisualDL",
      "help_website": [
        "https://www.paddlepaddle.org.cn/paddle/visualdl"
      ],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "paddlepaddle",
        "dashboard",
        "deep-learning"
      ],
      "id": 37
    },
    {
      "name": "tft-torch",
      "one_line_profile": "Temporal Fusion Transformers for Interpretable Time Series Forecasting",
      "detailed_description": "A PyTorch implementation of Temporal Fusion Transformers, designed for interpretable multi-horizon time series forecasting.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "forecasting",
        "time_series",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PlaytikaOSS/tft-torch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "time-series",
        "forecasting",
        "pytorch",
        "interpretability"
      ],
      "id": 38
    },
    {
      "name": "ViT-Prisma",
      "one_line_profile": "Mechanistic interpretability library for Vision Transformers",
      "detailed_description": "A library dedicated to mechanistic interpretability research for Vision and Video Transformers, enabling deep analysis of model internal states.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "mechanistic_interpretability",
        "model_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Prisma-Multimodal/ViT-Prisma",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vision-transformers",
        "mechanistic-interpretability",
        "xai",
        "research-tool"
      ],
      "id": 39
    },
    {
      "name": "ann-visualizer",
      "one_line_profile": "Python library for visualizing Artificial Neural Networks (ANN) architecture",
      "detailed_description": "A Python library that uses Graphviz to create a visualization of the Artificial Neural Network graph. It supports Keras and helps in understanding the model architecture.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "model_inspection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/RedaOps/ann-visualizer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "neural-networks",
        "keras",
        "graphviz"
      ],
      "id": 40
    },
    {
      "name": "RobustX",
      "one_line_profile": "Benchmarking library for robustness of counterfactual explanation methods",
      "detailed_description": "RobustX is an open-source Python library designed for benchmarking the robustness of counterfactual explanation (CE) methods. It provides a systematic framework for generating, evaluating, and comparing CEs with a focus on robustness.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "benchmarking",
        "counterfactual_explanation",
        "robustness_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/RobustCounterfactualX/RobustX",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "counterfactuals",
        "robustness",
        "benchmarking",
        "xai"
      ],
      "id": 41
    },
    {
      "name": "InterpretME",
      "one_line_profile": "Interpretable machine learning pipeline over knowledge graphs",
      "detailed_description": "An interpretable machine learning pipeline that integrates knowledge graphs to provide enhanced interpretability for ML models. It assists in tracing predictions back to domain knowledge.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "knowledge_graph",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/SDM-TIB/InterpretME",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "interpretability",
        "machine-learning",
        "pipeline"
      ],
      "id": 42
    },
    {
      "name": "alibi",
      "one_line_profile": "Algorithms for explaining machine learning models",
      "detailed_description": "Alibi is an open source Python library aimed at machine learning model inspection and interpretation. The focus of the library is to provide high-quality implementations of black-box, white-box, local and global explanation methods for classification and regression models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "explanation",
        "model_inspection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SeldonIO/alibi",
      "help_website": [
        "https://docs.seldon.io/projects/alibi/en/latest/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "xai",
        "interpretability",
        "machine-learning",
        "black-box-explanation"
      ],
      "id": 43
    },
    {
      "name": "PiML-Toolbox",
      "one_line_profile": "Python Interpretable Machine Learning toolbox for model development and diagnostics",
      "detailed_description": "PiML (Python Interpretable Machine Learning) is a toolbox for model development and diagnostics. It provides a suite of interpretable ML models and diagnostic tools to assess model reliability and trustworthiness.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretable_modeling",
        "model_diagnostics",
        "trustworthiness"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/SelfExplainML/PiML-Toolbox",
      "help_website": [
        "https://selfexplainml.github.io/PiML-Toolbox/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "interpretable-ml",
        "diagnostics",
        "trustworthiness",
        "toolbox"
      ],
      "id": 44
    },
    {
      "name": "eli5",
      "one_line_profile": "Library for debugging/inspecting machine learning classifiers",
      "detailed_description": "ELI5 is a Python library which allows to visualize and debug various Machine Learning models using unified API. It has built-in support for several ML frameworks and provides ways to explain black-box models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "debugging",
        "inspection",
        "explanation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/TeamHG-Memex/eli5",
      "help_website": [
        "https://eli5.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "debugging",
        "inspection",
        "visualization",
        "xai"
      ],
      "id": 45
    },
    {
      "name": "shapkit",
      "one_line_profile": "Interpret machine learning predictions using Shapley Values",
      "detailed_description": "Shapkit provides agnostic local feature importance based on Shapley Values to interpret machine learning predictions.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "feature_attribution",
        "shapley_values",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ThalesGroup/shapkit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "shapley-values",
        "feature-importance",
        "xai"
      ],
      "id": 46
    },
    {
      "name": "TransformerLens",
      "one_line_profile": "Library for mechanistic interpretability of GPT-style language models",
      "detailed_description": "A library for mechanistic interpretability of GPT-style language models. It allows researchers to inspect the internal activations and weights of transformers to understand how they work.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "mechanistic_interpretability",
        "model_inspection",
        "transformer_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TransformerLensOrg/TransformerLens",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mechanistic-interpretability",
        "transformers",
        "gpt",
        "analysis"
      ],
      "id": 47
    },
    {
      "name": "AIX360",
      "one_line_profile": "Interpretability and explainability of data and machine learning models",
      "detailed_description": "The AI Explainability 360 (AIX360) toolkit is an open-source library that supports the interpretability and explainability of datasets and machine learning models. It includes a comprehensive set of algorithms for different explanation needs.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "explainability",
        "interpretability",
        "dataset_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Trusted-AI/AIX360",
      "help_website": [
        "http://aix360.mybluemix.net/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "xai",
        "explainability",
        "toolkit",
        "ibm"
      ],
      "id": 48
    },
    {
      "name": "xaitk-saliency",
      "one_line_profile": "Explainable AI framework for visual saliency algorithms",
      "detailed_description": "XAITK-Saliency is an open source, explainable AI framework for visual saliency algorithm interfaces and implementations, built for analytics and autonomy applications. It provides a standard API for saliency generation.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "saliency_map",
        "visual_explanation",
        "xai_framework"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/XAITK/xaitk-saliency",
      "help_website": [
        "https://xaitk-saliency.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "saliency",
        "xai",
        "computer-vision",
        "explainability"
      ],
      "id": 49
    },
    {
      "name": "VaLSe",
      "one_line_profile": "Visualization library for interpretability and hallucination analysis of Large Vision-Language Models",
      "detailed_description": "A library of visualization tools designed to analyze the interpretability and hallucination phenomena in Large Vision-Language Models (LVLMs), aiding in model understanding and debugging.",
      "domains": [
        "X1-04",
        "Computer Vision",
        "NLP"
      ],
      "subtask_category": [
        "interpretability",
        "visualization",
        "hallucination_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Ziwei-Zheng/VaLSe",
      "help_website": [],
      "license": null,
      "tags": [
        "lvlm",
        "interpretability",
        "visualization",
        "hallucination"
      ],
      "id": 50
    },
    {
      "name": "XAI-Bench",
      "one_line_profile": "Benchmarking library for feature attribution explainability techniques",
      "detailed_description": "A library designed to benchmark and evaluate various feature attribution methods in explainable AI, providing metrics to assess the quality and reliability of explanations.",
      "domains": [
        "X1-04"
      ],
      "subtask_category": [
        "benchmarking",
        "evaluation",
        "feature_attribution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/abacusai/xai-bench",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "xai",
        "benchmarking",
        "feature-attribution",
        "evaluation"
      ],
      "id": 51
    },
    {
      "name": "GRETEL",
      "one_line_profile": "Framework for Counterfactual Explanations on Graph Classifiers",
      "detailed_description": "A framework for the development and evaluation of counterfactual explanation methods specifically for graph classification models, supporting graph-based interpretability research.",
      "domains": [
        "X1-04",
        "Graph Learning"
      ],
      "subtask_category": [
        "counterfactual_explanation",
        "graph_classification",
        "evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/aiim-research/GRETEL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-neural-networks",
        "counterfactuals",
        "xai",
        "evaluation-framework"
      ],
      "id": 52
    },
    {
      "name": "ShapleyValueFL",
      "one_line_profile": "Library for calculating Shapley Values in Federated Learning",
      "detailed_description": "A pip-installable library for computing the marginal contribution of clients in a Federated Learning environment using Shapley Values, aiding in data valuation and incentive mechanism design.",
      "domains": [
        "X1-04",
        "Federated Learning"
      ],
      "subtask_category": [
        "data_valuation",
        "shapley_value",
        "federated_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/akassharjun/ShapleyValueFL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "federated-learning",
        "shapley-value",
        "data-valuation"
      ],
      "id": 53
    },
    {
      "name": "pySaliencyMap",
      "one_line_profile": "Python implementation of Itti's saliency map algorithm",
      "detailed_description": "A Python implementation of the classic Itti-Koch-Niebur saliency map algorithm, used for modeling visual attention and extracting salient features in images.",
      "domains": [
        "X1-04",
        "Computer Vision"
      ],
      "subtask_category": [
        "saliency_detection",
        "visual_attention",
        "feature_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/akisatok/pySaliencyMap",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "saliency-map",
        "computer-vision",
        "itti-model",
        "attention"
      ],
      "id": 54
    },
    {
      "name": "familiar",
      "one_line_profile": "End-to-end pipeline for interpretable machine learning of tabular data",
      "detailed_description": "An R package that implements an end-to-end pipeline for interpretable machine learning on tabular data, including feature selection, model training, and explanation generation.",
      "domains": [
        "X1-04",
        "Bioinformatics"
      ],
      "subtask_category": [
        "interpretable_ml",
        "tabular_data_analysis",
        "feature_selection"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/alexzwanenburg/familiar",
      "help_website": [],
      "license": "EUPL-1.2",
      "tags": [
        "r-package",
        "interpretable-ml",
        "tabular-data",
        "pipeline"
      ],
      "id": 55
    },
    {
      "name": "ml-mycelium",
      "one_line_profile": "Interactive web viewer for exploring large neural networks",
      "detailed_description": "A web-based visualization tool designed to explore and interact with large neural network graphs, powering the visualization capabilities of systems like Talaria.",
      "domains": [
        "X1-04",
        "Deep Learning"
      ],
      "subtask_category": [
        "visualization",
        "model_exploration",
        "network_graph"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/apple/ml-mycelium",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "visualization",
        "neural-networks",
        "interactive",
        "graph"
      ],
      "id": 56
    },
    {
      "name": "HyperSHAP",
      "one_line_profile": "Framework for explaining hyperparameter optimization using Shapley values",
      "detailed_description": "A framework that applies Shapley value-based attribution to explain the results of hyperparameter optimization (HPO) processes, helping researchers understand hyperparameter importance and interactions.",
      "domains": [
        "X1-04",
        "AutoML"
      ],
      "subtask_category": [
        "hpo_explanation",
        "shapley_value",
        "automl"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/automl/HyperSHAP",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "automl",
        "hpo",
        "shapley-values",
        "explainability"
      ],
      "id": 57
    },
    {
      "name": "Shape As Points",
      "one_line_profile": "Differentiable Poisson Solver for 3D shape reconstruction",
      "detailed_description": "A differentiable Poisson solver that reconstructs 3D shapes from point clouds, enabling gradient-based optimization for 3D geometry tasks.",
      "domains": [
        "Scientific Modeling",
        "Computer Vision"
      ],
      "subtask_category": [
        "3d_reconstruction",
        "differentiable_physics",
        "geometry_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/autonomousvision/shape_as_points",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "3d-reconstruction",
        "differentiable-rendering",
        "poisson-solver",
        "point-cloud"
      ],
      "id": 58
    },
    {
      "name": "shapley",
      "one_line_profile": "Implementation of Shapley Value for classifiers in ensemble games",
      "detailed_description": "A Python library implementing the Shapley Value of Classifiers in Ensemble Games, providing attribution methods for machine learning models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "attribution",
        "model_interpretation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/benedekrozemberczki/shapley",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "shapley-values",
        "xai",
        "attribution"
      ],
      "id": 59
    },
    {
      "name": "fastshap",
      "one_line_profile": "Fast approximate Shapley values in R",
      "detailed_description": "An R package for computing fast approximate Shapley values, enabling efficient feature attribution for machine learning models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "attribution",
        "model_interpretation"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/bgreenwell/fastshap",
      "help_website": [],
      "license": null,
      "tags": [
        "r-package",
        "shapley-values",
        "xai"
      ],
      "id": 60
    },
    {
      "name": "CARLA",
      "one_line_profile": "Benchmark library for algorithmic recourse and counterfactual explanations",
      "detailed_description": "A Python library designed to benchmark and evaluate algorithmic recourse and counterfactual explanation algorithms, providing a standardized framework for XAI research.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "benchmarking",
        "counterfactual_explanation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/carla-recourse/CARLA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "counterfactuals",
        "benchmarking",
        "xai"
      ],
      "id": 61
    },
    {
      "name": "transformers-interpret",
      "one_line_profile": "Model explainability for Hugging Face Transformers",
      "detailed_description": "A Python package providing model explainability features specifically for Transformers models, enabling easy visualization of feature attribution.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "model_interpretation",
        "attribution"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/cdpierse/transformers-interpret",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "transformers",
        "nlp",
        "xai"
      ],
      "id": 62
    },
    {
      "name": "shap-hypetune",
      "one_line_profile": "Hyperparameter tuning and feature selection using SHAP",
      "detailed_description": "A Python package for simultaneous hyperparameter tuning and feature selection for gradient boosting models, leveraging SHAP values for feature importance.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "feature_selection",
        "hyperparameter_tuning"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/cerlymarco/shap-hypetune",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "shap",
        "automl",
        "feature-selection"
      ],
      "id": 63
    },
    {
      "name": "mace",
      "one_line_profile": "Model Agnostic Counterfactual Explanations",
      "detailed_description": "A Python library for generating model-agnostic counterfactual explanations, aiding in the interpretation of machine learning models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "counterfactual_explanation",
        "model_interpretation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/charmlab/mace",
      "help_website": [],
      "license": null,
      "tags": [
        "counterfactuals",
        "xai",
        "model-agnostic"
      ],
      "id": 64
    },
    {
      "name": "counterfactuals",
      "one_line_profile": "R package for Counterfactual Explanation Methods",
      "detailed_description": "An R package providing various methods for generating counterfactual explanations for machine learning models, facilitating model interpretability.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "counterfactual_explanation",
        "model_interpretation"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/dandls/counterfactuals",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "r-package",
        "counterfactuals",
        "xai"
      ],
      "id": 65
    },
    {
      "name": "CVVideoPlayer",
      "one_line_profile": "Video player for CV model debugging and analysis",
      "detailed_description": "A Python-based customizable video player designed for computer vision practitioners to develop, analyze, and debug video-related algorithms and models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "debugging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/danieltomer1/CVVideoPlayer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "computer-vision",
        "debugging",
        "visualization"
      ],
      "id": 66
    },
    {
      "name": "darkon",
      "one_line_profile": "Toolkit to Hack Your Deep Learning Models",
      "detailed_description": "A toolkit for understanding deep learning models, providing methods for influence analysis and visualization to interpret model behavior.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "model_interpretation",
        "influence_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/darkonhub/darkon",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "xai",
        "influence-functions",
        "visualization"
      ],
      "id": 67
    },
    {
      "name": "portal",
      "one_line_profile": "Visualization tool for deep neural networks",
      "detailed_description": "A tool to load and visualize deep neural networks on images and videos, facilitating model inspection and debugging.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "model_inspection"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/datature/portal",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "computer-vision",
        "deep-learning"
      ],
      "id": 68
    },
    {
      "name": "xplique",
      "one_line_profile": "Neural Networks Explainability Toolbox",
      "detailed_description": "A comprehensive Neural Networks Explainability Toolbox providing a wide range of attribution methods and visualization tools for XAI.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "model_interpretation",
        "attribution",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deel-ai/xplique",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "xai",
        "explainability",
        "attribution"
      ],
      "id": 69
    },
    {
      "name": "LIMES",
      "one_line_profile": "Link discovery framework for metric spaces and knowledge graphs",
      "detailed_description": "A framework for link discovery on the Semantic Web, implementing time-efficient approaches for large-scale link discovery in metric spaces.",
      "domains": [
        "X1",
        "Data Science"
      ],
      "subtask_category": [
        "data_alignment",
        "link_discovery"
      ],
      "application_level": "workflow",
      "primary_language": "Java",
      "repo_url": "https://github.com/dice-group/LIMES",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "semantic-web",
        "link-discovery",
        "knowledge-graph"
      ],
      "id": 70
    },
    {
      "name": "DICe",
      "one_line_profile": "Digital Image Correlation Engine for material deformation analysis",
      "detailed_description": "A stereo Digital Image Correlation (DIC) application that computes full-field displacement and strain from sequences of digital images, used in experimental mechanics.",
      "domains": [
        "Materials Science",
        "Physics"
      ],
      "subtask_category": [
        "image_analysis",
        "deformation_measurement"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/dicengine/dice",
      "help_website": [
        "https://dicengine.github.io/dice/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "digital-image-correlation",
        "strain-measurement",
        "experimental-mechanics"
      ],
      "id": 71
    },
    {
      "name": "Concept-based XAI",
      "one_line_profile": "Library for concept-based and disentanglement learning methods in XAI",
      "detailed_description": "A Python library implementing state-of-the-art Concept-based Explainable AI methods, focusing on disentanglement learning to provide human-interpretable explanations.",
      "domains": [
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "concept_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dmitrykazhdan/concept-based-xai",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "xai",
        "concept-based-explanations",
        "disentanglement"
      ],
      "id": 72
    },
    {
      "name": "GNNLens2",
      "one_line_profile": "Interactive visualization tool for Graph Neural Networks",
      "detailed_description": "A visualization tool designed to help researchers and developers understand and debug Graph Neural Networks (GNNs) through interactive graph exploration.",
      "domains": [
        "X1-04",
        "Graph Learning"
      ],
      "subtask_category": [
        "visualization",
        "model_debugging"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/dmlc/GNNLens2",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gnn",
        "visualization",
        "graph-neural-networks"
      ],
      "id": 73
    },
    {
      "name": "dominance-analysis",
      "one_line_profile": "Library for dominance analysis and Shapley Value Regression",
      "detailed_description": "A Python package for determining the relative importance of predictors in statistical models using dominance analysis and Shapley Value Regression.",
      "domains": [
        "X1-04",
        "Statistics"
      ],
      "subtask_category": [
        "feature_importance",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dominance-analysis/dominance-analysis",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "shapley-value",
        "feature-importance",
        "regression-analysis"
      ],
      "id": 74
    },
    {
      "name": "SBSCL",
      "one_line_profile": "Systems Biology Simulation Core Library",
      "detailed_description": "A Java implementation for interpreting and simulating models encoded in the Systems Biology Markup Language (SBML), providing numerical solution methods.",
      "domains": [
        "Systems Biology"
      ],
      "subtask_category": [
        "simulation",
        "model_interpretation"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/draeger-lab/SBSCL",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "sbml",
        "systems-biology",
        "simulation"
      ],
      "id": 75
    },
    {
      "name": "DataScope",
      "one_line_profile": "Tool for measuring data importance in ML pipelines",
      "detailed_description": "A library for measuring the importance of training data points in machine learning pipelines using Shapley values, facilitating data debugging and selection.",
      "domains": [
        "X1-04",
        "Data-Centric AI"
      ],
      "subtask_category": [
        "data_valuation",
        "attribution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/easeml/datascope",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "shapley-value",
        "data-importance",
        "ml-debugging"
      ],
      "id": 76
    },
    {
      "name": "ELI5",
      "one_line_profile": "Library for debugging and explaining machine learning classifiers",
      "detailed_description": "A Python library for inspecting machine learning classifiers and explaining their predictions, supporting various frameworks like scikit-learn and XGBoost.",
      "domains": [
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "model_debugging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/eli5-org/eli5",
      "help_website": [
        "https://eli5.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "xai",
        "model-inspection",
        "feature-importance"
      ],
      "id": 77
    },
    {
      "name": "emergent",
      "one_line_profile": "Biologically based neural network simulator",
      "detailed_description": "A comprehensive simulation environment for biologically based neural networks of the brain, featuring a 3D GUI and written in Go.",
      "domains": [
        "Neuroscience",
        "Computational Biology"
      ],
      "subtask_category": [
        "simulation",
        "neural_modeling"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/emer/emergent",
      "help_website": [
        "https://github.com/emer/emergent/wiki"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "neuroscience",
        "neural-network-simulation",
        "brain-modeling"
      ],
      "id": 78
    },
    {
      "name": "BioData",
      "one_line_profile": "Arduino library for interpreting biological signals",
      "detailed_description": "An Arduino library designed to facilitate the reading and interpretation of biological signals such as GSR and EMG for experimental data acquisition.",
      "domains": [
        "Biomedical Engineering"
      ],
      "subtask_category": [
        "data_acquisition",
        "signal_processing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/eringee/BioData",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "arduino",
        "biosignals",
        "sensor-interface"
      ],
      "id": 79
    },
    {
      "name": "LIME-MATLAB",
      "one_line_profile": "Low-Light Image Enhancement via Illumination Map Estimation",
      "detailed_description": "A MATLAB implementation of the LIME algorithm for enhancing low-light images by estimating illumination maps, used in image processing research.",
      "domains": [
        "Image Processing"
      ],
      "subtask_category": [
        "image_enhancement",
        "illumination_estimation"
      ],
      "application_level": "solver",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/estija/LIME",
      "help_website": [],
      "license": null,
      "tags": [
        "image-enhancement",
        "low-light",
        "matlab"
      ],
      "id": 80
    },
    {
      "name": "Netscope",
      "one_line_profile": "Web-based neural network architecture visualizer",
      "detailed_description": "A tool for visualizing the structure of neural networks, particularly supporting Caffe prototxt format, aiding in model design and inspection.",
      "domains": [
        "Deep Learning"
      ],
      "subtask_category": [
        "visualization",
        "model_inspection"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/ethereon/netscope",
      "help_website": [
        "http://ethereon.github.io/netscope/"
      ],
      "license": null,
      "tags": [
        "neural-network-visualization",
        "caffe",
        "model-graph"
      ],
      "id": 81
    },
    {
      "name": "deep-viz-keras",
      "one_line_profile": "Saliency map implementations for Keras models",
      "detailed_description": "A toolkit providing implementations of popular saliency map algorithms (like Saliency Maps, Grad-CAM) for visualizing and interpreting Keras models.",
      "domains": [
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/experiencor/deep-viz-keras",
      "help_website": [],
      "license": null,
      "tags": [
        "saliency-maps",
        "keras",
        "visualization"
      ],
      "id": 82
    },
    {
      "name": "explainX",
      "one_line_profile": "Explainable AI framework for data scientists",
      "detailed_description": "An open-source library for explaining and debugging black-box machine learning models, providing dashboards and metrics for model interpretability.",
      "domains": [
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "model_debugging"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/explainX/explainx",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "xai",
        "model-explanation",
        "dashboard"
      ],
      "id": 83
    },
    {
      "name": "ELI5 Dataset Scripts",
      "one_line_profile": "Scripts to recreate the ELI5 (Explain Like I'm 5) dataset",
      "detailed_description": "Provides the necessary scripts and documentation to download, process, and recreate the ELI5 dataset, a benchmark for question answering and explanation generation.",
      "domains": [
        "NLP",
        "X1-04"
      ],
      "subtask_category": [
        "dataset_creation",
        "data_processing"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/ELI5",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "dataset",
        "nlp",
        "question-answering"
      ],
      "id": 84
    },
    {
      "name": "PytorchRevelio",
      "one_line_profile": "Visualization toolkit for PyTorch neural networks",
      "detailed_description": "A toolkit for visualizing learned features in PyTorch models, including implementations of Saliency Maps, Grad-CAM, and DeepDream.",
      "domains": [
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/farhad-dalirani/PytorchRevelio",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "visualization",
        "grad-cam"
      ],
      "id": 85
    },
    {
      "name": "BME280 Library",
      "one_line_profile": "Arduino library for BME280 environmental sensor",
      "detailed_description": "A library for interfacing with the Bosch BME280 sensor to read temperature, humidity, and pressure data, facilitating environmental data acquisition.",
      "domains": [
        "Environmental Science",
        "IoT"
      ],
      "subtask_category": [
        "data_acquisition",
        "sensor_interface"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/finitespace/BME280",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "arduino",
        "sensor",
        "environmental-data"
      ],
      "id": 86
    },
    {
      "name": "ML Fairness Framework",
      "one_line_profile": "Fairness and robustness framework for LightGBM",
      "detailed_description": "A framework (FairPut) designed to enhance fairness, robustness, and explainability in machine learning models, specifically targeting LightGBM implementations.",
      "domains": [
        "X1-04",
        "X1-01"
      ],
      "subtask_category": [
        "fairness_audit",
        "model_optimization"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/firmai/ml-fairness-framework",
      "help_website": [],
      "license": null,
      "tags": [
        "fairness",
        "lightgbm",
        "robustness"
      ],
      "id": 87
    },
    {
      "name": "LeanVerifier",
      "one_line_profile": "Formal verification framework for ML properties using Lean 4",
      "detailed_description": "A framework for specifying and proving properties of machine learning models, such as robustness, fairness, and interpretability, using the Lean 4 theorem prover.",
      "domains": [
        "X1-01",
        "Formal Methods"
      ],
      "subtask_category": [
        "formal_verification",
        "model_checking"
      ],
      "application_level": "workflow",
      "primary_language": "Lean",
      "repo_url": "https://github.com/fraware/leanverifier",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "formal-verification",
        "lean4",
        "ml-robustness"
      ],
      "id": 88
    },
    {
      "name": "TSInterpret",
      "one_line_profile": "Interpretability library for time series classifiers",
      "detailed_description": "An open-source Python library dedicated to the interpretability of time series classification models, providing various attribution and explanation methods tailored for temporal data.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "time_series_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fzi-forschungszentrum-informatik/TSInterpret",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "time-series",
        "interpretability",
        "xai",
        "classification"
      ],
      "id": 89
    },
    {
      "name": "cnnshapes",
      "one_line_profile": "CNN intermediate activation visualizer for Keras",
      "detailed_description": "A tool for visualizing intermediate activations in Convolutional Neural Networks (CNNs) built with Keras, aiding in the understanding of feature extraction processes.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "model_debugging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gabrielpierobon/cnnshapes",
      "help_website": [],
      "license": null,
      "tags": [
        "keras",
        "cnn",
        "visualization",
        "activations"
      ],
      "id": 90
    },
    {
      "name": "iml",
      "one_line_profile": "Interpretable Machine Learning R package",
      "detailed_description": "An R package that provides a toolbox for analyzing and interpreting machine learning models, featuring model-agnostic methods like partial dependence plots, feature importance, and Shapley values.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "model_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/giuseppec/iml",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "r",
        "interpretability",
        "machine-learning",
        "feature-importance"
      ],
      "id": 91
    },
    {
      "name": "Model Explorer",
      "one_line_profile": "Modern model graph visualizer and debugger",
      "detailed_description": "A visualization tool designed to help researchers and engineers visualize, debug, and understand the structure and behavior of complex machine learning models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "model_debugging"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/google-ai-edge/model-explorer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "neural-networks",
        "debugging",
        "graph"
      ],
      "id": 92
    },
    {
      "name": "Penzai",
      "one_line_profile": "JAX toolkit for building and visualizing neural networks",
      "detailed_description": "A JAX-based research toolkit that facilitates the construction, editing, and visualization of neural networks, designed to support interpretability research and model understanding.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "modeling",
        "visualization",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google-deepmind/penzai",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jax",
        "neural-networks",
        "visualization",
        "interpretability"
      ],
      "id": 93
    },
    {
      "name": "Yggdrasil Decision Forests",
      "one_line_profile": "Library for decision forest models",
      "detailed_description": "A library to train, evaluate, interpret, and productionize decision forest models such as Random Forest and Gradient Boosted Decision Trees, with a focus on efficiency and interpretability.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "modeling",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/google/yggdrasil-decision-forests",
      "help_website": [
        "https://yggdrasil-decision-forests.github.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "decision-forests",
        "random-forest",
        "gbdt",
        "interpretability"
      ],
      "id": 94
    },
    {
      "name": "Booster",
      "one_line_profile": "Accelerator for LLM inference and debugging",
      "detailed_description": "An open accelerator tool designed to improve inference performance and provide debugging capabilities for Large Language Models (LLMs).",
      "domains": [
        "X1"
      ],
      "subtask_category": [
        "inference",
        "model_debugging"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/gotzmann/booster",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "inference",
        "optimization",
        "debugging"
      ],
      "id": 95
    },
    {
      "name": "OptBinning",
      "one_line_profile": "Optimal binning and scorecard modelling library",
      "detailed_description": "A library for optimal binning with constraints, supporting batch and stream processing, scorecard modelling, and counterfactual explanations for credit risk and other applications.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "modeling",
        "interpretability",
        "counterfactuals"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/guillermo-navas-palencia/optbinning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "binning",
        "scorecard",
        "counterfactuals",
        "credit-risk"
      ],
      "id": 96
    },
    {
      "name": "Blase",
      "one_line_profile": "Interpretable ML for astronomical spectroscopy",
      "detailed_description": "A PyTorch and JAX-based library for interpretable machine learning applications in astronomical spectroscopy, enabling analysis of spectral data.",
      "domains": [
        "X1",
        "X1-04",
        "Astronomy"
      ],
      "subtask_category": [
        "scientific_analysis",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/gully/blase",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "astronomy",
        "spectroscopy",
        "interpretability",
        "pytorch"
      ],
      "id": 97
    },
    {
      "name": "DeepVisualization",
      "one_line_profile": "Deep Neural Network visualization tool",
      "detailed_description": "A MATLAB-based tool for visualizing Deep Neural Networks by alternately applying image blurring and deblurring techniques to reveal feature activations.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "model_analysis"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/happynear/DeepVisualization",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "matlab",
        "visualization",
        "cnn",
        "deep-learning"
      ],
      "id": 98
    },
    {
      "name": "IntegratedGradients",
      "one_line_profile": "Integrated Gradients implementation for Keras",
      "detailed_description": "A Python/Keras implementation of the Integrated Gradients axiomatic attribution method for explaining deep network predictions.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "attribution",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/hiranumn/IntegratedGradients",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "integrated-gradients",
        "keras",
        "attribution",
        "xai"
      ],
      "id": 99
    },
    {
      "name": "DiceLoss-PyTorch",
      "one_line_profile": "Dice Loss implementation for PyTorch",
      "detailed_description": "A reusable implementation of Dice Loss for PyTorch, supporting both binary and multi-class segmentation tasks, commonly used in medical image analysis.",
      "domains": [
        "Computer Vision",
        "Modeling"
      ],
      "subtask_category": [
        "modeling",
        "loss_function"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hubutui/DiceLoss-PyTorch",
      "help_website": [],
      "license": null,
      "tags": [
        "pytorch",
        "dice-loss",
        "segmentation",
        "medical-imaging"
      ],
      "id": 100
    },
    {
      "name": "Saliency",
      "one_line_profile": "PyTorch implementation of various saliency mapping methods for model interpretability",
      "detailed_description": "A PyTorch library implementing 'Vanilla' Gradient, Grad-CAM, Guided Backprop, Integrated Gradients, and SmoothGrad variants for explaining deep learning model predictions.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "attribution"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/hummat/saliency",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pytorch",
        "saliency-maps",
        "grad-cam",
        "xai"
      ],
      "id": 101
    },
    {
      "name": "FastSHAP",
      "one_line_profile": "Amortized approach for calculating local Shapley value explanations",
      "detailed_description": "A Python library for fast estimation of Shapley values to explain model predictions, utilizing an amortized approach to speed up computation compared to standard sampling methods.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "attribution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/iancovert/fastshap",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "shapley-values",
        "feature-importance",
        "xai"
      ],
      "id": 102
    },
    {
      "name": "SAGE",
      "one_line_profile": "Global feature importance calculation using Shapley values",
      "detailed_description": "Shapley Additive Global Importance (SAGE) is a method for quantifying the global importance of features in machine learning models, providing a theoretically sound alternative to permutation importance.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "feature_importance"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/iancovert/sage",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "shapley-values",
        "global-importance",
        "xai"
      ],
      "id": 103
    },
    {
      "name": "Shapley Regression",
      "one_line_profile": "Calculation of Shapley values via linear regression",
      "detailed_description": "A library implementing methods to estimate Shapley values by formulating the problem as a weighted linear regression, enabling efficient attribution for machine learning models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "attribution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/iancovert/shapley-regression",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "shapley-values",
        "regression",
        "xai"
      ],
      "id": 104
    },
    {
      "name": "FullGrad Saliency",
      "one_line_profile": "Full-gradient saliency maps for neural network interpretation",
      "detailed_description": "Implementation of Full-Gradient Saliency Maps, a method that aggregates gradients from all layers to provide a more complete explanation of neural network predictions.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "saliency_map"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/idiap/fullgrad-saliency",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "saliency-maps",
        "deep-learning",
        "xai"
      ],
      "id": 105
    },
    {
      "name": "Inseq",
      "one_line_profile": "Interpretability toolkit for sequence generation models",
      "detailed_description": "A toolkit for interpreting sequence generation models (like Transformers) in NLP and potentially biological sequence analysis, offering feature attribution and visualization methods.",
      "domains": [
        "X1",
        "X1-04",
        "Bioinformatics"
      ],
      "subtask_category": [
        "interpretability",
        "sequence_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/inseq-team/inseq",
      "help_website": [
        "https://inseq.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "transformers",
        "attribution",
        "sequence-generation"
      ],
      "id": 106
    },
    {
      "name": "DiCE",
      "one_line_profile": "Diverse Counterfactual Explanations for machine learning models",
      "detailed_description": "A library for generating diverse counterfactual explanations for any machine learning model, helping to understand how to change inputs to achieve a desired prediction.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "counterfactuals"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/interpretml/DiCE",
      "help_website": [
        "https://interpretml.github.io/DiCE/"
      ],
      "license": "MIT",
      "tags": [
        "counterfactuals",
        "xai",
        "machine-learning"
      ],
      "id": 107
    },
    {
      "name": "InterpretML",
      "one_line_profile": "Toolkit for fitting interpretable models and explaining blackbox models",
      "detailed_description": "A comprehensive package for training interpretable models (like EBMs) and explaining blackbox systems using methods like SHAP and LIME. It serves as a unified framework for model interpretability.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/interpretml/interpret",
      "help_website": [
        "https://interpret.ml"
      ],
      "license": "MIT",
      "tags": [
        "ebm",
        "shap",
        "lime",
        "glassbox"
      ],
      "id": 108
    },
    {
      "name": "dev-survivors",
      "one_line_profile": "Reliable and interpretable survival analysis library",
      "detailed_description": "A Python library for survival analysis, providing interpretable models and reliable metrics for time-to-event data, commonly used in medical and biological research.",
      "domains": [
        "X1",
        "X1-04",
        "Biostatistics"
      ],
      "subtask_category": [
        "survival_analysis",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/iuliivasilev/dev-survivors",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "survival-analysis",
        "interpretability",
        "time-to-event"
      ],
      "id": 109
    },
    {
      "name": "BioAutoMATED",
      "one_line_profile": "Automated machine learning for biological sequence analysis and design",
      "detailed_description": "An automated machine learning system specifically designed for analyzing, interpreting, and designing biological sequences (DNA, proteins), facilitating model selection and interpretation for biologists.",
      "domains": [
        "Biology",
        "X1-04"
      ],
      "subtask_category": [
        "modeling",
        "sequence_design",
        "interpretability"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/jackievaleri/BioAutoMATED",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "automl",
        "biology",
        "sequences",
        "synthetic-biology"
      ],
      "id": 110
    },
    {
      "name": "Saliency from Backproj",
      "one_line_profile": "Saliency map generation via histogram back-projection",
      "detailed_description": "A lightweight tool to generate saliency maps by back-projecting image histograms and refining with GrabCut, useful for basic image region importance analysis.",
      "domains": [
        "X1-04",
        "Computer Vision"
      ],
      "subtask_category": [
        "interpretability",
        "saliency_map"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jacobgil/saliency-from-backproj",
      "help_website": [],
      "license": null,
      "tags": [
        "saliency",
        "image-processing",
        "grabcut"
      ],
      "id": 111
    },
    {
      "name": "Time Interpret",
      "one_line_profile": "Unified model interpretability library for time series",
      "detailed_description": "A Python library dedicated to interpreting machine learning models applied to time series data, offering methods tailored for temporal dependencies and feature importance.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "time_series_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/josephenguehard/time_interpret",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "time-series",
        "xai",
        "feature-importance"
      ],
      "id": 112
    },
    {
      "name": "CF-SHAP",
      "one_line_profile": "Counterfactual SHAP framework for feature importance",
      "detailed_description": "A framework combining counterfactual explanations with Shapley values to provide feature importance scores that reflect the changes needed to alter a model's prediction.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "counterfactuals",
        "attribution"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/jpmorganchase/cf-shap",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "shap",
        "counterfactuals",
        "xai"
      ],
      "id": 113
    },
    {
      "name": "nn_vis",
      "one_line_profile": "Neural network visualization and rendering tool",
      "detailed_description": "A tool for processing neural network architectures and rendering decluttered visualizations to gain insights into model structure and parameters.",
      "domains": [
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "model_inspection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/julrog/nn_vis",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "neural-networks",
        "visualization",
        "architecture"
      ],
      "id": 114
    },
    {
      "name": "Visualize Neural Network",
      "one_line_profile": "Tool to visualize neural network architectures with weights",
      "detailed_description": "A Python utility to generate visualizations of neural network structures, optionally displaying weight connections, aiding in model understanding and debugging.",
      "domains": [
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "model_inspection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jzliu-100/visualize-neural-network",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "visualization",
        "neural-networks",
        "weights"
      ],
      "id": 115
    },
    {
      "name": "tf-keras-vis",
      "one_line_profile": "Neural network visualization toolkit for tf.keras",
      "detailed_description": "A visualization toolkit for TensorFlow Keras models, supporting various saliency map methods (Grad-CAM, Saliency, etc.) to interpret model decisions.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/keisen/tf-keras-vis",
      "help_website": [
        "https://keisen.github.io/tf-keras-vis-docs/"
      ],
      "license": "MIT",
      "tags": [
        "keras",
        "tensorflow",
        "visualization",
        "grad-cam"
      ],
      "id": 116
    },
    {
      "name": "Interpret",
      "one_line_profile": "PyTorch implementation of SmoothGrad and Integrated Gradients for NLP",
      "detailed_description": "A PyTorch library implementing interpretability methods like SmoothGrad and Integrated Gradients specifically tailored for Natural Language Processing models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "attribution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/koren-v/Interpret",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "pytorch",
        "integrated-gradients",
        "xai"
      ],
      "id": 117
    },
    {
      "name": "PIZZA",
      "one_line_profile": "Attribution library for Large Language Models",
      "detailed_description": "A library designed for attribution analysis in Large Language Models (LLMs), helping to identify which parts of the input contribute to the model's generation.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "attribution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/leap-laboratories/PIZZA",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "attribution",
        "xai"
      ],
      "id": 118
    },
    {
      "name": "NNView",
      "one_line_profile": "Neural network architecture visualizer",
      "detailed_description": "A C-based library for visualizing the structure and connectivity of neural networks, aiding in model understanding and debugging.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "model_visualization",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/lighttransport/nnview",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "neural-networks",
        "debugging"
      ],
      "id": 119
    },
    {
      "name": "FastTreeSHAP",
      "one_line_profile": "Fast SHAP value computation for tree-based models",
      "detailed_description": "A Python package designed to accelerate the computation of SHAP (SHapley Additive exPlanations) values for interpreting predictions from tree ensemble models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "feature_attribution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/linkedin/FastTreeSHAP",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "shap",
        "tree-models",
        "explainable-ai"
      ],
      "id": 120
    },
    {
      "name": "TE2Rules",
      "one_line_profile": "Rule-based explainer for Tree Ensemble models",
      "detailed_description": "A Python library that translates Tree Ensemble models (like XGBoost) into a list of interpretable rules, facilitating model transparency and verification.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "model_translation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/linkedin/TE2Rules",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "xgboost",
        "rule-extraction",
        "explainable-ai"
      ],
      "id": 121
    },
    {
      "name": "DeepVis-PredDiff",
      "one_line_profile": "Prediction Difference Analysis for DNN visualization",
      "detailed_description": "A tool for visualizing deep neural network decisions using Prediction Difference Analysis, helping to identify which input features contribute to specific predictions.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lmzintgraf/DeepVis-PredDiff",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "deep-learning",
        "attribution"
      ],
      "id": 122
    },
    {
      "name": "KRLS",
      "one_line_profile": "Kernel-based Regularized Least Squares for interpretable modeling",
      "detailed_description": "An R package implementing Kernel-based Regularized Least Squares (KRLS), a machine learning technique to fit flexible, interpretable functional forms for continuous and binary outcomes without strong parametric assumptions.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "modeling",
        "statistical_inference"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/lukesonnet/KRLS",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "statistics",
        "interpretable-ml",
        "regression"
      ],
      "id": 123
    },
    {
      "name": "Netron",
      "one_line_profile": "Visualizer for neural network and ML models",
      "detailed_description": "A viewer for neural network, deep learning, and machine learning models. It supports visualizing the architecture of models exported in various formats (ONNX, Keras, Core ML, etc.).",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "model_visualization",
        "inspection"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/lutzroeder/netron",
      "help_website": [
        "https://netron.app"
      ],
      "license": "MIT",
      "tags": [
        "visualization",
        "onnx",
        "deep-learning"
      ],
      "id": 124
    },
    {
      "name": "DeepExplain",
      "one_line_profile": "Perturbation and gradient-based attribution framework",
      "detailed_description": "A unified framework for Deep Neural Network interpretability, implementing various perturbation and gradient-based attribution methods, including support for Shapley Values sampling.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "attribution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/marcoancona/DeepExplain",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gradient-attribution",
        "shapley-values",
        "pytorch"
      ],
      "id": 125
    },
    {
      "name": "LIME",
      "one_line_profile": "Local Interpretable Model-agnostic Explanations",
      "detailed_description": "A widely used library for explaining the predictions of any machine learning classifier by approximating it locally with an interpretable model.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "local_explanation"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/marcotcr/lime",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "model-agnostic",
        "explanation",
        "classifier"
      ],
      "id": 126
    },
    {
      "name": "SEARs",
      "one_line_profile": "Semantically Equivalent Adversarial Rules for NLP debugging",
      "detailed_description": "A tool for debugging NLP models by generating semantically equivalent adversarial rules to identify model inconsistencies and bugs.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "debugging",
        "adversarial_testing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/marcotcr/sears",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "nlp",
        "debugging",
        "adversarial"
      ],
      "id": 127
    },
    {
      "name": "ENNUI",
      "one_line_profile": "Drag-and-drop neural network builder and visualizer",
      "detailed_description": "An interactive user interface to build neural networks via drag-and-drop, train them in the browser, visualize the training process, and export the model to Python.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "modeling",
        "visualization",
        "education"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/martinjm97/ENNUI",
      "help_website": [
        "https://math.mit.edu/ennui/"
      ],
      "license": "MIT",
      "tags": [
        "gui",
        "neural-network-builder",
        "visualization"
      ],
      "id": 128
    },
    {
      "name": "shapefile",
      "one_line_profile": "Streaming parser for ESRI Shapefile format",
      "detailed_description": "A cross-platform streaming parser for the ESRI Shapefile spatial data format, essential for processing geospatial data in scientific research.",
      "domains": [
        "X1"
      ],
      "subtask_category": [
        "data_processing",
        "geospatial_analysis"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/mbostock/shapefile",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "gis",
        "geospatial",
        "data-parsing"
      ],
      "id": 129
    },
    {
      "name": "TensorCast.jl",
      "one_line_profile": "Tensor manipulation and broadcasting for Julia",
      "detailed_description": "A Julia library for convenient tensor slicing, dicing, and splicing using Einstein summation-like notation, facilitating scientific computing and modeling.",
      "domains": [
        "X1"
      ],
      "subtask_category": [
        "scientific_computing",
        "tensor_operations"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/mcabbott/TensorCast.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "julia",
        "tensor",
        "broadcasting"
      ],
      "id": 130
    },
    {
      "name": "LM-Debugger",
      "one_line_profile": "Interactive inspection tool for transformer language models",
      "detailed_description": "An interactive tool for inspection and intervention in transformer-based language models, allowing researchers to debug and understand model behavior.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "debugging",
        "interpretability"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mega002/lm-debugger",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "transformers",
        "debugging",
        "nlp"
      ],
      "id": 131
    },
    {
      "name": "shape_based_matching",
      "one_line_profile": "Implementation of Halcon-like shape based matching",
      "detailed_description": "An implementation of shape-based matching algorithms for computer vision, useful for object detection and alignment in scientific imaging tasks.",
      "domains": [
        "X1"
      ],
      "subtask_category": [
        "image_analysis",
        "object_detection"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/meiqua/shape_based_matching",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "computer-vision",
        "pattern-matching",
        "halcon"
      ],
      "id": 132
    },
    {
      "name": "debug-mistakes-cce",
      "one_line_profile": "Conceptual counterfactual explanations for model debugging",
      "detailed_description": "A tool for debugging model mistakes using conceptual counterfactual explanations, helping to identify high-level conceptual errors in model reasoning.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "debugging",
        "counterfactuals"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mertyg/debug-mistakes-cce",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "debugging",
        "counterfactuals",
        "concepts"
      ],
      "id": 133
    },
    {
      "name": "Captum",
      "one_line_profile": "Model interpretability and understanding for PyTorch",
      "detailed_description": "A comprehensive library for model interpretability in PyTorch, offering a wide range of attribution algorithms (Integrated Gradients, DeepLIFT, SHAP, etc.) to understand model predictions.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "attribution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/meta-pytorch/captum",
      "help_website": [
        "https://captum.ai"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "pytorch",
        "interpretability",
        "feature-attribution"
      ],
      "id": 134
    },
    {
      "name": "Responsible AI Toolbox",
      "one_line_profile": "Suite for model and data exploration and assessment",
      "detailed_description": "A suite of tools providing user interfaces and libraries for model and data exploration, error analysis, fairness assessment, and interpretability to enable responsible AI development.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "model_assessment",
        "interpretability",
        "fairness"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/microsoft/responsible-ai-toolbox",
      "help_website": [
        "https://responsibleaitoolbox.ai/"
      ],
      "license": "MIT",
      "tags": [
        "responsible-ai",
        "dashboard",
        "error-analysis"
      ],
      "id": 135
    },
    {
      "name": "vision-explanation-methods",
      "one_line_profile": "Saliency map generation for computer vision models",
      "detailed_description": "A library implementing various methods for creating saliency maps to explain the predictions of computer vision models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "saliency_maps"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/vision-explanation-methods",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "computer-vision",
        "saliency",
        "explanation"
      ],
      "id": 136
    },
    {
      "name": "TSCaptum",
      "one_line_profile": "Captum wrapper for Time Series XAI",
      "detailed_description": "A wrapper around the Captum library specifically designed to facilitate explainable AI (XAI) for time series data and models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "time_series_analysis"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/mlgig/tscaptum",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "time-series",
        "captum",
        "xai"
      ],
      "id": 137
    },
    {
      "name": "shapiq",
      "one_line_profile": "Shapley Interactions and Values for Machine Learning",
      "detailed_description": "A Python library for computing Shapley values and Shapley interactions to explain machine learning models, focusing on higher-order feature interactions.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "interaction_quantification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mmschlk/shapiq",
      "help_website": [
        "https://shapiq.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "shapley-values",
        "interactions",
        "game-theory"
      ],
      "id": 138
    },
    {
      "name": "DeepGaze",
      "one_line_profile": "Computer Vision library for HCI and gaze estimation",
      "detailed_description": "A computer vision library implementing head pose estimation, gaze direction estimation, and saliency mapping, widely used in human-computer interaction and behavioral research.",
      "domains": [
        "X1"
      ],
      "subtask_category": [
        "image_analysis",
        "behavioral_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mpatacchiola/deepgaze",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gaze-estimation",
        "head-pose",
        "saliency"
      ],
      "id": 139
    },
    {
      "name": "x264_saliency_mod",
      "one_line_profile": "x264 encoder with custom saliency map support",
      "detailed_description": "A modification of the x264 video encoder that supports custom saliency maps as input to improve the perceptual quality of salient objects in video compression.",
      "domains": [
        "X1"
      ],
      "subtask_category": [
        "data_processing",
        "video_compression"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/msu-video-group/x264_saliency_mod",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "video-encoding",
        "saliency",
        "compression"
      ],
      "id": 140
    },
    {
      "name": "Archipelago",
      "one_line_profile": "Interpretable attribution for feature interactions",
      "detailed_description": "A tool for generating interpretable attributions for feature interactions in machine learning models, helping to understand how features combine to affect predictions.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretability",
        "interaction_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mtsang/archipelago",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "feature-interactions",
        "attribution",
        "xai"
      ],
      "id": 141
    },
    {
      "name": "shapy",
      "one_line_profile": "3D body shape regression model using metric and semantic attributes",
      "detailed_description": "A framework for accurate 3D body shape regression that leverages metric and semantic attributes to provide interpretable control over the generated shapes, useful for computer vision and anthropometric analysis.",
      "domains": [
        "Computer Vision",
        "X1-04"
      ],
      "subtask_category": [
        "scientific_modeling",
        "inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/muelea/shapy",
      "help_website": [],
      "license": null,
      "tags": [
        "3d-reconstruction",
        "body-shape",
        "attributes",
        "interpretability"
      ],
      "id": 142
    },
    {
      "name": "AutoScore",
      "one_line_profile": "Interpretable ML-based automatic clinical score generator",
      "detailed_description": "An R package that automatically generates interpretable clinical scoring models from machine learning based variable selection, designed for medical research and clinical decision support.",
      "domains": [
        "Medical Informatics",
        "X1-04"
      ],
      "subtask_category": [
        "scientific_modeling",
        "clinical_scoring"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/nliulab/AutoScore",
      "help_website": [],
      "license": null,
      "tags": [
        "clinical-scores",
        "interpretable-ml",
        "healthcare"
      ],
      "id": 143
    },
    {
      "name": "ShapleyVIC",
      "one_line_profile": "Shapley Variable Importance Cloud for interpretable machine learning",
      "detailed_description": "A tool for visualizing and interpreting variable importance in machine learning models using Shapley values, providing a 'cloud' visualization to understand global and local feature effects.",
      "domains": [
        "X1-04"
      ],
      "subtask_category": [
        "model_interpretation",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/nliulab/ShapleyVIC",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "shapley-values",
        "visualization",
        "variable-importance"
      ],
      "id": 144
    },
    {
      "name": "ShapML.jl",
      "one_line_profile": "Julia package for interpretable ML with stochastic Shapley values",
      "detailed_description": "A Julia library that implements stochastic Shapley value estimation for interpreting machine learning models, offering performance benefits for large datasets.",
      "domains": [
        "X1-04"
      ],
      "subtask_category": [
        "model_interpretation"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/nredell/ShapML.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "shapley-values",
        "interpretable-ml"
      ],
      "id": 145
    },
    {
      "name": "shapFlex",
      "one_line_profile": "R package for asymmetric Shapley values and causality assessment",
      "detailed_description": "An R package designed to compute asymmetric Shapley values, allowing researchers to assess causal relationships and feature importance in trained machine learning models.",
      "domains": [
        "X1-04",
        "Causal Inference"
      ],
      "subtask_category": [
        "causal_inference",
        "model_interpretation"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/nredell/shapFlex",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "causality",
        "shapley-values",
        "r-package"
      ],
      "id": 146
    },
    {
      "name": "explanation_explorer",
      "one_line_profile": "User interface to interpret machine learning models",
      "detailed_description": "A web-based user interface that allows users to interactively explore and interpret predictions from machine learning models, facilitating error analysis and model understanding.",
      "domains": [
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "model_debugging"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/nyuvis/explanation_explorer",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "ui",
        "interactive-visualization",
        "xai"
      ],
      "id": 147
    },
    {
      "name": "explainerdashboard",
      "one_line_profile": "Framework to build interactive Explainable AI dashboards",
      "detailed_description": "A Python library that allows users to quickly build and deploy interactive web-based dashboards for explaining the inner workings of machine learning models, including feature importance, shapley values, and individual predictions.",
      "domains": [
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "reporting"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/oegedijk/explainerdashboard",
      "help_website": [
        "http://explainerdashboard.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "dashboard",
        "shap",
        "interactive",
        "model-monitoring"
      ],
      "id": 148
    },
    {
      "name": "shap-e",
      "one_line_profile": "Conditional 3D object generation model",
      "detailed_description": "A generative model that produces 3D objects (represented as implicit functions) conditioned on text or images, useful for synthesizing 3D assets for simulation and modeling.",
      "domains": [
        "Computer Vision",
        "Generative AI"
      ],
      "subtask_category": [
        "scientific_data_generation",
        "3d_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/openai/shap-e",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "generative-model",
        "text-to-3d",
        "image-to-3d"
      ],
      "id": 149
    },
    {
      "name": "OpenVINO XAI",
      "one_line_profile": "Explainable AI toolkit for OpenVINO models",
      "detailed_description": "A toolkit providing visual explanation algorithms (like saliency maps) for models optimized with OpenVINO, enabling interpretation of inference results on edge devices.",
      "domains": [
        "X1-04",
        "Edge AI"
      ],
      "subtask_category": [
        "model_interpretation",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/openvinotoolkit/openvino_xai",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "openvino",
        "saliency-map",
        "edge-inference"
      ],
      "id": 150
    },
    {
      "name": "Visual-Feature-Attribution-VAGANs",
      "one_line_profile": "Visual Feature Attribution using Wasserstein GANs",
      "detailed_description": "A PyTorch implementation of Visual Feature Attribution using Wasserstein GANs (VAGANs) to generate counterfactual maps for explaining classifier decisions in medical imaging and other domains.",
      "domains": [
        "X1-04",
        "Medical Imaging"
      ],
      "subtask_category": [
        "model_interpretation",
        "counterfactual_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/orobix/Visual-Feature-Attribution-Using-Wasserstein-GANs-Pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gan",
        "counterfactuals",
        "feature-attribution"
      ],
      "id": 151
    },
    {
      "name": "LimeGPS",
      "one_line_profile": "Real-time GPS signal simulator for LimeSDR",
      "detailed_description": "A command-line tool that generates GPS L1 signals for transmission via LimeSDR, used for testing GPS receivers and conducting GNSS research.",
      "domains": [
        "Signal Processing",
        "Navigation"
      ],
      "subtask_category": [
        "scientific_data_generation",
        "simulation"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/osqzss/LimeGPS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gps",
        "sdr",
        "simulator"
      ],
      "id": 152
    },
    {
      "name": "ICE",
      "one_line_profile": "Interactive Composition Explorer for language model programs",
      "detailed_description": "A visual debugger and interactive exploration tool for compositional language model programs, helping researchers understand and debug complex chains of LLM calls.",
      "domains": [
        "X1-04",
        "NLP"
      ],
      "subtask_category": [
        "model_debugging",
        "visualization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/oughtinc/ice",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "debugging",
        "compositionality"
      ],
      "id": 153
    },
    {
      "name": "stanford-shapenet-renderer",
      "one_line_profile": "Batch rendering scripts for ShapeNet models",
      "detailed_description": "A set of Blender scripts for batch rendering 3D models from the ShapeNet dataset, facilitating the creation of 2D image datasets for computer vision research.",
      "domains": [
        "Computer Vision"
      ],
      "subtask_category": [
        "scientific_data_processing",
        "rendering"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/panmari/stanford-shapenet-renderer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "blender",
        "shapenet",
        "rendering"
      ],
      "id": 154
    },
    {
      "name": "Concuerror",
      "one_line_profile": "Stateless model checking tool for Erlang programs",
      "detailed_description": "A systematic testing tool (model checker) for concurrent Erlang programs that explores execution interleavings to detect concurrency errors, serving the domain of formal verification.",
      "domains": [
        "X1",
        "Formal Methods"
      ],
      "subtask_category": [
        "verification",
        "model_checking"
      ],
      "application_level": "solver",
      "primary_language": "Erlang",
      "repo_url": "https://github.com/parapluu/Concuerror",
      "help_website": [
        "http://parapluu.github.io/Concuerror/"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "model-checking",
        "concurrency",
        "erlang"
      ],
      "id": 155
    },
    {
      "name": "visualkeras",
      "one_line_profile": "Visualization library for Keras neural network architectures",
      "detailed_description": "A Python package to generate layered or graph-style visualizations of Keras/TensorFlow neural network architectures, useful for scientific communication and model documentation.",
      "domains": [
        "X1-04"
      ],
      "subtask_category": [
        "scientific_visualization",
        "model_documentation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/paulgavrikov/visualkeras",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "keras",
        "visualization",
        "neural-networks"
      ],
      "id": 156
    },
    {
      "name": "CoMTE",
      "one_line_profile": "Counterfactual Explanations for Multivariate Time Series",
      "detailed_description": "A library for generating counterfactual explanations specifically for multivariate time series classifiers, helping to identify minimal changes needed to alter model predictions.",
      "domains": [
        "X1-04",
        "Time Series"
      ],
      "subtask_category": [
        "model_interpretation",
        "counterfactual_generation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/peaclab/CoMTE",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "time-series",
        "counterfactuals",
        "xai"
      ],
      "id": 157
    },
    {
      "name": "webshap",
      "one_line_profile": "In-browser Shapley value computation library",
      "detailed_description": "A JavaScript library that enables the computation of Shapley values directly in the web browser, allowing for client-side, privacy-preserving machine learning model explanation.",
      "domains": [
        "X1-04"
      ],
      "subtask_category": [
        "model_interpretation"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/poloclub/webshap",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "javascript",
        "shapley-values",
        "client-side-ml"
      ],
      "id": 158
    },
    {
      "name": "secml",
      "one_line_profile": "Library for Secure and Explainable Machine Learning",
      "detailed_description": "A Python library designed for the security evaluation of machine learning algorithms, providing tools for adversarial attacks, robustness testing, and explainability.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "security_evaluation",
        "model_interpretation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/pralab/secml",
      "help_website": [
        "https://secml.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "adversarial-ml",
        "security",
        "explainability"
      ],
      "id": 159
    },
    {
      "name": "PyC (Pytorch Concepts)",
      "one_line_profile": "Library for training concept-based interpretable deep learning models",
      "detailed_description": "PyC is a PyTorch-based library designed to facilitate the training and evaluation of concept-based interpretable deep learning models, enabling users to define and utilize high-level concepts for model explanations.",
      "domains": [
        "X1-04",
        "Computer Science"
      ],
      "subtask_category": [
        "interpretability",
        "concept_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pyc-team/pytorch_concepts",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pytorch",
        "interpretability",
        "concept-based-learning",
        "xai"
      ],
      "id": 160
    },
    {
      "name": "XRD Symmetry Prediction",
      "one_line_profile": "Interpretable ML for symmetry prediction from X-ray diffraction patterns",
      "detailed_description": "A tool leveraging interpretable machine learning approaches to predict symmetry and discover knowledge from X-ray diffraction (XRD) patterns, specifically designed for materials science applications.",
      "domains": [
        "X1-04",
        "Materials Science"
      ],
      "subtask_category": [
        "scientific_inference",
        "interpretability",
        "pattern_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/quantumbeam/xrd-symmetry-prediction",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "xrd",
        "materials-science",
        "interpretable-ml",
        "symmetry-prediction"
      ],
      "id": 161
    },
    {
      "name": "Zennit-CRP",
      "one_line_profile": "XAI toolkit for Concept Relevance Propagation and Relevance Maximization",
      "detailed_description": "An Explainable AI (XAI) toolkit that implements Concept Relevance Propagation (CRP) and Relevance Maximization, allowing for detailed attribution and visualization of neural network decisions.",
      "domains": [
        "X1-04",
        "Computer Science"
      ],
      "subtask_category": [
        "attribution",
        "visualization",
        "model_debugging"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/rachtibat/zennit-crp",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "xai",
        "concept-relevance-propagation",
        "attribution",
        "visualization"
      ],
      "id": 162
    },
    {
      "name": "keras-vis",
      "one_line_profile": "Neural network visualization toolkit for Keras",
      "detailed_description": "A toolkit for visualizing and debugging trained Keras neural network models. It provides implementations for saliency maps, activation maximization, and class activation maps to interpret model behavior.",
      "domains": [
        "X1-04",
        "Computer Science"
      ],
      "subtask_category": [
        "visualization",
        "saliency_maps",
        "model_debugging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/raghakot/keras-vis",
      "help_website": [
        "https://raghakot.github.io/keras-vis/"
      ],
      "license": "MIT",
      "tags": [
        "keras",
        "visualization",
        "saliency-maps",
        "grad-cam"
      ],
      "id": 163
    },
    {
      "name": "TCAV (PyTorch)",
      "one_line_profile": "Quantitative testing with Concept Activation Vectors in PyTorch",
      "detailed_description": "A PyTorch implementation of Testing with Concept Activation Vectors (TCAV), a method to interpret the internal state of deep learning models using high-level concepts.",
      "domains": [
        "X1-04",
        "Computer Science"
      ],
      "subtask_category": [
        "interpretability",
        "concept_activation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rakhimovv/tcav",
      "help_website": [],
      "license": null,
      "tags": [
        "tcav",
        "pytorch",
        "interpretability",
        "concept-activation-vectors"
      ],
      "id": 164
    },
    {
      "name": "Causing",
      "one_line_profile": "Causal interpretation using graphs",
      "detailed_description": "A Python package for causal interpretation using structural equation models and graphs, allowing for the analysis of causal effects in multivariate data.",
      "domains": [
        "X1-04",
        "Statistics"
      ],
      "subtask_category": [
        "causal_inference",
        "structural_equation_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/realrate/Causing",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "causality",
        "structural-equation-modeling",
        "interpretation",
        "graphs"
      ],
      "id": 165
    },
    {
      "name": "ShapleyR",
      "one_line_profile": "Shapley value usage for mlr in R",
      "detailed_description": "An R package designed to facilitate the calculation and usage of Shapley values for model interpretation within the mlr (Machine Learning in R) framework.",
      "domains": [
        "X1-04",
        "Statistics"
      ],
      "subtask_category": [
        "interpretability",
        "feature_importance"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/redichh/ShapleyR",
      "help_website": [],
      "license": null,
      "tags": [
        "r",
        "shapley-values",
        "mlr",
        "interpretability"
      ],
      "id": 166
    },
    {
      "name": "pastalog",
      "one_line_profile": "Realtime visualization of neural network training performance",
      "detailed_description": "A simple, realtime visualization server for monitoring neural network training metrics, useful for tracking model performance and convergence.",
      "domains": [
        "X1",
        "Computer Science"
      ],
      "subtask_category": [
        "visualization",
        "training_monitoring"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/rewonc/pastalog",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "deep-learning",
        "monitoring",
        "training-metrics"
      ],
      "id": 167
    },
    {
      "name": "SIRUS.jl",
      "one_line_profile": "Interpretable Machine Learning via Rule Extraction in Julia",
      "detailed_description": "A Julia package for Stable and Interpretable RUle Set (SIRUS) algorithms, providing interpretable machine learning models via rule extraction.",
      "domains": [
        "X1-04",
        "Computer Science"
      ],
      "subtask_category": [
        "interpretability",
        "rule_extraction"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/rikhuijzer/SIRUS.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "interpretable-ml",
        "rule-extraction",
        "sirus"
      ],
      "id": 168
    },
    {
      "name": "ChainPlots.jl",
      "one_line_profile": "Visualization for Flux.Chain neural networks",
      "detailed_description": "A Julia package for visualizing the structure and connections of neural networks built with Flux.Chain, aiding in model understanding and debugging.",
      "domains": [
        "X1-04",
        "Computer Science"
      ],
      "subtask_category": [
        "visualization",
        "model_inspection"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/rmsrosa/ChainPlots.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "flux",
        "visualization",
        "neural-networks"
      ],
      "id": 169
    },
    {
      "name": "OmniXAI",
      "one_line_profile": "Comprehensive library for eXplainable AI",
      "detailed_description": "OmniXAI is a library for explainable AI (XAI) that offers omni-way explanation capabilities for various machine learning models and data types, including tabular, image, text, and time-series data.",
      "domains": [
        "X1-04",
        "Computer Science"
      ],
      "subtask_category": [
        "interpretability",
        "explanation_generation",
        "feature_importance"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/salesforce/OmniXAI",
      "help_website": [
        "https://salesforce.github.io/OmniXAI/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "xai",
        "interpretability",
        "machine-learning",
        "visualization"
      ],
      "id": 170
    },
    {
      "name": "ACV",
      "one_line_profile": "Active Coalition of Variables for model explanation",
      "detailed_description": "ACV is a Python library that provides local rule-based explanations and different Shapley Value estimations for any machine learning model, with specific optimizations for tree-based models.",
      "domains": [
        "X1-04",
        "Computer Science"
      ],
      "subtask_category": [
        "interpretability",
        "shapley_values",
        "rule_extraction"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/salimamoukou/acv00",
      "help_website": [
        "https://acv.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "xai",
        "shapley-values",
        "interpretability",
        "random-forest"
      ],
      "id": 171
    },
    {
      "name": "CellBox",
      "one_line_profile": "Interpretable Machine Learning for Perturbation Biology",
      "detailed_description": "CellBox is a framework for modeling biological networks using interpretable machine learning, specifically designed to predict cellular responses to perturbations.",
      "domains": [
        "X1-04",
        "Biology"
      ],
      "subtask_category": [
        "biological_modeling",
        "perturbation_analysis",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/sanderlab/CellBox",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "biology",
        "interpretable-ml",
        "perturbation",
        "network-modeling"
      ],
      "id": 172
    },
    {
      "name": "convisualize_nb",
      "one_line_profile": "Visualisations for Convolutional Neural Networks in Pytorch",
      "detailed_description": "A collection of visualization techniques for Convolutional Neural Networks (CNNs) implemented in PyTorch, aiding in the interpretation of learned features.",
      "domains": [
        "X1-04",
        "Computer Science"
      ],
      "subtask_category": [
        "visualization",
        "feature_visualization",
        "cnn_interpretation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/sar-gupta/convisualize_nb",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "visualization",
        "cnn",
        "interpretability"
      ],
      "id": 173
    },
    {
      "name": "Graph Saliency Maps",
      "one_line_profile": "Graph saliency maps through spectral convolutional networks for brain mapping",
      "detailed_description": "A tool for generating saliency maps on graphs using spectral convolutional networks, specifically applied to brain mapping tasks to identify relevant brain regions.",
      "domains": [
        "X1-04",
        "Neuroscience"
      ],
      "subtask_category": [
        "saliency_mapping",
        "brain_mapping",
        "graph_neural_networks"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sarslancs/graph_saliency_maps",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "neuroscience",
        "graph-neural-networks",
        "saliency-maps",
        "brain-mapping"
      ],
      "id": 174
    },
    {
      "name": "Data_Driven_Symbolic_Regression",
      "one_line_profile": "Symbolic regression tool for identifying physical processes and turbulence models",
      "detailed_description": "A Python library implementing data-driven symbolic regression using Genetic Programming and Gene Expression Programming. It is specifically designed to identify physical processes, numerical schemes, and Large Eddy Simulation (LES) subgrid-scale turbulence models from data, offering interpretable machine learning capabilities for physics and fluid dynamics.",
      "domains": [
        "X1",
        "X1-04",
        "Physics",
        "Fluid Dynamics"
      ],
      "subtask_category": [
        "scientific_modeling",
        "symbolic_regression",
        "equation_discovery"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sayin/Data_Driven_Symbolic_Regression",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "symbolic-regression",
        "turbulence-modeling",
        "interpretable-ml",
        "physics-informed"
      ],
      "id": 175
    },
    {
      "name": "AutoMLWhitebox",
      "one_line_profile": "Automated machine learning library for building interpretable 'whitebox' models",
      "detailed_description": "A library designed to automatically construct interpretable machine learning models (Whitebox AutoML). It focuses on transparency and explainability in automated model generation, making it suitable for scientific applications where model rationale is critical.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "model_building",
        "automl",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sb-ai-lab/AutoMLWhitebox",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "automl",
        "interpretable-ml",
        "whitebox-models"
      ],
      "id": 176
    },
    {
      "name": "pyss3",
      "one_line_profile": "Interpretable text classification library using the SS3 model",
      "detailed_description": "A Python library implementing the SS3 text classifier, designed to be naturally interpretable. It includes visualization tools for Explainable AI (XAI) to analyze text classification decisions, applicable in social science and literature analysis.",
      "domains": [
        "X1",
        "X1-04",
        "NLP"
      ],
      "subtask_category": [
        "text_classification",
        "interpretability",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sergioburdisso/pyss3",
      "help_website": [
        "https://pyss3.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "nlp",
        "explainable-ai",
        "text-classification",
        "ss3"
      ],
      "id": 177
    },
    {
      "name": "SHAP",
      "one_line_profile": "Game theoretic approach to explain the output of any machine learning model",
      "detailed_description": "A unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations) assigns each feature an importance value for a particular prediction. It is widely used across scientific disciplines (genomics, physics, chemistry) to understand complex black-box models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "feature_attribution",
        "model_interpretation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shap/shap",
      "help_website": [
        "https://shap.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "xai",
        "shapley-values",
        "feature-importance",
        "interpretability"
      ],
      "id": 178
    },
    {
      "name": "AxBench",
      "one_line_profile": "Benchmarking library for LLM interpretability methods",
      "detailed_description": "A Python library developed by Stanford NLP for benchmarking the utility of Large Language Model (LLM) interpretability methods. It provides a standardized framework to evaluate how well explanation methods work.",
      "domains": [
        "X1",
        "X1-04",
        "NLP"
      ],
      "subtask_category": [
        "benchmarking",
        "evaluation",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanfordnlp/axbench",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "interpretability",
        "benchmark",
        "xai"
      ],
      "id": 179
    },
    {
      "name": "pyreft",
      "one_line_profile": "Library for Representation Finetuning (ReFT) of language models",
      "detailed_description": "A Python library for Representation Finetuning (ReFT), a method for intervening on internal model representations to steer behavior. It is a tool for mechanistic interpretability and model control.",
      "domains": [
        "X1",
        "X1-04",
        "NLP"
      ],
      "subtask_category": [
        "model_steering",
        "intervention",
        "finetuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanfordnlp/pyreft",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "representation-learning",
        "intervention",
        "interpretability"
      ],
      "id": 180
    },
    {
      "name": "pyvene",
      "one_line_profile": "Library for intervention-based model understanding and improvement",
      "detailed_description": "A Python library for performing interventions on PyTorch models to understand their internal mechanisms. It supports causal abstraction and interchange intervention training, facilitating mechanistic interpretability research.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "causal_intervention",
        "mechanistic_interpretability",
        "model_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanfordnlp/pyvene",
      "help_website": [
        "https://stanfordnlp.github.io/pyvene/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "intervention",
        "causality",
        "pytorch",
        "interpretability"
      ],
      "id": 181
    },
    {
      "name": "attributionpriors",
      "one_line_profile": "Tools for training explainable models using attribution priors",
      "detailed_description": "A library for training machine learning models with attribution priors, which constrain the model's explanations to align with prior domain knowledge. This improves model interpretability and reliability in scientific contexts.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "model_training",
        "regularization",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/suinleelab/attributionpriors",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "attribution-priors",
        "explainable-ai",
        "regularization"
      ],
      "id": 182
    },
    {
      "name": "path_explain",
      "one_line_profile": "Feature attribution and interaction analysis for deep neural networks",
      "detailed_description": "A repository and library for explaining feature attributions and feature interactions in deep neural networks, particularly using path-integrated gradients. Developed by the Su-In Lee lab, it is used for interpreting deep learning models in genomics and healthcare.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "feature_attribution",
        "interaction_analysis",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/suinleelab/path_explain",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "feature-interactions",
        "integrated-gradients",
        "deep-learning"
      ],
      "id": 183
    },
    {
      "name": "Lucid",
      "one_line_profile": "Infrastructure and tools for neural network interpretability research",
      "detailed_description": "A collection of infrastructure and tools for research in neural network interpretability, primarily focused on feature visualization. It allows researchers to visualize what specific neurons or layers in a neural network are detecting.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "feature_visualization",
        "interpretability",
        "model_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/tensorflow/lucid",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "feature-visualization",
        "tensorflow",
        "interpretability"
      ],
      "id": 184
    },
    {
      "name": "TensorSpace",
      "one_line_profile": "3D visualization framework for neural networks",
      "detailed_description": "A framework for building interactive 3D visualizations of neural network models in the browser. It supports models from TensorFlow, Keras, and TensorFlow.js, helping researchers and users intuitively understand model architecture and data flow.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "scientific_visualization",
        "model_visualization"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/tensorspace-team/tensorspace",
      "help_website": [
        "https://tensorspace.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "3d",
        "neural-networks",
        "browser-based"
      ],
      "id": 185
    },
    {
      "name": "GGOS_Tropospheric_Delay_Solver",
      "one_line_profile": "C project for solving tropospheric delay using GGOS products",
      "detailed_description": "A C-based tool developed to solve tropospheric delay using GGOS (Global Geodetic Observing System) tropospheric products. It is based on RTKLIB and is designed to facilitate GNSS research by providing a tool for atmospheric delay estimation.",
      "domains": [
        "X1",
        "Geodesy",
        "Atmospheric Science"
      ],
      "subtask_category": [
        "data_processing",
        "atmospheric_correction",
        "gnss_analysis"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/tianruivpn1001/C-project-for-solving-tropospheric-delay-using-GGOS-tropospheric-products",
      "help_website": [],
      "license": null,
      "tags": [
        "gnss",
        "troposphere",
        "rtklib",
        "geodesy"
      ],
      "id": 186
    },
    {
      "name": "lime (R)",
      "one_line_profile": "R port of Local Interpretable Model-Agnostic Explanations (LIME)",
      "detailed_description": "The R implementation of LIME, a method for explaining the predictions of any machine learning classifier. It approximates the black-box model locally with an interpretable model to explain individual predictions.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "model_explanation",
        "local_interpretation"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/tidymodels/lime",
      "help_website": [
        "https://lime.data-imaginist.com"
      ],
      "license": "NOASSERTION",
      "tags": [
        "xai",
        "lime",
        "model-agnostic",
        "r-package"
      ],
      "id": 187
    },
    {
      "name": "causalglm",
      "one_line_profile": "Causal inference for heterogeneous treatment effects using GLMs",
      "detailed_description": "An R package for interpretable and model-robust causal inference. It estimates heterogeneous treatment effects using generalized linear working models combined with targeted machine learning, suitable for biostatistics and epidemiology.",
      "domains": [
        "X1",
        "X1-04",
        "Statistics"
      ],
      "subtask_category": [
        "causal_inference",
        "statistical_modeling"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/tlverse/causalglm",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "causal-inference",
        "heterogeneous-treatment-effects",
        "targeted-learning"
      ],
      "id": 188
    },
    {
      "name": "sklearn-interpretable-tree",
      "one_line_profile": "Simplified tree-based classifier and regressor for interpretable machine learning",
      "detailed_description": "A Python library that provides a simplified, scikit-learn compatible implementation of tree-based classifiers and regressors designed specifically for interpretable machine learning workflows.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "interpretable_modeling",
        "model_explanation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tmadl/sklearn-interpretable-tree",
      "help_website": [],
      "license": null,
      "tags": [
        "interpretable-ml",
        "decision-trees",
        "scikit-learn"
      ],
      "id": 189
    },
    {
      "name": "nshap",
      "one_line_profile": "Computation of interaction indices extending the Shapley Value",
      "detailed_description": "A Python package developed by the Trustworthy Machine Learning group at University of Tübingen to compute interaction indices that extend the Shapley Value, as presented at AISTATS 2023.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "feature_attribution",
        "interaction_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/tml-tuebingen/nshap",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "shapley-values",
        "interaction-indices",
        "xai"
      ],
      "id": 190
    },
    {
      "name": "shap-select",
      "one_line_profile": "Feature selection for gradient boosting models using Shapley values",
      "detailed_description": "A library designed for performing feature selection on gradient boosting models by utilizing regression on feature Shapley values to identify the most impactful features.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "feature_selection",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/transferwise/shap-select",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "feature-selection",
        "shapley-values",
        "gradient-boosting"
      ],
      "id": 191
    },
    {
      "name": "DICE",
      "one_line_profile": "Disentangling User Interest and Conformity for Recommendation with Causal Embedding",
      "detailed_description": "Implementation of the DICE framework (WWW '21) which uses causal embedding to disentangle user interest from conformity in recommendation systems, aiding in causal modeling of user behavior.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "causal_inference",
        "disentanglement"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tsinghua-fib-lab/DICE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "causal-embedding",
        "recommender-systems",
        "disentanglement"
      ],
      "id": 192
    },
    {
      "name": "Manifold",
      "one_line_profile": "Model-agnostic visual debugging tool for machine learning",
      "detailed_description": "A visual debugging tool for machine learning that provides model-agnostic visualizations to help researchers identify performance issues and understand model behavior across different data subsets.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "visual_debugging",
        "model_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/uber/manifold",
      "help_website": [
        "https://eng.uber.com/manifold/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "debugging",
        "model-agnostic"
      ],
      "id": 193
    },
    {
      "name": "Quantus",
      "one_line_profile": "Toolkit for responsible evaluation of neural network explanations",
      "detailed_description": "An eXplainable AI (XAI) toolkit designed for the quantitative evaluation of neural network explanations, providing metrics to assess the reliability and faithfulness of explanation methods.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "xai_evaluation",
        "explanation_metrics"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/understandable-machine-intelligence-lab/Quantus",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "xai",
        "evaluation",
        "neural-networks"
      ],
      "id": 194
    },
    {
      "name": "pytorch-cnn-visualizations",
      "one_line_profile": "PyTorch implementation of convolutional neural network visualization techniques",
      "detailed_description": "A comprehensive collection of PyTorch implementations for various convolutional neural network visualization techniques, aiding in the interpretability of deep learning models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "feature_attribution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/utkuozbulak/pytorch-cnn-visualizations",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "cnn",
        "visualization"
      ],
      "id": 195
    },
    {
      "name": "cnn-fixations",
      "one_line_profile": "Visualising predictions of deep neural networks",
      "detailed_description": "A tool for visualizing the predictions of deep neural networks, focusing on identifying fixations or salient regions that contribute to model decisions.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "saliency_mapping"
      ],
      "application_level": "library",
      "primary_language": null,
      "repo_url": "https://github.com/val-iisc/cnn-fixations",
      "help_website": [],
      "license": null,
      "tags": [
        "visualization",
        "deep-learning",
        "saliency"
      ],
      "id": 196
    },
    {
      "name": "OCTET",
      "one_line_profile": "Object-aware Counterfactual Explanations",
      "detailed_description": "Implementation of OCTET (CVPR 2023), a method for generating object-aware counterfactual explanations to improve the interpretability of computer vision models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "counterfactual_explanation",
        "image_interpretability"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/valeoai/OCTET",
      "help_website": [],
      "license": null,
      "tags": [
        "counterfactuals",
        "computer-vision",
        "xai"
      ],
      "id": 197
    },
    {
      "name": "STEEX",
      "one_line_profile": "Steering Counterfactual Explanations with Semantics",
      "detailed_description": "A tool for generating counterfactual explanations that can be steered using semantic attributes, enhancing the control and interpretability of model explanations.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "counterfactual_explanation",
        "semantic_steering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/valeoai/STEEX",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "counterfactuals",
        "semantics",
        "xai"
      ],
      "id": 198
    },
    {
      "name": "Data2Vis",
      "one_line_profile": "Automatic Generation of Data Visualizations Using Sequence to Sequence RNNs",
      "detailed_description": "An automatic visualization generation tool that uses sequence-to-sequence recurrent neural networks to convert data specifications into visualization specifications.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "scientific_visualization",
        "automated_visualization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/victordibia/data2vis",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "seq2seq",
        "rnn"
      ],
      "id": 199
    },
    {
      "name": "OCEAN",
      "one_line_profile": "Optimal Counterfactual Explanations in Tree Ensembles",
      "detailed_description": "Implementation of OCEAN (ICML 2021), a method for finding optimal counterfactual explanations specifically for tree ensemble models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "counterfactual_explanation",
        "tree_ensembles"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/vidalt/OCEAN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "counterfactuals",
        "tree-ensembles",
        "optimization"
      ],
      "id": 200
    },
    {
      "name": "Net2Vis",
      "one_line_profile": "Automatic neural network visualizations generated in your browser",
      "detailed_description": "A web-based tool for automatically generating abstract visualizations of neural network architectures from code, facilitating the documentation and communication of model structures.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "network_visualization",
        "architecture_diagram"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/viscom-ulm/Net2Vis",
      "help_website": [
        "https://viscom.net2vis.uni-ulm.de/"
      ],
      "license": "MIT",
      "tags": [
        "visualization",
        "neural-networks",
        "architecture"
      ],
      "id": 201
    },
    {
      "name": "WindowSHAP",
      "one_line_profile": "Model-agnostic framework for explaining time-series classifiers using Shapley values",
      "detailed_description": "A framework designed to provide explanations for time-series classifiers by adapting Shapley values to work with sliding windows over temporal data.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "time_series_explanation",
        "shapley_values"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/vsubbian/WindowSHAP",
      "help_website": [],
      "license": null,
      "tags": [
        "time-series",
        "shapley-values",
        "xai"
      ],
      "id": 202
    },
    {
      "name": "cnn-visualization",
      "one_line_profile": "Visualize How Convolutional Neural Networks Work with Keras",
      "detailed_description": "A collection of Keras-based implementations for visualizing the internal workings of Convolutional Neural Networks (CNNs), including feature maps and filters.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "visualization",
        "feature_inspection"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/waleedka/cnn-visualization",
      "help_website": [],
      "license": null,
      "tags": [
        "keras",
        "cnn",
        "visualization"
      ],
      "id": 203
    },
    {
      "name": "HiddenLayer",
      "one_line_profile": "Neural network graphs and training metrics for PyTorch, Tensorflow, and Keras",
      "detailed_description": "A lightweight library for visualizing neural network graphs and tracking training metrics in real-time for PyTorch, TensorFlow, and Keras models.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "network_visualization",
        "training_monitoring"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/waleedka/hiddenlayer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "pytorch",
        "tensorflow"
      ],
      "id": 204
    },
    {
      "name": "CFAI",
      "one_line_profile": "A collection of algorithms of counterfactual explanations",
      "detailed_description": "A repository collecting various algorithms and implementations for generating counterfactual explanations, serving as a resource for XAI research and application.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "counterfactual_explanation",
        "algorithm_collection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wangyongjie-ntu/CFAI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "counterfactuals",
        "xai",
        "algorithms"
      ],
      "id": 205
    },
    {
      "name": "VisualTorch",
      "one_line_profile": "Visualization of Torch-based neural network architectures",
      "detailed_description": "A library to help visualize the architecture of Torch-based neural networks, generating diagrams to inspect model structure.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "network_visualization",
        "architecture_inspection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/willyfh/visualtorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "visualization",
        "architecture"
      ],
      "id": 206
    },
    {
      "name": "ClusterShapley",
      "one_line_profile": "Explaining dimensionality results using SHAP values",
      "detailed_description": "A tool for explaining the results of dimensionality reduction and clustering algorithms by applying Shapley value analysis to understand feature contributions.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "clustering_explanation",
        "dimensionality_reduction_analysis"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/wilsonjr/ClusterShapley",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "shapley-values",
        "clustering",
        "dimensionality-reduction"
      ],
      "id": 207
    },
    {
      "name": "NLP-Loss-Pytorch",
      "one_line_profile": "Implementation of unbalanced loss functions like focal_loss, dice_loss",
      "detailed_description": "A PyTorch implementation of various loss functions designed for handling unbalanced data, such as Focal Loss, Dice Loss, and GHM Loss, useful for robust model training.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "model_training",
        "loss_functions"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/xinyi-code/NLP-Loss-Pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "loss-functions",
        "pytorch",
        "imbalanced-learning"
      ],
      "id": 208
    },
    {
      "name": "Arrakis",
      "one_line_profile": "Library to conduct, track and visualize mechanistic interpretability experiments",
      "detailed_description": "A library designed for mechanistic interpretability research, providing tools to conduct, track, and visualize experiments aimed at reverse-engineering neural network behaviors.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "mechanistic_interpretability",
        "experiment_tracking"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/yash-srivastava19/arrakis",
      "help_website": [],
      "license": null,
      "tags": [
        "mechanistic-interpretability",
        "visualization",
        "neural-networks"
      ],
      "id": 209
    },
    {
      "name": "WeightedSHAP",
      "one_line_profile": "Analyzing and improving Shapley based feature attributions",
      "detailed_description": "Implementation of WeightedSHAP (NeurIPS 2022), a method for analyzing and improving the reliability of Shapley-based feature attribution methods in machine learning.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "feature_attribution",
        "shapley_values"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ykwon0407/WeightedSHAP",
      "help_website": [],
      "license": null,
      "tags": [
        "shapley-values",
        "feature-attribution",
        "xai"
      ],
      "id": 210
    },
    {
      "name": "fast_dist_shapley",
      "one_line_profile": "Efficient Computation and Analysis of Distributional Shapley Values",
      "detailed_description": "Code for efficient computation and analysis of Distributional Shapley Values (AISTATS 2021), enabling faster estimation of feature importance in distributional settings.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "feature_attribution",
        "shapley_values"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ykwon0407/fast_dist_shapley",
      "help_website": [],
      "license": null,
      "tags": [
        "shapley-values",
        "distributional-analysis",
        "efficiency"
      ],
      "id": 211
    },
    {
      "name": "convnet-drawer",
      "one_line_profile": "Script for illustrating Convolutional Neural Networks using Keras-like definitions",
      "detailed_description": "A Python script that generates illustrations of Convolutional Neural Network (CNN) architectures using Keras-like model definitions, useful for visualizing and documenting model structures.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "network_visualization",
        "architecture_diagram"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yu4u/convnet-drawer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "cnn",
        "keras"
      ],
      "id": 212
    },
    {
      "name": "3D-Human-Body-Shape",
      "one_line_profile": "3D Human Body Reshaping with Anthropometric Modeling",
      "detailed_description": "Implementation of a method for 3D human body reshaping based on anthropometric modeling, allowing for the manipulation and analysis of 3D body shapes.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "3d_modeling",
        "anthropometry"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zengyh1900/3D-Human-Body-Shape",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "3d-reconstruction",
        "human-body",
        "modeling"
      ],
      "id": 213
    },
    {
      "name": "RAW2RGB-GAN",
      "one_line_profile": "Saliency map-aided GAN for Auto-demosaic+denosing",
      "detailed_description": "A PyTorch implementation of a Generative Adversarial Network (GAN) that uses saliency maps to aid in the joint task of demosaicing and denoising RAW images.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "image_restoration",
        "saliency_guided_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhaoyuzhi/RAW2RGB-GAN",
      "help_website": [],
      "license": null,
      "tags": [
        "gan",
        "image-processing",
        "saliency"
      ],
      "id": 214
    },
    {
      "name": "SCGAN",
      "one_line_profile": "Saliency-map Guided Colorization with Generative Adversarial Network",
      "detailed_description": "Implementation of SCGAN (IEEE TCSVT 2020), a method for image colorization that leverages saliency maps to guide the generation process for more realistic results.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "image_colorization",
        "saliency_guided_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhaoyuzhi/Semantic-Colorization-GAN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gan",
        "colorization",
        "saliency"
      ],
      "id": 215
    },
    {
      "name": "cnnvisualizer",
      "one_line_profile": "Visualization tool for inspecting internal activations of Deep Neural Networks",
      "detailed_description": "A toolkit designed to visualize and diagnose Deep Neural Networks (DNNs) by displaying the activation maps of network layers. It helps researchers understand the features learned by CNNs, supporting model interpretability and debugging in scientific deep learning applications.",
      "domains": [
        "X1",
        "X1-04"
      ],
      "subtask_category": [
        "model_interpretation",
        "scientific_visualization"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/zhoubolei/cnnvisualizer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "cnn",
        "interpretability",
        "deep-learning"
      ],
      "id": 216
    }
  ]
}