{
  "generated_at": "2025-12-16T05:36:29.133362+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "D2",
      "leaf_cluster_name": "科研工作流生态（Nextflow/Snakemake等）",
      "domain": "Data/Workflow",
      "typical_objects": "pipelines",
      "task_chain": "组件→组合→执行→测试→复现",
      "tool_form": "workflow engine + modules"
    },
    "unit": {
      "unit_id": "D2-01",
      "unit_name": "工作流引擎与执行后端",
      "target_scale": "200–450",
      "coverage_tools": "engines、executors"
    },
    "search": {
      "target_candidates": 450,
      "queries": [
        "[GH] MiniWDL",
        "[GH] Galaxy",
        "[GH] Prefect",
        "[GH] Luigi",
        "[GH] Toil",
        "[GH] Argo Workflows",
        "[GH] Airflow",
        "[GH] Cromwell",
        "[GH] Snakemake",
        "[GH] Nextflow",
        "[GH] workflow engine",
        "[GH] pipeline orchestrator",
        "[GH] task scheduler",
        "[GH] DAG execution",
        "[GH] Common Workflow Language",
        "[GH] Workflow Description Language",
        "[GH] distributed computing framework",
        "[GH] HPC job submission",
        "[GH] cloud batch execution",
        "[GH] reproducible research pipeline",
        "[GH] scientific workflow system",
        "[GH] container orchestration",
        "[GH] workflow management system",
        "[WEB] awesome scientific workflow engines github",
        "[WEB] Nextflow pipeline orchestration github",
        "[WEB] Snakemake workflow management github",
        "[WEB] WDL execution engine github",
        "[WEB] CWL runner implementation github",
        "[WEB] Kubernetes native workflow github"
      ],
      "total_candidates": 1251,
      "tool_candidates": 939,
      "final_tools": 213
    }
  },
  "tools": [
    {
      "name": "4DN CWL Pipelines",
      "one_line_profile": "Collection of genomic processing pipelines in Common Workflow Language",
      "detailed_description": "A repository containing the Common Workflow Language (CWL) pipeline definitions used by the 4D Nucleome Data Coordination and Integration Center (4DN-DCIC) for genomic data processing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genomics_pipeline",
        "workflow_definition"
      ],
      "application_level": "workflow",
      "primary_language": "Common Workflow Language",
      "repo_url": "https://github.com/4dn-dcic/pipelines-cwl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cwl",
        "genomics",
        "bioinformatics",
        "pipeline"
      ],
      "id": 1
    },
    {
      "name": "Tibanna",
      "one_line_profile": "Execution engine for running genomic pipelines on AWS",
      "detailed_description": "Tibanna is a software tool that deploys and manages the execution of genomic pipelines (CWL/WDL/Snakemake) on Amazon Web Services (AWS), specifically designed for the 4D Nucleome project.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "cloud_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/4dn-dcic/tibanna",
      "help_website": [
        "https://tibanna.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "aws",
        "genomics",
        "workflow-engine",
        "cwl",
        "wdl"
      ],
      "id": 2
    },
    {
      "name": "DAGEE",
      "one_line_profile": "Directed Acyclic Graph Execution Engine for heterogeneous computing",
      "detailed_description": "A C++ library developed by AMD Research that enables the expression of computation and data movement as task graphs, scheduled concurrently and asynchronously on CPUs and GPUs for high-performance scientific computing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "task_scheduling",
        "parallel_computing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/AMDResearch/DAGEE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hpc",
        "gpu",
        "task-graph",
        "amd"
      ],
      "id": 3
    },
    {
      "name": "APPIAN",
      "one_line_profile": "Automated pipeline for PET/MRI image analysis",
      "detailed_description": "An open-source automated software pipeline designed for analyzing PET images in conjunction with MRI, facilitating tracer kinetic data analysis and reproducible medical imaging research.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "medical_imaging",
        "image_analysis",
        "pet_mri"
      ],
      "application_level": "workflow",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/APPIAN-PET/APPIAN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "neuroimaging",
        "pet",
        "mri",
        "pipeline"
      ],
      "id": 4
    },
    {
      "name": "toil-rnaseq",
      "one_line_profile": "Scalable RNA-seq analysis pipeline based on Toil",
      "detailed_description": "A comprehensive RNA-seq analysis pipeline developed by the UC Santa Cruz Computational Genomics Lab, built on the Toil workflow engine for scalability across cloud and local environments.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "rna_seq",
        "genomics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/BD2KGenomics/toil-rnaseq",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rna-seq",
        "bioinformatics",
        "toil",
        "pipeline"
      ],
      "id": 5
    },
    {
      "name": "toil-scripts",
      "one_line_profile": "Collection of genomic workflows for Toil",
      "detailed_description": "A repository containing various genomic pipelines and workflows (e.g., exome variant calling) implemented to run on the Toil workflow engine.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "genomics_pipeline",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/BD2KGenomics/toil-scripts",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "genomics",
        "bioinformatics",
        "toil"
      ],
      "id": 6
    },
    {
      "name": "GridBee Framework",
      "one_line_profile": "Browser-based distributed computing framework for BOINC",
      "detailed_description": "A JavaScript framework that enables web browsers to participate in volunteer distributed computing projects by communicating with BOINC servers, facilitating citizen science.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "distributed_computing",
        "volunteer_computing"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/BME-IK/gridbee-framework",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "boinc",
        "distributed-computing",
        "citizen-science"
      ],
      "id": 7
    },
    {
      "name": "iSkyLIMS",
      "one_line_profile": "LIMS for NGS sample and bioinformatics management",
      "detailed_description": "An open-source Laboratory Information Management System (LIMS) specifically designed for Next Generation Sequencing (NGS) centers to manage samples, wet-lab workflows, and bioinformatics analysis services.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "lab_management",
        "sample_tracking",
        "bioinformatics_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/BU-ISCIII/iskylims",
      "help_website": [
        "http://iskylims.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "lims",
        "ngs",
        "bioinformatics",
        "lab-management"
      ],
      "id": 8
    },
    {
      "name": "Cromwell Frontend",
      "one_line_profile": "Web interface for Cromwell workflow engine",
      "detailed_description": "A web-based frontend for the Cromwell job server, providing authentication and management capabilities for scientific workflow definitions and executions.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "job_monitoring"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/BiRG/cromwell-frontend",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cromwell",
        "workflow-gui",
        "bioinformatics"
      ],
      "id": 9
    },
    {
      "name": "CWL.jl",
      "one_line_profile": "Julia interface for Common Workflow Language",
      "detailed_description": "A Julia package providing utilities for working with the Common Workflow Language (CWL), enabling Julia-based scientific workflows to interact with the CWL ecosystem.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_definition",
        "interoperability"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/BioJulia/CWL.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "cwl",
        "bioinformatics",
        "workflow"
      ],
      "id": 10
    },
    {
      "name": "CmdParser",
      "one_line_profile": "Command line parser and CWL creator",
      "detailed_description": "A C++ tool designed to parse command line arguments and automatically generate or read Common Workflow Language (CWL) specifications, facilitating the integration of command-line tools into scientific workflows.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_generation",
        "tool_wrapping"
      ],
      "application_level": "tool",
      "primary_language": "C++",
      "repo_url": "https://github.com/CBICA/CmdParser",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "cwl",
        "cli",
        "workflow-automation"
      ],
      "id": 11
    },
    {
      "name": "CalliNGS-NF",
      "one_line_profile": "Nextflow pipeline for GATK RNA-Seq variant calling",
      "detailed_description": "A Nextflow pipeline implementing the GATK Best Practices for RNA-Seq variant calling, developed by CRG-CNAG for reproducible genomic analysis.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "variant_calling",
        "rna_seq",
        "genomics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/CRG-CNAG/CalliNGS-NF",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "nextflow",
        "gatk",
        "rna-seq",
        "bioinformatics"
      ],
      "id": 12
    },
    {
      "name": "ClarityNLP",
      "one_line_profile": "NLP framework for clinical phenotyping",
      "detailed_description": "A Natural Language Processing framework specifically designed for extracting clinical phenotypes from medical notes and reports, supporting healthcare research and data analysis.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "clinical_nlp",
        "phenotyping",
        "text_mining"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ClarityNLP/ClarityNLP",
      "help_website": [
        "http://claritynlp.readthedocs.io/en/latest/"
      ],
      "license": "MPL-2.0",
      "tags": [
        "nlp",
        "clinical-informatics",
        "phenotyping",
        "healthcare"
      ],
      "id": 13
    },
    {
      "name": "FogBus2",
      "one_line_profile": "Distributed framework for IoT-Edge-Cloud integration",
      "detailed_description": "A lightweight and distributed container-based framework designed for research in integrating IoT systems with Edge and Cloud computing environments, facilitating experimental evaluation of distributed architectures.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "distributed_computing",
        "edge_computing",
        "iot_simulation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Cloudslab/FogBus2",
      "help_website": [],
      "license": null,
      "tags": [
        "edge-computing",
        "iot",
        "distributed-systems",
        "research-framework"
      ],
      "id": 14
    },
    {
      "name": "ChIPseq_workflows",
      "one_line_profile": "CWL workflows for ChIP-seq and Cut&Run analysis",
      "detailed_description": "A collection of Common Workflow Language (CWL) workflows for processing ChIP-seq, ChIPmentation, and Cut&Run sequencing data, maintained by the Computational Epigenetics group.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "chip_seq",
        "epigenetics",
        "genomics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Common Workflow Language",
      "repo_url": "https://github.com/CompEpigen/ChIPseq_workflows",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "cwl",
        "chip-seq",
        "epigenetics",
        "bioinformatics"
      ],
      "id": 15
    },
    {
      "name": "Toil",
      "one_line_profile": "Scalable workflow engine for CWL, WDL and Python pipelines",
      "detailed_description": "A scalable, efficient, cross-platform workflow engine that supports Common Workflow Language (CWL), Workflow Description Language (WDL), and Python workflow definitions, widely used in genomic data processing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "pipeline_orchestration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DataBiosphere/toil",
      "help_website": [
        "https://toil.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "cwl",
        "wdl",
        "bioinformatics",
        "cloud-computing"
      ],
      "id": 16
    },
    {
      "name": "fold_tree",
      "one_line_profile": "Snakemake pipeline for creating phylogenetic trees from sequence sets",
      "detailed_description": "A Snakemake workflow designed to automate the generation of phylogenetic trees from sets of biological sequences, facilitating evolutionary analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "phylogenetics",
        "tree_building"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/DessimozLab/fold_tree",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "phylogenetics",
        "bioinformatics"
      ],
      "id": 17
    },
    {
      "name": "VIRify",
      "one_line_profile": "Pipeline for detection of phages and eukaryotic viruses from metagenomic assemblies",
      "detailed_description": "A bioinformatics pipeline developed by EBI for identifying viral signals (phages and eukaryotic viruses) in metagenomic and metatranscriptomic assembly data.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "metagenomics",
        "viral_detection"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/EBI-Metagenomics/emg-viral-pipeline",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "metagenomics",
        "virus",
        "bioinformatics"
      ],
      "id": 18
    },
    {
      "name": "REAT",
      "one_line_profile": "Robust Eukaryotic Annotation Toolkit for genome annotation",
      "detailed_description": "A toolkit designed to improve the robustness and accuracy of eukaryotic genome annotation, developed by the Earlham Institute.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genome_annotation",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/EI-CoreBioinformatics/reat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "annotation",
        "genomics",
        "eukaryotic"
      ],
      "id": 19
    },
    {
      "name": "Caper",
      "one_line_profile": "Python wrapper for Cromwell workflow engine to simplify cloud/HPC execution",
      "detailed_description": "A wrapper tool for the Cromwell workflow engine (WDL) that simplifies the configuration and execution of pipelines on various backends including Google Cloud and HPC clusters, widely used in the ENCODE project.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "pipeline_execution"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ENCODE-DCC/caper",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cromwell",
        "wdl",
        "workflow-management"
      ],
      "id": 20
    },
    {
      "name": "Croo",
      "one_line_profile": "Output organizer for Cromwell workflows",
      "detailed_description": "A utility tool designed to organize and manage the output files generated by Cromwell workflows, facilitating data management in large-scale genomic analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_utility",
        "data_organization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ENCODE-DCC/croo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cromwell",
        "workflow",
        "utility"
      ],
      "id": 21
    },
    {
      "name": "MAG_Snakemake_wf",
      "one_line_profile": "Pipeline for recovery of prokaryotic genomes from shotgun metagenomic data",
      "detailed_description": "A Snakemake workflow for the recovery of Metagenome-Assembled Genomes (MAGs) from shotgun sequencing data, automating assembly and binning steps.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "metagenomics",
        "genome_assembly"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/Finn-Lab/MAG_Snakemake_wf",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "snakemake",
        "metagenomics",
        "mag"
      ],
      "id": 22
    },
    {
      "name": "GalSim",
      "one_line_profile": "Modular galaxy image simulation toolkit for astronomy",
      "detailed_description": "A software library for simulating images of galaxies and stars, widely used in the weak lensing community for testing measurement algorithms.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "simulation",
        "astronomy"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/GalSim-developers/GalSim",
      "help_website": [
        "https://galsim-developers.github.io/GalSim/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "astronomy",
        "simulation",
        "image-processing"
      ],
      "id": 23
    },
    {
      "name": "sv-callers",
      "one_line_profile": "Snakemake workflow for detecting structural variants in genomic data",
      "detailed_description": "A comprehensive Snakemake-based workflow that integrates multiple structural variant calling tools for genomic data analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "variant_calling",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/GooglingTheCancerGenome/sv-callers",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "snakemake",
        "structural-variants",
        "genomics"
      ],
      "id": 24
    },
    {
      "name": "dropSeqPipe",
      "one_line_profile": "Snakemake workflow for SingleCell RNASeq pre-processing",
      "detailed_description": "A pipeline for processing Drop-Seq data, handling steps from raw reads to expression matrices, implemented using Snakemake.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "scRNA-seq",
        "preprocessing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Hoohm/dropSeqPipe",
      "help_website": [],
      "license": "CC-BY-SA-4.0",
      "tags": [
        "snakemake",
        "rnaseq",
        "single-cell"
      ],
      "id": 25
    },
    {
      "name": "HyperQueue",
      "one_line_profile": "Efficient sub-node task scheduler for HPC systems",
      "detailed_description": "A task scheduler designed for High Performance Computing (HPC) environments to efficiently execute a large number of sub-node tasks, reducing overhead on clusters like Slurm or PBS.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "task_scheduling",
        "hpc"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/It4innovations/hyperqueue",
      "help_website": [
        "https://it4innovations.github.io/hyperqueue/"
      ],
      "license": "MIT",
      "tags": [
        "hpc",
        "scheduler",
        "rust"
      ],
      "id": 26
    },
    {
      "name": "Dagger.jl",
      "one_line_profile": "Framework for out-of-core and parallel execution in Julia",
      "detailed_description": "A Julia library for parallel and out-of-core computing, enabling scalable scientific calculations by constructing and executing dynamic task graphs.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "parallel_computing",
        "scientific_computing"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaParallel/Dagger.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "julia",
        "parallel-computing",
        "dag"
      ],
      "id": 27
    },
    {
      "name": "pytest-workflow",
      "one_line_profile": "Test framework for scientific workflows/pipelines (Nextflow, Snakemake, etc.)",
      "detailed_description": "A pytest plugin designed to test scientific workflows (like Nextflow, Snakemake, WDL) by running them and validating the output files against expected results.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pipeline_testing",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/LUMC/pytest-workflow",
      "help_website": [
        "https://pytest-workflow.readthedocs.io/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "testing",
        "workflow",
        "bioinformatics",
        "pipeline-validation"
      ],
      "id": 28
    },
    {
      "name": "LuigiNLP",
      "one_line_profile": "Workflow system specifically designed for Natural Language Processing",
      "detailed_description": "A workflow system built on top of Luigi, providing specific functionality and abstractions for constructing and managing Natural Language Processing (NLP) pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "nlp_workflow",
        "text_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/LanguageMachines/LuigiNLP",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "nlp",
        "workflow",
        "luigi",
        "pipeline"
      ],
      "id": 29
    },
    {
      "name": "AWE",
      "one_line_profile": "Workflow and resource management system for bioinformatics",
      "detailed_description": "AWE (Shock) is a workflow and resource management system designed for scalable bioinformatics data analysis, often used in conjunction with MG-RAST.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "resource_scheduling"
      ],
      "application_level": "workflow",
      "primary_language": "Go",
      "repo_url": "https://github.com/MG-RAST/AWE",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "bioinformatics",
        "workflow-engine",
        "distributed-computing"
      ],
      "id": 30
    },
    {
      "name": "pgsc_calc",
      "one_line_profile": "Nextflow pipeline for polygenic score calculation",
      "detailed_description": "A reproducible Nextflow pipeline for calculating polygenic scores (PGS) from genomic data, integrating with the PGS Catalog.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "polygenic_score_calculation",
        "genomic_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/PGScatalog/pgsc_calc",
      "help_website": [
        "https://pgsc-calc.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nextflow",
        "bioinformatics",
        "genomics",
        "polygenic-scores"
      ],
      "id": 31
    },
    {
      "name": "HiFi-16S-workflow",
      "one_line_profile": "Nextflow pipeline for PacBio HiFi 16S rRNA analysis",
      "detailed_description": "A bioinformatics pipeline built with Nextflow for analyzing full-length 16S rRNA sequencing data generated by PacBio HiFi technology.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "16s_analysis",
        "metagenomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/PacificBiosciences/HiFi-16S-workflow",
      "help_website": [],
      "license": "BSD-3-Clause-Clear",
      "tags": [
        "nextflow",
        "pacbio",
        "16s",
        "microbiome"
      ],
      "id": 32
    },
    {
      "name": "PyPSA-Eur",
      "one_line_profile": "Sector-coupled open optimisation model of the European energy system",
      "detailed_description": "PyPSA-Eur is an open optimization model of the European energy system that includes electricity, transport, and heat sectors. It uses the PyPSA library to model and optimize energy flows, generation, and transmission across Europe.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "energy_modeling",
        "optimization",
        "simulation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/PyPSA/pypsa-eur",
      "help_website": [
        "https://pypsa-eur.readthedocs.io"
      ],
      "license": null,
      "tags": [
        "energy-system",
        "optimization",
        "pypsa",
        "simulation"
      ],
      "id": 33
    },
    {
      "name": "VesselExpress",
      "one_line_profile": "Automated analysis pipeline for 3D light-sheet images of blood vasculature",
      "detailed_description": "VesselExpress is a tool for the automated analysis of blood vasculature in 3D light-sheet image volumes. It performs segmentation, skeletonization, and quantitative analysis of vascular networks.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "image_analysis",
        "segmentation",
        "quantification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RUB-Bioinf/VesselExpress",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bioimage-analysis",
        "vasculature",
        "light-sheet-microscopy",
        "3d-imaging"
      ],
      "id": 34
    },
    {
      "name": "reticulatus",
      "one_line_profile": "Snakemake-based pipeline for assembling and polishing long genomes",
      "detailed_description": "Reticulatus is a bioinformatics pipeline built with Snakemake for assembling and polishing genomes using long nanopore reads. It automates the workflow from raw reads to polished assemblies.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genome_assembly",
        "polishing",
        "workflow"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/SamStudio8/reticulatus",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "nanopore",
        "genomics",
        "assembly"
      ],
      "id": 35
    },
    {
      "name": "QA-Board",
      "one_line_profile": "Experiment tracker and visualization platform for algorithm R&D",
      "detailed_description": "QA-Board is an experiment tracking tool designed for algorithm and performance R&D. It allows researchers to organize, visualize, compare, and share runs, specifically targeting tuning and optimization in scientific/engineering contexts.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "experiment_tracking",
        "visualization",
        "performance_analysis"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/Samsung/qaboard",
      "help_website": [
        "https://samsung.github.io/qaboard/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "experiment-tracking",
        "r-and-d",
        "visualization",
        "tuning"
      ],
      "id": 36
    },
    {
      "name": "Proteus",
      "one_line_profile": "Transpiler for converting Common Workflow Language (CWL) to Argo Workflows",
      "detailed_description": "Proteus is a utility that transpiles Common Workflow Language (CWL) definitions into Argo Workflow syntax, facilitating the execution of standard scientific workflows on Kubernetes-based Argo clusters.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_conversion",
        "pipeline_management"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/SerRichard/proteus",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "cwl",
        "argo-workflows",
        "transpiler",
        "scientific-workflow"
      ],
      "id": 37
    },
    {
      "name": "ACES",
      "one_line_profile": "Workflow for querying small sequences in large genomes with phylogenetic analysis",
      "detailed_description": "ACES is a bioinformatics workflow designed to query small sequences within a large set of genomes. It produces BLAST results, multiple sequence alignments, fragment assemblies, and phylogenetic trees.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "sequence_alignment",
        "phylogenetic_analysis",
        "assembly"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/TNTurnerLab/ACES",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "genomics",
        "phylogeny",
        "blast",
        "alignment"
      ],
      "id": 38
    },
    {
      "name": "Timefold Solver",
      "one_line_profile": "AI constraint solver for optimizing planning and scheduling problems",
      "detailed_description": "Timefold Solver is an open-source constraint satisfaction solver that optimizes complex planning and scheduling problems (e.g., vehicle routing, rostering) using AI algorithms. It is applicable to operations research and scientific optimization tasks.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "optimization",
        "scheduling",
        "planning"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/TimefoldAI/timefold-solver",
      "help_website": [
        "https://timefold.ai/docs/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "optimization",
        "solver",
        "operations-research",
        "constraint-satisfaction"
      ],
      "id": 39
    },
    {
      "name": "AkôFlow",
      "one_line_profile": "Middleware for orchestrating container-based scientific workflows",
      "detailed_description": "AkôFlow is a middleware designed for orchestrating and executing container-based scientific workflows across heterogeneous environments. It focuses on the specific needs of scientific computing and reproducibility.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "execution_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/UFFeScience/akoflow",
      "help_website": [],
      "license": null,
      "tags": [
        "scientific-workflow",
        "orchestration",
        "containers",
        "middleware"
      ],
      "id": 40
    },
    {
      "name": "snk",
      "one_line_profile": "CLI generation tool for Snakemake workflows",
      "detailed_description": "Snk is a tool that automatically generates a Command Line Interface (CLI) for Snakemake workflows, making scientific pipelines easier to distribute and execute as standalone applications.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "cli_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Wytamma/snk",
      "help_website": [
        "https://snk.wytamma.com"
      ],
      "license": "MIT",
      "tags": [
        "snakemake",
        "cli",
        "workflow",
        "reproducibility"
      ],
      "id": 41
    },
    {
      "name": "Oozie",
      "one_line_profile": "Workflow scheduler system to manage Apache Hadoop jobs",
      "detailed_description": "Oozie is a workflow scheduler system to manage Apache Hadoop jobs. It allows users to define actions (such as MapReduce, Spark, Hive, Pig) in a Directed Acyclic Graph (DAG) and orchestrate their execution. While primarily a big data tool, it is widely used in scientific data engineering pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "job_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/YahooArchive/oozie",
      "help_website": [
        "http://oozie.apache.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "hadoop",
        "scheduler",
        "etl"
      ],
      "id": 42
    },
    {
      "name": "yawn",
      "one_line_profile": "Lightweight subprocess-based DAG execution system",
      "detailed_description": "Yawn (Yet Another Workflow Engine) is a lightweight workflow engine designed to execute Directed Acyclic Graphs (DAGs) of subprocesses. It provides a simple PostgreSQL-backed queue and execution system for managing dependent tasks.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "task_execution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aclowes/yawn",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "workflow-engine",
        "dag",
        "python",
        "task-scheduler"
      ],
      "id": 43
    },
    {
      "name": "Wexflow",
      "one_line_profile": "Extensible workflow automation engine with a cross-platform backend",
      "detailed_description": "Wexflow is a high-performance, extensible workflow automation engine. It allows users to design and execute complex workflows involving file processing, database operations, and system interactions. It supports a wide range of tasks and provides a backend for orchestration.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_automation",
        "process_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "C#",
      "repo_url": "https://github.com/aelassas/wexflow",
      "help_website": [
        "https://wexflow.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "workflow-engine",
        "automation",
        "c-sharp",
        "etl"
      ],
      "id": 44
    },
    {
      "name": "BindFlow",
      "one_line_profile": "Snakemake workflow for FEP and MM(PB/GB)SA calculations with GROMACS",
      "detailed_description": "BindFlow is a scientific workflow built on Snakemake for automating Free Energy Perturbation (FEP) and Molecular Mechanics Poisson-Boltzmann/Generalized Born Surface Area (MM/PBSA, MM/GBSA) calculations using GROMACS. It streamlines molecular dynamics simulation analysis.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "molecular_dynamics",
        "free_energy_calculation",
        "workflow_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ale94mleon/BindFlow",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "snakemake",
        "gromacs",
        "molecular-dynamics",
        "bioinformatics"
      ],
      "id": 45
    },
    {
      "name": "Table-Computing",
      "one_line_profile": "High-performance distributed computing framework for relational operations",
      "detailed_description": "Table-Computing (TC) is a high-performance, low-latency distributed computing framework designed to handle complicated use cases faster than Flink. It focuses on relational operations and provides a lightweight, distributed engine for data processing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "distributed_computing",
        "data_processing"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/alibaba/table-computing",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-computing",
        "data-processing",
        "framework"
      ],
      "id": 46
    },
    {
      "name": "DependsWorkflow",
      "one_line_profile": "Workflow management system for dependency-based task execution",
      "detailed_description": "DependsWorkflow is a workflow management system designed to handle task dependencies and execution. It provides a framework for defining and running computational workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "task_execution"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/andrew-gardner/dependsworkflow",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "workflow-management",
        "python",
        "pipeline"
      ],
      "id": 47
    },
    {
      "name": "FedERA",
      "one_line_profile": "Modular and customizable Federated Learning framework",
      "detailed_description": "FedERA is an open-source Federated Learning (FL) framework designed for heterogeneous edge devices. It supports both standalone and distributed computing, enabling the orchestration of training workflows across decentralized data sources, which is critical for privacy-preserving scientific modeling.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "federated_learning",
        "distributed_training",
        "model_orchestration"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/anupamkliv/FedERA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "federated-learning",
        "distributed-computing",
        "edge-computing"
      ],
      "id": 48
    },
    {
      "name": "Apache Airflow",
      "one_line_profile": "Platform to programmatically author, schedule, and monitor workflows",
      "detailed_description": "Apache Airflow is a platform to programmatically author, schedule, and monitor workflows. It allows users to define workflows as code (DAGs), providing a rich user interface to visualize pipelines, monitor progress, and troubleshoot issues. It is a standard tool for orchestrating scientific and data engineering pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "pipeline_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/apache/airflow",
      "help_website": [
        "https://airflow.apache.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "orchestration",
        "python",
        "dag"
      ],
      "id": 49
    },
    {
      "name": "Auron",
      "one_line_profile": "Accelerator for distributed computing frameworks leveraging vectorized execution",
      "detailed_description": "Auron is an accelerator for distributed computing frameworks (like Apache Spark) that leverages native vectorized execution to speed up query processing and data transformation tasks. It enhances the performance of data-intensive scientific workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "data_processing_acceleration",
        "vectorized_execution"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/apache/auron",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "spark-accelerator",
        "distributed-computing",
        "rust",
        "performance"
      ],
      "id": 50
    },
    {
      "name": "ccwl",
      "one_line_profile": "Compiler for Concise Common Workflow Language (CWL)",
      "detailed_description": "A compiler and toolchain for a concise dialect of the Common Workflow Language (CWL), designed to simplify the creation of scientific workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_compilation",
        "pipeline_definition"
      ],
      "application_level": "solver",
      "primary_language": "Scheme",
      "repo_url": "https://github.com/arunisaac/ccwl",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "cwl",
        "workflow",
        "bioinformatics",
        "compiler"
      ],
      "id": 51
    },
    {
      "name": "nf-test",
      "one_line_profile": "Testing framework for Nextflow pipelines",
      "detailed_description": "A simple and powerful testing framework specifically designed for Nextflow pipelines, enabling developers to write and run tests for scientific workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_testing",
        "pipeline_validation"
      ],
      "application_level": "workflow",
      "primary_language": "Java",
      "repo_url": "https://github.com/askimed/nf-test",
      "help_website": [
        "https://www.nf-test.com"
      ],
      "license": "MIT",
      "tags": [
        "nextflow",
        "testing",
        "bioinformatics",
        "pipeline"
      ],
      "id": 52
    },
    {
      "name": "FlowCraft",
      "one_line_profile": "Component-based pipeline composer for omics analysis",
      "detailed_description": "A tool to build Nextflow pipelines for omics analysis by assembling pre-defined components, facilitating the creation of reproducible bioinformatics workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pipeline_composition",
        "omics_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/assemblerflow/flowcraft",
      "help_website": [
        "https://flowcraft.readthedocs.io"
      ],
      "license": "GPL-3.0",
      "tags": [
        "nextflow",
        "omics",
        "bioinformatics",
        "pipeline-builder"
      ],
      "id": 53
    },
    {
      "name": "Bactopia",
      "one_line_profile": "Flexible pipeline for complete analysis of bacterial genomes",
      "detailed_description": "A comprehensive and flexible workflow for bacterial genome analysis, integrating numerous bioinformatics tools for QC, assembly, annotation, and variant calling.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genome_analysis",
        "bacterial_genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/bactopia/bactopia",
      "help_website": [
        "https://bactopia.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "bacteria",
        "genomics",
        "nextflow"
      ],
      "id": 54
    },
    {
      "name": "Snaketool",
      "one_line_profile": "Cookiecutter profile for creating Snakemake-based bioinformatics tools",
      "detailed_description": "A scaffolding tool that helps researchers and developers create standardized, reproducible bioinformatics pipelines using Snakemake.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pipeline_development",
        "workflow_scaffolding"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/beardymcjohnface/Snaketool",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "bioinformatics",
        "cookiecutter",
        "reproducibility"
      ],
      "id": 55
    },
    {
      "name": "docker-galaxy",
      "one_line_profile": "Dockerized deployment for the Galaxy scientific workflow platform",
      "detailed_description": "A collection of Docker images designed to deploy and manage stable releases of the Galaxy bioinformatics platform, facilitating reproducible scientific workflow execution.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_deployment",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/bgruening/docker-galaxy",
      "help_website": [
        "https://github.com/bgruening/docker-galaxy"
      ],
      "license": "MIT",
      "tags": [
        "galaxy",
        "docker",
        "bioinformatics",
        "workflow"
      ],
      "id": 56
    },
    {
      "name": "kraken2_classification",
      "one_line_profile": "Snakemake workflow for metagenomic classification using Kraken2",
      "detailed_description": "A Snakemake-based pipeline designed for metagenomic classification tasks, automating the execution of Kraken2 for taxonomic sequence classification.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "metagenomics",
        "taxonomic_classification"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bhattlab/kraken2_classification",
      "help_website": [
        "https://github.com/bhattlab/kraken2_classification"
      ],
      "license": null,
      "tags": [
        "snakemake",
        "metagenomics",
        "kraken2",
        "bioinformatics"
      ],
      "id": 57
    },
    {
      "name": "ABFE_workflow",
      "one_line_profile": "Snakemake workflow for Absolute Binding Free Energy calculations",
      "detailed_description": "A scalable Snakemake workflow designed for high-throughput Absolute Binding Free Energy (ABFE) calculations in computational chemistry, supporting Slurm execution.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "molecular_dynamics",
        "free_energy_calculation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bigginlab/ABFE_workflow",
      "help_website": [
        "https://github.com/bigginlab/ABFE_workflow"
      ],
      "license": "GPL-3.0",
      "tags": [
        "snakemake",
        "computational-chemistry",
        "abfe",
        "molecular-dynamics"
      ],
      "id": 58
    },
    {
      "name": "master_of_pores",
      "one_line_profile": "Nextflow pipeline for direct RNA Nanopore sequencing analysis",
      "detailed_description": "A Nextflow pipeline specifically designed for the analysis of direct RNA sequencing data from Nanopore devices, handling alignment, quality control, and modification detection.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "rna_seq_analysis",
        "nanopore_sequencing"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/biocorecrg/master_of_pores",
      "help_website": [
        "https://github.com/biocorecrg/master_of_pores"
      ],
      "license": "MIT",
      "tags": [
        "nextflow",
        "nanopore",
        "rna-seq",
        "bioinformatics"
      ],
      "id": 59
    },
    {
      "name": "cromshell",
      "one_line_profile": "CLI tool for interacting with the Cromwell workflow engine",
      "detailed_description": "A command-line interface for submitting workflows, checking status, and retrieving metadata from a Cromwell server, streamlining scientific workflow management.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "job_submission"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/broadinstitute/cromshell",
      "help_website": [
        "https://github.com/broadinstitute/cromshell"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "cromwell",
        "wdl",
        "cli",
        "workflow-management"
      ],
      "id": 60
    },
    {
      "name": "Cromwell",
      "one_line_profile": "Scientific workflow engine for WDL and CWL",
      "detailed_description": "A workflow management system designed to simplify the definition and execution of scientific workflows, supporting both WDL and CWL standards, scalable from local to cloud environments.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "pipeline_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Scala",
      "repo_url": "https://github.com/broadinstitute/cromwell",
      "help_website": [
        "https://cromwell.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "wdl",
        "cwl",
        "workflow-engine",
        "bioinformatics"
      ],
      "id": 61
    },
    {
      "name": "cromwell-tools",
      "one_line_profile": "Python client library for the Cromwell workflow engine",
      "detailed_description": "A collection of Python clients and utility scripts for interacting with the Cromwell workflow engine API, facilitating programmatic workflow submission and monitoring.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "api_client"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/broadinstitute/cromwell-tools",
      "help_website": [
        "https://github.com/broadinstitute/cromwell-tools"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "cromwell",
        "python",
        "api-client",
        "workflow"
      ],
      "id": 62
    },
    {
      "name": "wdl-ide",
      "one_line_profile": "IDE support tools for Workflow Description Language (WDL)",
      "detailed_description": "Provides rich IDE features such as syntax highlighting, code completion, and validation for developing scientific workflows in WDL.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_authoring",
        "code_development"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/broadinstitute/wdl-ide",
      "help_website": [
        "https://github.com/broadinstitute/wdl-ide"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "wdl",
        "ide",
        "workflow-development"
      ],
      "id": 63
    },
    {
      "name": "calkit",
      "one_line_profile": "Project management tool for reproducible research pipelines",
      "detailed_description": "A command-line tool that simplifies version control, environment management, and pipeline execution specifically for reproducible scientific research projects.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "reproducibility_management",
        "pipeline_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/calkit/calkit",
      "help_website": [
        "https://github.com/calkit/calkit"
      ],
      "license": "MIT",
      "tags": [
        "reproducibility",
        "research-management",
        "pipeline",
        "git"
      ],
      "id": 64
    },
    {
      "name": "V-pipe",
      "one_line_profile": "Bioinformatics pipeline for viral genome analysis",
      "detailed_description": "A workflow designed for the analysis of next-generation sequencing (NGS) data from short viral genomes, facilitating variant calling and viral diversity analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "viral_genomics",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/cbg-ethz/V-pipe",
      "help_website": [
        "https://cbg-ethz.github.io/V-pipe/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "bioinformatics",
        "virus",
        "ngs",
        "snakemake"
      ],
      "id": 65
    },
    {
      "name": "exelixi",
      "one_line_profile": "Distributed framework for genetic algorithms",
      "detailed_description": "A distributed computing framework based on Apache Mesos, designed to run genetic algorithms and other partitioned batch jobs at scale using Python.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genetic_algorithm",
        "optimization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ceteri/exelixi",
      "help_website": [
        "https://github.com/ceteri/exelixi"
      ],
      "license": "Apache-2.0",
      "tags": [
        "genetic-algorithm",
        "distributed-computing",
        "mesos",
        "optimization"
      ],
      "id": 66
    },
    {
      "name": "miniwdl",
      "one_line_profile": "Local runner and developer toolkit for WDL workflows",
      "detailed_description": "A local runner and developer toolkit for the Workflow Description Language (WDL), enabling rapid development, testing, and execution of scientific workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "workflow_development"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chanzuckerberg/miniwdl",
      "help_website": [
        "https://miniwdl.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "wdl",
        "workflow-runner",
        "bioinformatics",
        "developer-tools"
      ],
      "id": 67
    },
    {
      "name": "Gleam",
      "one_line_profile": "Fast, scalable distributed map/reduce system and DAG execution engine",
      "detailed_description": "Gleam is a high-performance distributed execution system written in Go. It provides a MapReduce-like framework and DAG execution capabilities, allowing for scalable data processing in memory or on disk, suitable for large-scale scientific data analysis pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "distributed_computing",
        "dag_execution"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/chrislusf/gleam",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mapreduce",
        "distributed-computing",
        "dag",
        "go"
      ],
      "id": 68
    },
    {
      "name": "Parabricks WDL",
      "one_line_profile": "Accelerated genomics workflows using NVIDIA Parabricks in WDL",
      "detailed_description": "A collection of Workflow Description Language (WDL) scripts for running NVIDIA Clara Parabricks pipelines. These workflows enable accelerated genomic analysis, including germline and somatic variant calling, on GPU-enabled infrastructure.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genomics_pipeline",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/clara-parabricks-workflows/parabricks-wdl",
      "help_website": [
        "https://docs.nvidia.com/clara/parabricks/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "genomics",
        "wdl",
        "gpu-acceleration",
        "bioinformatics"
      ],
      "id": 69
    },
    {
      "name": "ClearML",
      "one_line_profile": "Integrated MLOps platform for experiment management and orchestration",
      "detailed_description": "ClearML is an open-source MLOps platform that automates the tracking, orchestration, and management of machine learning experiments and pipelines. It provides tools for data management, remote execution, and model serving, facilitating reproducible AI for Science workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "experiment_tracking",
        "pipeline_orchestration",
        "mlops"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/clearml/clearml",
      "help_website": [
        "https://clear.ml/docs/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "experiment-tracking",
        "orchestration",
        "reproducibility"
      ],
      "id": 70
    },
    {
      "name": "ClearML Server",
      "one_line_profile": "Backend server for the ClearML MLOps platform",
      "detailed_description": "The backend infrastructure for ClearML, handling the storage, synchronization, and management of experiment data, model artifacts, and workflow orchestration logic. It serves as the central engine for self-hosted ClearML deployments.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "experiment_tracking",
        "pipeline_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/clearml/clearml-server",
      "help_website": [
        "https://clear.ml/docs/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "mlops",
        "backend",
        "server",
        "orchestration"
      ],
      "id": 71
    },
    {
      "name": "CompareM2",
      "one_line_profile": "Microbial genomes-to-report analysis pipeline",
      "detailed_description": "A comprehensive bioinformatics pipeline for processing microbial genomes. It automates the workflow from raw genomic data to final analytical reports, facilitating comparative genomics and quality assessment.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "microbial_genomics",
        "comparative_genomics",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/cmkobel/CompareM2",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "microbiology",
        "genomics",
        "pipeline",
        "snakemake"
      ],
      "id": 72
    },
    {
      "name": "cwldep",
      "one_line_profile": "Dependency manager for Common Workflow Language documents",
      "detailed_description": "A utility tool for managing dependencies within Common Workflow Language (CWL) projects. It allows users to define, install, and manage external CWL tools and workflow references, streamlining the development of complex scientific workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "dependency_management"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/common-workflow-language/cwldep",
      "help_website": [
        "https://www.commonwl.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "cwl",
        "dependency-manager",
        "workflow"
      ],
      "id": 73
    },
    {
      "name": "cwljava",
      "one_line_profile": "Java SDK for Common Workflow Language standards",
      "detailed_description": "A Java library providing support for the Common Workflow Language (CWL) standards. It enables Java applications to parse, validate, and interact with CWL workflow definitions, facilitating the integration of CWL into Java-based scientific tools.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_development",
        "interoperability"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/common-workflow-language/cwljava",
      "help_website": [
        "https://www.commonwl.org/"
      ],
      "license": null,
      "tags": [
        "cwl",
        "java",
        "sdk",
        "workflow"
      ],
      "id": 74
    },
    {
      "name": "cwltool",
      "one_line_profile": "Reference implementation of the Common Workflow Language",
      "detailed_description": "The official reference implementation for the Common Workflow Language (CWL). It serves as a portable workflow runner that can execute CWL descriptions for data analysis pipelines, ensuring compliance with the CWL standard.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "pipeline_runner"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/common-workflow-language/cwltool",
      "help_website": [
        "https://cwltool.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "cwl",
        "workflow-engine",
        "reproducibility",
        "bioinformatics"
      ],
      "id": 75
    },
    {
      "name": "CWL Viewer",
      "one_line_profile": "Web application to view and visualize CWL workflows",
      "detailed_description": "A visualization tool that generates graphical representations of Common Workflow Language (CWL) workflows. It helps researchers understand workflow structure, inputs, and outputs, aiding in the documentation and sharing of scientific pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_visualization",
        "documentation"
      ],
      "application_level": "service",
      "primary_language": "Java",
      "repo_url": "https://github.com/common-workflow-language/cwlviewer",
      "help_website": [
        "https://view.commonwl.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "cwl",
        "visualization",
        "workflow",
        "web-tool"
      ],
      "id": 76
    },
    {
      "name": "ncov2019-artic-nf",
      "one_line_profile": "Nextflow pipeline for SARS-CoV-2 ARTIC field bioinformatics",
      "detailed_description": "A Nextflow pipeline designed for the analysis of SARS-CoV-2 sequencing data using the ARTIC network protocols. It automates alignment, variant calling, and consensus sequence generation for viral genomics surveillance.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "viral_genomics",
        "variant_calling",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/connor-lab/ncov2019-artic-nf",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "covid-19",
        "nextflow",
        "bioinformatics",
        "artic-network"
      ],
      "id": 77
    },
    {
      "name": "Couler",
      "one_line_profile": "Unified interface for constructing workflows on Argo, Tekton, and Airflow",
      "detailed_description": "Couler provides a unified Python API for defining and managing workflows across different execution engines like Argo Workflows, Tekton, and Apache Airflow. It simplifies the creation of complex machine learning and data processing pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_definition",
        "pipeline_orchestration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/couler-proj/couler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "workflow",
        "argo",
        "tekton",
        "airflow",
        "mlops"
      ],
      "id": 78
    },
    {
      "name": "pyflow-ATACseq",
      "one_line_profile": "Snakemake pipeline for ATAC-seq data analysis",
      "detailed_description": "A Snakemake-based bioinformatics pipeline for processing ATAC-seq data. It handles steps from raw read processing to peak calling and quality control, enabling reproducible chromatin accessibility analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "epigenomics",
        "atac-seq",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/crazyhottommy/pyflow-ATACseq",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "atac-seq",
        "snakemake",
        "bioinformatics",
        "reproducibility"
      ],
      "id": 79
    },
    {
      "name": "pyflow-ChIPseq",
      "one_line_profile": "Snakemake pipeline for ChIP-seq data analysis",
      "detailed_description": "A Snakemake pipeline designed for ChIP-seq data processing. It automates alignment, peak calling, and quality control for chromatin immunoprecipitation sequencing data analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "epigenomics",
        "chip-seq",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/crazyhottommy/pyflow-ChIPseq",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chip-seq",
        "snakemake",
        "bioinformatics",
        "pipeline"
      ],
      "id": 80
    },
    {
      "name": "LLMCompiler",
      "one_line_profile": "Agent architecture for parallel execution of LLM tasks via DAGs",
      "detailed_description": "LLMCompiler is an agent framework that optimizes the execution of Large Language Model tasks by compiling them into a Directed Acyclic Graph (DAG). This enables parallel execution and reduces redundant token usage, enhancing the efficiency of complex AI workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "llm_orchestration",
        "agent_workflow",
        "parallel_execution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/crazyyanchao/llmcompiler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "agents",
        "dag",
        "optimization",
        "ai4s"
      ],
      "id": 81
    },
    {
      "name": "ARMOR",
      "one_line_profile": "Snakemake workflow for RNA-seq analysis and quality control",
      "detailed_description": "ARMOR (Automated Reproducible MOdular RNA-seq analysis) is a lightweight Snakemake workflow for preprocessing, quality control, and statistical analysis of RNA-seq data, integrating various standard bioinformatics tools.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "transcriptomics",
        "rna-seq",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/csoneson/ARMOR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rna-seq",
        "snakemake",
        "bioinformatics",
        "reproducibility"
      ],
      "id": 82
    },
    {
      "name": "ATLAS MCP Server",
      "one_line_profile": "Neo4j-powered task management system for LLM Agents",
      "detailed_description": "A Model Context Protocol (MCP) server that implements a three-tier architecture (Projects, Tasks, Knowledge) using Neo4j. It serves as a backend for managing complex workflows and state for LLM-based autonomous agents.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "knowledge_graph",
        "task_management"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/cyanheads/atlas-mcp-server",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-agent",
        "neo4j",
        "mcp",
        "workflow-management"
      ],
      "id": 83
    },
    {
      "name": "Cylc",
      "one_line_profile": "General purpose workflow engine specialized for cycling workflows",
      "detailed_description": "Cylc is a workflow engine designed for cycling systems, widely used in meteorology and climate science for weather forecasting and climate modeling pipelines. It handles complex dependencies and infinite cycling workflows efficiently.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "climate_modeling",
        "weather_forecasting",
        "workflow_scheduling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cylc/cylc-flow",
      "help_website": [
        "https://cylc.org/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "meteorology",
        "climate-science",
        "workflow-engine",
        "cycling"
      ],
      "id": 84
    },
    {
      "name": "SOFA",
      "one_line_profile": "Performance profiler for heterogeneous computing and distributed ML",
      "detailed_description": "SOFA is a cross-framework performance profiler designed for heterogeneous computing systems and distributed machine learning. It helps researchers analyze and optimize the performance of AI and scientific computing workloads.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "performance_profiling",
        "hpc_optimization",
        "distributed_ml"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/cyliustack/sofa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "profiling",
        "hpc",
        "distributed-ml",
        "performance"
      ],
      "id": 85
    },
    {
      "name": "Dagu",
      "one_line_profile": "Lightweight, self-contained DAG workflow engine",
      "detailed_description": "Dagu is a lightweight, single-binary workflow engine for executing Directed Acyclic Graphs (DAGs). It supports container execution and SSH commands, making it a portable solution for orchestrating data processing and scientific tasks in various environments.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "dag_execution"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/dagu-org/dagu",
      "help_website": [
        "https://dagu.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "workflow-engine",
        "dag",
        "scheduler",
        "go"
      ],
      "id": 86
    },
    {
      "name": "Dask",
      "one_line_profile": "Parallel computing library with task scheduling for analytics",
      "detailed_description": "Dask is a flexible library for parallel computing in Python. It provides advanced parallelism for analytics, enabling users to scale scientific computing workflows from a single laptop to a cluster, integrating seamlessly with NumPy, Pandas, and Scikit-Learn.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "parallel_computing",
        "distributed_analytics",
        "task_scheduling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask",
      "help_website": [
        "https://dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "parallel-computing",
        "distributed-systems",
        "python",
        "data-science"
      ],
      "id": 87
    },
    {
      "name": "Dask Distributed",
      "one_line_profile": "Distributed task scheduler for Dask",
      "detailed_description": "The distributed scheduler for Dask, providing a lightweight and robust engine for executing task graphs on distributed clusters. It manages the execution of Dask computations across multiple machines, essential for large-scale scientific data processing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "distributed_scheduling",
        "cluster_computing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/distributed",
      "help_website": [
        "https://distributed.dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "distributed-computing",
        "scheduler",
        "dask",
        "python"
      ],
      "id": 88
    },
    {
      "name": "DBND",
      "one_line_profile": "Agile pipeline framework for data engineering orchestration",
      "detailed_description": "DBND (Databand) is an orchestration and observability framework for data pipelines. It helps data engineering teams build, track, and monitor data workflows, ensuring reliability and visibility in scientific and ML data processing pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pipeline_orchestration",
        "data_observability",
        "workflow_tracking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/databand-ai/dbnd",
      "help_website": [
        "https://docs.databand.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-engineering",
        "orchestration",
        "observability",
        "pipeline"
      ],
      "id": 89
    },
    {
      "name": "HiCExplorer",
      "one_line_profile": "Set of tools to process, normalize and visualize Hi-C data",
      "detailed_description": "HiCExplorer is a powerful and easy to use set of tools to process, normalize and visualize Hi-C data. It facilitates the analysis of chromosome conformation capture data.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "data_processing",
        "visualization",
        "normalization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/deeptools/HiCExplorer",
      "help_website": [
        "https://hicexplorer.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "hic",
        "genomics",
        "visualization",
        "bioinformatics"
      ],
      "id": 90
    },
    {
      "name": "dxWDL",
      "one_line_profile": "Compiler for running WDL workflows on DNAnexus",
      "detailed_description": "dxWDL is a compiler that takes a workflow written in Workflow Description Language (WDL) and compiles it to an applet that can run on the DNAnexus cloud platform, enabling scientific workflow portability.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_compilation",
        "cloud_execution"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/dnanexus/dxWDL",
      "help_website": [
        "https://github.com/dnanexus/dxWDL"
      ],
      "license": "Apache-2.0",
      "tags": [
        "wdl",
        "dnanexus",
        "bioinformatics",
        "workflow"
      ],
      "id": 91
    },
    {
      "name": "Dockstore",
      "one_line_profile": "Registry for scientific workflows and tools",
      "detailed_description": "Dockstore is an open platform used by the GA4GH for sharing Docker-based scientific tools and workflows (CWL, WDL, Nextflow, Galaxy). It serves as a central registry for the scientific community.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_sharing",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/dockstore/dockstore",
      "help_website": [
        "https://dockstore.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow-registry",
        "ga4gh",
        "bioinformatics",
        "cwl",
        "wdl"
      ],
      "id": 92
    },
    {
      "name": "KSVD",
      "one_line_profile": "High performance distributed SVD solver",
      "detailed_description": "The KAUST SVD (KSVD) is a high performance software framework for computing a dense Singular Value Decomposition (SVD) on distributed-memory manycore systems, essential for various scientific computing tasks.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "linear_algebra",
        "dimensionality_reduction"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/ecrc/ksvd",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "svd",
        "linear-algebra",
        "scientific-computing"
      ],
      "id": 93
    },
    {
      "name": "Elyra",
      "one_line_profile": "Visual pipeline editor and AI toolkit for JupyterLab",
      "detailed_description": "Elyra extends JupyterLab with an AI-centric approach, providing a visual editor for building and running data science and machine learning pipelines (e.g., Kubeflow, Airflow) directly from the notebook environment.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_design",
        "pipeline_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/elyra-ai/elyra",
      "help_website": [
        "https://elyra.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "jupyter",
        "workflow",
        "pipeline",
        "data-science"
      ],
      "id": 94
    },
    {
      "name": "Pipeline Builder",
      "one_line_profile": "JavaScript library for visualizing and constructing WDL workflows",
      "detailed_description": "A JavaScript library for visualizing and constructing bioinformatics workflows using Workflow Description Language (WDL), enabling the creation of visual workflow editors.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_visualization",
        "workflow_design"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/epam/pipeline-builder",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "bioinformatics",
        "visualization",
        "workflow-editor"
      ],
      "id": 95
    },
    {
      "name": "WDL Workspace",
      "one_line_profile": "Web UI for running WDL workflows via Cromwell",
      "detailed_description": "A Web-based User Interface to run WDL bioinformatics workflows using the Cromwell server, facilitating the management and execution of scientific pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "job_management"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/epam/wdl-workspace",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "cromwell",
        "bioinformatics",
        "ui"
      ],
      "id": 96
    },
    {
      "name": "MrBiomics",
      "one_line_profile": "Composable modules for bioinformatics multi-omics analyses",
      "detailed_description": "MrBiomics provides composable modules and recipes to automate bioinformatics for multi-omics analyses, built on top of Snakemake.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "multi_omics",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/epigen/MrBiomics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "multi-omics",
        "bioinformatics",
        "pipeline"
      ],
      "id": 97
    },
    {
      "name": "atacseq_pipeline",
      "one_line_profile": "Snakemake workflow for ATAC-seq data processing",
      "detailed_description": "A Snakemake workflow and MrBiomics module for ATAC-seq data processing, quantification, and annotation.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "data_processing",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/epigen/atacseq_pipeline",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "atac-seq",
        "snakemake",
        "bioinformatics"
      ],
      "id": 98
    },
    {
      "name": "dea_limma",
      "one_line_profile": "Snakemake workflow for differential expression analysis using limma",
      "detailed_description": "A Snakemake workflow and MrBiomics module for performing and visualizing differential analyses of NGS data powered by the R package limma.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "differential_expression",
        "statistical_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/epigen/dea_limma",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "limma",
        "rna-seq",
        "snakemake",
        "bioinformatics"
      ],
      "id": 99
    },
    {
      "name": "enrichment_analysis",
      "one_line_profile": "Snakemake workflow for genomic enrichment analysis",
      "detailed_description": "A Snakemake workflow and MrBiomics module for performing genomic region set and gene set enrichment analyses using tools like LOLA, GREAT, and GSEApy.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "enrichment_analysis",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/epigen/enrichment_analysis",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gsea",
        "snakemake",
        "bioinformatics",
        "enrichment"
      ],
      "id": 100
    },
    {
      "name": "genome_tracks",
      "one_line_profile": "Snakemake workflow for genome browser track visualization",
      "detailed_description": "A Snakemake workflow and MrBiomics module for easy visualization of genome browser tracks of aligned BAM files (RNA-seq, ATAC-seq, etc.) using pyGenomeTracks.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "visualization",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/epigen/genome_tracks",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "genome-browser",
        "snakemake",
        "bioinformatics"
      ],
      "id": 101
    },
    {
      "name": "scrnaseq_processing_seurat",
      "one_line_profile": "Snakemake workflow for scRNA-seq processing with Seurat",
      "detailed_description": "A Snakemake workflow and MrBiomics module for processing and visualizing sc/snRNA-seq data powered by the R package Seurat.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "single_cell_analysis",
        "data_processing"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/epigen/scrnaseq_processing_seurat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scRNA-seq",
        "seurat",
        "snakemake",
        "bioinformatics"
      ],
      "id": 102
    },
    {
      "name": "unsupervised_analysis",
      "one_line_profile": "Snakemake workflow for unsupervised dimensionality reduction and clustering",
      "detailed_description": "A general purpose Snakemake workflow and MrBiomics module to perform unsupervised analyses (dimensionality reduction & cluster analysis) and visualizations of high-dimensional data.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "dimensionality_reduction",
        "clustering"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/epigen/unsupervised_analysis",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pca",
        "clustering",
        "snakemake",
        "data-analysis"
      ],
      "id": 103
    },
    {
      "name": "slurm-replay",
      "one_line_profile": "Tool to replay job submissions for Slurm workload analysis",
      "detailed_description": "A tool developed by CSCS to replay job submissions from logs on Slurm clusters, aiding in HPC workload analysis and scheduler optimization.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "hpc_workload_analysis",
        "scheduler_simulation"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/eth-cscs/slurm-replay",
      "help_website": [],
      "license": "BSD-3-Clause-Clear",
      "tags": [
        "slurm",
        "hpc",
        "workload-analysis"
      ],
      "id": 104
    },
    {
      "name": "Flyte SDK",
      "one_line_profile": "Python SDK for Flyte, a workflow automation platform for complex data and ML processes",
      "detailed_description": "The Python SDK for Flyte, enabling the creation of type-safe, distributed scientific and machine learning workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "ml_pipeline"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/flyteorg/flyte-sdk",
      "help_website": [
        "https://flyte.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow",
        "machine-learning",
        "orchestration"
      ],
      "id": 105
    },
    {
      "name": "bacannot",
      "one_line_profile": "Comprehensive pipeline for prokaryotic genome annotation",
      "detailed_description": "A Nextflow pipeline designed for the annotation and interrogation of prokaryotic genomes, including interactive reporting features.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "genome_annotation",
        "prokaryotic_genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/fmalmeida/bacannot",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "nextflow",
        "bioinformatics",
        "annotation"
      ],
      "id": 106
    },
    {
      "name": "metaGEM",
      "one_line_profile": "Workflow for generating genome-scale metabolic models from metagenomic data",
      "detailed_description": "An integrated workflow for reconstructing context-specific genome-scale metabolic models and predicting interactions in microbial communities directly from metagenomes.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "metabolic_modeling",
        "metagenomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/franciscozorrilla/metaGEM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "metabolism",
        "microbiome",
        "reconstruction"
      ],
      "id": 107
    },
    {
      "name": "Galaxy",
      "one_line_profile": "Open, web-based platform for accessible computational research",
      "detailed_description": "A scientific workflow, data integration, and data analysis platform that aims to make computational biology accessible to research scientists that do not have computer programming experience.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_platform",
        "bioinformatics_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/galaxyproject/galaxy",
      "help_website": [
        "https://galaxyproject.org"
      ],
      "license": "AFL-3.0",
      "tags": [
        "bioinformatics",
        "reproducibility",
        "workflow-engine"
      ],
      "id": 108
    },
    {
      "name": "Planemo",
      "one_line_profile": "Command-line utilities for developing Galaxy tools and CWL artifacts",
      "detailed_description": "A command-line toolkit for building, testing, and publishing Galaxy tools and Common Workflow Language (CWL) workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_development",
        "tool_wrapping"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/galaxyproject/planemo",
      "help_website": [
        "https://planemo.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "galaxy",
        "cwl",
        "dev-tools"
      ],
      "id": 109
    },
    {
      "name": "hybracter",
      "one_line_profile": "Automated long-read first bacterial genome assembly pipeline",
      "detailed_description": "A Snakemake pipeline for bacterial genome assembly that prioritizes long reads, utilizing Snaketool for workflow management.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "genome_assembly",
        "bacterial_genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/gbouras13/hybracter",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "assembly",
        "long-read"
      ],
      "id": 110
    },
    {
      "name": "noWorkflow",
      "one_line_profile": "Provenance tracking infrastructure for scientific scripts",
      "detailed_description": "A tool to capture and analyze the provenance of scientific experiments and scripts without requiring a heavy-weight workflow management system.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "provenance_tracking",
        "reproducibility"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gems-uff/noworkflow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "provenance",
        "reproducibility",
        "experiment-tracking"
      ],
      "id": 111
    },
    {
      "name": "nanopype",
      "one_line_profile": "Snakemake pipelines for nanopore sequencing data processing",
      "detailed_description": "A collection of Snakemake pipelines designed for the archiving and processing of Oxford Nanopore sequencing data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "sequencing_processing",
        "basecalling"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/giesselmann/nanopype",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "nanopore",
        "ngs"
      ],
      "id": 112
    },
    {
      "name": "snpArcher",
      "one_line_profile": "Snakemake workflow for variant calling in non-model organisms",
      "detailed_description": "A reproducible and scalable Snakemake workflow designed for variant calling, specifically optimized for ease of use with non-model organisms.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "variant_calling",
        "population_genetics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/harvardinformatics/snpArcher",
      "help_website": [
        "https://snparcher.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "snakemake",
        "genomics",
        "variant-calling"
      ],
      "id": 113
    },
    {
      "name": "rnaflow",
      "one_line_profile": "A simple RNA-Seq differential gene expression pipeline using Nextflow",
      "detailed_description": "A bioinformatics pipeline built with Nextflow for RNA-Seq data analysis, specifically designed for differential gene expression profiling.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pipeline",
        "rna_seq",
        "differential_expression"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/hoelzer-lab/rnaflow",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "rna-seq",
        "nextflow",
        "bioinformatics",
        "pipeline"
      ],
      "id": 114
    },
    {
      "name": "JupyterFlow",
      "one_line_profile": "Tool to run workflows on Kubernetes via JupyterHub",
      "detailed_description": "A tool that enables data scientists to execute DAG-based workflows on Kubernetes clusters directly from JupyterHub, facilitating interactive scientific computing and batch processing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "interactive_computing"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/hongkunyoo/jupyterflow",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyterhub",
        "kubernetes",
        "workflow",
        "data-science"
      ],
      "id": 115
    },
    {
      "name": "nextNEOpi",
      "one_line_profile": "Comprehensive pipeline for computational neoantigen prediction",
      "detailed_description": "A bioinformatics pipeline implemented in Nextflow for the prediction of neoantigens from sequencing data, supporting cancer immunotherapy research.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pipeline",
        "neoantigen_prediction",
        "immunotherapy"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/icbi-lab/nextNEOpi",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "neoantigen",
        "nextflow",
        "cancer-research",
        "bioinformatics"
      ],
      "id": 116
    },
    {
      "name": "ICGC ARGO DNA-Seq Workflow",
      "one_line_profile": "Standardized DNA-Seq processing workflow for ICGC ARGO",
      "detailed_description": "The official DNA sequencing data processing workflow used by the International Cancer Genome Consortium (ICGC) ARGO project, implemented in Nextflow.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pipeline",
        "dna_seq",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/icgc-argo-workflows/dna-seq-processing-wfs",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "icgc",
        "dna-seq",
        "genomics",
        "nextflow"
      ],
      "id": 117
    },
    {
      "name": "redun",
      "one_line_profile": "Scientific workflow engine designed for complex biological data pipelines",
      "detailed_description": "A workflow engine developed by Insitro, designed to handle complex data dependencies and caching for biological discovery and data science pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_engine",
        "pipeline_orchestration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/insitro/redun",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "bioinformatics",
        "data-science",
        "caching"
      ],
      "id": 118
    },
    {
      "name": "ducttape",
      "one_line_profile": "Workflow management system for researchers",
      "detailed_description": "A workflow management system designed for researchers, particularly in NLP and machine translation, to manage experimental pipelines and hyperparameter tuning.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "experiment_tracking"
      ],
      "application_level": "solver",
      "primary_language": "Scala",
      "repo_url": "https://github.com/jhclark/ducttape",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "workflow",
        "research",
        "nlp",
        "experimentation"
      ],
      "id": 119
    },
    {
      "name": "multiPrime",
      "one_line_profile": "Mismatch-tolerant minimal primer set design tool",
      "detailed_description": "A tool for designing minimal primer sets that are mismatch-tolerant, suitable for detecting diverse sequences such as viruses.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "primer_design",
        "genomics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/joybio/multiPrime",
      "help_website": [
        "http://multiPrime.cn"
      ],
      "license": "MIT",
      "tags": [
        "primer-design",
        "bioinformatics",
        "virology",
        "pcr"
      ],
      "id": 120
    },
    {
      "name": "Katana Skipper",
      "one_line_profile": "Simple and flexible workflow engine for machine learning pipelines",
      "detailed_description": "A lightweight, event-driven workflow engine designed specifically for orchestrating machine learning tasks. It supports defining pipelines as code and managing dependencies between ML steps.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "ml_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/katanaml/katana-skipper",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "mlops",
        "pipeline"
      ],
      "id": 121
    },
    {
      "name": "Kestra",
      "one_line_profile": "Language-agnostic orchestration and scheduling platform",
      "detailed_description": "A scalable, event-driven orchestration platform that allows users to declare workflows as code (YAML). It is widely used for data orchestration, including scientific data pipelines and AI/ML workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "data_pipeline"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/kestra-io/kestra",
      "help_website": [
        "https://kestra.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "orchestration",
        "workflow-engine",
        "scheduler"
      ],
      "id": 122
    },
    {
      "name": "Ruigi",
      "one_line_profile": "Pipeline management system for R, inspired by Luigi",
      "detailed_description": "A workflow management tool designed for the R ecosystem, enabling the definition and execution of dependent tasks in data science and statistical pipelines. It mimics the functionality of Python's Luigi for R users.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/kirillseva/ruigi",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "r",
        "pipeline",
        "workflow"
      ],
      "id": 123
    },
    {
      "name": "Kueue",
      "one_line_profile": "Kubernetes-native job queueing system for batch workloads",
      "detailed_description": "A job queueing controller for Kubernetes that manages quotas and admission for batch jobs. It is critical infrastructure for running scientific workloads (AI/ML, HPC) on cloud-native platforms.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubernetes-sigs/kueue",
      "help_website": [
        "https://kueue.sigs.k8s.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "batch-processing",
        "hpc"
      ],
      "id": 124
    },
    {
      "name": "Godel Scheduler",
      "one_line_profile": "Unified scheduler for online and offline (batch) tasks on Kubernetes",
      "detailed_description": "A high-performance scheduler for Kubernetes designed to handle massive scale batch processing and AI training workloads, optimizing resource utilization for scientific and data-intensive tasks.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "job_scheduling",
        "batch_processing"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubewharf/godel-scheduler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "scheduler",
        "kubernetes",
        "batch-jobs"
      ],
      "id": 125
    },
    {
      "name": "LncPipe",
      "one_line_profile": "Nextflow-based pipeline for long non-coding RNA analysis",
      "detailed_description": "A comprehensive bioinformatics pipeline built with Nextflow for analyzing lncRNAs from RNA-seq data. It handles alignment, assembly, identification, and quantification.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "bioinformatics_pipeline",
        "rna_seq_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Groovy",
      "repo_url": "https://github.com/likelet/LncPipe",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "nextflow",
        "bioinformatics",
        "lncrna"
      ],
      "id": 126
    },
    {
      "name": "LLM Workflow Engine",
      "one_line_profile": "Workflow manager and CLI for Large Language Models",
      "detailed_description": "A tool designed to manage and execute workflows involving Large Language Models (LLMs). It facilitates the orchestration of LLM-based tasks, which are increasingly used in scientific reasoning and automated research agents.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "llm_inference"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/llm-workflow-engine/llm-workflow-engine",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "workflow",
        "ai-agents"
      ],
      "id": 127
    },
    {
      "name": "gokart",
      "one_line_profile": "Wrapper for Luigi workflow engine focusing on reproducibility and task dependencies for ML pipelines",
      "detailed_description": "Gokart is a wrapper for the Luigi workflow engine that addresses reproducibility, task dependencies, and ease of use specifically for Machine Learning pipelines. It simplifies the creation of complex data processing workflows common in data science.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "pipeline_orchestration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/m3dev/gokart",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "luigi",
        "pipeline",
        "machine-learning",
        "reproducibility"
      ],
      "id": 128
    },
    {
      "name": "redshells",
      "one_line_profile": "Collection of machine learning tasks and pipelines using luigi and gokart",
      "detailed_description": "Redshells provides a set of pre-defined machine learning tasks and pipeline components that work with the Luigi and Gokart frameworks, facilitating the construction of ML workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_tasks",
        "pipeline_components"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/m3dev/redshells",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "luigi",
        "gokart",
        "machine-learning",
        "pipeline"
      ],
      "id": 129
    },
    {
      "name": "snakepipes",
      "one_line_profile": "Best-practice NGS data analysis workflows based on Snakemake",
      "detailed_description": "SnakePipes provides a set of flexible and customizable workflows for the analysis of Next-Generation Sequencing (NGS) data, built on top of the Snakemake workflow management system.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "bioinformatics_pipeline",
        "ngs_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/maxplanck-ie/snakepipes",
      "help_website": [
        "https://snakepipes.readthedocs.io/"
      ],
      "license": null,
      "tags": [
        "snakemake",
        "ngs",
        "bioinformatics",
        "workflow"
      ],
      "id": 130
    },
    {
      "name": "TorchX",
      "one_line_profile": "Universal job launcher for PyTorch applications",
      "detailed_description": "TorchX is a universal job launcher for PyTorch applications that supports orchestrating distributed training and batch inference jobs on various schedulers (Kubernetes, Slurm, AWS Batch, etc.), facilitating scientific machine learning workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "job_orchestration",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/meta-pytorch/torchx",
      "help_website": [
        "https://pytorch.org/torchx/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "pytorch",
        "job-scheduler",
        "orchestration",
        "mlops"
      ],
      "id": 131
    },
    {
      "name": "ATLAS",
      "one_line_profile": "Metagenome assembly and binning pipeline",
      "detailed_description": "ATLAS is a robust and reproducible workflow for metagenome data analysis, automating tasks from quality control to assembly, binning, and annotation using Snakemake.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "metagenomics_pipeline",
        "assembly",
        "binning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/metagenome-atlas/atlas",
      "help_website": [
        "https://metagenome-atlas.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "metagenomics",
        "snakemake",
        "bioinformatics",
        "pipeline"
      ],
      "id": 132
    },
    {
      "name": "CromwellOnAzure",
      "one_line_profile": "Deployment of Cromwell workflow engine on Azure",
      "detailed_description": "This repository contains the implementation and configuration required to deploy and run the Broad Institute's Cromwell workflow engine on Microsoft Azure, enabling scalable genomic data analysis in the cloud.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "cloud_infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "C#",
      "repo_url": "https://github.com/microsoft/CromwellOnAzure",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cromwell",
        "azure",
        "genomics",
        "workflow-engine"
      ],
      "id": 133
    },
    {
      "name": "miniwdl-aws",
      "one_line_profile": "AWS Batch backend for miniwdl",
      "detailed_description": "An extension for miniwdl that allows running WDL (Workflow Description Language) workflows on AWS Batch and EFS, facilitating cloud-based scientific computing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "cloud_computing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/miniwdl-ext/miniwdl-aws",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "aws-batch",
        "bioinformatics",
        "workflow"
      ],
      "id": 134
    },
    {
      "name": "miniwdl-omics-run",
      "one_line_profile": "Launcher for WDL workflows on AWS HealthOmics",
      "detailed_description": "A tool to launch and manage WDL workflows on AWS HealthOmics service using miniwdl, bridging local development and cloud execution for omics data.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_submission",
        "omics_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/miniwdl-ext/miniwdl-omics-run",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "aws-healthomics",
        "wdl",
        "bioinformatics"
      ],
      "id": 135
    },
    {
      "name": "grenepipe",
      "one_line_profile": "Pipeline for variant calling from raw sequence reads",
      "detailed_description": "Grenepipe is a flexible, scalable, and reproducible Snakemake pipeline designed to automate variant calling from raw sequencing reads, supporting both sampled individuals and pool sequencing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "variant_calling",
        "bioinformatics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/moiexpositoalonsolab/grenepipe",
      "help_website": [
        "https://grenepipe.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "snakemake",
        "variant-calling",
        "genomics",
        "pipeline"
      ],
      "id": 136
    },
    {
      "name": "MOLGENIS Compute",
      "one_line_profile": "Framework for bioinformatics workflow management",
      "detailed_description": "MOLGENIS Compute is a framework designed for bioinformatics that enables large-scale data and computational workflow management in distributed execution environments.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "bioinformatics_infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/molgenis/molgenis-compute",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "bioinformatics",
        "workflow",
        "grid-computing"
      ],
      "id": 137
    },
    {
      "name": "mulinlab-pip",
      "one_line_profile": "Collection of bioinformatics pipelines from Mulin Lab",
      "detailed_description": "A repository containing various bioinformatics pipelines developed by Mulin Lab for reproducible research.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "bioinformatics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/mulinlab/mulinlab-pip",
      "help_website": [],
      "license": null,
      "tags": [
        "bioinformatics",
        "pipeline",
        "reproducibility"
      ],
      "id": 138
    },
    {
      "name": "JUDI",
      "one_line_profile": "Workflow management system for complex bioinformatics software development",
      "detailed_description": "A workflow management system designed to facilitate the development of complex bioinformatics software with numerous parameter settings, ensuring reproducibility and efficiency.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "pipeline_development"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ncbi/JUDI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "workflow-management",
        "bioinformatics",
        "reproducibility"
      ],
      "id": 139
    },
    {
      "name": "MayomicsVC",
      "one_line_profile": "Variant Calling Pipeline using Cromwell and WDL",
      "detailed_description": "A bioinformatics pipeline for variant calling, implemented in WDL and designed to run on the Cromwell execution engine.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/ncsa/MayomicsVC",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "variant-calling",
        "wdl",
        "cromwell",
        "bioinformatics"
      ],
      "id": 140
    },
    {
      "name": "argo-jupyter-scheduler",
      "one_line_profile": "Jupyter extension for scheduling notebooks via Argo Workflows",
      "detailed_description": "An extension for Jupyter-Scheduler that enables the execution of scheduled notebooks using Argo Workflows as the backend, facilitating scientific workflow automation.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_scheduling",
        "notebook_execution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nebari-dev/argo-jupyter-scheduler",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "jupyter",
        "argo-workflows",
        "scheduling",
        "data-science"
      ],
      "id": 141
    },
    {
      "name": "Nextflow",
      "one_line_profile": "Data-driven computational pipeline engine",
      "detailed_description": "A workflow engine and DSL for writing data-driven computational pipelines that are scalable, portable, and reproducible across various compute environments.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Groovy",
      "repo_url": "https://github.com/nextflow-io/nextflow",
      "help_website": [
        "https://www.nextflow.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "pipeline",
        "reproducibility",
        "bioinformatics"
      ],
      "id": 142
    },
    {
      "name": "nf-core/ampliseq",
      "one_line_profile": "Amplicon sequencing analysis workflow",
      "detailed_description": "A Nextflow pipeline for amplicon sequencing analysis, utilizing DADA2 and QIIME2 for processing and analyzing 16S, ITS, and other amplicon data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "amplicon_sequencing",
        "microbiome_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/ampliseq",
      "help_website": [
        "https://nf-co.re/ampliseq"
      ],
      "license": "MIT",
      "tags": [
        "amplicon",
        "16s",
        "qiime2",
        "dada2"
      ],
      "id": 143
    },
    {
      "name": "nf-core/atacseq",
      "one_line_profile": "ATAC-seq peak-calling and QC pipeline",
      "detailed_description": "A bioinformatics pipeline for ATAC-seq data analysis, including quality control, alignment, and peak calling.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "atac_seq",
        "peak_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/atacseq",
      "help_website": [
        "https://nf-co.re/atacseq"
      ],
      "license": "MIT",
      "tags": [
        "atac-seq",
        "epigenetics",
        "chromatin"
      ],
      "id": 144
    },
    {
      "name": "nf-core/bacass",
      "one_line_profile": "Bacterial assembly and annotation pipeline",
      "detailed_description": "A pipeline for the assembly and annotation of bacterial genomes from NGS data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "genome_assembly",
        "genome_annotation"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/bacass",
      "help_website": [
        "https://nf-co.re/bacass"
      ],
      "license": "MIT",
      "tags": [
        "bacteria",
        "assembly",
        "annotation"
      ],
      "id": 145
    },
    {
      "name": "nf-core/chipseq",
      "one_line_profile": "ChIP-seq analysis pipeline",
      "detailed_description": "A comprehensive pipeline for ChIP-seq data analysis, covering quality control, alignment, peak calling, and differential binding analysis.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "chip_seq",
        "peak_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/chipseq",
      "help_website": [
        "https://nf-co.re/chipseq"
      ],
      "license": "MIT",
      "tags": [
        "chip-seq",
        "epigenetics",
        "transcription-factors"
      ],
      "id": 146
    },
    {
      "name": "nf-core/cutandrun",
      "one_line_profile": "CUT&RUN and CUT&TAG analysis pipeline",
      "detailed_description": "A pipeline for analyzing CUT&RUN and CUT&TAG experiments, including QC, spike-in normalization, and peak calling.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "cut_and_run",
        "epigenetics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/cutandrun",
      "help_website": [
        "https://nf-co.re/cutandrun"
      ],
      "license": "MIT",
      "tags": [
        "cut-and-run",
        "cut-and-tag",
        "chromatin"
      ],
      "id": 147
    },
    {
      "name": "nf-core/differentialabundance",
      "one_line_profile": "Differential abundance analysis pipeline",
      "detailed_description": "A pipeline for performing differential abundance analysis on feature matrices (e.g., from RNA-seq), producing plots and tables.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "differential_expression",
        "statistical_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/differentialabundance",
      "help_website": [
        "https://nf-co.re/differentialabundance"
      ],
      "license": "MIT",
      "tags": [
        "rnaseq",
        "differential-abundance",
        "statistics"
      ],
      "id": 148
    },
    {
      "name": "nf-core/eager",
      "one_line_profile": "Ancient DNA analysis pipeline",
      "detailed_description": "A fully reproducible pipeline for ancient DNA (aDNA) analysis, handling preprocessing, mapping, and genotyping of ancient samples.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "ancient_dna",
        "genotyping"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/eager",
      "help_website": [
        "https://nf-co.re/eager"
      ],
      "license": "MIT",
      "tags": [
        "ancient-dna",
        "paleogenomics",
        "adna"
      ],
      "id": 149
    },
    {
      "name": "nf-core/fetchngs",
      "one_line_profile": "Pipeline to fetch NGS data from public databases",
      "detailed_description": "A utility pipeline to retrieve metadata and raw FastQ files from public repositories like SRA and ENA for downstream analysis.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "data_retrieval",
        "metadata_acquisition"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/fetchngs",
      "help_website": [
        "https://nf-co.re/fetchngs"
      ],
      "license": "MIT",
      "tags": [
        "sra",
        "ena",
        "data-download"
      ],
      "id": 150
    },
    {
      "name": "nf-core/funcscan",
      "one_line_profile": "Functional gene screening pipeline",
      "detailed_description": "A pipeline for screening (meta-)genomes for functional and natural product gene sequences.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "functional_screening",
        "metagenomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/funcscan",
      "help_website": [
        "https://nf-co.re/funcscan"
      ],
      "license": "MIT",
      "tags": [
        "biosynthetic-gene-clusters",
        "screening",
        "genomics"
      ],
      "id": 151
    },
    {
      "name": "nf-core/hic",
      "one_line_profile": "Hi-C data analysis pipeline",
      "detailed_description": "A pipeline for the analysis of Chromosome Conformation Capture (Hi-C) data, including mapping, filtering, and contact map generation.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "hic_analysis",
        "chromosome_conformation"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/hic",
      "help_website": [
        "https://nf-co.re/hic"
      ],
      "license": "MIT",
      "tags": [
        "hi-c",
        "3d-genome",
        "chromatin-interaction"
      ],
      "id": 152
    },
    {
      "name": "nf-core/mag",
      "one_line_profile": "Metagenome assembly and binning pipeline",
      "detailed_description": "A pipeline for the assembly, binning, and annotation of metagenomes (Metagenome-Assembled Genomes).",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "metagenome_assembly",
        "binning"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/mag",
      "help_website": [
        "https://nf-co.re/mag"
      ],
      "license": "MIT",
      "tags": [
        "metagenomics",
        "mag",
        "assembly"
      ],
      "id": 153
    },
    {
      "name": "nf-core/methylseq",
      "one_line_profile": "Bisulfite sequencing analysis pipeline",
      "detailed_description": "A pipeline for methylation analysis using Bisulfite-Sequencing data, supporting alignment and methylation calling.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "methylation_analysis",
        "bisulfite_sequencing"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/methylseq",
      "help_website": [
        "https://nf-co.re/methylseq"
      ],
      "license": "MIT",
      "tags": [
        "methylation",
        "epigenetics",
        "bisulfite"
      ],
      "id": 154
    },
    {
      "name": "nf-core/nanoseq",
      "one_line_profile": "Nanopore sequencing analysis pipeline",
      "detailed_description": "A pipeline for analyzing Nanopore sequencing data, including demultiplexing, QC, and alignment.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "nanopore_analysis",
        "long_read_sequencing"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/nanoseq",
      "help_website": [
        "https://nf-co.re/nanoseq"
      ],
      "license": "MIT",
      "tags": [
        "nanopore",
        "ont",
        "long-read"
      ],
      "id": 155
    },
    {
      "name": "nf-core/oncoanalyser",
      "one_line_profile": "Cancer DNA/RNA analysis pipeline",
      "detailed_description": "A comprehensive pipeline for cancer research, integrating DNA and RNA analysis for variant calling and reporting.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "cancer_genomics",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/oncoanalyser",
      "help_website": [
        "https://nf-co.re/oncoanalyser"
      ],
      "license": "MIT",
      "tags": [
        "cancer",
        "oncology",
        "genomics"
      ],
      "id": 156
    },
    {
      "name": "nf-core/pangenome",
      "one_line_profile": "Pangenome graph construction pipeline",
      "detailed_description": "A pipeline to render a collection of sequences into a pangenome graph.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "pangenomics",
        "graph_construction"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/pangenome",
      "help_website": [
        "https://nf-co.re/pangenome"
      ],
      "license": "MIT",
      "tags": [
        "pangenome",
        "graph-genome",
        "genomics"
      ],
      "id": 157
    },
    {
      "name": "nf-core/proteinfold",
      "one_line_profile": "Protein 3D structure prediction pipeline",
      "detailed_description": "A pipeline for protein 3D structure prediction using tools like AlphaFold2 and ColabFold.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "structure_prediction",
        "protein_folding"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/proteinfold",
      "help_website": [
        "https://nf-co.re/proteinfold"
      ],
      "license": "MIT",
      "tags": [
        "alphafold",
        "protein-structure",
        "folding"
      ],
      "id": 158
    },
    {
      "name": "nf-core/raredisease",
      "one_line_profile": "Rare disease variant calling pipeline",
      "detailed_description": "A pipeline for calling and scoring variants from WGS/WES data specifically for rare disease diagnosis.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "variant_calling",
        "rare_disease"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/raredisease",
      "help_website": [
        "https://nf-co.re/raredisease"
      ],
      "license": "MIT",
      "tags": [
        "rare-disease",
        "variant-calling",
        "clinical-genomics"
      ],
      "id": 159
    },
    {
      "name": "nf-core/rnafusion",
      "one_line_profile": "RNA-seq gene fusion detection pipeline",
      "detailed_description": "A pipeline for detecting gene fusions from RNA-seq data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "gene_fusion_detection",
        "rnaseq"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/rnafusion",
      "help_website": [
        "https://nf-co.re/rnafusion"
      ],
      "license": "MIT",
      "tags": [
        "rna-fusion",
        "transcriptomics",
        "cancer"
      ],
      "id": 160
    },
    {
      "name": "nf-core/rnaseq",
      "one_line_profile": "RNA sequencing analysis pipeline",
      "detailed_description": "A standard pipeline for RNA sequencing analysis, including alignment, quantification, and extensive quality control.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "rnaseq",
        "gene_expression"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/rnaseq",
      "help_website": [
        "https://nf-co.re/rnaseq"
      ],
      "license": "MIT",
      "tags": [
        "rnaseq",
        "transcriptomics",
        "expression"
      ],
      "id": 161
    },
    {
      "name": "nf-core/sarek",
      "one_line_profile": "Germline and somatic variant calling pipeline",
      "detailed_description": "A comprehensive pipeline for detecting germline or somatic variants from WGS or targeted sequencing data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "variant_calling",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/sarek",
      "help_website": [
        "https://nf-co.re/sarek"
      ],
      "license": "MIT",
      "tags": [
        "variant-calling",
        "wgs",
        "wes",
        "cancer"
      ],
      "id": 162
    },
    {
      "name": "nf-core/scdownstream",
      "one_line_profile": "Single-cell transcriptomics downstream analysis pipeline",
      "detailed_description": "A pipeline for the downstream analysis of single-cell transcriptomics data, including QC, integration, and visualization.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "single_cell_analysis",
        "transcriptomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/scdownstream",
      "help_website": [
        "https://nf-co.re/scdownstream"
      ],
      "license": "MIT",
      "tags": [
        "single-cell",
        "scrnaseq",
        "downstream"
      ],
      "id": 163
    },
    {
      "name": "nf-core/scrnaseq",
      "one_line_profile": "Single-cell RNA-Seq processing pipeline",
      "detailed_description": "A pipeline for processing single-cell RNA-Seq data (10x, SmartSeq, etc.) from raw reads to expression matrices.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "single_cell_processing",
        "rnaseq"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/scrnaseq",
      "help_website": [
        "https://nf-co.re/scrnaseq"
      ],
      "license": "MIT",
      "tags": [
        "single-cell",
        "scrnaseq",
        "10x"
      ],
      "id": 164
    },
    {
      "name": "nf-core/smrnaseq",
      "one_line_profile": "Small RNA sequencing analysis pipeline",
      "detailed_description": "A pipeline for the analysis of small RNA sequencing data, such as miRNAs.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "small_rna_analysis",
        "mirna"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/smrnaseq",
      "help_website": [
        "https://nf-co.re/smrnaseq"
      ],
      "license": "MIT",
      "tags": [
        "small-rna",
        "mirna",
        "sequencing"
      ],
      "id": 165
    },
    {
      "name": "nf-core/taxprofiler",
      "one_line_profile": "Multi-taxonomic profiling pipeline",
      "detailed_description": "A pipeline for highly parallelised multi-taxonomic profiling of shotgun metagenomic data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "taxonomic_profiling",
        "metagenomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/taxprofiler",
      "help_website": [
        "https://nf-co.re/taxprofiler"
      ],
      "license": "MIT",
      "tags": [
        "metagenomics",
        "taxonomy",
        "profiling"
      ],
      "id": 166
    },
    {
      "name": "nf-core/viralrecon",
      "one_line_profile": "Viral assembly and variant calling pipeline",
      "detailed_description": "A pipeline for the assembly and variant calling of viral samples, widely used for SARS-CoV-2 analysis.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "viral_genomics",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/viralrecon",
      "help_website": [
        "https://nf-co.re/viralrecon"
      ],
      "license": "MIT",
      "tags": [
        "virus",
        "covid-19",
        "assembly"
      ],
      "id": 167
    },
    {
      "name": "nlppln",
      "one_line_profile": "NLP pipeline generation tool using Common Workflow Language (CWL)",
      "detailed_description": "A Python library that facilitates the creation of Natural Language Processing (NLP) pipelines by wrapping NLP tools in Common Workflow Language (CWL) definitions, enabling reproducible text analysis workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "nlp_pipeline",
        "text_mining",
        "workflow_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nlppln/nlppln",
      "help_website": [
        "https://nlppln.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "cwl",
        "workflow",
        "text-analysis"
      ],
      "id": 168
    },
    {
      "name": "distiller-nf",
      "one_line_profile": "Modular Hi-C mapping pipeline using Nextflow",
      "detailed_description": "A bioinformatics pipeline built with Nextflow for processing Hi-C data, handling mapping, parsing, and filtering of contact pairs to generate contact matrices for 3D genome analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "hic_mapping",
        "genomics",
        "3d_genome"
      ],
      "application_level": "workflow",
      "primary_language": "Groovy",
      "repo_url": "https://github.com/open2c/distiller-nf",
      "help_website": [
        "https://github.com/open2c/distiller-nf"
      ],
      "license": "MIT",
      "tags": [
        "nextflow",
        "hic",
        "genomics",
        "bioinformatics"
      ],
      "id": 169
    },
    {
      "name": "Orchest",
      "one_line_profile": "Visual platform for building and orchestrating data science pipelines",
      "detailed_description": "A browser-based platform for creating data science pipelines where steps can be executable notebooks (Jupyter) or scripts, facilitating reproducible data analysis and machine learning workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pipeline_orchestration",
        "data_science",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/orchest/orchest",
      "help_website": [
        "https://www.orchest.io/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-science",
        "pipeline",
        "jupyter",
        "orchestration"
      ],
      "id": 170
    },
    {
      "name": "Panoptes",
      "one_line_profile": "Real-time monitoring service for computational workflows",
      "detailed_description": "A system for monitoring the execution of computational workflows (such as those in bioinformatics) in real-time, providing visibility into task status and resource usage across distributed environments.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_monitoring",
        "observability"
      ],
      "application_level": "service",
      "primary_language": "CSS",
      "repo_url": "https://github.com/panoptes-organization/panoptes",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "monitoring",
        "workflow",
        "bioinformatics"
      ],
      "id": 171
    },
    {
      "name": "Pegasus WMS",
      "one_line_profile": "Workflow management system for scientific high-performance computing",
      "detailed_description": "A Workflow Management System that automates the execution of complex scientific workflows on distributed infrastructures (HPC, cloud, grid), handling data management, error recovery, and job scheduling.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "hpc_workflow",
        "distributed_computing",
        "job_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/pegasus-isi/pegasus",
      "help_website": [
        "https://pegasus.isi.edu"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "workflow-engine",
        "distributed-systems"
      ],
      "id": 172
    },
    {
      "name": "dispy",
      "one_line_profile": "Distributed and parallel computing framework for Python",
      "detailed_description": "A comprehensive Python framework for distributed and parallel computing, allowing users to execute computations across clusters of machines, often used for scientific simulations and data analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "parallel_computing",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pgiri/dispy",
      "help_website": [
        "http://dispy.sourceforge.net"
      ],
      "license": "NOASSERTION",
      "tags": [
        "distributed-computing",
        "parallel-processing",
        "python"
      ],
      "id": 173
    },
    {
      "name": "sciluigi",
      "one_line_profile": "Helper library for writing scientific workflows in Luigi",
      "detailed_description": "A wrapper library around Spotify's Luigi workflow engine, adding features specifically useful for scientific workflows such as improved dependency management and modularity for bioinformatics pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_authoring",
        "bioinformatics_workflow"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pharmbio/sciluigi",
      "help_website": [
        "https://github.com/pharmbio/sciluigi"
      ],
      "license": "MIT",
      "tags": [
        "luigi",
        "workflow",
        "bioinformatics"
      ],
      "id": 174
    },
    {
      "name": "pitagora-cwl",
      "one_line_profile": "Collection of Common Workflow Language tools for bioinformatics",
      "detailed_description": "A repository of reusable Common Workflow Language (CWL) tool definitions and workflows, maintained by the Pitagora Network for bioinformatics analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "bioinformatics_workflow",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Common Workflow Language",
      "repo_url": "https://github.com/pitagora-network/pitagora-cwl",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "cwl",
        "bioinformatics",
        "workflow-library"
      ],
      "id": 175
    },
    {
      "name": "pytask",
      "one_line_profile": "Workflow management system for reproducible data analysis",
      "detailed_description": "pytask is a workflow management system designed to facilitate reproducible data analyses, particularly in economics and social sciences. It handles dependencies, parallel execution, and integrates with various data formats to ensure research reproducibility.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "reproducible_research",
        "workflow_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/pytask-dev/pytask",
      "help_website": [
        "https://pytask-dev.readthedocs.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "reproducibility",
        "workflow",
        "data-analysis"
      ],
      "id": 176
    },
    {
      "name": "SoapFilm3D",
      "one_line_profile": "Simulation of soap films and foams using vortex sheets",
      "detailed_description": "A C++ framework for simulating the dynamics of soap films and foams using discrete circulation-preserving vortex sheets. It is designed for physics-based modeling of surface tension and fluid dynamics.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "simulation",
        "fluid_dynamics"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/raymondyfei/SoapFilm3D",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "physics-simulation",
        "fluid-dynamics",
        "vortex-methods"
      ],
      "id": 177
    },
    {
      "name": "Refinery Platform",
      "one_line_profile": "Bioinformatics data management and analysis platform",
      "detailed_description": "A system for managing, analyzing, and visualizing bioinformatics data. It integrates a data repository with a workflow engine based on Galaxy, providing a comprehensive environment for computational biology applications.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "bioinformatics_workflow",
        "data_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/refinery-platform/refinery-platform",
      "help_website": [
        "http://refinery-platform.org/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "bioinformatics",
        "galaxy",
        "workflow-management"
      ],
      "id": 178
    },
    {
      "name": "What the Phage",
      "one_line_profile": "Phage identification pipeline using Nextflow",
      "detailed_description": "A bioinformatics pipeline for bacteriophage identification and annotation. It utilizes Nextflow for orchestration and supports Docker/Singularity for reproducible execution of analysis tasks.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "phage_identification",
        "genomics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/replikation/What_the_Phage",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "nextflow",
        "bioinformatics",
        "phage"
      ],
      "id": 179
    },
    {
      "name": "law",
      "one_line_profile": "Large-scale analysis workflow framework for High Energy Physics",
      "detailed_description": "A Python package that extends Luigi to build large-scale task workflows, specifically designed for High Energy Physics (HEP) analyses. It supports remote job submission (HTCondor, etc.) and environment sandboxing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "physics_analysis",
        "workflow_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/riga/law",
      "help_website": [
        "https://law.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "hep",
        "physics",
        "luigi",
        "workflow"
      ],
      "id": 180
    },
    {
      "name": "UCSCXenaTools",
      "one_line_profile": "R package for accessing UCSC Xena genomics data",
      "detailed_description": "An R package designed to access, download, and explore genomics data from the UCSC Xena platform. It facilitates the integration of multi-omics data (cancer, single-cell) into R analysis workflows.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "data_access",
        "genomics"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/ropensci/UCSCXenaTools",
      "help_website": [
        "https://cran.r-project.org/web/packages/UCSCXenaTools/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "genomics",
        "bioinformatics",
        "r-package"
      ],
      "id": 181
    },
    {
      "name": "SCIP",
      "one_line_profile": "Scalable Cytometry Image Processing pipeline using Dask",
      "detailed_description": "An open-source tool implementing an image processing pipeline for cytometry data, performing projection, illumination correction, segmentation, and feature extraction on top of the Dask distributed computing framework.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "image_processing",
        "segmentation",
        "feature_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/saeyslab/SCIP",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "cytometry",
        "image-processing",
        "dask",
        "bioinformatics"
      ],
      "id": 182
    },
    {
      "name": "wdlRunR",
      "one_line_profile": "R interface for running WDL workflows",
      "detailed_description": "A tool that allows running WDL (Workflow Description Language) genomic data science workflows directly from the R environment, leveraging cloud resources for elastic and reproducible analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "genomics"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/seandavi/wdlRunR",
      "help_website": [],
      "license": null,
      "tags": [
        "wdl",
        "genomics",
        "r",
        "workflow-runner"
      ],
      "id": 183
    },
    {
      "name": "Nextflow Tower",
      "one_line_profile": "Management platform for Nextflow workflows",
      "detailed_description": "The open-source core of the Nextflow Tower system, providing monitoring, logging, and management capabilities for Nextflow scientific workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "monitoring"
      ],
      "application_level": "platform",
      "primary_language": "Groovy",
      "repo_url": "https://github.com/seqeralabs/nf-tower",
      "help_website": [
        "https://tower.nf"
      ],
      "license": "MPL-2.0",
      "tags": [
        "nextflow",
        "workflow-management",
        "bioinformatics"
      ],
      "id": 184
    },
    {
      "name": "Sequana",
      "one_line_profile": "Collection of Snakemake NGS pipelines",
      "detailed_description": "A comprehensive set of Snakemake pipelines for Next-Generation Sequencing (NGS) analysis, including tools for quality control, variant calling, and coverage analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "ngs_analysis",
        "quality_control",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/sequana/sequana",
      "help_website": [
        "https://sequana.readthedocs.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "snakemake",
        "ngs",
        "bioinformatics",
        "pipeline"
      ],
      "id": 185
    },
    {
      "name": "hecatomb",
      "one_line_profile": "Viral metagenomics analysis pipeline",
      "detailed_description": "A bioinformatics pipeline designed for the analysis of viral metagenomes (viromes) from Illumina sequencing data, focusing on rigorous quality control and contaminant removal.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "metagenomics",
        "virology",
        "sequence_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/shandley/hecatomb",
      "help_website": [
        "https://hecatomb.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "virome",
        "metagenomics",
        "snakemake",
        "bioinformatics"
      ],
      "id": 186
    },
    {
      "name": "snakefiles",
      "one_line_profile": "Reusable Snakemake workflows for RNA-seq",
      "detailed_description": "A collection of Snakemake workflow definitions (Snakefiles) for common RNA-seq data analysis tasks, including alignment with STAR and quantification with Kallisto.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "rna_seq",
        "alignment",
        "quantification"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/slowkow/snakefiles",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "rna-seq",
        "bioinformatics",
        "workflow"
      ],
      "id": 187
    },
    {
      "name": "Snakemake GATK Workflow",
      "one_line_profile": "GATK best-practices pipeline using Snakemake",
      "detailed_description": "A standardized Snakemake implementation of the GATK best-practices workflow for DNA sequencing data variant calling.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "variant_calling",
        "dna_seq"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake-workflows/dna-seq-gatk-variant-calling",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gatk",
        "snakemake",
        "variant-calling",
        "genomics"
      ],
      "id": 188
    },
    {
      "name": "Snakemake Varlociraptor Workflow",
      "one_line_profile": "Variant calling workflow using Varlociraptor",
      "detailed_description": "A Snakemake workflow for calling small and structural variants using the Varlociraptor statistical model, supporting various scenarios like tumor/normal and pedigree analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "variant_calling",
        "structural_variation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake-workflows/dna-seq-varlociraptor",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "varlociraptor",
        "snakemake",
        "genomics",
        "variant-calling"
      ],
      "id": 189
    },
    {
      "name": "Snakemake Kallisto-Sleuth Workflow",
      "one_line_profile": "RNA-seq differential expression workflow",
      "detailed_description": "A Snakemake workflow for performing differential expression analysis on RNA-seq data using Kallisto for quantification and Sleuth for statistical analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "rna_seq",
        "differential_expression"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake-workflows/rna-seq-kallisto-sleuth",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kallisto",
        "sleuth",
        "rna-seq",
        "snakemake"
      ],
      "id": 190
    },
    {
      "name": "Snakemake STAR-DESeq2 Workflow",
      "one_line_profile": "RNA-seq workflow with STAR and DESeq2",
      "detailed_description": "A standard Snakemake workflow for RNA-seq analysis, utilizing STAR for alignment and DESeq2 for differential expression analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "rna_seq",
        "alignment",
        "differential_expression"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake-workflows/rna-seq-star-deseq2",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "star",
        "deseq2",
        "rna-seq",
        "snakemake"
      ],
      "id": 191
    },
    {
      "name": "Snakemake",
      "one_line_profile": "Scalable bioinformatics workflow management system",
      "detailed_description": "A workflow management system that aims to reduce the complexity of creating workflows by providing a fast and comfortable execution environment, together with a clean and modern specification language in Python.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "pipeline_orchestration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake/snakemake",
      "help_website": [
        "https://snakemake.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "workflow-engine",
        "reproducibility",
        "bioinformatics",
        "python"
      ],
      "id": 192
    },
    {
      "name": "Snakemake Wrappers",
      "one_line_profile": "Repository of reusable tool wrappers for the Snakemake workflow engine",
      "detailed_description": "The official repository containing wrapper scripts for Snakemake, allowing easy integration of various bioinformatics and scientific tools into Snakemake workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_composition",
        "tool_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake/snakemake-wrappers",
      "help_website": [
        "https://snakemake-wrappers.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "snakemake",
        "workflow",
        "bioinformatics",
        "wrappers"
      ],
      "id": 193
    },
    {
      "name": "ToolJig",
      "one_line_profile": "Web application for building simplified Common Workflow Language (CWL) descriptions",
      "detailed_description": "A web-based tool designed to assist researchers in creating tool and workflow descriptions in the Common Workflow Language (CWL) format, facilitating the creation of reproducible scientific workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_creation",
        "metadata_management"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/srp33/ToolJig",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "cwl",
        "workflow",
        "bioinformatics",
        "gui"
      ],
      "id": 194
    },
    {
      "name": "Steep",
      "one_line_profile": "Scientific workflow management system for cloud execution",
      "detailed_description": "A workflow management system specifically designed to run scientific workflows in cloud environments, handling task orchestration and execution.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "cloud_computing"
      ],
      "application_level": "workflow",
      "primary_language": "Kotlin",
      "repo_url": "https://github.com/steep-wms/steep",
      "help_website": [
        "https://steep-wms.github.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "cloud",
        "scientific-computing"
      ],
      "id": 195
    },
    {
      "name": "Sprocket",
      "one_line_profile": "Bioinformatics workflow engine for WDL",
      "detailed_description": "A bioinformatics-focused workflow engine built in Rust that executes workflows defined in the Workflow Description Language (WDL).",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "pipeline_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Rust",
      "repo_url": "https://github.com/stjude-rust-labs/sprocket",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "wdl",
        "bioinformatics",
        "workflow-engine",
        "rust"
      ],
      "id": 196
    },
    {
      "name": "wdl-crates",
      "one_line_profile": "Rust libraries for parsing and working with WDL documents",
      "detailed_description": "A collection of Rust crates providing functionality to parse, validate, and manipulate Workflow Description Language (WDL) documents, serving as foundational infrastructure for WDL-based scientific tools.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_parsing",
        "metadata_handling"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/stjude-rust-labs/wdl",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "wdl",
        "rust",
        "parser",
        "workflow"
      ],
      "id": 197
    },
    {
      "name": "wdldoc",
      "one_line_profile": "Documentation generator for WDL workflows",
      "detailed_description": "A utility tool that generates Markdown documentation from Workflow Description Language (WDL) files, helping researchers document their scientific pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "documentation",
        "workflow_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/stjudecloud/wdldoc",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "documentation",
        "bioinformatics"
      ],
      "id": 198
    },
    {
      "name": "St. Jude Cloud Workflows",
      "one_line_profile": "Collection of bioinformatics workflows for St. Jude Cloud",
      "detailed_description": "A repository of production-grade bioinformatics workflows (WDL) used for genomic analysis on the St. Jude Cloud platform.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genomic_analysis",
        "pipeline_execution"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/stjudecloud/workflows",
      "help_website": [
        "https://stjude.cloud"
      ],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "wdl",
        "genomics",
        "pipeline"
      ],
      "id": 199
    },
    {
      "name": "Sunbeam",
      "one_line_profile": "Extensible metagenomics pipeline",
      "detailed_description": "A robust and extensible pipeline for metagenomic sequencing analysis, built on Snakemake, handling quality control, assembly, and classification.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "metagenomics",
        "sequence_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/sunbeam-labs/sunbeam",
      "help_website": [
        "https://sunbeam.readthedocs.io"
      ],
      "license": null,
      "tags": [
        "metagenomics",
        "snakemake",
        "pipeline",
        "bioinformatics"
      ],
      "id": 200
    },
    {
      "name": "systemPipeShiny",
      "one_line_profile": "Shiny interface for systemPipeR workflow management",
      "detailed_description": "A Shiny-based graphical user interface for the systemPipeR workflow management system, enabling interactive design, control, and visualization of data analysis workflows in R.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_visualization",
        "interactive_analysis"
      ],
      "application_level": "platform",
      "primary_language": "R",
      "repo_url": "https://github.com/systemPipeR/systemPipeShiny",
      "help_website": [
        "https://systempipe.org/"
      ],
      "license": null,
      "tags": [
        "shiny",
        "workflow",
        "r",
        "visualization"
      ],
      "id": 201
    },
    {
      "name": "Jetstream",
      "one_line_profile": "Workflow management system for batch schedulers",
      "detailed_description": "A workflow management system developed by TGen, designed to model complex workflows as DAGs and execute them on batch schedulers, specifically for genomic data analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "job_scheduling"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/tgen/jetstream",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "workflow",
        "genomics",
        "hpc",
        "dag"
      ],
      "id": 202
    },
    {
      "name": "scib-pipeline",
      "one_line_profile": "Snakemake pipeline for benchmarking single-cell integration methods",
      "detailed_description": "A reproducible Snakemake pipeline designed to benchmark various data integration methods for single-cell RNA sequencing data, working in conjunction with the scIB package.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "benchmarking",
        "single_cell_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/theislab/scib-pipeline",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "single-cell",
        "benchmarking",
        "snakemake",
        "bioinformatics"
      ],
      "id": 203
    },
    {
      "name": "Paperboy",
      "one_line_profile": "Web frontend for scheduling Jupyter notebook reports",
      "detailed_description": "A web application that allows users to schedule and execute Jupyter notebooks as reports, managing the workflow of periodic scientific analysis and reporting.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "reporting",
        "notebook_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/tkp-archive/paperboy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jupyter",
        "scheduling",
        "reporting",
        "workflow"
      ],
      "id": 204
    },
    {
      "name": "cwl-inspector",
      "one_line_profile": "Tool to inspect CWL tool and workflow properties",
      "detailed_description": "A command-line utility for inspecting and validating Common Workflow Language (CWL) documents, aiding in the development and debugging of scientific workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_validation",
        "debugging"
      ],
      "application_level": "solver",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/tom-tan/cwl-inspector",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cwl",
        "workflow",
        "inspection",
        "utility"
      ],
      "id": 205
    },
    {
      "name": "seq2science",
      "one_line_profile": "Automated preprocessing workflows for NGS data (ATAC/ChIP/RNA-seq)",
      "detailed_description": "A user-friendly command-line tool that automates the preprocessing of Next-Generation Sequencing (NGS) data. It supports various protocols including ATAC-seq, ChIP-seq, and RNA-seq, handling downloading, alignment, and quantification.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "ngs_preprocessing",
        "alignment",
        "quantification"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/vanheeringen-lab/seq2science",
      "help_website": [
        "https://vanheeringen-lab.github.io/seq2science/"
      ],
      "license": "MIT",
      "tags": [
        "ngs",
        "snakemake",
        "bioinformatics",
        "rna-seq",
        "atac-seq"
      ],
      "id": 206
    },
    {
      "name": "toil-vg",
      "one_line_profile": "Distributed framework for running Variation Graph (vg) workflows",
      "detailed_description": "A framework that leverages Toil to run Variation Graph (vg) workflows at scale, supporting distributed and cloud computing environments for pangenomics analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pangenomics",
        "variant_calling",
        "graph_alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/vgteam/toil-vg",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pangenomics",
        "variation-graph",
        "toil",
        "bioinformatics"
      ],
      "id": 207
    },
    {
      "name": "vg_wdl",
      "one_line_profile": "WDL workflows for Variation Graph (vg) analysis",
      "detailed_description": "A collection of Workflow Description Language (WDL) scripts designed for executing common Variation Graph (vg) workflows, enabling portable and reproducible pangenomic analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pangenomics",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/vgteam/vg_wdl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "pangenomics",
        "variation-graph",
        "workflows"
      ],
      "id": 208
    },
    {
      "name": "vsn-pipelines",
      "one_line_profile": "Nextflow pipelines for single-cell data analysis",
      "detailed_description": "A repository of scalable pipelines for processing single-cell sequencing data, implemented in Nextflow DSL2. It provides reproducible workflows for single-cell genomics and transcriptomics.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "single_cell_analysis",
        "scRNA-seq"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/vib-singlecell-nf/vsn-pipelines",
      "help_website": [
        "https://vsn-pipelines.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "single-cell",
        "nextflow",
        "bioinformatics",
        "pipelines"
      ],
      "id": 209
    },
    {
      "name": "nano-snakemake",
      "one_line_profile": "Snakemake pipeline for Nanopore structural variant analysis",
      "detailed_description": "A Snakemake-based workflow designed for the analysis of structural variants (SV) from Oxford Nanopore Technologies (ONT) genome sequencing data.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "structural_variant_calling",
        "nanopore_sequencing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/wdecoster/nano-snakemake",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nanopore",
        "snakemake",
        "structural-variants",
        "bioinformatics"
      ],
      "id": 210
    },
    {
      "name": "maestro",
      "one_line_profile": "Lightweight orchestrator for R data pipelines",
      "detailed_description": "A framework for orchestrating R-based data pipelines. It allows users to schedule and manage R scripts as organized workflows, facilitating reproducible data science and statistical analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "statistical_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/whipson/maestro",
      "help_website": [
        "https://whipson.github.io/maestro/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "r",
        "orchestration",
        "pipelines",
        "data-science"
      ],
      "id": 211
    },
    {
      "name": "FRACTAL",
      "one_line_profile": "Distributed computing framework for lineage tracing",
      "detailed_description": "A framework for distributed computing designed to trace large and accurate lineages, facilitating phylogenetic analysis and evolutionary biology studies.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "lineage_tracing",
        "phylogeny",
        "distributed_computing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yachielab/FRACTAL",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "phylogeny",
        "lineage-tracing",
        "distributed-computing",
        "bioinformatics"
      ],
      "id": 212
    },
    {
      "name": "tunnel",
      "one_line_profile": "Distributed computing framework for Torch 7",
      "detailed_description": "A data-driven framework for distributed computing built on Torch 7, designed to facilitate large-scale deep learning and scientific computing tasks (Legacy).",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "distributed_computing",
        "deep_learning"
      ],
      "application_level": "library",
      "primary_language": "Lua",
      "repo_url": "https://github.com/zhangxiangxiao/tunnel",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "torch7",
        "distributed-computing",
        "deep-learning",
        "legacy"
      ],
      "id": 213
    }
  ]
}