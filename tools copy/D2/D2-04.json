{
  "generated_at": "2025-12-16T07:15:12.185091+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "D2",
      "leaf_cluster_name": "科研工作流生态（Nextflow/Snakemake等）",
      "domain": "Data/Workflow",
      "typical_objects": "pipelines",
      "task_chain": "组件→组合→执行→测试→复现",
      "tool_form": "workflow engine + modules"
    },
    "unit": {
      "unit_id": "D2-04",
      "unit_name": "测试/回归/可复现评测",
      "target_scale": "150–300",
      "coverage_tools": "harness、CI"
    },
    "search": {
      "target_candidates": 300,
      "queries": [
        "[GH] test-harness",
        "[GH] biocheck",
        "[GH] snakemake-wrappers",
        "[GH] Pavilion",
        "[GH] miniwdl",
        "[GH] ReFrame",
        "[GH] pytest-workflow",
        "[GH] nf-test",
        "[GH] pipeline testing framework",
        "[GH] workflow validation",
        "[GH] reproducibility harness",
        "[GH] scientific workflow CI",
        "[GH] nextflow test",
        "[GH] snakemake unit test",
        "[GH] wdl validation",
        "[GH] regression testing bioinformatics",
        "[GH] pipeline benchmark",
        "[GH] data integrity check",
        "[GH] workflow verification",
        "[GH] HPC regression testing",
        "[WEB] scientific workflow testing framework github",
        "[WEB] nextflow pipeline regression testing github",
        "[WEB] snakemake reproducibility tools github",
        "[WEB] HPC system testing harness github",
        "[WEB] bioinformatics pipeline validation github"
      ],
      "total_candidates": 859,
      "tool_candidates": 440,
      "final_tools": 91
    }
  },
  "tools": [
    {
      "name": "ALLBioTC2",
      "one_line_profile": "Benchmark pipeline for Structural Variation analyses in bioinformatics",
      "detailed_description": "A benchmarking pipeline designed for Structural Variation (SV) analyses, funded by ALLBio. It provides a workflow to evaluate different SV detection tools or parameters.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "structural_variation_analysis",
        "bioinformatics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ALLBio/allbiotc2",
      "help_website": [],
      "license": null,
      "tags": [
        "bioinformatics",
        "structural-variation",
        "benchmarking",
        "pipeline"
      ],
      "id": 1
    },
    {
      "name": "ContextCheck",
      "one_line_profile": "Testing framework for LLMs, RAGs, and Chatbots integration in CI pipelines",
      "detailed_description": "A framework designed for automated testing of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) systems, and chatbots. It is configurable via YAML and integrates into CI pipelines to ensure model performance and reliability.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "model_testing",
        "llm_evaluation",
        "ci_integration"
      ],
      "application_level": "harness",
      "primary_language": "Python",
      "repo_url": "https://github.com/Addepto/contextcheck",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "rag",
        "testing-framework",
        "ci-cd"
      ],
      "id": 2
    },
    {
      "name": "Optimum Transformers",
      "one_line_profile": "Accelerated NLP pipelines for fast inference on CPU and GPU",
      "detailed_description": "A library that provides accelerated NLP pipelines for fast inference, built with Transformers, Optimum, and ONNX Runtime. It focuses on optimizing the performance of transformer models for scientific and general AI applications.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "inference_optimization",
        "nlp_pipeline",
        "model_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AlekseyKorshuk/optimum-transformers",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "nlp",
        "transformers",
        "optimization",
        "onnx"
      ],
      "id": 3
    },
    {
      "name": "MMSearch",
      "one_line_profile": "Multimodal Search Engine Pipeline and Benchmark for LMMs",
      "detailed_description": "A comprehensive pipeline and benchmark designed for evaluating Large Multimodal Models (LMMs) in the context of multimodal search tasks. It serves as a tool for assessing model performance in information retrieval.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "multimodal_retrieval",
        "model_evaluation"
      ],
      "application_level": "harness",
      "primary_language": "Python",
      "repo_url": "https://github.com/CaraJ7/MMSearch",
      "help_website": [],
      "license": null,
      "tags": [
        "multimodal",
        "benchmark",
        "search-engine",
        "lmm"
      ],
      "id": 4
    },
    {
      "name": "Bird-SQL Pipeline",
      "one_line_profile": "Text-to-SQL pipeline for BIRD benchmark",
      "detailed_description": "A pipeline implementation for the BIRD benchmark, facilitating the conversion of natural language text to SQL queries. It is used for evaluating and developing models for database interaction tasks in research.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "text_to_sql",
        "benchmarking",
        "pipeline_implementation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ContextualAI/bird-sql",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "text-to-sql",
        "benchmark",
        "bird",
        "nlp"
      ],
      "id": 5
    },
    {
      "name": "Pavilion",
      "one_line_profile": "Unreal Engine-based alternative to Gazebo for robotics simulation",
      "detailed_description": "A robotics simulation environment built on Unreal Engine, designed as an alternative to Gazebo. It provides high-fidelity rendering and physics for testing and validating robotics algorithms.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "robotics_simulation",
        "environment_simulation",
        "testing_harness"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/CoreRC/Pavilion",
      "help_website": [],
      "license": null,
      "tags": [
        "robotics",
        "simulation",
        "unreal-engine",
        "gazebo-alternative"
      ],
      "id": 6
    },
    {
      "name": "Reads2Map",
      "one_line_profile": "WDL workflows to benchmark genetic markers using linkage map quality",
      "detailed_description": "A collection of WDL (Workflow Description Language) bioinformatics workflows designed to benchmark genetic markers derived from different pipelines. It uses linkage map quality as a diagnostic metric for evaluation.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "bioinformatics_benchmarking",
        "genetic_mapping",
        "workflow_validation"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/Cristianetaniguti/Reads2Map",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "bioinformatics",
        "benchmarking",
        "genetics"
      ],
      "id": 7
    },
    {
      "name": "KITE",
      "one_line_profile": "End-to-end benchmark for RAG pipelines evaluation",
      "detailed_description": "KITE (Knowledge-Intensive Task Evaluation) is a benchmarking tool designed to evaluate Retrieval-Augmented Generation (RAG) pipelines. It assesses the performance of RAG systems on knowledge-intensive tasks.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "benchmarking",
        "nlp_testing"
      ],
      "application_level": "harness",
      "primary_language": "Python",
      "repo_url": "https://github.com/D-Star-AI/KITE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "benchmark",
        "evaluation",
        "nlp"
      ],
      "id": 8
    },
    {
      "name": "wdl-ci",
      "one_line_profile": "CI/CD tools for validating and testing WDL-based bioinformatics workflows",
      "detailed_description": "A set of tools designed to validate and test Workflow Description Language (WDL) repositories. It is intended for use within Continuous Integration/Continuous Deployment (CI/CD) pipelines to ensure the integrity and correctness of scientific workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "workflow_validation",
        "ci_cd",
        "bioinformatics_pipeline"
      ],
      "application_level": "harness",
      "primary_language": "Python",
      "repo_url": "https://github.com/DNAstack/wdl-ci",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "wdl",
        "ci",
        "bioinformatics",
        "workflow-testing"
      ],
      "id": 9
    },
    {
      "name": "EMODnetBiocheck",
      "one_line_profile": "Quality control tool for checking IPT resources against OBIS guidelines",
      "detailed_description": "A tool developed by EMODnet to check if Integrated Publishing Toolkit (IPT) resources comply with the guidelines of the Ocean Biodiversity Information System (OBIS). It ensures data quality and standardization for marine biological data.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "data_quality_control",
        "marine_biology",
        "compliance_checking"
      ],
      "application_level": "solver",
      "primary_language": "R",
      "repo_url": "https://github.com/EMODnet/EMODnetBiocheck",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "obis",
        "marine-biology",
        "quality-control",
        "biodiversity"
      ],
      "id": 10
    },
    {
      "name": "ETH3D Dataset Pipeline",
      "one_line_profile": "Pipeline for creating multi-view benchmark datasets from laser scans",
      "detailed_description": "A C++ pipeline used to create high-quality multi-view benchmark datasets for 3D reconstruction, combining laser scans and images. It is a tool for generating ground truth data for computer vision research.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "dataset_generation",
        "3d_reconstruction",
        "benchmarking"
      ],
      "application_level": "pipeline",
      "primary_language": "C++",
      "repo_url": "https://github.com/ETH3D/dataset-pipeline",
      "help_website": [
        "https://www.eth3d.net/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "computer-vision",
        "3d-reconstruction",
        "dataset-generation",
        "benchmark"
      ],
      "id": 11
    },
    {
      "name": "precisionFDA",
      "one_line_profile": "Cloud-based platform for benchmarking NGS analysis pipelines",
      "detailed_description": "A platform developed by the FDA to provide an environment for testing, piloting, and benchmarking new approaches to validating next-generation sequencing (NGS) analysis pipelines. It facilitates community collaboration and standardization in genomics.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "ngs_benchmarking",
        "bioinformatics_validation",
        "genomics_platform"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/FDA/precisionFDA",
      "help_website": [
        "https://precision.fda.gov/"
      ],
      "license": "CC0-1.0",
      "tags": [
        "ngs",
        "fda",
        "benchmarking",
        "bioinformatics"
      ],
      "id": 12
    },
    {
      "name": "FloTorch",
      "one_line_profile": "Optimization tool for Generative AI workloads and RAG pipelines",
      "detailed_description": "An open-source tool designed to optimize Generative AI workloads, specifically automating RAG proof-of-concept development. It includes features for hyperparameter tuning, vector database optimization, and LLM integration to accelerate AI research and deployment.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "ai_optimization",
        "rag_automation",
        "hyperparameter_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/FissionAI/FloTorch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "generative-ai",
        "rag",
        "optimization",
        "mlops"
      ],
      "id": 13
    },
    {
      "name": "LAGraph",
      "one_line_profile": "Library and test harness for GraphBLAS based graph algorithms",
      "detailed_description": "A library and test harness for collecting and benchmarking algorithms that use the GraphBLAS standard, facilitating the development and testing of high-performance graph algorithms used in scientific computing.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "graph_algorithms",
        "benchmarking",
        "algorithm_testing"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/GraphBLAS/LAGraph",
      "help_website": [
        "https://lagraph.readthedocs.org",
        "https://graphblas.org/LAGraph/"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "graphblas",
        "graph-algorithms",
        "hpc",
        "benchmarking"
      ],
      "id": 14
    },
    {
      "name": "SVsim",
      "one_line_profile": "Synthetic Structural Variant generator for benchmarking pipelines",
      "detailed_description": "A tool designed to generate synthetic Structural Variant (SV) calls to serve as ground truth benchmarks for testing and evaluating the performance of SV calling pipelines in genomics.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "synthetic_data_generation",
        "benchmarking",
        "variant_calling_validation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GregoryFaust/SVsim",
      "help_website": [],
      "license": null,
      "tags": [
        "genomics",
        "structural-variants",
        "simulation",
        "benchmarking"
      ],
      "id": 15
    },
    {
      "name": "SQuADDS",
      "one_line_profile": "Design database and simulation workflow for superconducting quantum hardware",
      "detailed_description": "A validated design database and simulation workflow software specifically for superconducting quantum hardware, enabling researchers to generate and simulate quantum device designs.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "simulation",
        "hardware_design",
        "quantum_physics"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/LFL-Lab/SQuADDS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "quantum-computing",
        "simulation",
        "superconducting-circuits",
        "workflow"
      ],
      "id": 16
    },
    {
      "name": "pytest-workflow",
      "one_line_profile": "Test runner for scientific pipelines (Nextflow/Snakemake) using YAML",
      "detailed_description": "A pytest plugin designed to test computational pipelines (such as those written in Nextflow or Snakemake) by defining test cases in YAML files, widely used in bioinformatics for workflow verification.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "pipeline_testing",
        "workflow_verification",
        "reproducibility"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LUMC/pytest-workflow",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "testing",
        "bioinformatics",
        "pipeline",
        "pytest",
        "workflow"
      ],
      "id": 17
    },
    {
      "name": "LW-BenchHub",
      "one_line_profile": "Unified benchmark hub for embodied AI and robotics simulation",
      "detailed_description": "A benchmark hub built on Isaac Lab-Arena for embodied AI, providing consistent interfaces, realistic environments, and multi-robot support for evaluating robot policies in scientific simulations.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "robotics_simulation",
        "benchmarking",
        "embodied_ai"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/LightwheelAI/LW-BenchHub",
      "help_website": [],
      "license": null,
      "tags": [
        "robotics",
        "isaac-sim",
        "benchmarking",
        "reinforcement-learning"
      ],
      "id": 18
    },
    {
      "name": "B4PPI",
      "one_line_profile": "Benchmarking pipeline for Protein-Protein Interaction prediction",
      "detailed_description": "A benchmarking pipeline designed to evaluate methods for the prediction of Protein-Protein Interactions (PPI), facilitating comparative analysis of computational biology tools.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "protein_interaction_prediction",
        "bioinformatics"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Llannelongue/B4PPI",
      "help_website": [],
      "license": null,
      "tags": [
        "ppi",
        "benchmarking",
        "proteomics",
        "computational-biology"
      ],
      "id": 19
    },
    {
      "name": "PRBench",
      "one_line_profile": "CUDA implementation of the PageRank Pipeline Benchmark",
      "detailed_description": "A high-performance CUDA implementation of the PageRank pipeline benchmark, used for evaluating graph analytics performance in scientific computing and HPC contexts.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "graph_analytics",
        "benchmarking",
        "hpc"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/NVIDIA/PRBench",
      "help_website": [],
      "license": null,
      "tags": [
        "cuda",
        "pagerank",
        "graph-algorithms",
        "benchmarking"
      ],
      "id": 20
    },
    {
      "name": "DBS-Gym",
      "one_line_profile": "RL Environment and Benchmark for Deep Brain Stimulation",
      "detailed_description": "A reinforcement learning environment and benchmarking pipeline for comparing adaptive Deep Brain Stimulation (DBS) algorithms, facilitating neurophysiological research and medical AI development.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "neuroscience_simulation",
        "reinforcement_learning",
        "benchmarking"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/NevVerVer/DBS-Gym",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "neuroscience",
        "reinforcement-learning",
        "deep-brain-stimulation",
        "simulation"
      ],
      "id": 21
    },
    {
      "name": "seurigiotto-benchmark-framework",
      "one_line_profile": "Benchmarking framework for Spatial Transcriptomics analysis",
      "detailed_description": "A framework optimizing pipelines for Spatial Transcriptomics (ST) data analysis using Seurat and Giotto, designed for reproducible benchmarking and generating biological insights.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "spatial_transcriptomics",
        "benchmarking",
        "bioinformatics"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/Nuiter/seurigiotto-benchmark-framework",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "spatial-transcriptomics",
        "seurat",
        "giotto",
        "benchmarking"
      ],
      "id": 22
    },
    {
      "name": "Modelling-Urban-Heat-Islands-from-Satellite-Imagery",
      "one_line_profile": "Synthetic modeling of Urban Heat Islands using satellite-like data",
      "detailed_description": "A tool for synthetic modeling of Urban Heat Islands (UHI) that generates spectral bands, vegetation/urban indices, and land surface temperature (LST) for testing machine learning models and validating geospatial workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "synthetic_data_generation",
        "remote_sensing",
        "environmental_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Okes2024/Modelling-Urban-Heat-Islands-from-Satellite-Imagery",
      "help_website": [],
      "license": null,
      "tags": [
        "remote-sensing",
        "urban-heat-island",
        "synthetic-data",
        "earth-science"
      ],
      "id": 23
    },
    {
      "name": "pecheck",
      "one_line_profile": "Integrity checker for paired-end FASTQ data",
      "detailed_description": "A tool to check the integrity of paired-end FASTQ data, ensuring data quality for downstream bioinformatics analysis.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "quality_control",
        "data_integrity",
        "bioinformatics"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/OpenGene/pecheck",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fastq",
        "quality-control",
        "ngs",
        "bioinformatics"
      ],
      "id": 24
    },
    {
      "name": "Project-Eucalyptus",
      "one_line_profile": "Pipelines for satellite-based methane detection and benchmarking",
      "detailed_description": "Open-source pipelines for satellite-based methane detection, including trained segmentation models, a synthetic plume generator, and benchmarking tools for Sentinel-2, Landsat, and EMIT data.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "remote_sensing",
        "methane_detection",
        "benchmarking",
        "environmental_science"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Orbio-Earth/Project-Eucalyptus",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "remote-sensing",
        "methane",
        "satellite-imagery",
        "benchmarking"
      ],
      "id": 25
    },
    {
      "name": "CATD_snakemake",
      "one_line_profile": "Snakemake pipeline for benchmarking cell-type deconvolution methods",
      "detailed_description": "A Snakemake pipeline designed to benchmark cell-type deconvolution methods and deconvolve real bulk RNA-seq data using scRNA-seq datasets as references.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "deconvolution",
        "transcriptomics"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/Papatheodorou-Group/CATD_snakemake",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "snakemake",
        "deconvolution",
        "rna-seq",
        "benchmarking"
      ],
      "id": 26
    },
    {
      "name": "MONAI Deploy App SDK",
      "one_line_profile": "Framework to develop and verify AI-driven healthcare imaging applications",
      "detailed_description": "A framework and set of tools designed to design, develop, and verify AI-driven applications in the healthcare imaging domain, facilitating the deployment of medical AI models.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "medical_imaging",
        "model_verification",
        "deployment",
        "healthcare_ai"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Project-MONAI/monai-deploy-app-sdk",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-imaging",
        "monai",
        "healthcare",
        "verification"
      ],
      "id": 27
    },
    {
      "name": "ProteoBench",
      "one_line_profile": "Community-curated benchmarking platform for proteomics pipelines",
      "detailed_description": "An open and collaborative platform for community-curated benchmarks of proteomics data analysis pipelines, enabling continuous and controlled comparison of different analysis workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "proteomics",
        "workflow_comparison"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Proteobench/ProteoBench",
      "help_website": [
        "https://proteobench.cubimed.rub.de/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "proteomics",
        "benchmarking",
        "bioinformatics",
        "community-platform"
      ],
      "id": 28
    },
    {
      "name": "CITE-seq_optimization",
      "one_line_profile": "Benchmarking and optimization scripts for CITE-seq antibody titration pipelines",
      "detailed_description": "A set of scripts and workflows designed to optimize and benchmark TotalSeqC antibody titration pipelines for CITE-seq experiments, aiding in the quality control and parameter tuning of single-cell multi-omics data processing.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "optimization",
        "pipeline_validation"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/Terkild/CITE-seq_optimization",
      "help_website": [],
      "license": null,
      "tags": [
        "cite-seq",
        "single-cell",
        "antibody-titration",
        "bioinformatics"
      ],
      "id": 29
    },
    {
      "name": "nextflow-test-pipelines",
      "one_line_profile": "Bioinformatics pipeline test suite for platform monitoring",
      "detailed_description": "A collection of Nextflow and WDL bioinformatics pipelines used as a test harness to validate the functionality and performance of pipeline monitoring platforms, ensuring reproducibility and stability of scientific workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "pipeline_testing",
        "workflow_validation"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/Tracer-Cloud/nextflow-test-pipelines",
      "help_website": [],
      "license": null,
      "tags": [
        "nextflow",
        "wdl",
        "bioinformatics",
        "testing"
      ],
      "id": 30
    },
    {
      "name": "gptoss20b-redteam-harness",
      "one_line_profile": "Safety evaluation harness for GPT-OSS-20B model",
      "detailed_description": "A testing harness designed to probe and reproduce safety failures in the GPT-OSS-20B large language model, serving as a tool for AI safety research and model evaluation.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "safety_testing",
        "red_teaming"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/VietHann/gptoss20b-redteam-harness",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "ai-safety",
        "evaluation",
        "red-teaming"
      ],
      "id": 31
    },
    {
      "name": "BenchPOTS",
      "one_line_profile": "Benchmarking toolbox for partially-observed time series analysis",
      "detailed_description": "A Python toolbox designed to benchmark machine learning algorithms on partially-observed time series (POTS) data, supporting pipelines for 172 public datasets, facilitating standardized evaluation in time-series research.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "time_series_analysis",
        "algorithm_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/WenjieDu/BenchPOTS",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "time-series",
        "benchmarking",
        "machine-learning",
        "missing-data"
      ],
      "id": 32
    },
    {
      "name": "acwf-verification-scripts",
      "one_line_profile": "Verification scripts for AiiDA common workflows in materials science",
      "detailed_description": "A set of scripts for running and analyzing data from the AiiDA Common Workflows (ACWF) verification project, ensuring the reliability and consistency of computational materials science simulations.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "workflow_verification",
        "data_analysis",
        "materials_science"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/aiidateam/acwf-verification-scripts",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "aiida",
        "materials-science",
        "verification",
        "workflow"
      ],
      "id": 33
    },
    {
      "name": "aiida-sssp-workflow",
      "one_line_profile": "Verification workflows for Standard Solid State Pseudopotentials",
      "detailed_description": "AiiDA workflows designed for the verification of Standard Solid State Pseudopotentials (SSSP), providing automated testing and validation for materials science calculations.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "pseudopotential_verification",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/aiidateam/aiida-sssp-workflow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "aiida",
        "sssp",
        "pseudopotentials",
        "verification"
      ],
      "id": 34
    },
    {
      "name": "RefChecker",
      "one_line_profile": "Pipeline for detecting hallucinations in Large Language Models",
      "detailed_description": "An automatic checking pipeline and benchmark dataset designed to detect fine-grained hallucinations generated by Large Language Models (LLMs), facilitating rigorous evaluation of AI model reliability.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/amazon-science/RefChecker",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "hallucination",
        "evaluation",
        "benchmark"
      ],
      "id": 35
    },
    {
      "name": "nf-test",
      "one_line_profile": "Test framework for Nextflow pipelines",
      "detailed_description": "A simple and powerful testing framework specifically designed for Nextflow pipelines, enabling developers to write and execute unit and integration tests for scientific workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "pipeline_testing",
        "unit_testing",
        "workflow_validation"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/askimed/nf-test",
      "help_website": [
        "https://www.nf-test.com"
      ],
      "license": "MIT",
      "tags": [
        "nextflow",
        "testing",
        "bioinformatics",
        "pipeline"
      ],
      "id": 36
    },
    {
      "name": "bcbio-nextgen",
      "one_line_profile": "Validated, scalable, community developed variant calling and RNA-seq analysis pipeline",
      "detailed_description": "A python toolkit providing best-practice pipelines for automated high-throughput sequencing analysis, including variant calling, RNA-seq, and small RNA analysis. It handles data processing, quality control, and integrates various bioinformatics tools into a cohesive workflow.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "variant_calling",
        "rna_seq_analysis",
        "pipeline_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bcbio/bcbio-nextgen",
      "help_website": [
        "https://bcbio-nextgen.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "genomics",
        "variant-calling",
        "rna-seq",
        "pipeline"
      ],
      "id": 37
    },
    {
      "name": "bcbio_validation_workflows",
      "one_line_profile": "Automated validation workflows for the bcbio-nextgen pipeline",
      "detailed_description": "A collection of automated workflows designed to validate variant calling and other analyses performed by bcbio-nextgen. It uses the Common Workflow Language (CWL) to ensure reproducibility and correctness of the pipeline's outputs against standard benchmarks.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "pipeline_validation",
        "benchmarking",
        "quality_assurance"
      ],
      "application_level": "workflow",
      "primary_language": "Common Workflow Language",
      "repo_url": "https://github.com/bcbio/bcbio_validation_workflows",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "validation",
        "benchmarking",
        "cwl",
        "bioinformatics",
        "variant-calling"
      ],
      "id": 38
    },
    {
      "name": "WES-Benchmarking-Pipeline",
      "one_line_profile": "Benchmarking pipeline for Whole Exome Sequencing aligners and variant callers",
      "detailed_description": "A shell-based pipeline designed to benchmark the performance of various aligners and variant callers specifically for Whole Exome Sequencing (WES) data. It facilitates the evaluation of bioinformatics tools for accuracy and efficiency.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "variant_calling",
        "alignment_evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/bharani-lab/WES-Benchmarking-Pipeline_Manoj",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmarking",
        "wes",
        "variant-calling",
        "bioinformatics",
        "pipeline"
      ],
      "id": 39
    },
    {
      "name": "biobakery_workflows",
      "one_line_profile": "Standardized workflows for microbial community analysis",
      "detailed_description": "A collection of workflows and tasks for executing common microbial community analyses (microbiome) using standardized, validated tools and parameters. It simplifies the process of running complex bioBakery toolchains.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "microbiome_analysis",
        "metagenomics",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/biobakery/biobakery_workflows",
      "help_website": [
        "https://github.com/biobakery/biobakery_workflows/wiki"
      ],
      "license": "NOASSERTION",
      "tags": [
        "microbiome",
        "metagenomics",
        "workflow",
        "biobakery"
      ],
      "id": 40
    },
    {
      "name": "mapping-benchmarking",
      "one_line_profile": "Snakemake pipeline for benchmarking read mappers",
      "detailed_description": "A Snakemake-based pipeline designed to benchmark the performance of various DNA read mappers. It automates the execution and evaluation of mapping tools, facilitating comparative analysis in bioinformatics.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "read_mapping",
        "performance_evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bioinf-benchmarking/mapping-benchmarking",
      "help_website": [],
      "license": null,
      "tags": [
        "snakemake",
        "benchmarking",
        "read-mapping",
        "bioinformatics"
      ],
      "id": 41
    },
    {
      "name": "Cromwell",
      "one_line_profile": "Scientific workflow engine for WDL",
      "detailed_description": "A workflow management system geared towards scientific workflows, originally developed for bioinformatics. It supports the Workflow Description Language (WDL) and is designed for simplicity and scalability in cloud and local environments.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "pipeline_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Scala",
      "repo_url": "https://github.com/broadinstitute/cromwell",
      "help_website": [
        "https://cromwell.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "workflow-engine",
        "wdl",
        "bioinformatics",
        "cromwell"
      ],
      "id": 42
    },
    {
      "name": "docker-benchmarks",
      "one_line_profile": "Benchmarks of genomic pipelines running in Docker containers",
      "detailed_description": "A repository containing benchmarks for evaluating the performance of genomic pipelines when executed within Docker containers. It provides a framework for assessing the overhead and efficiency of containerized bioinformatics workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "container_performance",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/cbcrg/docker-benchmarks",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmarking",
        "docker",
        "genomics",
        "bioinformatics"
      ],
      "id": 43
    },
    {
      "name": "ReFramed",
      "one_line_profile": "Metabolic modeling package",
      "detailed_description": "A Python package for metabolic modeling, supporting constraint-based analysis of metabolic networks. It allows for the simulation and analysis of cellular metabolism.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "metabolic_modeling",
        "systems_biology",
        "constraint_based_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cdanielmachado/reframed",
      "help_website": [
        "https://reframed.readthedocs.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "metabolic-modeling",
        "systems-biology",
        "python"
      ],
      "id": 44
    },
    {
      "name": "miniwdl",
      "one_line_profile": "Local runner and developer toolkit for Workflow Description Language (WDL)",
      "detailed_description": "A local runner and developer toolkit for the Workflow Description Language (WDL), widely used in bioinformatics. It provides a Pythonic API and command-line tools for developing, testing, and running WDL workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "wdl_development",
        "pipeline_testing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/chanzuckerberg/miniwdl",
      "help_website": [
        "https://miniwdl.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "wdl",
        "workflow-runner",
        "bioinformatics",
        "developer-tools"
      ],
      "id": 45
    },
    {
      "name": "miniwdl-plugins",
      "one_line_profile": "Plugins for the miniwdl workflow runner",
      "detailed_description": "A collection of plugins to extend the functionality of the miniwdl workflow runner, enhancing its capabilities for scientific workflow execution and management.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_extension",
        "pipeline_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chanzuckerberg/miniwdl-plugins",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "plugins",
        "workflow",
        "bioinformatics"
      ],
      "id": 46
    },
    {
      "name": "snakescale",
      "one_line_profile": "Non-strict wrappers for Snakemake",
      "detailed_description": "A library providing non-strict wrappers for Snakemake, a popular workflow management system in bioinformatics. It aims to simplify the creation and management of data pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_utility",
        "pipeline_development"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/clintval/snakescale",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "workflow",
        "bioinformatics",
        "wrapper"
      ],
      "id": 47
    },
    {
      "name": "benchmark_scrnaseq_cnv_callers",
      "one_line_profile": "Benchmark pipeline for scRNA-seq CNV callers",
      "detailed_description": "An analysis pipeline designed to benchmark Copy Number Variant (CNV) callers specifically for single-cell RNA sequencing (scRNA-seq) data. It enables the comparative evaluation of different CNV detection tools.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "cnv_calling",
        "scrna_seq_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/colomemaria/benchmark_scrnaseq_cnv_callers",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmarking",
        "scrna-seq",
        "cnv",
        "bioinformatics"
      ],
      "id": 48
    },
    {
      "name": "ck-scc18",
      "one_line_profile": "Collective Knowledge workflow for SeisSol application",
      "detailed_description": "A Collective Knowledge (CK) workflow designed to automate the installation, execution, and validation of the SeisSol application (seismology simulation) across different platforms. It facilitates reproducibility in high-performance computing for science.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_automation",
        "reproducibility",
        "seismology_simulation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ctuning/ck-scc18",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "collective-knowledge",
        "seissol",
        "hpc",
        "reproducibility",
        "seismology"
      ],
      "id": 49
    },
    {
      "name": "poreTally",
      "one_line_profile": "Benchmark MinION assembler pipelines",
      "detailed_description": "A tool to benchmark various assembler pipelines for MinION sequencing data. It automates the execution and reporting of assembly performance, aiding in the selection of optimal tools for nanopore sequencing analysis.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "genome_assembly",
        "nanopore_sequencing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/cvdelannoy/poreTally",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmarking",
        "minion",
        "assembly",
        "bioinformatics"
      ],
      "id": 50
    },
    {
      "name": "snakemake-wrappers",
      "one_line_profile": "Snakemake wrappers for bioinformatics tools",
      "detailed_description": "A collection of wrappers for Snakemake, facilitating the integration of various bioinformatics tools into Snakemake workflows. It simplifies the process of building reproducible data analysis pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_integration",
        "bioinformatics_utility"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dohlee/snakemake-wrappers",
      "help_website": [],
      "license": null,
      "tags": [
        "snakemake",
        "bioinformatics",
        "wrappers",
        "workflow"
      ],
      "id": 51
    },
    {
      "name": "BayesicFitting",
      "one_line_profile": "Bayesian fitting package for data analysis",
      "detailed_description": "A Python package for performing Bayesian fitting on data. It provides tools for statistical modeling and inference, suitable for scientific data analysis tasks requiring Bayesian approaches.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "statistical_inference",
        "curve_fitting",
        "bayesian_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dokester/BayesicFitting",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bayesian",
        "fitting",
        "statistics",
        "data-analysis"
      ],
      "id": 52
    },
    {
      "name": "genome_tracks",
      "one_line_profile": "Snakemake workflow for visualizing genome browser tracks from BAM files",
      "detailed_description": "A Snakemake workflow and MrBiomics module for easy visualization of genome browser tracks of aligned BAM files (e.g., RNA-seq, ATAC-seq, scRNA-seq) powered by pyGenomeTracks and IGV-reports.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "visualization",
        "genomics",
        "workflow"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/epigen/genome_tracks",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "genomics",
        "visualization",
        "bam"
      ],
      "id": 53
    },
    {
      "name": "Evidently",
      "one_line_profile": "ML and LLM observability and evaluation framework",
      "detailed_description": "An open-source ML and LLM observability framework to evaluate, test, and monitor AI-powered systems or data pipelines. It provides metrics for data drift, model performance, and data quality, suitable for scientific ML workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "data_validation",
        "drift_detection"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/evidentlyai/evidently",
      "help_website": [
        "https://docs.evidentlyai.com"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "evaluation",
        "monitoring",
        "data-quality"
      ],
      "id": 54
    },
    {
      "name": "NitroML",
      "one_line_profile": "Model-quality benchmarking framework for ML and AutoML pipelines",
      "detailed_description": "A modular, portable, and scalable model-quality benchmarking framework for Machine Learning and Automated Machine Learning (AutoML) pipelines, facilitating reproducible evaluation of ML models.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "automl",
        "model_evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/google/nitroml",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmarking",
        "ml-pipelines",
        "automl",
        "reproducibility"
      ],
      "id": 55
    },
    {
      "name": "scArchon",
      "one_line_profile": "Benchmarking pipeline for single-cell perturbation prediction tools",
      "detailed_description": "A benchmarking pipeline designed to evaluate single-cell perturbation prediction tools, facilitating comparative analysis in computational biology.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "single_cell",
        "perturbation_prediction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/hdsu-bioquant/scArchon",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "single-cell",
        "benchmarking",
        "bioinformatics",
        "perturbation"
      ],
      "id": 56
    },
    {
      "name": "Pavilion",
      "one_line_profile": "Framework for running and analyzing tests targeting HPC systems",
      "detailed_description": "A Python-based framework for running and analyzing tests targeting High Performance Computing (HPC) systems, ensuring infrastructure reliability for scientific computing.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "hpc_testing",
        "regression_testing",
        "infrastructure_validation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/hpc/pavilion2",
      "help_website": [
        "https://pavilion.readthedocs.io"
      ],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "testing",
        "regression",
        "infrastructure"
      ],
      "id": 57
    },
    {
      "name": "immune_deconvolution_benchmark",
      "one_line_profile": "Reproducible pipeline for evaluating cell-type quantification methods",
      "detailed_description": "A reproducible pipeline for the comprehensive evaluation of cell-type quantification methods for immuno-oncology, supporting the benchmarking of immune deconvolution algorithms.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "immuno_oncology",
        "deconvolution"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/icbi-lab/immune_deconvolution_benchmark",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "bioinformatics",
        "benchmarking",
        "immunology",
        "reproducibility"
      ],
      "id": 58
    },
    {
      "name": "HPC Challenge Benchmark",
      "one_line_profile": "Benchmark suite for High Performance Computing systems",
      "detailed_description": "The HPC Challenge Benchmark is a suite of tests that examine the performance of HPC architectures using kernels with more challenging memory access patterns than standard benchmarks.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_evaluation",
        "hpc"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/icl-utk-edu/hpcc",
      "help_website": [
        "http://icl.cs.utk.edu/hpcc/"
      ],
      "license": null,
      "tags": [
        "hpc",
        "benchmark",
        "performance",
        "supercomputing"
      ],
      "id": 59
    },
    {
      "name": "gwas-assoc",
      "one_line_profile": "GWAS Association Testing Pipeline",
      "detailed_description": "The IKMB GWAS Association Testing Pipeline, designed to streamline genome-wide association studies.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "gwas",
        "association_testing",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ikmb/gwas-assoc",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gwas",
        "genomics",
        "pipeline",
        "bioinformatics"
      ],
      "id": 60
    },
    {
      "name": "cellmap-segmentation-challenge",
      "one_line_profile": "Toolkit for 3D cell segmentation model training and evaluation",
      "detailed_description": "A repository containing scripts and workflows to facilitate participation in CellMap's segmentation challenge, including data downloading, training setups for 2D/3D models, and evaluation pipelines for biological image segmentation.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "image_segmentation",
        "model_evaluation",
        "bioimage_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/janelia-cellmap/cellmap-segmentation-challenge",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "segmentation",
        "microscopy",
        "benchmark"
      ],
      "id": 61
    },
    {
      "name": "Archer-GIS-AI-Assistant",
      "one_line_profile": "AI assistant for automating GIS workflows in ArcGIS Pro",
      "detailed_description": "An AI-powered tool that transforms natural language commands into automated GIS workflows within ArcGIS Pro, streamlining spatial analysis and reducing manual effort in geospatial research.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "spatial_analysis",
        "workflow_automation",
        "gis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/korporalK/Archer-GIS-AI-Assitant",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gis",
        "llm-agent",
        "arcgis"
      ],
      "id": 62
    },
    {
      "name": "Pavilion",
      "one_line_profile": "HPC testing and regression framework",
      "detailed_description": "A Python-based testing framework designed for High Performance Computing (HPC) systems to manage regression testing, system validation, and test harness execution in scientific computing environments.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "hpc_testing",
        "system_validation",
        "regression_testing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/lanl/Pavilion",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "testing-framework",
        "cluster-management"
      ],
      "id": 63
    },
    {
      "name": "BenchmarkDatasetCreator",
      "one_line_profile": "Pipeline for creating standardized bioacoustic datasets",
      "detailed_description": "A standardized pipeline for creating, storing, sharing, and using expert-labeled bioacoustic datasets to train and test AI models for biological sound analysis.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "dataset_creation",
        "bioacoustics",
        "data_standardization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/leabouffaut/BenchmarkDatasetCreator",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "bioacoustics",
        "dataset",
        "benchmark"
      ],
      "id": 64
    },
    {
      "name": "Simscape-Electrical-Power-Plant-Model-Validation",
      "one_line_profile": "Workflow for power plant model validation using PMU data",
      "detailed_description": "A workflow and set of tools for validating Simscape Electrical power plant models against phasor measurement unit (PMU) data, supporting online performance monitoring and model verification.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "model_validation",
        "power_system_simulation",
        "performance_monitoring"
      ],
      "application_level": "workflow",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/mathworks/Simscape-Electrical-Power-Plant-Model-Validation",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "simscape",
        "power-systems",
        "model-validation"
      ],
      "id": 65
    },
    {
      "name": "nextflow_for_nextstrain",
      "one_line_profile": "Nextflow pipeline for Nextstrain viral evolution analysis",
      "detailed_description": "A Nextflow-based pipeline for parallelizing Nextstrain builds and parameter testing, facilitating efficient viral evolution analysis and phylogenetics workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "workflow_management",
        "viral_evolution",
        "phylogenetics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/matt-sd-watson/nextflow_for_nextstrain",
      "help_website": [],
      "license": null,
      "tags": [
        "nextflow",
        "nextstrain",
        "bioinformatics"
      ],
      "id": 66
    },
    {
      "name": "RBFE-Benchmark",
      "one_line_profile": "Workflows for benchmarking alchemical binding free energy calculations",
      "detailed_description": "A collection of modular and interoperable workflows and datasets for benchmarking alchemical relative binding free energy (RBFE) calculation methodologies in computational chemistry.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "binding_free_energy",
        "benchmarking",
        "molecular_dynamics"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/michellab/RBFE-Benchmark",
      "help_website": [],
      "license": null,
      "tags": [
        "free-energy",
        "computational-chemistry",
        "benchmark"
      ],
      "id": 67
    },
    {
      "name": "WeatherReal-Benchmark",
      "one_line_profile": "Benchmark for weather forecast verification",
      "detailed_description": "Evaluation pipelines and components for the WeatherReal benchmark dataset, designed to support the verification and benchmarking of weather forecasting models.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "weather_forecasting",
        "benchmark",
        "model_verification"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/WeatherReal-Benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "weather",
        "benchmark",
        "meteorology"
      ],
      "id": 68
    },
    {
      "name": "miniwdl-aws",
      "one_line_profile": "AWS backend extension for miniwdl workflow runner",
      "detailed_description": "An extension for the miniwdl workflow runner that enables the execution of WDL-based scientific workflows on AWS Batch and EFS infrastructure.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_execution",
        "cloud_computing",
        "bioinformatics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/miniwdl-ext/miniwdl-aws",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "aws",
        "workflow-runner"
      ],
      "id": 69
    },
    {
      "name": "miniwdl-omics-run",
      "one_line_profile": "WDL launcher for AWS HealthOmics",
      "detailed_description": "A tool to launch and manage WDL workflows specifically on AWS HealthOmics service, facilitating cloud-native genomics analysis.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "genomics",
        "workflow_execution",
        "cloud_computing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/miniwdl-ext/miniwdl-omics-run",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "aws-healthomics",
        "wdl",
        "genomics"
      ],
      "id": 70
    },
    {
      "name": "nf-schema",
      "one_line_profile": "Schema validation library for Nextflow pipelines",
      "detailed_description": "A plugin and library for validating input parameters and sample sheets in Nextflow scientific pipelines against a defined JSON schema, ensuring data integrity before workflow execution.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "data_validation",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "Groovy",
      "repo_url": "https://github.com/nextflow-io/nf-schema",
      "help_website": [
        "https://nextflow-io.github.io/nf-schema/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nextflow",
        "schema-validation",
        "workflow",
        "bioinformatics"
      ],
      "id": 71
    },
    {
      "name": "nf-core/deepmodeloptim",
      "one_line_profile": "Pipeline for stochastic testing and optimization of learning systems",
      "detailed_description": "A Nextflow pipeline designed for the stochastic testing and input manipulation of unbiased learning systems, facilitating model evaluation and optimization in scientific machine learning contexts.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "optimization"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/deepmodeloptim",
      "help_website": [
        "https://nf-co.re/deepmodeloptim"
      ],
      "license": "MIT",
      "tags": [
        "machine-learning",
        "optimization",
        "testing",
        "nextflow"
      ],
      "id": 72
    },
    {
      "name": "nf-core/drugresponseeval",
      "one_line_profile": "Pipeline for evaluating drug response prediction models",
      "detailed_description": "A bioinformatics pipeline for testing and benchmarking drug response prediction models using statistically and biologically sound methods.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "drug_response_prediction"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/drugresponseeval",
      "help_website": [
        "https://nf-co.re/drugresponseeval"
      ],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "drug-discovery",
        "benchmarking",
        "nextflow"
      ],
      "id": 73
    },
    {
      "name": "nf-core/modules",
      "one_line_profile": "Standard library of bioinformatics tool wrappers for Nextflow",
      "detailed_description": "A centralized repository of DSL2 modules for the Nextflow ecosystem, providing pre-packaged, reusable wrappers for hundreds of bioinformatics and scientific tools to build reproducible workflows.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_composition",
        "tool_wrapping"
      ],
      "application_level": "library",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/modules",
      "help_website": [
        "https://nf-co.re/modules"
      ],
      "license": "MIT",
      "tags": [
        "nextflow",
        "bioinformatics",
        "modules",
        "workflow"
      ],
      "id": 74
    },
    {
      "name": "nf-core/nft-utils",
      "one_line_profile": "Utility functions for testing Nextflow pipelines",
      "detailed_description": "A library of utility functions designed to be used with nf-test, facilitating the creation of robust tests for Nextflow pipelines and modules.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "testing",
        "validation"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/nf-core/nft-utils",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nextflow",
        "testing",
        "nf-test",
        "utils"
      ],
      "id": 75
    },
    {
      "name": "nf-core/variantbenchmarking",
      "one_line_profile": "Pipeline for benchmarking genomic variant calling methods",
      "detailed_description": "A Nextflow pipeline designed to evaluate and validate the accuracy of variant calling methods in genomic research, providing metrics for precision, recall, and F1 score.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "variant_calling_evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/variantbenchmarking",
      "help_website": [
        "https://nf-co.re/variantbenchmarking"
      ],
      "license": "MIT",
      "tags": [
        "genomics",
        "benchmarking",
        "variant-calling",
        "nextflow"
      ],
      "id": 76
    },
    {
      "name": "Geospatial Analysis Integrity Tool (GAIT)",
      "one_line_profile": "Geospatial data integrity and validation tool",
      "detailed_description": "A tool that validates geospatial data against defined data models (MGCP, GIFD, TDS, VMap), checking geometry, feature codes, attributes, and metadata integrity.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "data_validation",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/ngageoint/Geospatial-Analysis-Integrity-Tool",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gis",
        "geospatial",
        "data-integrity",
        "validation"
      ],
      "id": 77
    },
    {
      "name": "NMDP Consensus Pipeline",
      "one_line_profile": "Consensus assembly and allele interpretation pipeline",
      "detailed_description": "A bioinformatics pipeline for consensus assembly and allele interpretation, developed by the National Marrow Donor Program bioinformatics group.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "sequence_assembly",
        "allele_interpretation"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/nmdp-bioinformatics/pipeline",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "bioinformatics",
        "assembly",
        "genomics",
        "hla"
      ],
      "id": 78
    },
    {
      "name": "nft-bam",
      "one_line_profile": "nf-test plugin for BAM/SAM/CRAM file assertions",
      "detailed_description": "A plugin for the nf-test framework that enables assertions on the contents of SAM, BAM, and CRAM files, facilitating automated testing of bioinformatics pipelines involving alignment data.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "testing",
        "data_validation"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/nvnieuwk/nft-bam",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "testing",
        "nf-test",
        "bam"
      ],
      "id": 79
    },
    {
      "name": "Atlas Checks",
      "one_line_profile": "OpenStreetMap data integrity checks framework",
      "detailed_description": "A framework for performing data integrity checks on OpenStreetMap data using the Atlas library, used for validating geospatial data quality.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "data_validation",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/osmlab/atlas-checks",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "geospatial",
        "osm",
        "data-quality",
        "validation"
      ],
      "id": 80
    },
    {
      "name": "pipeComp",
      "one_line_profile": "Benchmark framework for bioinformatics pipelines",
      "detailed_description": "An R framework for benchmarking bioinformatics pipelines, with a specific focus on single-cell RNA-seq data analysis workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "pipeline_evaluation"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/plger/pipeComp",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bioinformatics",
        "benchmarking",
        "scrnaseq",
        "r"
      ],
      "id": 81
    },
    {
      "name": "Skore",
      "one_line_profile": "ML model evaluation and reporting library",
      "detailed_description": "A Python library that accelerates machine learning model development by providing automated evaluation reports, methodological guidance, and cross-validation analysis.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "reporting"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/probabl-ai/skore",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "machine-learning",
        "evaluation",
        "data-science",
        "visualization"
      ],
      "id": 82
    },
    {
      "name": "ReFrame",
      "one_line_profile": "HPC regression testing and benchmarking framework",
      "detailed_description": "A framework for writing and running portable regression tests and benchmarks for High Performance Computing (HPC) systems, ensuring the reliability of scientific computing infrastructure.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "hpc_testing",
        "benchmarking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/reframe-hpc/reframe",
      "help_website": [
        "https://reframe-hpc.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "testing",
        "benchmarking",
        "supercomputing"
      ],
      "id": 83
    },
    {
      "name": "GRETA",
      "one_line_profile": "Benchmarking pipeline for Gene Regulatory Network (GRN) inference methods",
      "detailed_description": "A pipeline designed to benchmark Gene Regulatory Network (GRN) inference methods. It facilitates the evaluation of different algorithms for inferring regulatory interactions from gene expression data.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "network_inference"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/saezlab/greta",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "gene-regulatory-networks",
        "benchmarking",
        "bioinformatics"
      ],
      "id": 84
    },
    {
      "name": "tonkaz",
      "one_line_profile": "CLI tool to verify reproducibility of scientific workflows via GA4GH WES",
      "detailed_description": "A command-line tool designed to verify the reproducibility of scientific workflows (such as CWL, WDL, and Nextflow) by executing them through a GA4GH Workflow Execution Service (WES) interface and comparing outputs.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "reproducibility_verification",
        "workflow_testing"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/sapporo-wes/tonkaz",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reproducibility",
        "ga4gh",
        "workflow-execution-service",
        "wes"
      ],
      "id": 85
    },
    {
      "name": "BayesianSafetyValidation.jl",
      "one_line_profile": "Bayesian optimization library for safety validation of critical systems",
      "detailed_description": "A Julia library for estimating the probability of failure in safety-critical systems using Bayesian optimization. It is used for validation and verification tasks in engineering and control systems.",
      "domains": [
        "D2-04",
        "D4"
      ],
      "subtask_category": [
        "safety_validation",
        "bayesian_optimization",
        "risk_estimation"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/sisl/BayesianSafetyValidation.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bayesian-optimization",
        "safety-critical-systems",
        "validation"
      ],
      "id": 86
    },
    {
      "name": "Snakemake",
      "one_line_profile": "Scalable and reproducible workflow management system",
      "detailed_description": "A workflow management system that aims to reduce the complexity of creating facsimiles of data analysis to create reproducible and scalable data analyses. It uses a Python-based language to define workflows.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_management",
        "pipeline_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake/snakemake",
      "help_website": [
        "https://snakemake.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "workflow-engine",
        "reproducibility",
        "pipeline"
      ],
      "id": 87
    },
    {
      "name": "scib-pipeline",
      "one_line_profile": "Snakemake pipeline for benchmarking single-cell data integration methods",
      "detailed_description": "A reproducible Snakemake pipeline designed to benchmark various single-cell data integration methods using the scIB (Single-cell Integration Benchmarking) package, facilitating comparative analysis of integration algorithms.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "data_integration",
        "single_cell_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/theislab/scib-pipeline",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "single-cell",
        "benchmarking",
        "bioinformatics"
      ],
      "id": 88
    },
    {
      "name": "tool-NFTest",
      "one_line_profile": "CLI automation tool for testing Nextflow pipelines",
      "detailed_description": "A command-line interface developed by UCLA Health CDS to automate the testing and validation of Nextflow-based scientific workflows, ensuring pipeline reliability and reproducibility.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "pipeline_testing",
        "workflow_validation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/uclahs-cds/tool-NFTest",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "nextflow",
        "testing",
        "ci",
        "workflow-automation"
      ],
      "id": 89
    },
    {
      "name": "WfCommons",
      "one_line_profile": "Framework for enabling scientific workflow research and benchmarking",
      "detailed_description": "A framework designed to facilitate research and development in scientific workflows by providing tools to generate, analyze, and simulate workflow execution instances for benchmarking Workflow Management Systems (WMS).",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "workflow_benchmarking",
        "simulation",
        "performance_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wfcommons/WfCommons",
      "help_website": [
        "https://wfcommons.org"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "scientific-workflows",
        "benchmarking",
        "simulation",
        "reproducibility"
      ],
      "id": 90
    },
    {
      "name": "ZnTrack",
      "one_line_profile": "DVC-based framework for creating and benchmarking scientific pipelines",
      "detailed_description": "A Python interface for DVC (Data Version Control) that facilitates the creation, visualization, execution, and benchmarking of scientific data pipelines, enhancing reproducibility in ML and data science workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "pipeline_management",
        "benchmarking",
        "reproducibility"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zincware/ZnTrack",
      "help_website": [
        "https://zntrack.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dvc",
        "pipeline",
        "benchmarking",
        "machine-learning"
      ],
      "id": 91
    }
  ]
}