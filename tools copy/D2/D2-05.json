{
  "generated_at": "2025-12-16T07:42:07.196109+08:00",
  "metadata": {
    "leaf_cluster": {
      "leaf_cluster_id": "D2",
      "leaf_cluster_name": "科研工作流生态（Nextflow/Snakemake等）",
      "domain": "Data/Workflow",
      "typical_objects": "pipelines",
      "task_chain": "组件→组合→执行→测试→复现",
      "tool_form": "workflow engine + modules"
    },
    "unit": {
      "unit_id": "D2-05",
      "unit_name": "AI生成/修复工作流",
      "target_scale": "150–300",
      "coverage_tools": "synthesis tools、lint/fix"
    },
    "search": {
      "target_candidates": 300,
      "queries": [
        "[GH] seqera-platform",
        "[GH] latch",
        "[GH] wdl-aid",
        "[GH] snakemake-lint",
        "[GH] vscode-nextflow",
        "[GH] cwltool",
        "[GH] miniwdl",
        "[GH] womtool",
        "[GH] snakefmt",
        "[GH] nf-core",
        "[GH] workflow generation",
        "[GH] pipeline synthesis",
        "[GH] nextflow linter",
        "[GH] snakemake formatter",
        "[GH] wdl validator",
        "[GH] cwl validation",
        "[GH] ai pipeline generator",
        "[GH] workflow auto-fix",
        "[GH] static analysis bioinformatics",
        "[GH] code repair nextflow",
        "[GH] llm workflow agent",
        "[GH] pipeline optimizer",
        "[GH] workflow refactoring",
        "[GH] automated workflow testing",
        "[WEB] ai generated scientific workflows github",
        "[WEB] nextflow snakemake linter static analysis github",
        "[WEB] automated pipeline repair tools github",
        "[WEB] llm for bioinformatics workflows github",
        "[WEB] wdl cwl pipeline generator github"
      ],
      "total_candidates": 711,
      "tool_candidates": 424,
      "final_tools": 117
    }
  },
  "tools": [
    {
      "name": "DFFRAM",
      "one_line_profile": "Memory compiler for standard cell libraries",
      "detailed_description": "A compiler that generates memory macros using standard cells (flip-flops and latches), serving as a synthesis tool in digital integrated circuit design workflows.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "synthesis",
        "circuit_design"
      ],
      "application_level": "solver",
      "primary_language": "Verilog",
      "repo_url": "https://github.com/AUCOHL/DFFRAM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "eda",
        "memory-compiler",
        "synthesis"
      ],
      "id": 1
    },
    {
      "name": "iskyLIMS",
      "one_line_profile": "LIMS for NGS sample and analysis management",
      "detailed_description": "An open-source Laboratory Information Management System designed for managing Next Generation Sequencing samples, wet-lab workflows, and bioinformatics analysis services.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "lab_management",
        "sample_tracking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/BU-ISCIII/iskylims",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "lims",
        "ngs",
        "bioinformatics"
      ],
      "id": 2
    },
    {
      "name": "BioWardrobe-Airflow",
      "one_line_profile": "Airflow-based backend for BioWardrobe epigenomics analysis",
      "detailed_description": "A reimplementation of the BioWardrobe experimental data analysis platform's backend using Apache Airflow to orchestrate bioinformatics workflows for epigenomics data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "epigenomics_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "TSQL",
      "repo_url": "https://github.com/Barski-lab/biowardrobe-airflow-analysis",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "airflow",
        "bioinformatics",
        "epigenomics"
      ],
      "id": 3
    },
    {
      "name": "CWL HTS Pipelines",
      "one_line_profile": "CWL workflows for High-Throughput Sequencing data",
      "detailed_description": "A collection of Common Workflow Language (CWL) pipelines and wrappers for processing RNA-Seq, ChIP-Seq, and Germline Variant calling data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "sequence_analysis",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Common Workflow Language",
      "repo_url": "https://github.com/BiodataAnalysisGroup/CWL_HTS_pipelines",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cwl",
        "ngs",
        "bioinformatics"
      ],
      "id": 4
    },
    {
      "name": "BlenderRL",
      "one_line_profile": "Deep Reinforcement Learning interface for Blender",
      "detailed_description": "A tool that connects Blender's internal controls to external AI agents, enabling the use of Blender as a simulation environment for reinforcement learning research.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "simulation",
        "reinforcement_learning"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/BlenderAI/BlenderRL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "blender",
        "reinforcement-learning",
        "simulation"
      ],
      "id": 5
    },
    {
      "name": "CaPTk",
      "one_line_profile": "Cancer Imaging Phenomics Toolkit",
      "detailed_description": "A software platform for medical image analysis, featuring tools for segmentation, feature extraction, and predictive modeling of cancer imaging data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "image_analysis",
        "phenomics"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/CBICA/CaPTk",
      "help_website": [
        "https://cbica.github.io/CaPTk"
      ],
      "license": "NOASSERTION",
      "tags": [
        "medical-imaging",
        "cancer-research",
        "radiomics"
      ],
      "id": 6
    },
    {
      "name": "RobustFlow",
      "one_line_profile": "Framework for robust agentic workflow generation",
      "detailed_description": "A research tool designed to generate robust workflows using AI agents, addressing the challenges of reliability in automated agentic processes.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DEFENSE-SEU/RobustFlow",
      "help_website": [],
      "license": null,
      "tags": [
        "agentic-workflow",
        "ai-agents",
        "workflow-generation"
      ],
      "id": 7
    },
    {
      "name": "wdl-ci",
      "one_line_profile": "CI/CD tools for WDL workflows",
      "detailed_description": "A set of utilities to validate, lint, and test Workflow Description Language (WDL) files, facilitating Continuous Integration for scientific workflows.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_validation",
        "linting"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/DNAstack/wdl-ci",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "wdl",
        "ci-cd",
        "bioinformatics"
      ],
      "id": 8
    },
    {
      "name": "TOPMed GWAS WDL",
      "one_line_profile": "WDL workflows for GWAS analysis",
      "detailed_description": "A collection of WDL workflows implementing the University of Washington TOPMed DCC Best Practices for Genome-Wide Association Studies (GWAS).",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "gwas",
        "genetic_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/DataBiosphere/analysis_pipeline_WDL",
      "help_website": [],
      "license": null,
      "tags": [
        "wdl",
        "gwas",
        "genomics"
      ],
      "id": 9
    },
    {
      "name": "Strwythura",
      "one_line_profile": "Knowledge graph construction from unstructured data",
      "detailed_description": "A library for constructing knowledge graphs from unstructured data sources, implementing GraphRAG and ontology pipelines for domain-specific AI applications.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "graph_construction"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/DerwenAI/strwythura",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "graphrag",
        "unstructured-data"
      ],
      "id": 10
    },
    {
      "name": "VCF Annotation Pipeline",
      "one_line_profile": "Snakemake workflow for VCF annotation",
      "detailed_description": "A Snakemake-based workflow to filter and annotate Variant Call Format (VCF) data using tools like GATK4, SnpSift, and VEP.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "variant_annotation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ESR-NZ/vcf_annotation_pipeline",
      "help_website": [],
      "license": null,
      "tags": [
        "snakemake",
        "vcf",
        "bioinformatics"
      ],
      "id": 11
    },
    {
      "name": "TPOT",
      "one_line_profile": "Automated Machine Learning using Genetic Programming",
      "detailed_description": "A Python Automated Machine Learning (AutoML) tool that optimizes machine learning pipelines using genetic programming to discover the best model for a given dataset.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "automl",
        "pipeline_optimization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/EpistasisLab/tpot",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "automl",
        "genetic-programming",
        "data-science"
      ],
      "id": 12
    },
    {
      "name": "TPOT2",
      "one_line_profile": "Next-generation TPOT AutoML tool",
      "detailed_description": "The successor to TPOT, providing automated machine learning pipeline optimization with improved performance and features.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "automl",
        "pipeline_optimization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/EpistasisLab/tpot2",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "automl",
        "genetic-programming",
        "data-science"
      ],
      "id": 13
    },
    {
      "name": "AFlow",
      "one_line_profile": "Automated Agentic Workflow Generation Framework",
      "detailed_description": "A framework for automating the generation of agentic workflows, optimizing the construction of AI agent interactions for complex tasks.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/FoundationAgents/AFlow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agentic-workflow",
        "ai-agents",
        "workflow-automation"
      ],
      "id": 14
    },
    {
      "name": "HuntsmanCancerInstitute/Workflows",
      "one_line_profile": "Snakemake workflows for genomic analysis best practices",
      "detailed_description": "A collection of Snakemake workflows designed for best-practice genomic analysis, maintained by the Huntsman Cancer Institute. It provides reproducible pipelines for processing sequencing data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "genomic_analysis",
        "workflow_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/HuntsmanCancerInstitute/Workflows",
      "help_website": [],
      "license": null,
      "tags": [
        "snakemake",
        "genomics",
        "bioinformatics",
        "pipeline"
      ],
      "id": 15
    },
    {
      "name": "BRAD",
      "one_line_profile": "LLM-powered agent for bioinformatics tasks",
      "detailed_description": "A Language Model powered agent specifically designed for bioinformatics. It assists researchers by automating tasks, retrieving information, and potentially executing bioinformatics workflows through natural language interaction.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "bioinformatics_agent",
        "workflow_automation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Jpickard1/BRAD",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-agent",
        "bioinformatics",
        "automation"
      ],
      "id": 16
    },
    {
      "name": "InferOpt.jl",
      "one_line_profile": "Combinatorial optimization layers for machine learning pipelines",
      "detailed_description": "A Julia library that enables the integration of combinatorial optimization problems as differentiable layers within machine learning pipelines. This is crucial for 'decision-focused learning' in scientific modeling and operations research.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "optimization",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaDecisionFocusedLearning/InferOpt.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "optimization",
        "machine-learning",
        "combinatorial-optimization"
      ],
      "id": 17
    },
    {
      "name": "claude-scientific-skills",
      "one_line_profile": "Scientific toolset and skills for Claude LLM",
      "detailed_description": "A comprehensive set of tools and prompts designed to equip the Claude LLM with scientific capabilities, enabling it to perform tasks such as data analysis, mathematical reasoning, and scientific literature processing.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "scientific_reasoning",
        "data_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/K-Dense-AI/claude-scientific-skills",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "claude",
        "scientific-tools",
        "agent-skills"
      ],
      "id": 18
    },
    {
      "name": "DNAscan",
      "one_line_profile": "Fast and efficient bioinformatics pipeline for DNA NGS analysis",
      "detailed_description": "A bioinformatics pipeline optimized for speed and efficiency in analyzing DNA Next Generation Sequencing (NGS) data. It handles the entire workflow from raw data to variant calling with minimal computational resource usage.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "ngs_analysis",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/KHP-Informatics/DNAscan",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "ngs",
        "pipeline",
        "dna-analysis"
      ],
      "id": 19
    },
    {
      "name": "pytest-workflow",
      "one_line_profile": "Test framework for scientific pipelines (Nextflow/Snakemake)",
      "detailed_description": "A pytest plugin specifically designed to test computational pipelines and workflows (such as those written in Nextflow, Snakemake, or Cromwell). It allows researchers to ensure the reproducibility and correctness of scientific data processing pipelines.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "pipeline_testing",
        "quality_assurance"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/LUMC/pytest-workflow",
      "help_website": [
        "https://pytest-workflow.readthedocs.io/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "testing",
        "workflow",
        "nextflow",
        "snakemake",
        "reproducibility"
      ],
      "id": 20
    },
    {
      "name": "RefTrace",
      "one_line_profile": "Linter for Nextflow pipelines to ensure code quality and best practices",
      "detailed_description": "RefTrace is a static analysis tool designed specifically for Nextflow pipelines. It helps developers identify potential issues, enforce coding standards, and maintain the quality of scientific workflows written in Nextflow.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_linting",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/RefTrace/RefTrace",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "nextflow",
        "linting",
        "workflow-management"
      ],
      "id": 21
    },
    {
      "name": "doped",
      "one_line_profile": "Python toolkit for managing and analyzing solid-state defect calculations",
      "detailed_description": "doped is a Python package for the generation, pre-processing, and post-processing of defect supercell calculations in materials science. It streamlines the workflow for defect simulation, interfacing with codes like VASP.",
      "domains": [
        "D2",
        "M1"
      ],
      "subtask_category": [
        "simulation_setup",
        "defect_analysis",
        "structure_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SMTG-Bham/doped",
      "help_website": [
        "https://doped.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "materials-science",
        "defects",
        "dft",
        "vasp"
      ],
      "id": 22
    },
    {
      "name": "The AI Scientist",
      "one_line_profile": "Fully automated open-ended scientific discovery agent",
      "detailed_description": "The AI Scientist is a framework for automated scientific discovery. It uses LLMs to generate research ideas, write code, execute experiments, visualize results, and draft scientific papers, demonstrating an end-to-end AI-driven research workflow.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "hypothesis_generation",
        "experiment_automation",
        "paper_writing"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/SakanaAI/AI-Scientist",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "automated-science",
        "llm-agent",
        "research-automation"
      ],
      "id": 23
    },
    {
      "name": "snk",
      "one_line_profile": "Tool to convert Snakemake workflows into dynamically generated CLIs",
      "detailed_description": "snk allows users to install Snakemake workflows as Command Line Interfaces (CLIs). It simplifies the execution and management of scientific workflows by wrapping them in a user-friendly CLI structure.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_management",
        "cli_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Wytamma/snk",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "workflow",
        "cli"
      ],
      "id": 24
    },
    {
      "name": "linter-rules-for-nextflow",
      "one_line_profile": "Collection of linting rules for Nextflow DSL scripts",
      "detailed_description": "This repository provides a set of linter rules for Nextflow DSL, helping developers ensure their scientific workflows adhere to best practices and syntax correctness.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_linting",
        "code_quality"
      ],
      "application_level": "library",
      "primary_language": "Groovy",
      "repo_url": "https://github.com/awslabs/linter-rules-for-nextflow",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nextflow",
        "linting",
        "dsl"
      ],
      "id": 25
    },
    {
      "name": "wdl-aid",
      "one_line_profile": "Automatic documentation generator for WDL scientific workflows",
      "detailed_description": "A tool that automatically generates documentation for workflows written in the Workflow Description Language (WDL), facilitating the maintenance and sharing of bioinformatics pipelines.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "documentation",
        "workflow_management"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/biowdl/wdl-aid",
      "help_website": [
        "https://wdl-aid.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "wdl",
        "documentation",
        "bioinformatics",
        "workflow"
      ],
      "id": 26
    },
    {
      "name": "syn-cerebral-octa-seg",
      "one_line_profile": "Synthesis pipeline for blood vessel segmentation in cerebral 3D OCTA images",
      "detailed_description": "A deep learning-based synthesis pipeline designed for annotation-free segmentation of blood vessels in cerebral 3D Optical Coherence Tomography Angiography (OCTA) images.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "image_segmentation",
        "medical_imaging",
        "data_synthesis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bwittmann/syn-cerebral-octa-seg",
      "help_website": [],
      "license": null,
      "tags": [
        "octa",
        "segmentation",
        "medical-imaging",
        "synthesis"
      ],
      "id": 27
    },
    {
      "name": "miniwdl",
      "one_line_profile": "Local runner and developer toolkit for Workflow Description Language (WDL)",
      "detailed_description": "A local runner and developer toolkit for WDL, enabling the development and execution of bioinformatics and scientific workflows on local machines.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_execution",
        "pipeline_development"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chanzuckerberg/miniwdl",
      "help_website": [
        "https://miniwdl.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "wdl",
        "bioinformatics",
        "workflow-engine"
      ],
      "id": 28
    },
    {
      "name": "miniwdl-plugins",
      "one_line_profile": "Plugin collection for the miniwdl workflow runner",
      "detailed_description": "A collection of plugins that extend the functionality of miniwdl, providing additional capabilities for scientific workflow execution and management.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_extension"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chanzuckerberg/miniwdl-plugins",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "plugins",
        "bioinformatics"
      ],
      "id": 29
    },
    {
      "name": "doepipeline",
      "one_line_profile": "Pipeline optimization using Design of Experiments (DoE)",
      "detailed_description": "A Python package for optimizing scientific processing pipelines using statistical Design of Experiments (DoE) methodologies to find optimal parameters.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "pipeline_optimization",
        "experimental_design"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/clicumu/doepipeline",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "doe",
        "optimization",
        "pipeline"
      ],
      "id": 30
    },
    {
      "name": "wdl-cwl-translator",
      "one_line_profile": "Translator between WDL and CWL scientific workflow standards",
      "detailed_description": "A tool to translate workflows defined in WDL (Workflow Description Language) to CWL (Common Workflow Language), facilitating interoperability in bioinformatics.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_conversion"
      ],
      "application_level": "tool",
      "primary_language": "Common Workflow Language",
      "repo_url": "https://github.com/common-workflow-lab/wdl-cwl-translator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "wdl",
        "cwl",
        "bioinformatics",
        "interoperability"
      ],
      "id": 31
    },
    {
      "name": "cwltool",
      "one_line_profile": "Reference implementation of the Common Workflow Language (CWL)",
      "detailed_description": "The reference implementation for the Common Workflow Language, a standard for describing data analysis workflows used extensively in bioinformatics and other scientific fields.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_execution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/common-workflow-language/cwltool",
      "help_website": [
        "https://github.com/common-workflow-language/cwltool"
      ],
      "license": "Apache-2.0",
      "tags": [
        "cwl",
        "workflow-engine",
        "bioinformatics"
      ],
      "id": 32
    },
    {
      "name": "Auto-QChem",
      "one_line_profile": "Automated workflow for DFT calculations of organic molecules",
      "detailed_description": "An automated workflow tool for the generation, management, and storage of Density Functional Theory (DFT) calculations specifically for organic molecules.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "dft_calculation",
        "molecular_modeling",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/doyle-lab-ucla/auto-qchem",
      "help_website": [
        "https://auto-qchem.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "chemistry",
        "dft",
        "automation",
        "organic-molecules"
      ],
      "id": 33
    },
    {
      "name": "scrnaseq_processing_seurat",
      "one_line_profile": "Snakemake workflow for scRNA-seq data processing with Seurat",
      "detailed_description": "A Snakemake workflow module for processing and visualizing single-cell RNA-seq data, leveraging the Seurat R package for analysis.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "scrna_seq_analysis",
        "bioinformatics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/epigen/scrnaseq_processing_seurat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "seurat",
        "scrna-seq",
        "bioinformatics"
      ],
      "id": 34
    },
    {
      "name": "spilterlize_integrate",
      "one_line_profile": "Snakemake workflow for NGS count matrix preprocessing",
      "detailed_description": "A Snakemake workflow for splitting, filtering, normalizing, and integrating count matrices from Next-Generation Sequencing (NGS) experiments (RNA-seq, ATAC-seq, etc.).",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "ngs_preprocessing",
        "data_integration"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/epigen/spilterlize_integrate",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "ngs",
        "preprocessing",
        "bioinformatics"
      ],
      "id": 35
    },
    {
      "name": "WASS",
      "one_line_profile": "Stereo processing pipeline for sea waves 3D reconstruction",
      "detailed_description": "Waves Acquisition Stereo System (WASS) is an optimized stereo processing pipeline designed specifically for the 3D reconstruction of sea waves from image data, used in oceanography.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "3d_reconstruction",
        "oceanography",
        "image_processing"
      ],
      "application_level": "workflow",
      "primary_language": "C++",
      "repo_url": "https://github.com/fbergama/wass",
      "help_website": [
        "http://www.bergamasco.net/wass/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "oceanography",
        "stereo-vision",
        "3d-reconstruction"
      ],
      "id": 36
    },
    {
      "name": "SPORTS1.1",
      "one_line_profile": "Annotation pipeline optimized for rRNA- and tRNA-derived small RNAs",
      "detailed_description": "A small non-coding RNA annotation pipeline specifically optimized for analyzing rRNA- and tRNA-derived small RNAs from sequencing data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "sequence_annotation",
        "rna_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Perl",
      "repo_url": "https://github.com/junchaoshi/sports1.1",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bioinformatics",
        "rna-seq",
        "annotation"
      ],
      "id": 37
    },
    {
      "name": "AQME",
      "one_line_profile": "Automated Quantum Mechanical Environments for chemistry workflows",
      "detailed_description": "A workflow tool for automated quantum mechanical calculations, including conformer generation, QM input creation, and post-processing of outputs for computational chemistry.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "conformer_generation",
        "molecular_modeling",
        "qm_calculations"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/jvalegre/aqme",
      "help_website": [
        "https://aqme.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "computational-chemistry",
        "quantum-mechanics",
        "workflow-automation"
      ],
      "id": 38
    },
    {
      "name": "Latch SDK",
      "one_line_profile": "Python framework for defining and deploying bioinformatics workflows",
      "detailed_description": "A software development kit (SDK) that allows users to define, upload, and execute bioinformatics workflows on the LatchBio platform using Python.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "bioinformatics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/latchbio/latch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "workflow-management",
        "cloud-computing"
      ],
      "id": 39
    },
    {
      "name": "NIPT-human-genetics",
      "one_line_profile": "Workflow for analysis of ultra-low-pass NIPT sequencing data",
      "detailed_description": "A semi-automated bioinformatics workflow designed for the analysis of large-scale ultra-low-pass non-invasive prenatal test (NIPT) sequencing data in human genetic studies.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "variant_calling",
        "genomic_analysis",
        "prenatal_testing"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/liusylab/NIPT-human-genetics",
      "help_website": [],
      "license": null,
      "tags": [
        "genomics",
        "nipt",
        "bioinformatics-pipeline"
      ],
      "id": 40
    },
    {
      "name": "ERP_CORE",
      "one_line_profile": "Optimized paradigms and analysis pipelines for Event-Related Potential (ERP) research",
      "detailed_description": "A comprehensive resource and toolset for neuroscience research containing optimized experiment control scripts, data processing pipelines, and analysis scripts for 7 different ERP components.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "data_processing",
        "experiment_control",
        "neuroscience_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/lucklab/ERP_CORE",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "neuroscience",
        "erp",
        "eeg",
        "pipeline"
      ],
      "id": 41
    },
    {
      "name": "Magpie",
      "one_line_profile": "Synthetic data generation pipeline for aligning Large Language Models",
      "detailed_description": "A pipeline for generating high-quality synthetic alignment data by prompting aligned LLMs, serving as a methodology tool for AI research and model development.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "data_synthesis",
        "model_alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/magpie-align/magpie",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "synthetic-data",
        "llm-alignment",
        "ai-research"
      ],
      "id": 42
    },
    {
      "name": "nf-linter",
      "one_line_profile": "Linter for Nextflow scientific workflows",
      "detailed_description": "A code linting tool specifically designed for Nextflow, helping scientists maintain quality and correctness in their bioinformatics and data analysis pipelines.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_validation",
        "code_quality"
      ],
      "application_level": "solver",
      "primary_language": "Groovy",
      "repo_url": "https://github.com/mberacochea/nf-linter",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nextflow",
        "linter",
        "workflow-dev"
      ],
      "id": 43
    },
    {
      "name": "openMVG-LATCH",
      "one_line_profile": "OpenMVG extension with LATCH descriptors for 3D reconstruction",
      "detailed_description": "An extension of the OpenMVG library integrating LATCH descriptors and GPU-based matchers for photogrammetry and computer vision tasks in scientific imaging.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "image_processing",
        "3d_reconstruction",
        "photogrammetry"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/mdaiter/openMVG",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "computer-vision",
        "photogrammetry",
        "3d-reconstruction"
      ],
      "id": 44
    },
    {
      "name": "NUWA",
      "one_line_profile": "Unified 3D Transformer pipeline for visual synthesis",
      "detailed_description": "A multimodal pre-trained model and pipeline for generating and manipulating visual data (images/video), serving as a research tool for computer vision and generative AI.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "visual_synthesis",
        "generative_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/NUWA",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "computer-vision",
        "generative-ai",
        "transformer"
      ],
      "id": 45
    },
    {
      "name": "miniwdl-aws",
      "one_line_profile": "AWS backend extension for miniwdl workflow runner",
      "detailed_description": "A plugin for miniwdl that enables the execution of WDL-based scientific workflows on AWS Batch and EFS infrastructure.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_execution",
        "cloud_computing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/miniwdl-ext/miniwdl-aws",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "aws",
        "bioinformatics-workflow"
      ],
      "id": 46
    },
    {
      "name": "miniwdl-omics-run",
      "one_line_profile": "Launcher for WDL workflows on AWS HealthOmics",
      "detailed_description": "A utility to launch and manage WDL workflows specifically on AWS HealthOmics service, facilitating large-scale genomic data analysis.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_execution",
        "genomics_cloud"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/miniwdl-ext/miniwdl-omics-run",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "aws-healthomics",
        "wdl",
        "genomics"
      ],
      "id": 47
    },
    {
      "name": "Osprey",
      "one_line_profile": "Hyperparameter optimization for scientific machine learning pipelines",
      "detailed_description": "A tool for hyperparameter optimization designed for machine learning pipelines, particularly associated with the MSMBuilder ecosystem for molecular dynamics.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "hyperparameter_optimization",
        "model_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/msmbuilder/osprey",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "machine-learning",
        "molecular-dynamics",
        "optimization"
      ],
      "id": 48
    },
    {
      "name": "NeuralLambda",
      "one_line_profile": "Differentiable Lambda Calculus framework for neuro-symbolic AI",
      "detailed_description": "A research framework implementing fully differentiable Lambda Calculus and neural data structures (stacks, queues) for neuro-symbolic reasoning and modeling.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "scientific_modeling",
        "neuro_symbolic_reasoning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/neurallambda/neurallambda",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "neuro-symbolic",
        "differentiable-programming",
        "ai-research"
      ],
      "id": 49
    },
    {
      "name": "Nextflow Hyperopt",
      "one_line_profile": "Nextflow pipeline for ML hyperparameter optimization",
      "detailed_description": "A Nextflow-based pipeline designed to automate hyperparameter optimization for machine learning models, facilitating reproducible scientific ML workflows.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "hyperparameter_optimization",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/nextflow-io/hyperopt",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "nextflow",
        "machine-learning",
        "optimization"
      ],
      "id": 50
    },
    {
      "name": "vscode-dag-preview",
      "one_line_profile": "Nextflow DAG visualization for VSCode",
      "detailed_description": "A Visual Studio Code extension that renders the execution Directed Acyclic Graph (DAG) of Nextflow pipelines, aiding in scientific workflow design and debugging.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_visualization",
        "pipeline_development"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/nextflow-io/vscode-dag-preview",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nextflow",
        "visualization",
        "vscode-extension"
      ],
      "id": 51
    },
    {
      "name": "vscode-language-nextflow",
      "one_line_profile": "Nextflow language support for VSCode",
      "detailed_description": "A Visual Studio Code extension providing syntax highlighting and language support for Nextflow, essential for developing scientific workflows.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_development",
        "code_editing"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/nextflow-io/vscode-language-nextflow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nextflow",
        "ide-support",
        "bioinformatics"
      ],
      "id": 52
    },
    {
      "name": "nf-core/airrflow",
      "one_line_profile": "AIRR sequencing analysis pipeline",
      "detailed_description": "A bioinformatics pipeline for analyzing B-cell and T-cell Adaptive Immune Receptor Repertoire (AIRR) sequencing data using the Immcantation framework.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "immunology_analysis",
        "sequence_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/airrflow",
      "help_website": [
        "https://nf-co.re/airrflow"
      ],
      "license": "MIT",
      "tags": [
        "immunology",
        "airr-seq",
        "nextflow"
      ],
      "id": 53
    },
    {
      "name": "nf-core/ampliseq",
      "one_line_profile": "Amplicon sequencing analysis workflow",
      "detailed_description": "A pipeline for amplicon sequencing analysis (e.g., 16S, ITS) using DADA2 and QIIME2, widely used for microbiome studies.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "microbiome_analysis",
        "amplicon_sequencing"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/ampliseq",
      "help_website": [
        "https://nf-co.re/ampliseq"
      ],
      "license": "MIT",
      "tags": [
        "microbiome",
        "16s",
        "qiime2"
      ],
      "id": 54
    },
    {
      "name": "nf-core/atacseq",
      "one_line_profile": "ATAC-seq analysis pipeline",
      "detailed_description": "A comprehensive pipeline for ATAC-seq data analysis, including quality control, alignment, and peak calling for chromatin accessibility studies.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "epigenetics",
        "peak_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/atacseq",
      "help_website": [
        "https://nf-co.re/atacseq"
      ],
      "license": "MIT",
      "tags": [
        "atac-seq",
        "chromatin",
        "epigenetics"
      ],
      "id": 55
    },
    {
      "name": "nf-core/bacass",
      "one_line_profile": "Bacterial assembly and annotation pipeline",
      "detailed_description": "A pipeline for the assembly and annotation of bacterial genomes from sequencing data.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "genome_assembly",
        "genome_annotation"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/bacass",
      "help_website": [
        "https://nf-co.re/bacass"
      ],
      "license": "MIT",
      "tags": [
        "bacteria",
        "assembly",
        "annotation"
      ],
      "id": 56
    },
    {
      "name": "nf-core/bactmap",
      "one_line_profile": "Bacterial phylogeny mapping pipeline",
      "detailed_description": "A mapping-based pipeline for creating phylogenetic trees from bacterial whole genome sequences.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "phylogenetics",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/bactmap",
      "help_website": [
        "https://nf-co.re/bactmap"
      ],
      "license": "MIT",
      "tags": [
        "bacteria",
        "phylogeny",
        "mapping"
      ],
      "id": 57
    },
    {
      "name": "nf-core/bamtofastq",
      "one_line_profile": "BAM/CRAM to FASTQ conversion pipeline",
      "detailed_description": "A utility pipeline for converting aligned BAM or CRAM files back to FASTQ format, including quality control steps.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "file_conversion",
        "quality_control"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/bamtofastq",
      "help_website": [
        "https://nf-co.re/bamtofastq"
      ],
      "license": "MIT",
      "tags": [
        "format-conversion",
        "bam",
        "fastq"
      ],
      "id": 58
    },
    {
      "name": "nf-core/chipseq",
      "one_line_profile": "ChIP-seq analysis pipeline",
      "detailed_description": "A pipeline for ChIP-seq data analysis, covering QC, alignment, peak calling, and differential binding analysis.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "epigenetics",
        "peak_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/chipseq",
      "help_website": [
        "https://nf-co.re/chipseq"
      ],
      "license": "MIT",
      "tags": [
        "chip-seq",
        "protein-dna",
        "epigenetics"
      ],
      "id": 59
    },
    {
      "name": "nf-core/circdna",
      "one_line_profile": "Extrachromosomal circular DNA identification pipeline",
      "detailed_description": "A pipeline for identifying extrachromosomal circular DNA (ecDNA) from various sequencing data types (Circle-seq, WGS, ATAC-seq).",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "genomics",
        "structural_variant_detection"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/nf-core/circdna",
      "help_website": [
        "https://nf-co.re/circdna"
      ],
      "license": "MIT",
      "tags": [
        "ecdna",
        "cancer-genomics",
        "circle-seq"
      ],
      "id": 60
    },
    {
      "name": "nf-core/circrna",
      "one_line_profile": "Circular RNA analysis pipeline",
      "detailed_description": "A pipeline for the quantification, differential expression analysis, and miRNA target prediction of circular RNAs (circRNA) from RNA-Seq data.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "transcriptomics",
        "rna_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/circrna",
      "help_website": [
        "https://nf-co.re/circrna"
      ],
      "license": "MIT",
      "tags": [
        "circrna",
        "rna-seq",
        "transcriptomics"
      ],
      "id": 61
    },
    {
      "name": "nf-core/crisprseq",
      "one_line_profile": "CRISPR editing analysis pipeline",
      "detailed_description": "A pipeline for analyzing CRISPR gene editing experiments, supporting both targeted sequencing QC and pooled screening analysis.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "gene_editing_analysis",
        "crispr_screening"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/crisprseq",
      "help_website": [
        "https://nf-co.re/crisprseq"
      ],
      "license": "MIT",
      "tags": [
        "crispr",
        "gene-editing",
        "screening"
      ],
      "id": 62
    },
    {
      "name": "nf-core/cutandrun",
      "one_line_profile": "CUT&RUN and CUT&TAG analysis pipeline",
      "detailed_description": "A pipeline for analyzing CUT&RUN and CUT&TAG epigenomic data, including quality control, peak calling, and downstream analysis.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "epigenetics",
        "peak_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/cutandrun",
      "help_website": [
        "https://nf-co.re/cutandrun"
      ],
      "license": "MIT",
      "tags": [
        "cut-and-run",
        "epigenetics",
        "chromatin"
      ],
      "id": 63
    },
    {
      "name": "nf-core/demultiplex",
      "one_line_profile": "Sequencing data demultiplexing pipeline",
      "detailed_description": "A pipeline for demultiplexing raw sequencing data (BCL files) into FASTQ files, a critical initial step in sequencing workflows.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "demultiplexing",
        "data_preprocessing"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/demultiplex",
      "help_website": [
        "https://nf-co.re/demultiplex"
      ],
      "license": "MIT",
      "tags": [
        "sequencing",
        "demultiplexing",
        "bcl"
      ],
      "id": 64
    },
    {
      "name": "nf-core/differentialabundance",
      "one_line_profile": "Differential abundance analysis pipeline",
      "detailed_description": "A pipeline for performing differential abundance analysis on feature matrices (e.g., from RNA-seq), generating statistical reports and visualizations.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "statistical_analysis",
        "differential_expression"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/differentialabundance",
      "help_website": [
        "https://nf-co.re/differentialabundance"
      ],
      "license": "MIT",
      "tags": [
        "rna-seq",
        "statistics",
        "differential-analysis"
      ],
      "id": 65
    },
    {
      "name": "nf-core/eager",
      "one_line_profile": "Ancient DNA analysis pipeline",
      "detailed_description": "A fully reproducible pipeline designed for the specific challenges of ancient DNA (aDNA) analysis, including damage assessment and authentication.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "ancient_dna",
        "paleogenomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/eager",
      "help_website": [
        "https://nf-co.re/eager"
      ],
      "license": "MIT",
      "tags": [
        "ancient-dna",
        "paleogenomics",
        "archaeology"
      ],
      "id": 66
    },
    {
      "name": "nf-core/epitopeprediction",
      "one_line_profile": "Bioinformatics pipeline for epitope prediction and annotation",
      "detailed_description": "A best-practice analysis pipeline for epitope prediction and annotation, utilizing various prediction methods to identify potential epitopes in protein sequences.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Immunology"
      ],
      "subtask_category": [
        "epitope_prediction",
        "sequence_annotation"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/epitopeprediction",
      "help_website": [
        "https://nf-co.re/epitopeprediction"
      ],
      "license": "MIT",
      "tags": [
        "epitope",
        "immunology",
        "prediction",
        "pipeline"
      ],
      "id": 67
    },
    {
      "name": "nf-core/fetchngs",
      "one_line_profile": "Pipeline to fetch metadata and raw FastQ files from public databases",
      "detailed_description": "A pipeline designed to retrieve sequencing data (FastQ) and metadata from public archives like SRA, ENA, and DDBJ, facilitating data acquisition for downstream analysis.",
      "domains": [
        "D2",
        "Bioinformatics"
      ],
      "subtask_category": [
        "data_retrieval",
        "metadata_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/fetchngs",
      "help_website": [
        "https://nf-co.re/fetchngs"
      ],
      "license": "MIT",
      "tags": [
        "sra",
        "ena",
        "fastq",
        "data-acquisition"
      ],
      "id": 68
    },
    {
      "name": "nf-core/funcscan",
      "one_line_profile": "Screening pipeline for functional and natural product gene sequences",
      "detailed_description": "A pipeline for screening (meta-)genomic data to identify functional genes and natural product biosynthetic gene clusters (BGCs).",
      "domains": [
        "D2",
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "functional_screening",
        "gene_mining"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/funcscan",
      "help_website": [
        "https://nf-co.re/funcscan"
      ],
      "license": "MIT",
      "tags": [
        "metagenomics",
        "biosynthetic-gene-clusters",
        "screening"
      ],
      "id": 69
    },
    {
      "name": "nf-core/genomeassembler",
      "one_line_profile": "Assembly pipeline for haploid/unphased genomes using long reads",
      "detailed_description": "A pipeline for the assembly and scaffolding of haploid or unphased genomes using long-read sequencing data from Oxford Nanopore (ONT) or PacBio HiFi.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "genome_assembly",
        "scaffolding"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/genomeassembler",
      "help_website": [
        "https://nf-co.re/genomeassembler"
      ],
      "license": "MIT",
      "tags": [
        "assembly",
        "long-read",
        "pacbio",
        "nanopore"
      ],
      "id": 70
    },
    {
      "name": "nf-core/hic",
      "one_line_profile": "Analysis pipeline for Chromosome Conformation Capture (Hi-C) data",
      "detailed_description": "A pipeline for processing Hi-C data, including mapping, filtering, matrix generation, and quality control to analyze 3D genome organization.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "hic_analysis",
        "chromatin_structure"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/hic",
      "help_website": [
        "https://nf-co.re/hic"
      ],
      "license": "MIT",
      "tags": [
        "hic",
        "chromatin",
        "3d-genome"
      ],
      "id": 71
    },
    {
      "name": "nf-core/hlatyping",
      "one_line_profile": "Precision HLA typing pipeline from NGS data",
      "detailed_description": "A bioinformatics pipeline for Human Leukocyte Antigen (HLA) typing using next-generation sequencing data, supporting various HLA typing tools.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Immunogenomics"
      ],
      "subtask_category": [
        "hla_typing",
        "genotyping"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/hlatyping",
      "help_website": [
        "https://nf-co.re/hlatyping"
      ],
      "license": "MIT",
      "tags": [
        "hla",
        "immunology",
        "sequencing"
      ],
      "id": 72
    },
    {
      "name": "nf-core/isoseq",
      "one_line_profile": "Genome annotation pipeline using PacBio Iso-Seq data",
      "detailed_description": "A pipeline for processing PacBio Iso-Seq data, taking raw subreads to generate Full Length Non-Chimeric (FLNC) sequences and producing genome annotations.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "genome_annotation",
        "transcriptomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/isoseq",
      "help_website": [
        "https://nf-co.re/isoseq"
      ],
      "license": "MIT",
      "tags": [
        "isoseq",
        "pacbio",
        "annotation"
      ],
      "id": 73
    },
    {
      "name": "nf-core/mag",
      "one_line_profile": "Assembly and binning pipeline for metagenomes",
      "detailed_description": "A comprehensive pipeline for the assembly, binning, and taxonomic classification of metagenomic data, supporting both short and long reads.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Metagenomics"
      ],
      "subtask_category": [
        "metagenome_assembly",
        "binning"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/mag",
      "help_website": [
        "https://nf-co.re/mag"
      ],
      "license": "MIT",
      "tags": [
        "metagenomics",
        "assembly",
        "binning"
      ],
      "id": 74
    },
    {
      "name": "nf-core/metatdenovo",
      "one_line_profile": "De novo assembly and annotation for metatranscriptomics/metagenomics",
      "detailed_description": "A pipeline for the de novo assembly and annotation of metatranscriptomic or metagenomic data, covering prokaryotic, eukaryotic, and viral sequences.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Metagenomics"
      ],
      "subtask_category": [
        "assembly",
        "annotation"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/metatdenovo",
      "help_website": [
        "https://nf-co.re/metatdenovo"
      ],
      "license": "MIT",
      "tags": [
        "metatranscriptomics",
        "de-novo-assembly",
        "annotation"
      ],
      "id": 75
    },
    {
      "name": "nf-core/methylseq",
      "one_line_profile": "Methylation (Bisulfite-Sequencing) analysis pipeline",
      "detailed_description": "A pipeline for analyzing Bisulfite-Sequencing data to detect DNA methylation, utilizing tools like Bismark, bwa-meth, and MethylDackel.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Epigenetics"
      ],
      "subtask_category": [
        "methylation_analysis",
        "epigenetics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/methylseq",
      "help_website": [
        "https://nf-co.re/methylseq"
      ],
      "license": "MIT",
      "tags": [
        "methylation",
        "bisulfite-sequencing",
        "epigenetics"
      ],
      "id": 76
    },
    {
      "name": "nf-core/mhcquant",
      "one_line_profile": "Pipeline to identify and quantify MHC eluted peptides",
      "detailed_description": "A bioinformatics pipeline to identify and quantify peptides eluted from Major Histocompatibility Complex (MHC) molecules using mass spectrometry raw data.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Proteomics"
      ],
      "subtask_category": [
        "peptide_identification",
        "quantification"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/mhcquant",
      "help_website": [
        "https://nf-co.re/mhcquant"
      ],
      "license": "MIT",
      "tags": [
        "immunopeptidomics",
        "mass-spectrometry",
        "mhc"
      ],
      "id": 77
    },
    {
      "name": "nf-core/multiplesequencealign",
      "one_line_profile": "Pipeline to run and evaluate Multiple Sequence Alignment (MSA) methods",
      "detailed_description": "A pipeline designed to run various Multiple Sequence Alignment (MSA) tools and systematically evaluate their performance.",
      "domains": [
        "D2",
        "Bioinformatics"
      ],
      "subtask_category": [
        "msa",
        "benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/multiplesequencealign",
      "help_website": [
        "https://nf-co.re/multiplesequencealign"
      ],
      "license": "MIT",
      "tags": [
        "alignment",
        "msa",
        "evaluation"
      ],
      "id": 78
    },
    {
      "name": "nf-core/nanoseq",
      "one_line_profile": "Nanopore sequencing data processing pipeline",
      "detailed_description": "A pipeline for analyzing Oxford Nanopore sequencing data, performing demultiplexing, quality control, and alignment.",
      "domains": [
        "D2",
        "Bioinformatics"
      ],
      "subtask_category": [
        "sequencing_processing",
        "alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/nanoseq",
      "help_website": [
        "https://nf-co.re/nanoseq"
      ],
      "license": "MIT",
      "tags": [
        "nanopore",
        "qc",
        "alignment"
      ],
      "id": 79
    },
    {
      "name": "nf-core/oncoanalyser",
      "one_line_profile": "Comprehensive cancer DNA/RNA analysis pipeline",
      "detailed_description": "A pipeline for comprehensive analysis of cancer genomics data, integrating DNA and RNA sequencing analysis for oncology research.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Oncology"
      ],
      "subtask_category": [
        "cancer_genomics",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/oncoanalyser",
      "help_website": [
        "https://nf-co.re/oncoanalyser"
      ],
      "license": "MIT",
      "tags": [
        "cancer",
        "genomics",
        "oncology"
      ],
      "id": 80
    },
    {
      "name": "nf-core/pangenome",
      "one_line_profile": "Pipeline to construct pangenome graphs from sequences",
      "detailed_description": "A pipeline that renders a collection of genomic sequences into a pangenome graph, facilitating pangenomic analysis.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Pangenomics"
      ],
      "subtask_category": [
        "pangenome_construction",
        "graph_genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/pangenome",
      "help_website": [
        "https://nf-co.re/pangenome"
      ],
      "license": "MIT",
      "tags": [
        "pangenome",
        "graph",
        "genomics"
      ],
      "id": 81
    },
    {
      "name": "nf-core/pathogensurveillance",
      "one_line_profile": "Pathogen surveillance pipeline using genomics",
      "detailed_description": "A pipeline for the surveillance of pathogens using population genomics and sequencing data, aiding in epidemiological tracking.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Epidemiology"
      ],
      "subtask_category": [
        "pathogen_surveillance",
        "genomic_epidemiology"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/pathogensurveillance",
      "help_website": [
        "https://nf-co.re/pathogensurveillance"
      ],
      "license": "MIT",
      "tags": [
        "pathogen",
        "surveillance",
        "epidemiology"
      ],
      "id": 82
    },
    {
      "name": "nf-core/proteinfold",
      "one_line_profile": "Protein 3D structure prediction pipeline",
      "detailed_description": "A pipeline for predicting protein 3D structures from sequences, integrating tools like AlphaFold2 and ColabFold.",
      "domains": [
        "D2",
        "D2-05",
        "Bioinformatics",
        "Structural Biology"
      ],
      "subtask_category": [
        "structure_prediction",
        "folding"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/proteinfold",
      "help_website": [
        "https://nf-co.re/proteinfold"
      ],
      "license": "MIT",
      "tags": [
        "protein-structure",
        "alphafold",
        "prediction"
      ],
      "id": 83
    },
    {
      "name": "nf-core/proteomicslfq",
      "one_line_profile": "Proteomics label-free quantification (LFQ) pipeline",
      "detailed_description": "A pipeline for label-free quantification (LFQ) analysis of proteomics data derived from mass spectrometry.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Proteomics"
      ],
      "subtask_category": [
        "quantification",
        "proteomics_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/proteomicslfq",
      "help_website": [
        "https://nf-co.re/proteomicslfq"
      ],
      "license": "MIT",
      "tags": [
        "proteomics",
        "lfq",
        "mass-spectrometry"
      ],
      "id": 84
    },
    {
      "name": "nf-core/raredisease",
      "one_line_profile": "Variant calling pipeline for rare disease genomics",
      "detailed_description": "A pipeline to call and score variants from Whole Genome Sequencing (WGS) or Whole Exome Sequencing (WES) data for rare disease diagnosis.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Medical Genetics"
      ],
      "subtask_category": [
        "variant_calling",
        "disease_diagnosis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/raredisease",
      "help_website": [
        "https://nf-co.re/raredisease"
      ],
      "license": "MIT",
      "tags": [
        "rare-disease",
        "variant-calling",
        "wgs"
      ],
      "id": 85
    },
    {
      "name": "nf-core/readsimulator",
      "one_line_profile": "Pipeline to simulate sequencing reads",
      "detailed_description": "A pipeline for simulating various types of sequencing data, including Amplicon, Target Capture, Metagenome, and Whole Genome reads, useful for benchmarking and testing.",
      "domains": [
        "D2",
        "Bioinformatics"
      ],
      "subtask_category": [
        "data_simulation",
        "read_generation"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/readsimulator",
      "help_website": [
        "https://nf-co.re/readsimulator"
      ],
      "license": "MIT",
      "tags": [
        "simulation",
        "ngs",
        "synthetic-data"
      ],
      "id": 86
    },
    {
      "name": "nf-core/rnafusion",
      "one_line_profile": "RNA-seq pipeline for gene fusion detection",
      "detailed_description": "A pipeline designed for the detection of gene fusions from RNA-seq data, utilizing multiple fusion detection tools.",
      "domains": [
        "D2",
        "Bioinformatics"
      ],
      "subtask_category": [
        "fusion_detection",
        "rna_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/rnafusion",
      "help_website": [
        "https://nf-co.re/rnafusion"
      ],
      "license": "MIT",
      "tags": [
        "gene-fusion",
        "rna-seq",
        "detection"
      ],
      "id": 87
    },
    {
      "name": "nf-core/rnaseq",
      "one_line_profile": "Comprehensive RNA sequencing analysis pipeline",
      "detailed_description": "A standard RNA-seq analysis pipeline that performs alignment (STAR, HISAT2), quantification (Salmon, RSEM), and extensive quality control.",
      "domains": [
        "D2",
        "Bioinformatics"
      ],
      "subtask_category": [
        "rna_seq_analysis",
        "expression_quantification"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/rnaseq",
      "help_website": [
        "https://nf-co.re/rnaseq"
      ],
      "license": "MIT",
      "tags": [
        "rna-seq",
        "transcriptomics",
        "quantification"
      ],
      "id": 88
    },
    {
      "name": "nf-core/rnasplice",
      "one_line_profile": "RNA-seq alternative splicing analysis pipeline",
      "detailed_description": "A bioinformatics pipeline specifically designed for analyzing alternative splicing events in RNA-seq data.",
      "domains": [
        "D2",
        "Bioinformatics"
      ],
      "subtask_category": [
        "splicing_analysis",
        "transcriptomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/rnasplice",
      "help_website": [
        "https://nf-co.re/rnasplice"
      ],
      "license": "MIT",
      "tags": [
        "alternative-splicing",
        "rna-seq",
        "splicing"
      ],
      "id": 89
    },
    {
      "name": "nf-core/rnavar",
      "one_line_profile": "RNA variant calling pipeline using GATK",
      "detailed_description": "A pipeline for calling variants from RNA-seq data, following GATK best practices for RNA variant discovery.",
      "domains": [
        "D2",
        "Bioinformatics"
      ],
      "subtask_category": [
        "variant_calling",
        "rna_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/rnavar",
      "help_website": [
        "https://nf-co.re/rnavar"
      ],
      "license": "MIT",
      "tags": [
        "variant-calling",
        "rna-seq",
        "gatk"
      ],
      "id": 90
    },
    {
      "name": "nf-core/sarek",
      "one_line_profile": "Germline and somatic variant calling pipeline",
      "detailed_description": "A comprehensive pipeline for detecting germline or somatic variants from Whole Genome Sequencing (WGS) or targeted sequencing data.",
      "domains": [
        "D2",
        "Bioinformatics"
      ],
      "subtask_category": [
        "variant_calling",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/sarek",
      "help_website": [
        "https://nf-co.re/sarek"
      ],
      "license": "MIT",
      "tags": [
        "wgs",
        "variant-calling",
        "somatic"
      ],
      "id": 91
    },
    {
      "name": "nf-core/scdownstream",
      "one_line_profile": "Single-cell transcriptomics downstream analysis pipeline",
      "detailed_description": "A pipeline for the downstream analysis of single-cell transcriptomics data, including quality control, integration, and visualization.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Single-cell"
      ],
      "subtask_category": [
        "single_cell_analysis",
        "qc"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/scdownstream",
      "help_website": [
        "https://nf-co.re/scdownstream"
      ],
      "license": "MIT",
      "tags": [
        "single-cell",
        "transcriptomics",
        "downstream"
      ],
      "id": 92
    },
    {
      "name": "nf-core/scnanoseq",
      "one_line_profile": "Single-cell Nanopore sequencing pipeline",
      "detailed_description": "A pipeline for analyzing single-cell or single-nuclei sequencing data derived from Oxford Nanopore and 10X Genomics protocols.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Single-cell"
      ],
      "subtask_category": [
        "single_cell_analysis",
        "nanopore_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/scnanoseq",
      "help_website": [
        "https://nf-co.re/scnanoseq"
      ],
      "license": "MIT",
      "tags": [
        "single-cell",
        "nanopore",
        "10x"
      ],
      "id": 93
    },
    {
      "name": "nf-core/scrnaseq",
      "one_line_profile": "Single-cell RNA-Seq analysis pipeline",
      "detailed_description": "A pipeline for processing single-cell RNA-Seq data from barcode-based protocols (e.g., 10x, DropSeq), including alignment and quantification.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Single-cell"
      ],
      "subtask_category": [
        "single_cell_processing",
        "quantification"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/scrnaseq",
      "help_website": [
        "https://nf-co.re/scrnaseq"
      ],
      "license": "MIT",
      "tags": [
        "single-cell",
        "rna-seq",
        "quantification"
      ],
      "id": 94
    },
    {
      "name": "nf-core/smrnaseq",
      "one_line_profile": "Small-RNA sequencing analysis pipeline",
      "detailed_description": "A pipeline for the analysis of small-RNA sequencing data, such as miRNA, including trimming, alignment, and quantification.",
      "domains": [
        "D2",
        "Bioinformatics"
      ],
      "subtask_category": [
        "small_rna_analysis",
        "mirna_profiling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/smrnaseq",
      "help_website": [
        "https://nf-co.re/smrnaseq"
      ],
      "license": "MIT",
      "tags": [
        "small-rna",
        "mirna",
        "sequencing"
      ],
      "id": 95
    },
    {
      "name": "nf-core/spatialvi",
      "one_line_profile": "Spatial transcriptomics processing pipeline",
      "detailed_description": "A pipeline for processing spatially-resolved gene counts and image data, specifically designed for 10x Genomics Visium technology.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Spatial Transcriptomics"
      ],
      "subtask_category": [
        "spatial_analysis",
        "image_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/spatialvi",
      "help_website": [
        "https://nf-co.re/spatialvi"
      ],
      "license": "MIT",
      "tags": [
        "spatial-transcriptomics",
        "visium",
        "10x"
      ],
      "id": 96
    },
    {
      "name": "nf-core/taxprofiler",
      "one_line_profile": "Multi-taxonomic profiling pipeline for metagenomics",
      "detailed_description": "A highly parallelized pipeline for multi-taxonomic profiling of shotgun metagenomic data, supporting both short and long reads.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Metagenomics"
      ],
      "subtask_category": [
        "taxonomic_profiling",
        "metagenomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/taxprofiler",
      "help_website": [
        "https://nf-co.re/taxprofiler"
      ],
      "license": "MIT",
      "tags": [
        "taxonomy",
        "profiling",
        "metagenomics"
      ],
      "id": 97
    },
    {
      "name": "nf-core/variantbenchmarking",
      "one_line_profile": "Pipeline for benchmarking variant calling methods",
      "detailed_description": "A pipeline designed to evaluate and validate the accuracy and performance of various variant calling methods in genomic research.",
      "domains": [
        "D2",
        "Bioinformatics"
      ],
      "subtask_category": [
        "benchmarking",
        "method_evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/variantbenchmarking",
      "help_website": [
        "https://nf-co.re/variantbenchmarking"
      ],
      "license": "MIT",
      "tags": [
        "benchmarking",
        "variant-calling",
        "validation"
      ],
      "id": 98
    },
    {
      "name": "nf-core/viralrecon",
      "one_line_profile": "Viral assembly and variant calling pipeline",
      "detailed_description": "A pipeline for the assembly and intrahost/low-frequency variant calling of viral samples, widely used for SARS-CoV-2 analysis.",
      "domains": [
        "D2",
        "Bioinformatics",
        "Virology"
      ],
      "subtask_category": [
        "viral_assembly",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/viralrecon",
      "help_website": [
        "https://nf-co.re/viralrecon"
      ],
      "license": "MIT",
      "tags": [
        "virus",
        "assembly",
        "covid-19"
      ],
      "id": 99
    },
    {
      "name": "HiC-Pro",
      "one_line_profile": "Optimized pipeline for Hi-C data processing",
      "detailed_description": "An optimized and flexible pipeline for processing Hi-C data, from raw reads to normalized contact maps.",
      "domains": [
        "D2",
        "Bioinformatics"
      ],
      "subtask_category": [
        "hic_processing",
        "contact_map_generation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/nservant/HiC-Pro",
      "help_website": [
        "https://nservant.github.io/HiC-Pro/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "hic",
        "genomics",
        "pipeline"
      ],
      "id": 100
    },
    {
      "name": "MinerU",
      "one_line_profile": "High-quality data extraction tool for complex scientific documents",
      "detailed_description": "A comprehensive data extraction tool designed to transform complex documents like PDFs (containing formulas, tables, and diagrams) into LLM-ready formats (Markdown/JSON), specifically optimized for scientific literature mining and agentic workflows.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "data_extraction",
        "literature_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/opendatalab/MinerU",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "pdf-parsing",
        "ocr",
        "llm-data-prep",
        "scientific-literature"
      ],
      "id": 101
    },
    {
      "name": "neural-imaging",
      "one_line_profile": "Modeling and optimization toolbox for photo acquisition pipelines",
      "detailed_description": "A Python toolbox for modeling, simulation, and optimization of photo acquisition and distribution pipelines, covering camera ISP, compression, forensics, and manipulation detection. Used in CVPR/ICLR research.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "imaging_pipeline_simulation",
        "image_forensics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pkorus/neural-imaging",
      "help_website": [],
      "license": null,
      "tags": [
        "computational-photography",
        "isp",
        "image-processing",
        "simulation"
      ],
      "id": 102
    },
    {
      "name": "nf-aggregate",
      "one_line_profile": "Metrics aggregation pipeline for Nextflow runs",
      "detailed_description": "A specialized pipeline designed to aggregate pertinent metrics across multiple pipeline runs on the Seqera Platform, aiding in the monitoring and optimization of scientific workflows.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_monitoring",
        "metrics_aggregation"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/seqeralabs/nf-aggregate",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "nextflow",
        "workflow-metrics",
        "bioinformatics-ops"
      ],
      "id": 103
    },
    {
      "name": "Versatile-OCR-Program",
      "one_line_profile": "Multi-modal OCR pipeline for scientific documents",
      "detailed_description": "An OCR pipeline optimized for machine learning training data preparation, capable of handling text, figures, math formulas, tables, and diagrams, suitable for extracting structured data from scientific papers.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "ocr",
        "data_extraction"
      ],
      "application_level": "pipeline",
      "primary_language": "Python",
      "repo_url": "https://github.com/ses4255/Versatile-OCR-Program",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ocr",
        "scientific-data-extraction",
        "multimodal"
      ],
      "id": 104
    },
    {
      "name": "DermSynth3D",
      "one_line_profile": "Synthesis pipeline for dermatological images",
      "detailed_description": "A data generation pipeline for creating photorealistic, in-the-wild synthetic dermatological data with rich multi-task annotations, supporting skin-analysis research and model training.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "image_synthesis",
        "data_augmentation"
      ],
      "application_level": "pipeline",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/sfu-mial/DermSynth3D",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "medical-imaging",
        "dermatology",
        "synthetic-data",
        "3d-synthesis"
      ],
      "id": 105
    },
    {
      "name": "auto-docking-vessels",
      "one_line_profile": "Simulation environment for autonomous robotic vessels",
      "detailed_description": "A Webots-based simulation environment and vision-based autonomous docking algorithm for robotic vessels, supporting research in marine robotics and control systems.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "robotics_simulation",
        "autonomous_control"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/silvery107/auto-docking-vessels",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "robotics",
        "simulation",
        "webots",
        "marine-systems"
      ],
      "id": 106
    },
    {
      "name": "snakefmt",
      "one_line_profile": "Code formatter for Snakemake workflows",
      "detailed_description": "The standard code formatter for Snakemake files, essential for maintaining code quality and readability in scientific workflow development.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "code_formatting",
        "workflow_maintenance"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake/snakefmt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "formatter",
        "workflow-dev-tools"
      ],
      "id": 107
    },
    {
      "name": "genpei",
      "one_line_profile": "GA4GH Workflow Execution Service implementation",
      "detailed_description": "A microservice implementation of the GA4GH (Global Alliance for Genomics and Health) Workflow Execution Service Standard, facilitating standardized execution of genomics workflows.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_execution",
        "genomics_standard"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/suecharo/genpei",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ga4gh",
        "genomics",
        "workflow-service",
        "wes"
      ],
      "id": 108
    },
    {
      "name": "4KAgent",
      "one_line_profile": "Agentic image super-resolution and restoration tool",
      "detailed_description": "An intelligent computer vision agent (NeurIPS 2025) capable of restoring images to 4K resolution, applicable in scientific imaging enhancement and microscopy data restoration.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "image_restoration",
        "super_resolution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/taco-group/4KAgent",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "computer-vision",
        "image-restoration",
        "super-resolution",
        "agentic-workflow"
      ],
      "id": 109
    },
    {
      "name": "HLS_FPGA",
      "one_line_profile": "High-Level Synthesis projects for signal processing",
      "detailed_description": "A collection of real-time High-Level Synthesis (HLS) compute cores and pipelines for UltraScale+ FPGAs, focusing on signal processing for SDR and 5G applications.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "signal_processing",
        "fpga_synthesis"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/taitashaw/HLS_FPGA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fpga",
        "hls",
        "signal-processing",
        "sdr"
      ],
      "id": 110
    },
    {
      "name": "Tuplex",
      "one_line_profile": "Parallel big data processing framework for data science",
      "detailed_description": "A high-performance parallel data processing framework that compiles Python data science pipelines into optimized LLVM bytecode, accelerating data cleaning and transformation tasks.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "data_processing",
        "pipeline_optimization"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/tuplex/tuplex",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-science",
        "etl",
        "compiler",
        "parallel-computing"
      ],
      "id": 111
    },
    {
      "name": "DocETL",
      "one_line_profile": "Agentic LLM-powered data processing system",
      "detailed_description": "A system for defining and executing complex data processing and ETL pipelines using LLM agents, suitable for unstructured scientific data curation and transformation.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "data_etl",
        "data_curation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/ucbepic/docetl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "etl",
        "llm-agents",
        "data-processing",
        "unstructured-data"
      ],
      "id": 112
    },
    {
      "name": "workflow-testing",
      "one_line_profile": "Automated testing tool for Galaxy workflows",
      "detailed_description": "A utility for automated testing of scientific workflows against the Galaxy platform, ensuring reproducibility and correctness of bioinformatics pipelines.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_testing",
        "quality_assurance"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/usegalaxy-eu/workflow-testing",
      "help_website": [],
      "license": null,
      "tags": [
        "galaxy",
        "bioinformatics",
        "workflow-testing"
      ],
      "id": 113
    },
    {
      "name": "seq2science",
      "one_line_profile": "Automated preprocessing workflows for NGS data",
      "detailed_description": "A comprehensive pipeline for automated and customizable preprocessing of Next-Generation Sequencing data, supporting ATAC-seq, ChIP-seq, and RNA-seq workflows.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "ngs_preprocessing",
        "bioinformatics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/vanheeringen-lab/seq2science",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ngs",
        "rna-seq",
        "atac-seq",
        "snakemake"
      ],
      "id": 114
    },
    {
      "name": "analysis-wdls",
      "one_line_profile": "Scalable genomic analysis pipelines using WDL",
      "detailed_description": "A collection of scalable genomic analysis pipelines written in Workflow Description Language (WDL), covering alignment, variant calling, and quality control tasks for oncology research.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genomic_analysis",
        "variant_calling",
        "workflow_management"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/wustl-oncology/analysis-wdls",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "genomics",
        "wdl",
        "bioinformatics",
        "pipeline"
      ],
      "id": 115
    },
    {
      "name": "PHOTONAI",
      "one_line_profile": "High-level Python API for designing and optimizing machine learning pipelines",
      "detailed_description": "A high-level machine learning library designed for rapid prototyping and optimization of pipelines in scientific research, with specific features for neuroimaging and medical data analysis.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "pipeline_optimization",
        "model_selection",
        "machine_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wwu-mmll/photonai",
      "help_website": [
        "https://www.photon-ai.com"
      ],
      "license": "GPL-3.0",
      "tags": [
        "machine-learning",
        "neuroimaging",
        "pipeline-optimization",
        "scientific-research"
      ],
      "id": 116
    },
    {
      "name": "WorfBench",
      "one_line_profile": "Benchmark for Agentic Workflow Generation",
      "detailed_description": "A benchmarking framework designed to evaluate the capability of Large Language Models (LLMs) in generating agentic workflows, supporting research in AI-driven workflow synthesis and automation.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_generation",
        "benchmarking",
        "agent_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/WorfBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agents",
        "workflow-generation",
        "benchmark",
        "llm"
      ],
      "id": 117
    }
  ]
}