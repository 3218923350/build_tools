{
  "leaf_cluster_name": "科研领域模型训练与微调生态",
  "domain": "AI Toolchain",
  "typical_objects": "domain corpora",
  "task_chain": "数据→训练→微调→对齐→评测→发布",
  "tool_form": "训练栈 + 数据管线 + serving",
  "total_tools": 1358,
  "tools": [
    {
      "name": "AdaptiveCpp",
      "one_line_profile": "Independent open-source compiler for C++-based heterogeneous programming models (SYCL, CUDA, HIP)",
      "detailed_description": "AdaptiveCpp (formerly hipSYCL) is a community-driven compiler infrastructure that enables C++ applications to run on hardware from all major vendors (NVIDIA, AMD, Intel) using standard parallelism models like SYCL and C++17/20 parallel algorithms. It serves as a foundational tool for high-performance scientific computing and AI acceleration.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "compilation",
        "heterogeneous_computing"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/AdaptiveCpp/AdaptiveCpp",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "sycl",
        "compiler",
        "gpu-acceleration",
        "hpc"
      ],
      "id": 1
    },
    {
      "name": "AgentFly",
      "one_line_profile": "Scalable and extensible reinforcement learning framework for Large Language Model agents",
      "detailed_description": "AgentFly is a research framework designed for training and evaluating LLM agents using reinforcement learning. It supports scalable training pipelines and provides extensibility for developing new agent-based RL algorithms.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "agent_training",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Agent-One-Lab/AgentFly",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reinforcement-learning",
        "llm-agents",
        "training-framework"
      ],
      "id": 2
    },
    {
      "name": "AgileRL",
      "one_line_profile": "Reinforcement learning framework with evolutionary hyperparameter optimization",
      "detailed_description": "AgileRL is a deep reinforcement learning library focused on RLOps and efficiency. It implements evolutionary algorithms for hyperparameter optimization during training, allowing for faster convergence and better model performance in scientific and control tasks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "hyperparameter_optimization",
        "training_framework"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AgileRL/AgileRL",
      "help_website": [
        "https://docs.agilerl.com"
      ],
      "license": "Apache-2.0",
      "tags": [
        "reinforcement-learning",
        "evolutionary-algorithms",
        "rlops"
      ],
      "id": 3
    },
    {
      "name": "fsdp_qlora",
      "one_line_profile": "Utility for training LLMs using QLoRA and FSDP",
      "detailed_description": "A specialized training utility that combines Fully Sharded Data Parallel (FSDP) with Quantized LoRA (QLoRA) to enable efficient fine-tuning of large language models on limited GPU resources. It serves as a practical solver for memory-constrained model training.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "fine_tuning",
        "memory_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/AnswerDotAI/fsdp_qlora",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fsdp",
        "qlora",
        "llm-training",
        "quantization"
      ],
      "id": 4
    },
    {
      "name": "distribuuuu",
      "one_line_profile": "Lightweight PyTorch distributed training framework",
      "detailed_description": "A pure and concise distributed training framework for PyTorch designed to simplify the setup and execution of multi-GPU training tasks. It provides abstractions for distributed data parallel (DDP) and other training strategies.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "training_framework"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BIGBALLON/distribuuuu",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "distributed-training",
        "ddp"
      ],
      "id": 5
    },
    {
      "name": "PySNN",
      "one_line_profile": "Efficient Spiking Neural Network framework based on PyTorch",
      "detailed_description": "PySNN is a framework for simulating and training Spiking Neural Networks (SNNs) with GPU acceleration. It extends PyTorch to support neuromorphic computing models, enabling research into biologically plausible neural networks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "neuromorphic_computing",
        "snn_simulation",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BasBuller/PySNN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snn",
        "spiking-neural-networks",
        "neuromorphic"
      ],
      "id": 6
    },
    {
      "name": "Bluefog",
      "one_line_profile": "Distributed and decentralized training framework for PyTorch over graphs",
      "detailed_description": "Bluefog is a high-performance distributed training framework for PyTorch that implements decentralized optimization algorithms over virtual topologies (graphs). It is designed for large-scale deep learning training on heterogeneous or bandwidth-constrained networks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "decentralized_optimization",
        "training_framework"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Bluefog-Lib/bluefog",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "decentralized-optimization",
        "pytorch"
      ],
      "id": 7
    },
    {
      "name": "VeOmni",
      "one_line_profile": "Model-centric distributed training framework for multi-modality models",
      "detailed_description": "VeOmni is a distributed training framework designed to scale model training across various modalities. It provides a collection of distributed recipes and optimizations to facilitate the training of large-scale foundation models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "large_scale_training",
        "multimodal_learning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/ByteDance-Seed/VeOmni",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "foundation-models",
        "multimodal"
      ],
      "id": 8
    },
    {
      "name": "Verbalized Sampling",
      "one_line_profile": "Training-free prompting framework to mitigate mode collapse in LLMs",
      "detailed_description": "Verbalized Sampling is a framework and CLI tool that implements a training-free prompting strategy to improve the diversity of Large Language Model (LLM) outputs. It is used for synthetic data generation, dialogue simulation, and mitigating mode collapse in scientific and creative text generation tasks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "inference_control",
        "synthetic_data_generation",
        "prompt_engineering"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CHATS-lab/verbalized-sampling",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "sampling-strategy",
        "inference"
      ],
      "id": 9
    },
    {
      "name": "CV-CUDA",
      "one_line_profile": "GPU-accelerated library for cloud-scale image processing and computer vision",
      "detailed_description": "An open-source, GPU-accelerated library designed for building efficient, cloud-scale image processing and computer vision pipelines. It provides specialized kernels for pre-processing and post-processing tasks in AI workflows.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "image_processing",
        "computer_vision",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/CVCUDA/CV-CUDA",
      "help_website": [
        "https://github.com/CVCUDA/CV-CUDA"
      ],
      "license": "NOASSERTION",
      "tags": [
        "gpu-acceleration",
        "computer-vision",
        "image-processing",
        "cuda"
      ],
      "id": 10
    },
    {
      "name": "trlx",
      "one_line_profile": "Distributed training framework for RLHF on language models",
      "detailed_description": "A library for distributed training of large language models using Reinforcement Learning via Human Feedback (RLHF). It supports various RL algorithms and integrates with distributed training backends.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "rlhf",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CarperAI/trlx",
      "help_website": [
        "https://github.com/CarperAI/trlx"
      ],
      "license": "MIT",
      "tags": [
        "rlhf",
        "distributed-training",
        "llm",
        "reinforcement-learning"
      ],
      "id": 11
    },
    {
      "name": "Mist",
      "one_line_profile": "Efficient distributed training system for LLMs via memory-parallelism co-optimization",
      "detailed_description": "A system for efficient distributed training of Large Language Models (LLMs) that optimizes memory usage and parallelism strategies. It implements techniques described in the EuroSys'25 paper.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "memory_optimization",
        "llm_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CentML/Mist",
      "help_website": [
        "https://github.com/CentML/Mist"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "llm",
        "memory-optimization"
      ],
      "id": 12
    },
    {
      "name": "wolpertinger_ddpg",
      "one_line_profile": "Implementation of Wolpertinger Training with DDPG for discrete action spaces",
      "detailed_description": "A PyTorch implementation of the Wolpertinger policy for Deep Reinforcement Learning in large discrete action spaces, compatible with Multi-GPU/CPU setups.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChangyWen/wolpertinger_ddpg",
      "help_website": [
        "https://github.com/ChangyWen/wolpertinger_ddpg"
      ],
      "license": null,
      "tags": [
        "reinforcement-learning",
        "ddpg",
        "pytorch"
      ],
      "id": 13
    },
    {
      "name": "llm-rk3588",
      "one_line_profile": "GPU-accelerated LLM inference on RK3588 edge devices",
      "detailed_description": "A tool to run Large Language Models on Rockchip RK3588 platforms with GPU acceleration, enabling edge AI inference.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "inference_acceleration",
        "edge_computing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/Chrisz236/llm-rk3588",
      "help_website": [
        "https://github.com/Chrisz236/llm-rk3588"
      ],
      "license": "Apache-2.0",
      "tags": [
        "edge-ai",
        "rk3588",
        "llm-inference",
        "gpu-acceleration"
      ],
      "id": 14
    },
    {
      "name": "OpenGPT",
      "one_line_profile": "Framework for creating grounded instruction datasets and training domain expert LLMs",
      "detailed_description": "A framework designed to create grounded instruction-based datasets and train conversational domain expert Large Language Models, facilitating the development of specialized AI agents.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "dataset_creation",
        "model_training",
        "domain_adaptation"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/CogStack/OpenGPT",
      "help_website": [
        "https://github.com/CogStack/OpenGPT"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "dataset-generation",
        "domain-expert"
      ],
      "id": 15
    },
    {
      "name": "gdGPT",
      "one_line_profile": "LLM training tool using DeepSpeed pipeline mode",
      "detailed_description": "A tool for training large language models (BLOOM, LLaMA, Baichuan, ChatGLM) using DeepSpeed's pipeline parallelism mode, optimized for speed compared to Zero/FSDP.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "distributed_training",
        "pipeline_parallelism"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CoinCheung/gdGPT",
      "help_website": [
        "https://github.com/CoinCheung/gdGPT"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-training",
        "deepspeed",
        "pipeline-parallelism"
      ],
      "id": 16
    },
    {
      "name": "net2net",
      "one_line_profile": "Network-to-Network Translation with Conditional Invertible Neural Networks",
      "detailed_description": "A library implementing Network-to-Network translation using Conditional Invertible Neural Networks (cINNs), useful for generative modeling and domain translation tasks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "generative_modeling",
        "network_translation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CompVis/net2net",
      "help_website": [
        "https://github.com/CompVis/net2net"
      ],
      "license": null,
      "tags": [
        "generative-models",
        "invertible-neural-networks",
        "deep-learning"
      ],
      "id": 17
    },
    {
      "name": "MPP-LLaVA",
      "one_line_profile": "Multimodal Pipeline Parallel training framework for LLaVA-like models",
      "detailed_description": "A project enabling Multimodal Pipeline Parallel (MPP) training for Qwen-based MLLMs, allowing the training of large multimodal models on consumer-grade GPUs (e.g., RTX 3090/4090).",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "multimodal_learning",
        "pipeline_parallelism"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Coobiw/MPP-LLaVA",
      "help_website": [
        "https://github.com/Coobiw/MPP-LLaVA"
      ],
      "license": null,
      "tags": [
        "multimodal",
        "pipeline-parallelism",
        "llava",
        "qwen"
      ],
      "id": 18
    },
    {
      "name": "flash-attention",
      "one_line_profile": "Fast and memory-efficient exact attention mechanism",
      "detailed_description": "A library providing fast and memory-efficient implementations of exact attention (FlashAttention), a critical primitive for accelerating Transformer-based model training and inference.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Dao-AILab/flash-attention",
      "help_website": [
        "https://github.com/Dao-AILab/flash-attention"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "attention-mechanism",
        "gpu-acceleration",
        "cuda",
        "transformer"
      ],
      "id": 19
    },
    {
      "name": "mixed_precision_for_JAX",
      "one_line_profile": "Mixed Precision Training utilities for JAX based on Equinox",
      "detailed_description": "A repository providing tools and utilities for implementing Mixed Precision Training in JAX, specifically built upon the Equinox library.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "mixed_precision",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Data-Science-in-Mechanical-Engineering/mixed_precision_for_JAX",
      "help_website": [
        "https://github.com/Data-Science-in-Mechanical-Engineering/mixed_precision_for_JAX"
      ],
      "license": "MIT",
      "tags": [
        "jax",
        "mixed-precision",
        "equinox",
        "training"
      ],
      "id": 20
    },
    {
      "name": "gpuRIR",
      "one_line_profile": "GPU-accelerated Room Impulse Response (RIR) simulation library",
      "detailed_description": "A Python library for simulating Room Impulse Responses (RIR) with GPU acceleration, used for generating acoustic data for audio processing and machine learning tasks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "simulation",
        "data_generation",
        "acoustics"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/DavidDiazGuerra/gpuRIR",
      "help_website": [
        "https://github.com/DavidDiazGuerra/gpuRIR"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "simulation",
        "acoustics",
        "gpu-acceleration",
        "rir"
      ],
      "id": 21
    },
    {
      "name": "horizonml",
      "one_line_profile": "Hybrid Model Parallelism Framework for Distributed Training on Edge Devices",
      "detailed_description": "A framework enabling efficient distributed training of machine learning models across heterogeneous edge devices using hybrid model parallelism.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "edge_computing",
        "model_parallelism"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Deeptanshu-sankhwar/horizonml",
      "help_website": [
        "https://github.com/Deeptanshu-sankhwar/horizonml"
      ],
      "license": "MIT",
      "tags": [
        "edge-ai",
        "distributed-training",
        "model-parallelism"
      ],
      "id": 22
    },
    {
      "name": "Insanely-Fast-Transcription",
      "one_line_profile": "GPU-accelerated audio transcription utility using Whisper",
      "detailed_description": "A utility for rapid audio transcription leveraging GPU acceleration (CUDA/MPS) and the Whisper model, optimized for high-performance speech-to-text conversion.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "data_processing",
        "speech_recognition",
        "acceleration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Doriandarko/Insanely-Fast-Transcription",
      "help_website": [
        "https://github.com/Doriandarko/Insanely-Fast-Transcription"
      ],
      "license": null,
      "tags": [
        "whisper",
        "transcription",
        "gpu-acceleration",
        "audio-processing"
      ],
      "id": 23
    },
    {
      "name": "nemesyst",
      "one_line_profile": "Hybrid-parallelism, database-based deep learning framework",
      "detailed_description": "A generalised and highly customisable deep learning framework that employs hybrid parallelism and a database-based approach for training.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "distributed_training",
        "framework"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/DreamingRaven/nemesyst",
      "help_website": [
        "https://github.com/DreamingRaven/nemesyst"
      ],
      "license": "MIT",
      "tags": [
        "deep-learning",
        "hybrid-parallelism",
        "framework"
      ],
      "id": 24
    },
    {
      "name": "xshinnosuke",
      "one_line_profile": "Pure Numpy deep learning framework with GPU acceleration support",
      "detailed_description": "A deep learning framework implemented purely in Numpy, supporting both dynamic and static graphs, with optional GPU acceleration.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "framework",
        "educational"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/E1eveNn/xshinnosuke",
      "help_website": [
        "https://github.com/E1eveNn/xshinnosuke"
      ],
      "license": "MIT",
      "tags": [
        "deep-learning-framework",
        "numpy",
        "gpu-acceleration"
      ],
      "id": 25
    },
    {
      "name": "sheeprl",
      "one_line_profile": "Distributed Reinforcement Learning framework accelerated by Lightning Fabric",
      "detailed_description": "A distributed Reinforcement Learning framework that leverages Lightning Fabric for acceleration, enabling scalable RL training.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "distributed_training",
        "acceleration"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Eclectic-Sheep/sheeprl",
      "help_website": [
        "https://github.com/Eclectic-Sheep/sheeprl"
      ],
      "license": "Apache-2.0",
      "tags": [
        "reinforcement-learning",
        "distributed-training",
        "pytorch-lightning"
      ],
      "id": 26
    },
    {
      "name": "gpt-neox",
      "one_line_profile": "Library for model-parallel training of autoregressive transformers on GPUs",
      "detailed_description": "An implementation of model-parallel autoregressive transformers on GPUs, built on Megatron-LM and DeepSpeed, designed for training massive language models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "model_parallelism",
        "llm_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EleutherAI/gpt-neox",
      "help_website": [
        "https://github.com/EleutherAI/gpt-neox"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "distributed-training",
        "megatron-lm",
        "deepspeed"
      ],
      "id": 27
    },
    {
      "name": "pytorch_tempest",
      "one_line_profile": "Template/Scaffold for training neural nets with PyTorch Lightning and Hydra",
      "detailed_description": "A structured template and workflow tool for training neural networks, integrating PyTorch Lightning for training loops and Hydra for configuration management.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "workflow_management",
        "model_training"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Erlemar/pytorch_tempest",
      "help_website": [
        "https://github.com/Erlemar/pytorch_tempest"
      ],
      "license": "MIT",
      "tags": [
        "pytorch-lightning",
        "hydra",
        "template",
        "training-workflow"
      ],
      "id": 28
    },
    {
      "name": "llm_parallelisms.c",
      "one_line_profile": "Pure C implementation of LLM training parallelisms",
      "detailed_description": "A minimal, educational implementation of various LLM training parallelism strategies (Data Parallelism, FSDP, Tensor Parallelism, Pipeline Parallelism) in pure C.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "parallelism",
        "educational"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/EugenHotaj/llm_parallelisms.c",
      "help_website": [
        "https://github.com/EugenHotaj/llm_parallelisms.c"
      ],
      "license": "MIT",
      "tags": [
        "llm",
        "parallelism",
        "c",
        "distributed-training"
      ],
      "id": 29
    },
    {
      "name": "LLaVA-OneVision-1.5",
      "one_line_profile": "Open framework for democratized multimodal model training",
      "detailed_description": "A fully open framework designed to democratize the training of multimodal models, specifically focusing on the LLaVA-OneVision architecture.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "multimodal_learning",
        "framework"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5",
      "help_website": [
        "https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5"
      ],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "llava",
        "training-framework"
      ],
      "id": 30
    },
    {
      "name": "celldetection",
      "one_line_profile": "Scalable Instance Segmentation library for bioimage analysis",
      "detailed_description": "A library for scalable instance segmentation using PyTorch and PyTorch Lightning, specifically tailored for cell detection and bioimage analysis tasks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "image_segmentation",
        "bioimage_analysis",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/FZJ-INM1-BDA/celldetection",
      "help_website": [
        "https://github.com/FZJ-INM1-BDA/celldetection"
      ],
      "license": "Apache-2.0",
      "tags": [
        "cell-detection",
        "instance-segmentation",
        "bioimage",
        "pytorch"
      ],
      "id": 31
    },
    {
      "name": "Medusa",
      "one_line_profile": "Framework for accelerating LLM generation with multiple decoding heads",
      "detailed_description": "A simple framework that accelerates Large Language Model (LLM) generation by employing multiple decoding heads, improving inference speed.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_optimization"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/FasterDecoding/Medusa",
      "help_website": [
        "https://github.com/FasterDecoding/Medusa"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-acceleration",
        "decoding",
        "inference"
      ],
      "id": 32
    },
    {
      "name": "FedML",
      "one_line_profile": "Unified library for distributed training and federated learning",
      "detailed_description": "A scalable machine learning library for large-scale distributed training, model serving, and federated learning, supporting cross-cloud scheduling.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "federated_learning",
        "model_serving"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/FedML-AI/FedML",
      "help_website": [
        "https://doc.fedml.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "federated-learning",
        "distributed-training",
        "edge-ai"
      ],
      "id": 33
    },
    {
      "name": "FlexQ",
      "one_line_profile": "Post-training INT6 quantization framework for LLM inference",
      "detailed_description": "A post-training quantization framework specifically tailored for Large Language Model (LLM) inference, utilizing INT6 quantization to improve efficiency.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_quantization",
        "inference_optimization"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/FlyFoxPlayer/FlexQ",
      "help_website": [
        "https://github.com/FlyFoxPlayer/FlexQ"
      ],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "llm",
        "inference"
      ],
      "id": 34
    },
    {
      "name": "LightningFSL",
      "one_line_profile": "PyTorch Lightning implementations of Few-Shot Learning models",
      "detailed_description": "A library providing PyTorch Lightning implementations of various Few-Shot Learning algorithms and models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "few_shot_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Frankluox/LightningFSL",
      "help_website": [
        "https://github.com/Frankluox/LightningFSL"
      ],
      "license": "MIT",
      "tags": [
        "few-shot-learning",
        "pytorch-lightning",
        "meta-learning"
      ],
      "id": 35
    },
    {
      "name": "CosyVoice",
      "one_line_profile": "Multi-lingual large voice generation model framework",
      "detailed_description": "A full-stack framework for multi-lingual large voice generation models, providing capabilities for inference, training, and deployment.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "inference",
        "voice_generation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/FunAudioLLM/CosyVoice",
      "help_website": [
        "https://github.com/FunAudioLLM/CosyVoice"
      ],
      "license": "Apache-2.0",
      "tags": [
        "voice-generation",
        "tts",
        "model-training"
      ],
      "id": 36
    },
    {
      "name": "edm2",
      "one_line_profile": "Multi-GPU implementation of EDM2 diffusion model training",
      "detailed_description": "A minimal multi-GPU implementation of the EDM2 (Analyzing and Improving the Training Dynamics of Diffusion Models) framework.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "diffusion_models",
        "distributed_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FutureXiang/edm2",
      "help_website": [
        "https://github.com/FutureXiang/edm2"
      ],
      "license": null,
      "tags": [
        "diffusion-models",
        "multi-gpu",
        "training"
      ],
      "id": 37
    },
    {
      "name": "Rust-SSP",
      "one_line_profile": "Structured Stream Parallelism library for Rust",
      "detailed_description": "A Rust library implementing Structured Stream Parallelism, providing high-performance parallel computing capabilities suitable for scientific data processing streams.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "parallel_computing",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/GMAP/Rust-SSP",
      "help_website": [
        "https://github.com/GMAP/Rust-SSP"
      ],
      "license": "MIT",
      "tags": [
        "rust",
        "parallelism",
        "stream-processing"
      ],
      "id": 38
    },
    {
      "name": "RadeonRays_SDK",
      "one_line_profile": "Ray intersection acceleration library for CPU and GPU",
      "detailed_description": "An acceleration library for ray intersection calculations, supporting hardware and software multiplatforms using CPU and GPU, useful for physics simulation and rendering.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "simulation",
        "ray_tracing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/GPUOpen-LibrariesAndSDKs/RadeonRays_SDK",
      "help_website": [
        "https://github.com/GPUOpen-LibrariesAndSDKs/RadeonRays_SDK"
      ],
      "license": "MIT",
      "tags": [
        "ray-tracing",
        "acceleration",
        "gpu",
        "simulation"
      ],
      "id": 39
    },
    {
      "name": "MG-GCN",
      "one_line_profile": "Scalable Multi-GPU Graph Convolutional Network Training Framework",
      "detailed_description": "A framework for scalable training of Graph Convolutional Networks (GCNs) across multiple GPUs, enabling the processing of large-scale graph data.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "graph_neural_networks"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/GT-TDAlab/MG-GCN",
      "help_website": [
        "https://github.com/GT-TDAlab/MG-GCN"
      ],
      "license": "NOASSERTION",
      "tags": [
        "gcn",
        "multi-gpu",
        "distributed-training",
        "graph-learning"
      ],
      "id": 40
    },
    {
      "name": "nvidia-nemo-on-gke",
      "one_line_profile": "Infrastructure code for training NVIDIA NeMo LLMs on GKE",
      "detailed_description": "A set of configurations and scripts (Terraform/HCL) for deploying and training NVIDIA NeMo Megatron Large Language Models on Google Kubernetes Engine (GKE).",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "infrastructure_deployment",
        "llm_training"
      ],
      "application_level": "workflow",
      "primary_language": "HCL",
      "repo_url": "https://github.com/GoogleCloudPlatform/nvidia-nemo-on-gke",
      "help_website": [
        "https://github.com/GoogleCloudPlatform/nvidia-nemo-on-gke"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "gke",
        "nemo",
        "llm-training"
      ],
      "id": 41
    },
    {
      "name": "relora",
      "one_line_profile": "Implementation of ReLoRA for high-rank training through low-rank updates",
      "detailed_description": "The official implementation of ReLoRA, a method for efficient high-rank training of neural networks using low-rank updates, reducing memory and compute requirements.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "optimization",
        "parameter_efficient_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Guitaricet/relora",
      "help_website": [
        "https://github.com/Guitaricet/relora"
      ],
      "license": "Apache-2.0",
      "tags": [
        "peft",
        "training-optimization",
        "low-rank-updates"
      ],
      "id": 42
    },
    {
      "name": "hedgehog-lab",
      "one_line_profile": "Browser-based scientific computing and data visualization environment",
      "detailed_description": "An open-source scientific computing environment that runs entirely in the browser, offering matrix operations with GPU acceleration, TeX support, and data visualization.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "scientific_computing",
        "visualization",
        "data_analysis"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/Hedgehog-Computing/hedgehog-lab",
      "help_website": [
        "https://hedgehog-lab.github.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "scientific-computing",
        "visualization",
        "web-based",
        "gpu-acceleration"
      ],
      "id": 43
    },
    {
      "name": "llm-trainer",
      "one_line_profile": "Framework for training Large Language Models from scratch",
      "detailed_description": "A complete framework designed to facilitate the training of Large Language Models (LLMs) from scratch, providing necessary tools and abstractions.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "llm"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/HelpingAI/llm-trainer",
      "help_website": [
        "https://github.com/HelpingAI/llm-trainer"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-training",
        "framework",
        "deep-learning"
      ],
      "id": 44
    },
    {
      "name": "revlib",
      "one_line_profile": "Memory-efficient reversible network library for PyTorch",
      "detailed_description": "A lightweight library implementing reversible neural networks in PyTorch, enabling significant memory savings during training by reconstructing activations during the backward pass. Supports DeepSpeed and XLA.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "memory_optimization",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HomebrewML/revlib",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "pytorch",
        "reversible-networks",
        "memory-efficient",
        "deepspeed"
      ],
      "id": 45
    },
    {
      "name": "Hetu",
      "one_line_profile": "High-performance distributed deep learning system",
      "detailed_description": "A distributed deep learning system targeting large-scale and automated distributed training, developed by PKU-DAIR. It optimizes communication and computation for efficient model training.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "system_optimization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Hsword/Hetu",
      "help_website": [
        "https://github.com/PKU-DAIR/Hetu"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-systems",
        "deep-learning",
        "training-framework"
      ],
      "id": 46
    },
    {
      "name": "transpeeder",
      "one_line_profile": "Efficient LLaMA training tool using Pipeline Parallelism",
      "detailed_description": "A tool designed to train LLaMA models on limited hardware (e.g., single A100) by leveraging Hugging Face Transformers and DeepSpeed Pipeline Parallelism.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "llm_training",
        "distributed_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HuangLK/transpeeder",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llama",
        "deepspeed",
        "pipeline-parallelism",
        "training-optimization"
      ],
      "id": 47
    },
    {
      "name": "DeepMath",
      "one_line_profile": "Framework for training math reasoning agents",
      "detailed_description": "A framework from Intel Labs for training and evaluating mathematical reasoning agents using local models, GRPO, and vLLM. Facilitates research in AI for mathematics.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "math_reasoning",
        "agent_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/IntelLabs/DeepMath",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "math-ai",
        "reasoning",
        "training-framework",
        "intel-labs"
      ],
      "id": 48
    },
    {
      "name": "lmdeploy",
      "one_line_profile": "Toolkit for compressing and serving LLMs",
      "detailed_description": "A comprehensive toolkit for compressing, deploying, and serving Large Language Models. It supports high-performance inference and quantization, essential for the LLM lifecycle.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_compression",
        "inference_serving"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/InternLM/lmdeploy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "deployment",
        "quantization",
        "inference"
      ],
      "id": 49
    },
    {
      "name": "fast-reid",
      "one_line_profile": "SOTA Re-identification Toolbox",
      "detailed_description": "A software library for object re-identification research and development. It provides state-of-the-art methods and efficient training pipelines for computer vision tasks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "computer_vision",
        "re_identification"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/JDAI-CV/fast-reid",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reid",
        "computer-vision",
        "pytorch",
        "toolbox"
      ],
      "id": 50
    },
    {
      "name": "Surge",
      "one_line_profile": "High-performance matrix math library for Swift",
      "detailed_description": "A Swift library leveraging the Accelerate framework to provide high-performance functions for matrix mathematics, digital signal processing (DSP), and image manipulation, serving as a scientific computing foundation for the Swift ecosystem.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "matrix_computation",
        "signal_processing"
      ],
      "application_level": "library",
      "primary_language": "Swift",
      "repo_url": "https://github.com/Jounce/Surge",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "swift",
        "linear-algebra",
        "dsp",
        "accelerate"
      ],
      "id": 51
    },
    {
      "name": "bert-squeeze",
      "one_line_profile": "Toolbox for Transformer model compression",
      "detailed_description": "A set of tools for compressing Transformer models using techniques like distillation, quantization, and pruning, built on PyTorch Lightning.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_compression",
        "distillation"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/JulesBelveze/bert-squeeze",
      "help_website": [],
      "license": null,
      "tags": [
        "transformers",
        "compression",
        "pytorch-lightning",
        "distillation"
      ],
      "id": 52
    },
    {
      "name": "demucs_lightning",
      "one_line_profile": "PyTorch Lightning implementation of Demucs",
      "detailed_description": "A PyTorch Lightning wrapper for the Demucs music source separation model, facilitating training with features like Hydra configuration and Tensorboard logging.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "audio_processing",
        "source_separation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KinWaiCheuk/demucs_lightning",
      "help_website": [],
      "license": null,
      "tags": [
        "audio",
        "demucs",
        "pytorch-lightning",
        "music-separation"
      ],
      "id": 53
    },
    {
      "name": "FlashDeBERTa",
      "one_line_profile": "Flash attention implementation for DeBERTa",
      "detailed_description": "An optimized implementation of the DeBERTa disentangled attention mechanism using Flash Attention, designed to accelerate training and inference of DeBERTa models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_acceleration",
        "attention_mechanism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Knowledgator/FlashDeBERTa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deberta",
        "flash-attention",
        "optimization",
        "nlp"
      ],
      "id": 54
    },
    {
      "name": "libROM",
      "one_line_profile": "Library for Reduced Order Modeling",
      "detailed_description": "A C++ library for data-driven model reduction with an emphasis on large-scale parallelism and linear subspace methods, developed by LLNL for physical simulations.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_reduction",
        "physics_simulation"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/LLNL/libROM",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "model-reduction",
        "hpc",
        "physics",
        "linear-algebra"
      ],
      "id": 55
    },
    {
      "name": "lightning-thunder",
      "one_line_profile": "PyTorch compiler for training acceleration",
      "detailed_description": "A source-to-source compiler for PyTorch that accelerates training and inference by optimizing performance, memory usage, and parallelism.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "compilation",
        "model_acceleration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lightning-AI/lightning-thunder",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compiler",
        "pytorch",
        "optimization",
        "acceleration"
      ],
      "id": 56
    },
    {
      "name": "lit-llama",
      "one_line_profile": "Hackable implementation of LLaMA",
      "detailed_description": "A clean, hackable implementation of the LLaMA language model based on nanoGPT. Supports pre-training, fine-tuning (LoRA, Adapter), and quantization, serving as a research workbench for LLMs.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "llm_training",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lightning-AI/lit-llama",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llama",
        "llm",
        "finetuning",
        "nanogpt"
      ],
      "id": 57
    },
    {
      "name": "pytorch-lightning",
      "one_line_profile": "High-level framework for PyTorch training",
      "detailed_description": "A lightweight PyTorch wrapper that decouples science code from engineering, enabling easy scaling of model training across multiple GPUs and TPUs.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "training_framework",
        "distributed_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lightning-AI/pytorch-lightning",
      "help_website": [
        "https://lightning.ai/docs/pytorch/stable/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "pytorch",
        "deep-learning",
        "framework",
        "distributed"
      ],
      "id": 58
    },
    {
      "name": "lightning-ColossalAI",
      "one_line_profile": "ColossalAI strategy for PyTorch Lightning",
      "detailed_description": "An integration library that brings ColossalAI's large-scale distributed model training strategies to the PyTorch Lightning ecosystem.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "strategy_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lightning-Universe/lightning-ColossalAI",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "colossalai",
        "distributed-training",
        "pytorch-lightning"
      ],
      "id": 59
    },
    {
      "name": "lightning-bolts",
      "one_line_profile": "Toolbox of models and callbacks for Lightning",
      "detailed_description": "A collection of pre-built models, callbacks, and datasets for PyTorch Lightning, designed to accelerate research prototyping and experimentation.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_library",
        "prototyping"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lightning-Universe/lightning-bolts",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "models",
        "callbacks",
        "research-tools",
        "pytorch-lightning"
      ],
      "id": 60
    },
    {
      "name": "lightning-flash",
      "one_line_profile": "Task-based AI framework",
      "detailed_description": "A high-level framework built on PyTorch Lightning that provides ready-to-use tasks for various domains (text, image, audio), simplifying the configuration and running of complex AI recipes.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "task_framework",
        "automl"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lightning-Universe/lightning-flash",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "automl",
        "tasks",
        "pytorch-lightning",
        "high-level-api"
      ],
      "id": 61
    },
    {
      "name": "lightning-transformers",
      "one_line_profile": "Transformers integration for Lightning",
      "detailed_description": "A library that provides flexible components to pair Hugging Face Transformers with PyTorch Lightning, facilitating efficient training and fine-tuning of Transformer models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_integration",
        "nlp_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lightning-Universe/lightning-transformers",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "transformers",
        "huggingface",
        "pytorch-lightning",
        "nlp"
      ],
      "id": 62
    },
    {
      "name": "naifu",
      "one_line_profile": "Generative model training tool",
      "detailed_description": "A tool for training generative models (specifically diffusion models) using PyTorch Lightning, often used for fine-tuning image generation models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "generative_models",
        "diffusion_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Mikubill/naifu",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "diffusion",
        "generative-ai",
        "training-tool",
        "pytorch-lightning"
      ],
      "id": 63
    },
    {
      "name": "EasyLLM",
      "one_line_profile": "Usability-focused LLM training framework",
      "detailed_description": "A framework built upon Megatron-Deepspeed and HuggingFace Trainer that reorganizes code logic to improve usability and training efficiency for Large Language Models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "llm_training",
        "framework_wrapper"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/ModelTC/EasyLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "megatron",
        "deepspeed",
        "training-framework"
      ],
      "id": 64
    },
    {
      "name": "MyCaffe/NCCL",
      "one_line_profile": "Windows port of NVIDIA's NCCL library for multi-GPU communication",
      "detailed_description": "A Windows adaptation of the NVIDIA Collective Communications Library (NCCL), enabling multi-GPU and multi-node collective communication primitives for deep learning frameworks on Windows systems.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "communication_primitives"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/MyCaffe/NCCL",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "nccl",
        "windows",
        "distributed-training",
        "gpu"
      ],
      "id": 65
    },
    {
      "name": "LARS-ImageNet-PyTorch",
      "one_line_profile": "PyTorch implementation of LARS optimizer for large batch training",
      "detailed_description": "A library implementing the Layer-wise Adaptive Rate Scaling (LARS) optimizer, designed for large batch training of deep neural networks (e.g., ResNet on ImageNet) with support for Horovod distributed training.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_optimization",
        "training_optimizer"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NUS-HPC-AI-Lab/LARS-ImageNet-PyTorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lars",
        "optimizer",
        "large-batch",
        "pytorch"
      ],
      "id": 66
    },
    {
      "name": "NVIDIA NeMo Automodel",
      "one_line_profile": "Distributed training library for LLMs and VLMs with Hugging Face support",
      "detailed_description": "A PyTorch Distributed native training library designed for Large Language Models (LLMs) and Vision Language Models (VLMs), offering out-of-the-box integration with Hugging Face models and optimized for NVIDIA hardware.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "llm_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA-NeMo/Automodel",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "distributed-training",
        "pytorch",
        "nemo"
      ],
      "id": 67
    },
    {
      "name": "NVIDIA DALI",
      "one_line_profile": "GPU-accelerated data loading and augmentation library",
      "detailed_description": "A library containing highly optimized building blocks and an execution engine for data processing to accelerate deep learning training and inference applications, focusing on removing CPU bottlenecks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "data_processing",
        "data_loading",
        "augmentation"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/NVIDIA/DALI",
      "help_website": [
        "https://docs.nvidia.com/deeplearning/dali"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-loading",
        "gpu-acceleration",
        "augmentation",
        "pipeline"
      ],
      "id": 68
    },
    {
      "name": "Megatron-LM",
      "one_line_profile": "Framework for large-scale distributed training of Transformer models",
      "detailed_description": "A highly optimized library for training massive Transformer language models at scale, implementing efficient model parallelism (tensor and pipeline) and data parallelism techniques.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "model_parallelism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/Megatron-LM",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "transformer",
        "distributed-training",
        "llm",
        "parallelism"
      ],
      "id": 69
    },
    {
      "name": "Transformer Engine",
      "one_line_profile": "Library for accelerating Transformer models with FP8/FP4 precision",
      "detailed_description": "A library for accelerating Transformer models on NVIDIA GPUs, enabling 8-bit and 4-bit floating point (FP8 and FP4) precision for better performance and lower memory utilization in training and inference.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "mixed_precision"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/TransformerEngine",
      "help_website": [
        "https://docs.nvidia.com/deeplearning/transformer-engine"
      ],
      "license": "Apache-2.0",
      "tags": [
        "fp8",
        "transformer",
        "acceleration",
        "hopper"
      ],
      "id": 70
    },
    {
      "name": "Video Processing Framework",
      "one_line_profile": "Hardware-accelerated video processing library for Python",
      "detailed_description": "A set of Python bindings to C++ libraries providing full hardware acceleration for video decoding, encoding, and GPU-accelerated color space/pixel format conversions, useful for scientific video data pipelines.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "data_processing",
        "video_decoding"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/NVIDIA/VideoProcessingFramework",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "video-processing",
        "gpu-acceleration",
        "decoding",
        "encoding"
      ],
      "id": 71
    },
    {
      "name": "NVIDIA Apex",
      "one_line_profile": "PyTorch extension for mixed precision and distributed training",
      "detailed_description": "A library providing tools for easy mixed precision (AMP) and distributed training in PyTorch, including optimized fused optimizers and layers.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "mixed_precision",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/apex",
      "help_website": [
        "https://nvidia.github.io/apex/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "mixed-precision",
        "pytorch",
        "distributed-training",
        "amp"
      ],
      "id": 72
    },
    {
      "name": "JaxPP",
      "one_line_profile": "JAX library for flexible MPMD pipeline parallelism",
      "detailed_description": "A library for JAX that enables flexible MPMD (Multiple Program Multiple Data) pipeline parallelism, specifically designed for large-scale LLM training workflows.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "pipeline_parallelism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/jaxpp",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jax",
        "pipeline-parallelism",
        "llm",
        "distributed"
      ],
      "id": 73
    },
    {
      "name": "nvidia-dlfw-inspect",
      "one_line_profile": "Debugging tool for LLM training convergence issues",
      "detailed_description": "A tool designed to facilitate debugging of convergence issues and testing of new algorithms for training LLMs using NVIDIA libraries like Transformer Engine, Megatron-LM, and NeMo.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "debugging",
        "model_convergence"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/nvidia-dlfw-inspect",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "debugging",
        "llm",
        "convergence",
        "training-tools"
      ],
      "id": 74
    },
    {
      "name": "NVIDIA Warp",
      "one_line_profile": "Python framework for high-performance simulation and spatial computing",
      "detailed_description": "A Python framework that compiles Python functions to efficient kernel code for accelerated simulation, geometry processing, and data generation tasks on CPU and GPU.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "simulation",
        "data_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/warp",
      "help_website": [
        "https://nvidia.github.io/warp/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "simulation",
        "spatial-computing",
        "cuda",
        "physics"
      ],
      "id": 75
    },
    {
      "name": "Kaolin",
      "one_line_profile": "PyTorch library for 3D deep learning research",
      "detailed_description": "A PyTorch library aimed at accelerating 3D deep learning research, providing implementations of 3D modules, differentiable rendering, and data processing for 3D structures.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "scientific_modeling",
        "3d_deep_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIAGameWorks/kaolin",
      "help_website": [
        "https://kaolin.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "3d-vision",
        "pytorch",
        "differentiable-rendering",
        "geometry"
      ],
      "id": 76
    },
    {
      "name": "Fast-dLLM",
      "one_line_profile": "Acceleration library for Diffusion LLMs via KV cache",
      "detailed_description": "A training-free acceleration framework for Diffusion LLMs that enables KV cache and parallel decoding to improve inference speed and efficiency.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVlabs/Fast-dLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-models",
        "llm",
        "acceleration",
        "kv-cache"
      ],
      "id": 77
    },
    {
      "name": "tiny-cuda-nn",
      "one_line_profile": "High-performance C++/CUDA neural network framework",
      "detailed_description": "A lightning-fast C++/CUDA neural network framework, particularly optimized for multi-resolution hash encodings and NeRF applications.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/NVlabs/tiny-cuda-nn",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "cuda",
        "neural-network",
        "nerf",
        "optimization"
      ],
      "id": 78
    },
    {
      "name": "mlstm_kernels",
      "one_line_profile": "Optimized kernels for mLSTM and Flash Linear Attention",
      "detailed_description": "A library providing Tiled Flash Linear Attention kernels for fast and efficient training and inference of mLSTM (matrix LSTM) models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "kernel_optimization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/NX-AI/mlstm_kernels",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "lstm",
        "attention",
        "cuda-kernels",
        "acceleration"
      ],
      "id": 79
    },
    {
      "name": "NoteDance Note",
      "one_line_profile": "Lightweight distributed training and machine learning library",
      "detailed_description": "A machine learning library supporting distributed training, deep learning, and reinforcement learning, compatible with TensorFlow and PyTorch.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NoteDance/Note",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "reinforcement-learning",
        "deep-learning"
      ],
      "id": 80
    },
    {
      "name": "DisTrO",
      "one_line_profile": "Framework for decentralized distributed training over the internet",
      "detailed_description": "A framework enabling Distributed Training Over-The-Internet, allowing for decentralized model training across geographically distributed resources with optimized communication.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "decentralized_learning"
      ],
      "application_level": "library",
      "primary_language": null,
      "repo_url": "https://github.com/NousResearch/DisTrO",
      "help_website": [],
      "license": null,
      "tags": [
        "distributed-training",
        "decentralized",
        "internet-scale"
      ],
      "id": 81
    },
    {
      "name": "LiBai",
      "one_line_profile": "Toolbox for large-scale distributed parallel training based on OneFlow",
      "detailed_description": "A toolbox designed for large-scale distributed parallel training of deep learning models, built on top of the OneFlow framework.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "model_parallelism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Oneflow-Inc/libai",
      "help_website": [
        "https://libai.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "oneflow",
        "large-scale",
        "parallelism"
      ],
      "id": 82
    },
    {
      "name": "OneFlow",
      "one_line_profile": "Scalable and efficient distributed deep learning framework",
      "detailed_description": "A deep learning framework designed to be user-friendly, scalable, and efficient, with a strong focus on distributed training and performance optimization.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/Oneflow-Inc/oneflow",
      "help_website": [
        "https://docs.oneflow.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "deep-learning-framework",
        "distributed-training",
        "compiler"
      ],
      "id": 83
    },
    {
      "name": "llm-finetune",
      "one_line_profile": "Framework for fine-tuning large language models",
      "detailed_description": "A framework for training and fine-tuning large language models, supporting LoRA and full parameter fine-tuning with YAML-based configuration.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_finetuning",
        "llm_training"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenCSGs/llm-finetune",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "finetuning",
        "lora",
        "training-framework"
      ],
      "id": 84
    },
    {
      "name": "FlashVSR",
      "one_line_profile": "Diffusion-based framework for real-time video super-resolution",
      "detailed_description": "An efficient one-step diffusion framework for streaming video super-resolution (VSR) utilizing locality-constrained sparse attention.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "data_processing",
        "super_resolution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenImagingLab/FlashVSR",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "video-super-resolution",
        "diffusion-models",
        "image-processing"
      ],
      "id": 85
    },
    {
      "name": "CoLLiE",
      "one_line_profile": "Library for efficient collaborative training of LLMs",
      "detailed_description": "Collaborative Training of Large Language Models in an Efficient Way (CoLLiE) is a library designed to facilitate efficient and collaborative training processes for LLMs.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "llm_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenMOSS/CoLLiE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "collaborative-training",
        "efficient-training"
      ],
      "id": 86
    },
    {
      "name": "MegatronApp",
      "one_line_profile": "Toolchain and utilities for distributed training with Megatron-LM",
      "detailed_description": "A toolchain built around Megatron-LM to facilitate distributed training workflows, providing additional utilities and ease of use.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "workflow_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenSQZ/MegatronApp",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "megatron-lm",
        "distributed-training",
        "toolchain"
      ],
      "id": 87
    },
    {
      "name": "Safe-RLHF",
      "one_line_profile": "Framework for constrained value alignment via Safe RLHF",
      "detailed_description": "A library for Safe Reinforcement Learning from Human Feedback (RLHF), focusing on constrained value alignment to ensure safety in LLM training.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_alignment",
        "rlhf"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PKU-Alignment/safe-rlhf",
      "help_website": [
        "https://safe-rlhf.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "alignment",
        "safety",
        "llm"
      ],
      "id": 88
    },
    {
      "name": "LLM-boost-recognition",
      "one_line_profile": "OCR and voice recognition module with LLM-based correction",
      "detailed_description": "A module for converting documents and audio into text using OCR and voice recognition, enhanced with LLM-based correction and GPU acceleration, suitable for scientific data digitization.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "data_processing",
        "ocr",
        "speech_recognition"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PStarH/LLM-boost-recognition",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "ocr",
        "voice-recognition",
        "llm-correction",
        "data-ingestion"
      ],
      "id": 89
    },
    {
      "name": "PARL",
      "one_line_profile": "High-performance distributed training framework for Reinforcement Learning",
      "detailed_description": "A flexible and high-performance framework for reinforcement learning (RL) training, supporting distributed architecture and massive parallel environment simulation.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PaddlePaddle/PARL",
      "help_website": [
        "https://parl.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "reinforcement-learning",
        "distributed-training",
        "paddlepaddle"
      ],
      "id": 90
    },
    {
      "name": "PaddlePaddle",
      "one_line_profile": "Industrial-grade distributed deep learning framework",
      "detailed_description": "PArallel Distributed Deep LEarning (PaddlePaddle) is a comprehensive machine learning framework supporting high-performance distributed training and cross-platform deployment.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/PaddlePaddle/Paddle",
      "help_website": [
        "https://www.paddlepaddle.org.cn/documentation/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "deep-learning-framework",
        "distributed-training",
        "industrial"
      ],
      "id": 91
    },
    {
      "name": "Chimera",
      "one_line_profile": "Library for bidirectional pipeline parallelism in large-scale training",
      "detailed_description": "An implementation of Chimera, a bidirectional pipeline parallelism scheme for efficiently training large-scale models with improved resource utilization.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "pipeline_parallelism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ParCIS/Chimera",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pipeline-parallelism",
        "distributed-training",
        "efficiency"
      ],
      "id": 92
    },
    {
      "name": "PERSIA",
      "one_line_profile": "Distributed training framework for deep learning recommendation models",
      "detailed_description": "A high-performance distributed framework specifically designed for training deep learning recommendation models, leveraging hybrid data/model parallelism.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "recommendation_systems"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/PersiaML/PERSIA",
      "help_website": [
        "https://persiaml-tutorials.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "recommendation-models",
        "distributed-training",
        "rust",
        "pytorch"
      ],
      "id": 93
    },
    {
      "name": "Search-R1",
      "one_line_profile": "RL training framework for reasoning and search engine interleaved LLMs",
      "detailed_description": "An efficient and scalable Reinforcement Learning (RL) training framework designed for Large Language Models that interleave reasoning with search engine calls.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "reinforcement_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PeterGriffinJin/Search-R1",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rl",
        "llm",
        "reasoning",
        "search-engine"
      ],
      "id": 94
    },
    {
      "name": "NeuralSolvers",
      "one_line_profile": "PyTorch library for solving PDEs and inverse problems using neural networks",
      "detailed_description": "A library implementing physics-informed neural networks (PINNs) and other neural solvers for partial differential equations (PDEs) and inverse problems.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "scientific_modeling",
        "pde_solver"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Photon-AI-Research/NeuralSolvers",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pinn",
        "pde",
        "physics-informed",
        "inverse-problems"
      ],
      "id": 95
    },
    {
      "name": "sparse-frontier",
      "one_line_profile": "Framework for evaluating training-free sparse attention in LLMs",
      "detailed_description": "An evaluation framework designed to analyze and benchmark training-free sparse attention mechanisms in Large Language Models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_evaluation",
        "attention_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PiotrNawrot/sparse-frontier",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "sparse-attention",
        "llm",
        "evaluation",
        "benchmarking"
      ],
      "id": 96
    },
    {
      "name": "OpenDiloco",
      "one_line_profile": "Framework for globally distributed low-communication model training",
      "detailed_description": "An open-source framework implementing the DiLoCo algorithm for globally distributed training with low communication overhead, enabling training across disconnected clusters.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "decentralized_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PrimeIntellect-ai/OpenDiloco",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "low-bandwidth",
        "diloco"
      ],
      "id": 97
    },
    {
      "name": "Prime DiLoCo",
      "one_line_profile": "Framework for globally distributed AI model training over the internet",
      "detailed_description": "A framework designed for efficient, globally distributed training of AI models across geographically dispersed devices connected via the internet, enabling decentralized computing resources to collaborate on model training.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "decentralized_computing"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/PrimeIntellect-ai/prime-diloco",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "decentralized-ai",
        "diloco"
      ],
      "id": 98
    },
    {
      "name": "Prime Iroh",
      "one_line_profile": "Asynchronous P2P communication backend for decentralized pipeline parallelism",
      "detailed_description": "A Rust-based asynchronous peer-to-peer (P2P) communication backend designed to support decentralized pipeline parallelism in distributed AI training workflows.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_communication",
        "pipeline_parallelism"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/PrimeIntellect-ai/prime-iroh",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "p2p",
        "distributed-training",
        "communication-backend"
      ],
      "id": 99
    },
    {
      "name": "Prime vLLM",
      "one_line_profile": "Modified vLLM for pipeline parallelism over public networks",
      "detailed_description": "A modification of the vLLM library tailored to execute pipeline parallelism across public networks, facilitating distributed inference and training setups in decentralized environments.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "inference_optimization",
        "pipeline_parallelism"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/PrimeIntellect-ai/prime-vllm",
      "help_website": [],
      "license": null,
      "tags": [
        "vllm",
        "pipeline-parallelism",
        "distributed-inference"
      ],
      "id": 100
    },
    {
      "name": "MAPLE",
      "one_line_profile": "Hardware-software co-design for asynchronous memory parallelism",
      "detailed_description": "A hardware-software co-design framework that enables programs to perform long-latency memory accesses asynchronously from the core, reducing pipeline stalls and increasing memory level parallelism (MLP).",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "memory_optimization",
        "hardware_acceleration"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/PrincetonUniversity/maple",
      "help_website": [],
      "license": null,
      "tags": [
        "memory-parallelism",
        "hardware-software-codesign",
        "performance-optimization"
      ],
      "id": 101
    },
    {
      "name": "TensorNet",
      "one_line_profile": "Distributed training framework optimized for large-scale sparse data",
      "detailed_description": "A C++ based distributed training framework built on TensorFlow, specifically optimized for handling large-scale sparse data typical in recommendation systems and advertising scenarios.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "sparse_data_processing"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/Qihoo360/tensornet",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "sparse-data",
        "tensorflow"
      ],
      "id": 102
    },
    {
      "name": "QizNLP",
      "one_line_profile": "TensorFlow framework for rapid NLP task execution",
      "detailed_description": "A TensorFlow-based framework designed for quickly running various Natural Language Processing (NLP) tasks such as classification, sequence labeling, matching, and generation, with support for distributed training.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "nlp_tasks",
        "model_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Qznan/QizNLP",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "nlp",
        "tensorflow",
        "distributed-training"
      ],
      "id": 103
    },
    {
      "name": "Reinforce-Ada",
      "one_line_profile": "Adaptive sampling framework for Reinforce-style LLM post-training",
      "detailed_description": "A framework implementing adaptive sampling strategies for Reinforce-style post-training of Large Language Models (LLMs), aiming to improve alignment and performance efficiency.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "post_training",
        "rlhf",
        "adaptive_sampling"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/RLHFlow/Reinforce-Ada",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "reinforcement-learning",
        "post-training"
      ],
      "id": 104
    },
    {
      "name": "Flash-Sparse-Attention",
      "one_line_profile": "Efficient implementations of Native Sparse Attention",
      "detailed_description": "A library providing efficient implementations of Native Sparse Attention mechanisms, designed to accelerate Transformer models by reducing computational complexity and memory usage.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "attention_mechanism",
        "model_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Relaxed-System-Lab/Flash-Sparse-Attention",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sparse-attention",
        "optimization",
        "transformer"
      ],
      "id": 105
    },
    {
      "name": "Flash Attention v2 RDNA3",
      "one_line_profile": "Flash Attention v2 implementation for ROCm/RDNA3 GPUs",
      "detailed_description": "A minimal implementation of Flash Attention v2 optimized for AMD RDNA3 GPUs using ROCm, enabling accelerated inference and training for models like Stable Diffusion in specific hardware environments.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "hardware_acceleration",
        "attention_mechanism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Repeerc/flash-attention-v2-RDNA3-minimal",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rocm",
        "flash-attention",
        "rdna3"
      ],
      "id": 106
    },
    {
      "name": "AI Attention Acceleration",
      "one_line_profile": "Pre-compiled attention acceleration packages for Windows AI workflows",
      "detailed_description": "A utility repository providing pre-compiled acceleration libraries (xformers, Flash Attention, SageAttention) to enhance the efficiency of AI workflows like ComfyUI and Fooocus on Windows systems.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "workflow_optimization",
        "hardware_acceleration"
      ],
      "application_level": "utility",
      "primary_language": "Python",
      "repo_url": "https://github.com/Rogala/AI_Attention",
      "help_website": [],
      "license": "Unlicense",
      "tags": [
        "windows",
        "acceleration",
        "xformers"
      ],
      "id": 107
    },
    {
      "name": "FastCkpt",
      "one_line_profile": "Rematerialization-aware gradient checkpointing for memory efficiency",
      "detailed_description": "A Python package implementing rematerialization-aware gradient checkpointing, optimizing memory usage during the training of deep learning models by selectively recomputing activations.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "memory_optimization",
        "gradient_checkpointing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/RulinShao/FastCkpt",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gradient-checkpointing",
        "memory-optimization",
        "training"
      ],
      "id": 108
    },
    {
      "name": "LightSeq (DistFlashAttn)",
      "one_line_profile": "Distributed memory-efficient attention for long-context LLM training",
      "detailed_description": "The official repository for DistFlashAttn, providing distributed memory-efficient attention mechanisms to support the training of Large Language Models (LLMs) with long context windows.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "attention_mechanism",
        "distributed_training",
        "long_context"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/RulinShao/LightSeq",
      "help_website": [],
      "license": null,
      "tags": [
        "distributed-attention",
        "llm",
        "long-context"
      ],
      "id": 109
    },
    {
      "name": "MagiAttention",
      "one_line_profile": "Distributed attention for linear scalability in ultra-long context training",
      "detailed_description": "A distributed attention mechanism designed to achieve linear scalability, enabling the training of models with ultra-long contexts and heterogeneous data.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "attention_mechanism",
        "distributed_training",
        "scalability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SandAI-org/MagiAttention",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-attention",
        "long-context",
        "linear-scalability"
      ],
      "id": 110
    },
    {
      "name": "DiffEqGPU.jl",
      "one_line_profile": "GPU-acceleration routines for DifferentialEquations.jl",
      "detailed_description": "A library providing GPU-acceleration routines for the DifferentialEquations.jl package, facilitating high-performance scientific machine learning (SciML) and differential equation solving on GPUs.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "scientific_computing",
        "differential_equations",
        "gpu_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/SciML/DiffEqGPU.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sciml",
        "differential-equations",
        "gpu",
        "julia"
      ],
      "id": 111
    },
    {
      "name": "Fast-LLM",
      "one_line_profile": "Framework for accelerating LLM training",
      "detailed_description": "A framework developed by ServiceNow Research to accelerate the training of Large Language Models (LLMs), optimizing performance and resource utilization.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "performance_optimization"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/ServiceNow/Fast-LLM",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "training-acceleration",
        "servicenow"
      ],
      "id": 112
    },
    {
      "name": "LLM-Training",
      "one_line_profile": "Distributed training framework for LLMs powered by Lightning",
      "detailed_description": "A distributed training framework built on PyTorch Lightning, designed to facilitate the training of Large Language Models (LLMs) with distributed computing capabilities.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "llm"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/ShinoharaHare/LLM-Training",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pytorch-lightning",
        "distributed-training",
        "llm"
      ],
      "id": 113
    },
    {
      "name": "simpleT5",
      "one_line_profile": "Wrapper for quick T5 model training using PyTorch Lightning",
      "detailed_description": "A simplified wrapper library built on top of PyTorch Lightning and Hugging Face Transformers, designed to streamline and accelerate the training process for T5 (Text-to-Text Transfer Transformer) models.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "model_training",
        "nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Shivanandroy/simpleT5",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "t5",
        "pytorch-lightning",
        "transformers",
        "nlp"
      ],
      "id": 114
    },
    {
      "name": "DRPO (Dynamic Alignment Optimization)",
      "one_line_profile": "Tuning-free approach for self-alignment with prompt optimization",
      "detailed_description": "An implementation of Dynamic Rewarding with Prompt Optimization (DRPO), a tuning-free framework that enables Large Language Models (LLMs) to iteratively self-improve and design optimal alignment instructions without additional training.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "model_alignment",
        "prompt_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Singla17/dynamic-alignment-optimization",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "prompt-optimization",
        "llm"
      ],
      "id": 115
    },
    {
      "name": "Tiresias",
      "one_line_profile": "GPU cluster manager for distributed deep learning training",
      "detailed_description": "A GPU cluster scheduling and management system designed specifically for distributed deep learning training workloads, optimizing resource allocation and job scheduling.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "cluster_management",
        "resource_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/SymbioticLab/Tiresias",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu-scheduling",
        "distributed-training",
        "cluster-manager"
      ],
      "id": 116
    },
    {
      "name": "Aparapi",
      "one_line_profile": "Framework for executing native Java and Scala code on the GPU",
      "detailed_description": "A framework that allows developers to write native Java or Scala code and execute it on the GPU by converting bytecode to OpenCL, facilitating parallel computing and acceleration.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "parallel_computing",
        "gpu_acceleration"
      ],
      "application_level": "framework",
      "primary_language": "Java",
      "repo_url": "https://github.com/Syncleus/aparapi",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu",
        "java",
        "opencl",
        "parallel-computing"
      ],
      "id": 117
    },
    {
      "name": "Slime",
      "one_line_profile": "LLM post-training framework for RL Scaling",
      "detailed_description": "A post-training framework for Large Language Models (LLMs) focused on Reinforcement Learning (RL) scaling, providing tools and methods to enhance model performance through RL techniques.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "post_training",
        "reinforcement_learning",
        "rlhf"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/THUDM/slime",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "rlhf",
        "post-training"
      ],
      "id": 118
    },
    {
      "name": "MARTI",
      "one_line_profile": "LLM-based Multi-Agent Reinforced Training and Inference Framework",
      "detailed_description": "A framework designed for multi-agent reinforced training and inference using Large Language Models (LLMs), developed by Tsinghua University C3I.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "training_framework",
        "multi_agent_reinforcement_learning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/TsinghuaC3I/MARTI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "multi-agent",
        "reinforcement-learning"
      ],
      "id": 119
    },
    {
      "name": "Mandheling",
      "one_line_profile": "Mixed-Precision On-Device DNN Training with DSP Offloading",
      "detailed_description": "An open-source implementation of the Mandheling system (MobiCom'2022) for efficient on-device deep neural network training using DSP offloading and mixed-precision techniques.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "on_device_training",
        "acceleration"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/UbiquitousLearning/Mandheling-DSP-Training",
      "help_website": [],
      "license": null,
      "tags": [
        "on-device-learning",
        "dsp-offloading",
        "mixed-precision"
      ],
      "id": 120
    },
    {
      "name": "PP-Schedule-Visualization",
      "one_line_profile": "Pipeline Parallelism Emulation and Visualization Tool",
      "detailed_description": "A tool for emulating and visualizing the scheduling of pipeline parallelism in distributed deep learning training, aiding in performance analysis and optimization.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "visualization",
        "performance_analysis"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/Victarry/PP-Schedule-Visualization",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pipeline-parallelism",
        "visualization",
        "distributed-training"
      ],
      "id": 121
    },
    {
      "name": "blitzdg",
      "one_line_profile": "Parallel Discontinuous Galerkin (DG) Solver",
      "detailed_description": "An open-source parallel discontinuous Galerkin (DG) solver implementation for partial differential equations, utilizing blitz++ for tensor manipulation and MPI for distributed parallelism.",
      "domains": [
        "Scientific Computing"
      ],
      "subtask_category": [
        "pde_solver",
        "simulation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/WQCG/blitzdg",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "pde",
        "discontinuous-galerkin",
        "mpi"
      ],
      "id": 122
    },
    {
      "name": "SRUM",
      "one_line_profile": "Fine-Grained Self-Rewarding Framework for Multimodal Models",
      "detailed_description": "A post-training framework that creates a cost-effective, self-iterative optimization loop for unified multimodal models, implementing fine-grained self-rewarding mechanisms.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "post_training",
        "optimization"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/WayneJin0918/SRUM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "self-rewarding",
        "post-training"
      ],
      "id": 123
    },
    {
      "name": "tf-recsys",
      "one_line_profile": "TensorFlow-based Collaborative Filtering Library",
      "detailed_description": "A library implementing collaborative filtering models (SVD, SVD++) using TensorFlow to utilize GPU acceleration for recommendation system tasks.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "recommendation",
        "model_implementation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/WindQAQ/tf-recsys",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "recsys",
        "tensorflow",
        "collaborative-filtering"
      ],
      "id": 124
    },
    {
      "name": "Mochi-Full-Finetuner",
      "one_line_profile": "Full Finetuning Tool for Mochi Model",
      "detailed_description": "A specialized tool for performing full parameter finetuning of the Mochi video generation model using FSDP (Fully Sharded Data Parallel) and Context Parallelism.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_finetuning",
        "video_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Yaofang-Liu/Mochi-Full-Finetuner",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "finetuning",
        "fsdp",
        "mochi"
      ],
      "id": 125
    },
    {
      "name": "ray-skorch",
      "one_line_profile": "Distributed Skorch on Ray Train",
      "detailed_description": "A library that integrates Skorch (a scikit-learn compatible neural network library) with Ray Train to enable distributed training capabilities.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "framework_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Yard1/ray-skorch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ray",
        "skorch",
        "distributed"
      ],
      "id": 126
    },
    {
      "name": "OptimalShardedDataParallel",
      "one_line_profile": "Automated Parallel Training System (OSDP)",
      "detailed_description": "An automated parallel training system that combines the advantages of data and model parallelism, optimizing sharded data parallel strategies (IJCAI 2023).",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "parallelism_optimization"
      ],
      "application_level": "system",
      "primary_language": "Python",
      "repo_url": "https://github.com/Youhe-Jiang/IJCAI2023-OptimalShardedDataParallel",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "distributed-training",
        "sharding",
        "parallelism"
      ],
      "id": 127
    },
    {
      "name": "GNNAdvisor",
      "one_line_profile": "Adaptive Runtime System for GNN Acceleration",
      "detailed_description": "An adaptive and efficient runtime system designed for accelerating Graph Neural Networks (GNNs) on GPUs (OSDI'21 Artifact).",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "gnn_acceleration",
        "runtime_system"
      ],
      "application_level": "system",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/YukeWang96/GNNAdvisor_OSDI21",
      "help_website": [],
      "license": null,
      "tags": [
        "gnn",
        "gpu-acceleration",
        "runtime"
      ],
      "id": 128
    },
    {
      "name": "train-CLIP",
      "one_line_profile": "PyTorch Lightning Solution for Training CLIP",
      "detailed_description": "A comprehensive PyTorch Lightning-based framework for training OpenAI's CLIP models from scratch, providing a reusable training pipeline.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "multimodal"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zasder3/train-CLIP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "clip",
        "pytorch-lightning",
        "training-pipeline"
      ],
      "id": 129
    },
    {
      "name": "TSDS",
      "one_line_profile": "Task-Specific Data Selection Framework",
      "detailed_description": "An optimal-transport based framework for selecting domain-specific and task-specific training data to improve LLM finetuning and instruction tuning efficiency.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "data_selection",
        "finetuning_optimization"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/ZifanL/TSDS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-selection",
        "llm",
        "optimal-transport"
      ],
      "id": 130
    },
    {
      "name": "ProteinWorkshop",
      "one_line_profile": "Protein Representation Learning Benchmarking Framework",
      "detailed_description": "A comprehensive framework for benchmarking protein representation learning, including datasets, pre-training models, and downstream task utilities (ICLR 2024).",
      "domains": [
        "AI4S",
        "Biology"
      ],
      "subtask_category": [
        "protein_modeling",
        "benchmarking"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/a-r-j/ProteinWorkshop",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-structure",
        "representation-learning",
        "benchmark"
      ],
      "id": 131
    },
    {
      "name": "MinimalGPT",
      "one_line_profile": "Minimalist GPT Training and Inference Framework",
      "detailed_description": "A concise and adaptable framework implemented in Keras/TensorFlow for constructing, training, and finetuning GPT models, serving as a lightweight tool for research and education.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "inference"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/abhaskumarsinha/MinimalGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpt",
        "keras",
        "educational-framework"
      ],
      "id": 132
    },
    {
      "name": "synth.",
      "one_line_profile": "Synthetic Instruction Generation Framework",
      "detailed_description": "A framework designed for generating synthetic instructions to enhance Large Language Model (LLM) training datasets.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "data_generation",
        "synthetic_data"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/aboros98/synth",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "synthetic-data",
        "instruction-tuning",
        "llm"
      ],
      "id": 133
    },
    {
      "name": "AidLearning",
      "one_line_profile": "Mobile AIOT Development and Inference Platform",
      "detailed_description": "A powerful AIOT development platform supporting Linux on Android, enabling CPU+GPU+NPU accelerated inference and development directly on mobile devices.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "edge_inference",
        "mobile_ai"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/aidlearning/AidLearning-FrameWork",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "mobile-ai",
        "edge-computing",
        "inference-acceleration"
      ],
      "id": 134
    },
    {
      "name": "minPP",
      "one_line_profile": "Minimalist Pipeline Parallelism Library",
      "detailed_description": "A lightweight implementation of pipeline parallelism for distributed deep learning training, designed for simplicity and ease of integration.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "pipeline_parallelism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ailzhang/minPP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pipeline-parallelism",
        "distributed-training",
        "minimalist"
      ],
      "id": 135
    },
    {
      "name": "rllib-fast-serve",
      "one_line_profile": "Lightweight Inference Tool for Ray RLlib Policies",
      "detailed_description": "A set of tools to export policies trained with Ray RLlib for lightweight and fast inference, decoupling inference from the heavy Ray dependencies.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "inference_serving",
        "reinforcement_learning"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/airboxlab/rllib-fast-serve",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rllib",
        "inference",
        "serving"
      ],
      "id": 136
    },
    {
      "name": "IceVision",
      "one_line_profile": "Agnostic Computer Vision Framework",
      "detailed_description": "A computer vision framework that is agnostic to the underlying training library, allowing pluggable integration with Fastai, PyTorch Lightning, and others.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "computer_vision",
        "training_framework"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/airctic/icevision",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "computer-vision",
        "framework-agnostic",
        "object-detection"
      ],
      "id": 137
    },
    {
      "name": "full_stack_transformer",
      "one_line_profile": "End-to-End Transformer Training and Serving Library",
      "detailed_description": "A PyTorch library designed for the complete lifecycle of transformer models, including training, inference, and serving.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "serving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/alexeykarnachev/full_stack_transformer",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "transformer",
        "serving",
        "pytorch"
      ],
      "id": 138
    },
    {
      "name": "flashattention2-custom-mask",
      "one_line_profile": "FlashAttention2 with Custom Mask Support",
      "detailed_description": "A Triton-based implementation of FlashAttention2 that extends the original kernel to support custom attention masks, useful for specialized attention patterns.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration_kernel",
        "attention_mechanism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/alexzhang13/flashattention2-custom-mask",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "flash-attention",
        "triton",
        "custom-mask"
      ],
      "id": 139
    },
    {
      "name": "EasyParallelLibrary",
      "one_line_profile": "Distributed Model Training Framework (EPL)",
      "detailed_description": "A general and efficient deep learning framework developed by Alibaba for distributed model training, simplifying the implementation of parallel strategies.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "parallelism"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/alibaba/EasyParallelLibrary",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "deep-learning",
        "alibaba"
      ],
      "id": 140
    },
    {
      "name": "Euler",
      "one_line_profile": "Distributed Graph Deep Learning Framework",
      "detailed_description": "A large-scale distributed graph learning framework developed by Alibaba, designed to handle massive graph data for deep learning tasks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "graph_learning",
        "distributed_training"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/alibaba/euler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "graph-neural-networks",
        "distributed-system",
        "graph-learning"
      ],
      "id": 141
    },
    {
      "name": "oss-connector-for-ai-ml",
      "one_line_profile": "OSS Storage Connector for AI/ML Frameworks",
      "detailed_description": "A high-performance Python library for connecting major AI/ML frameworks (like PyTorch, TensorFlow) directly with Alibaba Cloud OSS storage for efficient data loading.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "data_io",
        "storage_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aliyun/oss-connector-for-ai-ml",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-loading",
        "oss",
        "cloud-storage"
      ],
      "id": 142
    },
    {
      "name": "AlpaServe",
      "one_line_profile": "Statistical Multiplexing for Deep Learning Serving",
      "detailed_description": "A system for deep learning serving that utilizes statistical multiplexing with model parallelism to improve efficiency and throughput (OSDI 23).",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_serving",
        "distributed_inference"
      ],
      "application_level": "system",
      "primary_language": "Python",
      "repo_url": "https://github.com/alpa-projects/mms",
      "help_website": [],
      "license": null,
      "tags": [
        "serving",
        "model-parallelism",
        "multiplexing"
      ],
      "id": 143
    },
    {
      "name": "alpaka",
      "one_line_profile": "Abstraction Library for Parallel Kernel Acceleration",
      "detailed_description": "A C++ header-only library that provides an abstraction layer for parallel kernel acceleration across various hardware backends (CUDA, HIP, OpenMP, etc.).",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "hpc"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/alpaka-group/alpaka",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "hpc",
        "kernel-acceleration",
        "portability"
      ],
      "id": 144
    },
    {
      "name": "jvp_flash_attention",
      "one_line_profile": "Flash Attention with Second-Order Derivative Support",
      "detailed_description": "A Flash Attention Triton kernel implementation that supports Jacobian-Vector Products (JVP), enabling second-order derivative computations.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration_kernel",
        "differentiation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/amorehead/jvp_flash_attention",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "flash-attention",
        "triton",
        "second-order-derivatives"
      ],
      "id": 145
    },
    {
      "name": "Galaxy_simulation",
      "one_line_profile": "GPU-Accelerated N-Body Galaxy Simulation",
      "detailed_description": "An N-body simulation tool utilizing GPU acceleration to simulate galaxies, galaxy collisions, and expanding universes.",
      "domains": [
        "Scientific Computing",
        "Astrophysics"
      ],
      "subtask_category": [
        "simulation",
        "n_body"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/angeluriot/Galaxy_simulation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "n-body",
        "galaxy-simulation",
        "gpu"
      ],
      "id": 146
    },
    {
      "name": "LLMOPT",
      "one_line_profile": "Comprehensive resources and framework for LLM training and inference optimization",
      "detailed_description": "A project offering a model, dataset, training framework, and inference code to enable users to utilize and optimize Large Language Models (LLMs), specifically focusing on instruction tuning and optimization.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": "model_training",
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/antgroup/LLMOPT",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "training-framework",
        "optimization",
        "instruction-tuning"
      ],
      "id": 147
    },
    {
      "name": "GLake",
      "one_line_profile": "GPU memory management and IO transmission optimization library",
      "detailed_description": "A library designed to optimize GPU memory management and I/O transmission for deep learning training, aiming to improve efficiency and performance in distributed environments.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": "infrastructure_optimization",
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/antgroup/glake",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu-optimization",
        "memory-management",
        "distributed-training"
      ],
      "id": 148
    },
    {
      "name": "Apache MXNet",
      "one_line_profile": "Flexible and efficient distributed deep learning framework",
      "detailed_description": "A lightweight, portable, and flexible distributed deep learning framework that supports dynamic, mutation-aware dataflow dependency scheduling. It supports multiple languages including Python, R, and Julia.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": "model_training",
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/apache/mxnet",
      "help_website": [
        "https://mxnet.apache.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "deep-learning",
        "distributed-training",
        "framework"
      ],
      "id": 149
    },
    {
      "name": "Apache SINGA",
      "one_line_profile": "Distributed deep learning platform",
      "detailed_description": "A distributed deep learning platform for training big deep learning models over large datasets, designed to be intuitive and usable.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": "model_training",
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/apache/singa",
      "help_website": [
        "http://singa.apache.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "deep-learning",
        "distributed-system",
        "training-platform"
      ],
      "id": 150
    },
    {
      "name": "TensorFlow for macOS",
      "one_line_profile": "TensorFlow accelerated for macOS using ML Compute",
      "detailed_description": "A version of TensorFlow optimized for macOS 11.0+ that leverages Apple's ML Compute framework for hardware-accelerated training and inference on Mac devices.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": "model_training",
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/apple/tensorflow_macos",
      "help_website": [],
      "license": null,
      "tags": [
        "tensorflow",
        "macos",
        "acceleration",
        "ml-compute"
      ],
      "id": 151
    },
    {
      "name": "LLM-Inference-Bench",
      "one_line_profile": "Benchmark suite for LLM inference performance",
      "detailed_description": "A benchmarking tool designed to evaluate the inference performance of Large Language Models, likely developed by Argonne National Laboratory.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": "performance_analysis",
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/argonne-lcf/LLM-Inference-Bench",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "llm",
        "benchmarking",
        "inference",
        "hpc"
      ],
      "id": 152
    },
    {
      "name": "Arkalos",
      "one_line_profile": "Python framework for data analysis and LLM training",
      "detailed_description": "A Python framework designed to simplify data analysis, building data apps, and training Large Language Models (LLMs) with an elegant syntax.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": "model_training",
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/arkaloscom/arkalos",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-training",
        "data-analysis",
        "framework"
      ],
      "id": 153
    },
    {
      "name": "SiLLM",
      "one_line_profile": "LLM training and inference framework for Apple Silicon",
      "detailed_description": "A framework that simplifies the process of training and running Large Language Models (LLMs) on Apple Silicon devices by leveraging the MLX framework.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": "model_training",
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/armbues/SiLLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "apple-silicon",
        "mlx",
        "llm",
        "training"
      ],
      "id": 154
    },
    {
      "name": "StringZilla",
      "one_line_profile": "High-performance string processing library leveraging SIMD",
      "detailed_description": "A library providing up to 100x faster string operations (search, hashing, sorting, edit distances) for C, C++, Python, and other languages by leveraging NEON, AVX2, AVX-512, and other hardware acceleration. Useful for bioinformatics and text processing.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": "data_processing",
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/ashvardanian/StringZilla",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "simd",
        "string-processing",
        "hpc",
        "acceleration"
      ],
      "id": 155
    },
    {
      "name": "Fine-Tune Codebase",
      "one_line_profile": "Tool for fine-tuning LLMs on codebases",
      "detailed_description": "A scalable and efficient tool for fine-tuning large language models (LLMs) specifically on codebases. It supports LoRA, mixed precision training, and quantization.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": "model_training",
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ayminovitch/fine-tune-codebase",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "fine-tuning",
        "lora",
        "code-llm"
      ],
      "id": 156
    },
    {
      "name": "Piper Plus",
      "one_line_profile": "Enhanced Piper TTS training framework",
      "detailed_description": "An enhanced version of Piper TTS supporting multi-GPU training, Japanese language support, and quality improvements. It serves as a training framework for text-to-speech models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": "model_training",
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/ayutaz/piper-plus",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tts",
        "training-framework",
        "multi-gpu"
      ],
      "id": 157
    },
    {
      "name": "Distributed Llama",
      "one_line_profile": "Distributed LLM inference on home devices",
      "detailed_description": "A tool for distributed LLM inference that allows connecting multiple devices into a cluster to accelerate inference, effectively creating a distributed computing environment for LLMs.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": "inference",
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/b4rtaz/distributed-llama",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "distributed-inference",
        "llm",
        "edge-computing"
      ],
      "id": 158
    },
    {
      "name": "tf2-gradient-checkpointing",
      "one_line_profile": "Gradient checkpointing implementation for TensorFlow 2 eager execution",
      "detailed_description": "A Python library providing gradient checkpointing functionality for TensorFlow 2 in eager mode, enabling the training of larger models by trading compute for memory.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "memory_optimization",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/davisyoshida/tf2-gradient-checkpointing",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tensorflow",
        "gradient-checkpointing",
        "memory-optimization"
      ],
      "id": 159
    },
    {
      "name": "AdaSplash",
      "one_line_profile": "Adaptive Sparse Flash Attention implementation",
      "detailed_description": "A library implementing Adaptive Sparse Flash Attention (Flash Entmax Attention), designed to optimize attention mechanisms in transformer models for better efficiency.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "attention_mechanism",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deep-spin/adasplash",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "attention",
        "sparse-attention",
        "transformer"
      ],
      "id": 160
    },
    {
      "name": "3FS",
      "one_line_profile": "High-performance distributed file system for AI training",
      "detailed_description": "A high-performance distributed file system specifically designed to address the I/O challenges of large-scale AI training and inference workloads, providing high throughput and low latency.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "data_storage",
        "distributed_training"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/deepseek-ai/3FS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "file-system",
        "distributed-storage",
        "ai-infrastructure"
      ],
      "id": 161
    },
    {
      "name": "DualPipe",
      "one_line_profile": "Bidirectional pipeline parallelism for LLM training",
      "detailed_description": "A bidirectional pipeline parallelism algorithm designed to overlap computation and communication during the training of large language models like DeepSeek V3/R1.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "pipeline_parallelism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepseek-ai/DualPipe",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pipeline-parallelism",
        "llm-training",
        "distributed-computing"
      ],
      "id": 162
    },
    {
      "name": "FlashMLA",
      "one_line_profile": "Efficient Multi-head Latent Attention Kernels",
      "detailed_description": "A library providing optimized kernels for Multi-head Latent Attention (MLA), designed to accelerate inference and training of large language models on GPUs.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "kernel_optimization",
        "attention_mechanism"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/deepseek-ai/FlashMLA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cuda-kernels",
        "attention",
        "optimization"
      ],
      "id": 163
    },
    {
      "name": "DeepSpeed",
      "one_line_profile": "Deep learning optimization library for distributed training",
      "detailed_description": "A deep learning optimization library that enables massive-scale distributed training and inference with high efficiency, ease of use, and effectiveness, supporting techniques like ZeRO, pipeline parallelism, and 3D parallelism.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepspeedai/DeepSpeed",
      "help_website": [
        "https://www.deepspeed.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "zero-redundancy",
        "optimization"
      ],
      "id": 164
    },
    {
      "name": "DeepSpeed-MII",
      "one_line_profile": "Low-latency and high-throughput inference library",
      "detailed_description": "Model Implementations for Inference (MII) is a library powered by DeepSpeed that provides low-latency and high-throughput inference for deep learning models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "inference_optimization",
        "model_serving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepspeedai/DeepSpeed-MII",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "latency-optimization",
        "deepspeed"
      ],
      "id": 165
    },
    {
      "name": "Determined",
      "one_line_profile": "Open-source deep learning training platform",
      "detailed_description": "A platform that simplifies distributed training, hyperparameter tuning, experiment tracking, and resource management for deep learning models, supporting PyTorch and TensorFlow.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "training_platform",
        "experiment_management",
        "hyperparameter_tuning"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/determined-ai/determined",
      "help_website": [
        "https://docs.determined.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "distributed-training",
        "experiment-tracking"
      ],
      "id": 166
    },
    {
      "name": "DeepDist",
      "one_line_profile": "Distributed Deep Learning on Apache Spark",
      "detailed_description": "A tool that enables distributed deep learning training on Apache Spark clusters, allowing users to leverage Spark's data processing capabilities for deep learning workflows.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "spark_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dirkneumann/deepdist",
      "help_website": [],
      "license": null,
      "tags": [
        "spark",
        "distributed-learning",
        "deep-learning"
      ],
      "id": 167
    },
    {
      "name": "Paracel",
      "one_line_profile": "Distributed training framework with parameter server",
      "detailed_description": "A distributed training framework that implements the parameter server architecture to scale machine learning model training across multiple nodes.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "parameter_server"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/douban/paracel",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "parameter-server",
        "distributed-ml",
        "framework"
      ],
      "id": 168
    },
    {
      "name": "Dragonfly",
      "one_line_profile": "P2P-based data distribution and acceleration system",
      "detailed_description": "An intelligent P2P based image and file distribution system that provides efficient data distribution and acceleration for cloud native and AI workloads.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "data_distribution",
        "infrastructure_acceleration"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/dragonflyoss/dragonfly",
      "help_website": [
        "https://d7y.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "p2p",
        "file-distribution",
        "container-acceleration"
      ],
      "id": 169
    },
    {
      "name": "VisDrone-dataset-python-toolkit",
      "one_line_profile": "Toolkit for VisDrone aerial object detection dataset",
      "detailed_description": "A PyTorch toolkit designed for the VisDrone dataset, providing training pipelines, inference tools, and format converters for aerial object detection tasks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "data_processing",
        "object_detection",
        "training_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/dronefreak/VisDrone-dataset-python-toolkit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "visdrone",
        "object-detection",
        "aerial-imagery"
      ],
      "id": 170
    },
    {
      "name": "js-pytorch",
      "one_line_profile": "JavaScript deep learning library with GPU acceleration",
      "detailed_description": "A JavaScript library that provides a PyTorch-like API for deep learning, supporting GPU acceleration for training and inference in JavaScript environments.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/eduardoleao052/js-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "javascript",
        "deep-learning",
        "gpu-acceleration"
      ],
      "id": 171
    },
    {
      "name": "jax-flash-attn2",
      "one_line_profile": "Flash Attention 2.0 implementation for JAX",
      "detailed_description": "A flexible and efficient implementation of Flash Attention 2.0 for JAX, supporting multiple backends (GPU/TPU) and enabling efficient attention computation in JAX-based models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "attention_mechanism",
        "kernel_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/erfanzar/jax-flash-attn2",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jax",
        "flash-attention",
        "optimization"
      ],
      "id": 172
    },
    {
      "name": "fsdp_optimizers",
      "one_line_profile": "Optimizer support for PyTorch FSDP",
      "detailed_description": "A library that provides support for using various optimizers with PyTorch's Fully Sharded Data Parallel (FSDP) training, facilitating distributed training workflows.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ethansmith2000/fsdp_optimizers",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fsdp",
        "pytorch",
        "distributed-training"
      ],
      "id": 173
    },
    {
      "name": "nvblox_ros1",
      "one_line_profile": "ROS1 wrappers for nvblox GPU volumetric mapping",
      "detailed_description": "ROS1 wrappers for nvblox, enabling GPU-accelerated volumetric mapping for robotics and perception tasks, facilitating real-time 3D reconstruction.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "volumetric_mapping",
        "robotics_perception"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/ethz-asl/nvblox_ros1",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ros",
        "mapping",
        "gpu-acceleration"
      ],
      "id": 174
    },
    {
      "name": "Expert Kit",
      "one_line_profile": "Expert Parallelism foundation for MoE inference",
      "detailed_description": "A library providing efficient implementations of Expert Parallelism (EP) for Mixture-of-Experts (MoE) model inference on heterogeneous hardware.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "inference_optimization",
        "moe_parallelism"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/expert-kit/expert-kit",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "moe",
        "inference",
        "parallelism"
      ],
      "id": 175
    },
    {
      "name": "spaCy",
      "one_line_profile": "Industrial-strength Natural Language Processing library",
      "detailed_description": "A comprehensive library for Natural Language Processing (NLP) in Python, featuring pre-trained models, efficient tokenization, and support for deep learning integration.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "nlp",
        "text_processing",
        "model_inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/explosion/spaCy",
      "help_website": [
        "https://spacy.io/"
      ],
      "license": "MIT",
      "tags": [
        "nlp",
        "text-processing",
        "linguistics"
      ],
      "id": 176
    },
    {
      "name": "Dynolog",
      "one_line_profile": "Telemetry daemon for AI performance monitoring",
      "detailed_description": "A telemetry daemon for performance monitoring and tracing of AI workloads, capable of exporting metrics from system components and integrating with PyTorch for distributed training analysis.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "performance_monitoring",
        "profiling"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/facebookincubator/dynolog",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "telemetry",
        "profiling",
        "gpu-monitoring"
      ],
      "id": 177
    },
    {
      "name": "Flashy",
      "one_line_profile": "Framework for deep learning training loops",
      "detailed_description": "A lightweight framework for writing deep learning training loops that handles checkpointing, logging, and distributed training setup, allowing researchers to focus on model design.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "training_framework",
        "experiment_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/flashy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "training-loop",
        "pytorch",
        "boilerplate"
      ],
      "id": 178
    },
    {
      "name": "moolib",
      "one_line_profile": "Library for distributed ML training with PyTorch",
      "detailed_description": "A C++ and Python library designed to facilitate distributed machine learning training with PyTorch, offering efficient communication primitives and data loading.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "communication_primitives"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/facebookresearch/moolib",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "distributed-ml",
        "rpc",
        "pytorch"
      ],
      "id": 179
    },
    {
      "name": "Stochastic Gradient Push",
      "one_line_profile": "Stochastic Gradient Push algorithm for distributed learning",
      "detailed_description": "An implementation of the Stochastic Gradient Push algorithm, enabling decentralized distributed deep learning on directed graphs.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "optimization_algorithm"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/stochastic_gradient_push",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "distributed-learning",
        "gossip-algorithm",
        "decentralized"
      ],
      "id": 180
    },
    {
      "name": "flash-bidirectional-linear-attention",
      "one_line_profile": "Triton implementation of bi-directional linear attention",
      "detailed_description": "A library providing efficient Triton-based implementations of bi-directional (non-causal) linear attention mechanisms for transformer models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "attention_mechanism",
        "kernel_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fla-org/flash-bidirectional-linear-attention",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "linear-attention",
        "triton",
        "optimization"
      ],
      "id": 181
    },
    {
      "name": "flash-linear-attention",
      "one_line_profile": "Efficient linear attention model implementations",
      "detailed_description": "A library containing efficient implementations of state-of-the-art linear attention models, optimized for speed and memory usage in sequence modeling tasks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "attention_mechanism",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fla-org/flash-linear-attention",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "linear-attention",
        "efficient-transformers",
        "cuda"
      ],
      "id": 182
    },
    {
      "name": "Flash Sparse Attention",
      "one_line_profile": "Fast and memory-efficient sparse attention mechanism for Transformer training",
      "detailed_description": "A library providing trainable, fast, and memory-efficient sparse attention kernels, designed to accelerate the training of large-scale Transformer models by optimizing GPU memory usage and computation speed.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_acceleration",
        "training_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/flash-algo/flash-sparse-attention",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "sparse-attention",
        "transformer",
        "acceleration",
        "gpu-kernels"
      ],
      "id": 183
    },
    {
      "name": "FlashInfer",
      "one_line_profile": "High-performance kernel library for LLM serving and inference acceleration",
      "detailed_description": "A kernel library designed to accelerate Large Language Model (LLM) serving. It provides optimized CUDA kernels for attention mechanisms and other operations critical for efficient inference in scientific and general AI applications.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_serving"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/flashinfer-ai/flashinfer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-serving",
        "cuda-kernels",
        "inference",
        "acceleration"
      ],
      "id": 184
    },
    {
      "name": "FlexFlow",
      "one_line_profile": "Deep learning framework for automatic distributed training parallelization",
      "detailed_description": "A deep learning framework that automatically discovers fast parallelization strategies for distributed deep neural network training, optimizing performance across heterogeneous cluster environments.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "parallelization_strategy"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/flexflow/flexflow-train",
      "help_website": [
        "https://flexflow.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "parallelization",
        "deep-learning"
      ],
      "id": 185
    },
    {
      "name": "Deep Learning on Flink",
      "one_line_profile": "Integration of deep learning frameworks with Apache Flink for distributed training",
      "detailed_description": "A framework that integrates Flink with deep learning libraries (TensorFlow, PyTorch) to enable distributed deep learning training and inference workflows on Flink clusters.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "workflow_integration"
      ],
      "application_level": "framework",
      "primary_language": "Java",
      "repo_url": "https://github.com/flink-extended/dl-on-flink",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "flink",
        "distributed-training",
        "tensorflow",
        "pytorch"
      ],
      "id": 186
    },
    {
      "name": "FMS Acceleration",
      "one_line_profile": "Acceleration libraries for fine-tuning foundation models",
      "detailed_description": "A collection of libraries designed to work with fms-hf-tuning to accelerate the fine-tuning and training processes of large foundation models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_acceleration",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/foundation-model-stack/fms-acceleration",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fine-tuning",
        "acceleration",
        "foundation-models"
      ],
      "id": 187
    },
    {
      "name": "FMS FSDP",
      "one_line_profile": "Efficient foundation model training using PyTorch FSDP",
      "detailed_description": "A library for efficiently pre-training and training foundation models leveraging native PyTorch features, specifically Fully Sharded Data Parallel (FSDP) and Flash Attention v2.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "fsdp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/foundation-model-stack/fms-fsdp",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fsdp",
        "distributed-training",
        "pytorch"
      ],
      "id": 188
    },
    {
      "name": "FMS HF Tuning",
      "one_line_profile": "Tuning recipes for foundation models with HuggingFace and FSDP",
      "detailed_description": "A collection of tuning recipes and utilities integrating HuggingFace SFTTrainer with PyTorch FSDP for efficient model fine-tuning.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "fine_tuning",
        "training_recipes"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/foundation-model-stack/fms-hf-tuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fine-tuning",
        "huggingface",
        "fsdp"
      ],
      "id": 189
    },
    {
      "name": "Foundation Model Stack",
      "one_line_profile": "Comprehensive stack for foundation model development and training",
      "detailed_description": "A collection of components for the development, training, tuning, and inference of foundation models, leveraging native PyTorch components for modularity and performance.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_development",
        "training_stack"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/foundation-model-stack/foundation-model-stack",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "foundation-models",
        "training-stack",
        "pytorch"
      ],
      "id": 190
    },
    {
      "name": "SkipPipe",
      "one_line_profile": "Framework for pipelined training of LLMs in heterogeneous networks",
      "detailed_description": "A framework implementing partial and reordered pipelining strategies to optimize the training of Large Language Models (LLMs) across heterogeneous network environments.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "pipeline_parallelism"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/gensyn-ai/skippipe",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pipeline-parallelism",
        "llm-training",
        "heterogeneous-computing"
      ],
      "id": 191
    },
    {
      "name": "Knowledge Distillation Toolkit",
      "one_line_profile": "Toolkit for knowledge distillation based on PyTorch Lightning",
      "detailed_description": "A toolkit designed to facilitate knowledge distillation experiments and implementation, built on top of PyTorch and PyTorch Lightning.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "knowledge_distillation",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/georgian-io/Knowledge-Distillation-Toolkit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-distillation",
        "pytorch-lightning"
      ],
      "id": 192
    },
    {
      "name": "Llama2 LoRA Fine-tuning",
      "one_line_profile": "Scripts for fine-tuning Llama2 using DeepSpeed and LoRA",
      "detailed_description": "A utility repository providing scripts and configurations for fine-tuning Llama2 models using DeepSpeed for distributed training and LoRA for parameter-efficient adaptation.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "fine_tuning",
        "parameter_efficient_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/git-cloner/llama2-lora-fine-tuning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llama2",
        "lora",
        "deepspeed",
        "fine-tuning"
      ],
      "id": 193
    },
    {
      "name": "Pax",
      "one_line_profile": "Jax-based framework for training large scale machine learning models",
      "detailed_description": "A machine learning framework built on Jax, designed for advanced configuration and parallelization to train large-scale models with high flop utilization.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "training_framework",
        "large_scale_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/google/paxml",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jax",
        "large-scale-training",
        "pax"
      ],
      "id": 194
    },
    {
      "name": "GPGPU-Sim",
      "one_line_profile": "Cycle-level simulator for NVIDIA GPUs",
      "detailed_description": "A detailed simulation model of contemporary NVIDIA GPUs running CUDA and/or OpenCL workloads, used for computer architecture research and performance analysis of GPU-accelerated applications.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "hardware_simulation",
        "performance_analysis"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/gpgpu-sim/gpgpu-sim_distribution",
      "help_website": [
        "http://www.gpgpu-sim.org/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "gpu-simulator",
        "cuda",
        "computer-architecture"
      ],
      "id": 195
    },
    {
      "name": "PyGraphistry",
      "one_line_profile": "GPU-accelerated library for big graph visualization and analysis",
      "detailed_description": "A Python library to load, shape, embed, and explore large graphs using GPU acceleration, facilitating visual graph analysis for scientific and data science applications.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "scientific_visualization",
        "graph_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/graphistry/pygraphistry",
      "help_website": [
        "https://github.com/graphistry/pygraphistry"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "graph-visualization",
        "gpu-acceleration",
        "data-analysis"
      ],
      "id": 196
    },
    {
      "name": "Koifish",
      "one_line_profile": "C++ framework for efficient LLM training and fine-tuning",
      "detailed_description": "A C++ framework designed for the efficient training and fine-tuning of Large Language Models (LLMs), offering performance optimizations for model development.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "training_framework",
        "fine_tuning"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/gruai/koifish",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-training",
        "c++",
        "fine-tuning"
      ],
      "id": 197
    },
    {
      "name": "gLLM",
      "one_line_profile": "Global balanced pipeline parallelism system for distributed LLM serving",
      "detailed_description": "A system for distributed Large Language Model (LLM) serving that implements global balanced pipeline parallelism and token throttling to optimize throughput and latency.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_serving",
        "pipeline_parallelism"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/gty111/gLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-serving",
        "distributed-system",
        "pipeline-parallelism"
      ],
      "id": 198
    },
    {
      "name": "BERT Pre-training",
      "one_line_profile": "Multi-GPU BERT pre-training implementation",
      "detailed_description": "A utility implementation for multi-GPU pre-training of BERT models on a single machine without requiring Horovod, facilitating model training workflows.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "pre_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/guotong1988/BERT-pre-training",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bert",
        "pre-training",
        "multi-gpu"
      ],
      "id": 199
    },
    {
      "name": "BERT Classifier",
      "one_line_profile": "General text classifier based on BERT with multi-GPU support",
      "detailed_description": "A general-purpose text classification tool based on BERT, supporting multi-process data processing and multi-GPU parallel training.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "text_classification",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/guoyaohua/BERT-Classifier",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bert",
        "text-classification",
        "nlp"
      ],
      "id": 200
    },
    {
      "name": "LvLLM",
      "one_line_profile": "NUMA-aware extension of vLLM for efficient CPU/GPU hybrid inference",
      "detailed_description": "A specialized extension of vLLM that optimizes for NUMA architectures, enabling efficient use of CPU and memory resources alongside GPUs for hybrid inference of large models, particularly MOEs.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "inference_acceleration",
        "hybrid_inference"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/guqiong96/Lvllm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vllm",
        "numa",
        "inference",
        "moe"
      ],
      "id": 201
    },
    {
      "name": "H2O-3",
      "one_line_profile": "Distributed and scalable open-source machine learning platform",
      "detailed_description": "A distributed, in-memory machine learning platform that provides scalable implementations of various algorithms (GBM, GLM, Deep Learning, etc.) and AutoML capabilities for data analysis and modeling.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "machine_learning_platform",
        "automl"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/h2oai/h2o-3",
      "help_website": [
        "http://docs.h2o.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "machine-learning",
        "distributed-computing",
        "automl"
      ],
      "id": 202
    },
    {
      "name": "APPy",
      "one_line_profile": "Annotated Parallelism for Python to GPU compiler",
      "detailed_description": "A framework that enables users to annotate Python loops and tensor expressions with compiler directives to automatically generate and compile optimized GPU kernels.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "code_acceleration",
        "compilation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/habanero-lab/APPy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu-compilation",
        "parallelism",
        "python"
      ],
      "id": 203
    },
    {
      "name": "XReflection",
      "one_line_profile": "Toolbox for single-image reflection removal",
      "detailed_description": "A toolbox providing state-of-the-art solutions for single-image reflection removal (SIRR), including training and inference pipelines with multi-GPU/TPU support.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "image_processing",
        "image_restoration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hainuo-wang/XReflection",
      "help_website": [],
      "license": null,
      "tags": [
        "reflection-removal",
        "image-processing",
        "computer-vision"
      ],
      "id": 204
    },
    {
      "name": "EfficientNetV2-pytorch",
      "one_line_profile": "PyTorch implementation of EfficientNetV2 with pretrained models",
      "detailed_description": "A PyTorch implementation of the EfficientNetV2 architecture, including pretrained models, facilitating its use in computer vision tasks.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "model_implementation",
        "computer_vision"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hankyul2/EfficientNetV2-pytorch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "efficientnetv2",
        "pytorch",
        "computer-vision"
      ],
      "id": 205
    },
    {
      "name": "FastVideo",
      "one_line_profile": "Framework for accelerated video generation inference and post-training",
      "detailed_description": "A unified framework designed to accelerate the inference and post-training processes for video generation models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "video_generation",
        "inference_acceleration"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/hao-ai-lab/FastVideo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "video-generation",
        "acceleration",
        "inference"
      ],
      "id": 206
    },
    {
      "name": "HeAT",
      "one_line_profile": "Distributed tensor and machine learning framework with GPU/MPI acceleration",
      "detailed_description": "A Python framework for distributed tensor processing and machine learning, leveraging GPU and MPI acceleration to handle large-scale scientific data analysis.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_computing",
        "tensor_processing"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/helmholtz-analytics/heat",
      "help_website": [
        "https://heat.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "distributed-tensors",
        "mpi",
        "gpu",
        "scientific-computing"
      ],
      "id": 207
    },
    {
      "name": "VodaScheduler",
      "one_line_profile": "GPU scheduler for elastic distributed deep learning workloads",
      "detailed_description": "A GPU scheduler designed for Kubernetes clusters to manage elastic and distributed deep learning workloads efficiently.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "resource_scheduling",
        "cluster_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/heyfey/vodascheduler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu-scheduler",
        "kubernetes",
        "distributed-training"
      ],
      "id": 208
    },
    {
      "name": "Higgsfield",
      "one_line_profile": "Fault-tolerant GPU orchestration and training framework for large-scale models",
      "detailed_description": "Higgsfield is a machine learning framework and GPU orchestration platform designed for training models with billions to trillions of parameters. It focuses on fault tolerance and high scalability, enabling efficient distributed training on large clusters.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/higgsfield-ai/higgsfield",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu-orchestration",
        "large-model-training",
        "fault-tolerance"
      ],
      "id": 209
    },
    {
      "name": "EasyR1",
      "one_line_profile": "Efficient multi-modality reinforcement learning training framework",
      "detailed_description": "EasyR1 is a scalable and efficient reinforcement learning (RL) training framework based on veRL. It supports multi-modality training, making it suitable for complex RLHF (Reinforcement Learning from Human Feedback) tasks and large model fine-tuning.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "fine_tuning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/hiyouga/EasyR1",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "multi-modality",
        "verl"
      ],
      "id": 210
    },
    {
      "name": "mipnerf_pl",
      "one_line_profile": "PyTorch Lightning implementation of Mip-NeRF for 3D reconstruction",
      "detailed_description": "An unofficial but widely used PyTorch Lightning implementation of Mip-NeRF, a method for high-quality 3D reconstruction and rendering from 2D images. It serves as a solver for inverse rendering tasks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "3d_reconstruction",
        "rendering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hjxwhy/mipnerf_pl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nerf",
        "pytorch-lightning",
        "3d-rendering"
      ],
      "id": 211
    },
    {
      "name": "ptlflow",
      "one_line_profile": "Unified interface for Optical Flow models using PyTorch Lightning",
      "detailed_description": "Ptlflow is a library that provides a unified interface for various optical flow models, scripts for training and inference, and pretrained weights. It facilitates the application of optical flow estimation in scientific video analysis.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "optical_flow",
        "computer_vision"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hmorimitsu/ptlflow",
      "help_website": [
        "https://ptlflow.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "optical-flow",
        "pytorch-lightning",
        "motion-estimation"
      ],
      "id": 212
    },
    {
      "name": "Horovod",
      "one_line_profile": "Distributed deep learning training framework",
      "detailed_description": "Horovod is a distributed deep learning training framework for TensorFlow, Keras, PyTorch, and Apache MXNet. It simplifies the process of scaling single-GPU training scripts to run across many GPUs and nodes using MPI.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/horovod/horovod",
      "help_website": [
        "https://horovod.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "mpi",
        "deep-learning"
      ],
      "id": 213
    },
    {
      "name": "CachedEmbedding",
      "one_line_profile": "Memory-efficient embedding solution for DLRM training",
      "detailed_description": "CachedEmbedding is a library designed to optimize memory usage during the training of Deep Learning Recommendation Models (DLRM). It utilizes ColossalAI to enable efficient handling of large embedding tables.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "memory_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hpcaitech/CachedEmbedding",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dlrm",
        "embedding",
        "colossalai"
      ],
      "id": 214
    },
    {
      "name": "Colossal-AI",
      "one_line_profile": "Unified deep learning system for large-scale model training and inference",
      "detailed_description": "Colossal-AI is a comprehensive system designed to make large AI models cheaper, faster, and more accessible. It provides a collection of parallel components (data, pipeline, tensor, sequence parallelism) and optimization techniques for distributed training.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "large_model_optimization"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/hpcaitech/ColossalAI",
      "help_website": [
        "https://colossalai.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-system",
        "parallelism",
        "large-models"
      ],
      "id": 215
    },
    {
      "name": "ColossalAI-Benchmark",
      "one_line_profile": "Benchmarking suite for ColossalAI performance",
      "detailed_description": "A utility tool for benchmarking the performance of models trained with ColossalAI, helping researchers and engineers evaluate training throughput and efficiency.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_analysis"
      ],
      "application_level": "utility",
      "primary_language": "Python",
      "repo_url": "https://github.com/hpcaitech/ColossalAI-Benchmark",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "performance",
        "colossalai"
      ],
      "id": 216
    },
    {
      "name": "ColossalAI-Platform-CLI",
      "one_line_profile": "Command-line interface for ColossalAI Platform",
      "detailed_description": "The official CLI tool for interacting with the ColossalAI Platform, enabling users to manage jobs, datasets, and compute resources for large-scale AI training.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "job_management",
        "platform_interface"
      ],
      "application_level": "utility",
      "primary_language": "Python",
      "repo_url": "https://github.com/hpcaitech/ColossalAI-Platform-CLI",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "cli",
        "colossalai",
        "cloud-platform"
      ],
      "id": 217
    },
    {
      "name": "Titans",
      "one_line_profile": "Model zoo for ColossalAI",
      "detailed_description": "Titans is a collection of model implementations built with ColossalAI. It serves as a model zoo library, providing ready-to-use model definitions compatible with ColossalAI's distributed training features.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_definition",
        "model_zoo"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hpcaitech/Titans",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "model-zoo",
        "colossalai",
        "transformers"
      ],
      "id": 218
    },
    {
      "name": "Accelerate",
      "one_line_profile": "Library for abstracting training loops across hardware configurations",
      "detailed_description": "Accelerate is a library that enables the same PyTorch code to run across any distributed configuration (single GPU, multi-GPU, TPU, MPS) without significant code changes. It handles device placement and distributed communication.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "hardware_abstraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/accelerate",
      "help_website": [
        "https://huggingface.co/docs/accelerate/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "pytorch",
        "distributed",
        "mixed-precision"
      ],
      "id": 219
    },
    {
      "name": "Nanotron",
      "one_line_profile": "Minimalistic 3D-parallelism training library for LLMs",
      "detailed_description": "Nanotron is a library designed for training Large Language Models (LLMs) using 3D parallelism (Tensor, Pipeline, and Data Parallelism). It focuses on simplicity and efficiency for scaling model training.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "llm_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/nanotron",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "3d-parallelism",
        "llm",
        "training"
      ],
      "id": 220
    },
    {
      "name": "Optimum",
      "one_line_profile": "Hardware optimization toolkit for Transformers",
      "detailed_description": "Optimum is an extension of Hugging Face Transformers that provides tools for training and inference optimization on specific hardware architectures (Intel, ONNX Runtime, AWS Trainium, etc.).",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "training_optimization",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/optimum",
      "help_website": [
        "https://huggingface.co/docs/optimum/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hardware-acceleration",
        "optimization",
        "transformers"
      ],
      "id": 221
    },
    {
      "name": "Transformers",
      "one_line_profile": "State-of-the-art machine learning model library",
      "detailed_description": "Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. It supports a wide range of tasks across text, vision, and audio, serving as a foundational library for AI4S modeling.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "model_definition"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/transformers",
      "help_website": [
        "https://huggingface.co/docs/transformers/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "computer-vision",
        "pretrained-models"
      ],
      "id": 222
    },
    {
      "name": "Machin",
      "one_line_profile": "Reinforcement learning library for PyTorch",
      "detailed_description": "Machin is a reinforcement learning library designed for PyTorch, implementing various algorithms like DQN, DDPG, PPO, SAC, etc. It provides a framework for developing and testing RL agents.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "reinforcement_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/iffiX/machin",
      "help_website": [
        "https://machin.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "reinforcement-learning",
        "pytorch",
        "rl-algorithms"
      ],
      "id": 223
    },
    {
      "name": "self_supervised",
      "one_line_profile": "PyTorch Lightning implementation of self-supervised algorithms",
      "detailed_description": "A library providing implementations of various self-supervised learning algorithms (SimCLR, BYOL, SwAV, etc.) using PyTorch Lightning, facilitating representation learning research.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "self_supervised_learning",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/imbue-ai/self_supervised",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "self-supervised",
        "contrastive-learning",
        "pytorch-lightning"
      ],
      "id": 224
    },
    {
      "name": "Multipack",
      "one_line_profile": "Distributed sampler for padding-free LLM training",
      "detailed_description": "Multipack is a specialized distributed sampler designed to optimize Large Language Model (LLM) training by enabling fast, padding-free data loading, improving training efficiency.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "data_loading",
        "training_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/imoneoi/multipack",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "data-sampler",
        "efficiency"
      ],
      "id": 225
    },
    {
      "name": "Asystem-Awex",
      "one_line_profile": "High-performance RL training-inference synchronization framework",
      "detailed_description": "A framework designed for high-performance Reinforcement Learning (RL) workflows, specifically focusing on the rapid synchronization of weights between training and inference processes.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "distributed_system"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/inclusionAI/asystem-awex",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reinforcement-learning",
        "synchronization",
        "inference"
      ],
      "id": 226
    },
    {
      "name": "Intel MLSL",
      "one_line_profile": "Intel Machine Learning Scaling Library",
      "detailed_description": "Intel MLSL is a library providing efficient implementations of communication patterns used in deep learning, designed to scale training across multiple nodes and clusters.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "communication_optimization"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/intel/MLSL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "distributed-learning",
        "intel"
      ],
      "id": 227
    },
    {
      "name": "Intel Extension for DeepSpeed",
      "one_line_profile": "Intel GPU (XPU) support for DeepSpeed",
      "detailed_description": "An extension that enables DeepSpeed features on Intel GPU (XPU) devices, allowing for optimized distributed training on Intel hardware architectures.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "hardware_acceleration",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/intel/intel-extension-for-deepspeed",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "deepspeed",
        "intel-xpu",
        "acceleration"
      ],
      "id": 228
    },
    {
      "name": "Intel Technology Enabling for OpenShift",
      "one_line_profile": "Full-stack AI solution for OpenShift on Intel hardware",
      "detailed_description": "A comprehensive solution for provisioning and managing Intel AI accelerators and software stacks on the OpenShift platform, facilitating enterprise AI workloads like LLM training and inference.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "infrastructure_provisioning",
        "platform_deployment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/intel/intel-technology-enabling-for-openshift",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "openshift",
        "intel",
        "ai-infrastructure"
      ],
      "id": 229
    },
    {
      "name": "IPEX-LLM",
      "one_line_profile": "LLM inference and finetuning acceleration on Intel XPU",
      "detailed_description": "IPEX-LLM is a library for accelerating local Large Language Model (LLM) inference and fine-tuning on Intel hardware (CPUs, GPUs, NPUs). It integrates with popular ecosystems like HuggingFace, vLLM, and LlamaIndex.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "inference_acceleration",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/intel/ipex-llm",
      "help_website": [
        "https://ipex-llm.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "intel",
        "llm",
        "acceleration"
      ],
      "id": 230
    },
    {
      "name": "Nauta",
      "one_line_profile": "Distributed deep learning platform for Intel Xeon systems",
      "detailed_description": "Nauta is a multi-user, distributed computing environment designed for running deep learning model training experiments on Intel Xeon Scalable processor-based systems using Kubernetes.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "cluster_management",
        "job_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/intel/nauta",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "deep-learning-platform",
        "intel"
      ],
      "id": 231
    },
    {
      "name": "DLRover",
      "one_line_profile": "Automatic distributed deep learning system",
      "detailed_description": "DLRover is an automatic distributed deep learning system that provides fault tolerance, auto-scaling, and resource optimization for training jobs on Kubernetes clusters.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "resource_management"
      ],
      "application_level": "system",
      "primary_language": "Python",
      "repo_url": "https://github.com/intelligent-machine-learning/dlrover",
      "help_website": [
        "https://dlrover.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "kubernetes",
        "auto-scaling"
      ],
      "id": 232
    },
    {
      "name": "NeuralNetworks",
      "one_line_profile": "Java deep learning library with GPU acceleration",
      "detailed_description": "A Java-based library for implementing deep learning algorithms and neural networks, featuring GPU acceleration support. It serves as a solver/library for Java-based scientific computing environments.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "deep_learning"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/ivan-vasilev/neuralnetworks",
      "help_website": [],
      "license": "Unknown",
      "tags": [
        "java",
        "deep-learning",
        "gpu"
      ],
      "id": 233
    },
    {
      "name": "Alpaca-LoRA-RLHF-PyTorch",
      "one_line_profile": "Pipeline for finetuning Alpaca with LoRA and RLHF",
      "detailed_description": "A complete pipeline implementation for fine-tuning Alpaca-style Large Language Models using Low-Rank Adaptation (LoRA) and Reinforcement Learning with Human Feedback (RLHF) on consumer hardware.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "fine_tuning",
        "rlhf"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/jackaduma/Alpaca-LoRA-RLHF-PyTorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lora",
        "rlhf",
        "alpaca"
      ],
      "id": 234
    },
    {
      "name": "ChatGLM-LoRA-RLHF-PyTorch",
      "one_line_profile": "Pipeline for finetuning ChatGLM with LoRA and RLHF",
      "detailed_description": "A complete pipeline implementation for fine-tuning ChatGLM models using LoRA and RLHF. It provides the necessary workflows to adapt ChatGLM for specific tasks using reinforcement learning.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "fine_tuning",
        "rlhf"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/jackaduma/ChatGLM-LoRA-RLHF-PyTorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chatglm",
        "lora",
        "rlhf"
      ],
      "id": 235
    },
    {
      "name": "robo-gym",
      "one_line_profile": "Open source toolkit for Distributed Deep Reinforcement Learning on real and simulated robots",
      "detailed_description": "A toolkit that enables distributed Deep Reinforcement Learning on both real and simulated robots, facilitating the development and training of robotic control policies.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "robotics_simulation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/jr-robotics/robo-gym",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "robotics",
        "reinforcement-learning",
        "simulation",
        "distributed-training"
      ],
      "id": 236
    },
    {
      "name": "torch_ACA",
      "one_line_profile": "Adaptive Checkpoint Adjoint (ACA) method for gradient estimation in neural ODEs",
      "detailed_description": "Implementation of the Adaptive Checkpoint Adjoint method to improve gradient estimation accuracy and memory efficiency in Neural Ordinary Differential Equations (Neural ODEs).",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "gradient_estimation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/juntang-zhuang/torch_ACA",
      "help_website": [],
      "license": null,
      "tags": [
        "neural-ode",
        "gradient-estimation",
        "pytorch"
      ],
      "id": 237
    },
    {
      "name": "pykaldi2",
      "one_line_profile": "Speech processing toolkit based on Kaldi and PyTorch",
      "detailed_description": "A toolkit for speech recognition and processing that integrates Kaldi's efficiency with PyTorch's flexibility, supporting various speech modeling tasks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "speech_processing",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jzlianglu/pykaldi2",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "speech-recognition",
        "kaldi",
        "pytorch"
      ],
      "id": 238
    },
    {
      "name": "point2vec",
      "one_line_profile": "Self-Supervised Representation Learning on Point Clouds",
      "detailed_description": "A library for self-supervised representation learning on 3D point clouds, enabling effective feature extraction for downstream 3D vision tasks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "representation_learning",
        "3d_vision"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kabouzeid/point2vec",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "point-cloud",
        "self-supervised-learning",
        "3d-vision"
      ],
      "id": 239
    },
    {
      "name": "FlashAttention.C",
      "one_line_profile": "Raw CUDA C implementation of Flash Attention",
      "detailed_description": "A highly optimized CUDA C implementation of the Flash Attention algorithm, designed to accelerate attention mechanisms in transformer models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "kernel_optimization"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/kilianhae/FlashAttention.C",
      "help_website": [],
      "license": null,
      "tags": [
        "cuda",
        "flash-attention",
        "optimization"
      ],
      "id": 240
    },
    {
      "name": "hydra",
      "one_line_profile": "Execution framework for multi-task model parallelism",
      "detailed_description": "A framework enabling the training of large models with multi-task model parallelism, offering linear speedups for multi-GPU execution.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "model_parallelism"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/knagrecha/hydra",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "model-parallelism",
        "multi-task"
      ],
      "id": 241
    },
    {
      "name": "Unity_GPUNearestNeighbor",
      "one_line_profile": "GPU-accelerated Spatial Hashing Algorithm for Unity",
      "detailed_description": "An implementation of the Spatial Hashing algorithm using GPU acceleration in Unity, useful for particle simulations and neighbor search in scientific visualization or simulation.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "simulation",
        "spatial_analysis"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/kodai100/Unity_GPUNearestNeighbor",
      "help_website": [],
      "license": null,
      "tags": [
        "unity",
        "gpu-acceleration",
        "spatial-hashing",
        "simulation"
      ],
      "id": 242
    },
    {
      "name": "raylight",
      "one_line_profile": "Multi-GPU distributed inference/training for ComfyUI using Ray",
      "detailed_description": "Enables distributed multi-GPU capabilities in ComfyUI workflows using XDiT, XFuser, and FSDP managed by Ray, facilitating large-scale image generation or processing.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_inference",
        "image_generation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/komikndr/raylight",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "comfyui",
        "ray",
        "distributed-computing",
        "fsdp"
      ],
      "id": 243
    },
    {
      "name": "perceiver-io",
      "one_line_profile": "PyTorch implementation of Perceiver architectures",
      "detailed_description": "A PyTorch implementation of Perceiver, Perceiver IO, and Perceiver AR architectures, including PyTorch Lightning scripts for distributed training.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_implementation",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/krasserm/perceiver-io",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "perceiver",
        "pytorch",
        "pytorch-lightning"
      ],
      "id": 244
    },
    {
      "name": "mpi-operator",
      "one_line_profile": "Kubernetes Operator for MPI-based applications",
      "detailed_description": "A Kubernetes Operator to manage MPI-based applications, essential for distributed training and HPC workloads on Kubernetes clusters.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "hpc_infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubeflow/mpi-operator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "mpi",
        "distributed-training",
        "hpc"
      ],
      "id": 245
    },
    {
      "name": "kubeflow-trainer",
      "one_line_profile": "Distributed AI Model Training on Kubernetes",
      "detailed_description": "A component of Kubeflow for managing distributed AI model training and fine-tuning jobs on Kubernetes infrastructure.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "mlops"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubeflow/trainer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubeflow",
        "kubernetes",
        "distributed-training"
      ],
      "id": 246
    },
    {
      "name": "jobset",
      "one_line_profile": "Kubernetes native API for distributed ML training and HPC",
      "detailed_description": "A Kubernetes native API designed to manage distributed machine learning training and HPC workloads as a set of related jobs.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "hpc_infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/kubernetes-sigs/jobset",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "hpc",
        "distributed-ml"
      ],
      "id": 247
    },
    {
      "name": "keras_multi_gpu",
      "one_line_profile": "Multi-GPU training utility for Keras",
      "detailed_description": "A utility library to enable multi-GPU training for Keras models, facilitating parallel processing.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kuixu/keras_multi_gpu",
      "help_website": [],
      "license": null,
      "tags": [
        "keras",
        "multi-gpu",
        "parallel-training"
      ],
      "id": 248
    },
    {
      "name": "CasMVSNet_pl",
      "one_line_profile": "Cascade Cost Volume for Multi-View Stereo using PyTorch Lightning",
      "detailed_description": "Implementation of Cascade Cost Volume for High-Resolution Multi-View Stereo (MVS) and Stereo Matching, utilizing PyTorch Lightning for training.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "3d_reconstruction",
        "stereo_matching"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/kwea123/CasMVSNet_pl",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "mvs",
        "3d-reconstruction",
        "pytorch-lightning"
      ],
      "id": 249
    },
    {
      "name": "nerf_pl",
      "one_line_profile": "NeRF implementation using PyTorch Lightning",
      "detailed_description": "A PyTorch Lightning implementation of Neural Radiance Fields (NeRF) and NeRF in the Wild, facilitating 3D scene synthesis and training.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "neural_rendering",
        "3d_synthesis"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/kwea123/nerf_pl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nerf",
        "neural-rendering",
        "pytorch-lightning"
      ],
      "id": 250
    },
    {
      "name": "ngp_pl",
      "one_line_profile": "Instant-NGP implementation in PyTorch",
      "detailed_description": "A high-performance implementation of Instant Neural Graphics Primitives (Instant-NGP) using PyTorch and CUDA, trained with PyTorch Lightning.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "neural_rendering",
        "acceleration"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/kwea123/ngp_pl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "instant-ngp",
        "nerf",
        "cuda"
      ],
      "id": 251
    },
    {
      "name": "nsff_pl",
      "one_line_profile": "Neural Scene Flow Fields using PyTorch Lightning",
      "detailed_description": "Implementation of Neural Scene Flow Fields for dynamic 3D scene reconstruction and flow estimation.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "3d_reconstruction",
        "scene_flow"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/kwea123/nsff_pl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scene-flow",
        "nerf",
        "dynamic-scene"
      ],
      "id": 252
    },
    {
      "name": "FlashAttention20",
      "one_line_profile": "FlashAttention 2.0 implementation in PyTorch",
      "detailed_description": "A PyTorch implementation of the FlashAttention 2.0 algorithm, providing accelerated attention mechanisms without complex custom CUDA kernels.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kyegomez/FlashAttention20",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "flash-attention",
        "pytorch",
        "optimization"
      ],
      "id": 253
    },
    {
      "name": "FlashAttention20Triton",
      "one_line_profile": "Triton implementation of Flash Attention 2.0",
      "detailed_description": "An implementation of Flash Attention 2.0 using OpenAI Triton, enabling high-performance attention computation on GPUs.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "kernel_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kyegomez/FlashAttention20Triton",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "triton",
        "flash-attention",
        "gpu-acceleration"
      ],
      "id": 254
    },
    {
      "name": "kymatio",
      "one_line_profile": "Wavelet scattering transforms with GPU acceleration",
      "detailed_description": "A library for computing wavelet scattering transforms in Python, featuring GPU acceleration and compatibility with major deep learning frameworks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "signal_processing",
        "feature_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kymatio/kymatio",
      "help_website": [
        "https://www.kymat.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "wavelet-scattering",
        "signal-processing",
        "gpu"
      ],
      "id": 255
    },
    {
      "name": "alpaca-rlhf",
      "one_line_profile": "RLHF Fine-tuning for LLaMA based on DeepSpeed Chat",
      "detailed_description": "A tool for fine-tuning LLaMA models using Reinforcement Learning with Human Feedback (RLHF), built upon the DeepSpeed Chat framework.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_finetuning",
        "rlhf"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/l294265421/alpaca-rlhf",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "rlhf",
        "deepspeed",
        "finetuning"
      ],
      "id": 256
    },
    {
      "name": "Chatglm_lora_multi-gpu",
      "one_line_profile": "Multi-GPU LoRA fine-tuning for ChatGLM",
      "detailed_description": "A tool for performing multi-GPU fine-tuning of ChatGLM models using LoRA and DeepSpeed, enabling efficient training of large language models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_finetuning",
        "distributed_training"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/liangwq/Chatglm_lora_multi-gpu",
      "help_website": [],
      "license": null,
      "tags": [
        "chatglm",
        "lora",
        "deepspeed",
        "multi-gpu"
      ],
      "id": 257
    },
    {
      "name": "Lightning-UQ-Box",
      "one_line_profile": "Uncertainty Quantification for Neural Networks with PyTorch Lightning",
      "detailed_description": "A comprehensive library for Uncertainty Quantification (UQ) in neural networks, leveraging PyTorch and PyTorch Lightning to provide various UQ methods.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "uncertainty_quantification",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lightning-uq-box/lightning-uq-box",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "uncertainty-quantification",
        "pytorch-lightning",
        "uq"
      ],
      "id": 258
    },
    {
      "name": "isolation-forest",
      "one_line_profile": "Distributed Isolation Forest implementation for Spark/Scala",
      "detailed_description": "A distributed implementation of the Isolation Forest algorithm for unsupervised outlier detection on Spark, supporting scalable training and ONNX export.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "anomaly_detection",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/linkedin/isolation-forest",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "spark",
        "isolation-forest",
        "anomaly-detection",
        "distributed-computing"
      ],
      "id": 259
    },
    {
      "name": "Crossbow",
      "one_line_profile": "Multi-GPU Deep Learning System for Training with Small Batch Sizes",
      "detailed_description": "Crossbow is a deep learning system designed for multi-GPU training, specifically optimized for small batch sizes to improve hardware efficiency and training speed.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "model_training"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/lsds/Crossbow",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deep-learning",
        "distributed-systems",
        "gpu-acceleration"
      ],
      "id": 260
    },
    {
      "name": "mu_transformer",
      "one_line_profile": "Transformer with Mu-Parameterization implemented in Jax/Flax",
      "detailed_description": "A library implementing Transformers with Mu-Parameterization (Maximal Update Parameterization) in Jax/Flax, supporting Fully Sharded Data Parallel (FSDP) on TPU pods.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "modeling",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucaslingle/mu_transformer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jax",
        "flax",
        "transformer",
        "fsdp",
        "tpu"
      ],
      "id": 261
    },
    {
      "name": "flash-attention-jax",
      "one_line_profile": "JAX implementation of Flash Attention",
      "detailed_description": "A JAX implementation of the Flash Attention algorithm, providing memory-efficient and fast attention mechanisms for deep learning models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucidrains/flash-attention-jax",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "jax",
        "flash-attention",
        "optimization"
      ],
      "id": 262
    },
    {
      "name": "flash-cosine-sim-attention",
      "one_line_profile": "Fused cosine similarity attention implementation",
      "detailed_description": "An implementation of fused cosine similarity attention, designed in the style of Flash Attention to optimize attention mechanisms in neural networks.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/lucidrains/flash-cosine-sim-attention",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "attention-mechanism",
        "cuda",
        "optimization"
      ],
      "id": 263
    },
    {
      "name": "flash-genomics-model",
      "one_line_profile": "Long context genomics model using Flash Attention",
      "detailed_description": "A deep learning model designed for genomics, leveraging long context attention modeling techniques like Flash Attention to process genomic sequences.",
      "domains": [
        "AI3",
        "Bioinformatics"
      ],
      "subtask_category": [
        "modeling",
        "genomics_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucidrains/flash-genomics-model",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "genomics",
        "deep-learning",
        "long-context"
      ],
      "id": 264
    },
    {
      "name": "JaxLightning",
      "one_line_profile": "Integration of JAX with PyTorch Lightning",
      "detailed_description": "A library that enables running JAX models and operations within the PyTorch Lightning training framework, facilitating mixed-framework workflows.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "interoperability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ludwigwinkler/JaxLightning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "jax",
        "pytorch-lightning",
        "training-framework"
      ],
      "id": 265
    },
    {
      "name": "cute-flash-attention",
      "one_line_profile": "Flash Attention implementation using CuTe",
      "detailed_description": "An implementation of the Flash Attention algorithm utilizing the CuTe layout and algebra library for CUDA C++, aimed at high-performance GPU computing.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/luliyucoordinate/cute-flash-attention",
      "help_website": [],
      "license": null,
      "tags": [
        "cuda",
        "flash-attention",
        "cute"
      ],
      "id": 266
    },
    {
      "name": "magix",
      "one_line_profile": "Model parallelism for Hugging Face Transformers",
      "detailed_description": "A tool to enable model parallelism for Hugging Face Transformers, allowing the training and inference of large models across multiple devices.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "model_parallelism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/luyug/magix",
      "help_website": [],
      "license": null,
      "tags": [
        "huggingface",
        "transformers",
        "parallel-computing"
      ],
      "id": 267
    },
    {
      "name": "llama-tune",
      "one_line_profile": "LLaMa tuning workflow with DeepSpeed",
      "detailed_description": "A workflow tool for fine-tuning LLaMa models using the Stanford Alpaca dataset, leveraging DeepSpeed and Hugging Face Transformers for efficiency.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_training"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/lxe/llama-tune",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "fine-tuning",
        "deepspeed"
      ],
      "id": 268
    },
    {
      "name": "Elephas",
      "one_line_profile": "Distributed Deep Learning with Keras & Spark",
      "detailed_description": "Elephas is an extension of Keras, which allows you to run distributed deep learning models at scale with Apache Spark.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/maxpumperla/elephas",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "keras",
        "spark",
        "distributed-deep-learning"
      ],
      "id": 269
    },
    {
      "name": "torcheval",
      "one_line_profile": "PyTorch model metrics and evaluation toolkit",
      "detailed_description": "A library providing a rich collection of performant PyTorch model metrics and tools to facilitate metric computation in distributed training and model evaluation.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics_computation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/meta-pytorch/torcheval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "pytorch",
        "metrics",
        "evaluation"
      ],
      "id": 270
    },
    {
      "name": "torchft",
      "one_line_profile": "Fault tolerance library for PyTorch",
      "detailed_description": "A library providing fault tolerance mechanisms for PyTorch distributed training, including implementations for HSDP, LocalSGD, and DiLoCo.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "fault_tolerance"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/meta-pytorch/torchft",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "pytorch",
        "fault-tolerance",
        "distributed-training"
      ],
      "id": 271
    },
    {
      "name": "CNTK",
      "one_line_profile": "Microsoft Cognitive Toolkit for deep learning",
      "detailed_description": "An open-source deep-learning toolkit by Microsoft that describes neural networks as a series of computational steps via a directed graph.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "deep_learning"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/microsoft/CNTK",
      "help_website": [
        "https://docs.microsoft.com/en-us/cognitive-toolkit/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "deep-learning",
        "neural-networks",
        "toolkit"
      ],
      "id": 272
    },
    {
      "name": "DirectML",
      "one_line_profile": "Hardware-accelerated DirectX 12 library for machine learning",
      "detailed_description": "A high-performance, hardware-accelerated DirectX 12 library for machine learning, providing GPU acceleration across a broad range of hardware.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/microsoft/DirectML",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "directx",
        "machine-learning",
        "gpu-acceleration"
      ],
      "id": 273
    },
    {
      "name": "ONNX Runtime",
      "one_line_profile": "Cross-platform ML inferencing and training accelerator",
      "detailed_description": "A cross-platform, high-performance engine for machine learning inference and training, supporting models from PyTorch, TensorFlow, and other frameworks via ONNX.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "inference",
        "model_training",
        "acceleration"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/microsoft/onnxruntime",
      "help_website": [
        "https://onnxruntime.ai"
      ],
      "license": "MIT",
      "tags": [
        "onnx",
        "inference",
        "acceleration"
      ],
      "id": 274
    },
    {
      "name": "WebDNN",
      "one_line_profile": "Fast DNN execution framework for web browsers",
      "detailed_description": "A framework for running deep neural networks (DNN) on web browsers with high performance, utilizing WebGPU and WebAssembly.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "inference",
        "web_deployment"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/mil-tokyo/webdnn",
      "help_website": [
        "https://mil-tokyo.github.io/webdnn/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "web-browser",
        "deep-learning",
        "inference"
      ],
      "id": 275
    },
    {
      "name": "DistriFusion",
      "one_line_profile": "Distributed Parallel Inference for High-Resolution Diffusion Models",
      "detailed_description": "A framework for distributed parallel inference of high-resolution diffusion models, enabling efficient generation across multiple devices.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "inference",
        "distributed_computing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/mit-han-lab/distrifuser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "diffusion-models",
        "distributed-inference",
        "parallel-computing"
      ],
      "id": 276
    },
    {
      "name": "TorchSparse",
      "one_line_profile": "Efficient Training and Inference for Sparse Convolution",
      "detailed_description": "A high-performance framework for training and inference of sparse convolutional neural networks on GPUs.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "inference",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/mit-han-lab/torchsparse",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sparse-convolution",
        "gpu",
        "optimization"
      ],
      "id": 277
    },
    {
      "name": "LiteAttention",
      "one_line_profile": "Optimized attention mechanism implementation over FlashAttention-3",
      "detailed_description": "A lightweight and efficient implementation of attention mechanisms built on top of FlashAttention-3, designed to accelerate Transformer model training and inference.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_acceleration",
        "attention_mechanism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/moonmath-ai/LiteAttention",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "flash-attention",
        "transformer",
        "optimization"
      ],
      "id": 278
    },
    {
      "name": "mptorch",
      "one_line_profile": "Mixed-precision arithmetic simulation wrapper for PyTorch",
      "detailed_description": "A wrapper framework built atop PyTorch to simulate the use of custom and mixed precision arithmetic in Deep Neural Network (DNN) training and inference workloads, aiding in hardware-aware algorithm development.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "training_simulation",
        "mixed_precision"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/mptorch/mptorch",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pytorch",
        "mixed-precision",
        "simulation"
      ],
      "id": 279
    },
    {
      "name": "QuIP",
      "one_line_profile": "Interactive environment for scientific computing and psychophysics",
      "detailed_description": "An interactive environment for computing, presenting images/sequences, and general scientific computing with built-in support for psychophysical experimentation and GPU acceleration.",
      "domains": [
        "Scientific Computing",
        "Psychophysics"
      ],
      "subtask_category": [
        "scientific_visualization",
        "experiment_control"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/nasa/QuIP",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "scientific-computing",
        "psychophysics",
        "visualization"
      ],
      "id": 280
    },
    {
      "name": "distributed_rl",
      "one_line_profile": "Distributed deep reinforcement learning library for PyTorch",
      "detailed_description": "A PyTorch-based implementation of distributed deep reinforcement learning algorithms, enabling scalable training of RL agents.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/neka-nat/distributed_rl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "reinforcement-learning",
        "distributed",
        "pytorch"
      ],
      "id": 281
    },
    {
      "name": "gsplat",
      "one_line_profile": "CUDA accelerated rasterization for Gaussian Splatting",
      "detailed_description": "A library providing CUDA-accelerated rasterization for Gaussian Splatting, a technique used in 3D reconstruction and novel view synthesis research.",
      "domains": [
        "Computer Vision",
        "AI3-01"
      ],
      "subtask_category": [
        "rendering",
        "3d_reconstruction"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/nerfstudio-project/gsplat",
      "help_website": [
        "https://docs.nerf.studio/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "gaussian-splatting",
        "cuda",
        "nerf"
      ],
      "id": 282
    },
    {
      "name": "Newton",
      "one_line_profile": "GPU-accelerated physics simulation engine for robotics",
      "detailed_description": "An open-source, GPU-accelerated physics simulation engine built upon NVIDIA Warp, specifically targeting roboticists and simulation researchers for generating physical data.",
      "domains": [
        "Robotics",
        "Physics Simulation"
      ],
      "subtask_category": [
        "physics_simulation",
        "data_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/newton-physics/newton",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "physics-engine",
        "robotics",
        "simulation"
      ],
      "id": 283
    },
    {
      "name": "NexRL",
      "one_line_profile": "Framework for LLM post-training and RLHF",
      "detailed_description": "An ultra-loosely-coupled framework designed for Large Language Model (LLM) post-training, including Reinforcement Learning from Human Feedback (RLHF).",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "llm_training",
        "rlhf"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/nex-agi/NexRL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "rlhf",
        "post-training"
      ],
      "id": 284
    },
    {
      "name": "disent",
      "one_line_profile": "Modular VAE disentanglement framework",
      "detailed_description": "A modular framework for Variational Autoencoder (VAE) disentanglement research, built with PyTorch Lightning, including metrics, datasets, and various supervision methods.",
      "domains": [
        "AI3",
        "Machine Learning"
      ],
      "subtask_category": [
        "representation_learning",
        "model_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/nmichlo/disent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vae",
        "disentanglement",
        "pytorch-lightning"
      ],
      "id": 285
    },
    {
      "name": "flash_attn_jax",
      "one_line_profile": "JAX bindings for Flash Attention v2",
      "detailed_description": "Provides JAX bindings for Flash Attention v2, enabling high-performance attention mechanism computation in JAX-based scientific machine learning workflows.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_acceleration",
        "attention_mechanism"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/nshepperd/flash_attn_jax",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "jax",
        "flash-attention",
        "acceleration"
      ],
      "id": 286
    },
    {
      "name": "DI-star",
      "one_line_profile": "Distributed training platform for StarCraft II AI",
      "detailed_description": "An artificial intelligence platform for StarCraft II enabling large-scale distributed training of grand-master agents, used in reinforcement learning research.",
      "domains": [
        "AI3",
        "Game AI"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/opendilab/DI-star",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "starcraft-ii",
        "reinforcement-learning",
        "distributed"
      ],
      "id": 287
    },
    {
      "name": "ReaLHF",
      "one_line_profile": "Efficient RLHF training framework for LLMs",
      "detailed_description": "A framework for super-efficient Reinforcement Learning from Human Feedback (RLHF) training of Large Language Models (LLMs) featuring parameter reallocation techniques.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "rlhf",
        "llm_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/openpsi-project/ReaLHF",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "llm",
        "optimization"
      ],
      "id": 288
    },
    {
      "name": "openspeech",
      "one_line_profile": "Open-source toolkit for end-to-end speech recognition",
      "detailed_description": "A comprehensive toolkit for End-to-End Speech Recognition leveraging PyTorch-Lightning and Hydra, supporting research and development of ASR models.",
      "domains": [
        "AI3",
        "Speech Processing"
      ],
      "subtask_category": [
        "speech_recognition",
        "model_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/openspeech-team/openspeech",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "asr",
        "speech-recognition",
        "pytorch-lightning"
      ],
      "id": 289
    },
    {
      "name": "EE-LLM",
      "one_line_profile": "Framework for early-exit LLM training and inference",
      "detailed_description": "A framework designed for large-scale training and inference of early-exit (EE) Large Language Models (LLMs), optimizing efficiency.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "llm_training",
        "inference_optimization"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/pan-x-c/EE-LLM",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "early-exit",
        "training-framework"
      ],
      "id": 290
    },
    {
      "name": "AutoDist",
      "one_line_profile": "Distributed Deep Learning framework for TensorFlow",
      "detailed_description": "A framework for simple distributed deep learning on TensorFlow, automating the distribution strategy for model training.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "model_parallelism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/petuum/autodist",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tensorflow",
        "distributed-learning",
        "automation"
      ],
      "id": 291
    },
    {
      "name": "metal-flash-attention",
      "one_line_profile": "FlashAttention implementation for Apple Metal",
      "detailed_description": "A port of FlashAttention to Apple's Metal API, enabling accelerated attention mechanism computation on Apple Silicon GPUs for AI research.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_acceleration",
        "attention_mechanism"
      ],
      "application_level": "library",
      "primary_language": "Swift",
      "repo_url": "https://github.com/philipturner/metal-flash-attention",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "metal",
        "flash-attention",
        "apple-silicon"
      ],
      "id": 292
    },
    {
      "name": "energizer",
      "one_line_profile": "Active learning library for PyTorch",
      "detailed_description": "An active learning library for PyTorch based on Lightning-Fabric, facilitating the development of active learning loops for scientific data analysis.",
      "domains": [
        "AI3",
        "Machine Learning"
      ],
      "subtask_category": [
        "active_learning",
        "data_selection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pietrolesci/energizer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "active-learning",
        "pytorch",
        "lightning-fabric"
      ],
      "id": 293
    },
    {
      "name": "VINS-Fusion-gpu",
      "one_line_profile": "GPU-accelerated VINS-Fusion for SLAM",
      "detailed_description": "A GPU-accelerated version of VINS-Fusion, a Visual-Inertial State Estimator, enabling real-time SLAM on embedded devices like Nvidia TX2.",
      "domains": [
        "Robotics",
        "Computer Vision"
      ],
      "subtask_category": [
        "slam",
        "state_estimation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/pjrambo/VINS-Fusion-gpu",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "slam",
        "vins-fusion",
        "gpu-acceleration"
      ],
      "id": 294
    },
    {
      "name": "libdnn",
      "one_line_profile": "Lightweight C++ library for deep neural networks with GPU acceleration",
      "detailed_description": "A lightweight and user-friendly C++ library designed for implementing deep and convolutional neural networks with GPU acceleration support. It provides low-level primitives for building and training neural networks efficiently.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/poweic/libdnn",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deep-learning",
        "gpu-acceleration",
        "cpp",
        "neural-networks"
      ],
      "id": 295
    },
    {
      "name": "DinkyTrain",
      "one_line_profile": "Pre-training library based on fairseq with DeepSpeed integration",
      "detailed_description": "A pre-training library developed by Princeton NLP, built upon fairseq and integrated with DeepSpeed kernels. It is designed to facilitate efficient training of large language models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "pretraining"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/princeton-nlp/DinkyTrain",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "pre-training",
        "deepspeed",
        "fairseq"
      ],
      "id": 296
    },
    {
      "name": "PiPPy",
      "one_line_profile": "Pipeline Parallelism library for PyTorch",
      "detailed_description": "A library that provides pipeline parallelism capabilities for PyTorch, enabling the training of large models that do not fit into a single GPU memory by splitting them across multiple devices.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "pipeline_parallelism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pytorch/PiPPy",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "pytorch",
        "pipeline-parallelism",
        "distributed-training"
      ],
      "id": 297
    },
    {
      "name": "PyTorch",
      "one_line_profile": "Open source machine learning framework",
      "detailed_description": "A comprehensive open-source machine learning framework that accelerates the path from research prototyping to production deployment. It provides tensor computation with strong GPU acceleration and deep neural networks built on a tape-based autograd system.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "deep_learning_framework"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/pytorch/pytorch",
      "help_website": [
        "https://pytorch.org"
      ],
      "license": "NOASSERTION",
      "tags": [
        "deep-learning",
        "tensor",
        "autograd",
        "gpu-acceleration"
      ],
      "id": 298
    },
    {
      "name": "Ray",
      "one_line_profile": "Unified framework for scaling AI and Python applications",
      "detailed_description": "An open-source unified compute framework that makes it easy to scale AI and Python workloads. It provides a core distributed runtime and a set of AI libraries for accelerating ML workloads, including training, tuning, and serving.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_computing",
        "scaling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ray-project/ray",
      "help_website": [
        "https://docs.ray.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-systems",
        "scaling",
        "machine-learning",
        "parallel-computing"
      ],
      "id": 299
    },
    {
      "name": "Ray Lightning",
      "one_line_profile": "PyTorch Lightning Distributed Accelerators using Ray",
      "detailed_description": "A library that integrates PyTorch Lightning with Ray, allowing users to leverage Ray's distributed computing capabilities for training PyTorch Lightning models across clusters.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ray-project/ray_lightning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pytorch-lightning",
        "ray",
        "distributed-training"
      ],
      "id": 300
    },
    {
      "name": "RobotPerf Benchmarks",
      "one_line_profile": "Benchmarking suite for robotics computing performance",
      "detailed_description": "A vendor-neutral benchmarking suite designed to evaluate robotics computing performance using grey-box and black-box approaches. It helps in assessing the efficiency of hardware and software stacks for robotics and AI workloads.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/robotperf/benchmarks",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "robotics",
        "benchmarking",
        "performance",
        "ros2"
      ],
      "id": 301
    },
    {
      "name": "KubeTorch",
      "one_line_profile": "Distributed AI workloads on Kubernetes for Python",
      "detailed_description": "A tool that allows users to distribute and run AI workloads on Kubernetes clusters seamlessly using Python, acting as an infrastructure layer for ML workflows similar to PyTorch's abstraction for tensors.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "infrastructure_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/run-house/kubetorch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "distributed-training",
        "mlops",
        "infrastructure"
      ],
      "id": 302
    },
    {
      "name": "l2hmc-qcd",
      "one_line_profile": "L2HMC algorithm for Lattice QCD simulations",
      "detailed_description": "An implementation of the L2HMC (Learn to Hamiltonian Monte Carlo) algorithm applied to simulations in Lattice Quantum Chromodynamics (QCD). It serves as a scientific simulation tool for physics research.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "simulation",
        "scientific_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/saforem2/l2hmc-qcd",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lattice-qcd",
        "physics",
        "mcmc",
        "generative-models"
      ],
      "id": 303
    },
    {
      "name": "PMLS-Caffe",
      "one_line_profile": "Distributed Deep Learning Framework based on Caffe",
      "detailed_description": "A distributed deep learning framework designed for Parallel Machine Learning Systems (PMLS). It extends Caffe to support distributed training, enabling efficient scaling of deep learning models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/sailing-pmls/pmls-caffe",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "caffe",
        "distributed-learning",
        "deep-learning",
        "framework"
      ],
      "id": 304
    },
    {
      "name": "GRACE",
      "one_line_profile": "Gradient Compression for distributed deep learning",
      "detailed_description": "A library for gradient compression in distributed deep learning. It aims to reduce communication overhead during distributed training by compressing gradients, thereby accelerating the training process.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "gradient_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sands-lab/grace",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "distributed-learning",
        "compression",
        "optimization",
        "gradient-compression"
      ],
      "id": 305
    },
    {
      "name": "FullLLM",
      "one_line_profile": "Full-stack library for LLM pre-training, fine-tuning, RLHF, and inference",
      "detailed_description": "A comprehensive toolkit for the Large Language Model lifecycle, supporting pre-training, supervised fine-tuning (SFT), reinforcement learning from human feedback (RLHF/PPO), inference, and quantization.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "finetuning",
        "rlhf"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/schinger/FullLLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "rlhf",
        "finetuning",
        "quantization"
      ],
      "id": 306
    },
    {
      "name": "SpecForge",
      "one_line_profile": "Framework for training speculative decoding models",
      "detailed_description": "A tool designed to effortlessly train speculative decoding models and port them to SGLang serving, optimizing inference speed for large language models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "acceleration",
        "inference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sgl-project/SpecForge",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "speculative-decoding",
        "llm",
        "inference-acceleration"
      ],
      "id": 307
    },
    {
      "name": "FlashAttention-PyTorch",
      "one_line_profile": "PyTorch implementation of FlashAttention for efficient transformer training",
      "detailed_description": "A PyTorch implementation of the FlashAttention algorithm, designed to accelerate attention computation and reduce memory usage in transformer models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shreyansh26/FlashAttention-PyTorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "flash-attention",
        "pytorch",
        "acceleration"
      ],
      "id": 308
    },
    {
      "name": "ShallowSpeed",
      "one_line_profile": "Lightweight distributed training library for deep learning",
      "detailed_description": "A small-scale distributed training library built on Numpy and MPI, designed for educational purposes and training sequential deep learning models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/siboehm/ShallowSpeed",
      "help_website": [],
      "license": null,
      "tags": [
        "distributed-training",
        "mpi",
        "numpy"
      ],
      "id": 309
    },
    {
      "name": "gpumonitor",
      "one_line_profile": "GPU monitoring callbacks for TensorFlow and PyTorch Lightning",
      "detailed_description": "A utility library providing callbacks to monitor GPU usage during model training with TensorFlow 2.x and PyTorch Lightning.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "monitoring",
        "resource_management"
      ],
      "application_level": "utility",
      "primary_language": "Python",
      "repo_url": "https://github.com/sicara/gpumonitor",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu-monitoring",
        "tensorflow",
        "pytorch-lightning"
      ],
      "id": 310
    },
    {
      "name": "ArcticTraining",
      "one_line_profile": "Framework for post-training large language models",
      "detailed_description": "A framework designed by Snowflake to simplify and accelerate the post-training process (fine-tuning, alignment) for large language models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "finetuning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/snowflakedb/ArcticTraining",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "post-training",
        "finetuning"
      ],
      "id": 311
    },
    {
      "name": "parallax",
      "one_line_profile": "Automatic parallelization tool for deep learning training",
      "detailed_description": "A tool that automates the parallelization of deep learning training across distributed multi-GPU environments.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "parallelization"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/snuspl/parallax",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "multi-gpu",
        "parallelization"
      ],
      "id": 312
    },
    {
      "name": "Flash-Attention-Softmax-N",
      "one_line_profile": "Flash Attention implementation with SoftmaxN",
      "detailed_description": "CUDA and Triton implementations of Flash Attention incorporating SoftmaxN, aimed at optimizing attention mechanisms in transformer models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/softmax1/Flash-Attention-Softmax-N",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "flash-attention",
        "cuda",
        "triton"
      ],
      "id": 313
    },
    {
      "name": "coom",
      "one_line_profile": "Large-scale language model training framework",
      "detailed_description": "A training framework based on Megatron-Core, designed to efficiently handle extensive model training, inspired by Deepseek's HAI-LLM optimizations.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "distributed_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/soketlabs/coom",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "megatron-core",
        "distributed-training"
      ],
      "id": 314
    },
    {
      "name": "llms_tool",
      "one_line_profile": "Tool for LLM training, testing, and quantization",
      "detailed_description": "A tool based on HuggingFace for training, testing, and deploying large language models, supporting pre-training, SFT, RLHF, DPO, and quantization.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "finetuning",
        "quantization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanleylsx/llms_tool",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "sft",
        "rlhf",
        "quantization"
      ],
      "id": 315
    },
    {
      "name": "flash-attention-windows",
      "one_line_profile": "Pre-built Flash Attention wheels for Windows",
      "detailed_description": "Provides pre-built binary wheels for Flash Attention 2 on Windows, enabling researchers to use accelerated attention mechanisms on Windows platforms without complex build setups.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "environment_setup"
      ],
      "application_level": "utility",
      "primary_language": null,
      "repo_url": "https://github.com/sunsetcoder/flash-attention-windows",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "flash-attention",
        "windows",
        "wheels"
      ],
      "id": 316
    },
    {
      "name": "RLHF",
      "one_line_profile": "Implementation of RLHF pipeline for Chinese ChatGPT",
      "detailed_description": "An implementation of the Reinforcement Learning from Human Feedback (RLHF) pipeline, specifically tailored for training Chinese language models similar to ChatGPT.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "rlhf"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/sunzeyeah/RLHF",
      "help_website": [],
      "license": null,
      "tags": [
        "rlhf",
        "llm",
        "chatgpt"
      ],
      "id": 317
    },
    {
      "name": "mixed-precision-pytorch",
      "one_line_profile": "Library for mixed precision training in PyTorch",
      "detailed_description": "A library/implementation for training deep learning models using FP16 weights (mixed precision) in PyTorch to accelerate training and reduce memory usage.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/suvojit-0x55aa/mixed-precision-pytorch",
      "help_website": [],
      "license": "WTFPL",
      "tags": [
        "mixed-precision",
        "fp16",
        "pytorch"
      ],
      "id": 318
    },
    {
      "name": "Silice",
      "one_line_profile": "Hardware description language for FPGA design",
      "detailed_description": "A hardware description language that simplifies designing hardware algorithms with parallelism and pipelines, useful for creating custom hardware accelerators for scientific computing.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "hardware_design",
        "acceleration"
      ],
      "application_level": "language",
      "primary_language": "C++",
      "repo_url": "https://github.com/sylefeb/Silice",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "fpga",
        "hdl",
        "hardware-acceleration"
      ],
      "id": 319
    },
    {
      "name": "deep-gradient-compression",
      "one_line_profile": "Deep Gradient Compression for distributed training",
      "detailed_description": "Implementation of Deep Gradient Compression (DGC) to reduce communication bandwidth requirements during distributed training of deep learning models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/synxlin/deep-gradient-compression",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "gradient-compression",
        "bandwidth-optimization"
      ],
      "id": 320
    },
    {
      "name": "pytorch-distributed",
      "one_line_profile": "Benchmark and quickstart for PyTorch distributed training",
      "detailed_description": "A repository providing benchmarks and quickstart guides for setting up and evaluating distributed training environments with PyTorch.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "benchmarking"
      ],
      "application_level": "utility",
      "primary_language": "Python",
      "repo_url": "https://github.com/tczhangzhi/pytorch-distributed",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "distributed-training",
        "pytorch",
        "benchmark"
      ],
      "id": 321
    },
    {
      "name": "Qwen2-Audio-finetune",
      "one_line_profile": "Fine-tuning toolkit for Qwen2-Audio models",
      "detailed_description": "A repository specifically designed for fine-tuning the Qwen2-Audio model, supporting Distributed Data Parallel (DDP) and DeepSpeed for efficient training.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "finetuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/teamtee/Qwen2-Audio-finetune",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "qwen2-audio",
        "finetuning",
        "deepspeed"
      ],
      "id": 322
    },
    {
      "name": "cube-studio",
      "one_line_profile": "Cloud-native one-stop MLOps and AI platform",
      "detailed_description": "An open-source, cloud-native machine learning platform supporting the full MLOps lifecycle, including distributed training, hyperparameter search, inference serving, and LLM fine-tuning.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "platform",
        "model_training",
        "mlops"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/tencentmusic/cube-studio",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "mlops",
        "distributed-training",
        "llm-platform"
      ],
      "id": 323
    },
    {
      "name": "TensorDiffEq",
      "one_line_profile": "Physics-Informed Deep Learning framework on TensorFlow",
      "detailed_description": "A library for Efficient and Scalable Physics-Informed Deep Learning (PINNs) and Scientific Machine Learning built on top of TensorFlow, supporting multi-worker distributed computing.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "scientific_modeling",
        "pinn_solver",
        "differential_equations"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tensordiffeq/TensorDiffEq",
      "help_website": [],
      "license": null,
      "tags": [
        "physics-informed-neural-networks",
        "scientific-machine-learning",
        "tensorflow",
        "distributed-computing"
      ],
      "id": 324
    },
    {
      "name": "Mesh TensorFlow",
      "one_line_profile": "Distributed deep learning library for model parallelism",
      "detailed_description": "A language for distributed deep learning capable of specifying a class of distributed tensor computations, enabling model parallelism for training very large models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "model_parallelism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tensorflow/mesh",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "model-parallelism",
        "tensorflow"
      ],
      "id": 325
    },
    {
      "name": "Tensor2Tensor",
      "one_line_profile": "Library of deep learning models and datasets",
      "detailed_description": "A library of deep learning models and datasets designed to make deep learning more accessible and accelerate ML research, featuring implementations of Transformers and other architectures.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "deep_learning_models"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tensorflow/tensor2tensor",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deep-learning",
        "transformer",
        "datasets"
      ],
      "id": 326
    },
    {
      "name": "ScalarLM",
      "one_line_profile": "Unified training and inference stack for LLMs",
      "detailed_description": "A unified stack for training and inference of Large Language Models, designed to streamline the lifecycle of LLM development.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "llm_training",
        "inference"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/tensorwavecloud/ScalarLM",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "training-stack",
        "inference"
      ],
      "id": 327
    },
    {
      "name": "ReMoE",
      "one_line_profile": "Fully Differentiable Mixture-of-Experts implementation",
      "detailed_description": "Codebase for ReMoE (Fully Differentiable Mixture-of-Experts with ReLU Routing), built on Megatron-LM, providing a specialized architecture for efficient large model training.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "mixture_of_experts"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-ml/ReMoE",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "mixture-of-experts",
        "megatron-lm",
        "llm-training"
      ],
      "id": 328
    },
    {
      "name": "libflash_attn",
      "one_line_profile": "Standalone Flash Attention v2 kernel",
      "detailed_description": "A standalone Flash Attention v2 kernel implementation without libtorch dependency, providing optimized attention mechanisms for transformer models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "attention_kernel"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/tlc-pack/libflash_attn",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "flash-attention",
        "cuda",
        "optimization"
      ],
      "id": 329
    },
    {
      "name": "keypoint-detection",
      "one_line_profile": "2D keypoint detection solver",
      "detailed_description": "A tool for 2D keypoint detection utilizing PyTorch Lightning and Weights & Biases for experiment tracking.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "keypoint_detection",
        "computer_vision"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tlpss/keypoint-detection",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "keypoint-detection",
        "pytorch-lightning",
        "computer-vision"
      ],
      "id": 330
    },
    {
      "name": "TonY",
      "one_line_profile": "Deep learning framework on Apache Hadoop",
      "detailed_description": "TonY is a framework to natively run deep learning frameworks (like TensorFlow and PyTorch) on Apache Hadoop, enabling distributed training on big data clusters.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "resource_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/tony-framework/TonY",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hadoop",
        "distributed-deep-learning",
        "yarn"
      ],
      "id": 331
    },
    {
      "name": "go-metal",
      "one_line_profile": "Deep learning library for Go on Apple Silicon",
      "detailed_description": "A high-performance deep learning library for the Go programming language that leverages Apple's Metal API for GPU acceleration on Apple Silicon devices.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_training",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/tsawler/go-metal",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "deep-learning",
        "go",
        "metal",
        "gpu-acceleration"
      ],
      "id": 332
    },
    {
      "name": "cuSNN",
      "one_line_profile": "GPU-accelerated Spiking Neural Networks library",
      "detailed_description": "A library for simulating Spiking Neural Networks (SNNs) in C++ with strong GPU acceleration through CUDA, suitable for neuromorphic computing research.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "neuromorphic_computing",
        "snn_simulation"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/tudelft/cuSNN",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "spiking-neural-networks",
        "cuda",
        "neuromorphic"
      ],
      "id": 333
    },
    {
      "name": "Cekirdekler",
      "one_line_profile": "Multi-device OpenCL kernel load balancer",
      "detailed_description": "A multi-device OpenCL kernel load balancer and pipeliner API for C#, designed to distribute workloads across multiple GPUs using a shared-distributed memory model.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "gpu_acceleration",
        "load_balancing"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/tugrul512bit/Cekirdekler",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "opencl",
        "load-balancing",
        "gpu-computing"
      ],
      "id": 334
    },
    {
      "name": "Petastorm",
      "one_line_profile": "Data loading library for deep learning from Parquet",
      "detailed_description": "A library enabling single machine or distributed training and evaluation of deep learning models directly from datasets in Apache Parquet format, supporting TensorFlow, PyTorch, and PySpark.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "data_loading",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/uber/petastorm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "parquet",
        "data-loading",
        "distributed-training"
      ],
      "id": 335
    },
    {
      "name": "Detoxify",
      "one_line_profile": "Toxic comment detection models and library",
      "detailed_description": "A library providing trained models and code to predict toxic comments, useful for dataset filtering and quality control in NLP research.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "text_classification",
        "data_filtering"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/unitaryai/detoxify",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "toxicity-detection",
        "data-cleaning"
      ],
      "id": 336
    },
    {
      "name": "PipeEdge",
      "one_line_profile": "Pipeline parallelism for edge inference",
      "detailed_description": "A framework for pipeline parallelism designed to enable large-scale model inference on heterogeneous edge devices.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_inference",
        "pipeline_parallelism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/usc-isi/PipeEdge",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "edge-computing",
        "pipeline-parallelism",
        "inference"
      ],
      "id": 337
    },
    {
      "name": "OnnxStream",
      "one_line_profile": "Lightweight ONNX inference library",
      "detailed_description": "A lightweight inference library for ONNX files written in C++, capable of running large models like Stable Diffusion and Mistral on low-resource devices.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_inference",
        "edge_computing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/vitoplantamura/OnnxStream",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "onnx",
        "inference",
        "edge-ai"
      ],
      "id": 338
    },
    {
      "name": "veScale",
      "one_line_profile": "PyTorch Distributed framework for hyperscale training",
      "detailed_description": "A distributed training framework based on PyTorch, optimized for hyperscale training of Large Language Models (LLMs) and Reinforcement Learning (RL).",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "llm_training"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/volcengine/veScale",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "pytorch",
        "llm"
      ],
      "id": 339
    },
    {
      "name": "PytorchAutoDrive",
      "one_line_profile": "Segmentation and lane detection models library",
      "detailed_description": "A library providing implementations of various segmentation and lane detection models based on PyTorch, including tools for training, visualization, and benchmarking.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "image_segmentation",
        "object_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/voldemortX/pytorch-auto-drive",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "autonomous-driving",
        "segmentation",
        "lane-detection"
      ],
      "id": 340
    },
    {
      "name": "solo-learn",
      "one_line_profile": "Self-supervised visual representation learning library",
      "detailed_description": "A library of self-supervised methods for visual representation learning, powered by PyTorch Lightning, facilitating research in unsupervised learning.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "self_supervised_learning",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vturrisi/solo-learn",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "self-supervised-learning",
        "computer-vision",
        "pytorch-lightning"
      ],
      "id": 341
    },
    {
      "name": "modelparallel_pytorch",
      "one_line_profile": "Model parallelism library for PyTorch",
      "detailed_description": "A library enabling model parallelism for training multiple networks across multiple GPUs using PyTorch.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_parallelism",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/waitwaitforget/modelparallel_pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "model-parallelism",
        "multi-gpu"
      ],
      "id": 342
    },
    {
      "name": "llm.scala",
      "one_line_profile": "LLM training framework in Scala",
      "detailed_description": "An extensible implementation of a Language Model (LLM) training framework written in Scala.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "llm_training"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/wassemgtk/llm.scala",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scala",
        "llm",
        "training-framework"
      ],
      "id": 343
    },
    {
      "name": "cutlass_flash_atten_fp8",
      "one_line_profile": "FP8 Flash Attention kernel implementation",
      "detailed_description": "An implementation of Flash Attention using FP8 precision on Ada architecture GPUs via Cutlass, serving as an acceleration kernel.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "acceleration",
        "attention_kernel"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/weishengying/cutlass_flash_atten_fp8",
      "help_website": [],
      "license": null,
      "tags": [
        "fp8",
        "flash-attention",
        "cutlass",
        "cuda"
      ],
      "id": 344
    },
    {
      "name": "TernGrad",
      "one_line_profile": "Ternary gradients implementation for reducing communication in distributed deep learning",
      "detailed_description": "An implementation of Ternary Gradients (TernGrad) to reduce communication overhead in distributed deep learning training, specifically for TensorFlow.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "gradient_compression"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wenwei202/terngrad",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "gradient-compression",
        "tensorflow"
      ],
      "id": 345
    },
    {
      "name": "FlashVGGT",
      "one_line_profile": "Efficient descriptor-based global attention acceleration for VGGT",
      "detailed_description": "A tool to accelerate VGGT (Visual Geometry Grounded Transformer) using efficient descriptor-based global attention mechanisms.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "model_acceleration",
        "attention_mechanism"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wzpscott/flashvggt",
      "help_website": [],
      "license": null,
      "tags": [
        "attention",
        "acceleration",
        "transformer"
      ],
      "id": 346
    },
    {
      "name": "PipeGoose",
      "one_line_profile": "Large scale 4D parallelism pre-training library for transformers",
      "detailed_description": "A library for large-scale 4D parallelism pre-training of Transformer models, specifically targeting Mixture of Experts (MoE) architectures.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "parallelism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/xrsrke/pipegoose",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "distributed-training",
        "parallelism",
        "moe",
        "transformers"
      ],
      "id": 347
    },
    {
      "name": "CaffeOnSpark",
      "one_line_profile": "Distributed deep learning framework on Hadoop and Spark clusters",
      "detailed_description": "A framework that enables distributed deep learning on Hadoop and Spark clusters, allowing for training of deep learning models on big data infrastructure.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "deep_learning"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/yahoo/CaffeOnSpark",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-learning",
        "spark",
        "hadoop",
        "caffe"
      ],
      "id": 348
    },
    {
      "name": "DeDLOC",
      "one_line_profile": "Distributed Deep Learning in Open Collaborations",
      "detailed_description": "Implementation of methods for distributed deep learning in open collaborations, enabling decentralized training workflows.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "decentralized_learning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/yandex-research/DeDLOC",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "collaborative-learning"
      ],
      "id": 349
    },
    {
      "name": "SWARM",
      "one_line_profile": "Communication-efficient SWARM parallelism for training large models",
      "detailed_description": "A library implementing SWARM parallelism to enable communication-efficient training of large models across unreliable or heterogeneous devices.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "parallelism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yandex-research/swarm",
      "help_website": [],
      "license": null,
      "tags": [
        "distributed-training",
        "swarm-parallelism"
      ],
      "id": 350
    },
    {
      "name": "YaFSDP",
      "one_line_profile": "Optimized Fully Sharded Data Parallel implementation",
      "detailed_description": "Yet another Fully Sharded Data Parallel (YaFSDP) implementation, providing optimized memory and communication efficiency for training large language models.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "memory_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yandex/YaFSDP",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fsdp",
        "distributed-training",
        "llm"
      ],
      "id": 351
    },
    {
      "name": "LLM-SFT",
      "one_line_profile": "Framework for Supervised Fine-Tuning of Large Language Models",
      "detailed_description": "A framework for Supervised Fine-Tuning (SFT) of Chinese and other Large Language Models, supporting LoRA, QLoRA, DeepSpeed, and various model architectures.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_training"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/yongzhuo/LLM-SFT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "sft",
        "fine-tuning",
        "lora"
      ],
      "id": 352
    },
    {
      "name": "Realtime Semantic Segmentation PyTorch",
      "one_line_profile": "PyTorch implementation of realtime semantic segmentation models",
      "detailed_description": "A comprehensive library providing PyTorch implementations for over 30 realtime semantic segmentation models, supporting distributed training and knowledge distillation.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "semantic_segmentation",
        "model_implementation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zh320/realtime-semantic-segmentation-pytorch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "semantic-segmentation",
        "pytorch",
        "computer-vision"
      ],
      "id": 353
    },
    {
      "name": "yolort",
      "one_line_profile": "Runtime stack for YOLOv5 on specialized accelerators",
      "detailed_description": "A runtime stack designed to accelerate YOLOv5 inference on specialized hardware accelerators such as TensorRT, LibTorch, ONNX Runtime, TVM, and NCNN.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_deployment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhiqwang/yolort",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "inference",
        "acceleration",
        "yolo",
        "tensorrt"
      ],
      "id": 354
    },
    {
      "name": "Ring Flash Attention",
      "one_line_profile": "Ring attention implementation with Flash Attention",
      "detailed_description": "An implementation of Ring Attention combined with Flash Attention to enable training with extremely long context windows in a distributed setting.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "distributed_training",
        "attention_mechanism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhuzilin/ring-flash-attention",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "flash-attention",
        "ring-attention",
        "distributed-training"
      ],
      "id": 355
    },
    {
      "name": "KnowLM",
      "one_line_profile": "Knowledgeable Large Language Model Framework",
      "detailed_description": "An open-source framework for training and utilizing Knowledgeable Large Language Models (KnowLM), focusing on knowledge extraction and reasoning.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "llm_training",
        "knowledge_extraction"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/KnowLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "knowledge-graph",
        "framework"
      ],
      "id": 356
    },
    {
      "name": "LLM-Adapters",
      "one_line_profile": "A framework for Parameter-Efficient Fine-Tuning (PEFT) of Large Language Models",
      "detailed_description": "A library integrating various adapter-based methods for parameter-efficient fine-tuning of Large Language Models (LLMs), enabling researchers to fine-tune models with limited compute resources.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AGI-Edgerunners/LLM-Adapters",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "peft",
        "llm",
        "adapters",
        "fine-tuning"
      ],
      "id": 357
    },
    {
      "name": "KG_RAG",
      "one_line_profile": "Knowledge Graph based Retrieval-Augmented Generation framework for biomedicine",
      "detailed_description": "A framework designed to empower Large Language Models (LLMs) with Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG), specifically optimized for knowledge-intensive scientific tasks such as biomedical information retrieval.",
      "domains": [
        "AI4",
        "AI3"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "rag",
        "biomedical_inference"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/BaranziniLab/KG_RAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "rag",
        "biomedicine",
        "llm"
      ],
      "id": 358
    },
    {
      "name": "bonito",
      "one_line_profile": "Synthetic instruction tuning dataset generator",
      "detailed_description": "A lightweight library for generating synthetic instruction tuning datasets from unannotated text, facilitating the creation of domain-specific training data for aligning Large Language Models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_generation",
        "instruction_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BatsResearch/bonito",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "synthetic-data",
        "instruction-tuning",
        "dataset-generation"
      ],
      "id": 359
    },
    {
      "name": "EmotionBench",
      "one_line_profile": "Benchmark suite for evaluating Large Language Models' emotional alignment with humans",
      "detailed_description": "A benchmarking tool designed to assess the emotional alignment of Large Language Models (LLMs) with human emotional responses. It provides datasets and evaluation metrics to measure how well models understand and generate emotionally appropriate content.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/CUHK-ARISE/EmotionBench",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "llm",
        "alignment",
        "benchmark",
        "emotion-recognition"
      ],
      "id": 360
    },
    {
      "name": "pykoi",
      "one_line_profile": "Unified interface for active learning and RLHF fine-tuning of LLMs",
      "detailed_description": "An open-source library for training and fine-tuning Large Language Models (LLMs) using Reinforcement Learning from Human Feedback (RLHF). It provides a unified interface for active learning, model comparison, and data collection to improve model alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "fine-tuning",
        "active_learning"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/CambioML/pykoi-rlhf-finetuned-transformers",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "llm",
        "fine-tuning",
        "active-learning"
      ],
      "id": 361
    },
    {
      "name": "BiPO",
      "one_line_profile": "Bi-directional Preference Optimization for personalized steering of LLMs",
      "detailed_description": "Implementation of Bi-directional Preference Optimization (BiPO) for creating versatile steering vectors to personalize Large Language Models. It focuses on aligning models with specific user preferences through efficient optimization techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization",
        "steering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CaoYuanpu/BiPO",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "alignment",
        "preference-optimization",
        "steering-vectors"
      ],
      "id": 362
    },
    {
      "name": "MELoRA",
      "one_line_profile": "Mini-Ensemble Low-Rank Adapter for parameter-efficient fine-tuning",
      "detailed_description": "Implementation of MELoRA, a parameter-efficient fine-tuning (PEFT) method that uses a mini-ensemble of low-rank adapters to improve model performance with minimal parameter overhead. It is designed for efficient adaptation of large pre-trained models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "fine-tuning",
        "lora"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChasonShi/MELoRA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "peft",
        "lora",
        "fine-tuning",
        "ensemble"
      ],
      "id": 363
    },
    {
      "name": "TimeCMA",
      "one_line_profile": "Cross-modality alignment for LLM-empowered time series forecasting",
      "detailed_description": "A framework for multivariate time series forecasting that leverages Large Language Models (LLMs) through cross-modality alignment. It aligns time series data with the semantic space of LLMs to enhance forecasting capabilities.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "time_series_forecasting",
        "cross_modality"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChenxiLiu-HNU/TimeCMA",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "time-series",
        "llm",
        "alignment",
        "forecasting"
      ],
      "id": 364
    },
    {
      "name": "Subspace-Tuning",
      "one_line_profile": "Generalized framework for subspace tuning in parameter-efficient fine-tuning",
      "detailed_description": "A unified framework for subspace tuning methods in Parameter-Efficient Fine-Tuning (PEFT). It generalizes various PEFT approaches by projecting optimization into lower-dimensional subspaces, facilitating research and application of efficient tuning techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "fine-tuning",
        "subspace_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Chongjie-Si/Subspace-Tuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "peft",
        "fine-tuning",
        "subspace",
        "llm"
      ],
      "id": 365
    },
    {
      "name": "Osprey",
      "one_line_profile": "Pixel-level visual instruction tuning for fine-grained visual understanding",
      "detailed_description": "A multimodal model and training framework for pixel-level visual understanding via visual instruction tuning. It enables fine-grained alignment between visual regions and textual instructions, supporting tasks like detailed image description and region-based QA.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "multimodal_alignment",
        "visual_understanding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CircleRadon/Osprey",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "instruction-tuning",
        "visual-understanding",
        "pixel-level"
      ],
      "id": 366
    },
    {
      "name": "CLAIR_and_APO",
      "one_line_profile": "Anchored Preference Optimization for addressing underspecification in alignment",
      "detailed_description": "Implementation of Anchored Preference Optimization (APO) and Contrastive Revisions (CLAIR) to improve the alignment of Large Language Models. These methods address underspecification in human preferences to produce more robustly aligned models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization",
        "rlhf"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ContextualAI/CLAIR_and_APO",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "alignment",
        "preference-optimization",
        "llm",
        "apo"
      ],
      "id": 367
    },
    {
      "name": "HALOs",
      "one_line_profile": "Library for Human-Aware Loss Functions (DPO, KTO, PPO) in LLM alignment",
      "detailed_description": "A comprehensive library providing implementations of various human-aware loss functions (HALOs) such as Direct Preference Optimization (DPO), Kahneman-Tversky Optimization (KTO), and PPO. It facilitates the alignment of LLMs with human preferences.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "loss_functions",
        "dpo",
        "kto"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ContextualAI/HALOs",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "dpo",
        "kto",
        "loss-functions"
      ],
      "id": 368
    },
    {
      "name": "GritLM",
      "one_line_profile": "Generative Representational Instruction Tuning for unified text embedding and generation",
      "detailed_description": "Implementation of Generative Representational Instruction Tuning (GRIT), a method that unifies text embedding and generative capabilities in a single Large Language Model. It enables models to handle both representation learning and instruction following tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "representation_learning",
        "embedding"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ContextualAI/gritlm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "instruction-tuning",
        "embedding",
        "llm",
        "representation"
      ],
      "id": 369
    },
    {
      "name": "Unsloth LLaMA-3 Pipeline",
      "one_line_profile": "Optimized 4-bit QLoRA fine-tuning pipeline for LLaMA 3",
      "detailed_description": "A production-grade fine-tuning pipeline leveraging Unsloth and QLoRA for efficient 4-bit training of LLaMA 3 models. It focuses on memory efficiency and speed for instruction-following specialization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine-tuning",
        "qlora",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Cre4T3Tiv3/unsloth-llama3-alpaca-lora",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fine-tuning",
        "qlora",
        "llama-3",
        "unsloth"
      ],
      "id": 370
    },
    {
      "name": "LongPO",
      "one_line_profile": "Long context self-evolution via short-to-long preference optimization",
      "detailed_description": "A framework for extending the context window of Large Language Models through self-evolution and preference optimization. It utilizes short-to-long preference learning to align models for long-context understanding and generation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "long_context",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DAMO-NLP-SG/LongPO",
      "help_website": [],
      "license": null,
      "tags": [
        "long-context",
        "alignment",
        "preference-optimization",
        "llm"
      ],
      "id": 371
    },
    {
      "name": "Video-LLaMA",
      "one_line_profile": "Instruction-tuned audio-visual language model for video understanding",
      "detailed_description": "A multi-modal framework that empowers Large Language Models with video and audio understanding capabilities through instruction tuning. It aligns visual and audio encoders with the LLM embedding space to support video-based Q&A and dialogue.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "multimodal_alignment",
        "video_understanding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DAMO-NLP-SG/Video-LLaMA",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "multimodal",
        "video-llm",
        "instruction-tuning",
        "alignment"
      ],
      "id": 372
    },
    {
      "name": "DISTRE",
      "one_line_profile": "Fine-tuning transformer models for distantly supervised relation extraction",
      "detailed_description": "A tool for fine-tuning pre-trained transformer language models specifically for the task of distantly supervised relation extraction. It adapts general-purpose models to extract semantic relations from text using distant supervision signals.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine-tuning",
        "relation_extraction",
        "nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DFKI-NLP/DISTRE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "relation-extraction",
        "fine-tuning",
        "transformer",
        "nlp"
      ],
      "id": 373
    },
    {
      "name": "General-Visual-Quality-RL",
      "one_line_profile": "Reinforcement learning for image quality assessment via preference optimization",
      "detailed_description": "Implementation of PreResQ-R1, a method using Reinforcement Learning and Preference-Response Disentangled Policy Optimization to align models for fine-grained image quality assessment. It focuses on rank-and-score capabilities.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "reinforcement_learning",
        "image_quality_assessment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DanceSkyCode/General-Visual-Quality-RL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rl",
        "alignment",
        "image-quality",
        "preference-optimization"
      ],
      "id": 374
    },
    {
      "name": "Docta",
      "one_line_profile": "Data-centric AI tool for detecting data errors and improving dataset quality",
      "detailed_description": "A data-centric AI tool designed to diagnose and cure data issues such as label errors and outliers. It helps improve the quality of training data, which is a critical step before model training and alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_quality",
        "data_cleaning",
        "preprocessing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Docta-ai/docta",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "data-centric-ai",
        "data-cleaning",
        "quality-control"
      ],
      "id": 375
    },
    {
      "name": "3dpose_gan",
      "one_line_profile": "Unsupervised adversarial learning for 3D human pose estimation",
      "detailed_description": "Implementation of a GAN-based approach for unsupervised learning of 3D human pose from 2D joint locations. It serves as a scientific modeling tool for converting 2D visual data into 3D structural information.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "modeling",
        "pose_estimation",
        "gan"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DwangoMediaVillage/3dpose_gan",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "3d-pose",
        "gan",
        "computer-vision",
        "modeling"
      ],
      "id": 376
    },
    {
      "name": "AutoPrompt",
      "one_line_profile": "Framework for intent-based prompt calibration and tuning",
      "detailed_description": "A framework for prompt tuning that utilizes Intent-based Prompt Calibration to automatically optimize prompts for Large Language Models. It helps in aligning model outputs with user intent without extensive fine-tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "prompt_tuning",
        "alignment",
        "calibration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Eladlev/AutoPrompt",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prompt-tuning",
        "llm",
        "alignment",
        "calibration"
      ],
      "id": 377
    },
    {
      "name": "UVQA",
      "one_line_profile": "Alignment framework for answerability in Video LLMs",
      "detailed_description": "Code and dataset for aligning Video Large Language Models to refuse unanswerable questions. It focuses on improving the reliability and safety of multimodal models by teaching them to recognize the limits of visual information.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "multimodal",
        "evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/EsYoon7/UVQA",
      "help_website": [],
      "license": null,
      "tags": [
        "video-llm",
        "alignment",
        "safety",
        "multimodal"
      ],
      "id": 378
    },
    {
      "name": "Otter",
      "one_line_profile": "Multi-modal model for in-context learning and instruction following",
      "detailed_description": "A multi-modal model based on OpenFlamingo, designed for improved instruction-following and in-context learning capabilities. It is trained on the MIMIC-IT dataset to align visual and textual understanding.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "multimodal_alignment",
        "in_context_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/EvolvingLMMs-Lab/Otter",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multimodal",
        "instruction-tuning",
        "openflamingo",
        "llm"
      ],
      "id": 379
    },
    {
      "name": "ComfyUI_ELLA",
      "one_line_profile": "Enhanced semantic alignment for diffusion models via LLM integration",
      "detailed_description": "A ComfyUI implementation of ELLA, a method that equips diffusion models with Large Language Models to improve semantic alignment between text prompts and generated images. It serves as a tool for enhanced generative modeling.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "generative_modeling",
        "diffusion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ExponentialML/ComfyUI_ELLA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion",
        "alignment",
        "llm",
        "comfyui"
      ],
      "id": 380
    },
    {
      "name": "SplitFM",
      "one_line_profile": "Split parameter-efficient fine-tuning and inference framework",
      "detailed_description": "A framework for split parameter-efficient fine-tuning (PEFT) and inference of foundation models. It enables efficient model adaptation and deployment by splitting computational loads or parameters.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "fine-tuning",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/FDU-INC/SplitFM",
      "help_website": [],
      "license": null,
      "tags": [
        "peft",
        "fine-tuning",
        "foundation-models"
      ],
      "id": 381
    },
    {
      "name": "Chinese-Vicuna",
      "one_line_profile": "Chinese instruction-following LLaMA model with LoRA fine-tuning",
      "detailed_description": "A low-resource solution for fine-tuning LLaMA models on Chinese instruction datasets using LoRA. It provides tools for training, inference, and deployment of Chinese-aligned LLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "lora",
        "fine-tuning"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/Facico/Chinese-Vicuna",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llama",
        "lora",
        "chinese-llm",
        "instruction-tuning"
      ],
      "id": 382
    },
    {
      "name": "GOAT-PEFT",
      "one_line_profile": "Adaptive singular value optimization for boosting LoRA alignment",
      "detailed_description": "Implementation of a method to boost LoRA performance using adaptive singular values and Mixture-of-Experts optimization. It aims to improve the alignment and efficiency of parameter-efficient fine-tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "lora",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Facico/GOAT-PEFT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "lora",
        "alignment",
        "optimization"
      ],
      "id": 383
    },
    {
      "name": "FantasyTalking2",
      "one_line_profile": "Timestep-layer adaptive preference optimization for audio-driven animation",
      "detailed_description": "A framework for audio-driven portrait animation that utilizes timestep-layer adaptive preference optimization. It aligns generated animations with audio inputs using advanced preference learning techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization",
        "generative_modeling"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/Fantasy-AMAP/fantasy-talking2",
      "help_website": [],
      "license": null,
      "tags": [
        "alignment",
        "audio-driven",
        "animation",
        "preference-optimization"
      ],
      "id": 384
    },
    {
      "name": "GPS",
      "one_line_profile": "Gradient-based parameter selection for efficient fine-tuning",
      "detailed_description": "A method for selecting the most important parameters for fine-tuning based on gradients. It optimizes the fine-tuning process by focusing on a subset of parameters, enhancing efficiency.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "fine-tuning",
        "parameter_selection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FightingFighting/GPS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "fine-tuning",
        "gradient-based",
        "efficiency"
      ],
      "id": 385
    },
    {
      "name": "MultilingualSIFT",
      "one_line_profile": "Multilingual supervised instruction fine-tuning framework",
      "detailed_description": "A framework for multilingual supervised instruction fine-tuning (SIFT) of large language models, enabling adaptation to multiple languages.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "fine_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/FreedomIntelligence/MultilingualSIFT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sift",
        "multilingual",
        "llm-training"
      ],
      "id": 386
    },
    {
      "name": "Diffusion-NPO",
      "one_line_profile": "Negative Preference Optimization for diffusion model alignment",
      "detailed_description": "Implementation of Negative Preference Optimization (NPO) to align diffusion models with human preferences by minimizing the likelihood of generating negative samples.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/G-U-N/Diffusion-NPO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-models",
        "alignment",
        "npo"
      ],
      "id": 387
    },
    {
      "name": "vlm-grpo",
      "one_line_profile": "GRPO implementation for Vision-Language Model training",
      "detailed_description": "An implementation of the GRPO (Group Relative Policy Optimization) algorithm specifically designed for training Vision-Language Models (VLMs) within the Unsloth framework.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "reinforcement_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GAD-cell/vlm-grpo",
      "help_website": [],
      "license": null,
      "tags": [
        "vlm",
        "grpo",
        "unsloth"
      ],
      "id": 388
    },
    {
      "name": "IISAN",
      "one_line_profile": "Efficient multimodal foundation model adaptation method",
      "detailed_description": "Implementation of IISAN for efficient adaptation of multimodal foundation models, specifically targeting recommendation systems.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_adaptation",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GAIR-Lab/IISAN",
      "help_website": [],
      "license": null,
      "tags": [
        "multimodal",
        "recommendation",
        "adaptation"
      ],
      "id": 389
    },
    {
      "name": "ChapTER",
      "one_line_profile": "Contrastive historical modeling with prefix-tuning for temporal KGs",
      "detailed_description": "A tool for temporal knowledge graph reasoning using contrastive historical modeling and prefix-tuning techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "prefix_tuning",
        "knowledge_graph_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GKNL/ChapTER",
      "help_website": [],
      "license": null,
      "tags": [
        "temporal-knowledge-graph",
        "prefix-tuning",
        "reasoning"
      ],
      "id": 390
    },
    {
      "name": "FineSSL",
      "one_line_profile": "Fine-tuning foundation models for semi-supervised learning",
      "detailed_description": "Implementation of a method to erase bias and fine-tune foundation models specifically for semi-supervised learning tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "semi_supervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Gank0078/FineSSL",
      "help_website": [],
      "license": null,
      "tags": [
        "ssl",
        "bias-mitigation",
        "foundation-models"
      ],
      "id": 391
    },
    {
      "name": "Beyond-Log-Likelihood",
      "one_line_profile": "Alternative objectives for supervised fine-tuning",
      "detailed_description": "Explores and implements alternative objective functions beyond log-likelihood for the supervised fine-tuning of language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "objective_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GaotangLi/Beyond-Log-Likelihood",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sft",
        "loss-functions",
        "llm"
      ],
      "id": 392
    },
    {
      "name": "ScoreFlow",
      "one_line_profile": "Score-based preference optimization for LLM agent workflows",
      "detailed_description": "A framework for optimizing LLM agent workflows using score-based preference optimization techniques to master complex tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "preference_optimization",
        "agent_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Gen-Verse/ScoreFlow",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-agent",
        "preference-optimization",
        "workflow"
      ],
      "id": 393
    },
    {
      "name": "dLLM-RL",
      "one_line_profile": "Reinforcement learning framework for Diffusion LLMs",
      "detailed_description": "TraceRL and TraDo-8B implementation, providing a reinforcement learning framework specifically tailored for Diffusion Large Language Models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Gen-Verse/dLLM-RL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-llm",
        "rlhf",
        "reinforcement-learning"
      ],
      "id": 394
    },
    {
      "name": "cognify",
      "one_line_profile": "Auto-tuning tool for AI agents and workflows",
      "detailed_description": "A tool for automatically optimizing LangChain, LangGraph, and DSPy programs to improve quality, latency, and cost of AI agent workflows.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "workflow_optimization",
        "auto_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/GenseeAI/cognify",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent-optimization",
        "langchain",
        "dspy"
      ],
      "id": 395
    },
    {
      "name": "mlx-lm-lora",
      "one_line_profile": "LoRA fine-tuning for LLMs on Apple MLX",
      "detailed_description": "A library for training and fine-tuning Large Language Models using LoRA on Apple Silicon via the MLX framework.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "lora"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Goekdeniz-Guelmez/mlx-lm-lora",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mlx",
        "lora",
        "apple-silicon"
      ],
      "id": 396
    },
    {
      "name": "PiSSA",
      "one_line_profile": "Principal Singular Values and Singular Vectors Adaptation for LLMs",
      "detailed_description": "Implementation of PiSSA, a parameter-efficient fine-tuning method that adapts principal singular values and vectors of Large Language Models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/GraphPKU/PiSSA",
      "help_website": [],
      "license": null,
      "tags": [
        "peft",
        "svd",
        "llm-adaptation"
      ],
      "id": 397
    },
    {
      "name": "ffrecord",
      "one_line_profile": "High-performance file format for DL training samples",
      "detailed_description": "FireFlyer Record (ffrecord) is a file format and library designed for efficient reading and writing of deep learning training samples.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "data_io",
        "training_infrastructure"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HFAiLab/ffrecord",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-format",
        "io",
        "deep-learning"
      ],
      "id": 398
    },
    {
      "name": "GraphGPT",
      "one_line_profile": "Graph instruction tuning for Large Language Models",
      "detailed_description": "A framework for graph instruction tuning, enabling Large Language Models to understand and process graph-structured data.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "graph_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUDS/GraphGPT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "graph-neural-networks",
        "instruction-tuning",
        "llm"
      ],
      "id": 399
    },
    {
      "name": "UrbanGPT",
      "one_line_profile": "Spatio-temporal Large Language Models",
      "detailed_description": "A model and toolkit for spatio-temporal prediction tasks using Large Language Models, tailored for urban computing scenarios.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "spatio_temporal_modeling",
        "scientific_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUDS/UrbanGPT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "urban-computing",
        "spatio-temporal",
        "llm"
      ],
      "id": 400
    },
    {
      "name": "swarmlib",
      "one_line_profile": "Library for swarm optimization algorithms",
      "detailed_description": "A library implementing various swarm optimization algorithms including Particle Swarm Optimization, Firefly Algorithm, and Ant Colony Optimization.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "optimization",
        "scientific_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HaaLeo/swarmlib",
      "help_website": [
        "https://swarmlib.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "optimization",
        "swarm-intelligence",
        "algorithms"
      ],
      "id": 401
    },
    {
      "name": "transformers_tasks",
      "one_line_profile": "Collection of NLP task implementations with Transformers",
      "detailed_description": "A comprehensive library of scripts and implementations for various NLP tasks (classification, generation, extraction, RLHF, SFT) using the Transformers library.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "rlhf",
        "nlp_tasks"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/HarderThenHarder/transformers_tasks",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "transformers",
        "rlhf"
      ],
      "id": 402
    },
    {
      "name": "VistaDPO",
      "one_line_profile": "Video hierarchical spatial-temporal Direct Preference Optimization",
      "detailed_description": "Implementation of VistaDPO for aligning large video models using hierarchical spatial-temporal direct preference optimization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "dpo",
        "video_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HaroldChen19/VistaDPO",
      "help_website": [],
      "license": null,
      "tags": [
        "video-models",
        "dpo",
        "alignment"
      ],
      "id": 403
    },
    {
      "name": "HugNLP",
      "one_line_profile": "Unified NLP library based on HuggingFace Transformers",
      "detailed_description": "A comprehensive NLP library designed to simplify the development and training of NLP models, built on top of HuggingFace Transformers.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HugAILab/HugNLP",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "transformers",
        "framework"
      ],
      "id": 404
    },
    {
      "name": "DiffuseKronA",
      "one_line_profile": "Parameter efficient fine-tuning for personalized diffusion models",
      "detailed_description": "A parameter-efficient fine-tuning method (KronA) specifically designed for personalizing diffusion models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "diffusion_personalization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/IBM/DiffuseKronA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion",
        "peft",
        "personalization"
      ],
      "id": 405
    },
    {
      "name": "VTAGML",
      "one_line_profile": "Vision Transformer Adapters for generalizable multitask learning",
      "detailed_description": "Implementation of adapters for Vision Transformers to enable generalizable multitask learning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "multitask_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/IVRL/VTAGML",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vision-transformer",
        "adapters",
        "multitask-learning"
      ],
      "id": 406
    },
    {
      "name": "rulm",
      "one_line_profile": "Russian language modeling and instruction tuning toolkit",
      "detailed_description": "A toolkit for language modeling and instruction tuning specifically for the Russian language, including datasets and training scripts.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "language_modeling"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/IlyaGusev/rulm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "russian-nlp",
        "instruction-tuning",
        "llm"
      ],
      "id": 407
    },
    {
      "name": "GPT-4-LLM",
      "one_line_profile": "Instruction tuning data generation with GPT-4",
      "detailed_description": "A workflow and dataset collection for using GPT-4 to generate instruction-following data for fine-tuning LLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_synthesis",
        "instruction_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "instruction-tuning",
        "synthetic-data",
        "gpt-4"
      ],
      "id": 408
    },
    {
      "name": "Condor",
      "one_line_profile": "Knowledge-driven data synthesis for LLM alignment",
      "detailed_description": "A tool to enhance LLM alignment through knowledge-driven data synthesis and refinement.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "data_synthesis"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/InternLM/Condor",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "synthetic-data",
        "llm"
      ],
      "id": 409
    },
    {
      "name": "InternLM",
      "one_line_profile": "Comprehensive Large Language Model training and inference suite",
      "detailed_description": "The official codebase for the InternLM series, providing a complete toolchain for pre-training, fine-tuning, and deploying large language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "fine_tuning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/InternLM/InternLM",
      "help_website": [
        "https://internlm.intern-ai.org.cn/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "training-framework",
        "internlm"
      ],
      "id": 410
    },
    {
      "name": "InternLM-XComposer",
      "one_line_profile": "Multimodal LLM system for advanced interactions",
      "detailed_description": "A comprehensive multimodal system based on InternLM for long-term streaming video and audio interactions, including training and inference tools.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "multimodal_training",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/InternLM/InternLM-XComposer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "vlm",
        "internlm"
      ],
      "id": 411
    },
    {
      "name": "xtuner",
      "one_line_profile": "High-efficiency fine-tuning toolkit for LLMs",
      "detailed_description": "A next-generation training engine designed for efficient fine-tuning of Large Language Models, supporting various PEFT methods and ultra-large MoE models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/InternLM/xtuner",
      "help_website": [
        "https://xtuner.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "fine-tuning",
        "peft",
        "lora"
      ],
      "id": 412
    },
    {
      "name": "GraphGen",
      "one_line_profile": "Knowledge-driven synthetic data generation for SFT",
      "detailed_description": "A tool for enhancing Supervised Fine-Tuning (SFT) of LLMs by generating knowledge-driven synthetic data.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_synthesis",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/InternScience/GraphGen",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "synthetic-data",
        "sft",
        "knowledge-graph"
      ],
      "id": 413
    },
    {
      "name": "DreamArtist-stable-diffusion",
      "one_line_profile": "Stable Diffusion webui extension for contrastive prompt tuning",
      "detailed_description": "A Stable Diffusion WebUI extension that implements the DreamArtist algorithm for contrastive prompt tuning, allowing for high-quality style and object learning with parameter efficiency.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "parameter_efficient_fine_tuning",
        "generative_model_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IrisRainbowNeko/DreamArtist-stable-diffusion",
      "help_website": [],
      "license": null,
      "tags": [
        "stable-diffusion",
        "prompt-tuning",
        "peft"
      ],
      "id": 414
    },
    {
      "name": "Point-PEFT",
      "one_line_profile": "Parameter-Efficient Fine-Tuning for 3D Pre-trained Models",
      "detailed_description": "Implementation of Point-PEFT (AAAI 2024), a method for parameter-efficient fine-tuning specifically designed for 3D pre-trained models, enabling adaptation to downstream 3D tasks with minimal trainable parameters.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "parameter_efficient_fine_tuning",
        "3d_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Ivan-Tang-3D/Point-PEFT",
      "help_website": [],
      "license": null,
      "tags": [
        "3d-deep-learning",
        "peft",
        "aaai-2024"
      ],
      "id": 415
    },
    {
      "name": "MiniHF",
      "one_line_profile": "Local tool for inference, human preference data collection, and fine-tuning",
      "detailed_description": "A comprehensive tool for local language model development, facilitating inference, collection of human preference data (RLHF), and fine-tuning workflows to develop prompts into full models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf_data_collection",
        "fine_tuning",
        "inference"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/JD-P/minihf",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "fine-tuning",
        "data-collection"
      ],
      "id": 416
    },
    {
      "name": "AMoPO",
      "one_line_profile": "Adaptive Multi-objective Preference Optimization for LLMs",
      "detailed_description": "Implementation of AMoPO, an alignment algorithm that performs adaptive multi-objective preference optimization without requiring reward models or reference models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Javkonline/AMoPO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dpo",
        "alignment",
        "llm"
      ],
      "id": 417
    },
    {
      "name": "InPO",
      "one_line_profile": "Inversion Preference Optimization for Diffusion Model Alignment",
      "detailed_description": "Implementation of InPO (CVPR 2025), a method for efficient diffusion model alignment using inversion preference optimization with reparametrized DDIM.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "diffusion_model_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JaydenLyh/InPO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-models",
        "alignment",
        "cvpr-2025"
      ],
      "id": 418
    },
    {
      "name": "AIDoctor",
      "one_line_profile": "Medical GPT model training pipeline including SFT, RLHF, and DPO",
      "detailed_description": "A complete training pipeline for medical domain LLMs, implementing Pretraining, Supervised Fine-tuning (SFT), Reward Modeling, Reinforcement Learning (RLHF), and Direct Preference Optimization (DPO).",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "domain_adaptation",
        "rlhf",
        "sft"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Jerry-XDL/AIDoctor",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-llm",
        "rlhf",
        "dpo"
      ],
      "id": 419
    },
    {
      "name": "LLM-RLHF-Tuning",
      "one_line_profile": "LLM Tuning pipeline with PEFT, SFT, RM, PPO, and DPO",
      "detailed_description": "A comprehensive library for Large Language Model tuning, integrating Parameter-Efficient Fine-Tuning (PEFT) with LoRA, Supervised Fine-Tuning (SFT), Reward Modeling, PPO, and DPO algorithms.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "peft",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Joyce94/LLM-RLHF-Tuning",
      "help_website": [],
      "license": null,
      "tags": [
        "rlhf",
        "lora",
        "ppo"
      ],
      "id": 420
    },
    {
      "name": "VPT",
      "one_line_profile": "Visual Prompt Tuning for vision models",
      "detailed_description": "Implementation of Visual Prompt Tuning (ECCV 2022), a parameter-efficient fine-tuning method for large-scale vision models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "visual_prompt_tuning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/KMnP/vpt",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "computer-vision",
        "prompt-tuning",
        "eccv-2022"
      ],
      "id": 421
    },
    {
      "name": "Kiln",
      "one_line_profile": "Platform for building AI systems with fine-tuning and synthetic data",
      "detailed_description": "A development platform for building AI systems that integrates evaluations, RAG, agents, fine-tuning, and synthetic data generation workflows.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "synthetic_data_generation",
        "evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Kiln-AI/Kiln",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "fine-tuning",
        "synthetic-data",
        "rag"
      ],
      "id": 422
    },
    {
      "name": "Time-LLM",
      "one_line_profile": "Time Series Forecasting by Reprogramming Large Language Models",
      "detailed_description": "Official implementation of Time-LLM (ICLR 2024), a framework for reprogramming large language models to perform time series forecasting tasks.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "time_series_forecasting",
        "model_reprogramming"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/KimMeen/Time-LLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "time-series",
        "llm",
        "iclr-2024"
      ],
      "id": 423
    },
    {
      "name": "LyCORIS",
      "one_line_profile": "Parameter-efficient fine-tuning library for Stable Diffusion",
      "detailed_description": "A library implementing various parameter-efficient fine-tuning methods (LoRA, LoCon, LoHa, etc.) specifically optimized for Stable Diffusion and other generative models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "parameter_efficient_fine_tuning",
        "generative_model_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KohakuBlueleaf/LyCORIS",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lora",
        "stable-diffusion",
        "peft"
      ],
      "id": 424
    },
    {
      "name": "LPO",
      "one_line_profile": "Latent Preference Optimization for Diffusion Models",
      "detailed_description": "Implementation of Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level Preference Optimization, enabling alignment of diffusion models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Kwai-Kolors/LPO",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "diffusion-models",
        "alignment",
        "rlhf"
      ],
      "id": 425
    },
    {
      "name": "MM-RLHF",
      "one_line_profile": "Multimodal LLM Alignment Framework",
      "detailed_description": "A framework for multimodal large language model alignment, implementing RLHF techniques adapted for multimodal contexts.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "multimodal_learning",
        "rlhf"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Kwai-YuanQi/MM-RLHF",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "rlhf",
        "alignment"
      ],
      "id": 426
    },
    {
      "name": "Open-Assistant",
      "one_line_profile": "Open source chat-based assistant and data collection platform",
      "detailed_description": "A massive open-source project providing tools for data collection, RLHF, and training of chat-based AI assistants.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_collection",
        "rlhf",
        "model_training"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/LAION-AI/Open-Assistant",
      "help_website": [
        "https://open-assistant.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "chatbot",
        "open-source"
      ],
      "id": 427
    },
    {
      "name": "CHiP",
      "one_line_profile": "Cross-modal Hierarchical Direct Preference Optimization",
      "detailed_description": "Implementation of CHiP (ICLR 2025), a method for cross-modal hierarchical direct preference optimization for aligning multimodal LLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "dpo",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LVUGAI/CHiP",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dpo",
        "multimodal",
        "iclr-2025"
      ],
      "id": 428
    },
    {
      "name": "BELLE",
      "one_line_profile": "Open-source Chinese dialogue model engine and training codebase",
      "detailed_description": "An open-source project for Chinese dialogue large language models, providing training code, data, and model checkpoints for instruction tuning and alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/LianjiaTech/BELLE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "chinese-nlp",
        "instruction-tuning"
      ],
      "id": 429
    },
    {
      "name": "Lit-LLaMA",
      "one_line_profile": "Implementation of LLaMA for pre-training and fine-tuning",
      "detailed_description": "A clean, hackable implementation of the LLaMA language model, supporting pre-training, fine-tuning (LoRA, Adapter), and quantization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "pre_training",
        "fine_tuning",
        "peft"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lightning-AI/lit-llama",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llama",
        "fine-tuning",
        "lora"
      ],
      "id": 430
    },
    {
      "name": "APO",
      "one_line_profile": "Adversarial Preference Optimization for LLM alignment",
      "detailed_description": "Implementation of Adversarial Preference Optimization (ACL 2024), a method for aligning large language models using adversarial training techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Linear95/APO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "acl-2024",
        "adversarial-training"
      ],
      "id": 431
    },
    {
      "name": "CTune-MLX",
      "one_line_profile": "Fine-tuning tool for Apple Silicon (MLX)",
      "detailed_description": "A fine-tuning tool based on the MLX framework, designed to enable efficient model tuning on Apple Silicon devices.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "on_device_training"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/Lt2023/CTune-MLX",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "mlx",
        "fine-tuning",
        "apple-silicon"
      ],
      "id": 432
    },
    {
      "name": "DGPO",
      "one_line_profile": "Direct Group Preference Optimization for Diffusion Models",
      "detailed_description": "Implementation of Direct Group Preference Optimization for reinforcing diffusion models, enabling efficient alignment with human preferences.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "diffusion_model_tuning"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/Luo-Yihong/DGPO",
      "help_website": [],
      "license": null,
      "tags": [
        "diffusion-models",
        "alignment",
        "rl"
      ],
      "id": 433
    },
    {
      "name": "Genome_Factory",
      "one_line_profile": "Library for Tuning, Deploying and Interpreting Genomic Models",
      "detailed_description": "An integrated library designed for the development, fine-tuning, deployment, and interpretation of deep learning models in genomics.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "genomics_modeling",
        "fine_tuning",
        "interpretation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MAGICS-LAB/Genome_Factory",
      "help_website": [],
      "license": null,
      "tags": [
        "genomics",
        "bioinformatics",
        "deep-learning"
      ],
      "id": 434
    },
    {
      "name": "DPO-Shift",
      "one_line_profile": "Shifting the Distribution of Direct Preference Optimization",
      "detailed_description": "Implementation of DPO-Shift, an algorithm that improves Direct Preference Optimization by shifting the distribution of preference data.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "dpo"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Meaquadddd/DPO-Shift",
      "help_website": [],
      "license": null,
      "tags": [
        "dpo",
        "alignment",
        "llm"
      ],
      "id": 435
    },
    {
      "name": "SAN",
      "one_line_profile": "Open-vocabulary Semantic Segmentation",
      "detailed_description": "Implementation of Side Adapter Network (SAN) for open-vocabulary semantic segmentation, allowing models to segment objects based on arbitrary text descriptions.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "semantic_segmentation",
        "computer_vision"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MendelXu/SAN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-segmentation",
        "open-vocabulary",
        "vision"
      ],
      "id": 436
    },
    {
      "name": "Shimmy",
      "one_line_profile": "Rust inference server for GGUF/SafeTensors models",
      "detailed_description": "A high-performance, Python-free inference server written in Rust, supporting GGUF and SafeTensors models with OpenAI-API compatibility.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "inference",
        "model_serving"
      ],
      "application_level": "service",
      "primary_language": "Rust",
      "repo_url": "https://github.com/Michael-A-Kuykendall/shimmy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "inference-server",
        "rust",
        "gguf"
      ],
      "id": 437
    },
    {
      "name": "VLA0-TRL",
      "one_line_profile": "Reimplementation of VLA-0 using TRL",
      "detailed_description": "An unofficial reimplementation of the VLA-0 (Vision-Language-Action) model training using the TRL (Transformer Reinforcement Learning) library.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "robotics",
        "fine_tuning",
        "vla"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MilkClouds/vla0-trl",
      "help_website": [],
      "license": null,
      "tags": [
        "robotics",
        "trl",
        "vla"
      ],
      "id": 438
    },
    {
      "name": "GPTQModel",
      "one_line_profile": "LLM model quantization toolkit with hardware acceleration",
      "detailed_description": "A toolkit for LLM model quantization (compression) supporting hardware acceleration for Nvidia CUDA, AMD ROCm, and Intel XPU, facilitating efficient model deployment.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ModelCloud/GPTQModel",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "quantization",
        "gptq",
        "model-compression"
      ],
      "id": 439
    },
    {
      "name": "NExT-GPT",
      "one_line_profile": "Any-to-Any Multimodal Large Language Model",
      "detailed_description": "Code and models for NExT-GPT (ICML 2024), an any-to-any multimodal large language model capable of processing and generating various modalities.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "multimodal_learning",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NExT-GPT/NExT-GPT",
      "help_website": [
        "https://next-gpt.github.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "multimodal-llm",
        "icml-2024",
        "generative-ai"
      ],
      "id": 440
    },
    {
      "name": "MAPO",
      "one_line_profile": "Multilingual alignment-as-preference optimization implementation",
      "detailed_description": "An implementation of the MAPO algorithm designed to advance multilingual reasoning capabilities in large language models through preference optimization techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NJUNLP/MAPO",
      "help_website": [],
      "license": null,
      "tags": [
        "multilingual",
        "alignment",
        "dpo",
        "reasoning"
      ],
      "id": 441
    },
    {
      "name": "DoRA",
      "one_line_profile": "Weight-decomposed low-rank adaptation for parameter-efficient fine-tuning",
      "detailed_description": "The official PyTorch implementation of DoRA, a PEFT method that decomposes weights into magnitude and direction components to improve fine-tuning performance and stability.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "model_adaptation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVlabs/DoRA",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "peft",
        "lora",
        "weight-decomposition",
        "fine-tuning"
      ],
      "id": 442
    },
    {
      "name": "catk",
      "one_line_profile": "Closed-loop supervised fine-tuning toolkit for traffic models",
      "detailed_description": "A toolkit for the closed-loop supervised fine-tuning of tokenized traffic models, enabling the generation and refinement of realistic traffic simulations.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "simulation_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVlabs/catk",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "traffic-simulation",
        "sft",
        "closed-loop"
      ],
      "id": 443
    },
    {
      "name": "OneTrainer",
      "one_line_profile": "Comprehensive training platform for Stable Diffusion models",
      "detailed_description": "A one-stop GUI and backend solution for training Stable Diffusion models, supporting various fine-tuning methods like LoRA and embeddings for generative modeling.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "image_synthesis"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Nerogar/OneTrainer",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "stable-diffusion",
        "training-gui",
        "lora"
      ],
      "id": 444
    },
    {
      "name": "Vision-LLM-Alignment",
      "one_line_profile": "Alignment toolkit for vision-based Large Language Models",
      "detailed_description": "A codebase providing SFT, RLHF, and DPO implementations specifically designed for aligning vision-based LLMs such as LLaVA and LLaMA-Vision.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NiuTrans/Vision-LLM-Alignment",
      "help_website": [],
      "license": null,
      "tags": [
        "vllm",
        "dpo",
        "rlhf",
        "sft"
      ],
      "id": 445
    },
    {
      "name": "InsTag",
      "one_line_profile": "Data analysis tool for LLM supervised fine-tuning",
      "detailed_description": "A tool designed to analyze and tag data used in Large Language Model supervised fine-tuning, helping researchers understand data distribution and quality.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_analysis",
        "data_tagging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OFA-Sys/InsTag",
      "help_website": [],
      "license": null,
      "tags": [
        "sft",
        "data-analysis",
        "instruction-tuning"
      ],
      "id": 446
    },
    {
      "name": "OFA",
      "one_line_profile": "Unified sequence-to-sequence framework for multimodal tasks",
      "detailed_description": "A framework unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning paradigm, supporting pretraining and fine-tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "multimodal_learning",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OFA-Sys/OFA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "seq2seq",
        "unified-architecture"
      ],
      "id": 447
    },
    {
      "name": "Unlearn-Simple",
      "one_line_profile": "Negative preference optimization for LLM unlearning",
      "detailed_description": "An implementation of negative preference optimization techniques designed for efficient and effective unlearning in Large Language Models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "unlearning",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OPTML-Group/Unlearn-Simple",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "unlearning",
        "preference-optimization",
        "safety"
      ],
      "id": 448
    },
    {
      "name": "ViT_PEFT_Vision",
      "one_line_profile": "Parameter-efficient fine-tuning library for Vision Transformers",
      "detailed_description": "A codebase providing implementations and insights for applying Parameter-Efficient Fine-Tuning (PEFT) methods specifically to Vision Transformers (ViT) in visual recognition tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "computer_vision"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/OSU-MLB/ViT_PEFT_Vision",
      "help_website": [],
      "license": null,
      "tags": [
        "vit",
        "peft",
        "visual-recognition"
      ],
      "id": 449
    },
    {
      "name": "InternVideo",
      "one_line_profile": "Video foundation models for multimodal understanding",
      "detailed_description": "A comprehensive library containing video foundation models and tools for multimodal video understanding, supporting various downstream tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "video_understanding",
        "multimodal_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/InternVideo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "video-foundation-model",
        "multimodal",
        "computer-vision"
      ],
      "id": 450
    },
    {
      "name": "LLaMA-Adapter",
      "one_line_profile": "Efficient fine-tuning method for LLaMA models",
      "detailed_description": "An implementation of LLaMA-Adapter, a lightweight adaptation method for fine-tuning LLaMA models to follow instructions with minimal parameter overhead.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "instruction_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/LLaMA-Adapter",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "adapter",
        "llama",
        "efficient-tuning"
      ],
      "id": 451
    },
    {
      "name": "TPO",
      "one_line_profile": "Task preference optimization for multimodal LLMs",
      "detailed_description": "A tool for Task Preference Optimization, designed to improve Multimodal Large Language Models by aligning them with vision tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "multimodal_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/OpenGVLab/TPO",
      "help_website": [],
      "license": null,
      "tags": [
        "preference-optimization",
        "mllm",
        "vision-alignment"
      ],
      "id": 452
    },
    {
      "name": "MOSS-RLHF",
      "one_line_profile": "PPO-based RLHF implementation for LLMs",
      "detailed_description": "A codebase revealing the implementation details of Reinforcement Learning from Human Feedback (RLHF), specifically focusing on the PPO algorithm for large language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenLMLab/MOSS-RLHF",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ppo",
        "rlhf",
        "alignment"
      ],
      "id": 453
    },
    {
      "name": "ART",
      "one_line_profile": "Agent Reinforcement Trainer for multi-step tasks",
      "detailed_description": "A reinforcement learning training framework (Agent Reinforcement Trainer) designed for training multi-step agents using GRPO on models like Qwen and Llama.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "agent_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenPipe/ART",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "grpo",
        "agent-training",
        "rl"
      ],
      "id": 454
    },
    {
      "name": "OpenPipe",
      "one_line_profile": "Platform for converting prompts into fine-tuned models",
      "detailed_description": "A developer tool and platform that facilitates the collection of prompt data and the creation of fine-tuned models to optimize cost and latency.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_distillation"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/OpenPipe/OpenPipe",
      "help_website": [
        "https://openpipe.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "fine-tuning",
        "distillation",
        "prompt-engineering"
      ],
      "id": 455
    },
    {
      "name": "OpenRLHF",
      "one_line_profile": "Scalable and high-performance RLHF framework",
      "detailed_description": "An easy-to-use, scalable, and high-performance framework for Reinforcement Learning from Human Feedback (RLHF), built on Ray and supporting PPO, GRPO, and other algorithms.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenRLHF/OpenRLHF",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "ray",
        "ppo",
        "distributed-training"
      ],
      "id": 456
    },
    {
      "name": "align-anything",
      "one_line_profile": "Framework for training all-modality models with feedback",
      "detailed_description": "A comprehensive framework for aligning models across various modalities (text, image, video, audio) using feedback mechanisms.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "multimodal_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PKU-Alignment/align-anything",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "multimodal",
        "feedback-learning"
      ],
      "id": 457
    },
    {
      "name": "safe-rlhf",
      "one_line_profile": "Constrained value alignment via safe RLHF",
      "detailed_description": "A library implementing Safe RLHF, which decouples helpfulness and harmlessness training to achieve constrained value alignment in large language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "safety_alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PKU-Alignment/safe-rlhf",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "safety",
        "rlhf",
        "alignment"
      ],
      "id": 458
    },
    {
      "name": "Video-LLaVA",
      "one_line_profile": "Unified visual representation learning by alignment",
      "detailed_description": "An implementation of Video-LLaVA that learns united visual representations for images and videos through alignment before projection, enhancing multimodal understanding.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "multimodal_alignment",
        "video_understanding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PKU-YuanGroup/Video-LLaVA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "video-llm",
        "alignment",
        "multimodal"
      ],
      "id": 459
    },
    {
      "name": "UniPT",
      "one_line_profile": "Universal parallel tuning for transfer learning",
      "detailed_description": "A tool implementing Universal Parallel Tuning (UniPT), designed for efficient parameter and memory usage during transfer learning across various modalities.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "transfer_learning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Paranioar/UniPT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "parallel-tuning",
        "transfer-learning",
        "efficiency"
      ],
      "id": 460
    },
    {
      "name": "Alpaca-CoT",
      "one_line_profile": "Unified interface for instruction tuning and PEFT",
      "detailed_description": "A platform that unifies interfaces for instruction-tuning data (including CoT), multiple LLMs, and parameter-efficient fine-tuning methods to facilitate research.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "peft"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/PhoebusSi/Alpaca-CoT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "instruction-tuning",
        "cot",
        "peft"
      ],
      "id": 461
    },
    {
      "name": "tabpfn-time-series",
      "one_line_profile": "Zero-shot time series forecasting with TabPFN",
      "detailed_description": "An extension of TabPFN specifically designed for zero-shot time series forecasting, enabling high-quality predictions without task-specific training.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "time_series_forecasting",
        "zero_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/PriorLabs/tabpfn-time-series",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "time-series",
        "forecasting",
        "tabpfn"
      ],
      "id": 462
    },
    {
      "name": "AdaLoRA",
      "one_line_profile": "Adaptive budget allocation for PEFT",
      "detailed_description": "The official implementation of AdaLoRA, a parameter-efficient fine-tuning method that adaptively allocates parameter budgets based on importance.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "model_compression"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/QingruZhang/AdaLoRA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "lora",
        "adaptive-tuning"
      ],
      "id": 463
    },
    {
      "name": "RLHF-V",
      "one_line_profile": "Behavior alignment for multimodal LLMs via RLHF",
      "detailed_description": "A tool for aligning Multimodal Large Language Models (MLLMs) using fine-grained correctional human feedback to improve trustworthiness and reduce hallucinations.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "multimodal_alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RLHF-V/RLHF-V",
      "help_website": [],
      "license": null,
      "tags": [
        "rlhf",
        "mllm",
        "alignment"
      ],
      "id": 464
    },
    {
      "name": "Directional-Preference-Alignment",
      "one_line_profile": "Directional preference alignment for LLMs",
      "detailed_description": "An implementation of Directional Preference Alignment, a method to align language models with user preferences by considering the direction of improvement.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/RLHFlow/Directional-Preference-Alignment",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dpo",
        "alignment",
        "preference-learning"
      ],
      "id": 465
    },
    {
      "name": "Online-DPO-R1",
      "one_line_profile": "Iterative DPO using rule-based rewards",
      "detailed_description": "A codebase for Online Direct Preference Optimization (DPO), facilitating iterative alignment of models using rule-based reward systems.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "dpo",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RLHFlow/Online-DPO-R1",
      "help_website": [],
      "license": null,
      "tags": [
        "online-dpo",
        "alignment",
        "iterative-training"
      ],
      "id": 466
    },
    {
      "name": "Online-RLHF",
      "one_line_profile": "A recipe and pipeline for online RLHF and online iterative DPO training",
      "detailed_description": "This repository provides a comprehensive recipe and implementation for Online Reinforcement Learning from Human Feedback (RLHF) and Online Iterative Direct Preference Optimization (DPO), enabling efficient alignment of Large Language Models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "dpo"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/RLHFlow/Online-RLHF",
      "help_website": [],
      "license": null,
      "tags": [
        "rlhf",
        "dpo",
        "alignment",
        "llm-training"
      ],
      "id": 467
    },
    {
      "name": "RLHF-Reward-Modeling",
      "one_line_profile": "Recipes and tools to train reward models for RLHF",
      "detailed_description": "A collection of recipes and scripts designed to train reward models, a critical component in the Reinforcement Learning from Human Feedback (RLHF) pipeline for aligning Large Language Models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "reward_modeling",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RLHFlow/RLHF-Reward-Modeling",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reward-model",
        "rlhf",
        "alignment"
      ],
      "id": 468
    },
    {
      "name": "APT",
      "one_line_profile": "Adaptive Pruning and Tuning for efficient Pretrained Language Models",
      "detailed_description": "Implementation of APT (Adaptive Pruning and Tuning), a method for efficient training and inference of Pretrained Language Models by dynamically pruning and tuning parameters.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "model_compression",
        "pruning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ROIM1998/APT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "pruning",
        "efficient-training"
      ],
      "id": 469
    },
    {
      "name": "gpu_poor",
      "one_line_profile": "Calculator for LLM token generation speed and GPU memory requirements",
      "detailed_description": "A utility tool to calculate expected token/s and GPU memory requirements for various Large Language Models, supporting different quantization methods like llama.cpp, ggml, bnb, and QLoRA.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "resource_estimation",
        "inference_planning"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/RahulSChand/gpu_poor",
      "help_website": [],
      "license": null,
      "tags": [
        "gpu-memory",
        "llm-calculator",
        "quantization"
      ],
      "id": 470
    },
    {
      "name": "ICEdit",
      "one_line_profile": "Efficient image editing using a single LoRA",
      "detailed_description": "A tool for fantastic image editing using only a single LoRA and minimal training data (0.1%), surpassing larger models in ID persistence and running on low VRAM.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "image_editing",
        "generation",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/River-Zhang/ICEdit",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "lora",
        "image-editing",
        "generative-ai"
      ],
      "id": 471
    },
    {
      "name": "CipherChat",
      "one_line_profile": "Framework to evaluate safety alignment generalization in LLMs",
      "detailed_description": "A framework designed to evaluate the generalization capability of safety alignment for Large Language Models, specifically testing robustness against cipher-based attacks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "safety_evaluation",
        "alignment_evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/RobustNLP/CipherChat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "safety",
        "alignment",
        "evaluation"
      ],
      "id": 472
    },
    {
      "name": "SPO",
      "one_line_profile": "Step-by-step Preference Optimization for diffusion models",
      "detailed_description": "Implementation of Step-by-step Preference Optimization (SPO) to align aesthetic post-training diffusion models with generic preferences.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization",
        "diffusion_models"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RockeyCoss/SPO",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dpo",
        "diffusion",
        "alignment"
      ],
      "id": 473
    },
    {
      "name": "S-LoRA",
      "one_line_profile": "Scalable serving system for concurrent LoRA adapters",
      "detailed_description": "A serving system designed to efficiently serve thousands of concurrent LoRA adapters, optimizing memory and throughput for multi-tenant LLM serving.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_serving",
        "peft_serving"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/S-LoRA/S-LoRA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lora",
        "serving",
        "inference"
      ],
      "id": 474
    },
    {
      "name": "ADHMR",
      "one_line_profile": "Aligning Diffusion-based Human Mesh Recovery via DPO",
      "detailed_description": "Official code for ADHMR, a method to align diffusion-based human mesh recovery models using Direct Preference Optimization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "human_mesh_recovery",
        "dpo"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SMPLCap/ADHMR",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "diffusion",
        "dpo",
        "human-mesh"
      ],
      "id": 475
    },
    {
      "name": "DiffusionDPO",
      "one_line_profile": "Direct Preference Optimization for Diffusion Model Alignment",
      "detailed_description": "Implementation of Direct Preference Optimization (DPO) specifically adapted for aligning diffusion models to human preferences.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "dpo",
        "diffusion_models"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SalesforceAIResearch/DiffusionDPO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dpo",
        "diffusion",
        "alignment"
      ],
      "id": 476
    },
    {
      "name": "TapeAgents",
      "one_line_profile": "Framework for LLM Agent development lifecycle",
      "detailed_description": "A framework that facilitates all stages of the Large Language Model (LLM) Agent development lifecycle, enabling the creation and management of intelligent agents.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "agent_development",
        "modeling"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/ServiceNow/TapeAgents",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-agent",
        "framework",
        "ai-agents"
      ],
      "id": 477
    },
    {
      "name": "DePT",
      "one_line_profile": "Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning",
      "detailed_description": "Implementation of DePT (Decomposed Prompt Tuning), a parameter-efficient fine-tuning method for large language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "prompt_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ShiZhengyan/DePT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "prompt-tuning",
        "llm"
      ],
      "id": 478
    },
    {
      "name": "SparseAdapter",
      "one_line_profile": "Sparse Adapter for Parameter-Efficient Fine-Tuning",
      "detailed_description": "Source code for SparseAdapter, an approach to improve the parameter efficiency of adapters in fine-tuning pre-trained language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "adapter_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Shwai-He/SparseAdapter",
      "help_website": [],
      "license": null,
      "tags": [
        "peft",
        "adapter",
        "sparse-tuning"
      ],
      "id": 479
    },
    {
      "name": "Simplifine",
      "one_line_profile": "Easy open-source LLM finetuning tool",
      "detailed_description": "A user-friendly tool for LLM fine-tuning offering one-line commands, cloud integration, and support for popular optimization frameworks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Simplifine-gamedev/Simplifine",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "fine-tuning",
        "llm",
        "simplification"
      ],
      "id": 480
    },
    {
      "name": "DRPO",
      "one_line_profile": "Dynamic Rewarding with Prompt Optimization for self-alignment",
      "detailed_description": "Implementation of DRPO (Dynamic Rewarding with Prompt Optimization), a tuning-free approach for self-alignment of LLMs using search-based optimization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "prompt_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Singla17/dynamic-alignment-optimization",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "prompt-optimization",
        "self-improvement"
      ],
      "id": 481
    },
    {
      "name": "SwanLab",
      "one_line_profile": "AI training tracking and visualization tool",
      "detailed_description": "An open-source, modern AI training tracking and visualization tool that integrates with popular frameworks like PyTorch, Transformers, and LLaMA Factory to monitor experiments.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "experiment_tracking",
        "visualization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/SwanHubX/SwanLab",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "experiment-tracking",
        "visualization",
        "mlops"
      ],
      "id": 482
    },
    {
      "name": "LongAlign",
      "one_line_profile": "Recipe for Long Context Alignment of LLMs",
      "detailed_description": "A comprehensive recipe and toolset for aligning Large Language Models to handle long contexts effectively, including data processing and training strategies.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "long_context"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/THUDM/LongAlign",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "long-context",
        "llm"
      ],
      "id": 483
    },
    {
      "name": "P-tuning",
      "one_line_profile": "Method for prompt tuning language models",
      "detailed_description": "Implementation of P-tuning, a novel method to tune language models using continuous prompt embeddings, enabling GPT models to understand prompts better.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "prompt_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/THUDM/P-tuning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "prompt-tuning",
        "p-tuning"
      ],
      "id": 484
    },
    {
      "name": "P-tuning-v2",
      "one_line_profile": "Optimized deep prompt tuning strategy",
      "detailed_description": "An optimized deep prompt tuning strategy (P-tuning v2) that achieves comparable performance to fine-tuning across various scales and tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "prompt_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/THUDM/P-tuning-v2",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "peft",
        "prompt-tuning",
        "deep-tuning"
      ],
      "id": 485
    },
    {
      "name": "MoE-PEFT",
      "one_line_profile": "Efficient fine-tuning factory optimized for Mixture-of-Experts (MoE) models",
      "detailed_description": "A specialized framework designed for parameter-efficient fine-tuning (PEFT) of Mixture-of-Experts (MoE) large language models, supporting methods like LoRA and QLoRA specifically adapted for MoE architectures.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft",
        "moe_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TUDB-Labs/MoE-PEFT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "moe",
        "peft",
        "llm-training",
        "lora"
      ],
      "id": 486
    },
    {
      "name": "mLoRA",
      "one_line_profile": "High-efficiency factory for building and training multiple LoRA adapters",
      "detailed_description": "An efficient framework for fine-tuning Large Language Models (LLMs) using LoRA (Low-Rank Adaptation) and its variants. It supports training multiple adapters concurrently and is optimized for throughput and memory usage.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft",
        "adapter_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TUDB-Labs/mLoRA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lora",
        "multi-adapter",
        "fine-tuning",
        "llm"
      ],
      "id": 487
    },
    {
      "name": "PIXIU",
      "one_line_profile": "Comprehensive benchmark and instruction tuning suite for financial LLMs",
      "detailed_description": "An open-source resource featuring financial large language models (LLMs), instruction tuning datasets, and evaluation benchmarks designed to holistically assess the performance of financial AI models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "benchmarking",
        "instruction_tuning",
        "evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/The-FinAI/PIXIU",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "financial-llm",
        "benchmark",
        "instruction-tuning",
        "evaluation"
      ],
      "id": 488
    },
    {
      "name": "VL-RLHF",
      "one_line_profile": "RLHF infrastructure for fine-tuning Vision-Language Models",
      "detailed_description": "A specialized infrastructure and codebase for performing Reinforcement Learning from Human Feedback (RLHF) on Vision-Language Models (VLMs), facilitating alignment and optimization of multimodal AI.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "multimodal_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TideDra/VL-RLHF",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "vlm",
        "alignment",
        "multimodal"
      ],
      "id": 489
    },
    {
      "name": "Effective LLM Alignment",
      "one_line_profile": "Toolkit for efficient Large Language Model alignment",
      "detailed_description": "A toolkit designed to streamline the process of aligning Large Language Models (LLMs), likely providing implementations of various alignment algorithms and utilities for training pipelines.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/VikhrModels/effective_llm_alignment",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "llm",
        "toolkit"
      ],
      "id": 490
    },
    {
      "name": "SLAM-LLM",
      "one_line_profile": "Framework for speech, audio, and music processing using LLMs",
      "detailed_description": "A comprehensive framework leveraging Large Language Models for processing and understanding speech, language, audio, and music, enabling multimodal tasks and research.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "multimodal_processing",
        "audio_analysis",
        "speech_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/X-LANCE/SLAM-LLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "audio",
        "speech",
        "music",
        "llm",
        "multimodal"
      ],
      "id": 491
    },
    {
      "name": "grpo-flat",
      "one_line_profile": "Lightweight training tool for GRPO with low resource requirements",
      "detailed_description": "A training tool designed to facilitate GRPO (Generative Reward Policy Optimization) training with minimal dataset requirements and support for low-resource environments, including 8bit/4bit quantization and LoRA/QLoRA.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "fine_tuning",
        "quantization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/XU-YIJIE/grpo-flat",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "grpo",
        "low-resource",
        "quantization",
        "lora"
      ],
      "id": 492
    },
    {
      "name": "TRLO",
      "one_line_profile": "Efficient LiDAR Odometry with 3D dynamic object tracking",
      "detailed_description": "A LiDAR odometry system that integrates 3D dynamic object tracking and removal, providing a robust solution for simultaneous localization and mapping (SLAM) in dynamic environments.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "slam",
        "lidar_processing",
        "tracking"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/Yaepiii/TRLO",
      "help_website": [],
      "license": null,
      "tags": [
        "lidar",
        "odometry",
        "slam",
        "robotics"
      ],
      "id": 493
    },
    {
      "name": "YiVal",
      "one_line_profile": "Automatic prompt engineering and evaluation assistant for GenAI",
      "detailed_description": "A tool designed to automate the prompt engineering process, providing evaluation and optimization capabilities for Generative AI applications to improve model performance and alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "prompt_engineering",
        "evaluation",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/YiVal/YiVal",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prompt-engineering",
        "genai",
        "automation",
        "evaluation"
      ],
      "id": 494
    },
    {
      "name": "Adapters",
      "one_line_profile": "A unified library for parameter-efficient and modular transfer learning",
      "detailed_description": "Adapters is a library that integrates adapter modules into pre-trained language models, enabling efficient fine-tuning and modular transfer learning. It supports various PEFT methods and composition of adapters.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "transfer_learning",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/adapter-hub/adapters",
      "help_website": [
        "https://docs.adapterhub.ml/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "peft",
        "adapters",
        "transfer-learning",
        "nlp"
      ],
      "id": 495
    },
    {
      "name": "Firefly",
      "one_line_profile": "A WebGL interactive particle viewer for scientific data",
      "detailed_description": "Firefly is a browser-based interactive visualization tool designed for exploring particle-based scientific datasets, such as those from astronomical simulations.",
      "domains": [
        "Scientific Visualization"
      ],
      "subtask_category": [
        "visualization",
        "particle_viewing",
        "data_exploration"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ageller/Firefly",
      "help_website": [
        "http://ageller.github.io/Firefly/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "visualization",
        "astronomy",
        "webgl",
        "particles"
      ],
      "id": 496
    },
    {
      "name": "ROLL",
      "one_line_profile": "Efficient scaling library for Reinforcement Learning with Large Language Models",
      "detailed_description": "ROLL is a library designed to scale reinforcement learning with large language models (RLHF), focusing on efficiency and user-friendliness for aligning LLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "alignment",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/alibaba/ROLL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "llm",
        "alignment",
        "reinforcement-learning"
      ],
      "id": 497
    },
    {
      "name": "RewardBench",
      "one_line_profile": "Evaluation tool and benchmark for reward models",
      "detailed_description": "RewardBench is a toolkit and benchmark designed to evaluate the performance and capabilities of reward models used in RLHF pipelines.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking",
        "reward_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/reward-bench",
      "help_website": [
        "https://huggingface.co/spaces/allenai/reward-bench"
      ],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "rlhf",
        "reward-model",
        "benchmark"
      ],
      "id": 498
    },
    {
      "name": "SMASHED",
      "one_line_profile": "Toolkit for applying transformations to dataset samples in NLP pipelines",
      "detailed_description": "SMASHED is a data processing toolkit designed to handle tokenization, prompting, batching, and field extraction for NLP datasets, supporting various data sources.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "data_processing",
        "tokenization",
        "pipeline"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/smashed",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-processing",
        "nlp",
        "pipeline"
      ],
      "id": 499
    },
    {
      "name": "Aphrodite Engine",
      "one_line_profile": "Large-scale LLM inference engine",
      "detailed_description": "Aphrodite Engine is a high-performance inference engine for Large Language Models, designed to serve thousands of users with fast throughput and low latency.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "inference",
        "serving",
        "model_deployment"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/aphrodite-engine/aphrodite-engine",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "inference",
        "llm",
        "serving",
        "vllm"
      ],
      "id": 500
    },
    {
      "name": "Argilla",
      "one_line_profile": "Collaboration tool for data annotation and dataset management",
      "detailed_description": "Argilla is an open-source platform for data-centric AI, enabling collaboration between engineers and domain experts to label, validate, and refine datasets for LLM training and alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_annotation",
        "rlhf",
        "data_management",
        "quality_control"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/argilla-io/argilla",
      "help_website": [
        "https://docs.argilla.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-annotation",
        "rlhf",
        "dataset",
        "nlp"
      ],
      "id": 501
    },
    {
      "name": "Distilabel",
      "one_line_profile": "Framework for synthetic data generation and AI feedback",
      "detailed_description": "Distilabel is a framework designed to build scalable pipelines for generating synthetic data and collecting AI feedback, facilitating the creation of high-quality datasets for model training and alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "synthetic_data_generation",
        "ai_feedback",
        "alignment",
        "data_augmentation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/argilla-io/distilabel",
      "help_website": [
        "https://distilabel.argilla.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "synthetic-data",
        "rlhf",
        "dpo",
        "feedback"
      ],
      "id": 502
    },
    {
      "name": "Axolotl",
      "one_line_profile": "A comprehensive post-training framework for fine-tuning Large Language Models (LLMs)",
      "detailed_description": "Axolotl is a tool designed to streamline the fine-tuning of various AI models, offering support for multiple training methods including full fine-tuning, LoRA, QLoRA, and ReLoRA. It provides a unified configuration interface (YAML) to manage datasets, model architectures, and training hyperparameters, widely used in the open-source AI community for customizing models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "instruction_tuning",
        "peft"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/axolotl-ai-cloud/axolotl",
      "help_website": [
        "https://axolotl-ai-cloud.github.io/axolotl/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "fine-tuning",
        "lora",
        "qlora",
        "automation"
      ],
      "id": 503
    },
    {
      "name": "Curator",
      "one_line_profile": "Library for synthetic data curation and structured data extraction using LLMs",
      "detailed_description": "Curator is a Python library designed to automate the creation and curation of high-quality synthetic datasets for post-training and fine-tuning AI models. It leverages Large Language Models to generate, filter, and structure data, facilitating the data preparation phase of model alignment and instruction tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_curation",
        "synthetic_data_generation",
        "alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bespokelabsai/curator",
      "help_website": [
        "https://github.com/bespokelabsai/curator"
      ],
      "license": "Apache-2.0",
      "tags": [
        "synthetic-data",
        "data-curation",
        "llm",
        "alignment"
      ],
      "id": 504
    },
    {
      "name": "bitsandbytes",
      "one_line_profile": "Lightweight wrapper for CUDA custom functions focusing on 8-bit optimizers and quantization",
      "detailed_description": "bitsandbytes is a library that provides efficient CUDA implementations for 8-bit optimizers, matrix multiplication (LLM.int8()), and quantization functions. It is a critical dependency for QLoRA and other parameter-efficient fine-tuning methods, enabling the training of large language models on consumer-grade hardware.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "quantization",
        "optimization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bitsandbytes-foundation/bitsandbytes",
      "help_website": [
        "https://huggingface.co/docs/bitsandbytes/index"
      ],
      "license": "MIT",
      "tags": [
        "quantization",
        "cuda",
        "optimization",
        "qlora"
      ],
      "id": 505
    },
    {
      "name": "Prompt Poet",
      "one_line_profile": "Tool for designing and managing prompts for LLMs",
      "detailed_description": "Prompt Poet is a library that simplifies and streamlines the design of prompts for Large Language Models. It provides a low-code approach to constructing complex prompt contexts, managing templates, and integrating dynamic data, which is essential for instruction tuning and in-context learning workflows.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "prompt_engineering",
        "instruction_tuning",
        "context_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/character-ai/prompt-poet",
      "help_website": [
        "https://github.com/character-ai/prompt-poet"
      ],
      "license": "MIT",
      "tags": [
        "prompt-engineering",
        "llm",
        "templating",
        "low-code"
      ],
      "id": 506
    },
    {
      "name": "LoRA (cloneofsimo)",
      "one_line_profile": "Implementation of Low-rank adaptation for fine-tuning diffusion models",
      "detailed_description": "This repository provides a widely used implementation of Low-Rank Adaptation (LoRA) specifically tailored for fine-tuning diffusion models. It allows for parameter-efficient adaptation of large generative models, enabling users to train models on new concepts or styles with significantly reduced computational resources.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "fine_tuning",
        "diffusion_models"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/cloneofsimo/lora",
      "help_website": [
        "https://github.com/cloneofsimo/lora"
      ],
      "license": "Apache-2.0",
      "tags": [
        "lora",
        "stable-diffusion",
        "peft",
        "fine-tuning"
      ],
      "id": 507
    },
    {
      "name": "Fluxgym",
      "one_line_profile": "Simple UI for training FLUX LoRA models with low VRAM support",
      "detailed_description": "A lightweight user interface designed to simplify the training of LoRA (Low-Rank Adaptation) models for the FLUX image generation architecture. It lowers the barrier for fine-tuning foundation models by providing a streamlined workflow that supports low VRAM environments, making it accessible for researchers and developers working on generative model adaptation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "fine_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/cocktailpeanut/fluxgym",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lora",
        "flux",
        "fine-tuning",
        "ui",
        "generative-ai"
      ],
      "id": 508
    },
    {
      "name": "PEFT-SAM",
      "one_line_profile": "Parameter Efficient Fine-Tuning for Segment Anything Model (SAM)",
      "detailed_description": "A specialized library for applying Parameter Efficient Fine-Tuning (PEFT) techniques to the Segment Anything Model (SAM), specifically tailored for computational cell analytics and biological image segmentation tasks. It enables the adaptation of the powerful SAM foundation model to specific scientific domains with limited data and computational resources.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "image_segmentation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/computational-cell-analytics/peft-sam",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sam",
        "peft",
        "bioimaging",
        "segmentation",
        "fine-tuning"
      ],
      "id": 509
    },
    {
      "name": "LaMDA-rlhf-pytorch",
      "one_line_profile": "PyTorch implementation of LaMDA with RLHF alignment",
      "detailed_description": "An open-source implementation of Google's LaMDA architecture in PyTorch, incorporating Reinforcement Learning from Human Feedback (RLHF) for model alignment. It serves as a research framework for studying and developing large language models and alignment techniques similar to those used in ChatGPT.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/conceptofmind/LaMDA-rlhf-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rlhf",
        "lamda",
        "alignment",
        "llm",
        "pytorch"
      ],
      "id": 510
    },
    {
      "name": "ViT-Adapter",
      "one_line_profile": "Vision Transformer Adapter for dense prediction tasks",
      "detailed_description": "A framework that adapts plain Vision Transformers (ViT) for dense prediction tasks such as object detection and semantic segmentation. It introduces an adapter mechanism that injects inductive biases into the ViT architecture, enabling efficient fine-tuning and improved performance on downstream vision tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "dense_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/czczup/ViT-Adapter",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "vision-transformer",
        "adapter",
        "peft",
        "object-detection",
        "segmentation"
      ],
      "id": 511
    },
    {
      "name": "DataDreamer",
      "one_line_profile": "Library for synthetic data generation and model alignment",
      "detailed_description": "A comprehensive library for prompting, generating synthetic data, and training/aligning Large Language Models (LLMs). It automates the workflow of creating high-quality datasets from LLMs and using them to fine-tune or align models, facilitating research in data-centric AI and model adaptation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_generation",
        "alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/datadreamer-dev/DataDreamer",
      "help_website": [
        "https://datadreamer.dev"
      ],
      "license": "MIT",
      "tags": [
        "synthetic-data",
        "alignment",
        "llm",
        "fine-tuning",
        "prompt-engineering"
      ],
      "id": 512
    },
    {
      "name": "Data-Juicer",
      "one_line_profile": "Data processing system for foundation models",
      "detailed_description": "A robust data processing system designed for Large Language Models (LLMs). It provides a wide range of operators for data filtering, cleaning, deduplication, and formatting, ensuring high-quality data input for pre-training and fine-tuning foundation models.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "data_processing",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/datajuicer/data-juicer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-processing",
        "llm",
        "etl",
        "data-cleaning",
        "foundation-models"
      ],
      "id": 513
    },
    {
      "name": "EPOSearch",
      "one_line_profile": "Solver for preference-based multi-objective optimization",
      "detailed_description": "A Python library implementing the Exact Pareto Optimal Search algorithm for preference-based Multi-Objective Optimization (MOO). It is designed to find solutions that align with user preferences in complex optimization landscapes, applicable in scientific modeling and decision-making processes.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "optimization",
        "scientific_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dbmptr/EPOSearch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "optimization",
        "multi-objective",
        "pareto",
        "preference-learning"
      ],
      "id": 514
    },
    {
      "name": "Instruct-Eval",
      "one_line_profile": "Evaluation suite for instruction-tuned models",
      "detailed_description": "A framework for quantitatively evaluating instruction-tuned Large Language Models (LLMs) such as Alpaca and Flan-T5. It provides a standardized set of tasks and metrics to assess the performance of models on held-out instructions, facilitating the comparison and validation of alignment techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/declare-lab/instruct-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "instruction-tuning",
        "llm",
        "benchmarking"
      ],
      "id": 515
    },
    {
      "name": "LoRA Easy Training Scripts",
      "one_line_profile": "GUI and scripts for training LoRA/LoCon models",
      "detailed_description": "A user interface and collection of scripts designed to simplify the training of LoRA (Low-Rank Adaptation) and LoCon models using `sd-scripts`. It provides an accessible workflow for fine-tuning generative models, managing configuration, and executing training jobs without deep command-line expertise.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_training"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/derrian-distro/LoRA_Easy_Training_Scripts",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "lora",
        "gui",
        "fine-tuning",
        "stable-diffusion",
        "training-scripts"
      ],
      "id": 516
    },
    {
      "name": "ControlNeXt",
      "one_line_profile": "Library for controllable image and video generation",
      "detailed_description": "A comprehensive library for controllable generation in image and video models. It implements advanced techniques like ControlNet and ControlNeXt, allowing for precise spatial and temporal control over the generation process, which is essential for scientific visualization and synthetic data generation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "generation",
        "control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dvlab-research/ControlNeXt",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "controlnet",
        "generation",
        "video-generation",
        "lora",
        "controllable-ai"
      ],
      "id": 517
    },
    {
      "name": "LongLoRA",
      "one_line_profile": "Efficient fine-tuning for long-context LLMs",
      "detailed_description": "A tool and method for extending the context window of Large Language Models (LLMs) through efficient fine-tuning. It utilizes shifted sparse attention (S2-Attn) to enable training on long sequences with reduced computational overhead, facilitating the processing of long scientific texts and data sequences.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "context_extension"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dvlab-research/LongLoRA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "long-context",
        "lora",
        "fine-tuning",
        "llm",
        "efficiency"
      ],
      "id": 518
    },
    {
      "name": "TuneAI",
      "one_line_profile": "Automation tool for OpenAI model fine-tuning",
      "detailed_description": "A utility tool that automates the process of fine-tuning OpenAI models. It handles transcript cleaning, prompt-completion pair generation, and dataset preparation, streamlining the workflow for creating custom models from raw text or video inputs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_preparation",
        "fine_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/emmethalm/tuneAI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "openai",
        "fine-tuning",
        "automation",
        "dataset-creation"
      ],
      "id": 519
    },
    {
      "name": "DPO (Direct Preference Optimization)",
      "one_line_profile": "Reference implementation of Direct Preference Optimization for LLM alignment",
      "detailed_description": "The official reference implementation for Direct Preference Optimization (DPO), a stable and computationally lightweight alternative to RLHF for aligning language models with human preferences. It provides the core loss functions and training loops required to fine-tune models directly on preference data.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization",
        "rlhf_alternative"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/eric-mitchell/direct-preference-optimization",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dpo",
        "alignment",
        "llm",
        "preference-learning"
      ],
      "id": 520
    },
    {
      "name": "GAST-Net",
      "one_line_profile": "Graph Attention Spatio-temporal Convolutional Networks for 3D Human Pose Estimation",
      "detailed_description": "A deep learning framework for 3D human pose estimation in video. It utilizes Graph Attention Spatio-temporal Convolutional Networks (GAST-Net) to model the spatial and temporal dependencies of human joints, serving as a solver for computer vision tasks related to human dynamics.",
      "domains": [
        "Computer Vision",
        "AI3"
      ],
      "subtask_category": [
        "pose_estimation",
        "3d_reconstruction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/fabro66/GAST-Net-3DPoseEstimation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pose-estimation",
        "computer-vision",
        "graph-neural-networks"
      ],
      "id": 521
    },
    {
      "name": "SecAlign",
      "one_line_profile": "Safety alignment framework defending against prompt injection via preference optimization",
      "detailed_description": "A research tool from Facebook Research that implements safety alignment techniques to defend Large Language Models (LLMs) against prompt injection attacks. It utilizes preference optimization methods to enhance model robustness.",
      "domains": [
        "AI3",
        "AI3-02",
        "AI Safety"
      ],
      "subtask_category": [
        "safety_alignment",
        "defense",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/SecAlign",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "safety",
        "alignment",
        "prompt-injection",
        "llm"
      ],
      "id": 522
    },
    {
      "name": "C3DPO",
      "one_line_profile": "Canonical 3D Pose Networks for Non-rigid Structure From Motion",
      "detailed_description": "A computer vision tool for Non-rigid Structure From Motion (NRSfM). It implements Canonical 3D Pose Networks to reconstruct 3D shape and motion from 2D landmarks, serving as a solver for 3D geometric reconstruction tasks.",
      "domains": [
        "Computer Vision",
        "AI3"
      ],
      "subtask_category": [
        "structure_from_motion",
        "3d_reconstruction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/c3dpo_nrsfm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nrsfm",
        "3d-reconstruction",
        "computer-vision"
      ],
      "id": 523
    },
    {
      "name": "trlib",
      "one_line_profile": "Library for solving trust region subproblems in optimization",
      "detailed_description": "A C library dedicated to solving the trust region subproblem, a core component in many nonlinear optimization algorithms. It is used in scientific computing for numerical optimization tasks.",
      "domains": [
        "Mathematics",
        "Scientific Computing"
      ],
      "subtask_category": [
        "optimization",
        "numerical_solver"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/felixlen/trlib",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "optimization",
        "trust-region",
        "numerical-methods"
      ],
      "id": 524
    },
    {
      "name": "finetune-whisper-lora",
      "one_line_profile": "Workflow for fine-tuning Whisper models using LoRA and PEFT",
      "detailed_description": "A specialized tool for fine-tuning OpenAI's Whisper speech recognition models using Low-Rank Adaptation (LoRA) and Parameter-Efficient Fine-Tuning (PEFT) techniques. It enables efficient adaptation of ASR models on consumer hardware.",
      "domains": [
        "AI3",
        "AI3-02",
        "Audio"
      ],
      "subtask_category": [
        "speech_recognition",
        "fine_tuning",
        "peft"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/fengredrum/finetune-whisper-lora",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "whisper",
        "lora",
        "peft",
        "asr"
      ],
      "id": 525
    },
    {
      "name": "CoPEFT",
      "one_line_profile": "Parameter-efficient fine-tuning framework for multi-agent collaborative perception",
      "detailed_description": "An implementation of the CoPEFT framework (AAAI 2025) designed for fast adaptation in multi-agent collaborative perception tasks. It applies parameter-efficient fine-tuning strategies to optimize communication and perception in multi-agent systems.",
      "domains": [
        "AI3",
        "AI3-02",
        "Robotics"
      ],
      "subtask_category": [
        "multi_agent_perception",
        "fine_tuning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/fengxueguiren/CoPEFT",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "multi-agent",
        "perception",
        "peft",
        "aaai-2025"
      ],
      "id": 526
    },
    {
      "name": "Atlas",
      "one_line_profile": "Method for knowledge composition using task vectors with learned anisotropic scaling",
      "detailed_description": "The official implementation of the Atlas method (NeurIPS 2024) for composing knowledge from different models using task vectors. It provides a solver for merging model capabilities through learned anisotropic scaling.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_merging",
        "task_vectors",
        "knowledge_composition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/fredzzhang/atlas",
      "help_website": [],
      "license": null,
      "tags": [
        "model-merging",
        "neurips-2024",
        "task-vectors"
      ],
      "id": 527
    },
    {
      "name": "General Preference Model",
      "one_line_profile": "General preference model for language model alignment beyond Bradley-Terry",
      "detailed_description": "Implementation of a general preference model (ICML 2025) for LLM alignment that extends beyond the standard Bradley-Terry model. It serves as a solver for more complex preference learning scenarios in model alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_modeling",
        "rlhf"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/general-preference/general-preference-model",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "preference-model",
        "icml-2025"
      ],
      "id": 528
    },
    {
      "name": "llm_qlora",
      "one_line_profile": "Workflow scripts for fine-tuning LLMs using QLoRA",
      "detailed_description": "A widely used collection of scripts and workflows for fine-tuning Large Language Models using Quantized LoRA (QLoRA). It facilitates the efficient adaptation of LLMs on consumer-grade GPUs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "qlora",
        "peft"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/georgesung/llm_qlora",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "qlora",
        "fine-tuning",
        "llm"
      ],
      "id": 529
    },
    {
      "name": "LLM-Finetuning-Toolkit",
      "one_line_profile": "Toolkit for fine-tuning, ablating, and testing open-source LLMs",
      "detailed_description": "A comprehensive toolkit developed by Georgian for fine-tuning, ablation studies, and unit testing of open-source Large Language Models. It provides a structured workflow for adapting LLMs to specific domains.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_evaluation",
        "ablation_study"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/georgian-io/LLM-Finetuning-Toolkit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fine-tuning",
        "llm",
        "toolkit"
      ],
      "id": 530
    },
    {
      "name": "UDS",
      "one_line_profile": "Utility-Diversity Aware Online Batch Selection for LLM SFT",
      "detailed_description": "Implementation of the UDS algorithm for online batch selection during Supervised Fine-Tuning (SFT) of LLMs. It acts as a solver to optimize data efficiency by balancing utility and diversity in training batches.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_selection",
        "sft",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gfyddha/UDS",
      "help_website": [],
      "license": null,
      "tags": [
        "data-selection",
        "sft",
        "llm"
      ],
      "id": 531
    },
    {
      "name": "SelectiveDPO",
      "one_line_profile": "Principled data selection method for DPO alignment",
      "detailed_description": "A tool implementing a principled data selection strategy for Direct Preference Optimization (DPO). It helps in identifying and filtering difficult or noisy examples to improve the stability and performance of model alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_selection",
        "alignment",
        "dpo"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/glorgao/SelectiveDPO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-selection",
        "dpo",
        "alignment"
      ],
      "id": 532
    },
    {
      "name": "prompt-tuning",
      "one_line_profile": "Original implementation of Prompt Tuning for parameter-efficient adaptation",
      "detailed_description": "The original implementation of 'The Power of Scale for Parameter-Efficient Prompt Tuning' by Google Research. It provides the solver and methodology for adapting large pre-trained models using soft prompts, a key PEFT technique.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "prompt_tuning",
        "model_adaptation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/google-research/prompt-tuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prompt-tuning",
        "peft",
        "google-research"
      ],
      "id": 533
    },
    {
      "name": "LLaVA",
      "one_line_profile": "Visual Instruction Tuning framework for large multimodal models",
      "detailed_description": "The official repository for LLaVA (Large Language-and-Vision Assistant), providing the codebase for visual instruction tuning. It serves as a platform for training and evaluating multimodal models that connect vision encoders with LLMs.",
      "domains": [
        "AI3",
        "AI3-02",
        "Computer Vision"
      ],
      "subtask_category": [
        "visual_instruction_tuning",
        "multimodal_training",
        "vlm"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/haotian-liu/LLaVA",
      "help_website": [
        "https://llava-vl.github.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vlm",
        "multimodal",
        "instruction-tuning",
        "llava"
      ],
      "id": 534
    },
    {
      "name": "ChatGLM-Efficient-Tuning",
      "one_line_profile": "Efficient fine-tuning framework for ChatGLM models based on PEFT",
      "detailed_description": "A comprehensive framework for fine-tuning ChatGLM-6B and related models using PEFT techniques (LoRA, P-Tuning, etc.). It is the predecessor to LLaMA-Factory and serves as a workflow tool for adapting ChatGLM models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft",
        "chatglm"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/hiyouga/ChatGLM-Efficient-Tuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "chatglm",
        "peft",
        "fine-tuning"
      ],
      "id": 535
    },
    {
      "name": "LLaMA-Factory",
      "one_line_profile": "Unified efficient fine-tuning platform for 100+ LLMs and VLMs",
      "detailed_description": "A widely adopted platform for the efficient fine-tuning of over 100 large language and vision-language models. It integrates various PEFT methods, training strategies (SFT, RLHF, DPO), and provides a web UI and CLI for the entire model adaptation lifecycle.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft",
        "rlhf",
        "dpo",
        "training_platform"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/hiyouga/LLaMA-Factory",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fine-tuning",
        "llm",
        "peft",
        "rlhf",
        "gui"
      ],
      "id": 536
    },
    {
      "name": "visual_prompting",
      "one_line_profile": "Visual prompting methods for adapting large-scale vision models",
      "detailed_description": "Research code implementing visual prompting techniques to adapt large-scale pre-trained vision models to downstream tasks without fine-tuning the model weights. It serves as a solver for pixel-level PEFT in computer vision.",
      "domains": [
        "Computer Vision",
        "AI3-02"
      ],
      "subtask_category": [
        "visual_prompting",
        "model_adaptation",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hjbahng/visual_prompting",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visual-prompting",
        "adaptation",
        "computer-vision"
      ],
      "id": 537
    },
    {
      "name": "Deita",
      "one_line_profile": "Data-Efficient Instruction Tuning for Alignment",
      "detailed_description": "A tool for selecting high-quality instruction tuning data to align Large Language Models efficiently. It implements the Deita approach (ICLR 2024) to automatically filter and select data samples that maximize alignment performance.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_selection",
        "instruction_tuning",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hkust-nlp/deita",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-selection",
        "instruction-tuning",
        "alignment"
      ],
      "id": 538
    },
    {
      "name": "IR-QLoRA",
      "one_line_profile": "Accurate LoRA-Finetuning Quantization via Information Retention",
      "detailed_description": "Implementation of IR-QLoRA (ICML 2024), a method for accurate quantization of LLMs during LoRA fine-tuning. It serves as a solver for creating high-performance quantized models with parameter-efficient fine-tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "quantization",
        "peft",
        "qlora"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/htqin/IR-QLoRA",
      "help_website": [],
      "license": null,
      "tags": [
        "quantization",
        "lora",
        "peft",
        "icml-2024"
      ],
      "id": 539
    },
    {
      "name": "Alignment Handbook",
      "one_line_profile": "Recipes and workflows for aligning language models with human preferences",
      "detailed_description": "A collection of robust recipes and scripts from Hugging Face for aligning language models using methods like DPO, IPO, and KTO. It serves as a standard workflow reference for the community to perform model alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "dpo",
        "workflow_recipes"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/alignment-handbook",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "huggingface",
        "recipes",
        "dpo"
      ],
      "id": 540
    },
    {
      "name": "Optimum Benchmark",
      "one_line_profile": "Unified multi-backend benchmarking utility for Transformers and PEFT",
      "detailed_description": "A utility tool for benchmarking the performance of Transformers, PEFT, and other models across different backends and hardware. It supports measuring latency, throughput, and memory usage, essential for optimizing scientific model inference and training.",
      "domains": [
        "AI3",
        "AI3-02",
        "HPC"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_analysis",
        "optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/optimum-benchmark",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmarking",
        "optimization",
        "transformers"
      ],
      "id": 541
    },
    {
      "name": "PEFT",
      "one_line_profile": "State-of-the-art Parameter-Efficient Fine-Tuning (PEFT) library for adapting large pre-trained models",
      "detailed_description": "A library that enables efficient adaptation of pre-trained language models to various downstream applications without fine-tuning all the model's parameters. It supports methods like LoRA, Prefix Tuning, P-Tuning, and Prompt Tuning, significantly reducing computational and storage costs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "parameter_efficiency",
        "model_adaptation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/peft",
      "help_website": [
        "https://huggingface.co/docs/peft"
      ],
      "license": "Apache-2.0",
      "tags": [
        "lora",
        "qlora",
        "fine-tuning",
        "llm"
      ],
      "id": 542
    },
    {
      "name": "TRL",
      "one_line_profile": "Transformer Reinforcement Learning library for training and aligning language models",
      "detailed_description": "A full-stack library for training transformer language models with Reinforcement Learning (RL). It supports the entire pipeline from Supervised Fine-Tuning (SFT), Reward Modeling (RM), to Proximal Policy Optimization (PPO) and Direct Preference Optimization (DPO) for model alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "dpo",
        "ppo",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/trl",
      "help_website": [
        "https://huggingface.co/docs/trl"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "alignment",
        "ppo",
        "dpo"
      ],
      "id": 543
    },
    {
      "name": "LLamaTuner",
      "one_line_profile": "GUI and CLI tool for efficient fine-tuning and quantization of Large Language Models",
      "detailed_description": "A comprehensive tool designed to simplify the fine-tuning and quantization of various Large Language Models (LLMs) such as Llama, Qwen, and Baichuan. It provides both a graphical user interface and command-line tools to facilitate parameter-efficient fine-tuning (PEFT) and model deployment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "quantization",
        "workflow_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jianzhnie/LLamaTuner",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gui",
        "fine-tuning",
        "quantization",
        "llm"
      ],
      "id": 544
    },
    {
      "name": "MoRA",
      "one_line_profile": "High-rank updating method for parameter-efficient fine-tuning (PEFT)",
      "detailed_description": "An implementation of MoRA, a PEFT method that employs a square matrix for high-rank updating to achieve parameter efficiency while maintaining high capacity, serving as an alternative to LoRA.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kongds/MoRA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "peft",
        "fine-tuning",
        "llm"
      ],
      "id": 545
    },
    {
      "name": "CM3Leon",
      "one_line_profile": "Open source implementation of the CM3Leon multimodal model",
      "detailed_description": "An implementation of the CM3Leon architecture, an autoregressive multi-modal model capable of generating both text and images, facilitating research in multi-modal pretraining and instruction tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "multimodal_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kyegomez/CM3Leon",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multimodal",
        "transformer",
        "generative-ai"
      ],
      "id": 546
    },
    {
      "name": "Finetuning-Suite",
      "one_line_profile": "Streamlined suite for fine-tuning Hugging Face models",
      "detailed_description": "A tool designed to simplify and accelerate the fine-tuning process for various models available on Hugging Face, providing a quick setup for model adaptation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_adaptation"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/kyegomez/Finetuning-Suite",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fine-tuning",
        "huggingface",
        "productivity"
      ],
      "id": 547
    },
    {
      "name": "swarms-pytorch",
      "one_line_profile": "PyTorch implementation of swarm intelligence algorithms",
      "detailed_description": "A library implementing various swarm intelligence algorithms such as Particle Swarm Optimization (PSO) and Ant Colony Optimization in PyTorch, useful for scientific optimization tasks.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "optimization",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kyegomez/swarms-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "optimization",
        "swarm-intelligence",
        "pytorch"
      ],
      "id": 548
    },
    {
      "name": "tree-of-thoughts",
      "one_line_profile": "Framework for Tree of Thoughts reasoning in LLMs",
      "detailed_description": "An implementation of the Tree of Thoughts (ToT) framework, enabling large language models to perform deliberate problem solving and enhanced reasoning by exploring multiple thought paths.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "inference",
        "reasoning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kyegomez/tree-of-thoughts",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reasoning",
        "llm",
        "inference-optimization"
      ],
      "id": 549
    },
    {
      "name": "PRefLexOR",
      "one_line_profile": "Preference-based recursive language modeling for reasoning optimization",
      "detailed_description": "A framework for exploratory optimization of reasoning capabilities in language models using preference-based recursive modeling, useful for enhancing model performance on complex tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "optimization",
        "reasoning",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/lamm-mit/PRefLexOR",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reasoning",
        "preference-learning",
        "llm"
      ],
      "id": 550
    },
    {
      "name": "VB-LoRA",
      "one_line_profile": "Extreme parameter-efficient fine-tuning using Vector Banks",
      "detailed_description": "An implementation of VB-LoRA, a method for parameter-efficient fine-tuning that utilizes vector banks to further reduce trainable parameters compared to standard LoRA.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/leo-yangli/VB-LoRA",
      "help_website": [],
      "license": null,
      "tags": [
        "peft",
        "lora",
        "efficiency"
      ],
      "id": 551
    },
    {
      "name": "flash-preference",
      "one_line_profile": "Accelerated LLM preference tuning via prefix sharing",
      "detailed_description": "A library to accelerate preference tuning (alignment) of Large Language Models by implementing efficient prefix sharing mechanisms.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/li-plus/flash-preference",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "alignment",
        "preference-tuning",
        "acceleration"
      ],
      "id": 552
    },
    {
      "name": "prompt-optimizer",
      "one_line_profile": "Tool for optimizing prompts to improve LLM outputs",
      "detailed_description": "A tool designed to assist in writing and optimizing high-quality prompts, which is a critical part of the workflow for aligning and utilizing Large Language Models effectively.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "prompt_engineering",
        "alignment"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/linshenkx/prompt-optimizer",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "prompt-engineering",
        "optimization",
        "llm"
      ],
      "id": 553
    },
    {
      "name": "ChatGLM-Finetuning",
      "one_line_profile": "Comprehensive fine-tuning workflow for ChatGLM models",
      "detailed_description": "A widely used collection of scripts and workflows for fine-tuning ChatGLM series models, supporting various methods like Freeze, LoRA, P-tuning, and full parameter fine-tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/liucongg/ChatGLM-Finetuning",
      "help_website": [],
      "license": null,
      "tags": [
        "chatglm",
        "fine-tuning",
        "lora"
      ],
      "id": 554
    },
    {
      "name": "MOELoRA-peft",
      "one_line_profile": "Mixture-of-Experts based LoRA for PEFT",
      "detailed_description": "Implementation of MOELoRA, a parameter-efficient fine-tuning method that combines Mixture of Experts (MoE) with LoRA to enhance model adaptation capabilities.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liuqidong07/MOELoRA-peft",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "moe",
        "lora"
      ],
      "id": 555
    },
    {
      "name": "LLaVA-RLHF",
      "one_line_profile": "Factually augmented RLHF for aligning Large Multimodal Models",
      "detailed_description": "A tool/framework for aligning Large Multimodal Models (LMMs) using Reinforcement Learning with Human Feedback (RLHF), specifically focusing on reducing hallucinations and improving factual alignment.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "multimodal"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/llava-rlhf/LLaVA-RLHF",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "rlhf",
        "multimodal",
        "alignment"
      ],
      "id": 556
    },
    {
      "name": "PSEC",
      "one_line_profile": "Framework for skill expansion and composition in parameter space",
      "detailed_description": "Implementation of PSEC, a framework designed to facilitate efficient and flexible skill expansion and composition for agents by operating in the parameter space.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_adaptation",
        "skill_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ltlhuuu/PSEC",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "skill-expansion",
        "parameter-space",
        "agents"
      ],
      "id": 557
    },
    {
      "name": "trlda",
      "one_line_profile": "Online inference algorithms for Latent Dirichlet Allocation (LDA)",
      "detailed_description": "A C++ library with Python bindings providing implementations of various online inference algorithms for Latent Dirichlet Allocation, useful for statistical topic modeling.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "statistical_inference",
        "topic_modeling"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/lucastheis/trlda",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lda",
        "topic-modeling",
        "inference"
      ],
      "id": 558
    },
    {
      "name": "DiscoPOP",
      "one_line_profile": "Algorithm for discovering preference optimization methods",
      "detailed_description": "Code and framework for discovering new preference optimization algorithms for Large Language Models, enabling the development of better alignment techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "preference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/luchris429/DiscoPOP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "alignment",
        "preference-optimization",
        "llm"
      ],
      "id": 559
    },
    {
      "name": "PaLM-rlhf-pytorch",
      "one_line_profile": "PyTorch implementation of RLHF for PaLM architecture",
      "detailed_description": "A complete implementation of Reinforcement Learning with Human Feedback (RLHF) on top of the PaLM architecture, serving as a reference library for training aligned LLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucidrains/PaLM-rlhf-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rlhf",
        "palm",
        "pytorch"
      ],
      "id": 560
    },
    {
      "name": "mDPO",
      "one_line_profile": "Conditional Preference Optimization for Multimodal LLMs",
      "detailed_description": "Implementation of mDPO, a method for aligning Multimodal Large Language Models using conditional preference optimization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "multimodal",
        "dpo"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/luka-group/mDPO",
      "help_website": [],
      "license": null,
      "tags": [
        "dpo",
        "multimodal",
        "alignment"
      ],
      "id": 561
    },
    {
      "name": "RobustFT",
      "one_line_profile": "Robust Supervised Fine-tuning for LLMs under noisy response",
      "detailed_description": "A method and tool for performing robust supervised fine-tuning of Large Language Models, specifically designed to handle noisy training data effectively.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "robustness"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/luo-junyu/RobustFT",
      "help_website": [],
      "license": null,
      "tags": [
        "fine-tuning",
        "robustness",
        "noise-handling"
      ],
      "id": 562
    },
    {
      "name": "SemiEvol",
      "one_line_profile": "Semi-supervised Fine-tuning for LLM Adaptation",
      "detailed_description": "A framework for semi-supervised fine-tuning, enabling the adaptation of Large Language Models using both labeled and unlabeled data.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "semi_supervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/luo-junyu/SemiEvol",
      "help_website": [],
      "license": null,
      "tags": [
        "fine-tuning",
        "semi-supervised",
        "adaptation"
      ],
      "id": 563
    },
    {
      "name": "LaVIN",
      "one_line_profile": "Efficient Vision-Language Instruction Tuning",
      "detailed_description": "Implementation of LaVIN, a method for cheap and quick vision-language instruction tuning for Large Language Models, facilitating efficient multimodal adaptation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "multimodal"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/luogen1996/LaVIN",
      "help_website": [],
      "license": null,
      "tags": [
        "instruction-tuning",
        "multimodal",
        "efficiency"
      ],
      "id": 564
    },
    {
      "name": "LangCode",
      "one_line_profile": "Improving alignment and reasoning with natural language embedded programs",
      "detailed_description": "A tool/method for improving the alignment and reasoning capabilities of LLMs by utilizing natural language embedded programs (NLEP).",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/luohongyin/LangCode",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "alignment",
        "reasoning",
        "code-generation"
      ],
      "id": 565
    },
    {
      "name": "simple-llm-finetuner",
      "one_line_profile": "Simple UI for LLM Model Finetuning",
      "detailed_description": "A user-friendly interface and workflow tool for fine-tuning Large Language Models, designed to make the process accessible without deep coding requirements.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_training"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/lxe/simple-llm-finetuner",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ui",
        "fine-tuning",
        "low-code"
      ],
      "id": 566
    },
    {
      "name": "AirLLM",
      "one_line_profile": "Memory-efficient inference for large models on consumer GPUs",
      "detailed_description": "A library enabling the inference of very large language models (e.g., 70B) on hardware with limited memory (e.g., single 4GB GPU) through layered execution and optimization.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "inference",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/lyogavin/airllm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "memory-optimization",
        "consumer-hardware"
      ],
      "id": 567
    },
    {
      "name": "memprompt",
      "one_line_profile": "Method to fix LLMs after deployment with user feedback",
      "detailed_description": "A tool implementing MemPrompt, a method that allows fixing errors in deployed GPT-3 style models using user feedback without requiring full re-training.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "feedback_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/madaan/memprompt",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "human-feedback",
        "memory"
      ],
      "id": 568
    },
    {
      "name": "Magpie",
      "one_line_profile": "Alignment Data Synthesis from Scratch",
      "detailed_description": "A pipeline and tool for synthesizing high-quality alignment data by prompting aligned LLMs, facilitating efficient data generation for model training.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_synthesis",
        "alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/magpie-align/magpie",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "synthetic-data",
        "alignment",
        "data-generation"
      ],
      "id": 569
    },
    {
      "name": "Pruning-Weights-Biobjective",
      "one_line_profile": "Biobjective optimization strategy for neural network weight pruning in Keras",
      "detailed_description": "A pruning strategy integrated into the training process that uses multiobjective optimization to reduce network complexity and inference time without requiring extensive hyperparameter search or retraining.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_compression",
        "pruning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/malena1906/Pruning-Weights-with-Biobjective-Optimization-Keras",
      "help_website": [],
      "license": null,
      "tags": [
        "pruning",
        "optimization",
        "keras",
        "neural-networks"
      ],
      "id": 570
    },
    {
      "name": "MaPO",
      "one_line_profile": "Margin-aware Preference Optimization for aligning diffusion models",
      "detailed_description": "Official codebase for MaPO, a method to align diffusion models without requiring reference images, utilizing margin-aware preference optimization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "diffusion_model_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mapo-t2i/mapo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-models",
        "alignment",
        "preference-optimization"
      ],
      "id": 571
    },
    {
      "name": "6DPose",
      "one_line_profile": "Implementation of 6D pose estimation algorithms",
      "detailed_description": "A collection of algorithms and implementations for 6D pose estimation, useful for computer vision and robotics tasks involving spatial analysis.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "pose_estimation",
        "image_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/meiqua/6DPose",
      "help_website": [],
      "license": null,
      "tags": [
        "6d-pose",
        "computer-vision",
        "pose-estimation"
      ],
      "id": 572
    },
    {
      "name": "PromptCBLUE",
      "one_line_profile": "Large-scale Chinese medical instruction-tuning dataset",
      "detailed_description": "A large-scale instruction-tuning dataset designed for multi-task and few-shot learning in the medical domain, facilitating the training of medical LLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "dataset_preparation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/michael-wzhu/PromptCBLUE",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-ai",
        "instruction-tuning",
        "dataset",
        "chinese-nlp"
      ],
      "id": 573
    },
    {
      "name": "InstructLLaMA",
      "one_line_profile": "Pipeline for pre-training, SFT, and RLHF of LLaMA models",
      "detailed_description": "A comprehensive implementation for pre-training, supervised fine-tuning (SFT), and reinforcement learning from human feedback (RLHF) to align LLaMA models with human instructions.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "supervised_fine_tuning",
        "alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/michaelnny/InstructLLaMA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llama",
        "rlhf",
        "sft",
        "instruction-following"
      ],
      "id": 574
    },
    {
      "name": "CoMOLA",
      "one_line_profile": "Constrained Multi-objective Optimization of Land use Allocation",
      "detailed_description": "A generic Python tool for optimizing land use allocation considering ecosystem services and biodiversity, using constrained multi-objective optimization techniques.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "optimization",
        "simulation",
        "spatial_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/michstrauch/CoMOLA",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "optimization",
        "land-use",
        "multi-objective",
        "spatial-planning"
      ],
      "id": 575
    },
    {
      "name": "LoRA",
      "one_line_profile": "Reference implementation of Low-Rank Adaptation for LLMs",
      "detailed_description": "The official implementation of LoRA (Low-Rank Adaptation), a widely used parameter-efficient fine-tuning technique for large language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/LoRA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lora",
        "peft",
        "llm",
        "fine-tuning"
      ],
      "id": 576
    },
    {
      "name": "mttl",
      "one_line_profile": "Library for modular LLMs with parameter-efficient fine-tuning",
      "detailed_description": "A library for building modular language models using parameter-efficient fine-tuning (PEFT) techniques, facilitating flexible model adaptation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "modular_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/mttl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "modular-ai",
        "llm"
      ],
      "id": 577
    },
    {
      "name": "PEFT Proteomics",
      "one_line_profile": "LoRA implementation for protein language models",
      "detailed_description": "A specialized implementation of Low-Rank Adaptation (LoRA) tailored for fine-tuning protein language models in proteomics research.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "protein_modeling",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/microsoft/peft_proteomics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "proteomics",
        "protein-language-models",
        "lora",
        "bio-ai"
      ],
      "id": 578
    },
    {
      "name": "SAMMO",
      "one_line_profile": "Structure-aware Multi-Objective Metaprompt Optimization library",
      "detailed_description": "A library for prompt engineering and optimization that uses structure-aware multi-objective techniques to improve the performance of large language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "prompt_optimization",
        "prompt_engineering"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/sammo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-engineering",
        "optimization",
        "llm"
      ],
      "id": 579
    },
    {
      "name": "VADER",
      "one_line_profile": "Video Diffusion Alignment via Reward Gradients",
      "detailed_description": "A tool for aligning video diffusion models using reward gradients, supporting fine-tuning with various reward models like HPS, PickScore, and VideoMAE.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "video_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mihirp1998/VADER",
      "help_website": [],
      "license": null,
      "tags": [
        "video-diffusion",
        "alignment",
        "reward-gradients"
      ],
      "id": 580
    },
    {
      "name": "UniTS",
      "one_line_profile": "Unified multi-task time series model",
      "detailed_description": "A unified model and library for multi-task time series analysis, capable of handling forecasting, classification, and other temporal data tasks.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "time_series_analysis",
        "forecasting"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mims-harvard/UniTS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "time-series",
        "multi-task-learning",
        "forecasting"
      ],
      "id": 581
    },
    {
      "name": "DiffFit",
      "one_line_profile": "Parameter-Efficient Fine-Tuning for Diffusion Models",
      "detailed_description": "Implementation of DiffFit, a method for parameter-efficient fine-tuning of large diffusion models to unlock their transferability.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "diffusion_model_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mkshing/DiffFit-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "diffusion-models",
        "peft",
        "fine-tuning"
      ],
      "id": 582
    },
    {
      "name": "Trinity-RFT",
      "one_line_profile": "Framework for reinforcement fine-tuning of LLMs",
      "detailed_description": "A general-purpose, flexible, and scalable framework designed for reinforcement fine-tuning (RFT) of large language models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "fine_tuning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/modelscope/Trinity-RFT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "fine-tuning",
        "llm",
        "reinforcement-learning"
      ],
      "id": 583
    },
    {
      "name": "SWIFT",
      "one_line_profile": "Comprehensive framework for LLM/MLLM fine-tuning and alignment",
      "detailed_description": "A scalable framework supporting PEFT, full-parameter fine-tuning, and alignment (DPO/GRPO) for a wide range of LLMs and MLLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "alignment",
        "peft"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/modelscope/ms-swift",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "peft",
        "llm",
        "mllm",
        "alignment",
        "fine-tuning"
      ],
      "id": 584
    },
    {
      "name": "DPoser-X",
      "one_line_profile": "Diffusion Model as Robust 3D Whole-body Human Pose Prior",
      "detailed_description": "A tool utilizing diffusion models as a robust prior for 3D whole-body human pose estimation tasks.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "pose_estimation",
        "structure_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/moonbow721/DPoser-X",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "3d-pose",
        "diffusion-models",
        "human-pose-estimation"
      ],
      "id": 585
    },
    {
      "name": "LLM-Dojo",
      "one_line_profile": "Open source LLM training and RLHF framework",
      "detailed_description": "A framework for building model training pipelines and RLHF workflows (DPO/CPO/KTO/PPO), supporting various mainstream models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "fine_tuning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/mst272/LLM-Dojo",
      "help_website": [],
      "license": null,
      "tags": [
        "rlhf",
        "llm-training",
        "dpo",
        "ppo"
      ],
      "id": 586
    },
    {
      "name": "ChatGLM-Tuning",
      "one_line_profile": "LoRA fine-tuning solution for ChatGLM-6B",
      "detailed_description": "A widely used fine-tuning solution based on LoRA specifically designed for the ChatGLM-6B model.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/mymusise/ChatGLM-Tuning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chatglm",
        "lora",
        "fine-tuning"
      ],
      "id": 587
    },
    {
      "name": "llama2-fine-tune",
      "one_line_profile": "Scripts for fine-tuning Llama2 via SFT and DPO",
      "detailed_description": "A collection of scripts and workflows for fine-tuning Llama2 models using Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO).",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/mzbac/llama2-fine-tune",
      "help_website": [],
      "license": null,
      "tags": [
        "llama2",
        "sft",
        "dpo",
        "fine-tuning"
      ],
      "id": 588
    },
    {
      "name": "Nunchaku",
      "one_line_profile": "Inference engine and quantization library for 4-bit diffusion models",
      "detailed_description": "Nunchaku (SVDQuant) is a library designed for the quantization and efficient inference of diffusion models. It implements the SVDQuant algorithm to absorb outliers using low-rank components, enabling high-quality 4-bit quantization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "quantization",
        "inference",
        "diffusion_models"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nunchaku-tech/nunchaku",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "diffusion",
        "inference-engine"
      ],
      "id": 589
    },
    {
      "name": "Oumi",
      "one_line_profile": "Framework for fine-tuning, evaluating, and deploying open-source LLMs",
      "detailed_description": "Oumi is a comprehensive library that simplifies the lifecycle of Large Language Models (LLMs) and Vision Language Models (VLMs), providing tools for fine-tuning, evaluation, and deployment of models like Llama, Qwen, and DeepSeek.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine-tuning",
        "evaluation",
        "deployment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/oumi-ai/oumi",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "fine-tuning",
        "inference"
      ],
      "id": 590
    },
    {
      "name": "LoRAX",
      "one_line_profile": "Multi-LoRA inference server for scaling fine-tuned LLMs",
      "detailed_description": "LoRAX is an inference server designed to serve thousands of fine-tuned models on a single GPU using Low-Rank Adaptation (LoRA). It optimizes resource usage for multi-tenant LLM serving.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "inference",
        "serving",
        "lora"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/predibase/lorax",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference-server",
        "lora",
        "llm-serving"
      ],
      "id": 591
    },
    {
      "name": "LESS",
      "one_line_profile": "Data selection tool for targeted instruction tuning",
      "detailed_description": "LESS is a tool and method for selecting influential data for targeted instruction tuning of Large Language Models. It helps in optimizing training data to improve model performance on specific tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_selection",
        "instruction_tuning",
        "data_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/princeton-nlp/LESS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-selection",
        "instruction-tuning",
        "llm"
      ],
      "id": 592
    },
    {
      "name": "SimPO",
      "one_line_profile": "Simple Preference Optimization algorithm implementation",
      "detailed_description": "SimPO provides the reference implementation for Simple Preference Optimization, a reference-free reward optimization method for aligning Large Language Models. It serves as a solver for applying this alignment technique.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "preference_optimization",
        "alignment",
        "rlhf"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/princeton-nlp/SimPO",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "alignment",
        "dpo",
        "preference-optimization"
      ],
      "id": 593
    },
    {
      "name": "Promptify",
      "one_line_profile": "Library for structured output generation using LLMs",
      "detailed_description": "Promptify is a library that simplifies prompt engineering to obtain structured outputs (like JSON) from Large Language Models. It is used for NLP tasks such as Named Entity Recognition (NER) and classification.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "prompt_engineering",
        "information_extraction",
        "nlp"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/promptslab/Promptify",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prompt-engineering",
        "nlp",
        "structured-output"
      ],
      "id": 594
    },
    {
      "name": "T-Few",
      "one_line_profile": "Implementation of Few-Shot Parameter-Efficient Fine-Tuning",
      "detailed_description": "T-Few provides the code and implementation for the T-Few method, enabling few-shot parameter-efficient fine-tuning of language models. It serves as a solver/baseline for PEFT research.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "peft",
        "few_shot_learning",
        "fine-tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/r-three/t-few",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "peft",
        "few-shot",
        "fine-tuning"
      ],
      "id": 595
    },
    {
      "name": "LLM-RLHF-Tuning-with-PPO-and-DPO",
      "one_line_profile": "Toolkit for RLHF training using PPO and DPO",
      "detailed_description": "A comprehensive toolkit for Reinforcement Learning from Human Feedback (RLHF) training. It integrates instruction fine-tuning and reward modeling, supporting algorithms like PPO and DPO for models such as LLaMA.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "fine-tuning",
        "alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/raghavc/LLM-RLHF-Tuning-with-PPO-and-DPO",
      "help_website": [],
      "license": null,
      "tags": [
        "rlhf",
        "ppo",
        "dpo"
      ],
      "id": 596
    },
    {
      "name": "Crater",
      "one_line_profile": "Cloud-native AI training and inference platform",
      "detailed_description": "Crater is a platform designed for cloud-native AI training and inference, providing infrastructure management for AI workloads.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "model_training",
        "inference",
        "infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/raids-lab/crater",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-platform",
        "training",
        "inference"
      ],
      "id": 597
    },
    {
      "name": "TRLC-DK1",
      "one_line_profile": "Development kit for robot learning and control",
      "detailed_description": "A development kit provided by The Robot Learning Company, likely containing software interfaces and tools for controlling robotic hardware for learning tasks.",
      "domains": [
        "AI4",
        "Robotics"
      ],
      "subtask_category": [
        "robot_control",
        "reinforcement_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/robot-learning-co/trlc-dk1",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "robotics",
        "robot-learning",
        "sdk"
      ],
      "id": 598
    },
    {
      "name": "OAT",
      "one_line_profile": "Research-friendly framework for LLM online alignment",
      "detailed_description": "A framework designed for online alignment of Large Language Models, supporting reinforcement learning and preference learning techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "preference_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sail-sg/oat",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-alignment",
        "rlhf",
        "preference-optimization"
      ],
      "id": 599
    },
    {
      "name": "DialogStudio",
      "one_line_profile": "Unified dataset collection and loader for conversational AI",
      "detailed_description": "A library providing access to a diverse collection of unified datasets and instruction-aware models for conversational AI research.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "data_loading",
        "dataset_collection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/salesforce/DialogStudio",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "conversational-ai",
        "datasets",
        "instruction-tuning"
      ],
      "id": 600
    },
    {
      "name": "Finetune-Qwen2.5-VL",
      "one_line_profile": "Fine-tuning toolkit for Qwen2.5-VL vision-language models",
      "detailed_description": "A specialized toolkit for fine-tuning the Qwen2.5-VL model, optimized for vision understanding tasks with support for LoRA and PEFT.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft",
        "vision_language_modeling"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/sandy1990418/Finetune-Qwen2.5-VL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "qwen",
        "vlm",
        "lora",
        "fine-tuning"
      ],
      "id": 601
    },
    {
      "name": "XtunerGUI",
      "one_line_profile": "Graphical User Interface for Xtuner fine-tuning toolkit",
      "detailed_description": "A GUI wrapper for the Xtuner library, facilitating the fine-tuning process of Large Language Models for users who prefer a visual interface.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "gui"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/scchy/XtunerGUI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "xtuner",
        "gui",
        "fine-tuning"
      ],
      "id": 602
    },
    {
      "name": "GraphRAG-Local-UI",
      "one_line_profile": "Local platform for GraphRAG with LLMs",
      "detailed_description": "A comprehensive tool for running GraphRAG (Retrieval Augmented Generation with Knowledge Graphs) locally, including indexing, prompt tuning, and querying capabilities.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "rag",
        "knowledge_graph",
        "information_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/severian42/GraphRAG-Local-UI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graphrag",
        "rag",
        "local-llm"
      ],
      "id": 603
    },
    {
      "name": "Vodalus-Expert-LLM-Forge",
      "one_line_profile": "Toolkit for dataset crafting and efficient LLM fine-tuning",
      "detailed_description": "A tool suite for creating datasets using RAG/Wikipedia ground truth and performing efficient fine-tuning using MLX and Unsloth.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "dataset_creation",
        "fine_tuning",
        "rag"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/severian42/Vodalus-Expert-LLM-Forge",
      "help_website": [],
      "license": null,
      "tags": [
        "dataset-generation",
        "fine-tuning",
        "mlx",
        "unsloth"
      ],
      "id": 604
    },
    {
      "name": "MedicalGPT",
      "one_line_profile": "Comprehensive pipeline for training medical LLMs",
      "detailed_description": "A complete workflow for training medical large language models, including incremental pre-training, supervised fine-tuning (SFT), RLHF, DPO, and other alignment techniques.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "fine_tuning",
        "rlhf",
        "medical_ai"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/shibing624/MedicalGPT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-llm",
        "rlhf",
        "dpo",
        "sft"
      ],
      "id": 605
    },
    {
      "name": "promptimal",
      "one_line_profile": "Minimalist prompt optimizer for LLMs",
      "detailed_description": "A tool designed to optimize prompts for large language models, improving response quality and efficiency.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_optimization",
        "prompt_engineering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/shobrook/promptimal",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-optimization",
        "llm"
      ],
      "id": 606
    },
    {
      "name": "chatGLM-6B-QLoRA",
      "one_line_profile": "QLoRA fine-tuning implementation for ChatGLM-6B",
      "detailed_description": "A tool implementing 4-bit QLoRA efficient fine-tuning for ChatGLM-6B/ChatGLM2-6B models, including model merging and quantization utilities.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "qlora",
        "quantization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/shuxueslpi/chatGLM-6B-QLoRA",
      "help_website": [],
      "license": null,
      "tags": [
        "chatglm",
        "qlora",
        "peft"
      ],
      "id": 607
    },
    {
      "name": "OneDiff",
      "one_line_profile": "Acceleration library for diffusion models",
      "detailed_description": "An out-of-the-box acceleration library designed to optimize the inference speed of diffusion models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_acceleration",
        "diffusion_models"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/siliconflow/onediff",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion",
        "acceleration",
        "inference"
      ],
      "id": 608
    },
    {
      "name": "baichuan_finetuning",
      "one_line_profile": "Fine-tuning scripts for Baichuan models",
      "detailed_description": "A collection of scripts and tools for fine-tuning Baichuan and Baichuan2 models, supporting Alpaca-style instruction tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "instruction_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssbuild/baichuan_finetuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "baichuan",
        "fine-tuning",
        "llm"
      ],
      "id": 609
    },
    {
      "name": "chatglm_finetuning",
      "one_line_profile": "Fine-tuning toolkit for ChatGLM models",
      "detailed_description": "A widely used toolkit for fine-tuning ChatGLM-6B and related models, supporting various fine-tuning methods including Alpaca-style instruction tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "instruction_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssbuild/chatglm_finetuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "chatglm",
        "fine-tuning",
        "llm"
      ],
      "id": 610
    },
    {
      "name": "chatglm_rlhf",
      "one_line_profile": "RLHF fine-tuning implementation for ChatGLM",
      "detailed_description": "A specialized tool for performing Reinforcement Learning from Human Feedback (RLHF) fine-tuning on ChatGLM models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "rlhf",
        "alignment",
        "fine_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssbuild/chatglm_rlhf",
      "help_website": [],
      "license": null,
      "tags": [
        "chatglm",
        "rlhf",
        "alignment"
      ],
      "id": 611
    },
    {
      "name": "llm_finetuning",
      "one_line_profile": "Fine-tuning scripts for various Large Language Models (Bloom, OPT, GPT, LLaMA, etc.)",
      "detailed_description": "A collection of scripts and tools for fine-tuning multiple open-source Large Language Models including Bloom, OPT, GPT-2, LLaMA, and CPM-Ant, supporting various training configurations.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssbuild/llm_finetuning",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "fine-tuning",
        "llama",
        "bloom"
      ],
      "id": 612
    },
    {
      "name": "llm_rlhf",
      "one_line_profile": "Reinforcement Learning from Human Feedback (RLHF) implementation for LLMs",
      "detailed_description": "Implements reinforcement learning training pipelines (RLHF) for large language models such as GPT-2, LLaMA, and Bloom, facilitating alignment with human preferences.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssbuild/llm_rlhf",
      "help_website": [],
      "license": null,
      "tags": [
        "rlhf",
        "alignment",
        "llm"
      ],
      "id": 613
    },
    {
      "name": "moss_finetuning",
      "one_line_profile": "Fine-tuning tools specifically for the MOSS chat model",
      "detailed_description": "Provides scripts and utilities tailored for fine-tuning the MOSS conversational model, enabling domain adaptation and instruction tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssbuild/moss_finetuning",
      "help_website": [],
      "license": null,
      "tags": [
        "moss",
        "fine-tuning",
        "chat-model"
      ],
      "id": 614
    },
    {
      "name": "qwen_finetuning",
      "one_line_profile": "Fine-tuning framework for Qwen series models",
      "detailed_description": "A dedicated toolkit for fine-tuning Qwen (Tongyi Qianwen) models, supporting instruction tuning and domain adaptation workflows.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssbuild/qwen_finetuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "qwen",
        "fine-tuning",
        "llm"
      ],
      "id": 615
    },
    {
      "name": "rwkv_finetuning",
      "one_line_profile": "Fine-tuning scripts for RWKV RNN models",
      "detailed_description": "Tools designed for fine-tuning RWKV models, a type of RNN-based large language model, enabling customization and performance improvement on specific tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssbuild/rwkv_finetuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rwkv",
        "rnn",
        "fine-tuning"
      ],
      "id": 616
    },
    {
      "name": "SNELL",
      "one_line_profile": "Sparse tuning method for low-memory LLM adaptation",
      "detailed_description": "Implementation of the SNELL method (NeurIPS 2024) for expanding sparse tuning to reduce memory usage during Large Language Model fine-tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ssfgunner/SNELL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sparse-tuning",
        "memory-efficient",
        "peft"
      ],
      "id": 617
    },
    {
      "name": "xTuring",
      "one_line_profile": "Framework for building and personalizing LLMs",
      "detailed_description": "An easy-to-use framework for building, personalizing, and controlling LLMs, covering the pipeline from data pre-processing to fine-tuning open-source models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "data_processing"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/stochasticai/xTuring",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-personalization",
        "fine-tuning",
        "framework"
      ],
      "id": 618
    },
    {
      "name": "Simple-Trl-Training",
      "one_line_profile": "Simplified DPO training wrapper for LLMs",
      "detailed_description": "A lightweight tool based on the DPO (Direct Preference Optimization) algorithm for fine-tuning large language models, designed for ease of use.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "dpo"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sugarandgugu/Simple-Trl-Training",
      "help_website": [],
      "license": null,
      "tags": [
        "dpo",
        "alignment",
        "fine-tuning"
      ],
      "id": 619
    },
    {
      "name": "ChiMed-GPT",
      "one_line_profile": "Chinese medical LLM training and alignment implementation",
      "detailed_description": "Implementation for ChiMed-GPT, a Chinese medical large language model, including pipelines for pre-training, supervised fine-tuning (SFT), and RLHF on medical data.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "alignment",
        "domain_adaptation"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/synlp/ChiMed-GPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-llm",
        "sft",
        "rlhf"
      ],
      "id": 620
    },
    {
      "name": "Llama3.1-Finetuning",
      "one_line_profile": "Fine-tuning toolkit for Llama 3.1 models",
      "detailed_description": "Provides tools for full-parameter fine-tuning, LoRA, and QLoRA fine-tuning specifically optimized for the Llama 3.1 model family.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/taishan1994/Llama3.1-Finetuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llama-3",
        "lora",
        "qlora"
      ],
      "id": 621
    },
    {
      "name": "qlora-chinese-LLM",
      "one_line_profile": "QLoRA fine-tuning for Chinese LLMs",
      "detailed_description": "A tool for fine-tuning Chinese large language models (ChatGLM, Chinese-LLaMA-Alpaca, BELLE) using QLoRA (Quantized LoRA) for efficient adaptation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/taishan1994/qlora-chinese-LLM",
      "help_website": [],
      "license": null,
      "tags": [
        "qlora",
        "chinese-llm",
        "fine-tuning"
      ],
      "id": 622
    },
    {
      "name": "alpaca_eval",
      "one_line_profile": "Automatic evaluator for instruction-following models",
      "detailed_description": "A framework for automatic evaluation of instruction-following language models, providing a fast, cheap, and human-validated metric for model quality.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "evaluation",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/tatsu-lab/alpaca_eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "llm-benchmark",
        "instruction-following"
      ],
      "id": 623
    },
    {
      "name": "alpaca_farm",
      "one_line_profile": "Simulation framework for RLHF research",
      "detailed_description": "A simulation framework designed to facilitate research in Reinforcement Learning from Human Feedback (RLHF) and alternatives by simulating human feedback, enabling method development without expensive data collection.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "simulation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/tatsu-lab/alpaca_farm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "simulation",
        "alignment"
      ],
      "id": 624
    },
    {
      "name": "qlora-pipe",
      "one_line_profile": "Pipeline parallel training script for QLoRA",
      "detailed_description": "A training script enabling pipeline parallelism for Large Language Models, specifically optimized for QLoRA workflows to handle large models on limited hardware.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tdrussell/qlora-pipe",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pipeline-parallelism",
        "qlora",
        "training"
      ],
      "id": 625
    },
    {
      "name": "unsloth-5090-multiple",
      "one_line_profile": "Configuration and scripts for Unsloth on RTX 5090",
      "detailed_description": "Utilities and configuration scripts for running Unsloth (LLM training optimization tool) on multi-GPU setups involving RTX 5090 hardware.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/thad0ctor/unsloth-5090-multiple",
      "help_website": [],
      "license": null,
      "tags": [
        "unsloth",
        "hardware-optimization",
        "fine-tuning"
      ],
      "id": 626
    },
    {
      "name": "FinetuneGLMWithPeft",
      "one_line_profile": "Simple LoRA fine-tuning implementation for ChatGLM-6B",
      "detailed_description": "A lightweight implementation using the PEFT library to fine-tune the ChatGLM-6B model with LoRA, serving as a straightforward solver for this specific model.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/thaumstrial/FinetuneGLMWithPeft",
      "help_website": [],
      "license": null,
      "tags": [
        "chatglm",
        "lora",
        "peft"
      ],
      "id": 627
    },
    {
      "name": "LoRD",
      "one_line_profile": "Low-Rank adapter extraction tool",
      "detailed_description": "A utility for extracting Low-Rank adapters (LoRA) from fully fine-tuned transformer models, enabling the conversion of full weights back into modular adapters.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_processing",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/thomasgauthier/LoRD",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lora-extraction",
        "adapter",
        "transformers"
      ],
      "id": 628
    },
    {
      "name": "KnowledgeablePromptTuning",
      "one_line_profile": "Knowledgeable Prompt Tuning (KPT) implementation",
      "detailed_description": "Implementation of Knowledgeable Prompt Tuning, a method to optimize prompts for pre-trained language models by incorporating external knowledge.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "prompt_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/thunlp/KnowledgeablePromptTuning",
      "help_website": [],
      "license": null,
      "tags": [
        "prompt-tuning",
        "kpt",
        "nlp"
      ],
      "id": 629
    },
    {
      "name": "Cherry_LLM",
      "one_line_profile": "Self-data filtering tool for LLM instruction tuning",
      "detailed_description": "A tool for filtering LLM instruction-tuning data using a perplexity-based difficulty score (Cherry Score), enabling data quality improvement without external models.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_processing",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tianyi-lab/Cherry_LLM",
      "help_website": [],
      "license": null,
      "tags": [
        "data-filtering",
        "instruction-tuning",
        "data-quality"
      ],
      "id": 630
    },
    {
      "name": "Reflection_Tuning",
      "one_line_profile": "Selective Reflection-Tuning implementation",
      "detailed_description": "Implementation of Selective Reflection-Tuning, a method for recycling student-selected data to improve LLM instruction tuning performance.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "data_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tianyi-lab/Reflection_Tuning",
      "help_website": [],
      "license": null,
      "tags": [
        "instruction-tuning",
        "reflection-tuning",
        "llm"
      ],
      "id": 631
    },
    {
      "name": "alpaca-lora",
      "one_line_profile": "Instruct-tune LLaMA on consumer hardware using LoRA",
      "detailed_description": "A seminal tool for fine-tuning LLaMA models on consumer-grade hardware using Low-Rank Adaptation (LoRA), enabling widespread access to LLM instruction tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "peft"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/tloen/alpaca-lora",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lora",
        "llama",
        "fine-tuning"
      ],
      "id": 632
    },
    {
      "name": "ICLR25-FSCA",
      "one_line_profile": "Context-Alignment method for Time Series LLMs",
      "detailed_description": "Implementation of the Context-Alignment (FSCA) method to activate and enhance Large Language Model capabilities specifically for time series analysis tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "domain_adaptation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tokaka22/ICLR25-FSCA",
      "help_website": [],
      "license": null,
      "tags": [
        "time-series",
        "alignment",
        "llm"
      ],
      "id": 633
    },
    {
      "name": "axolotl-mobile-sensing",
      "one_line_profile": "Framework for mobile sensor data extraction and ML",
      "detailed_description": "A machine learning framework designed to extract and process accelerometric and gyroscopic data from mobile phones. (Note: Name collision with the popular LLM fine-tuning tool 'axolotl', but this is a distinct tool for sensor data).",
      "domains": [
        "IoT",
        "Sensor_Analysis"
      ],
      "subtask_category": [
        "data_processing",
        "feature_extraction"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/tomasreimers/axolotl",
      "help_website": [],
      "license": null,
      "tags": [
        "sensor-data",
        "mobile-sensing",
        "machine-learning"
      ],
      "id": 634
    },
    {
      "name": "transformerlab-app",
      "one_line_profile": "Desktop application for LLM and Diffusion model engineering",
      "detailed_description": "An open-source desktop application that allows users to interact with, train, fine-tune, and evaluate large language models and diffusion models locally.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "evaluation",
        "inference"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/transformerlab/transformerlab-app",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "gui",
        "llm-training",
        "local-inference"
      ],
      "id": 635
    },
    {
      "name": "Unsloth",
      "one_line_profile": "Optimized fine-tuning library for LLMs with significantly reduced VRAM usage and faster training speeds",
      "detailed_description": "Unsloth is a lightweight and highly optimized library for fine-tuning Large Language Models (LLMs). It implements custom kernels and backpropagation logic to achieve up to 2x faster training and 70% less memory usage compared to standard Hugging Face implementations, supporting models like Llama, Mistral, and Qwen.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "peft",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/unslothai/unsloth",
      "help_website": [
        "https://github.com/unslothai/unsloth"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "fine-tuning",
        "optimization",
        "peft",
        "lora"
      ],
      "id": 636
    },
    {
      "name": "Unsloth Zoo",
      "one_line_profile": "Utility library and dataset collection for the Unsloth fine-tuning ecosystem",
      "detailed_description": "Unsloth Zoo provides supplementary utilities, data collators, and dataset preparation scripts designed to work seamlessly with the Unsloth library. It facilitates the setup of training pipelines for various LLM fine-tuning tasks.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_processing",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/unslothai/unsloth-zoo",
      "help_website": [
        "https://github.com/unslothai/unsloth-zoo"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "utils",
        "datasets",
        "fine-tuning"
      ],
      "id": 637
    },
    {
      "name": "GLiNER",
      "one_line_profile": "Generalist and lightweight model/library for zero-shot Named Entity Recognition",
      "detailed_description": "GLiNER is a model and library capable of identifying any entity type using a bidirectional transformer encoder (BERT-like). It provides a practical alternative to traditional LLMs for information extraction tasks, offering high performance with lower resource requirements.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "information_extraction",
        "ner",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/urchade/GLiNER",
      "help_website": [
        "https://github.com/urchade/GLiNER"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ner",
        "nlp",
        "information-extraction",
        "zero-shot"
      ],
      "id": 638
    },
    {
      "name": "TextRL",
      "one_line_profile": "Library for Reinforcement Learning with Human Feedback (RLHF) on text generation models",
      "detailed_description": "TextRL is a Python library that implements RLHF pipelines compatible with Hugging Face Transformers. It allows users to fine-tune any text generation model using reinforcement learning techniques, supporting various reward models and environments.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/voidful/TextRL",
      "help_website": [
        "https://github.com/voidful/TextRL"
      ],
      "license": "MIT",
      "tags": [
        "rlhf",
        "reinforcement-learning",
        "nlp",
        "alignment"
      ],
      "id": 639
    },
    {
      "name": "transformers-qwen3-moe-fused",
      "one_line_profile": "Fused Mixture-of-Experts (MoE) layer implementation for accelerated Qwen3 training",
      "detailed_description": "This repository provides a highly optimized, fused implementation of the MoE layer for Qwen3 models. It is designed to be compatible with Hugging Face Transformers, LoRA, and Unsloth, enabling faster training and inference for MoE-based architectures.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "optimization",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/woct0rdho/transformers-qwen3-moe-fused",
      "help_website": [
        "https://github.com/woct0rdho/transformers-qwen3-moe-fused"
      ],
      "license": "Apache-2.0",
      "tags": [
        "moe",
        "optimization",
        "cuda",
        "qwen"
      ],
      "id": 640
    },
    {
      "name": "cycleformers",
      "one_line_profile": "Library for cycle-consistency training of transformer models",
      "detailed_description": "Cycleformers is a Python library that enables efficient cycle-consistency training (back-translation) for transformer models. It incorporates memory-efficient techniques like PEFT adapter switching, allowing for the training of larger models on limited hardware.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "alignment",
        "peft"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wrmthorne/cycleformers",
      "help_website": [
        "https://github.com/wrmthorne/cycleformers"
      ],
      "license": "CC-BY-4.0",
      "tags": [
        "transformers",
        "cycle-consistency",
        "peft",
        "training"
      ],
      "id": 641
    },
    {
      "name": "Xtreme1",
      "one_line_profile": "Multimodal data labeling and annotation platform for AI training",
      "detailed_description": "Xtreme1 is an open-source platform for multimodal training data annotation. It supports 3D LiDAR point clouds, images, and LLM data, providing tools for data visualization, labeling, and management to accelerate AI model development.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_processing",
        "annotation",
        "visualization"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/xtreme1-io/xtreme1",
      "help_website": [
        "https://docs.xtreme1.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "annotation",
        "labeling",
        "lidar",
        "multimodal",
        "llm"
      ],
      "id": 642
    },
    {
      "name": "LongQLoRA",
      "one_line_profile": "Efficient context extension tool for Large Language Models using QLoRA",
      "detailed_description": "A parameter-efficient fine-tuning tool designed to extend the context length of Large Language Models (LLMs) such as LLaMA. It utilizes QLoRA to reduce memory usage while maintaining performance, enabling the training of long-context models on consumer-grade hardware.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "context_extension",
        "fine_tuning",
        "qlora"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yangjianxin1/LongQLoRA",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "context-window",
        "qlora",
        "fine-tuning"
      ],
      "id": 643
    },
    {
      "name": "Self-Instruct",
      "one_line_profile": "Framework for aligning language models with self-generated instructions",
      "detailed_description": "A seminal framework for generating synthetic instruction-following data by bootstrapping off a pre-trained language model. It enables the creation of large-scale instruction tuning datasets with minimal human annotation, widely used for aligning LLMs.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "data_generation",
        "instruction_tuning",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yizhongw/self-instruct",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "synthetic-data",
        "instruction-tuning",
        "alignment",
        "llm"
      ],
      "id": 644
    },
    {
      "name": "Chinese-LLaMA-Alpaca",
      "one_line_profile": "Chinese-adapted LLaMA and Alpaca LLM training and deployment suite",
      "detailed_description": "A comprehensive project providing Chinese vocabulary expansion, LoRA fine-tuning scripts, and merged model weights for LLaMA and Alpaca. It serves as a foundational platform for training and deploying Chinese-capable LLMs in research and industry.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "vocabulary_expansion",
        "fine_tuning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ymcui/Chinese-LLaMA-Alpaca",
      "help_website": [
        "https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki"
      ],
      "license": "Apache-2.0",
      "tags": [
        "chinese-llm",
        "llama",
        "lora",
        "fine-tuning"
      ],
      "id": 645
    },
    {
      "name": "Chinese-LLaMA-Alpaca-2",
      "one_line_profile": "Second generation Chinese LLaMA-2 & Alpaca-2 training suite with long context support",
      "detailed_description": "The successor to Chinese-LLaMA-Alpaca, targeting LLaMA-2. It includes tools for training, quantization, and inference, with specific support for 64K long-context models, serving as a key toolchain for Chinese LLM research.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "long_context",
        "fine_tuning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ymcui/Chinese-LLaMA-Alpaca-2",
      "help_website": [
        "https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llama-2",
        "long-context",
        "chinese-llm",
        "peft"
      ],
      "id": 646
    },
    {
      "name": "qwen2-sft",
      "one_line_profile": "Fine-tuning and inference toolkit specifically for Qwen model family",
      "detailed_description": "A specialized toolkit for Supervised Fine-Tuning (SFT) and LoRA adaptation of the Qwen (Qwen1.5/Qwen2) model series. It streamlines the process of adapting Qwen models for downstream tasks using transformers and peft libraries.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "inference",
        "model_adaptation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yongzhuo/qwen2-sft",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "qwen",
        "sft",
        "lora",
        "fine-tuning"
      ],
      "id": 647
    },
    {
      "name": "Olympus",
      "one_line_profile": "Universal task routing model for computer vision tasks",
      "detailed_description": "A universal task router that directs input queries to appropriate vision experts or models. It serves as a meta-tool for managing and orchestrating diverse computer vision tasks, facilitating multi-task learning and model composition.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "task_routing",
        "model_orchestration",
        "computer_vision"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yuanze-lin/Olympus",
      "help_website": [],
      "license": null,
      "tags": [
        "task-routing",
        "computer-vision",
        "model-composition"
      ],
      "id": 648
    },
    {
      "name": "ImageReward",
      "one_line_profile": "Human preference evaluation metric for text-to-image generation",
      "detailed_description": "A comprehensive text-to-image human preference reward model. It serves as a scientific metric tool to evaluate and align generative models with human aesthetics and instruction following, addressing the lack of robust evaluation metrics in visual generation.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "evaluation",
        "reward_modeling",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zai-org/ImageReward",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reward-model",
        "rlhf",
        "evaluation-metric",
        "text-to-image"
      ],
      "id": 649
    },
    {
      "name": "VisionReward",
      "one_line_profile": "Fine-grained multi-dimensional preference learning for visual generation",
      "detailed_description": "An advanced reward modeling tool for image and video generation that evaluates outputs across multiple dimensions. It enables fine-grained alignment of visual generative models, supporting research in multimodal preference optimization.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "evaluation",
        "reward_modeling",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zai-org/VisionReward",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reward-model",
        "video-generation",
        "preference-learning"
      ],
      "id": 650
    },
    {
      "name": "LLaMA-LoRA-Tuner",
      "one_line_profile": "GUI tool for fine-tuning LLaMA models using LoRA",
      "detailed_description": "A user-friendly interface (UI) for fine-tuning LLaMA and other LLMs using LoRA. It simplifies the parameter configuration and training process, making advanced fine-tuning techniques accessible for research and experimentation without deep coding requirements.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "workflow_management",
        "ui_tool"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/zetavg/LLaMA-LoRA-Tuner",
      "help_website": [],
      "license": null,
      "tags": [
        "gui",
        "lora",
        "fine-tuning",
        "llama"
      ],
      "id": 651
    },
    {
      "name": "lmms-finetune",
      "one_line_profile": "Minimalist codebase for fine-tuning Large Multimodal Models",
      "detailed_description": "A streamlined and extensible codebase for fine-tuning various Large Multimodal Models (LMMs) such as LLaVA, Qwen-VL, and Phi3-V. It supports multiple architectures and provides a unified interface for multimodal instruction tuning.",
      "domains": [
        "AI3",
        "AI3-02"
      ],
      "subtask_category": [
        "multimodal_fine_tuning",
        "instruction_tuning",
        "model_adaptation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjysteven/lmms-finetune",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "fine-tuning",
        "llava",
        "qwen-vl"
      ],
      "id": 652
    },
    {
      "name": "text-extract-api",
      "one_line_profile": "API for extracting and cleaning text from various document formats including PDFs for dataset creation",
      "detailed_description": "A robust tool for parsing and extracting text from documents (PDF, Word, PPTX), essential for building scientific corpora from literature. It includes features for PII removal and structured data conversion.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_extraction",
        "cleaning",
        "preprocessing"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/CatchTheTornado/text-extract-api",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ocr",
        "pdf-parsing",
        "dataset-creation",
        "pii-removal"
      ],
      "id": 653
    },
    {
      "name": "text-dedup",
      "one_line_profile": "All-in-one text de-duplication tool for NLP datasets",
      "detailed_description": "A comprehensive library for deduplicating text datasets using methods like MinHash and SimHash, widely used in preparing training corpora for Large Language Models.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "deduplication",
        "cleaning",
        "preprocessing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChenghaoMou/text-dedup",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deduplication",
        "minhash",
        "simhash",
        "nlp",
        "dataset-cleaning"
      ],
      "id": 654
    },
    {
      "name": "PMLB",
      "one_line_profile": "Python interface for a curated repository of benchmark datasets for evaluating ML algorithms",
      "detailed_description": "PMLB (Penn Machine Learning Benchmarks) provides a standardized interface to access a large collection of curated benchmark datasets, facilitating the evaluation and comparison of supervised machine learning algorithms in scientific research.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "benchmarking",
        "data_loading",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EpistasisLab/pmlb",
      "help_website": [
        "https://epistasislab.github.io/pmlb/"
      ],
      "license": "MIT",
      "tags": [
        "benchmark",
        "datasets",
        "machine-learning",
        "evaluation"
      ],
      "id": 655
    },
    {
      "name": "paper-qa",
      "one_line_profile": "High accuracy RAG for answering questions from scientific documents with citations",
      "detailed_description": "A specialized Retrieval-Augmented Generation (RAG) tool designed for scientific workflows. It ingests scientific papers (PDFs/text) and provides answers to queries with precise citations, enabling efficient literature review and information extraction.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "information_retrieval",
        "question_answering",
        "literature_review"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Future-House/paper-qa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "scientific-literature",
        "citations",
        "llm"
      ],
      "id": 656
    },
    {
      "name": "ccNetViz",
      "one_line_profile": "Lightweight JavaScript library for visualization of large-scale biological network graphs",
      "detailed_description": "A high-performance WebGL-based library developed by Helikar Lab for visualizing large-scale networks, specifically tailored for biological systems and complex network analysis.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "visualization",
        "network_analysis"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/HelikarLab/ccNetViz",
      "help_website": [
        "http://helikarlab.github.io/ccNetViz/"
      ],
      "license": null,
      "tags": [
        "visualization",
        "network-biology",
        "webgl",
        "graphs"
      ],
      "id": 657
    },
    {
      "name": "OneCite",
      "one_line_profile": "Toolkit to parse, complete, and format academic references",
      "detailed_description": "An intelligent toolkit designed to automate the processing of academic references. It supports parsing, completion, and formatting, which is essential for cleaning and structuring bibliographic data in scientific corpora.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "metadata_processing",
        "cleaning",
        "reference_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HzaCode/OneCite",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "citations",
        "bibliography",
        "academic-references",
        "parsing"
      ],
      "id": 658
    },
    {
      "name": "Seave",
      "one_line_profile": "Web platform for filtering and annotating genetic variants",
      "detailed_description": "Seave is a web platform that enables genetic variants to be easily filtered and annotated with in silico pathogenicity prediction scores and annotations from popular disease databases. It stores genomic variation of all types and sizes, allowing filtering for specific inheritance patterns, quality values, allele frequencies, and gene lists.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "variant_filtering",
        "genomic_annotation"
      ],
      "application_level": "platform",
      "primary_language": "HTML",
      "repo_url": "https://github.com/KCCG/seave",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "genomics",
        "variant-filtering",
        "bioinformatics"
      ],
      "id": 659
    },
    {
      "name": "SmCCNet",
      "one_line_profile": "Canonical correlation analysis for regulatory network discovery",
      "detailed_description": "A canonical correlation analysis based method for discovering (quantitative) trait-specific heterogeneous regulatory networks. It integrates multi-omics data to identify regulatory relationships.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "network_analysis",
        "regulatory_network_inference"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/KechrisLab/SmCCNet",
      "help_website": [],
      "license": null,
      "tags": [
        "bioinformatics",
        "regulatory-networks",
        "multi-omics"
      ],
      "id": 660
    },
    {
      "name": "NeMo Curator",
      "one_line_profile": "Scalable data pre-processing and curation toolkit for LLMs",
      "detailed_description": "A scalable data pre-processing and curation toolkit for Large Language Models (LLMs). It provides modules for data download, text extraction, cleaning, quality filtering, and deduplication, essential for training scientific domain models.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "dataset_curation",
        "deduplication",
        "data_cleaning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA-NeMo/Curator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "data-curation",
        "nlp"
      ],
      "id": 661
    },
    {
      "name": "nougat-latex-ocr",
      "one_line_profile": "Fine-tuning and evaluation codebase for Nougat scientific OCR models",
      "detailed_description": "Codebase for fine-tuning and evaluating Nougat-based image-to-LaTeX generation models. Nougat is specialized for parsing scientific documents, converting PDFs to Markdown with LaTeX math support.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "ocr",
        "scientific_document_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NormXU/nougat-latex-ocr",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ocr",
        "latex",
        "scientific-papers"
      ],
      "id": 662
    },
    {
      "name": "AfterQC",
      "one_line_profile": "Automatic filtering, trimming, and quality control for FASTQ data",
      "detailed_description": "Automatic Filtering, Trimming, Error Removing and Quality Control for fastq data. It is designed to process high-throughput sequencing data efficiently.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "quality_control",
        "read_trimming"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGene/AfterQC",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "fastq",
        "quality-control"
      ],
      "id": 663
    },
    {
      "name": "fastp",
      "one_line_profile": "Ultra-fast all-in-one FASTQ preprocessor",
      "detailed_description": "An ultra-fast all-in-one FASTQ preprocessor that provides quality control, adapter trimming, filtering, splitting, and merging capabilities for sequencing data.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "quality_control",
        "adapter_trimming",
        "preprocessing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/OpenGene/fastp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "fastq",
        "ngs"
      ],
      "id": 664
    },
    {
      "name": "PteRedactyl",
      "one_line_profile": "PII redaction tool for clinical free-text",
      "detailed_description": "A python module for redaction of personally identifiable information (PII) in clinical free-text. It builds on Presidio and is designed for de-identifying medical records for research.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "pii_redaction",
        "clinical_data_cleaning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SETT-Centre-Data-and-AI/PteRedactyl",
      "help_website": [],
      "license": null,
      "tags": [
        "clinical-nlp",
        "de-identification",
        "medical-data"
      ],
      "id": 665
    },
    {
      "name": "CCNet-Pure-Pytorch",
      "one_line_profile": "Pure PyTorch implementation of Criss-Cross Attention for semantic segmentation",
      "detailed_description": "A faster and more precise implementation of Criss-Cross Attention (2D & 3D) for Semantic Segmentation in pure PyTorch, serving as a solver for computer vision tasks.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "semantic_segmentation",
        "model_implementation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Serge-weihao/CCNet-Pure-Pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "semantic-segmentation",
        "attention-mechanism",
        "computer-vision"
      ],
      "id": 666
    },
    {
      "name": "OmniStyle",
      "one_line_profile": "Data filtering tool for high-quality style transfer datasets",
      "detailed_description": "Official implementation for filtering high-quality style transfer data at scale, providing tools to curate and clean image datasets for model training.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_filtering",
        "dataset_curation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/StyleX-Research/OmniStyle",
      "help_website": [],
      "license": null,
      "tags": [
        "style-transfer",
        "data-filtering",
        "computer-vision"
      ],
      "id": 667
    },
    {
      "name": "awesome-semantic-segmentation-pytorch",
      "one_line_profile": "Collection of semantic segmentation model implementations in PyTorch",
      "detailed_description": "A comprehensive library providing implementations for various semantic segmentation models (FCN, PSPNet, Deeplabv3, etc.) on PyTorch, serving as a reference solver.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "semantic_segmentation",
        "model_implementation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Tramac/awesome-semantic-segmentation-pytorch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pytorch",
        "semantic-segmentation",
        "deep-learning",
        "computer-vision"
      ],
      "id": 668
    },
    {
      "name": "MLM_Filter",
      "one_line_profile": "Multimodal language model based data filtering tool",
      "detailed_description": "Official implementation of 'Finetuned Multimodal Language Models are High-Quality Image-Text Data Filters', providing a solver for cleaning and filtering multimodal datasets.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_filtering",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Victorwz/MLM_Filter",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-cleaning",
        "multimodal",
        "llm",
        "image-text"
      ],
      "id": 669
    },
    {
      "name": "dense_parser",
      "one_line_profile": "Dependency parser using Head Selection",
      "detailed_description": "Implementation of the DeNSe parser for Dependency Parsing as Head Selection, serving as a solver for NLP structure prediction tasks.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "dependency_parsing",
        "nlp"
      ],
      "application_level": "solver",
      "primary_language": "Lua",
      "repo_url": "https://github.com/XingxingZhang/dense_parser",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "nlp",
        "dependency-parsing",
        "deep-learning"
      ],
      "id": 670
    },
    {
      "name": "pydoxtools",
      "one_line_profile": "Library for data extraction from unstructured documents",
      "detailed_description": "A library to extract information from unstructured data using AI techniques, supporting customizable pipelines for data ingestion and cleaning in scientific workflows.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_extraction",
        "data_cleaning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Xyntopia/pydoxtools",
      "help_website": [
        "https://pydoxtools.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "etl",
        "unstructured-data",
        "pdf-extraction",
        "pipeline"
      ],
      "id": 671
    },
    {
      "name": "CCNet",
      "one_line_profile": "Palmprint recognition model implementation",
      "detailed_description": "Implementation of Comprehensive Competition Mechanism in Palmprint Recognition (IEEE TIFS), serving as a solver for biometric identification tasks.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "biometrics",
        "image_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zi-YuanYang/CCNet",
      "help_website": [],
      "license": null,
      "tags": [
        "palmprint-recognition",
        "computer-vision",
        "biometrics"
      ],
      "id": 672
    },
    {
      "name": "trafilatura",
      "one_line_profile": "Web scraping and text extraction tool",
      "detailed_description": "A Python and command-line tool to gather text and metadata from the Web, facilitating the creation of domain corpora through crawling, scraping, and extraction.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "web_scraping",
        "text_extraction",
        "corpus_creation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/adbar/trafilatura",
      "help_website": [
        "https://trafilatura.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "scraping",
        "text-extraction",
        "crawler",
        "nlp"
      ],
      "id": 673
    },
    {
      "name": "deidentify",
      "one_line_profile": "Tool for identifying and anonymizing personal information",
      "detailed_description": "A simple yet powerful tool for identifying and anonymizing personal information (PII) in various formats, essential for data cleaning in scientific corpora.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "pii_removal",
        "data_anonymization"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/aliengiraffe/deidentify",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pii",
        "anonymization",
        "data-privacy",
        "gdpr"
      ],
      "id": 674
    },
    {
      "name": "dolma",
      "one_line_profile": "Data curation tools for OLMo pre-training data",
      "detailed_description": "A library and toolkit for generating, inspecting, and processing large-scale pre-training data (OLMo), including deduplication and filtering pipelines.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "dataset_curation",
        "pretraining_data",
        "deduplication"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/dolma",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "dataset-curation",
        "nlp",
        "pretraining"
      ],
      "id": 675
    },
    {
      "name": "duplodocus",
      "one_line_profile": "Exact and MinHash deduplication tool for text datasets",
      "detailed_description": "Tooling for performing exact and MinHash-based deduplication on large-scale text datasets, a critical step in preparing scientific corpora for model training.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "deduplication",
        "data_cleaning"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/allenai/duplodocus",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deduplication",
        "minhash",
        "nlp",
        "rust"
      ],
      "id": 676
    },
    {
      "name": "deepfabric",
      "one_line_profile": "Platform for dataset curation and model training",
      "detailed_description": "A tool to curate high-quality datasets, train, evaluate, and ship models, providing an end-to-end workflow for AI model development.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "dataset_curation",
        "ml_workflow"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/always-further/deepfabric",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dataset-management",
        "mlops",
        "training-pipeline"
      ],
      "id": 677
    },
    {
      "name": "consimilo",
      "one_line_profile": "Clojure library for similarity querying on large datasets",
      "detailed_description": "A library for querying large datasets based on similarity (LSH/Simhash), useful for deduplication and near-duplicate detection in data pipelines.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "similarity_search",
        "deduplication"
      ],
      "application_level": "library",
      "primary_language": "Clojure",
      "repo_url": "https://github.com/andrewmcloud/consimilo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "clojure",
        "lsh",
        "simhash",
        "deduplication"
      ],
      "id": 678
    },
    {
      "name": "semlib",
      "one_line_profile": "Library for building LLM-powered data processing pipelines",
      "detailed_description": "A library to build data processing and analysis pipelines that leverage Large Language Models, facilitating complex data transformation and cleaning tasks.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_processing",
        "pipeline_construction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/anishathalye/semlib",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "data-pipeline",
        "semantic-processing"
      ],
      "id": 679
    },
    {
      "name": "pii-lib",
      "one_line_profile": "PII detection and redaction library for code datasets",
      "detailed_description": "A library designed for the BigCode project to detect and redact Personally Identifiable Information (PII) specifically in code datasets, supporting privacy compliance in LLM training.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "pii_redaction",
        "data_cleaning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bigcode-project/pii-lib",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pii",
        "redaction",
        "code-dataset",
        "llm"
      ],
      "id": 680
    },
    {
      "name": "BigScience Data Preparation",
      "one_line_profile": "Data sourcing and cleaning pipeline for the ROOTS corpus",
      "detailed_description": "A collection of scripts and notebooks used for sourcing, processing, and cleaning the BigScience ROOTS corpus, a large-scale multilingual dataset for training open science language models.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_cleaning",
        "corpus_preparation"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/bigscience-workshop/data-preparation",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bigscience",
        "roots-corpus",
        "data-cleaning",
        "nlp"
      ],
      "id": 681
    },
    {
      "name": "pdfdiff",
      "one_line_profile": "Tool to inspect text differences between PDF files",
      "detailed_description": "A command-line tool that allows users to compare the text content of two PDF files, useful for verifying data extraction fidelity or tracking changes in scientific documents.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "pdf_processing",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cascremers/pdfdiff",
      "help_website": [],
      "license": null,
      "tags": [
        "pdf",
        "diff",
        "text-extraction",
        "cli"
      ],
      "id": 682
    },
    {
      "name": "PDFeXpress",
      "one_line_profile": "PDF manipulation and extraction tool",
      "detailed_description": "A tool to handle various PDF operations such as merging, splitting, and extracting images and text, facilitating the preprocessing of PDF documents for corpus creation.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "pdf_processing",
        "text_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chianjin/PDFeXpress",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "pdf",
        "extraction",
        "preprocessing"
      ],
      "id": 683
    },
    {
      "name": "Cocoindex",
      "one_line_profile": "Incremental data transformation framework for AI",
      "detailed_description": "A high-performance framework for data transformation in AI pipelines, supporting incremental processing to efficiently handle large-scale datasets.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_transformation",
        "pipeline_orchestration"
      ],
      "application_level": "framework",
      "primary_language": "Rust",
      "repo_url": "https://github.com/cocoindex-io/cocoindex",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-pipeline",
        "incremental-processing",
        "etl",
        "rust"
      ],
      "id": 684
    },
    {
      "name": "text_dedup",
      "one_line_profile": "High-performance text deduplication toolkit",
      "detailed_description": "A toolkit designed for efficient text deduplication, essential for cleaning large language model training corpora to remove redundant data.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "deduplication",
        "data_cleaning"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/conanhujinming/text_dedup",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "deduplication",
        "nlp",
        "corpus-cleaning"
      ],
      "id": 685
    },
    {
      "name": "pdf2htmlEX",
      "one_line_profile": "High-fidelity PDF to HTML converter",
      "detailed_description": "A tool that converts PDF documents to HTML while preserving layout and typography, widely used in scientific literature parsing pipelines to extract structured data.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "pdf_processing",
        "format_conversion"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/coolwanglu/pdf2htmlEX",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "pdf-to-html",
        "parsing",
        "document-processing"
      ],
      "id": 686
    },
    {
      "name": "marimba",
      "one_line_profile": "Framework for FAIR scientific image datasets",
      "detailed_description": "A Python framework developed by CSIRO for structuring, processing, packaging, and distributing scientific image datasets in accordance with FAIR principles.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "image_processing",
        "dataset_management"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/csiro-fair/marimba",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "fair-data",
        "scientific-imaging",
        "csiro"
      ],
      "id": 687
    },
    {
      "name": "Lilac",
      "one_line_profile": "Data curation and exploration tool for LLMs",
      "detailed_description": "A tool for curating, filtering, and exploring datasets for Large Language Models, offering features for PII detection, quality filtering, and data visualization.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_curation",
        "pii_detection",
        "quality_control"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/databricks/lilac",
      "help_website": [
        "https://lilacml.com"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-curation",
        "llm",
        "visualization",
        "data-cleaning"
      ],
      "id": 688
    },
    {
      "name": "undatum",
      "one_line_profile": "CLI tool for data conversion and processing",
      "detailed_description": "A command-line utility for converting between various data formats (CSV, NDJSON, BSON, XML) and performing basic data processing tasks, useful in data pipelines.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "format_conversion",
        "data_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/datacoon/undatum",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cli",
        "data-conversion",
        "etl"
      ],
      "id": 689
    },
    {
      "name": "Haystack",
      "one_line_profile": "AI orchestration framework for LLM pipelines",
      "detailed_description": "An orchestration framework to build LLM applications, including components for data ingestion, preprocessing, cleaning, and vectorization, suitable for managing scientific corpora.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "pipeline_orchestration",
        "data_ingestion",
        "preprocessing"
      ],
      "application_level": "framework",
      "primary_language": "MDX",
      "repo_url": "https://github.com/deepset-ai/haystack",
      "help_website": [
        "https://haystack.deepset.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "llm",
        "pipeline",
        "nlp"
      ],
      "id": 690
    },
    {
      "name": "dockstring",
      "one_line_profile": "Package for molecular docking benchmarks",
      "detailed_description": "A Python package that facilitates molecular docking tasks, providing curated datasets and realistic benchmarks for drug discovery research.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "molecular_docking",
        "drug_discovery"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dockstring/dockstring",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "molecular-docking",
        "drug-discovery",
        "benchmark",
        "chemistry"
      ],
      "id": 691
    },
    {
      "name": "docling-parse",
      "one_line_profile": "PDF parsing and text extraction tool",
      "detailed_description": "A package for extracting text and coordinates from programmatic PDFs, part of the Docling ecosystem for document processing and parsing.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "pdf_parsing",
        "text_extraction"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/docling-project/docling-parse",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf",
        "parsing",
        "document-processing"
      ],
      "id": 692
    },
    {
      "name": "LSHR",
      "one_line_profile": "Locality Sensitive Hashing (LSH) library for R",
      "detailed_description": "An R implementation of Locality Sensitive Hashing (LSH) for finding similar items in large datasets, commonly used for deduplication of scientific corpora or genomic sequences.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "deduplication",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/dselivanov/LSHR",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "lsh",
        "deduplication",
        "r-package",
        "similarity-search"
      ],
      "id": 693
    },
    {
      "name": "luftdatenpumpe",
      "one_line_profile": "Tool for acquiring and processing air quality data",
      "detailed_description": "A pipeline tool to acquire, filter, process, and visualize live and historical air quality data from sources like Sensor.Community and OpenAQ, supporting time-series storage and reverse geocoding.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_acquisition",
        "data_processing",
        "environmental_science"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/earthobservations/luftdatenpumpe",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "air-quality",
        "data-pipeline",
        "earth-science",
        "etl"
      ],
      "id": 694
    },
    {
      "name": "datasketch",
      "one_line_profile": "Probabilistic data structures for big data processing",
      "detailed_description": "A Python library providing implementations of MinHash, LSH, LSH Forest, and HyperLogLog for processing and deduplicating massive datasets, widely used in scientific corpus cleaning.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "deduplication",
        "similarity_estimation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ekzhu/datasketch",
      "help_website": [
        "https://ekzhu.github.io/datasketch/"
      ],
      "license": "MIT",
      "tags": [
        "minhash",
        "lsh",
        "deduplication",
        "big-data"
      ],
      "id": 695
    },
    {
      "name": "minhash-lsh",
      "one_line_profile": "MinHash LSH implementation in Go",
      "detailed_description": "A Go library implementing MinHash and Locality Sensitive Hashing (LSH) for efficient similarity search and deduplication in large-scale data processing pipelines.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "deduplication",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/ekzhu/minhash-lsh",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "minhash",
        "lsh",
        "go",
        "deduplication"
      ],
      "id": 696
    },
    {
      "name": "Evidently",
      "one_line_profile": "ML and LLM observability and data quality framework",
      "detailed_description": "An open-source framework to evaluate, test, and monitor ML models and data pipelines, providing metrics for data drift, data quality, and model performance, essential for maintaining scientific datasets and models.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "quality_control",
        "data_drift_detection",
        "model_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/evidentlyai/evidently",
      "help_website": [
        "https://docs.evidentlyai.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-quality",
        "mlops",
        "observability",
        "drift-detection"
      ],
      "id": 697
    },
    {
      "name": "bitext-lexind",
      "one_line_profile": "Unsupervised bitext mining and lexicon induction pipeline",
      "detailed_description": "A research tool for inducing high-quality bilingual lexicons and mining bitexts from monolingual corpora using unsupervised methods, useful for constructing parallel scientific corpora.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "corpora_mining",
        "alignment",
        "nlp"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/bitext-lexind",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "bitext-mining",
        "lexicon-induction",
        "alignment"
      ],
      "id": 698
    },
    {
      "name": "Nougat",
      "one_line_profile": "Neural Optical Understanding for Academic Documents",
      "detailed_description": "A visual transformer model and tool designed to convert scientific PDF documents into structured Markdown, specifically handling mathematical formulas and academic layouts.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_extraction",
        "ocr",
        "pdf_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/nougat",
      "help_website": [
        "https://facebookresearch.github.io/nougat/"
      ],
      "license": "MIT",
      "tags": [
        "ocr",
        "pdf-to-markdown",
        "scientific-papers",
        "transformer"
      ],
      "id": 699
    },
    {
      "name": "Moira",
      "one_line_profile": "Quality filtering tool for metagenomic amplicon sequences",
      "detailed_description": "A tool for accurate quality filtering of metagenomic amplicon sequences, reducing errors in microbiome data analysis.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "quality_control",
        "bioinformatics",
        "filtering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/fpusan/moira",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "metagenomics",
        "bioinformatics",
        "quality-control",
        "amplicon"
      ],
      "id": 700
    },
    {
      "name": "OCRmyPDF",
      "one_line_profile": "Tool to add OCR text layers to scanned PDFs",
      "detailed_description": "A pipeline tool that adds an OCR text layer to scanned PDF files, enabling text search and extraction, widely used in digitizing scientific literature and archives.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_extraction",
        "ocr",
        "digitization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/fritz-hh/OCRmyPDF",
      "help_website": [
        "https://ocrmypdf.readthedocs.io/"
      ],
      "license": null,
      "tags": [
        "ocr",
        "pdf",
        "text-extraction",
        "archiving"
      ],
      "id": 701
    },
    {
      "name": "pdfocr",
      "one_line_profile": "Ruby script for PDF OCR using Cuneiform",
      "detailed_description": "A wrapper tool to add text layers to PDF files using the Cuneiform OCR software, facilitating text extraction from scanned documents.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_extraction",
        "ocr"
      ],
      "application_level": "solver",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/gkovacs/pdfocr",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ocr",
        "pdf",
        "ruby",
        "text-extraction"
      ],
      "id": 702
    },
    {
      "name": "Datatrove",
      "one_line_profile": "Large-scale data processing library for LLM training",
      "detailed_description": "A platform-agnostic library providing customizable pipeline processing blocks for filtering, deduplicating, and extracting data, specifically designed for preparing large-scale datasets for LLM training.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_pipeline",
        "deduplication",
        "filtering"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/datatrove",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-processing",
        "llm",
        "pipeline",
        "deduplication"
      ],
      "id": 703
    },
    {
      "name": "hydrobr",
      "one_line_profile": "R interface for Brazilian National Water Agency data",
      "detailed_description": "An R package to download, filter, and perform quality checks on hydrological data from the Brazilian National Water Agency (ANA), facilitating hydrological research and analysis.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_acquisition",
        "quality_control",
        "hydrology"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/hydroversebr/hydrobr",
      "help_website": [
        "https://hydroversebr.github.io/hydrobr/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "hydrology",
        "r-package",
        "data-access",
        "earth-science"
      ],
      "id": 704
    },
    {
      "name": "WordCab PII",
      "one_line_profile": "PII/PHI/PCI redaction models based on GLiNER architecture for data cleaning",
      "detailed_description": "A collection of state-of-the-art PII (Personally Identifiable Information) redaction models designed to clean sensitive data from corpora. It utilizes the GLiNER architecture to detect and redact entities, facilitating the preparation of safe scientific and medical datasets.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_cleaning",
        "pii_redaction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/info-wordcab/wordcab-pii",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pii-redaction",
        "data-cleaning",
        "nlp",
        "gliner"
      ],
      "id": 705
    },
    {
      "name": "FiftyOne Image Deduplication Plugin",
      "one_line_profile": "Plugin for FiftyOne to remove exact and approximate duplicates from image datasets",
      "detailed_description": "A plugin for the FiftyOne computer vision toolset that provides functionality to detect and remove duplicate images from datasets. It supports both exact and approximate deduplication, essential for cleaning scientific image corpora.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "deduplication",
        "data_cleaning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jacobmarks/image-deduplication-plugin",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "deduplication",
        "computer-vision",
        "data-cleaning",
        "fiftyone"
      ],
      "id": 706
    },
    {
      "name": "LLM Corpus Quality",
      "one_line_profile": "Tool for cleaning and quality assessment of large model pre-training corpora",
      "detailed_description": "A toolkit designed for the pre-processing of large language model (LLM) corpora. It includes functions for rule-based cleaning, sensitive word filtering, advertisement filtering, deduplication, and quality assessment, specifically tailored for Chinese and general text data.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_cleaning",
        "quality_control",
        "deduplication"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/jiangnanboy/llm_corpus_quality",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "corpus-cleaning",
        "data-quality",
        "llm",
        "preprocessing"
      ],
      "id": 707
    },
    {
      "name": "Arxiv Parser",
      "one_line_profile": "Tool to filter and parse publications from arXiv for corpus creation",
      "detailed_description": "A basic tool utilizing the arXiv API to filter and retrieve the latest publications. It assists researchers in creating scientific corpora by automating the collection of papers based on specific criteria.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_acquisition",
        "literature_mining"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/katjaschwarz/arxiv_parser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arxiv",
        "data-mining",
        "literature-review"
      ],
      "id": 708
    },
    {
      "name": "dpsprep",
      "one_line_profile": "DJVU to PDF converter preserving OCR text and metadata for scientific documents",
      "detailed_description": "A Python utility that converts DJVU files to PDF format while preserving the original OCR text layer and bookmark metadata (such as Table of Contents). This is particularly useful for digitizing and processing legacy scientific literature for downstream AI tasks.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_preparation",
        "format_conversion",
        "ocr_handling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kcroker/dpsprep",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "djvu",
        "pdf",
        "ocr",
        "document-conversion"
      ],
      "id": 709
    },
    {
      "name": "MarieAI",
      "one_line_profile": "Complex data extraction and orchestration framework for unstructured documents",
      "detailed_description": "A framework designed for processing unstructured documents, integrating AI-powered pipelines (GenAI, LLM, VLLM) for tasks like document cleanup, OCR, classification, and NER. Useful for creating scientific corpora from raw documents.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": "data_parsing",
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/marieai/marie-ai",
      "license": "MIT",
      "tags": [
        "ocr",
        "document-processing",
        "pipeline",
        "llm"
      ],
      "id": 710
    },
    {
      "name": "go-trafilatura",
      "one_line_profile": "Go port of the Trafilatura library for web text extraction",
      "detailed_description": "A Go implementation of the Trafilatura library, designed to extract text and metadata from web pages. Essential for building large-scale domain corpora from web sources.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": "data_extraction",
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/markusmobius/go-trafilatura",
      "license": "Apache-2.0",
      "tags": [
        "web-scraping",
        "text-extraction",
        "corpus-creation"
      ],
      "id": 711
    },
    {
      "name": "TICCL",
      "one_line_profile": "Text-Induced Corpus Clean-up tool",
      "detailed_description": "A tool for cleaning and correcting text corpora, specifically handling spelling variations and normalization. Useful for preparing high-quality NLP datasets.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": "data_cleaning",
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/martinreynaert/TICCL",
      "license": "GPL-3.0",
      "tags": [
        "corpus-cleaning",
        "nlp",
        "normalization"
      ],
      "id": 712
    },
    {
      "name": "Juicer",
      "one_line_profile": "Web API for extracting text and metadata from HTML pages",
      "detailed_description": "A Scala-based tool for extracting main text, metadata, and named entities from HTML articles. Used for gathering data for scientific corpora.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": "data_extraction",
      "application_level": "service",
      "primary_language": "Scala",
      "repo_url": "https://github.com/matth/juicer",
      "license": "MIT",
      "tags": [
        "text-extraction",
        "html-parsing",
        "corpus-creation"
      ],
      "id": 713
    },
    {
      "name": "LSH",
      "one_line_profile": "Locality Sensitive Hashing using MinHash for near-duplicate detection",
      "detailed_description": "A Python/Cython implementation of MinHash LSH to detect near-duplicate text documents. Critical for deduplicating large scientific corpora.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": "deduplication",
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mattilyra/LSH",
      "license": "MIT",
      "tags": [
        "lsh",
        "deduplication",
        "minhash",
        "text-mining"
      ],
      "id": 714
    },
    {
      "name": "prok-quality",
      "one_line_profile": "Workflow for assessing the quality of prokaryotic genomes",
      "detailed_description": "A Nextflow pipeline for filtering, dereplication, and quality assessment of prokaryotic genomes. Specifically designed for bioinformatics data processing.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": "quality_control",
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/metashot/prok-quality",
      "license": "GPL-3.0",
      "tags": [
        "bioinformatics",
        "genome-assembly",
        "quality-control",
        "nextflow"
      ],
      "id": 715
    },
    {
      "name": "ARXGEN",
      "one_line_profile": "Scripts to parse arXiv documents for NLP tasks",
      "detailed_description": "A set of scripts from Microsoft to parse and process arXiv LaTeX source files, extracting figures, tables, and text for training NLP models.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": "data_parsing",
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/ARXGEN",
      "license": "MIT",
      "tags": [
        "arxiv",
        "latex-parsing",
        "nlp",
        "corpus-creation"
      ],
      "id": 716
    },
    {
      "name": "NGSQCToolkit",
      "one_line_profile": "Toolkit for quality check and filtering of NGS data",
      "detailed_description": "A toolkit for quality control and filtering of Next Generation Sequencing (NGS) data from Roche and Illumina platforms. Essential for bioinformatics data preprocessing.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": "quality_control",
      "application_level": "solver",
      "primary_language": "Perl",
      "repo_url": "https://github.com/mjain-lab/NGSQCToolkit",
      "help_website": [
        "http://www.nipgr.res.in/ngsqctoolkit.html"
      ],
      "license": null,
      "tags": [
        "ngs",
        "bioinformatics",
        "quality-control",
        "filtering"
      ],
      "id": 717
    },
    {
      "name": "pdf2json",
      "one_line_profile": "Converts binary PDF to JSON and text",
      "detailed_description": "A tool to convert PDF documents into JSON format, enabling server-side processing and text extraction. Widely used in pipelines to parse scientific literature.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": "data_parsing",
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/modesty/pdf2json",
      "license": "NOASSERTION",
      "tags": [
        "pdf-parsing",
        "text-extraction",
        "json"
      ],
      "id": 718
    },
    {
      "name": "comparable-text-miner",
      "one_line_profile": "Miner for comparable Arabic-English documents and corpus processing",
      "detailed_description": "A tool for mining comparable documents, performing morphological analysis, POS tagging, and corpus cleaning/alignment. Useful for creating multilingual scientific corpora.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": "data_alignment",
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/motazsaad/comparable-text-miner",
      "license": "Apache-2.0",
      "tags": [
        "text-mining",
        "nlp",
        "corpus-alignment",
        "arabic"
      ],
      "id": 719
    },
    {
      "name": "MinerU",
      "one_line_profile": "Transforms complex documents like PDFs into LLM-ready markdown/JSON",
      "detailed_description": "A comprehensive tool for extracting content from complex documents (PDFs, etc.) and converting them into clean Markdown or JSON formats suitable for LLM training and RAG workflows.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": "data_parsing",
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/opendatalab/MinerU",
      "license": "AGPL-3.0",
      "tags": [
        "pdf-parsing",
        "llm-data",
        "markdown-conversion",
        "rag"
      ],
      "id": 720
    },
    {
      "name": "MinerU-HTML",
      "one_line_profile": "SLM-powered HTML main content extractor",
      "detailed_description": "A tool that uses Small Language Models (SLM) to extract main content from HTML pages, outputting clean HTML bodies. Designed for deep research agents and training data generation.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": "data_extraction",
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/opendatalab/MinerU-HTML",
      "license": "Apache-2.0",
      "tags": [
        "html-extraction",
        "web-scraping",
        "slm"
      ],
      "id": 721
    },
    {
      "name": "open-semantic-etl",
      "one_line_profile": "ETL tools for file crawling, text extraction, and content analysis",
      "detailed_description": "A Python-based ETL toolkit for processing documents (text extraction, OCR) and performing content analysis (NER, Entity Extraction). Used to enrich data for search indices and knowledge graphs.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": "data_processing",
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/opensemanticsearch/open-semantic-etl",
      "license": "GPL-3.0",
      "tags": [
        "etl",
        "ocr",
        "ner",
        "text-extraction"
      ],
      "id": 722
    },
    {
      "name": "open-semantic-search",
      "one_line_profile": "Semantic Search Engine and Text Mining platform",
      "detailed_description": "An integrated research tool for searching and analyzing large document collections. Combines ETL, OCR, NER, and a search UI to facilitate semantic exploration of scientific or unstructured data.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": "data_analysis",
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/opensemanticsearch/open-semantic-search",
      "license": "GPL-3.0",
      "tags": [
        "semantic-search",
        "text-mining",
        "knowledge-graph"
      ],
      "id": 723
    },
    {
      "name": "modis_restservice_qc_filter_Python",
      "one_line_profile": "Access and quality filter MODIS data",
      "detailed_description": "A tool from ORNL DAAC to access MODIS web services and perform quality filtering on the retrieved earth science data.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": "quality_control",
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ornldaac/modis_restservice_qc_filter_Python",
      "license": "NOASSERTION",
      "tags": [
        "earth-science",
        "modis",
        "quality-control",
        "data-access"
      ],
      "id": 724
    },
    {
      "name": "Phileas",
      "one_line_profile": "Engine for PII and PHI redaction and de-identification",
      "detailed_description": "A configuration-based engine for identifying and redacting sensitive information (PII/PHI) from text data. It supports various filter strategies and is essential for cleaning research corpora containing sensitive human data.",
      "domains": [
        "AI3-03",
        "AI3"
      ],
      "subtask_category": [
        "pii_redaction",
        "data_cleaning"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/philterd/phileas",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pii-redaction",
        "de-identification",
        "nlp"
      ],
      "id": 725
    },
    {
      "name": "Philter",
      "one_line_profile": "Command-line tool and library for text redaction",
      "detailed_description": "A tool designed to redact Personally Identifiable Information (PII) and Protected Health Information (PHI) from text. It serves as a component in data cleaning pipelines for preparing privacy-compliant datasets.",
      "domains": [
        "AI3-03",
        "AI3"
      ],
      "subtask_category": [
        "pii_redaction",
        "data_cleaning"
      ],
      "application_level": "solver",
      "primary_language": "CSS",
      "repo_url": "https://github.com/philterd/philter",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "redaction",
        "privacy",
        "data-cleaning"
      ],
      "id": 726
    },
    {
      "name": "pvanalytics",
      "one_line_profile": "Quality control and feature labeling for photovoltaic data",
      "detailed_description": "A library providing functions for quality control, filtering, and feature labeling of data from photovoltaic energy systems. It supports scientific analysis of energy production data through rigorous data cleaning and validation methods.",
      "domains": [
        "AI3-03",
        "AI3"
      ],
      "subtask_category": [
        "quality_control",
        "filtering",
        "feature_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pvlib/pvanalytics",
      "help_website": [
        "https://pvanalytics.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "photovoltaic",
        "quality-control",
        "energy-data"
      ],
      "id": 727
    },
    {
      "name": "FastSketchLSH",
      "one_line_profile": "High-performance LSH-based deduplication for large text corpora",
      "detailed_description": "A C++ implementation of FastSketch and MinHash-based Jaccard estimators using Locality Sensitive Hashing (LSH). It is designed to efficiently deduplicate extremely large text corpora, a critical step in training large language models.",
      "domains": [
        "AI3-03",
        "AI3"
      ],
      "subtask_category": [
        "deduplication",
        "hashing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/pzcddm/FastSketchLSH",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "deduplication",
        "lsh",
        "minhash",
        "nlp"
      ],
      "id": 728
    },
    {
      "name": "Filtlong",
      "one_line_profile": "Quality filtering tool for long-read sequencing data",
      "detailed_description": "A tool for filtering long sequencing reads (e.g., Nanopore, PacBio) based on quality and length. It is essential for quality control in genomics data pipelines to ensure high-quality input for downstream assembly or analysis.",
      "domains": [
        "AI3-03",
        "AI3"
      ],
      "subtask_category": [
        "quality_control",
        "filtering"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/rrwick/Filtlong",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bioinformatics",
        "long-reads",
        "quality-control"
      ],
      "id": 729
    },
    {
      "name": "docconv",
      "one_line_profile": "Library for converting documents to plain text",
      "detailed_description": "A Go library that converts various document formats (PDF, DOCX, HTML, etc.) into plain text. It is widely used in data ingestion pipelines to extract raw text from heterogeneous document sources for NLP tasks.",
      "domains": [
        "AI3-03",
        "AI3"
      ],
      "subtask_category": [
        "document_parsing",
        "text_extraction"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/sajari/docconv",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "document-conversion",
        "pdf-parsing",
        "text-extraction"
      ],
      "id": 730
    },
    {
      "name": "openredaction",
      "one_line_profile": "Local PII detection and redaction library",
      "detailed_description": "A TypeScript library for detecting and redacting Personally Identifiable Information (PII) locally. It provides high-performance, privacy-preserving data cleaning capabilities for text processing pipelines.",
      "domains": [
        "AI3-03",
        "AI3"
      ],
      "subtask_category": [
        "pii_redaction",
        "data_cleaning"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/sam247/openredaction",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pii",
        "redaction",
        "privacy"
      ],
      "id": 731
    },
    {
      "name": "doc_redaction",
      "one_line_profile": "GUI tool for document redaction",
      "detailed_description": "A Python-based tool with a graphical interface for redacting sensitive information from PDF, Word, and Excel files. It facilitates the manual or semi-automated cleaning of document datasets.",
      "domains": [
        "AI3-03",
        "AI3"
      ],
      "subtask_category": [
        "pii_redaction",
        "data_cleaning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/seanpedrick-case/doc_redaction",
      "help_website": [
        "https://huggingface.co/spaces/seanpedrickcase/document_redaction"
      ],
      "license": null,
      "tags": [
        "redaction",
        "document-processing",
        "gui"
      ],
      "id": 732
    },
    {
      "name": "gaoya",
      "one_line_profile": "Locality Sensitive Hashing (LSH) library in Rust",
      "detailed_description": "A Rust implementation of Locality Sensitive Hashing (LSH) algorithms, including MinHash and SimHash. It is a core building block for developing high-performance deduplication and similarity search tools for large-scale datasets.",
      "domains": [
        "AI3-03",
        "AI3"
      ],
      "subtask_category": [
        "deduplication",
        "hashing"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/serega/gaoya",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lsh",
        "minhash",
        "deduplication",
        "rust"
      ],
      "id": 733
    },
    {
      "name": "Text-file-to-handwritten-pdf-file",
      "one_line_profile": "Synthetic handwritten data generator",
      "detailed_description": "A tool that converts digital text files into simulated handwritten PDF documents. It is useful for generating synthetic training data for Optical Character Recognition (OCR) and handwriting analysis models.",
      "domains": [
        "AI3-03",
        "AI3"
      ],
      "subtask_category": [
        "data_synthesis",
        "data_augmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sharanya02/Text-file-to-handwritten-pdf-file",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "synthetic-data",
        "ocr",
        "handwriting-generation"
      ],
      "id": 734
    },
    {
      "name": "dupandas",
      "one_line_profile": "Flexible deduplication for pandas DataFrames",
      "detailed_description": "A Python package designed for performing deduplication on pandas DataFrames using flexible text matching and cleaning strategies. It simplifies the data cleaning process for tabular datasets.",
      "domains": [
        "AI3-03",
        "AI3"
      ],
      "subtask_category": [
        "deduplication",
        "data_cleaning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shivam5992/dupandas",
      "help_website": [],
      "license": null,
      "tags": [
        "pandas",
        "deduplication",
        "data-cleaning"
      ],
      "id": 735
    },
    {
      "name": "markdrop",
      "one_line_profile": "PDF to Markdown converter with LLM-based enrichment",
      "detailed_description": "A pipeline tool for converting PDF documents to Markdown format while extracting images and tables. It integrates with LLMs to generate descriptive text for extracted visual elements, enhancing the quality of data for RAG or training corpora.",
      "domains": [
        "AI3-03",
        "AI3"
      ],
      "subtask_category": [
        "document_parsing",
        "data_enrichment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shoryasethia/markdrop",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pdf-to-markdown",
        "llm",
        "data-extraction"
      ],
      "id": 736
    },
    {
      "name": "PREQUAL",
      "one_line_profile": "Pre-alignment quality filter for comparative sequence analysis",
      "detailed_description": "A tool for filtering non-homologous residues from unaligned sequences. It is used in bioinformatics pipelines to improve the quality of multiple sequence alignments by removing noise prior to alignment.",
      "domains": [
        "AI3-03",
        "AI3"
      ],
      "subtask_category": [
        "quality_control",
        "filtering"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/simonwhelan/prequal",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bioinformatics",
        "sequence-analysis",
        "quality-control"
      ],
      "id": 737
    },
    {
      "name": "UltimateKalman",
      "one_line_profile": "High-quality polymorphic implementations of Kalman filters and smoothers",
      "detailed_description": "A library providing implementations of Square-Root Kalman filters and smoothers in MATLAB, C, and Java. It is designed for scientific estimation and signal processing tasks, offering consistent APIs across languages.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "estimation",
        "signal_processing"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/sivantoledo/ultimate-kalman",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "kalman-filter",
        "estimation",
        "signal-processing"
      ],
      "id": 738
    },
    {
      "name": "slncky",
      "one_line_profile": "lncRNA discovery and filtering tool from RNA-Seq data",
      "detailed_description": "A bioinformatics tool for filtering high-quality noncoding transcripts, discovering lncRNA orthologs, and characterizing conserved lncRNA evolution from RNA-Seq data.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "bioinformatics_analysis",
        "filtering"
      ],
      "application_level": "solver",
      "primary_language": "CSS",
      "repo_url": "https://github.com/slncky/slncky",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lncrna",
        "rna-seq",
        "bioinformatics"
      ],
      "id": 739
    },
    {
      "name": "Splunk Attack Data",
      "one_line_profile": "Curated datasets of various security attacks for simulation and testing",
      "detailed_description": "A repository containing curated datasets generated from various simulated attacks. It serves as a domain corpus for training and testing security analytics and machine learning models.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "dataset_generation",
        "simulation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/splunk/attack_data",
      "help_website": [
        "https://attack.splunk.com"
      ],
      "license": "Apache-2.0",
      "tags": [
        "security-dataset",
        "attack-simulation",
        "corpus"
      ],
      "id": 740
    },
    {
      "name": "minhashcuda",
      "one_line_profile": "Weighted MinHash implementation on CUDA for multi-GPU",
      "detailed_description": "A high-performance implementation of Weighted MinHash using CUDA, designed for fast deduplication and similarity estimation on large datasets using multiple GPUs.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "deduplication",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/src-d/minhashcuda",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "minhash",
        "cuda",
        "deduplication"
      ],
      "id": 741
    },
    {
      "name": "STORM",
      "one_line_profile": "LLM-powered knowledge curation and research system",
      "detailed_description": "An LLM-powered system that automates the research process by researching a topic and generating full-length reports with citations, aiding in knowledge curation and scientific literature review.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "knowledge_curation",
        "literature_review"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanford-oval/storm",
      "help_website": [
        "https://storm.genie.stanford.edu"
      ],
      "license": "MIT",
      "tags": [
        "llm",
        "research-assistant",
        "knowledge-curation"
      ],
      "id": 742
    },
    {
      "name": "German Wikipedia Text Corpus",
      "one_line_profile": "Cleaned and preprocessed German Wikipedia corpus for NLP",
      "detailed_description": "A cleaned, preprocessed, and sentence-split German text corpus derived from Wikipedia, intended for training NLP embeddings like fastText or ELMo.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "corpus_preparation",
        "nlp_training"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/t-systems-on-site-services-gmbh/german-wikipedia-text-corpus",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "corpus",
        "nlp",
        "german-wikipedia"
      ],
      "id": 743
    },
    {
      "name": "slate",
      "one_line_profile": "Python library for extracting text from PDFs",
      "detailed_description": "A Python library that simplifies the process of extracting text from PDF documents, wrapping the PDFMiner library for easier use in data processing pipelines.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "text_extraction",
        "data_cleaning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/timClicks/slate",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pdf-extraction",
        "text-mining",
        "python"
      ],
      "id": 744
    },
    {
      "name": "RedPajama-Data",
      "one_line_profile": "Code for preparing large-scale datasets for LLM training",
      "detailed_description": "A repository containing code and workflows for preparing, cleaning, and deduplicating large-scale datasets (RedPajama) used for training large language models.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "dataset_preparation",
        "deduplication"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/togethercomputer/RedPajama-Data",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-dataset",
        "data-pipeline",
        "redpajama"
      ],
      "id": 745
    },
    {
      "name": "Towhee",
      "one_line_profile": "Framework for neural data processing pipelines",
      "detailed_description": "A framework dedicated to making neural data processing pipelines simple and fast, supporting tasks like embedding generation, ETL for unstructured data, and multimodal processing.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_pipeline",
        "embedding_generation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/towhee-io/towhee",
      "help_website": [
        "https://towhee.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "etl",
        "neural-pipeline",
        "unstructured-data"
      ],
      "id": 746
    },
    {
      "name": "Upgini",
      "one_line_profile": "Data search and enrichment library for Machine Learning",
      "detailed_description": "A library for automating data search and enrichment for machine learning pipelines. It helps find and add relevant features from external data sources to improve model accuracy.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "feature_enrichment",
        "data_augmentation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/upgini/upgini",
      "help_website": [
        "https://upgini.com"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "feature-engineering",
        "data-enrichment",
        "automl"
      ],
      "id": 747
    },
    {
      "name": "NIST OCR Pipeline",
      "one_line_profile": "Distributed pipeline for converting PDF corpora to clean text",
      "detailed_description": "A tool developed by NIST to convert a corpus of PDF documents into clean text files using a distributed architecture, facilitating the creation of scientific text corpora.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "ocr",
        "text_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/usnistgov/ocr-pipeline",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ocr",
        "pdf-processing",
        "nist"
      ],
      "id": 748
    },
    {
      "name": "Superpipe",
      "one_line_profile": "Optimized LLM pipelines for structured data extraction",
      "detailed_description": "A library for building optimized pipelines that use LLMs to extract structured data from unstructured sources, focusing on efficiency and accuracy in data processing workflows.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_extraction",
        "pipeline_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/villagecomputing/superpipe",
      "help_website": [
        "https://superpipe.ai"
      ],
      "license": "NOASSERTION",
      "tags": [
        "llm-pipeline",
        "structured-data",
        "extraction"
      ],
      "id": 749
    },
    {
      "name": "hotpdf",
      "one_line_profile": "Fast PDF parsing and text extraction library",
      "detailed_description": "A fast PDF parsing library built on top of pdfminer.six, designed to extract text and find text coordinates within PDF documents, useful for data ingestion pipelines.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "text_extraction",
        "pdf_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/weareprestatech/hotpdf",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-parser",
        "text-extraction",
        "python"
      ],
      "id": 750
    },
    {
      "name": "GROOT",
      "one_line_profile": "Resistome profiler for metagenomic data",
      "detailed_description": "A tool for graphing resistance out of metagenomes (GROOT). It is a resistome profiler that uses variation graphs to index and align reads to antimicrobial resistance genes.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "bioinformatics_analysis",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/will-rowe/groot",
      "help_website": [
        "https://groot-documentation.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "metagenomics",
        "bioinformatics",
        "resistome"
      ],
      "id": 751
    },
    {
      "name": "faster-nougat",
      "one_line_profile": "Optimized local implementation of the Nougat model for scientific PDF parsing",
      "detailed_description": "A highly efficient, local implementation of the Nougat (Neural Optical Understanding for Academic Documents) model. It is designed to convert scientific PDF documents into lightweight Markdown formats, accurately preserving mathematical formulas, tables, and citations, which is a critical step in building high-quality scientific corpora.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "data_extraction",
        "document_parsing",
        "ocr"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhuzilin/faster-nougat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-parsing",
        "scientific-papers",
        "nougat",
        "ocr",
        "markdown"
      ],
      "id": 752
    },
    {
      "name": "lazy-astroph",
      "one_line_profile": "Automated parser and notifier for arXiv Astrophysics papers",
      "detailed_description": "A workflow automation tool for researchers in Astrophysics. It parses the daily arXiv astro-ph feed, filters papers based on user-defined keywords, and delivers relevant results via email or Slack, facilitating efficient literature tracking and data collection.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "literature_mining",
        "data_collection"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/zingale/lazy-astroph",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "arxiv",
        "astrophysics",
        "literature-search",
        "automation"
      ],
      "id": 753
    },
    {
      "name": "GraphRAG Agent",
      "one_line_profile": "Integrated framework for GraphRAG construction and custom evaluation",
      "detailed_description": "A comprehensive tool that integrates GraphRAG, LightRAG, and Neo4j for knowledge graph construction and search. It includes a custom evaluation framework specifically designed for assessing GraphRAG performance, making it relevant for model evaluation and retrieval robustness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "knowledge_graph_construction",
        "retrieval_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/1517005260/graph-rag-agent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "graphrag",
        "evaluation",
        "neo4j"
      ],
      "id": 754
    },
    {
      "name": "Prompt Injection Generator",
      "one_line_profile": "Generator for prompt injection attacks to test model robustness",
      "detailed_description": "A tool designed to generate prompt injection payloads. It serves as a red teaming utility to test the robustness of Large Language Models against adversarial inputs.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming",
        "adversarial_attack_generation",
        "robustness_testing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/1celand/prompt-injection-generator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-injection",
        "red-teaming",
        "security"
      ],
      "id": 755
    },
    {
      "name": "Indic-Bias",
      "one_line_profile": "Benchmark for evaluating fairness of LLMs in Indian contexts",
      "detailed_description": "A comprehensive benchmark and evaluation suite designed to assess the fairness and bias of Large Language Models specifically within Indian cultural and linguistic contexts. Developed by AI4Bharat.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "bias_evaluation",
        "fairness_benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/AI4Bharat/indic-bias",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bias",
        "fairness",
        "llm-evaluation",
        "indic-languages"
      ],
      "id": 756
    },
    {
      "name": "AISBench Benchmark",
      "one_line_profile": "Model evaluation tool extending OpenCompass for service-based models",
      "detailed_description": "A model evaluation tool built upon the OpenCompass framework. It maintains compatibility with OpenCompass's configuration and datasets while extending support for evaluating service-based models, facilitating standardized benchmarking.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "performance_benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AISBench/benchmark",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "opencompass",
        "model-evaluation"
      ],
      "id": 757
    },
    {
      "name": "Agenta",
      "one_line_profile": "Open-source LLMOps platform for prompt management and evaluation",
      "detailed_description": "A platform for LLM operations that provides tools for prompt management, experimentation, and systematic evaluation of LLM applications. It enables researchers and developers to test and benchmark model performance.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "prompt_engineering",
        "llm_ops"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Agenta-AI/agenta",
      "help_website": [
        "https://agenta.ai"
      ],
      "license": "NOASSERTION",
      "tags": [
        "llmops",
        "evaluation",
        "prompt-management"
      ],
      "id": 758
    },
    {
      "name": "Strata-Sword",
      "one_line_profile": "Hierarchical Chinese-English jailbreak safety benchmark",
      "detailed_description": "A safety benchmark developed by Alibaba-AAIG that evaluates the robustness of LLMs against jailbreak attacks. It uses 'reasoning complexity' as a dimension to assess safety boundaries in both Chinese and English contexts.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "jailbreak_testing",
        "robustness_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Alibaba-AAIG/Strata-Sword",
      "help_website": [],
      "license": null,
      "tags": [
        "jailbreak",
        "safety",
        "benchmark",
        "llm"
      ],
      "id": 759
    },
    {
      "name": "ALERT",
      "one_line_profile": "Benchmark for assessing LLM safety through red teaming",
      "detailed_description": "A comprehensive benchmark designed to assess the safety of Large Language Models through red teaming methodologies. It provides a framework for evaluating model responses to adversarial and harmful inputs.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "red_teaming",
        "robustness_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Babelscape/ALERT",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "red-teaming",
        "safety",
        "benchmark",
        "llm"
      ],
      "id": 760
    },
    {
      "name": "PromptInjectionBench",
      "one_line_profile": "Benchmark for prompt injection attacks against LLMs",
      "detailed_description": "A benchmarking tool for evaluating the robustness of various Large Language Models (including GPT-4, Gemini, Azure) against prompt injection attacks and jailbreak attempts.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_injection_testing",
        "robustness_benchmarking",
        "red_teaming"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/BenderScript/PromptInjectionBench",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prompt-injection",
        "benchmark",
        "security"
      ],
      "id": 761
    },
    {
      "name": "ko-lm-evaluation-harness",
      "one_line_profile": "Evaluation harness for Korean Large Language Models",
      "detailed_description": "A fork of the EleutherAI lm-evaluation-harness, specifically adapted for evaluating Korean Large Language Models. It provides a standardized framework for benchmarking Korean language understanding and generation capabilities.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "language_specific_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Beomi/ko-lm-evaluation-harness",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation",
        "korean",
        "llm",
        "benchmark"
      ],
      "id": 762
    },
    {
      "name": "HonestyMeter",
      "one_line_profile": "NLP framework for evaluating objectivity and bias in media",
      "detailed_description": "An NLP-powered framework designed to evaluate objectivity and detect bias in text content. It identifies manipulative techniques and provides feedback, serving as a tool for analyzing model outputs or training data for fairness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "bias_evaluation",
        "objectivity_analysis",
        "fairness_testing"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/BetterForAll/HonestyMeter",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bias-detection",
        "nlp",
        "fairness",
        "evaluation"
      ],
      "id": 763
    },
    {
      "name": "prompt-injector",
      "one_line_profile": "Library for research-informed prompt injection attacks",
      "detailed_description": "A TypeScript library that implements various research-informed prompt injection attack patterns. It is designed to help developers and researchers test the vulnerability of their LLM applications to prompt injection.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_injection_testing",
        "red_teaming",
        "vulnerability_assessment"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/BlueprintLabIO/prompt-injector",
      "help_website": [],
      "license": null,
      "tags": [
        "prompt-injection",
        "security",
        "testing"
      ],
      "id": 764
    },
    {
      "name": "Spell Whisperer",
      "one_line_profile": "Platform for prompt injection challenges and red teaming",
      "detailed_description": "A platform designed for prompt injection challenges, serving as a gamified environment for red teaming and understanding LLM vulnerabilities. It facilitates the collection of adversarial prompts and testing of model robustness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming",
        "prompt_injection_challenges",
        "robustness_training"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/CX330Blake/Spell-Whisperer",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "prompt-injection",
        "red-teaming",
        "ctf"
      ],
      "id": 765
    },
    {
      "name": "OmniVerifier",
      "one_line_profile": "Generative Universal Verifier as Multimodal Meta-Reasoner",
      "detailed_description": "A framework serving as a generative universal verifier, utilizing multimodal meta-reasoning to enhance the verification process of AI models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_verification",
        "reasoning_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Cominclip/OmniVerifier",
      "help_website": [],
      "license": null,
      "tags": [
        "verification",
        "multimodal",
        "meta-reasoning"
      ],
      "id": 766
    },
    {
      "name": "NormalyzerDE",
      "one_line_profile": "Tools for normalization and differential expression analysis of omics data",
      "detailed_description": "A framework for normalization, outlier evaluation, technical bias assessment, batch effect handling, and differential expression analysis in proteomics and other omics data.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "normalization",
        "differential_expression",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/ComputationalProteomics/NormalyzerDE",
      "help_website": [],
      "license": null,
      "tags": [
        "proteomics",
        "normalization",
        "differential-expression",
        "r-package"
      ],
      "id": 767
    },
    {
      "name": "CartAI",
      "one_line_profile": "Open-source AI supervisor agent for lifecycle oversight and compliance",
      "detailed_description": "An intelligent agent designed for end-to-end oversight and compliance in the AI lifecycle, ensuring trustworthy AI development and deployment.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "ai_governance",
        "compliance_checking",
        "model_monitoring"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ContrastoAI/cartai",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-safety",
        "compliance",
        "agent",
        "trustworthy-ai"
      ],
      "id": 768
    },
    {
      "name": "DeepRobust",
      "one_line_profile": "PyTorch adversarial library for attack and defense on images and graphs",
      "detailed_description": "A comprehensive PyTorch library for adversarial attacks and defenses, covering both image processing and graph neural networks to evaluate and improve model robustness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "adversarial_defense",
        "robustness_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DSE-MSU/DeepRobust",
      "help_website": [
        "https://deeprobust.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "adversarial-learning",
        "pytorch",
        "graph-neural-networks",
        "robustness"
      ],
      "id": 769
    },
    {
      "name": "DreamLayer",
      "one_line_profile": "Benchmarking and evaluation automation for diffusion models",
      "detailed_description": "A tool to automate evaluations, seed management, and metric calculation for benchmarking diffusion models, ensuring reproducible results.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_benchmarking",
        "evaluation_automation",
        "reproducibility"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/DreamLayer-AI/DreamLayer",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "diffusion-models",
        "benchmarking",
        "evaluation"
      ],
      "id": 770
    },
    {
      "name": "lm-evaluation-harness",
      "one_line_profile": "Framework for few-shot evaluation of language models",
      "detailed_description": "A widely used framework for evaluating autoregressive language models on a large number of tasks, supporting few-shot evaluation and providing a standardized interface for model comparison.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "few_shot_testing",
        "benchmark_suite"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/EleutherAI/lm-evaluation-harness",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "evaluation",
        "nlp",
        "benchmark"
      ],
      "id": 771
    },
    {
      "name": "JamAIBase",
      "one_line_profile": "Collaborative spreadsheet interface for AI pipeline creation and evaluation",
      "detailed_description": "A platform that combines a spreadsheet interface with AI capabilities, allowing users to chain cells into pipelines, experiment with prompts, and evaluate LLM responses in real-time.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_engineering",
        "response_evaluation",
        "pipeline_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/EmbeddedLLM/JamAIBase",
      "help_website": [
        "https://jamaibase.com"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-ops",
        "spreadsheet-ui",
        "evaluation",
        "collaboration"
      ],
      "id": 772
    },
    {
      "name": "Cognitive-Hijacking-in-Long-Context-LLMs",
      "one_line_profile": "Implementation of prompt injection via forged internal states",
      "detailed_description": "A research tool demonstrating a novel prompt injection method that exploits forged internal states in long-context Large Language Models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming",
        "prompt_injection",
        "vulnerability_research"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Eric-Terminal/Cognitive-Hijacking-in-Long-Context-LLMs",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "prompt-injection",
        "llm-security",
        "exploit"
      ],
      "id": 773
    },
    {
      "name": "universal-triggers",
      "one_line_profile": "Universal Adversarial Triggers for Attacking and Analyzing NLP",
      "detailed_description": "Code for generating universal adversarial triggers that can cause specific predictions when concatenated to any input, used for analyzing NLP model robustness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_analysis",
        "nlp_security"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Eric-Wallace/universal-triggers",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "adversarial-nlp",
        "triggers",
        "robustness"
      ],
      "id": 774
    },
    {
      "name": "xai",
      "one_line_profile": "Explainability toolbox for machine learning",
      "detailed_description": "A library designed to provide explainability and fairness analysis for machine learning models, helping to evaluate model behavior and detect bias.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "explainability",
        "fairness_evaluation",
        "model_interpretation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EthicalML/xai",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "explainable-ai",
        "fairness",
        "machine-learning"
      ],
      "id": 775
    },
    {
      "name": "OpenFed",
      "one_line_profile": "Comprehensive Federated Learning Framework",
      "detailed_description": "A versatile open-source framework for federated learning, enabling distributed model training and evaluation while preserving data privacy.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "federated_learning",
        "distributed_training",
        "privacy_preserving_ml"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/FederalLab/OpenFed",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "federated-learning",
        "privacy",
        "distributed-systems"
      ],
      "id": 776
    },
    {
      "name": "LLMZoo",
      "one_line_profile": "Data, models, and evaluation benchmark for LLMs",
      "detailed_description": "A project providing a collection of instruction-tuned models, datasets, and evaluation benchmarks to facilitate research and development of Large Language Models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_benchmarking",
        "instruction_tuning",
        "dataset_provision"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/FreedomIntelligence/LLMZoo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "benchmark",
        "instruction-tuning"
      ],
      "id": 777
    },
    {
      "name": "LRV-Instruction",
      "one_line_profile": "Mitigating Hallucination in Large Multi-Modal Models",
      "detailed_description": "Code and resources for robust instruction tuning aimed at mitigating hallucinations in Large Multi-Modal Models (LMMs).",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_mitigation",
        "instruction_tuning",
        "robustness"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FuxiaoLiu/LRV-Instruction",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "multimodal",
        "hallucination",
        "instruction-tuning"
      ],
      "id": 778
    },
    {
      "name": "LLM-Check",
      "one_line_profile": "Detection of Hallucinations in Large Language Models",
      "detailed_description": "Implementation of methods for investigating and detecting hallucinations in Large Language Models, as presented at NeurIPS 2024.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/GaurangSriramanan/LLM_Check_Hallucination_Detection",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hallucination",
        "llm",
        "neurips-2024"
      ],
      "id": 779
    },
    {
      "name": "mcp-guard",
      "one_line_profile": "Security tool for Model Context Protocol (MCP) clients",
      "detailed_description": "A security tool designed to protect Model Context Protocol (MCP) clients from prompt injection attacks and other vulnerabilities.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_injection_defense",
        "client_security",
        "ai_protocol_security"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/General-Analysis/mcp-guard",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "prompt-injection",
        "security"
      ],
      "id": 780
    },
    {
      "name": "giskard-client",
      "one_line_profile": "API Client for Giskard AI evaluation platform",
      "detailed_description": "The Python client library for interacting with the Giskard platform, enabling programmatic control over AI model testing and evaluation workflows.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_testing",
        "evaluation_workflow",
        "api_client"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Giskard-AI/giskard-client",
      "help_website": [
        "https://docs.giskard.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "giskard",
        "testing",
        "client-library"
      ],
      "id": 781
    },
    {
      "name": "giskard-hub",
      "one_line_profile": "SDK for Giskard Enterprise platform",
      "detailed_description": "SDK for the Giskard Hub, facilitating enterprise-level LLM agent testing, team collaboration, and continuous red teaming.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming",
        "collaborative_testing",
        "enterprise_sdk"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Giskard-AI/giskard-hub",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "giskard",
        "enterprise",
        "red-teaming"
      ],
      "id": 782
    },
    {
      "name": "giskard-oss",
      "one_line_profile": "Open-Source Evaluation & Testing library for LLM Agents",
      "detailed_description": "A comprehensive open-source library for testing and evaluating LLM agents and AI models, focusing on detecting vulnerabilities, hallucinations, and performance issues.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_testing",
        "vulnerability_scanning",
        "quality_assurance"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Giskard-AI/giskard-oss",
      "help_website": [
        "https://docs.giskard.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-testing",
        "evaluation",
        "quality-assurance"
      ],
      "id": 783
    },
    {
      "name": "giskard-vision",
      "one_line_profile": "Evaluation & Testing for Computer Vision AI systems",
      "detailed_description": "A specialized module within the Giskard ecosystem for evaluating and testing computer vision models for robustness and correctness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "computer_vision_testing",
        "robustness_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Giskard-AI/giskard-vision",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "computer-vision",
        "testing",
        "giskard"
      ],
      "id": 784
    },
    {
      "name": "phare",
      "one_line_profile": "LLM benchmark for security and safety dimensions",
      "detailed_description": "A benchmark suite designed to evaluate Large Language Models across key dimensions of AI security and safety.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "security_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Giskard-AI/phare",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "ai-safety",
        "llm"
      ],
      "id": 785
    },
    {
      "name": "prompt-injections",
      "one_line_profile": "Collection of prompt injections for AI scanning",
      "detailed_description": "A dataset and collection of prompt injection patterns used by the Giskard Scan tool to test LLMs for security vulnerabilities.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_injection_testing",
        "security_dataset"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Giskard-AI/prompt-injections",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-injection",
        "dataset",
        "security"
      ],
      "id": 786
    },
    {
      "name": "Knowledge-Constrained-Decoding",
      "one_line_profile": "Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection",
      "detailed_description": "Implementation of the KCTS method for decoding in language models, incorporating token-level hallucination detection to improve factual accuracy.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "decoding_strategy",
        "hallucination_detection",
        "factuality"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUST-KnowComp/Knowledge-Constrained-Decoding",
      "help_website": [],
      "license": null,
      "tags": [
        "decoding",
        "hallucination",
        "nlp"
      ],
      "id": 787
    },
    {
      "name": "Graph Adversarial Attack",
      "one_line_profile": "Library for adversarial attacks on graph structured data",
      "detailed_description": "A Python library providing implementations of various adversarial attack methods specifically designed for Graph Neural Networks (GNNs), enabling robustness evaluation of graph-based models in scientific domains like chemistry and biology.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Hanjun-Dai/graph_adversarial_attack",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-neural-networks",
        "adversarial-attacks",
        "robustness"
      ],
      "id": 788
    },
    {
      "name": "PGD-pytorch",
      "one_line_profile": "PyTorch implementation of Projected Gradient Descent (PGD) attacks",
      "detailed_description": "A focused implementation of the Projected Gradient Descent (PGD) adversarial attack method in PyTorch, widely used as a standard baseline for evaluating the robustness of deep learning models against adversarial perturbations.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Harry24k/PGD-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "adversarial-attacks",
        "pgd"
      ],
      "id": 789
    },
    {
      "name": "TorchAttacks",
      "one_line_profile": "Comprehensive PyTorch library for adversarial attacks",
      "detailed_description": "A lightweight and comprehensive PyTorch library providing a wide range of adversarial attack algorithms (FGSM, PGD, CW, etc.) to evaluate the robustness of neural networks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Harry24k/adversarial-attacks-pytorch",
      "help_website": [
        "https://adversarial-attacks-pytorch.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "pytorch",
        "adversarial-attacks",
        "security"
      ],
      "id": 790
    },
    {
      "name": "Helicone",
      "one_line_profile": "Open-source observability and evaluation platform for LLMs",
      "detailed_description": "A platform designed for monitoring, logging, and evaluating Large Language Model (LLM) interactions, providing tools for tracking costs, latency, and quality metrics to ensure model reliability in production and research.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_monitoring",
        "performance_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/Helicone/helicone",
      "help_website": [
        "https://docs.helicone.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-ops",
        "observability",
        "evaluation"
      ],
      "id": 791
    },
    {
      "name": "Robust Tube MPC",
      "one_line_profile": "Implementation of Robust Model Predictive Control using Tube methods",
      "detailed_description": "A MATLAB implementation of Robust Model Predictive Control (MPC) utilizing tube-based methods to handle uncertainties in system dynamics, applicable in control theory research and robotics.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "control_simulation",
        "scientific_modeling"
      ],
      "application_level": "solver",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/HiroIshida/robust-tube-mpc",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mpc",
        "control-theory",
        "robust-control"
      ],
      "id": 792
    },
    {
      "name": "TrustGPT",
      "one_line_profile": "Benchmark for evaluating toxicity, bias, and value-alignment in LLMs",
      "detailed_description": "A benchmark framework designed to assess the trustworthiness of Large Language Models by evaluating them across dimensions such as toxicity, bias, and value alignment, ensuring responsible AI development.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmark",
        "bias_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/HowieHwong/TrustGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "benchmark",
        "trustworthiness"
      ],
      "id": 793
    },
    {
      "name": "TrustLLM",
      "one_line_profile": "Comprehensive toolkit for evaluating trustworthiness in Large Language Models",
      "detailed_description": "A comprehensive framework and benchmark for evaluating the trustworthiness of LLMs, covering multiple dimensions including truthfulness, safety, fairness, and robustness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmark",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HowieHwong/TrustLLM",
      "help_website": [
        "https://trustllmbenchmark.github.io/TrustLLM-Website/"
      ],
      "license": "MIT",
      "tags": [
        "llm",
        "safety",
        "evaluation"
      ],
      "id": 794
    },
    {
      "name": "TrustRAG",
      "one_line_profile": "Framework for enhancing and evaluating robustness in RAG systems",
      "detailed_description": "A research tool focused on improving and evaluating the trustworthiness and robustness of Retrieval-Augmented Generation (RAG) systems, addressing issues like retrieval errors and generation hallucinations.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "robustness_enhancement"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HuichiZhou/TrustRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "robustness",
        "trustworthiness"
      ],
      "id": 795
    },
    {
      "name": "Tensor Trust",
      "one_line_profile": "Platform for collecting prompt injection data for robust ML research",
      "detailed_description": "A gamified platform and dataset designed to crowdsource adversarial prompts (prompt injections) to facilitate research into the robustness and security of Large Language Models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "data_collection",
        "adversarial_attack"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/HumanCompatibleAI/tensor-trust",
      "help_website": [
        "https://tensortrust.ai/"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "prompt-injection",
        "security",
        "crowdsourcing"
      ],
      "id": 796
    },
    {
      "name": "xFinder",
      "one_line_profile": "Automated evaluator using LLMs for reliable evaluation",
      "detailed_description": "A tool that leverages Large Language Models as automated evaluators to assess the quality and correctness of outputs from other models, aiming to improve the reliability of automated evaluation metrics.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "automated_evaluation",
        "llm_as_judge"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IAAR-Shanghai/xFinder",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "evaluation",
        "llm",
        "automation"
      ],
      "id": 797
    },
    {
      "name": "xVerify",
      "one_line_profile": "Efficient answer verifier for reasoning model evaluations",
      "detailed_description": "A tool designed to verify the correctness of answers generated by reasoning models, facilitating efficient and accurate evaluation of complex reasoning tasks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "result_verification",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/IAAR-Shanghai/xVerify",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "reasoning",
        "verification",
        "evaluation"
      ],
      "id": 798
    },
    {
      "name": "SCERL",
      "one_line_profile": "Safety Constrained Environments for Reinforcement Learning",
      "detailed_description": "A collection of benchmark environments and datasets for evaluating Reinforcement Learning algorithms under safety constraints, supporting research into safe and robust RL agents.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmark",
        "reinforcement_learning"
      ],
      "application_level": "dataset",
      "primary_language": "Inform 7",
      "repo_url": "https://github.com/IBM/SCERL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reinforcement-learning",
        "safety",
        "benchmark"
      ],
      "id": 799
    },
    {
      "name": "EvalAssist",
      "one_line_profile": "Tool for refining LLM-as-a-Judge evaluation criteria",
      "detailed_description": "An open-source tool that assists users in iteratively refining evaluation criteria and prompts when using Large Language Models as evaluators (LLM-as-a-Judge), featuring a web-based interface for analysis.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "evaluation_workflow",
        "prompt_engineering"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/IBM/eval-assist",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-as-a-judge",
        "evaluation",
        "ui"
      ],
      "id": 800
    },
    {
      "name": "S-Eval",
      "one_line_profile": "Automated and comprehensive safety evaluation framework for LLMs",
      "detailed_description": "A framework designed for the automated and comprehensive safety evaluation of Large Language Models, providing metrics and datasets to assess various safety risks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_evaluation",
        "risk_assessment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IS2Lab/S-Eval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "safety",
        "llm",
        "evaluation"
      ],
      "id": 801
    },
    {
      "name": "Infosys Responsible AI Toolkit",
      "one_line_profile": "Toolkit for AI safety, security, explainability, and fairness",
      "detailed_description": "A comprehensive toolkit incorporating features for safety, security, explainability, fairness, bias, and hallucination detection to ensure the development of trustworthy and transparent AI solutions.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "responsible_ai",
        "model_audit"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Infosys/Infosys-Responsible-AI-Toolkit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "responsible-ai",
        "explainability",
        "fairness"
      ],
      "id": 802
    },
    {
      "name": "Factorio Learning Environment",
      "one_line_profile": "Open-ended environment for evaluating LLMs and agents in Factorio",
      "detailed_description": "A non-saturating, open-ended simulation environment based on the game Factorio, designed for evaluating the planning and problem-solving capabilities of Large Language Models and Reinforcement Learning agents.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "agent_evaluation",
        "simulation_environment"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/JackHopkins/factorio-learning-environment",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rl",
        "llm-agent",
        "simulation"
      ],
      "id": 803
    },
    {
      "name": "JailbreakBench",
      "one_line_profile": "Benchmark for jailbreaking language models",
      "detailed_description": "An open robustness benchmark specifically designed for evaluating the susceptibility of Language Models to jailbreaking attacks, providing a standardized dataset and evaluation protocol.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmark",
        "adversarial_attack"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/JailbreakBench/jailbreakbench",
      "help_website": [
        "https://jailbreakbench.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "jailbreak",
        "robustness",
        "benchmark"
      ],
      "id": 804
    },
    {
      "name": "Multilingual Safety Benchmark",
      "one_line_profile": "Safety benchmark for Large Language Models across multiple languages",
      "detailed_description": "A benchmark dataset and framework for evaluating the safety and robustness of Large Language Models in multilingual contexts, addressing the gap in non-English safety evaluation.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmark",
        "multilingual_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Jarviswang94/Multilingual_safety_benchmark",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multilingual",
        "safety",
        "llm"
      ],
      "id": 805
    },
    {
      "name": "Model Predictive Control (MPC)",
      "one_line_profile": "C++ implementation of MPC for vehicle control simulation",
      "detailed_description": "A C++ implementation of Model Predictive Control (MPC) designed to drive a vehicle in a simulator by optimizing steering and throttle commands, useful for research in control systems and autonomous driving.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "control_simulation",
        "scientific_modeling"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/JunshengFu/Model-Predictive-Control",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mpc",
        "control",
        "simulation"
      ],
      "id": 806
    },
    {
      "name": "LettuceDetect",
      "one_line_profile": "Hallucination detection framework for RAG applications",
      "detailed_description": "A framework designed to detect hallucinations in Retrieval-Augmented Generation (RAG) applications, helping to ensure the factual accuracy and reliability of generated content.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "rag_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KRLabsOrg/LettuceDetect",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "hallucination",
        "evaluation"
      ],
      "id": 807
    },
    {
      "name": "Mithra Scanner",
      "one_line_profile": "API testing tool for prompt injection and LLM security benchmarking",
      "detailed_description": "An interactive security testing tool for Large Language Model endpoints, supporting prompt injection testing, refusal detection, and security benchmarking via CLI and REST API integration.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "security_scanning",
        "red_teaming"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/KadirArslan/Mithra-Scanner",
      "help_website": [],
      "license": null,
      "tags": [
        "security",
        "red-teaming",
        "prompt-injection"
      ],
      "id": 808
    },
    {
      "name": "HouYi",
      "one_line_profile": "Automated prompt injection framework for LLM applications",
      "detailed_description": "A framework for automating prompt injection attacks against LLM-integrated applications, serving as a red-teaming tool to identify security vulnerabilities in AI systems.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming",
        "adversarial_attack"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/LLMSecurity/HouYi",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prompt-injection",
        "security",
        "red-teaming"
      ],
      "id": 809
    },
    {
      "name": "aac-metrics",
      "one_line_profile": "Metrics for evaluating Automated Audio Captioning systems",
      "detailed_description": "A PyTorch-based library providing a collection of metrics (SPIDEr, FENSE, etc.) for evaluating the performance of Automated Audio Captioning (AAC) systems.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "audio_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Labbeti/aac-metrics",
      "help_website": [
        "https://aac-metrics.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "audio-captioning",
        "metrics",
        "evaluation"
      ],
      "id": 810
    },
    {
      "name": "BERT-Attack",
      "one_line_profile": "Adversarial attack method against BERT models",
      "detailed_description": "An implementation of the BERT-Attack method, which generates high-quality adversarial samples to attack BERT-based models, used for evaluating the robustness of NLP models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/LinyangLee/BERT-Attack",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "adversarial-attack",
        "bert"
      ],
      "id": 811
    },
    {
      "name": "R-Judge",
      "one_line_profile": "Benchmark for safety risk awareness in LLM agents",
      "detailed_description": "A benchmark designed to evaluate the safety risk awareness of Large Language Model (LLM) agents, focusing on their ability to identify and handle risky scenarios.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmark",
        "agent_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lordog/R-Judge",
      "help_website": [
        "https://r-judge.github.io/"
      ],
      "license": null,
      "tags": [
        "llm-agent",
        "safety",
        "benchmark"
      ],
      "id": 812
    },
    {
      "name": "Trustworthy AI Fetal Brain Segmentation",
      "one_line_profile": "Trustworthy AI method for fetal brain MRI segmentation",
      "detailed_description": "An implementation of a trustworthy AI method based on Dempster-Shafer theory for the segmentation of fetal brains in 3D T2w MRI scans, providing uncertainty estimation for medical imaging analysis.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "medical_image_segmentation",
        "scientific_data_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LucasFidon/trustworthy-ai-fetal-brain-segmentation",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "medical-imaging",
        "segmentation",
        "uncertainty-estimation"
      ],
      "id": 813
    },
    {
      "name": "GenoArmory",
      "one_line_profile": "Unified evaluation framework for adversarial attacks on genomic foundation models",
      "detailed_description": "A comprehensive framework designed to evaluate the robustness of genomic foundation models against adversarial attacks. It provides a standardized environment for testing model vulnerabilities in bioinformatics contexts.",
      "domains": [
        "AI3-04",
        "Bioinformatics"
      ],
      "subtask_category": [
        "adversarial_attack",
        "model_evaluation",
        "robustness"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/MAGICS-LAB/GenoArmory",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "genomics",
        "adversarial-attacks",
        "foundation-models"
      ],
      "id": 814
    },
    {
      "name": "MJ-Bench",
      "one_line_profile": "Benchmark for evaluating multimodal reward models in text-to-image generation",
      "detailed_description": "A benchmark suite designed to assess whether multimodal reward models effectively judge the quality of text-to-image generation outputs, providing datasets and evaluation scripts.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "benchmarking",
        "reward_model_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/MJ-Bench/MJ-Bench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multimodal",
        "reward-model",
        "text-to-image"
      ],
      "id": 815
    },
    {
      "name": "nlg-eval",
      "one_line_profile": "Evaluation code for unsupervised automated metrics for Natural Language Generation",
      "detailed_description": "A library providing implementations for various unsupervised automated metrics (such as BLEU, METEOR, ROUGE, CIDEr) used to evaluate Natural Language Generation (NLG) models.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "nlg_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Maluuba/nlg-eval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "nlg",
        "evaluation-metrics",
        "nlp"
      ],
      "id": 816
    },
    {
      "name": "AutoRAG",
      "one_line_profile": "Automated framework for RAG evaluation and optimization",
      "detailed_description": "An AutoML-style framework designed to automatically evaluate and optimize Retrieval-Augmented Generation (RAG) pipelines, helping researchers select the best RAG modules and parameters.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "optimization",
        "automl"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "help_website": [
        "https://docs.autorag.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "automl"
      ],
      "id": 817
    },
    {
      "name": "pytector",
      "one_line_profile": "Python package for LLM prompt injection detection",
      "detailed_description": "A lightweight Python package designed to detect prompt injection attacks in Large Language Model (LLM) inputs, enhancing the security and robustness of LLM applications.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_injection_detection",
        "security"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MaxMLang/pytector",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prompt-injection",
        "security",
        "llm"
      ],
      "id": 818
    },
    {
      "name": "Dingo",
      "one_line_profile": "Comprehensive AI data, model, and application quality evaluation tool",
      "detailed_description": "A tool designed to evaluate the quality of AI data, models, and applications, providing metrics and insights to ensure the reliability and performance of AI systems.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "data_quality"
      ],
      "application_level": "tool",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/MigoXLab/dingo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "quality-assurance",
        "ai-testing"
      ],
      "id": 819
    },
    {
      "name": "summarization-eval",
      "one_line_profile": "Reference-free automatic summarization evaluation tool",
      "detailed_description": "A toolkit for evaluating text summarization models without reference summaries, including features for potential hallucination detection.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "summarization_evaluation",
        "hallucination_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Muhtasham/summarization-eval",
      "help_website": [],
      "license": null,
      "tags": [
        "summarization",
        "evaluation",
        "hallucination"
      ],
      "id": 820
    },
    {
      "name": "garak",
      "one_line_profile": "LLM vulnerability scanner and red teaming tool",
      "detailed_description": "A comprehensive vulnerability scanner for Large Language Models (LLMs), designed to probe for hallucinations, data leakage, prompt injection, and other security weaknesses.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "vulnerability_scanning",
        "red_teaming",
        "robustness"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/garak",
      "help_website": [
        "https://garak.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "security",
        "red-teaming"
      ],
      "id": 821
    },
    {
      "name": "RADTTS",
      "one_line_profile": "Flow-based TTS models with robust alignment learning",
      "detailed_description": "A library providing training and inference recipes for RADTTS and RADTTS++, enabling robust text-to-speech synthesis with fine-grained control over speech attributes.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "text_to_speech",
        "generative_model",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Roff",
      "repo_url": "https://github.com/NVIDIA/radtts",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tts",
        "speech-synthesis",
        "generative-ai"
      ],
      "id": 822
    },
    {
      "name": "sentiment-discovery",
      "one_line_profile": "Unsupervised language modeling for robust sentiment classification",
      "detailed_description": "A library implementing unsupervised language modeling techniques at scale to achieve robust sentiment classification, useful for analyzing large-scale text data.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "sentiment_analysis",
        "language_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/sentiment-discovery",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "sentiment-analysis",
        "nlp",
        "unsupervised-learning"
      ],
      "id": 823
    },
    {
      "name": "LLM Colosseum",
      "one_line_profile": "Benchmark for evaluating LLMs via game-playing interactions",
      "detailed_description": "A unique benchmarking tool that evaluates the quality and reasoning capabilities of Large Language Models (LLMs) by having them compete in Street Fighter 3, providing a dynamic evaluation environment.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "benchmarking",
        "llm_evaluation",
        "game_based_eval"
      ],
      "application_level": "tool",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/OpenGenerativeAI/llm-colosseum",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "benchmark",
        "game-ai"
      ],
      "id": 824
    },
    {
      "name": "EasyDetect",
      "one_line_profile": "Hallucination detection framework for LLMs",
      "detailed_description": "An easy-to-use framework designed to detect hallucinations in Large Language Model outputs, supporting various detection methods to ensure model reliability.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenKG-ORG/EasyDetect",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "llm",
        "reliability"
      ],
      "id": 825
    },
    {
      "name": "Bag-of-Tricks-for-AT",
      "one_line_profile": "Collection of empirical tricks for adversarial training",
      "detailed_description": "A library implementing various empirical tricks and best practices for training robust deep learning models using adversarial training techniques.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_training",
        "robustness",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/P2333/Bag-of-Tricks-for-AT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "adversarial-training",
        "robustness",
        "deep-learning"
      ],
      "id": 826
    },
    {
      "name": "Safety-Gymnasium",
      "one_line_profile": "Unified benchmark environments for safe reinforcement learning",
      "detailed_description": "A highly scalable and customizable benchmark suite for Safe Reinforcement Learning, providing environments to evaluate the safety and performance of RL agents.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "safety_benchmark",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PKU-Alignment/safety-gymnasium",
      "help_website": [
        "https://www.safety-gymnasium.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "reinforcement-learning",
        "safety",
        "benchmark"
      ],
      "id": 827
    },
    {
      "name": "LIFT3D",
      "one_line_profile": "Foundation policy for robust 3D robotic manipulation",
      "detailed_description": "A framework that lifts 2D large-scale pretrained models to 3D for robust robotic manipulation, serving as a foundation policy for robotics research.",
      "domains": [
        "AI3",
        "Robotics"
      ],
      "subtask_category": [
        "robotic_manipulation",
        "3d_policy",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PKU-HMI-Lab/LIFT3D",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "robotics",
        "3d-manipulation",
        "foundation-model"
      ],
      "id": 828
    },
    {
      "name": "Themis",
      "one_line_profile": "Reference-free NLG evaluation language model",
      "detailed_description": "A model-based evaluation tool for Natural Language Generation that operates without references, offering flexibility and interpretability in assessing text quality.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "nlg_evaluation",
        "model_based_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PKU-ONELab/Themis",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlg",
        "evaluation",
        "llm"
      ],
      "id": 829
    },
    {
      "name": "rko_lio",
      "one_line_profile": "Robust LiDAR-Inertial Odometry without sensor-specific modelling",
      "detailed_description": "A robust implementation of LiDAR-Inertial Odometry (LIO) that does not require sensor-specific modeling, useful for robotic navigation and mapping tasks.",
      "domains": [
        "Robotics"
      ],
      "subtask_category": [
        "lidar_inertial_odometry",
        "slam",
        "navigation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/PRBonn/rko_lio",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slam",
        "lidar",
        "robotics"
      ],
      "id": 830
    },
    {
      "name": "SafeLife",
      "one_line_profile": "Safety benchmarks for reinforcement learning agents",
      "detailed_description": "A set of environments and benchmarks designed to test the safety and robustness of reinforcement learning agents in complex, dynamic gridworlds.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "safety_benchmark"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PartnershipOnAI/safelife",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reinforcement-learning",
        "safety",
        "benchmark"
      ],
      "id": 831
    },
    {
      "name": "Parrot Paraphraser",
      "one_line_profile": "Paraphrasing framework for NLU data augmentation",
      "detailed_description": "A practical framework for generating paraphrases to augment training data for Natural Language Understanding (NLU) models, helping to build more robust conversational agents.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "data_augmentation",
        "paraphrasing",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PrithivirajDamodaran/Parrot_Paraphraser",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-augmentation",
        "nlp",
        "paraphrasing"
      ],
      "id": 832
    },
    {
      "name": "TextAttack",
      "one_line_profile": "Framework for adversarial attacks and data augmentation in NLP",
      "detailed_description": "A comprehensive Python framework for generating adversarial attacks, performing data augmentation, and training robust models in Natural Language Processing (NLP).",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "data_augmentation",
        "robustness"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/QData/TextAttack",
      "help_website": [
        "https://textattack.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "nlp",
        "adversarial-attacks",
        "data-augmentation"
      ],
      "id": 833
    },
    {
      "name": "TextAttack-A2T",
      "one_line_profile": "Implementation of A2T adversarial training method for NLP models",
      "detailed_description": "A repository containing the implementation of the 'A2T: Towards Improving Adversarial Training of NLP Models' method, designed to enhance the robustness of Natural Language Processing models against adversarial attacks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_training",
        "model_robustness"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/QData/TextAttack-A2T",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "adversarial-training",
        "robustness"
      ],
      "id": 834
    },
    {
      "name": "TextAttack-Search-Benchmark",
      "one_line_profile": "Benchmark for search algorithms in NLP adversarial example generation",
      "detailed_description": "A benchmarking suite for evaluating various search algorithms used to generate adversarial examples in Natural Language Processing, supporting research into the efficiency and effectiveness of adversarial attacks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/QData/TextAttack-Search-Benchmark",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "adversarial-attacks",
        "benchmarking"
      ],
      "id": 835
    },
    {
      "name": "RLAIF-V",
      "one_line_profile": "Framework for AI feedback on Vision-Language Models",
      "detailed_description": "An open-source framework implementing Reinforcement Learning from AI Feedback (RLAIF) specifically for Vision-Language Models (VLMs) to improve their trustworthiness and alignment.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "alignment",
        "rlhf",
        "multimodal_evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/RLHF-V/RLAIF-V",
      "help_website": [],
      "license": null,
      "tags": [
        "vlm",
        "rlaif",
        "trustworthiness"
      ],
      "id": 836
    },
    {
      "name": "LLMBox",
      "one_line_profile": "Unified library for LLM training and evaluation",
      "detailed_description": "A comprehensive library for implementing Large Language Models, featuring a unified pipeline for training and extensive model evaluation capabilities.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_training",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/RUCAIBox/LLMBox",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "training-pipeline",
        "evaluation"
      ],
      "id": 837
    },
    {
      "name": "RobustBench",
      "one_line_profile": "Standardized benchmark for adversarial robustness",
      "detailed_description": "A standardized benchmark and library for evaluating the adversarial robustness of image classification models, providing a leaderboard and easy access to robust models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "robustness_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/RobustBench/robustbench",
      "help_website": [
        "https://robustbench.github.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "adversarial-robustness",
        "computer-vision",
        "benchmark"
      ],
      "id": 838
    },
    {
      "name": "RouterArena",
      "one_line_profile": "Evaluation framework for LLM routing strategies",
      "detailed_description": "An open framework designed to evaluate Large Language Model routers, featuring standardized datasets, metrics, and an automated evaluation pipeline.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_routing",
        "evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/RouteWorks/RouterArena",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-routing",
        "evaluation-framework",
        "benchmark"
      ],
      "id": 839
    },
    {
      "name": "RAG-evaluation-harnesses",
      "one_line_profile": "Evaluation suite for Retrieval-Augmented Generation",
      "detailed_description": "A comprehensive evaluation suite specifically designed for assessing the performance of Retrieval-Augmented Generation (RAG) systems.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "retrieval_augmented_generation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/RulinShao/RAG-evaluation-harnesses",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "llm"
      ],
      "id": 840
    },
    {
      "name": "SORRY-Bench",
      "one_line_profile": "Benchmark for evaluating LLM safety refusal",
      "detailed_description": "A benchmark and evaluation toolkit for systematically assessing the safety refusal mechanisms of Large Language Models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_evaluation",
        "alignment"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/SORRY-Bench/sorry-bench",
      "help_website": [
        "https://sorry-bench.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "llm-safety",
        "benchmark",
        "refusal"
      ],
      "id": 841
    },
    {
      "name": "JailBreakV-28K",
      "one_line_profile": "Benchmark for LLM to MLLM jailbreak transferability",
      "detailed_description": "A comprehensive benchmark designed to evaluate the transferability of jailbreak attacks from Large Language Models to Multimodal Large Language Models, assessing robustness and safety.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming",
        "safety_evaluation",
        "multimodal"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/SaFo-Lab/JailBreakV_28K",
      "help_website": [
        "https://jailbreakv.github.io/"
      ],
      "license": null,
      "tags": [
        "jailbreak",
        "mllm",
        "safety-benchmark"
      ],
      "id": 842
    },
    {
      "name": "Robust Gymnasium",
      "one_line_profile": "Unified benchmark for robust Reinforcement Learning",
      "detailed_description": "A unified modular benchmark designed to evaluate the robustness of Reinforcement Learning agents under various perturbations and conditions.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "robustness_evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/SafeRL-Lab/Robust-Gymnasium",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "reinforcement-learning",
        "robustness",
        "benchmark"
      ],
      "id": 843
    },
    {
      "name": "Langtrace",
      "one_line_profile": "Observability and evaluation tool for LLM applications",
      "detailed_description": "An open-source observability tool based on Open Telemetry for LLM applications, providing real-time tracing, evaluations, and metrics.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "observability",
        "model_evaluation",
        "monitoring"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/Scale3-Labs/langtrace",
      "help_website": [
        "https://docs.langtrace.ai/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "llm-ops",
        "observability",
        "evaluation"
      ],
      "id": 844
    },
    {
      "name": "giskardpy",
      "one_line_profile": "Robot motion control library",
      "detailed_description": "The core Python library of the Giskard framework for constraint- and optimization-based robot motion control.",
      "domains": [
        "AI_Robotics"
      ],
      "subtask_category": [
        "motion_control",
        "robotics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SemRoCo/giskardpy",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "robotics",
        "motion-control",
        "optimization"
      ],
      "id": 845
    },
    {
      "name": "Universal-Prompt-Injection",
      "one_line_profile": "Implementation of universal prompt injection attacks",
      "detailed_description": "Official implementation of the paper 'Automatic and Universal Prompt Injection Attacks against Large Language Models', providing methods to generate prompt injection attacks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_injection",
        "red_teaming"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SheltonLiu-N/Universal-Prompt-Injection",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-injection",
        "llm-security",
        "adversarial-attacks"
      ],
      "id": 846
    },
    {
      "name": "JailDAM",
      "one_line_profile": "Jailbreak detection for Vision-Language Models",
      "detailed_description": "Implementation of 'JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model', a method for detecting jailbreak attempts in multimodal models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "jailbreak_detection",
        "safety_defense"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ShenzheZhu/JailDAM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "jailbreak-detection",
        "vlm",
        "safety"
      ],
      "id": 847
    },
    {
      "name": "JudgeDeceiver",
      "one_line_profile": "Prompt injection attack against LLM-as-a-Judge",
      "detailed_description": "Implementation of an optimization-based prompt injection attack specifically targeting LLM-as-a-Judge systems.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_injection",
        "red_teaming",
        "llm_as_a_judge"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ShiJiawenwen/JudgeDeceiver",
      "help_website": [],
      "license": null,
      "tags": [
        "prompt-injection",
        "llm-judge",
        "adversarial"
      ],
      "id": 848
    },
    {
      "name": "Gorilla",
      "one_line_profile": "Training and evaluation for LLM function calling",
      "detailed_description": "A framework and model suite for training and evaluating Large Language Models on function calling (tool use) capabilities.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "function_calling",
        "model_evaluation",
        "tool_use"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/ShishirPatil/gorilla",
      "help_website": [
        "https://gorilla.cs.berkeley.edu/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "function-calling",
        "api"
      ],
      "id": 849
    },
    {
      "name": "StruQ",
      "one_line_profile": "Defense against prompt injection using structured queries",
      "detailed_description": "Official implementation of StruQ, a method for defending against prompt injection attacks by utilizing structured queries.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_injection_defense",
        "safety"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Sizhe-Chen/StruQ",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "prompt-injection",
        "defense",
        "llm-security"
      ],
      "id": 850
    },
    {
      "name": "Skywork",
      "one_line_profile": "Open-source bilingual LLM suite and evaluation tools",
      "detailed_description": "A suite of large language models pre-trained on multilingual data, including open-source models, training data, and evaluation methods.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_training",
        "model_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/SkyworkAI/Skywork",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "bilingual",
        "foundation-model"
      ],
      "id": 851
    },
    {
      "name": "EmoLLM",
      "one_line_profile": "Mental health LLM framework and evaluation",
      "detailed_description": "A comprehensive framework for mental health Large Language Models, covering pre-training, post-training, datasets, and evaluation.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "domain_adaptation",
        "mental_health",
        "model_evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/SmartFlowAI/EmoLLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mental-health",
        "llm",
        "domain-specific"
      ],
      "id": 852
    },
    {
      "name": "AI-Safety_Benchmark",
      "one_line_profile": "Benchmark for guided jailbreak attacks",
      "detailed_description": "The official repository for a guided jailbreak benchmark, designed to evaluate the safety of AI models against sophisticated attacks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "jailbreak_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/SproutNan/AI-Safety_Benchmark",
      "help_website": [],
      "license": null,
      "tags": [
        "ai-safety",
        "benchmark",
        "jailbreak"
      ],
      "id": 853
    },
    {
      "name": "Bullet-Safety-Gym",
      "one_line_profile": "Safety benchmark framework for Reinforcement Learning",
      "detailed_description": "An open-source framework based on Bullet Physics to benchmark and assess safety specifications in Reinforcement Learning problems.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "safety_evaluation",
        "simulation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/SvenGronauer/Bullet-Safety-Gym",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rl",
        "safety",
        "benchmark"
      ],
      "id": 854
    },
    {
      "name": "HPCPerfStats",
      "one_line_profile": "HPC resource-usage monitoring and analysis tool",
      "detailed_description": "An automated resource-usage monitoring and analysis package designed for High Performance Computing (HPC) clusters.",
      "domains": [
        "Scientific_Computing"
      ],
      "subtask_category": [
        "performance_monitoring",
        "hpc_analysis"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/TACC/HPCPerfStats",
      "help_website": [],
      "license": "LGPL-2.1",
      "tags": [
        "hpc",
        "monitoring",
        "performance"
      ],
      "id": 855
    },
    {
      "name": "Omni-SafetyBench",
      "one_line_profile": "Safety benchmark for Audio-Visual LLMs",
      "detailed_description": "A benchmark designed for the safety evaluation of Audio-Visual Large Language Models, assessing risks across multiple modalities.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "multimodal_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/THU-BPM/Omni-SafetyBench",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "safety",
        "benchmark"
      ],
      "id": 856
    },
    {
      "name": "AgentBench",
      "one_line_profile": "Benchmark to evaluate LLMs as Agents",
      "detailed_description": "A comprehensive benchmark framework to evaluate the capabilities of Large Language Models acting as autonomous agents across various environments.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "agent_evaluation",
        "benchmarking"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/THUDM/AgentBench",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-agent",
        "benchmark",
        "evaluation"
      ],
      "id": 857
    },
    {
      "name": "FeverSymmetric",
      "one_line_profile": "Symmetric evaluation dataset for fact verification",
      "detailed_description": "A symmetric evaluation dataset based on the FEVER (fact verification) dataset, designed to test model consistency and bias.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "fact_verification",
        "dataset_creation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/TalSchuster/FeverSymmetric",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fever",
        "fact-verification",
        "dataset"
      ],
      "id": 858
    },
    {
      "name": "AI-Infra-Guard",
      "one_line_profile": "AI Red Teaming platform",
      "detailed_description": "A comprehensive, intelligent, and easy-to-use AI Red Teaming platform developed to secure AI infrastructure and models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming",
        "security_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Tencent/AI-Infra-Guard",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "red-teaming",
        "ai-security",
        "platform"
      ],
      "id": 859
    },
    {
      "name": "AICGSecEval",
      "one_line_profile": "AI-generated code security evaluation benchmark",
      "detailed_description": "A repository-level benchmark for evaluating the security of code generated by AI models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "code_security",
        "model_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Tencent/AICGSecEval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "code-generation",
        "security",
        "benchmark"
      ],
      "id": 860
    },
    {
      "name": "WeKnora",
      "one_line_profile": "RAG framework for document understanding",
      "detailed_description": "An LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using the RAG paradigm.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "rag",
        "document_understanding",
        "retrieval"
      ],
      "application_level": "framework",
      "primary_language": "Go",
      "repo_url": "https://github.com/Tencent/WeKnora",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "llm",
        "document-analysis"
      ],
      "id": 861
    },
    {
      "name": "PedestrianDetection-NohNMS",
      "one_line_profile": "NOH-NMS algorithm for pedestrian detection",
      "detailed_description": "Implementation of 'NOH-NMS: Improving Pedestrian Detection by Nearby Objects Hallucination', improving detection performance in crowded scenes.",
      "domains": [
        "AI_Computer_Vision"
      ],
      "subtask_category": [
        "object_detection",
        "pedestrian_detection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TencentYoutuResearch/PedestrianDetection-NohNMS",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "computer-vision",
        "pedestrian-detection",
        "nms"
      ],
      "id": 862
    },
    {
      "name": "trust-safety-evals",
      "one_line_profile": "Reference stack for AI model trust and safety evaluation",
      "detailed_description": "A project defining a reference stack for AI model and system evaluation, including evaluations, benchmarks, and leaderboards for trust and safety.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "trust_safety",
        "model_evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Makefile",
      "repo_url": "https://github.com/The-AI-Alliance/trust-safety-evals",
      "help_website": [],
      "license": null,
      "tags": [
        "ai-safety",
        "evaluation",
        "trust"
      ],
      "id": 863
    },
    {
      "name": "Ensemble-Pytorch",
      "one_line_profile": "Unified ensemble framework for PyTorch models",
      "detailed_description": "A library to implement, train, and evaluate ensemble learning methods in PyTorch, aiming to improve the performance and robustness of deep learning models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "robustness_enhancement",
        "model_ensemble"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TorchEnsemble-Community/Ensemble-Pytorch",
      "help_website": [
        "https://ensemble-pytorch.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "pytorch",
        "ensemble-learning",
        "robustness",
        "deep-learning"
      ],
      "id": 864
    },
    {
      "name": "TrustJudge",
      "one_line_profile": "Probabilistic evaluation framework for LLM-as-a-judge systems",
      "detailed_description": "A framework designed to reduce score-comparison and pairwise transitivity inconsistencies in Large Language Model (LLM) based evaluation systems, enhancing the reliability of automated judging.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "llm_as_a_judge"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TrustJudge/TrustJudge",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-evaluation",
        "reliability",
        "benchmarking"
      ],
      "id": 865
    },
    {
      "name": "Adversarial Robustness Toolbox (ART)",
      "one_line_profile": "Python library for machine learning security and robustness",
      "detailed_description": "A comprehensive library for machine learning security, providing tools for evasion, poisoning, extraction, and inference attacks, as well as defenses and robustness certification for red and blue teams.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_testing",
        "model_defense"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox",
      "help_website": [
        "https://adversarial-robustness-toolbox.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "adversarial-ml",
        "security",
        "robustness",
        "red-teaming"
      ],
      "id": 866
    },
    {
      "name": "TransferAttack",
      "one_line_profile": "Framework for transferable adversarial attacks",
      "detailed_description": "A PyTorch-based framework specifically designed to benchmark and boost the transferability of adversarial attacks in image classification tasks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_testing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Trustworthy-AI-Group/TransferAttack",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "adversarial-transferability",
        "pytorch",
        "security"
      ],
      "id": 867
    },
    {
      "name": "vllm-safety-benchmark",
      "one_line_profile": "Safety evaluation benchmark for Vision LLMs",
      "detailed_description": "A benchmark suite for evaluating the safety of Vision Large Language Models (VLLMs), focusing on detecting vulnerabilities and unsafe outputs in multimodal contexts.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_evaluation",
        "multimodal_benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/UCSC-VLAA/vllm-safety-benchmark",
      "help_website": [],
      "license": null,
      "tags": [
        "vllm",
        "safety",
        "benchmark",
        "vision-language"
      ],
      "id": 868
    },
    {
      "name": "Inspect",
      "one_line_profile": "Framework for large language model evaluations",
      "detailed_description": "An open-source framework developed by the UK AI Safety Institute for creating and running evaluations of large language models, supporting diverse metrics and safety checks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "safety_testing"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/UKGovernmentBEIS/inspect_ai",
      "help_website": [
        "https://inspect.ai-safety-institute.org.uk/"
      ],
      "license": "MIT",
      "tags": [
        "llm-eval",
        "ai-safety",
        "benchmarking"
      ],
      "id": 869
    },
    {
      "name": "LLM-judge-reporting",
      "one_line_profile": "Statistical reporting framework for LLM-as-a-judge",
      "detailed_description": "A plug-in framework that corrects bias and computes confidence intervals for LLM-as-a-judge evaluations, including adaptive algorithms for sample allocation.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "evaluation_statistics",
        "bias_correction"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/UW-Madison-Lee-Lab/LLM-judge-reporting",
      "help_website": [],
      "license": null,
      "tags": [
        "statistics",
        "llm-evaluation",
        "confidence-intervals"
      ],
      "id": 870
    },
    {
      "name": "Pangaea-Bench",
      "one_line_profile": "Evaluation benchmark for geospatial foundation models",
      "detailed_description": "A benchmark suite designed to evaluate the robustness and performance of foundation models in geospatial and earth science tasks.",
      "domains": [
        "AI3",
        "AI3-04",
        "Earth Science"
      ],
      "subtask_category": [
        "domain_benchmarking",
        "robustness_testing"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/VMarsocci/pangaea-bench",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "geospatial",
        "foundation-models",
        "earth-science",
        "benchmark"
      ],
      "id": 871
    },
    {
      "name": "Fair Sense AI",
      "one_line_profile": "Bias detection and risk management tool for AI",
      "detailed_description": "An AI-powered tool for detecting bias and managing risks in AI systems, promoting sustainable and trustworthy AI development.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "bias_detection",
        "risk_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/VectorInstitute/fair-sense-ai",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "fairness",
        "bias-detection",
        "trustworthy-ai"
      ],
      "id": 872
    },
    {
      "name": "owl-eval",
      "one_line_profile": "Evaluation harness for diffusion world models",
      "detailed_description": "A TypeScript-based evaluation harness specifically designed for assessing the performance of diffusion-based world models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "diffusion_models"
      ],
      "application_level": "framework",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/Wayfarer-Labs/owl-eval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "world-models",
        "diffusion",
        "evaluation"
      ],
      "id": 873
    },
    {
      "name": "CValues",
      "one_line_profile": "Evaluation and alignment for Chinese LLM values",
      "detailed_description": "A project focused on evaluating and aligning the values of Chinese Large Language Models, providing datasets and methodologies for value assessment.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "value_alignment",
        "model_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/X-PLUG/CValues",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alignment",
        "chinese-llm",
        "evaluation"
      ],
      "id": 874
    },
    {
      "name": "VLBiasBench",
      "one_line_profile": "Benchmark for social biases in Large Vision-Language Models",
      "detailed_description": "A large-scale dataset and benchmark composed of synthetic images aimed at evaluating and analyzing social biases in Large Vision-Language Models (LVLMs).",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "bias_evaluation",
        "multimodal_benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Xiangkui-Cao/VLBiasBench",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "bias",
        "lvlm",
        "synthetic-data",
        "benchmark"
      ],
      "id": 875
    },
    {
      "name": "DASH",
      "one_line_profile": "Detection and Assessment of Systematic Hallucinations of VLMs",
      "detailed_description": "A tool and framework for detecting and assessing systematic hallucinations in Vision-Language Models, helping to quantify model reliability.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/YanNeu/DASH",
      "help_website": [],
      "license": null,
      "tags": [
        "hallucination",
        "vlm",
        "evaluation"
      ],
      "id": 876
    },
    {
      "name": "Veridical Flow",
      "one_line_profile": "Framework for trustworthy data-science pipelines",
      "detailed_description": "A tool to facilitate building stable and trustworthy data-science pipelines based on the PCS (Predictability, Computability, Stability) framework.",
      "domains": [
        "AI3",
        "AI3-04",
        "Data Science"
      ],
      "subtask_category": [
        "pipeline_stability",
        "trustworthiness"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Yu-Group/veridical-flow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-science",
        "pcs-framework",
        "stability"
      ],
      "id": 877
    },
    {
      "name": "Whisper-AT",
      "one_line_profile": "Noise-robust automatic speech recognition and audio tagging",
      "detailed_description": "A unified model and toolkit for automatic speech recognition (ASR) and audio tagging, emphasizing noise robustness and multi-task learning capabilities.",
      "domains": [
        "AI3",
        "Audio"
      ],
      "subtask_category": [
        "speech_recognition",
        "audio_tagging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/YuanGongND/whisper-at",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "asr",
        "audio-tagging",
        "whisper",
        "robustness"
      ],
      "id": 878
    },
    {
      "name": "ECC",
      "one_line_profile": "Affective bias-inspired measures for visual emotion recognition",
      "detailed_description": "Implementation of evaluation measures for Visual Emotion Recognition (VER) that account for affective biases, aiming to err more like humans.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "evaluation_metric",
        "emotion_recognition"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ZhaoChenxi-nku/ECC",
      "help_website": [],
      "license": null,
      "tags": [
        "emotion-recognition",
        "evaluation-metric",
        "bias"
      ],
      "id": 879
    },
    {
      "name": "TransferAttackEval",
      "one_line_profile": "Evaluation framework for transferable adversarial images",
      "detailed_description": "A codebase for revisiting and evaluating transferable adversarial images, providing tools to assess attack performance across different models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_evaluation",
        "robustness_testing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ZhengyuZhao/TransferAttackEval",
      "help_website": [],
      "license": null,
      "tags": [
        "adversarial-attack",
        "transferability",
        "evaluation"
      ],
      "id": 880
    },
    {
      "name": "math-evaluation-harness",
      "one_line_profile": "Benchmark toolkit for LLM mathematical reasoning",
      "detailed_description": "A simple toolkit designed for benchmarking Large Language Models on various mathematical reasoning tasks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_benchmarking",
        "math_reasoning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/ZubinGou/math-evaluation-harness",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "math",
        "llm-benchmark",
        "reasoning"
      ],
      "id": 881
    },
    {
      "name": "ZoneEval",
      "one_line_profile": "Evaluation tool for spatial bias in object detection",
      "detailed_description": "A tool for revealing and evaluating spatial bias in object detection models, providing insights into performance variations across different image zones.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "bias_analysis",
        "object_detection_eval"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Zzh-tju/ZoneEval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "object-detection",
        "spatial-bias",
        "evaluation"
      ],
      "id": 882
    },
    {
      "name": "ACADO Toolkit",
      "one_line_profile": "Toolkit for automatic control and dynamic optimization",
      "detailed_description": "A software environment and algorithm collection for automatic control and dynamic optimization, supporting model predictive control and parameter estimation.",
      "domains": [
        "Scientific Computing",
        "Control Theory"
      ],
      "subtask_category": [
        "optimal_control",
        "dynamic_optimization"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/acado/acado",
      "help_website": [
        "http://acado.github.io/"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "optimization",
        "control-theory",
        "mpc",
        "c++"
      ],
      "id": 883
    },
    {
      "name": "AdvBox",
      "one_line_profile": "Adversarial example generation and robustness benchmark toolbox",
      "detailed_description": "A toolbox to generate adversarial examples to fool neural networks across multiple frameworks (PaddlePaddle, PyTorch, etc.) and benchmark the robustness of machine learning models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_benchmarking"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/advboxes/AdvBox",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "adversarial-examples",
        "robustness",
        "paddlepaddle",
        "pytorch"
      ],
      "id": 884
    },
    {
      "name": "T2ISafety",
      "one_line_profile": "Benchmark for assessing fairness, toxicity, and privacy in image generation",
      "detailed_description": "A benchmark suite for evaluating safety aspects such as fairness, toxicity, and privacy in Text-to-Image (T2I) generation models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "image_generation_eval"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/adwardlee/t2i_safety",
      "help_website": [],
      "license": null,
      "tags": [
        "text-to-image",
        "safety",
        "fairness",
        "benchmark"
      ],
      "id": 885
    },
    {
      "name": "PromptInject",
      "one_line_profile": "Framework for adversarial prompt attacks on LLMs",
      "detailed_description": "A modular framework for assembling prompts to quantitatively analyze the robustness of Large Language Models (LLMs) to adversarial prompt injection attacks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_injection",
        "robustness_analysis"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/agencyenterprise/PromptInject",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-injection",
        "llm-security",
        "red-teaming"
      ],
      "id": 886
    },
    {
      "name": "AgentFence",
      "one_line_profile": "Platform for AI agent security testing",
      "detailed_description": "An open-source platform for automatically testing the security of AI agents, identifying vulnerabilities like prompt injection, secret leakage, and instruction exposure.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "agent_security",
        "vulnerability_scanning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/agentfence/agentfence",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ai-agents",
        "security-testing",
        "red-teaming"
      ],
      "id": 887
    },
    {
      "name": "judgy",
      "one_line_profile": "Confidence interval estimator for LLM-as-a-Judge metrics",
      "detailed_description": "A Python package for estimating confidence intervals for metrics evaluated by LLM-as-a-Judge systems, helping to quantify uncertainty in automated evaluations.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "evaluation_statistics",
        "uncertainty_quantification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ai-evals-course/judgy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "statistics",
        "llm-evaluation",
        "confidence-intervals"
      ],
      "id": 888
    },
    {
      "name": "AIMon Python SDK",
      "one_line_profile": "SDK for detecting LLM hallucinations and quality issues",
      "detailed_description": "The Python SDK for AIMon, a system for detecting Large Language Model (LLM) quality issues such as hallucinations during evaluation or continuous monitoring.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_monitoring"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aimonlabs/aimon-python-sdk",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "llm-monitoring",
        "quality-control"
      ],
      "id": 889
    },
    {
      "name": "ABLE",
      "one_line_profile": "Ableism Bias Language Evaluation tool",
      "detailed_description": "A project to research and evaluate how AI systems reproduce discriminatory content and biases related to ableism.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "bias_evaluation",
        "ethics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aktionmensch/ABLE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bias",
        "ableism",
        "ai-ethics"
      ],
      "id": 890
    },
    {
      "name": "safety-eval",
      "one_line_profile": "Evaluation toolkit for generative language models and safety classifiers",
      "detailed_description": "A simple evaluation framework designed to assess the safety and robustness of generative language models and safety classifiers, providing metrics for potential harms.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "safety_check"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/safety-eval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "safety",
        "evaluation",
        "llm",
        "generative-ai"
      ],
      "id": 891
    },
    {
      "name": "last_layer",
      "one_line_profile": "Fast LLM prompt injection and jailbreak detection library",
      "detailed_description": "A lightweight and ultra-fast Python library designed to detect prompt injections and jailbreak attempts in Large Language Models (LLMs), suitable for real-time security monitoring.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "security_monitoring",
        "jailbreak_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/arekusandr/last_layer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-injection",
        "jailbreak-detection",
        "llm-security",
        "robustness"
      ],
      "id": 892
    },
    {
      "name": "OD-test",
      "one_line_profile": "Evaluation framework for Out-of-Distribution detectors",
      "detailed_description": "A library for evaluating Out-of-Distribution (OOD) detection methods in a less biased manner, providing standardized metrics and datasets for robust model assessment.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "ood_detection",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ashafaei/OD-test",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ood",
        "out-of-distribution",
        "evaluation",
        "pytorch"
      ],
      "id": 893
    },
    {
      "name": "BEIR",
      "one_line_profile": "Heterogeneous benchmark for information retrieval",
      "detailed_description": "A heterogeneous benchmark for zero-shot evaluation of information retrieval models across diverse datasets, facilitating robust assessment of retrieval systems.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "information_retrieval",
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/beir-cellar/beir",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "information-retrieval",
        "benchmark",
        "zero-shot",
        "evaluation"
      ],
      "id": 894
    },
    {
      "name": "Foolbox",
      "one_line_profile": "Adversarial attacks toolbox for neural networks",
      "detailed_description": "A Python toolbox to create adversarial examples that fool neural networks, supporting PyTorch, TensorFlow, and JAX, used for evaluating model robustness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bethgelab/foolbox",
      "help_website": [
        "https://foolbox.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "adversarial-attacks",
        "robustness",
        "pytorch",
        "tensorflow",
        "jax"
      ],
      "id": 895
    },
    {
      "name": "model-vs-human",
      "one_line_profile": "Benchmark for comparing model robustness against human perception",
      "detailed_description": "A benchmark framework to evaluate machine learning models on out-of-distribution datasets with collected human comparison data, assessing robustness and alignment with human perception.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "ood_evaluation",
        "human_comparison",
        "robustness"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bethgelab/model-vs-human",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "ood",
        "human-alignment",
        "computer-vision"
      ],
      "id": 896
    },
    {
      "name": "BigCode Evaluation Harness",
      "one_line_profile": "Evaluation framework for code generation models",
      "detailed_description": "A framework for the evaluation of autoregressive code generation language models, supporting various coding benchmarks and metrics.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "code_generation_eval",
        "model_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bigcode-project/bigcode-evaluation-harness",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "code-generation",
        "evaluation",
        "llm",
        "benchmark"
      ],
      "id": 897
    },
    {
      "name": "gmmreg",
      "one_line_profile": "Robust point set registration using Gaussian Mixture Models",
      "detailed_description": "C++ implementation of the robust point set registration algorithm using Gaussian Mixture Models (GMM), used for aligning point cloud data in computer vision and medical imaging.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "point_set_registration",
        "data_alignment"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/bing-jian/gmmreg",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "point-cloud",
        "registration",
        "gmm",
        "computer-vision"
      ],
      "id": 898
    },
    {
      "name": "nn_robust_attacks",
      "one_line_profile": "Robust evasion attacks implementation (Carlini & Wagner)",
      "detailed_description": "Implementation of robust evasion attacks against neural networks (including the Carlini & Wagner attack), serving as a standard baseline for evaluating model robustness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/carlini/nn_robust_attacks",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "adversarial-attacks",
        "robustness",
        "carlini-wagner",
        "neural-networks"
      ],
      "id": 899
    },
    {
      "name": "yet-another-applied-llm-benchmark",
      "one_line_profile": "Applied benchmark for evaluating LLM problem-solving capabilities",
      "detailed_description": "A benchmark suite designed to evaluate Large Language Models on practical, applied questions and problem-solving tasks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_benchmarking",
        "llm_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/carlini/yet-another-applied-llm-benchmark",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "llm",
        "benchmark",
        "evaluation",
        "applied-ai"
      ],
      "id": 900
    },
    {
      "name": "HarmBench",
      "one_line_profile": "Standardized evaluation framework for automated red teaming",
      "detailed_description": "A standardized evaluation framework for automated red teaming and robust refusal, designed to assess the safety and security of Large Language Models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming",
        "safety_evaluation",
        "robustness"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/centerforaisafety/HarmBench",
      "help_website": [
        "https://www.harmbench.org"
      ],
      "license": "MIT",
      "tags": [
        "red-teaming",
        "safety",
        "llm",
        "evaluation"
      ],
      "id": 901
    },
    {
      "name": "Simple Black-box Adversarial Attacks",
      "one_line_profile": "Implementation of simple black-box adversarial attacks for deep learning models",
      "detailed_description": "A Python implementation of the query-efficient black-box adversarial attack method proposed in the ICML 2019 paper. It allows researchers to evaluate the robustness of machine learning models against black-box attacks where gradients are unavailable.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_testing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cg563/simple-blackbox-attack",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "adversarial-attacks",
        "black-box-attacks",
        "robustness",
        "deep-learning"
      ],
      "id": 902
    },
    {
      "name": "CleverHans",
      "one_line_profile": "Adversarial example library for constructing attacks and building defenses",
      "detailed_description": "A Python library to benchmark machine learning systems' vulnerability to adversarial examples. It provides standard implementations of state-of-the-art attack algorithms and defenses to facilitate robust model development.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_testing",
        "defense_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cleverhans-lab/cleverhans",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "adversarial-machine-learning",
        "security",
        "robustness",
        "benchmarking"
      ],
      "id": 903
    },
    {
      "name": "Opik",
      "one_line_profile": "Platform for evaluating, testing, and monitoring LLM applications",
      "detailed_description": "An open-source platform designed to debug, evaluate, and monitor Large Language Model (LLM) applications. It provides tracing, automated evaluation metrics, and dashboards to ensure the reliability and performance of RAG systems and agents.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "monitoring",
        "tracing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/comet-ml/opik",
      "help_website": [
        "https://www.comet.com/docs/opik/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "observability",
        "rag",
        "monitoring"
      ],
      "id": 904
    },
    {
      "name": "DeepEval",
      "one_line_profile": "Unit testing and evaluation framework for LLMs",
      "detailed_description": "An open-source evaluation framework for Large Language Models (LLMs). It allows developers to build and run unit tests for LLM applications, measuring metrics such as hallucination, answer relevancy, and faithfulness to ensure model quality.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "unit_testing",
        "hallucination_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/confident-ai/deepeval",
      "help_website": [
        "https://docs.confident-ai.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "testing",
        "metrics",
        "rag"
      ],
      "id": 905
    },
    {
      "name": "DeepTeam",
      "one_line_profile": "Automated red teaming framework for LLMs",
      "detailed_description": "A framework designed to automate the red teaming process for Large Language Models. It helps identify vulnerabilities, biases, and safety issues in LLM systems through automated adversarial testing.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming",
        "safety_testing",
        "vulnerability_scanning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/confident-ai/deepteam",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "red-teaming",
        "llm-safety",
        "adversarial-testing"
      ],
      "id": 906
    },
    {
      "name": "3DFuse",
      "one_line_profile": "Robust text-to-3D generation using 2D diffusion models",
      "detailed_description": "A framework that leverages pre-trained 2D diffusion models to generate 3D consistent assets from text prompts. It introduces a method to inject 3D consistency into 2D models, enabling robust 3D generation for scientific and creative applications.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "3d_generation",
        "generative_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cvlab-kaist/3DFuse",
      "help_website": [],
      "license": null,
      "tags": [
        "text-to-3d",
        "diffusion-models",
        "3d-generation",
        "nerf"
      ],
      "id": 907
    },
    {
      "name": "UQLM",
      "one_line_profile": "Uncertainty quantification and hallucination detection for LLMs",
      "detailed_description": "A Python package for quantifying uncertainty in Large Language Models to detect hallucinations. It provides methods to estimate the confidence of model generations, aiding in the reliability assessment of LLM outputs.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "uncertainty_quantification",
        "hallucination_detection",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cvs-health/uqlm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "uncertainty-quantification",
        "hallucination",
        "llm",
        "reliability"
      ],
      "id": 908
    },
    {
      "name": "Simple LLM Eval",
      "one_line_profile": "Lightweight library for LLM evaluation using LLM-as-a-Judge",
      "detailed_description": "A simple Python library that implements the 'LLM-as-a-Judge' paradigm for evaluating Large Language Model outputs. It facilitates the creation of automated evaluation pipelines using stronger models to judge weaker ones.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "llm_as_a_judge"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cyberark/simple-llm-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "automation",
        "testing"
      ],
      "id": 909
    },
    {
      "name": "GNN Meta Attack",
      "one_line_profile": "Adversarial attacks on Graph Neural Networks via meta-learning",
      "detailed_description": "An implementation of adversarial attacks on Graph Neural Networks (GNNs) using meta-learning techniques. It allows researchers to evaluate the robustness of GNN models against perturbations in graph structure and node features.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "graph_neural_networks",
        "robustness_testing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/danielzuegner/gnn-meta-attack",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gnn",
        "adversarial-attacks",
        "meta-learning",
        "graph-mining"
      ],
      "id": 910
    },
    {
      "name": "Nettack",
      "one_line_profile": "Adversarial attacks on Neural Networks for Graph Data",
      "detailed_description": "A tool for generating adversarial attacks on Graph Neural Networks, specifically targeting node classification tasks. It helps in assessing the vulnerability of graph-based models to structural and feature perturbations.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "graph_neural_networks",
        "robustness_testing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/danielzuegner/nettack",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gnn",
        "adversarial-attacks",
        "graph-data",
        "security"
      ],
      "id": 911
    },
    {
      "name": "MAGSAC",
      "one_line_profile": "Robust model fitting algorithm without inlier-outlier threshold",
      "detailed_description": "An implementation of the MAGSAC (Model Agnostic Sample Consensus) algorithm for robust model estimation in computer vision. It improves upon RANSAC by eliminating the need for a manually tuned inlier-outlier threshold.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_fitting",
        "robust_estimation",
        "computer_vision"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/danini/magsac",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ransac",
        "robust-estimation",
        "computer-vision",
        "model-fitting"
      ],
      "id": 912
    },
    {
      "name": "Bisheng",
      "one_line_profile": "Open LLM DevOps platform for application development and evaluation",
      "detailed_description": "A comprehensive platform for developing, managing, and evaluating Large Language Model applications. It includes features for RAG, agent workflows, model evaluation, and dataset management, facilitating the full lifecycle of enterprise AI apps.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "llmops",
        "rag_management"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/dataelement/bisheng",
      "help_website": [
        "https://bisheng.dataelement.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llmops",
        "rag",
        "evaluation",
        "agent"
      ],
      "id": 913
    },
    {
      "name": "HuMoR",
      "one_line_profile": "3D Human Motion Model for Robust Pose Estimation",
      "detailed_description": "A library implementing a generative model for 3D human motion, used for robust pose estimation and motion generation. It enables the recovery of plausible 3D human motion from noisy or partial observations.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "pose_estimation",
        "motion_modeling",
        "3d_reconstruction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/davrempe/humor",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "human-motion",
        "pose-estimation",
        "generative-model",
        "3d-vision"
      ],
      "id": 914
    },
    {
      "name": "WEFE",
      "one_line_profile": "Word Embeddings Fairness Evaluation Framework",
      "detailed_description": "A framework for measuring and mitigating bias in word embedding models. It standardizes various fairness metrics to evaluate gender, racial, and other biases in pre-trained embeddings.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "bias_evaluation",
        "fairness_metrics",
        "embedding_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dccuchile/wefe",
      "help_website": [
        "https://wefe.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "fairness",
        "bias-detection",
        "word-embeddings",
        "nlp"
      ],
      "id": 915
    },
    {
      "name": "Vigil LLM",
      "one_line_profile": "Security scanner for detecting prompt injections and jailbreaks in LLMs",
      "detailed_description": "A security tool designed to detect and mitigate risks in Large Language Model inputs, such as prompt injections and jailbreak attempts. It acts as a firewall or scanner for LLM applications.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_injection_detection",
        "jailbreak_detection",
        "security_scanning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/deadbits/vigil-llm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-security",
        "prompt-injection",
        "jailbreak",
        "defense"
      ],
      "id": 916
    },
    {
      "name": "DebiAI",
      "one_line_profile": "Bias detection and contextual evaluation tool for AI projects",
      "detailed_description": "A tool for visualizing and analyzing AI model performance to detect biases and errors. It allows users to explore model results in context, identify underperforming subsets of data, and ensure model fairness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "bias_detection",
        "model_evaluation",
        "error_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Vue",
      "repo_url": "https://github.com/debiai/DebiAI",
      "help_website": [
        "https://debiai.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "bias-detection",
        "visualization",
        "evaluation",
        "fairness"
      ],
      "id": 917
    },
    {
      "name": "HaloScope",
      "one_line_profile": "Hallucination detection using unlabeled LLM generations",
      "detailed_description": "A tool implementing the HaloScope method for detecting hallucinations in Large Language Models. It leverages unlabeled generations to identify inconsistencies and factual errors without requiring extensive labeled datasets.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/deeplearning-wisc/haloscope",
      "help_website": [],
      "license": null,
      "tags": [
        "hallucination",
        "llm",
        "evaluation",
        "consistency"
      ],
      "id": 918
    },
    {
      "name": "LLM Prompt Injection Filtering",
      "one_line_profile": "Safety filter for LLM inputs using LLM-based classification",
      "detailed_description": "A Python tool that uses a secondary LLM call to evaluate user inputs for safety, specifically filtering out prompt injection attacks and dangerous queries before they reach the main model.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "input_filtering",
        "safety_guardrails",
        "prompt_injection_defense"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/derwiki/llm-prompt-injection-filtering",
      "help_website": [],
      "license": null,
      "tags": [
        "prompt-injection",
        "safety",
        "filtering",
        "llm"
      ],
      "id": 919
    },
    {
      "name": "PHUDGE",
      "one_line_profile": "Scalable LLM-as-a-Judge framework using Phi-3",
      "detailed_description": "A framework for evaluating LLMs using the Phi-3 model as a scalable judge. It supports custom rubrics, reference-based and reference-free evaluation, and hallucination detection.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "llm_as_a_judge",
        "grading"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/deshwalmahesh/PHUDGE",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-evaluation",
        "judge",
        "phi-3",
        "grading"
      ],
      "id": 920
    },
    {
      "name": "Ollama Grid Search",
      "one_line_profile": "Desktop application for evaluating and comparing local LLMs",
      "detailed_description": "A cross-platform desktop tool designed to perform grid search evaluations on local LLMs (via Ollama). It allows users to compare model outputs across different parameters and prompts to assess performance.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "parameter_tuning",
        "comparison"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/dezoito/ollama-grid-search",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-evaluation",
        "ollama",
        "grid-search",
        "local-llm"
      ],
      "id": 921
    },
    {
      "name": "Diffusion Classifier",
      "one_line_profile": "Zero-shot classification using pretrained diffusion models",
      "detailed_description": "A method and library for performing zero-shot image classification by leveraging the density estimates of pretrained diffusion models, without requiring additional training or fine-tuning.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "zero_shot_classification",
        "model_inference",
        "diffusion_models"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/diffusion-classifier/diffusion-classifier",
      "help_website": [],
      "license": null,
      "tags": [
        "diffusion-models",
        "classification",
        "zero-shot",
        "inference"
      ],
      "id": 922
    },
    {
      "name": "Docling SDG",
      "one_line_profile": "Synthetic data generation from documents for AI training",
      "detailed_description": "A toolkit for generating synthetic training data from document sources. It helps in creating labeled datasets for training or evaluating AI models when real data is scarce or sensitive.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "synthetic_data_generation",
        "data_augmentation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/docling-project/docling-sdg",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "synthetic-data",
        "document-processing",
        "data-generation"
      ],
      "id": 923
    },
    {
      "name": "AI Eval System",
      "one_line_profile": "Frontend UI system for OpenCompass model evaluation",
      "detailed_description": "A web-based evaluation system built on top of OpenCompass, providing a user interface for configuring and running AI model evaluations. It simplifies the process of benchmarking models for researchers.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking_platform"
      ],
      "application_level": "platform",
      "primary_language": "Vue",
      "repo_url": "https://github.com/domonic18/ai-eval-system",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation-ui",
        "opencompass",
        "benchmarking"
      ],
      "id": 924
    },
    {
      "name": "Non-Targeted Adversarial Attacks",
      "one_line_profile": "Implementation of momentum-based non-targeted adversarial attacks",
      "detailed_description": "Code implementation for the NIPS 2017 competition winning method on non-targeted adversarial attacks. It provides algorithms to generate adversarial examples that mislead models into incorrect classifications.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_testing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dongyp13/Non-Targeted-Adversarial-Attacks",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "adversarial-attacks",
        "deep-learning",
        "robustness"
      ],
      "id": 925
    },
    {
      "name": "Targeted Adversarial Attack",
      "one_line_profile": "Implementation of momentum-based targeted adversarial attacks",
      "detailed_description": "Code implementation for the NIPS 2017 competition winning method on targeted adversarial attacks. It enables the generation of perturbations that force a model to classify an input as a specific target class.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_testing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dongyp13/Targeted-Adversarial-Attack",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "adversarial-attacks",
        "targeted-attack",
        "robustness"
      ],
      "id": 926
    },
    {
      "name": "Translation-Invariant Attacks",
      "one_line_profile": "Translation-invariant adversarial attack method for transferability",
      "detailed_description": "Implementation of the translation-invariant attack method designed to improve the transferability of adversarial examples across different models. It is useful for black-box robustness testing.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "transferability",
        "robustness_testing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dongyp13/Translation-Invariant-Attacks",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "adversarial-attacks",
        "transferability",
        "robustness"
      ],
      "id": 927
    },
    {
      "name": "SafeDialBench",
      "one_line_profile": "Multi-turn dialogue benchmark for evaluating LLM safety",
      "detailed_description": "A comprehensive multi-turn dialogue benchmark dataset and evaluation framework designed to assess the safety of Large Language Models across various risk categories.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_evaluation",
        "benchmark_dataset"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/drivetosouth/SafeDialBench-Dataset",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-safety",
        "benchmark",
        "dialogue-systems"
      ],
      "id": 928
    },
    {
      "name": "FormatBiasEval",
      "one_line_profile": "Evaluation framework for output format bias in LLMs",
      "detailed_description": "Official implementation for evaluating and mitigating output format bias in Large Language Models, providing metrics to quantify how format constraints affect model reasoning and performance.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "bias_evaluation",
        "model_robustness"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dxlong2000/FormatBiasEval",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-bias",
        "format-bias",
        "evaluation-metric"
      ],
      "id": 929
    },
    {
      "name": "ibicus",
      "one_line_profile": "Bias correction toolkit for climate models",
      "detailed_description": "A flexible Python toolkit for the bias correction of climate models and associated evaluation, implementing various state-of-the-art methods for meteorological data adjustment.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "bias_correction",
        "climate_modeling",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ecmwf-projects/ibicus",
      "help_website": [
        "https://ibicus.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "climate-science",
        "bias-correction",
        "meteorology"
      ],
      "id": 930
    },
    {
      "name": "STEGOSAURUS-WRECKS",
      "one_line_profile": "Steganographic prompt injection tool for AI red teaming",
      "detailed_description": "A tool for automatically encoding images with steganographic payloads to act as prompt injections or jailbreaks for multimodal AI systems with code interpreter and vision capabilities.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming",
        "adversarial_attack",
        "prompt_injection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/elder-plinius/STEGOSAURUS-WRECKS",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "steganography",
        "prompt-injection",
        "red-teaming",
        "multimodal-security"
      ],
      "id": 931
    },
    {
      "name": "acceptance-bench",
      "one_line_profile": "LLM evaluation framework for acceptance vs refusal behavior",
      "detailed_description": "A robust evaluation framework for measuring Large Language Model acceptance versus refusal rates across difficulty levels, featuring multi-prompt variation testing and LLM-as-judge evaluation mechanisms.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_evaluation",
        "refusal_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ellydee/acceptance-bench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-evaluation",
        "safety-alignment",
        "benchmarking"
      ],
      "id": 932
    },
    {
      "name": "RL2Grid",
      "one_line_profile": "Reinforcement learning benchmark for power grid operations",
      "detailed_description": "A standardized benchmark for reinforcement learning agents in realistic power grid environments, modeling real-time operations, topology optimization, and safety-critical constraints.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "rl_benchmark",
        "power_grid_simulation",
        "safety_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/emarche/RL2Grid",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "reinforcement-learning",
        "power-grid",
        "benchmark"
      ],
      "id": 933
    },
    {
      "name": "ChatProtect",
      "one_line_profile": "Hallucination detection and mitigation for LLMs",
      "detailed_description": "Implementation of methods for evaluating, detecting, and mitigating self-contradictory hallucinations in Large Language Models, focusing on improving model reliability.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation",
        "mitigation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/eth-sri/ChatProtect",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "llm-reliability",
        "evaluation"
      ],
      "id": 934
    },
    {
      "name": "diffai",
      "one_line_profile": "Certifiable defense against adversarial examples",
      "detailed_description": "A system for training neural networks to be provably robust against adversarial examples, providing certifiable defenses for deep learning models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_defense",
        "robustness_verification",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/eth-sri/diffai",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "adversarial-robustness",
        "formal-verification",
        "deep-learning"
      ],
      "id": 935
    },
    {
      "name": "EvalPlus",
      "one_line_profile": "Rigorous evaluation framework for LLM-synthesized code",
      "detailed_description": "A framework for rigorously evaluating code generation models (like HumanEval+) by generating large amounts of test cases to ensure functional correctness and robustness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "code_evaluation",
        "model_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/evalplus/evalplus",
      "help_website": [
        "https://evalplus.github.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "code-generation",
        "evaluation",
        "llm"
      ],
      "id": 936
    },
    {
      "name": "decoding-biases",
      "one_line_profile": "Bias evaluation scripts for NLG models",
      "detailed_description": "A collection of scripts and tools to evaluate various bias metrics for Natural Language Generation models across different decoding algorithms.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "bias_evaluation",
        "nlg_assessment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ewsheng/decoding-biases",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bias-metrics",
        "nlg",
        "evaluation"
      ],
      "id": 937
    },
    {
      "name": "Meta SecAlign",
      "one_line_profile": "Secure foundation LLM against prompt injection",
      "detailed_description": "Implementation of Meta SecAlign, a method to create secure foundation LLMs that are robust against prompt injection attacks through safety alignment techniques.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_alignment",
        "prompt_injection_defense"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/Meta_SecAlign",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm-safety",
        "prompt-injection",
        "alignment"
      ],
      "id": 938
    },
    {
      "name": "rl-injector",
      "one_line_profile": "RL-based prompt injection attack generation",
      "detailed_description": "A reinforcement learning approach to generating stronger prompt injection attacks for evaluating the robustness of Large Language Models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming",
        "adversarial_attack",
        "rl_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/rl-injector",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "red-teaming",
        "reinforcement-learning",
        "prompt-injection"
      ],
      "id": 939
    },
    {
      "name": "unibench",
      "one_line_profile": "Robustness evaluation library for VLM models",
      "detailed_description": "A Python library designed to evaluate the robustness of Vision-Language Models (VLMs) across diverse benchmarks and multimodal tasks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "vlm_evaluation",
        "robustness_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/facebookresearch/unibench",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "vlm",
        "robustness",
        "benchmarking"
      ],
      "id": 940
    },
    {
      "name": "Bank Account Fraud Dataset",
      "one_line_profile": "Datasets for evaluating ML fairness and robustness in fraud detection",
      "detailed_description": "A suite of biased, imbalanced, and dynamic tabular datasets designed for evaluating machine learning models in fraud detection scenarios, specifically focusing on fairness and robustness metrics.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "fairness_evaluation",
        "dataset_benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/feedzai/bank-account-fraud",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ml-fairness",
        "fraud-detection",
        "evaluation-dataset"
      ],
      "id": 941
    },
    {
      "name": "NewsWCL50",
      "one_line_profile": "Evaluation dataset for media bias identification",
      "detailed_description": "An open-access evaluation dataset for methods to identify bias by word choice and labeling in news media, facilitating the development of bias detection algorithms.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "bias_detection",
        "dataset_benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/fhamborg/NewsWCL50",
      "help_website": [],
      "license": "CC-BY-SA-4.0",
      "tags": [
        "media-bias",
        "nlp-dataset",
        "evaluation"
      ],
      "id": 942
    },
    {
      "name": "Fiddler Auditor",
      "one_line_profile": "Tool for evaluating language model robustness and bias",
      "detailed_description": "An open-source tool designed to evaluate Large Language Models for robustness, bias, and correctness through perturbation testing and other evaluation techniques.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "robustness_testing",
        "bias_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fiddler-labs/fiddler-auditor",
      "help_website": [
        "https://docs.fiddler.ai"
      ],
      "license": "NOASSERTION",
      "tags": [
        "llm-evaluation",
        "robustness",
        "red-teaming"
      ],
      "id": 943
    },
    {
      "name": "Video-SafetyBench",
      "one_line_profile": "Benchmark for safety evaluation of Video LVLMs",
      "detailed_description": "A benchmark suite specifically designed for evaluating the safety of Video Large Vision-Language Models (LVLMs), covering various safety dimensions and risk categories.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "video_llm_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/flageval-baai/Video-SafetyBench",
      "help_website": [],
      "license": null,
      "tags": [
        "video-llm",
        "safety-benchmark",
        "evaluation"
      ],
      "id": 944
    },
    {
      "name": "AutoAttack",
      "one_line_profile": "Ensemble of parameter-free attacks for robustness evaluation",
      "detailed_description": "A reliable evaluation framework for adversarial robustness using an ensemble of diverse parameter-free attacks (APGD, etc.) to test deep learning models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fra31/auto-attack",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "adversarial-robustness",
        "deep-learning",
        "attack-ensemble"
      ],
      "id": 945
    },
    {
      "name": "gender-bias",
      "one_line_profile": "Library for detecting gender bias in text",
      "detailed_description": "A Python library designed to detect and measure gender bias in natural language text, useful for evaluating NLP datasets and model outputs.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "bias_detection",
        "text_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gender-bias/gender-bias",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gender-bias",
        "nlp",
        "fairness"
      ],
      "id": 946
    },
    {
      "name": "TOG",
      "one_line_profile": "Adversarial objectness gradient attacks for object detection",
      "detailed_description": "Implementation of TOG (Targeted Adversarial Objectness Gradient) attacks, a suite of adversarial attacks designed to deceive object detection systems (vanishing, fabrication, mislabeling).",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "object_detection_robustness"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/git-disl/TOG",
      "help_website": [],
      "license": null,
      "tags": [
        "adversarial-attack",
        "object-detection",
        "computer-vision"
      ],
      "id": 947
    },
    {
      "name": "camel-prompt-injection",
      "one_line_profile": "Code for defeating prompt injections by design",
      "detailed_description": "Research code and implementation for the paper 'Defeating Prompt Injections by Design', providing methods and evaluations for securing LLMs against injection attacks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_injection_defense",
        "safety_research"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/google-research/camel-prompt-injection",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prompt-injection",
        "llm-security",
        "defense"
      ],
      "id": 948
    },
    {
      "name": "lapeigvals",
      "one_line_profile": "Hallucination detection using spectral features of attention maps",
      "detailed_description": "Implementation of a method to detect hallucinations in Large Language Models by analyzing the spectral features (Laplacian eigenvalues) of their attention maps.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_interpretability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/graphml-lab-pwr/lapeigvals",
      "help_website": [],
      "license": null,
      "tags": [
        "hallucination",
        "spectral-analysis",
        "attention-maps"
      ],
      "id": 949
    },
    {
      "name": "PromptCARE",
      "one_line_profile": "Prompt copyright protection via watermark injection",
      "detailed_description": "A tool for protecting the copyright of prompts in LLMs by injecting and verifying watermarks, ensuring intellectual property protection for prompt engineering.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "copyright_protection",
        "watermarking",
        "model_security"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/grasses/PromptCARE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "watermarking",
        "prompt-protection",
        "security"
      ],
      "id": 950
    },
    {
      "name": "MM-Eval",
      "one_line_profile": "Multilingual meta-evaluation benchmark for LLM-as-a-Judge and reward models",
      "detailed_description": "A benchmark designed to evaluate the performance of LLM-as-a-Judge systems and reward models across multiple languages, focusing on meta-evaluation metrics.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "meta_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/guijinSON/MM-Eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-as-a-judge",
        "multilingual",
        "benchmark"
      ],
      "id": 951
    },
    {
      "name": "Verdict",
      "one_line_profile": "Inference-time scaling library for LLM-as-a-judge systems",
      "detailed_description": "A library that implements inference-time scaling techniques to improve the accuracy and reliability of Large Language Models when used as evaluators (LLM-as-a-judge).",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/haizelabs/verdict",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-as-a-judge",
        "scaling",
        "evaluation"
      ],
      "id": 952
    },
    {
      "name": "DDDM-VC",
      "one_line_profile": "Decoupled Denoising Diffusion Models for robust voice conversion",
      "detailed_description": "Official implementation of DDDM-VC, a voice conversion model using decoupled denoising diffusion models with disentangled representation and prior mixup.",
      "domains": [
        "AI2",
        "AI3"
      ],
      "subtask_category": [
        "voice_conversion",
        "generative_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hayeong0/DDDM-VC",
      "help_website": [],
      "license": null,
      "tags": [
        "diffusion-models",
        "voice-conversion",
        "audio-processing"
      ],
      "id": 953
    },
    {
      "name": "Adversarial Explainable AI",
      "one_line_profile": "Library for adversarial attacks on Explainable AI (XAI) methods",
      "detailed_description": "A collection of implementations for performing adversarial attacks on model explanations and methods to defend against them, facilitating robustness research in XAI.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "explainability_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hbaniecki/adversarial-explainable-ai",
      "help_website": [],
      "license": "CC-BY-SA-4.0",
      "tags": [
        "xai",
        "adversarial-attacks",
        "robustness"
      ],
      "id": 954
    },
    {
      "name": "HalluciDet",
      "one_line_profile": "Hallucination-based RGB modality generation for person detection",
      "detailed_description": "Implementation of a method that hallucinates RGB modality from other inputs to improve person detection, using privileged information during training.",
      "domains": [
        "AI2",
        "Computer Vision"
      ],
      "subtask_category": [
        "object_detection",
        "modality_hallucination"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/heitorrapela/HalluciDet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "computer-vision",
        "person-detection",
        "multimodal"
      ],
      "id": 955
    },
    {
      "name": "EvalView",
      "one_line_profile": "Pytest-style test harness for AI agent evaluation",
      "detailed_description": "A testing framework for AI agents that supports YAML scenarios, tool-call checks, cost/latency tracking, and safety evaluations in a CI-friendly format.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "agent_evaluation",
        "test_harness"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/hidai25/eval-view",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-agents",
        "evaluation",
        "testing-framework"
      ],
      "id": 956
    },
    {
      "name": "HolisticAI",
      "one_line_profile": "Library for assessing and improving AI system trustworthiness",
      "detailed_description": "An open-source tool to measure and mitigate risks in AI systems, focusing on bias, efficacy, robustness, and explainability.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "trustworthiness_assessment",
        "bias_detection"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/holistic-ai/holisticai",
      "help_website": [
        "https://holisticai.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ai-safety",
        "bias",
        "fairness"
      ],
      "id": 957
    },
    {
      "name": "Circular Bias Detection",
      "one_line_profile": "Statistical framework for detecting circular reasoning bias in AI evaluation",
      "detailed_description": "A comprehensive statistical framework designed to detect circular reasoning bias in the evaluation of AI algorithms.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "evaluation_bias",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hongping-zh/circular-bias-detection",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bias-detection",
        "evaluation",
        "statistics"
      ],
      "id": 958
    },
    {
      "name": "TrustworthyAI",
      "one_line_profile": "Collection of projects and tools for Trustworthy AI research",
      "detailed_description": "A repository containing various tools and libraries developed by Huawei Noah's Ark Lab for research in trustworthy AI, including robustness, explainability, and fairness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "trustworthy_ai",
        "robustness",
        "explainability"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/huawei-noah/trustworthyAI",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "trustworthy-ai",
        "robustness",
        "causality"
      ],
      "id": 959
    },
    {
      "name": "LightEval",
      "one_line_profile": "Comprehensive toolkit for evaluating LLMs across multiple backends",
      "detailed_description": "An all-in-one evaluation toolkit designed to assess Large Language Models using various metrics and benchmarks, supporting multiple inference backends.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/lighteval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-evaluation",
        "benchmarking",
        "huggingface"
      ],
      "id": 960
    },
    {
      "name": "Garak Analyzer & Mitigator",
      "one_line_profile": "Tool for analyzing Garak reports and generating mitigations",
      "detailed_description": "A utility to analyze adversarial reports generated by Garak, visualize attack attempts, detect triggers, and generate system prompt mitigations.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming_analysis",
        "mitigation_generation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/huseyingulsin/Garak-Analyzer-Mitigator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "red-teaming",
        "security",
        "llm-safety"
      ],
      "id": 961
    },
    {
      "name": "ChainForge",
      "one_line_profile": "Visual programming environment for prompt engineering and evaluation",
      "detailed_description": "An open-source visual environment for battle-testing, evaluating, and comparing prompts and responses from Large Language Models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_evaluation",
        "model_comparison"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/ianarawjo/ChainForge",
      "help_website": [
        "https://chainforge.ai/"
      ],
      "license": "MIT",
      "tags": [
        "prompt-engineering",
        "evaluation",
        "visualization"
      ],
      "id": 962
    },
    {
      "name": "JudgeIt",
      "one_line_profile": "Automation framework for LLM-as-a-judge evaluation",
      "detailed_description": "A framework using LLM-as-a-judge to evaluate Agentic AI, RAG systems, and Text2SQL applications at scale.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "llm-as-a-judge"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ibm-self-serve-assets/JudgeIt-LLM-as-a-Judge",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "rag",
        "agentic-ai"
      ],
      "id": 963
    },
    {
      "name": "PPTAgent",
      "one_line_profile": "Agent for generating and evaluating presentation slides",
      "detailed_description": "A system for generating presentations from text and evaluating them, moving beyond simple text-to-slide generation.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "content_generation",
        "evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/icip-cas/PPTAgent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent",
        "presentation-generation",
        "evaluation"
      ],
      "id": 964
    },
    {
      "name": "Hallucination Detection",
      "one_line_profile": "Tool for detecting hallucinations in BART summarization models",
      "detailed_description": "A tool to automatically detect hallucinations in BART summarization models by analyzing attention maps and decoding probabilities.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/idiap/hallucination-detection",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "hallucination",
        "summarization"
      ],
      "id": 965
    },
    {
      "name": "Innodata LLM Safety",
      "one_line_profile": "Benchmarking suite for LLM safety and factuality",
      "detailed_description": "A benchmarking tool for evaluating LLMs (Llama, Mistral, Gemma, GPT) on factuality, toxicity, bias, and hallucination propensity.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "model_evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/innodatalabs/innodata-llm-safety",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-safety",
        "benchmarking",
        "toxicity"
      ],
      "id": 966
    },
    {
      "name": "BIS",
      "one_line_profile": "Benchmark on Interactive Safety for AI agents",
      "detailed_description": "A benchmark designed to evaluate the interactive safety of AI systems.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "interactive_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/intelligent-control-lab/BIS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "safety",
        "benchmark",
        "interactive-ai"
      ],
      "id": 967
    },
    {
      "name": "Earthquake Detection",
      "one_line_profile": "Deep metric learning algorithm for detecting dynamically triggered earthquakes",
      "detailed_description": "Code for automating the detection of dynamically triggered earthquakes using a deep metric learning algorithm.",
      "domains": [
        "Earth Science",
        "Geophysics"
      ],
      "subtask_category": [
        "earthquake_detection",
        "signal_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/interactiveaudiolab/earthquakes",
      "help_website": [],
      "license": null,
      "tags": [
        "seismology",
        "deep-learning",
        "detection"
      ],
      "id": 968
    },
    {
      "name": "SAC3",
      "one_line_profile": "Semantic-aware cross-check consistency for hallucination detection",
      "detailed_description": "Implementation of SAC3, a method for reliable hallucination detection in black-box language models via semantic-aware cross-check consistency.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/intuit/sac3",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "consistency-check",
        "llm"
      ],
      "id": 969
    },
    {
      "name": "ReadabilityMetrics",
      "one_line_profile": "Library for computing text readability metrics",
      "detailed_description": "A tool that computes various readability metrics (ARI, Coleman-Liau, Flesch-Kincaid, etc.) for text analysis.",
      "domains": [
        "AI2",
        "NLP"
      ],
      "subtask_category": [
        "text_analysis",
        "metric_calculation"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/ipeirotis/ReadabilityMetrics",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "readability",
        "text-analysis"
      ],
      "id": 970
    },
    {
      "name": "DALL-Eval",
      "one_line_profile": "Benchmark for reasoning skills and social biases in text-to-image models",
      "detailed_description": "A toolkit for probing the reasoning skills and social biases of text-to-image generation models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "bias_detection"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/j-min/DallEval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "text-to-image",
        "bias",
        "evaluation"
      ],
      "id": 971
    },
    {
      "name": "LLM Warden",
      "one_line_profile": "Jailbreak detection tool for safeguarding LLMs",
      "detailed_description": "A tool designed to detect and prevent jailbreak attempts in Large Language Models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "jailbreak_detection",
        "safety_guardrail"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jackhhao/llm-warden",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-safety",
        "jailbreak",
        "security"
      ],
      "id": 972
    },
    {
      "name": "Adversarial Library",
      "one_line_profile": "PyTorch library for adversarial attacks",
      "detailed_description": "A library containing PyTorch implementations of various adversarial attacks for evaluating model robustness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jeromerony/adversarial-library",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "adversarial-attacks",
        "pytorch",
        "robustness"
      ],
      "id": 973
    },
    {
      "name": "Fast Adversarial",
      "one_line_profile": "Efficient gradient-based L2 adversarial attacks and defenses",
      "detailed_description": "Implementation of decoupled direction and norm methods for efficient gradient-based L2 adversarial attacks and defenses.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "defense_mechanism"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jeromerony/fast_adversarial",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "adversarial-attacks",
        "optimization",
        "robustness"
      ],
      "id": 974
    },
    {
      "name": "ModelNet40-C",
      "one_line_profile": "Benchmark for 3D point cloud recognition robustness",
      "detailed_description": "A benchmark dataset and codebase for evaluating the robustness of 3D point cloud recognition models against common corruptions.",
      "domains": [
        "AI3",
        "AI3-04",
        "Computer Vision"
      ],
      "subtask_category": [
        "robustness_benchmarking",
        "3d_vision"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/jiachens/ModelNet40-C",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "3d-vision",
        "robustness",
        "point-cloud"
      ],
      "id": 975
    },
    {
      "name": "runcharter",
      "one_line_profile": "Automated run chart analysis and visualization tool",
      "detailed_description": "An R package designed to automate the creation and analysis of run charts for faceted data displays across multiple metrics or locations, facilitating statistical process control and data visualization.",
      "domains": [
        "Scientific Visualization",
        "Statistics"
      ],
      "subtask_category": [
        "data_visualization",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/johnmackintosh/runcharter",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "r-package",
        "visualization",
        "run-chart",
        "statistics"
      ],
      "id": 976
    },
    {
      "name": "adv_attack_capsnet",
      "one_line_profile": "Adversarial attack implementation for Capsule Networks",
      "detailed_description": "A TensorFlow implementation of adversarial attacks specifically targeting Capsule Networks, serving as a tool for evaluating the robustness of this specific neural network architecture.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jsikyoon/adv_attack_capsnet",
      "help_website": [],
      "license": null,
      "tags": [
        "adversarial-attacks",
        "capsule-networks",
        "robustness"
      ],
      "id": 977
    },
    {
      "name": "Defense-GAN",
      "one_line_profile": "Generative model-based defense against adversarial attacks",
      "detailed_description": "An implementation of Defense-GAN, a mechanism that uses generative adversarial networks to project input images onto the range of the generator to purify adversarial perturbations before classification.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "model_defense",
        "robustness_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kabkabm/defensegan",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gan",
        "adversarial-defense",
        "security"
      ],
      "id": 978
    },
    {
      "name": "VSDFLOW",
      "one_line_profile": "Automated RTL-to-GDSII flow for semiconductor design",
      "detailed_description": "An automated open-source hardware design flow that converts Verilog RTL designs into GDSII layouts, integrating synthesis, placement, routing, and timing analysis tools for semiconductor engineering.",
      "domains": [
        "Electronic Design Automation",
        "Hardware Engineering"
      ],
      "subtask_category": [
        "circuit_synthesis",
        "layout_generation"
      ],
      "application_level": "workflow",
      "primary_language": "Verilog",
      "repo_url": "https://github.com/kunalg123/vsdflow",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "eda",
        "vlsi",
        "rtl-to-gds",
        "verilog"
      ],
      "id": 979
    },
    {
      "name": "limited-blackbox-attacks",
      "one_line_profile": "Black-box adversarial attacks with limited queries",
      "detailed_description": "A research codebase implementing black-box adversarial attack methods that operate under restricted query budgets and partial information, used for evaluating model robustness in realistic threat models.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/labsix/limited-blackbox-attacks",
      "help_website": [],
      "license": null,
      "tags": [
        "black-box-attacks",
        "adversarial-ml",
        "robustness"
      ],
      "id": 980
    },
    {
      "name": "pint-benchmark",
      "one_line_profile": "Benchmark for prompt injection detection systems",
      "detailed_description": "A benchmark suite designed to evaluate the effectiveness of prompt injection detection systems in Large Language Models, providing a standardized dataset and evaluation metrics for AI safety research.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "safety_evaluation",
        "prompt_injection_benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/lakeraai/pint-benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-injection",
        "benchmark",
        "llm-safety"
      ],
      "id": 981
    },
    {
      "name": "chembench",
      "one_line_profile": "Chemistry evaluation benchmark for LLMs",
      "detailed_description": "A framework and dataset for evaluating the capabilities of Large Language Models in solving chemistry-related tasks, assessing their scientific reasoning and domain knowledge.",
      "domains": [
        "AI3-04",
        "Chemistry"
      ],
      "subtask_category": [
        "domain_evaluation",
        "scientific_reasoning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/lamalab-org/chembench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chemistry",
        "llm-evaluation",
        "benchmark"
      ],
      "id": 982
    },
    {
      "name": "Langfuse",
      "one_line_profile": "LLM engineering platform for observability and evaluation",
      "detailed_description": "An open-source platform providing observability, metrics, and evaluation pipelines for Large Language Models, enabling researchers and engineers to trace model execution, manage datasets, and run systematic evaluations.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "observability",
        "metrics_tracking"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/langfuse/langfuse",
      "help_website": [
        "https://langfuse.com/docs"
      ],
      "license": "NOASSERTION",
      "tags": [
        "llm-ops",
        "evaluation",
        "observability"
      ],
      "id": 983
    },
    {
      "name": "LangWatch",
      "one_line_profile": "LLM Ops platform for analytics and evaluation",
      "detailed_description": "A platform for monitoring and evaluating LLM applications, offering tools for trace analysis, dataset management, and prompt optimization to ensure model quality and safety.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "analytics"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/langwatch/langwatch",
      "help_website": [
        "https://docs.langwatch.ai"
      ],
      "license": "NOASSERTION",
      "tags": [
        "llm-ops",
        "analytics",
        "evaluation"
      ],
      "id": 984
    },
    {
      "name": "Latitude",
      "one_line_profile": "Prompt engineering and evaluation platform",
      "detailed_description": "An open-source platform focused on the development, evaluation, and refinement of prompts for LLMs, providing tools to systematically test and improve model responses.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_evaluation",
        "prompt_engineering"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/latitude-dev/latitude-llm",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "prompt-engineering",
        "evaluation",
        "llm"
      ],
      "id": 985
    },
    {
      "name": "robotic_world_model",
      "one_line_profile": "Neural network simulator for robotics policy optimization",
      "detailed_description": "A neural network-based simulator designed to model robotic environments, facilitating robust policy optimization and reinforcement learning research in robotics.",
      "domains": [
        "Robotics",
        "AI3"
      ],
      "subtask_category": [
        "simulation",
        "policy_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/leggedrobotics/robotic_world_model",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "robotics",
        "simulation",
        "reinforcement-learning"
      ],
      "id": 986
    },
    {
      "name": "PIGuard",
      "one_line_profile": "Prompt injection guardrail via mitigating overdefense",
      "detailed_description": "An implementation of a defense mechanism against prompt injection attacks that specifically addresses the issue of overdefense, serving as a tool for enhancing LLM safety.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "safety_defense",
        "prompt_injection_mitigation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/leolee99/PIGuard",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-injection",
        "guardrails",
        "llm-safety"
      ],
      "id": 987
    },
    {
      "name": "Guided-Denoise",
      "one_line_profile": "Denoising-based defense against adversarial attacks",
      "detailed_description": "The winning submission for the NIPS 2017 Defense Against Adversarial Attack challenge, providing a guided denoising method to protect classifiers from adversarial perturbations.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "model_defense",
        "image_denoising"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lfz/Guided-Denoise",
      "help_website": [],
      "license": null,
      "tags": [
        "adversarial-defense",
        "denoising",
        "nips-2017"
      ],
      "id": 988
    },
    {
      "name": "Open-Prompt-Injection",
      "one_line_profile": "Benchmark for prompt injection attacks and defenses",
      "detailed_description": "A comprehensive benchmark repository for evaluating Large Language Models against various prompt injection attacks and assessing the effectiveness of defense mechanisms.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "prompt_injection"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/liu00222/Open-Prompt-Injection",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-injection",
        "benchmark",
        "llm-security"
      ],
      "id": 989
    },
    {
      "name": "DSRL",
      "one_line_profile": "Datasets and environment wrappers for safe reinforcement learning",
      "detailed_description": "A collection of datasets and environment wrappers specifically designed for offline safe reinforcement learning research, facilitating the development and evaluation of safe RL algorithms.",
      "domains": [
        "AI3",
        "Robotics"
      ],
      "subtask_category": [
        "dataset_provision",
        "environment_wrapping"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/liuzuxin/DSRL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "safe-rl",
        "offline-rl",
        "datasets"
      ],
      "id": 990
    },
    {
      "name": "RouteLLM",
      "one_line_profile": "Framework for serving and evaluating LLM routers",
      "detailed_description": "A framework designed to evaluate and deploy Large Language Model routers, enabling efficient model selection and cost optimization without compromising generation quality.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "model_routing",
        "efficiency_evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/lm-sys/RouteLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-routing",
        "evaluation",
        "optimization"
      ],
      "id": 991
    },
    {
      "name": "convex_adversarial",
      "one_line_profile": "Provably robust neural network training method",
      "detailed_description": "A library and method for training neural networks that are provably robust to adversarial attacks, utilizing convex relaxation techniques to certify robustness bounds.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "robust_training",
        "verification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/locuslab/convex_adversarial",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "robustness",
        "adversarial-training",
        "verification"
      ],
      "id": 992
    },
    {
      "name": "Square Attack",
      "one_line_profile": "Query-efficient black-box adversarial attack algorithm for model robustness evaluation",
      "detailed_description": "A Python implementation of Square Attack, a score-based black-box adversarial attack that does not rely on local gradient information. It is used to evaluate the robustness of machine learning models (particularly image classifiers) against adversarial perturbations in a query-efficient manner.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/max-andr/square-attack",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "adversarial-attacks",
        "black-box-attack",
        "robustness"
      ],
      "id": 993
    },
    {
      "name": "Video-ChatGPT",
      "one_line_profile": "Video conversation model and quantitative evaluation benchmarking framework",
      "detailed_description": "A framework combining a video conversation model with a rigorous quantitative evaluation benchmarking suite. It enables the assessment of video-based conversational models using LLMs to generate meaningful conversations about videos and evaluate performance across various metrics.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "multimodal_benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/mbzuai-oryx/Video-ChatGPT",
      "help_website": [],
      "license": "CC-BY-4.0",
      "tags": [
        "video-llm",
        "benchmarking",
        "multimodal"
      ],
      "id": 994
    },
    {
      "name": "Agent-as-a-Judge",
      "one_line_profile": "Framework for evaluating open-ended agentic tasks using agents as judges",
      "detailed_description": "A framework designed to evaluate AI agents in open-ended scenarios by employing other agents as judges. It addresses the challenges of assessing agent performance in complex, non-deterministic environments, providing a methodology for scalable and automated evaluation.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "agent_evaluation",
        "automated_benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/metauto-ai/agent-as-a-judge",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-as-a-judge",
        "agent-evaluation",
        "open-endedness"
      ],
      "id": 995
    },
    {
      "name": "BIPIA",
      "one_line_profile": "Benchmark for Indirect Prompt Injection Attacks on LLMs",
      "detailed_description": "A benchmark suite for evaluating the robustness of Large Language Models (LLMs) and their defenses against indirect prompt injection attacks. It provides a standardized dataset and evaluation methodology to assess security risks in LLM-integrated applications.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "security_benchmarking",
        "prompt_injection",
        "robustness_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/BIPIA",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "prompt-injection",
        "llm-security",
        "benchmark"
      ],
      "id": 996
    },
    {
      "name": "CoNLI",
      "one_line_profile": "Framework for ungrounded hallucination detection and reduction in LLMs",
      "detailed_description": "A plug-and-play framework designed to detect and reduce ungrounded hallucinations in Large Language Models. It utilizes Natural Language Inference (NLI) techniques to verify the consistency of generated text against source knowledge, improving model reliability.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/CoNLI_hallucination",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "nli",
        "fact-checking"
      ],
      "id": 997
    },
    {
      "name": "HaDes",
      "one_line_profile": "Token-level reference-free hallucination detection for LLMs",
      "detailed_description": "A tool for detecting hallucinations in Large Language Model outputs at the token level without requiring reference texts. It focuses on identifying self-contradictions and logical inconsistencies within the generated content to assess model faithfulness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/HaDes",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination-detection",
        "token-level",
        "llm-evaluation"
      ],
      "id": 998
    },
    {
      "name": "PromptBench",
      "one_line_profile": "Unified evaluation framework for Large Language Models",
      "detailed_description": "A comprehensive framework for evaluating Large Language Models across various dimensions, including adversarial robustness, prompt sensitivity, and task performance. It supports multiple datasets, models, and attack methods to facilitate systematic LLM assessment.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "robustness_benchmarking",
        "prompt_engineering"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/promptbench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-evaluation",
        "adversarial-robustness",
        "benchmark"
      ],
      "id": 999
    },
    {
      "name": "Prompty",
      "one_line_profile": "Tool for managing, debugging, and evaluating LLM prompts",
      "detailed_description": "An asset class and tooling format designed to enhance the observability, understandability, and portability of LLM prompts. It facilitates the development lifecycle of prompts, including creation, management, and evaluation within AI applications.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_engineering",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/prompty",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-management",
        "observability",
        "llm-ops"
      ],
      "id": 1000
    },
    {
      "name": "RobustDG",
      "one_line_profile": "Toolkit for domain generalization and robust machine learning",
      "detailed_description": "A toolkit for building machine learning models that generalize well to unseen domains and are robust against privacy attacks and other perturbations. It provides implementations of various domain generalization algorithms and evaluation metrics.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "domain_generalization",
        "robustness_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/robustdg",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "domain-generalization",
        "robustness",
        "privacy"
      ],
      "id": 1001
    },
    {
      "name": "FortisAVQA",
      "one_line_profile": "Robustness evaluation and bias mitigation for Audio-Visual Question Answering",
      "detailed_description": "A framework for evaluating the robustness of Audio-Visual Question Answering (AVQA) models and mitigating biases. It includes datasets and model implementations to analyze performance under various conditions and improve model reliability.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "robustness_evaluation",
        "bias_mitigation",
        "multimodal_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/mira-ai-lab/fortisavqa",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "avqa",
        "robustness",
        "bias-mitigation"
      ],
      "id": 1002
    },
    {
      "name": "MAITE",
      "one_line_profile": "Modular AI Trustworthy Engineering library for test and evaluation",
      "detailed_description": "A library providing common types, protocols, and utilities to support AI Test and Evaluation (T&E) workflows. It aims to standardize and facilitate the engineering of trustworthy AI systems through modular components.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "test_and_evaluation",
        "trustworthy_ai"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mit-ll-ai-technology/maite",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "test-and-evaluation",
        "trustworthy-ai",
        "protocols"
      ],
      "id": 1003
    },
    {
      "name": "ModelBench",
      "one_line_profile": "Safety benchmark runner for AI models",
      "detailed_description": "A tool developed by MLCommons to run safety benchmarks against AI models and generate detailed performance reports. It standardizes the evaluation of model safety across different dimensions and test sets.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "model_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/mlcommons/modelbench",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "safety",
        "benchmark",
        "mlcommons"
      ],
      "id": 1004
    },
    {
      "name": "WiSE-FT",
      "one_line_profile": "Robust fine-tuning method for zero-shot models",
      "detailed_description": "An implementation of the WiSE-FT (Weight-Space Ensembles for Fine-Tuning) method, which improves the robustness of fine-tuned zero-shot models. It enables models to maintain high accuracy on distribution shifts while adapting to new tasks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "robust_fine_tuning",
        "domain_adaptation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mlfoundations/wise-ft",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "fine-tuning",
        "robustness",
        "zero-shot"
      ],
      "id": 1005
    },
    {
      "name": "EvalScope",
      "one_line_profile": "Streamlined framework for LLM/VLM evaluation and benchmarking",
      "detailed_description": "A customizable framework for the efficient evaluation and performance benchmarking of Large Language Models (LLMs), Vision Language Models (VLMs), and AIGC models. It supports various datasets and metrics to assess model capabilities.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/modelscope/evalscope",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "benchmark",
        "modelscope"
      ],
      "id": 1006
    },
    {
      "name": "Agentic Security",
      "one_line_profile": "Vulnerability scanner and red teaming kit for Agentic LLMs",
      "detailed_description": "A security tool designed to scan for vulnerabilities in Agentic LLM systems. It serves as an AI red teaming kit, helping researchers and developers identify security flaws and robustness issues in autonomous agent deployments.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming",
        "vulnerability_scanning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/msoedov/agentic_security",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "red-teaming",
        "llm-security",
        "agent-evaluation"
      ],
      "id": 1007
    },
    {
      "name": "Disrupting Deepfakes",
      "one_line_profile": "Adversarial attacks on conditional image translation networks for deepfake defense",
      "detailed_description": "An implementation of adversarial attack methods designed to disrupt deepfake generation models (conditional image translation networks). It serves as a defensive tool to protect images from being used to generate deepfakes.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_defense",
        "deepfake_detection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/natanielruiz/disrupting-deepfakes",
      "help_website": [],
      "license": null,
      "tags": [
        "deepfake-defense",
        "adversarial-attack",
        "image-translation"
      ],
      "id": 1008
    },
    {
      "name": "Korean Safety Benchmarks",
      "one_line_profile": "Safety benchmarks (SQuARe and KoSBi) for Korean LLMs",
      "detailed_description": "A repository containing datasets and PyTorch implementations for SQuARe and KoSBi, which are safety benchmarks specifically designed for evaluating Korean Large Language Models. It addresses social bias and safety concerns in a non-English context.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "bias_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/naver-ai/korean-safety-benchmarks",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "korean-llm",
        "safety-benchmark",
        "bias"
      ],
      "id": 1009
    },
    {
      "name": "TD-MPC2",
      "one_line_profile": "Scalable and robust world models for continuous control",
      "detailed_description": "An implementation of TD-MPC2, a model-based reinforcement learning algorithm that learns scalable and robust world models for continuous control tasks. It is used for scientific modeling in robotics and control systems.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "robust_control",
        "world_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nicklashansen/tdmpc2",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "world-models",
        "reinforcement-learning",
        "robust-control"
      ],
      "id": 1010
    },
    {
      "name": "MoNA-Bench",
      "one_line_profile": "Benchmark for monocular depth estimation in UAV autonomous navigation",
      "detailed_description": "A benchmark suite designed for evaluating monocular depth estimation models in the context of unmanned aircraft autonomous navigation, focusing on obstacle avoidance and target tracking safety.",
      "domains": [
        "AI3-04",
        "Robotics"
      ],
      "subtask_category": [
        "model_evaluation",
        "safety_benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "C++",
      "repo_url": "https://github.com/npu-ius-lab/MoNA-Bench",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "depth-estimation",
        "uav",
        "benchmark",
        "safety"
      ],
      "id": 1011
    },
    {
      "name": "Oak AI Auto Eval Tools",
      "one_line_profile": "LLM-as-a-judge evaluation tools for educational resources",
      "detailed_description": "A set of tools developed by Oak National Academy to perform automated evaluation of lesson plans and educational resources using Large Language Models (LLM-as-a-judge).",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "llm_as_a_judge"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/oaknational/oak-ai-autoeval-tools",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-eval",
        "education",
        "automated-evaluation"
      ],
      "id": 1012
    },
    {
      "name": "Hallucination Probes",
      "one_line_profile": "Real-time detection of hallucinated entities in long-form generation",
      "detailed_description": "A tool for detecting hallucinations in Large Language Model generations, specifically focusing on entity-level errors in long-form text using probing techniques.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/obalcells/hallucination_probes",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "llm",
        "probing"
      ],
      "id": 1013
    },
    {
      "name": "LLM Proteomics Hallucination",
      "one_line_profile": "Hallucination risk evaluation for LLMs in clinical proteomics",
      "detailed_description": "A systematic evaluation framework and benchmark for detecting hallucinations in Large Language Models when interpreting clinical proteomics and mass spectrometry data.",
      "domains": [
        "AI3-04",
        "Bioinformatics"
      ],
      "subtask_category": [
        "hallucination_detection",
        "domain_specific_eval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/olaflaitinen/llm-proteomics-hallucination",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "proteomics",
        "hallucination",
        "clinical-ai"
      ],
      "id": 1014
    },
    {
      "name": "Meme-Safety-Bench",
      "one_line_profile": "Benchmark for evaluating safety of Vision-Language Models on memes",
      "detailed_description": "A benchmark study and dataset for assessing the safety and robustness of Vision-Language Models (VLMs) when processing meme-based content in the wild.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "multimodal_eval"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/oneonlee/Meme-Safety-Bench",
      "help_website": [],
      "license": null,
      "tags": [
        "vlm",
        "safety",
        "benchmark",
        "memes"
      ],
      "id": 1015
    },
    {
      "name": "GenAIEval",
      "one_line_profile": "OPEA evaluation framework for Generative AI performance and safety",
      "detailed_description": "A comprehensive evaluation toolkit from the Open Platform for Enterprise AI (OPEA) project, covering throughput, latency, accuracy, safety, and hallucination metrics for GenAI models.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "performance_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/opea-project/GenAIEval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "genai",
        "evaluation",
        "opea",
        "safety"
      ],
      "id": 1016
    },
    {
      "name": "CompassJudger",
      "one_line_profile": "All-in-one Judge Models for LLM evaluation",
      "detailed_description": "A collection of specialized 'Judge Models' developed by OpenCompass to perform automated evaluation of other Large Language Models, facilitating scalable and consistent assessment.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "llm_as_a_judge",
        "model_evaluation"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/open-compass/CompassJudger",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "judge-model",
        "opencompass",
        "llm-eval"
      ],
      "id": 1017
    },
    {
      "name": "VLMEvalKit",
      "one_line_profile": "Evaluation toolkit for Large Multi-modality Models",
      "detailed_description": "An open-source toolkit for evaluating Large Multi-modality Models (LMMs), supporting over 200 models and 80 benchmarks, enabling comprehensive assessment of vision-language capabilities.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "multimodal_eval",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/open-compass/VLMEvalKit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vlm",
        "lmm",
        "evaluation",
        "benchmark"
      ],
      "id": 1018
    },
    {
      "name": "OpenCompass",
      "one_line_profile": "Comprehensive LLM evaluation platform",
      "detailed_description": "A unified platform for evaluating Large Language Models across a wide range of datasets and capabilities, supporting distributed evaluation and various model architectures.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/open-compass/opencompass",
      "help_website": [
        "https://opencompass.org.cn/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-eval",
        "benchmark",
        "platform"
      ],
      "id": 1019
    },
    {
      "name": "OpenAI Evals",
      "one_line_profile": "Framework for evaluating LLMs and benchmark registry",
      "detailed_description": "A framework for evaluating Large Language Models and LLM systems, providing an open-source registry of benchmarks to test model capabilities and prevent regressions.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/openai/evals",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "openai",
        "evaluation",
        "benchmark"
      ],
      "id": 1020
    },
    {
      "name": "Safety Starter Agents",
      "one_line_profile": "Constrained RL agents for benchmarking safe exploration",
      "detailed_description": "A collection of basic constrained Reinforcement Learning agents designed to serve as baselines for benchmarking safe exploration algorithms in deep RL.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "reinforcement_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/openai/safety-starter-agents",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rl",
        "safety",
        "safe-exploration"
      ],
      "id": 1021
    },
    {
      "name": "OpenLIT",
      "one_line_profile": "OpenTelemetry-native LLM observability and evaluation platform",
      "detailed_description": "An open-source platform for AI engineering that provides OpenTelemetry-native observability, guardrails, and evaluation capabilities for LLMs and GPUs.",
      "domains": [
        "AI3-04",
        "AI3"
      ],
      "subtask_category": [
        "model_monitoring",
        "model_evaluation",
        "guardrails"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/openlit/openlit",
      "help_website": [
        "https://docs.openlit.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "observability",
        "opentelemetry",
        "llm-eval",
        "guardrails"
      ],
      "id": 1022
    },
    {
      "name": "AdvHat",
      "one_line_profile": "Real-world adversarial attack implementation on Face ID systems",
      "detailed_description": "A tool implementing real-world adversarial attacks against ArcFace Face ID systems using a sticker on a hat, useful for testing the robustness of face recognition models.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_testing"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/papermsucode/advhat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "adversarial-attack",
        "face-recognition",
        "robustness"
      ],
      "id": 1023
    },
    {
      "name": "Project Mantis",
      "one_line_profile": "Prompt injection tool for defense against LLM-driven cyberattacks",
      "detailed_description": "A framework exploring 'hacking back' AI hackers by using prompt injection as a defensive mechanism against LLM-driven cyberattacks, serving as a red-teaming tool.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_injection",
        "red_teaming",
        "defense"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/pasquini-dario/project_mantis",
      "help_website": [],
      "license": null,
      "tags": [
        "prompt-injection",
        "security",
        "llm"
      ],
      "id": 1024
    },
    {
      "name": "VideoHallucer",
      "one_line_profile": "Benchmark for hallucination detection in Large Video-Language Models",
      "detailed_description": "A comprehensive benchmark dataset and evaluation tool designed to detect and assess hallucinations in Large Video-Language Models (LVLMs).",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "multimodal_eval"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/patrick-tssn/VideoHallucer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "video-llm",
        "hallucination",
        "benchmark"
      ],
      "id": 1025
    },
    {
      "name": "Deck of Many Prompts",
      "one_line_profile": "Manual prompt injection and red teaming tool",
      "detailed_description": "A collection of prompts and a tool designed for manual red teaming and prompt injection testing against Large Language Models to identify security vulnerabilities.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming",
        "prompt_injection"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/peluche/deck-of-many-prompts",
      "help_website": [],
      "license": null,
      "tags": [
        "red-teaming",
        "prompt-injection",
        "security"
      ],
      "id": 1026
    },
    {
      "name": "Deep Mahalanobis Detector",
      "one_line_profile": "Framework for detecting out-of-distribution samples and adversarial attacks",
      "detailed_description": "A unified framework implementing the Mahalanobis distance-based method for detecting out-of-distribution (OOD) samples and adversarial attacks in deep neural networks.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "ood_detection",
        "adversarial_defense"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pokaxpoka/deep_Mahalanobis_detector",
      "help_website": [],
      "license": null,
      "tags": [
        "ood-detection",
        "adversarial-defense",
        "robustness"
      ],
      "id": 1027
    },
    {
      "name": "SelfCheckGPT",
      "one_line_profile": "Zero-resource black-box hallucination detection for LLMs",
      "detailed_description": "A tool for detecting hallucinations in Generative Large Language Models using a zero-resource, black-box approach that checks the consistency of sampled responses.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/potsawee/selfcheckgpt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "llm",
        "consistency-check"
      ],
      "id": 1028
    },
    {
      "name": "Adversarial Face Attack",
      "one_line_profile": "Black-box adversarial attack tool for face recognition systems",
      "detailed_description": "A tool implementing black-box adversarial attacks against public face recognition systems, useful for evaluating the robustness of biometric security models.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_testing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ppwwyyxx/Adversarial-Face-Attack",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "adversarial-attack",
        "face-recognition",
        "black-box"
      ],
      "id": 1029
    },
    {
      "name": "SecML Malware",
      "one_line_profile": "Adversarial attacks against malware detectors",
      "detailed_description": "A Python library for creating and testing adversarial attacks against machine learning-based Windows malware detectors, evaluating their robustness.",
      "domains": [
        "AI3-04",
        "Cybersecurity"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_testing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pralab/secml_malware",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "adversarial-ml",
        "malware-detection",
        "security"
      ],
      "id": 1030
    },
    {
      "name": "Prometheus Eval",
      "one_line_profile": "Evaluate LLM responses with Prometheus and GPT-4",
      "detailed_description": "A tool for evaluating Large Language Model responses using the Prometheus model or GPT-4, providing a structured way to assess generation quality.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "llm_as_a_judge"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/prometheus-eval/prometheus-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-eval",
        "prometheus",
        "judge-model"
      ],
      "id": 1031
    },
    {
      "name": "Promptfoo",
      "one_line_profile": "CLI tool for testing, red teaming, and evaluating LLMs",
      "detailed_description": "A CLI tool and library for testing prompts, agents, and RAG systems, supporting red teaming, vulnerability scanning, and performance comparison across multiple LLM providers.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming",
        "model_evaluation",
        "prompt_testing"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/promptfoo/promptfoo",
      "help_website": [
        "https://www.promptfoo.dev/"
      ],
      "license": "MIT",
      "tags": [
        "red-teaming",
        "prompt-engineering",
        "evaluation"
      ],
      "id": 1032
    },
    {
      "name": "Rebuff",
      "one_line_profile": "LLM Prompt Injection Detector",
      "detailed_description": "A security tool designed to detect and prevent prompt injection attacks in Large Language Model applications, enhancing the safety and robustness of AI systems.",
      "domains": [
        "AI3-04"
      ],
      "subtask_category": [
        "prompt_injection",
        "defense",
        "security"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/protectai/rebuff",
      "help_website": [
        "https://rebuff.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "prompt-injection",
        "security",
        "defense"
      ],
      "id": 1033
    },
    {
      "name": "RagaAI-Catalyst",
      "one_line_profile": "Comprehensive framework for Agent AI observability, monitoring, and evaluation",
      "detailed_description": "A Python SDK designed for the evaluation and debugging of Agentic AI systems. It provides features for tracing agents, LLMs, and tools, debugging multi-agent systems, and visualizing execution graphs. It supports the assessment of reliability and performance in AI applications.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "observability",
        "debugging"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/raga-ai-hub/RagaAI-Catalyst",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "agent-observability",
        "debugging"
      ],
      "id": 1034
    },
    {
      "name": "texture-vs-shape",
      "one_line_profile": "Evaluation artifacts for analyzing texture vs. shape bias in CNNs",
      "detailed_description": "Provides pre-trained models, datasets, and code to evaluate the inductive biases of Convolutional Neural Networks (CNNs), specifically measuring the trade-off between texture bias and shape bias. This tool helps in understanding model robustness and interpretability.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "robustness_analysis",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/rgeirhos/texture-vs-shape",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "cnn-bias",
        "robustness",
        "computer-vision"
      ],
      "id": 1035
    },
    {
      "name": "auto-evaluator",
      "one_line_profile": "Automated evaluation tool for LLM QA chains",
      "detailed_description": "A lightweight tool designed to evaluate the performance of Question Answering (QA) chains powered by Large Language Models. It automates the process of judging response quality, facilitating rapid iteration and testing of RAG (Retrieval-Augmented Generation) systems.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "qa_testing"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/rlancemartin/auto-evaluator",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-eval",
        "rag",
        "qa-evaluation"
      ],
      "id": 1036
    },
    {
      "name": "winogender-schemas",
      "one_line_profile": "Benchmark dataset for evaluating gender bias in coreference resolution",
      "detailed_description": "A collection of Winograd-schema-style sentences designed to test for the presence of gender bias in automated coreference resolution systems. It serves as a diagnostic tool for evaluating the fairness and robustness of NLP models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "bias_evaluation",
        "fairness_testing"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/rudinger/winogender-schemas",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gender-bias",
        "nlp-evaluation",
        "coreference-resolution"
      ],
      "id": 1037
    },
    {
      "name": "PsiloQA",
      "one_line_profile": "Pipeline for constructing hallucination detection datasets",
      "detailed_description": "Automates the creation of multilingual, span-level hallucination detection datasets with context. This pipeline aids in the evaluation of Large Language Models by generating data to test their faithfulness and detect hallucinations.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "dataset_generation",
        "hallucination_detection"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/s-nlp/PsiloQA",
      "help_website": [],
      "license": null,
      "tags": [
        "hallucination",
        "dataset-construction",
        "llm-evaluation"
      ],
      "id": 1038
    },
    {
      "name": "AuditNLG",
      "one_line_profile": "Library for auditing trustworthiness in Natural Language Generation",
      "detailed_description": "A Python library developed by Salesforce for auditing and evaluating the trustworthiness of Generative AI language models. It provides metrics and utilities to assess safety, bias, and quality in NLG outputs.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_auditing",
        "trustworthiness_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/salesforce/AuditNLG",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "nlg-evaluation",
        "trustworthy-ai",
        "auditing"
      ],
      "id": 1039
    },
    {
      "name": "YESciEval",
      "one_line_profile": "Robust LLM-as-a-Judge for Scientific Question Answering",
      "detailed_description": "An evaluation framework designed to assess the performance of Large Language Models in scientific question answering tasks. It employs a robust 'LLM-as-a-Judge' methodology to provide reliable metrics for scientific reasoning capabilities.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "scientific_qa"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sciknoworg/YESciEval",
      "help_website": [
        "https://pypi.org/project/YESciEval/"
      ],
      "license": "MIT",
      "tags": [
        "llm-as-a-judge",
        "scientific-qa",
        "evaluation"
      ],
      "id": 1040
    },
    {
      "name": "frai",
      "one_line_profile": "Open-source toolkit for responsible AI governance and evaluation",
      "detailed_description": "A CLI and SDK toolkit designed to facilitate responsible AI practices. It includes features to scan code, collect evidence, generate model cards, manage risk files, and run evaluations, supporting the governance and documentation of AI systems.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "responsible_ai",
        "model_governance",
        "evaluation"
      ],
      "application_level": "tool",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/sebuzdugan/frai",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "responsible-ai",
        "model-cards",
        "governance"
      ],
      "id": 1041
    },
    {
      "name": "ST-WebAgentBench",
      "one_line_profile": "Benchmark for evaluating safety and trustworthiness in web agents",
      "detailed_description": "A benchmark suite specifically designed to evaluate the safety and trustworthiness of AI agents operating in web environments, focusing on enterprise scenarios. It helps identify risks and validate agent behavior.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "agent_evaluation",
        "safety_benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/segev-shlomov/ST-WebAgentBench",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "web-agents",
        "safety-benchmark",
        "trustworthiness"
      ],
      "id": 1042
    },
    {
      "name": "robust-physical-attack",
      "one_line_profile": "Physical adversarial attack tool for object detectors",
      "detailed_description": "Implements physical adversarial attacks designed to fool object detection models like Faster R-CNN. This tool is used for evaluating the robustness of computer vision models against real-world physical perturbations.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_testing"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/shangtse/robust-physical-attack",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "adversarial-attack",
        "object-detection",
        "robustness"
      ],
      "id": 1043
    },
    {
      "name": "prompt-injection",
      "one_line_profile": "Assessment tool for prompt injection risks in GPTs",
      "detailed_description": "A repository containing code and data to assess and demonstrate prompt injection risks in user-designed GPTs. It serves as a resource for red teaming and evaluating the security of LLM applications.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming",
        "security_evaluation"
      ],
      "application_level": "tool",
      "primary_language": null,
      "repo_url": "https://github.com/sherdencooper/prompt-injection",
      "help_website": [],
      "license": null,
      "tags": [
        "prompt-injection",
        "llm-security",
        "red-teaming"
      ],
      "id": 1044
    },
    {
      "name": "ad_examples",
      "one_line_profile": "Collection of anomaly detection methods and adversarial attacks",
      "detailed_description": "A comprehensive library implementing various anomaly detection algorithms (point-based, graph, time series) and adversarial attacks (e.g., on Graph Convolutional Networks). It serves as a toolkit for researching and evaluating anomaly detection robustness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "anomaly_detection",
        "adversarial_attack",
        "algorithm_library"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shubhomoydas/ad_examples",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "anomaly-detection",
        "adversarial-learning",
        "graph-neural-networks"
      ],
      "id": 1045
    },
    {
      "name": "llm-security-prompt-injection",
      "one_line_profile": "Framework for detecting malicious prompts in LLMs",
      "detailed_description": "Investigates Large Language Model security by implementing binary classification of input prompts to detect malicious prompt injection attacks. It includes approaches using classical ML and fine-tuned LLMs for security evaluation.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "security_evaluation",
        "prompt_injection_detection"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/sinanw/llm-security-prompt-injection",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-security",
        "prompt-injection",
        "classification"
      ],
      "id": 1046
    },
    {
      "name": "local-llm-judge",
      "one_line_profile": "Tool for using local LLMs as search relevance judges",
      "detailed_description": "A utility that enables the use of locally hosted Large Language Models to evaluate search relevance. It facilitates the 'LLM-as-a-Judge' pattern for offline or privacy-preserving evaluation workflows.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "search_relevance"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/softwaredoug/local-llm-judge",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-as-a-judge",
        "search-evaluation",
        "local-llm"
      ],
      "id": 1047
    },
    {
      "name": "AIR-Bench 2024",
      "one_line_profile": "Safety benchmark aligning with AI regulations and policies",
      "detailed_description": "A safety evaluation benchmark designed to align with emerging government regulations and corporate policies for AI. It provides a standardized way to assess the compliance and safety risks of foundation models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "compliance_testing"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/stanford-crfm/air-bench-2024",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-safety",
        "benchmark",
        "regulation"
      ],
      "id": 1048
    },
    {
      "name": "HELM",
      "one_line_profile": "Holistic Evaluation of Language Models framework",
      "detailed_description": "A comprehensive framework developed by Stanford CRFM for the holistic, reproducible, and transparent evaluation of foundation models. It covers a wide range of metrics including accuracy, robustness, fairness, and bias across diverse scenarios.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanford-crfm/helm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "foundation-models",
        "benchmarking"
      ],
      "id": 1049
    },
    {
      "name": "PhiSat-2 Trustworthy AI",
      "one_line_profile": "Trustworthy AI pipeline for onboard satellite Earth Observation data processing",
      "detailed_description": "A toolchain for deploying trustworthy AI on satellite hardware, featuring quantization (PyTorch to ONNX to INT8), calibration, and telemetry for Earth Observation tasks.",
      "domains": [
        "AI3",
        "AI3-04",
        "Earth Science"
      ],
      "subtask_category": [
        "model_deployment",
        "trustworthiness_calibration",
        "onboard_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sylvesterkaczmarek/phisat2-trustworthy-onboard-ai",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "satellite-ai",
        "edge-computing",
        "trustworthy-ai",
        "earth-observation"
      ],
      "id": 1050
    },
    {
      "name": "AutoTrust",
      "one_line_profile": "Benchmark for assessing trustworthiness of Vision-Language Models in autonomous driving",
      "detailed_description": "A benchmark suite designed to evaluate the trustworthiness of DriveVLMs across critical safety dimensions, ensuring reliable operation in autonomous driving scenarios.",
      "domains": [
        "AI3",
        "AI3-04",
        "Autonomous Systems"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "trustworthiness_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/taco-group/AutoTrust",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "autonomous-driving",
        "vlm",
        "safety-benchmark",
        "trustworthiness"
      ],
      "id": 1051
    },
    {
      "name": "AISafetyLab",
      "one_line_profile": "Comprehensive framework for AI safety attack, defense, and evaluation",
      "detailed_description": "A framework integrating various methods for AI safety research, including adversarial attacks, defense mechanisms, and safety evaluation metrics for machine learning models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "safety_defense",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-coai/AISafetyLab",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ai-safety",
        "adversarial-ml",
        "robustness"
      ],
      "id": 1052
    },
    {
      "name": "DiaSafety",
      "one_line_profile": "Benchmark and dataset for evaluating safety of conversational models",
      "detailed_description": "A repository providing a taxonomy, dataset, and benchmark suite for assessing the safety of conversational AI models, focusing on dialogue safety risks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "dialogue_safety"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-coai/DiaSafety",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dialogue-safety",
        "benchmark",
        "llm-safety"
      ],
      "id": 1053
    },
    {
      "name": "Safety-Prompts",
      "one_line_profile": "Chinese safety prompts dataset for evaluating LLM safety",
      "detailed_description": "A collection of Chinese safety prompts designed to evaluate and improve the safety of Large Language Models, covering various risk categories.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_evaluation",
        "red_teaming"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/thu-coai/Safety-Prompts",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "safety-prompts",
        "llm-evaluation",
        "chinese-llm"
      ],
      "id": 1054
    },
    {
      "name": "SafetyBench",
      "one_line_profile": "Comprehensive benchmark for evaluating LLM safety",
      "detailed_description": "A comprehensive benchmark suite for evaluating the safety of Large Language Models across multiple languages and safety dimensions, supporting automated evaluation.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "automated_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-coai/SafetyBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-safety",
        "benchmark",
        "evaluation-framework"
      ],
      "id": 1055
    },
    {
      "name": "MLA-Trust",
      "one_line_profile": "Toolbox for benchmarking Multimodal LLM Agents trustworthiness",
      "detailed_description": "A benchmarking toolbox designed to assess the trustworthiness of Multimodal LLM Agents across dimensions such as truthfulness, controllability, safety, and privacy.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "agent_evaluation",
        "trustworthiness_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-ml/MLA-Trust",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multimodal-agents",
        "trustworthiness",
        "benchmark"
      ],
      "id": 1056
    },
    {
      "name": "MMTrustEval",
      "one_line_profile": "Toolbox for benchmarking trustworthiness of multimodal LLMs",
      "detailed_description": "A comprehensive toolbox for evaluating the trustworthiness of Multimodal Large Language Models, covering safety, hallucination, and robustness aspects.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "multimodal_evaluation",
        "trustworthiness_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-ml/MMTrustEval",
      "help_website": [],
      "license": "CC-BY-SA-4.0",
      "tags": [
        "multimodal-llm",
        "trustworthiness",
        "evaluation-toolbox"
      ],
      "id": 1057
    },
    {
      "name": "OpenAttack",
      "one_line_profile": "Open-source package for textual adversarial attacks",
      "detailed_description": "A Python library for generating textual adversarial examples, supporting various attack models, evaluation metrics, and victim models for NLP robustness research.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_testing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/thunlp/OpenAttack",
      "help_website": [
        "https://openattack.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "adversarial-nlp",
        "text-attack",
        "robustness"
      ],
      "id": 1058
    },
    {
      "name": "Tiger",
      "one_line_profile": "Toolkit for building trustworthy LLM applications",
      "detailed_description": "A toolkit comprising TigerArmor for AI safety, TigerRAG for retrieval-augmented generation, and TigerTune for fine-tuning, aiming to build secure and reliable LLM systems.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_guardrails",
        "rag_optimization",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/tigerlab-ai/tiger",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-safety",
        "rag",
        "llm-toolkit"
      ],
      "id": 1059
    },
    {
      "name": "OS-Harm",
      "one_line_profile": "Benchmark for measuring safety of computer use agents",
      "detailed_description": "A benchmark designed to evaluate the safety of agents that interact with operating systems (OS-use agents), identifying potential risks in automated computer control.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "agent_safety",
        "safety_benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/tml-epfl/os-harm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent-safety",
        "benchmark",
        "os-agents"
      ],
      "id": 1060
    },
    {
      "name": "Anamorpher",
      "one_line_profile": "Image scaling attacks for multi-modal prompt injection",
      "detailed_description": "A tool for generating adversarial images using scaling attacks to perform prompt injection in multi-modal models, bypassing visual safety filters.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "prompt_injection",
        "multimodal_security"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/trailofbits/anamorpher",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "adversarial-images",
        "prompt-injection",
        "security"
      ],
      "id": 1061
    },
    {
      "name": "TransformerLab",
      "one_line_profile": "Platform for LLM training, fine-tuning, and evaluation",
      "detailed_description": "A local application platform that provides a GUI for interacting with, training, fine-tuning, and evaluating Large Language Models and Diffusion models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "fine_tuning",
        "experiment_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/transformerlab/transformerlab-app",
      "help_website": [
        "https://transformerlab.ai"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "llm-platform",
        "fine-tuning",
        "evaluation-gui"
      ],
      "id": 1062
    },
    {
      "name": "TruLens",
      "one_line_profile": "Evaluation and tracking for LLM experiments and agents",
      "detailed_description": "A library for evaluating and tracking the performance of LLM applications and agents, providing feedback functions (RAG triad) and experiment management.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "experiment_tracking",
        "rag_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/truera/trulens",
      "help_website": [
        "https://www.trulens.org"
      ],
      "license": "MIT",
      "tags": [
        "llm-evaluation",
        "observability",
        "rag"
      ],
      "id": 1063
    },
    {
      "name": "SafeBench",
      "one_line_profile": "Benchmark for evaluating autonomous vehicles in safety-critical scenarios",
      "detailed_description": "A platform and benchmark for evaluating the safety of autonomous driving algorithms in critical scenarios, supporting simulation and adversarial testing.",
      "domains": [
        "AI3",
        "AI3-04",
        "Autonomous Systems"
      ],
      "subtask_category": [
        "safety_benchmarking",
        "simulation_testing"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/trust-ai/SafeBench",
      "help_website": [
        "https://trust-ai.github.io/SafeBench/"
      ],
      "license": "MIT",
      "tags": [
        "autonomous-driving",
        "safety-benchmark",
        "simulation"
      ],
      "id": 1064
    },
    {
      "name": "Folly",
      "one_line_profile": "Playground for LLM prompt injection and jailbreaking",
      "detailed_description": "An open-source playground tool designed for testing and experimenting with prompt injection and jailbreaking techniques on Large Language Models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "red_teaming",
        "jailbreak_testing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/user1342/Folly",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "prompt-injection",
        "jailbreak",
        "playground"
      ],
      "id": 1065
    },
    {
      "name": "PyTorch CNN Adversarial Attacks",
      "one_line_profile": "PyTorch implementation of CNN adversarial attack techniques",
      "detailed_description": "A collection of implementations for various adversarial attack algorithms on Convolutional Neural Networks using PyTorch, serving as a reference library for robustness research.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "robustness_research"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/utkuozbulak/pytorch-cnn-adversarial-attacks",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "adversarial-attacks",
        "pytorch",
        "cnn-robustness"
      ],
      "id": 1066
    },
    {
      "name": "Ragas",
      "one_line_profile": "Framework for evaluating Retrieval Augmented Generation (RAG) pipelines",
      "detailed_description": "A framework designed to evaluate RAG pipelines using metrics like faithfulness, answer relevance, and context precision, enabling automated assessment of LLM applications.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "automated_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vibrantlabsai/ragas",
      "help_website": [
        "https://docs.ragas.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag-evaluation",
        "llm-metrics",
        "automated-testing"
      ],
      "id": 1067
    },
    {
      "name": "caption-eval",
      "one_line_profile": "Automated metrics for sentence and image caption evaluation",
      "detailed_description": "A Python library providing standard evaluation metrics (BLEU, METEOR, ROUGE, CIDEr, SPICE) for assessing the quality of image captions and sentence generation models.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "natural_language_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vsubhashini/caption-eval",
      "help_website": [],
      "license": null,
      "tags": [
        "evaluation-metrics",
        "nlp",
        "image-captioning",
        "bleu",
        "cider"
      ],
      "id": 1068
    },
    {
      "name": "Adversarial Box",
      "one_line_profile": "PyTorch library for adversarial attacks and robust training",
      "detailed_description": "A toolbox for generating adversarial examples and performing adversarial training with PyTorch, supporting various attack methods to evaluate and improve model robustness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "adversarial_attack",
        "adversarial_training",
        "robustness"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wanglouis49/pytorch-adversarial_box",
      "help_website": [],
      "license": null,
      "tags": [
        "pytorch",
        "adversarial-attacks",
        "robustness",
        "security"
      ],
      "id": 1069
    },
    {
      "name": "Circle Guard Bench",
      "one_line_profile": "Benchmark for evaluating LLM guardrail systems",
      "detailed_description": "A benchmark suite designed to evaluate the protection capabilities and effectiveness of Large Language Model (LLM) guard systems, including guardrails and safeguards against various attacks.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_evaluation",
        "guardrail_benchmarking",
        "red_teaming"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/whitecircle-ai/circle-guard-bench",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-safety",
        "benchmark",
        "guardrails",
        "red-teaming"
      ],
      "id": 1070
    },
    {
      "name": "whylogs",
      "one_line_profile": "Data logging and quality monitoring library for ML/AI pipelines",
      "detailed_description": "An open-source library for logging data profiles, monitoring data quality, and tracking model performance over time. It enables privacy-preserving data collection and robustness checks for machine learning workflows.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "data_quality",
        "model_monitoring",
        "drift_detection"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/whylabs/whylogs",
      "help_website": [
        "https://whylabs.ai/whylogs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-logging",
        "mlops",
        "data-quality",
        "model-monitoring"
      ],
      "id": 1071
    },
    {
      "name": "RiOSWorld",
      "one_line_profile": "Benchmark for assessing risks of multimodal computer-use agents",
      "detailed_description": "A benchmark environment and dataset for evaluating the safety and risks associated with multimodal agents that operate computer interfaces, focusing on robustness and safety in agentic workflows.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "agent_evaluation",
        "safety_benchmarking",
        "multimodal_agents"
      ],
      "application_level": "dataset",
      "primary_language": "HTML",
      "repo_url": "https://github.com/yjyddq/RiOSWorld",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "multimodal-agents",
        "ai-safety",
        "neurips-2025"
      ],
      "id": 1072
    },
    {
      "name": "EasyLM",
      "one_line_profile": "JAX/Flax library for training, fine-tuning, and serving LLMs",
      "detailed_description": "A comprehensive solution for Large Language Model (LLM) pre-training, fine-tuning, evaluation, and serving using JAX and Flax. It simplifies scaling LLMs on TPU/GPU clusters.",
      "domains": [
        "AI3",
        "AI3-01",
        "AI3-02"
      ],
      "subtask_category": [
        "model_training",
        "model_serving",
        "fine_tuning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/young-geng/EasyLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jax",
        "flax",
        "llm",
        "distributed-training"
      ],
      "id": 1073
    },
    {
      "name": "MT-Consistency",
      "one_line_profile": "Framework for evaluating LLM acquiescence bias and consistency",
      "detailed_description": "A research framework investigating Large Language Models' tendency for acquiescence bias in sequential QA. It includes evaluation methods, datasets, and benchmarks to assess conversational consistency and robustness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "consistency_evaluation",
        "bias_evaluation",
        "robustness"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yubol-bobo/MT-Consistency",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-bias",
        "consistency",
        "evaluation",
        "qa"
      ],
      "id": 1074
    },
    {
      "name": "GLM-ASR",
      "one_line_profile": "Robust open-source speech recognition model",
      "detailed_description": "A robust 1.5B parameter speech recognition model (GLM-ASR-Nano) designed for high-quality automatic speech recognition tasks, serving as a tool for audio data analysis.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "speech_recognition",
        "audio_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zai-org/GLM-ASR",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "asr",
        "speech-recognition",
        "glm",
        "audio-processing"
      ],
      "id": 1075
    },
    {
      "name": "PE-RLHF",
      "one_line_profile": "RLHF framework incorporating physics knowledge for safe autonomous driving",
      "detailed_description": "Implementation of Reinforcement Learning with Human Feedback (RLHF) augmented with physics knowledge, designed to improve the safety and trustworthiness of autonomous driving agents.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "safety_alignment",
        "autonomous_driving"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zilin-huang/PE-RLHF",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rlhf",
        "autonomous-driving",
        "physics-informed",
        "safety"
      ],
      "id": 1076
    },
    {
      "name": "ChineseHarm-bench",
      "one_line_profile": "Benchmark for detecting harmful content in Chinese LLMs",
      "detailed_description": "A benchmark dataset and evaluation suite for detecting harmful content in Chinese Large Language Models, facilitating safety alignment and red teaming research.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "safety_evaluation",
        "harmful_content_detection"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/ChineseHarm-bench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "chinese-llm",
        "safety",
        "harm-detection"
      ],
      "id": 1077
    },
    {
      "name": "FactCHD",
      "one_line_profile": "Benchmark for fact-conflicting hallucination detection",
      "detailed_description": "A benchmark specifically designed to evaluate the detection of fact-conflicting hallucinations in Large Language Models, supporting research in model faithfulness.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "benchmark"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/FactCHD",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "benchmark",
        "fact-checking"
      ],
      "id": 1078
    },
    {
      "name": "HyperGen",
      "one_line_profile": "Optimized inference and fine-tuning framework for diffusion models",
      "detailed_description": "A framework designed to optimize the inference and fine-tuning of diffusion models (image and video), offering significant speed improvements and reduced VRAM usage compared to standard implementations.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "model_finetuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/0xCrunchyy/hypergen",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "diffusion-models",
        "inference-optimization",
        "fine-tuning"
      ],
      "id": 1079
    },
    {
      "name": "micronet",
      "one_line_profile": "Model compression and deployment library",
      "detailed_description": "A library for neural network model compression and deployment, supporting quantization (QAT, PTQ, Low-Bit), pruning (channel pruning), and deployment optimization via TensorRT.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "quantization",
        "pruning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/666DZY666/micronet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "quantization",
        "pruning",
        "tensorrt",
        "model-compression"
      ],
      "id": 1080
    },
    {
      "name": "JetStream",
      "one_line_profile": "Throughput and memory optimized LLM inference engine for XLA devices",
      "detailed_description": "A high-performance inference engine designed for Large Language Models (LLMs), optimized for throughput and memory efficiency on XLA devices such as TPUs.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "throughput_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AI-Hypercomputer/JetStream",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-inference",
        "tpu",
        "xla",
        "optimization"
      ],
      "id": 1081
    },
    {
      "name": "optimum-transformers",
      "one_line_profile": "Accelerated NLP pipelines for fast inference on CPU and GPU",
      "detailed_description": "A library providing accelerated inference pipelines for NLP models, built upon Hugging Face Transformers, Optimum, and ONNX Runtime to enhance performance on CPUs and GPUs.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_acceleration",
        "nlp_pipeline"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AlekseyKorshuk/optimum-transformers",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "nlp",
        "inference",
        "onnx",
        "optimization"
      ],
      "id": 1082
    },
    {
      "name": "llumnix",
      "one_line_profile": "Efficient multi-instance LLM serving system",
      "detailed_description": "A serving system designed for efficient and easy deployment of multiple Large Language Model (LLM) instances, optimizing resource utilization and request handling.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "resource_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/AlibabaPAI/llumnix",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-serving",
        "distributed-systems",
        "inference"
      ],
      "id": 1083
    },
    {
      "name": "REASONING_COMPILER",
      "one_line_profile": "LLM-guided optimizations for efficient model serving",
      "detailed_description": "A compiler-based approach that utilizes LLMs to guide optimizations for efficient model serving, as presented in NeurIPS 2025.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "serving_optimization",
        "compiler_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Anna-Bele/REASONING_COMPILER",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "compiler",
        "serving-optimization"
      ],
      "id": 1084
    },
    {
      "name": "AutoGPTQ",
      "one_line_profile": "Easy-to-use LLM quantization package based on GPTQ",
      "detailed_description": "A library providing user-friendly APIs for quantizing Large Language Models (LLMs) using the GPTQ algorithm, enabling efficient inference on consumer hardware.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_quantization",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AutoGPTQ/AutoGPTQ",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gptq",
        "quantization",
        "llm"
      ],
      "id": 1085
    },
    {
      "name": "BitNet-Transformers",
      "one_line_profile": "1-bit Transformer implementation for LLMs",
      "detailed_description": "A PyTorch implementation of the BitNet architecture, enabling 1-bit scaling for Large Language Models within the Hugging Face Transformers ecosystem.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_architecture",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Beomi/BitNet-Transformers",
      "help_website": [],
      "license": null,
      "tags": [
        "bitnet",
        "1-bit",
        "transformers",
        "quantization"
      ],
      "id": 1086
    },
    {
      "name": "LMDeploy-Jetson",
      "one_line_profile": "Offline LLM deployment tools for NVIDIA Jetson platform",
      "detailed_description": "A toolkit and set of scripts for deploying Large Language Models (LLMs) offline on NVIDIA Jetson edge devices, facilitating embodied intelligence applications.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "edge_deployment",
        "inference_serving"
      ],
      "application_level": "workflow",
      "primary_language": null,
      "repo_url": "https://github.com/BestAnHongjun/LMDeploy-Jetson",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jetson",
        "edge-computing",
        "llm-deployment"
      ],
      "id": 1087
    },
    {
      "name": "Audio-Denoiser-ONNX",
      "one_line_profile": "Audio denoising tool using ONNX Runtime",
      "detailed_description": "A tool utilizing ONNX Runtime to perform audio denoising, applicable for cleaning scientific audio data or speech signals.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "signal_processing",
        "audio_denoising"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DakeQQ/Audio-Denoiser-ONNX",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "audio-processing",
        "onnx",
        "denoising"
      ],
      "id": 1088
    },
    {
      "name": "F5-TTS-ONNX",
      "one_line_profile": "F5-TTS implementation using ONNX Runtime",
      "detailed_description": "An implementation of the F5-TTS text-to-speech model optimized for inference using ONNX Runtime.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "speech_synthesis",
        "inference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DakeQQ/F5-TTS-ONNX",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tts",
        "onnx",
        "inference"
      ],
      "id": 1089
    },
    {
      "name": "ReflectionFlow",
      "one_line_profile": "Inference-time optimization for text-to-image diffusion models",
      "detailed_description": "A method and tool for scaling inference-time optimization for text-to-image diffusion models via Reflection Tuning, improving generation quality.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "image_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Diffusion-CoT/ReflectionFlow",
      "help_website": [],
      "license": null,
      "tags": [
        "diffusion-models",
        "inference-time-optimization"
      ],
      "id": 1090
    },
    {
      "name": "keras_compressor",
      "one_line_profile": "Model compression CLI tool for Keras",
      "detailed_description": "A Command Line Interface tool for compressing Keras models, facilitating efficient deployment.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "deployment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DwangoMediaVillage/keras_compressor",
      "help_website": [],
      "license": null,
      "tags": [
        "keras",
        "compression",
        "cli"
      ],
      "id": 1091
    },
    {
      "name": "transformer-deploy",
      "one_line_profile": "Efficient CPU/GPU inference server for Transformer models",
      "detailed_description": "An enterprise-grade inference server designed for efficient and scalable deployment of Hugging Face transformer models on CPUs and GPUs.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "model_deployment"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/ELS-RD/transformer-deploy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "transformers",
        "inference-server",
        "gpu-acceleration"
      ],
      "id": 1092
    },
    {
      "name": "ENOVA",
      "one_line_profile": "Serverless LLM serving with autoscaling",
      "detailed_description": "A deployment, monitoring, and autoscaling service framework designed for serverless serving of Large Language Models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "autoscaling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Emerging-AI/ENOVA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "serverless",
        "llm-serving",
        "autoscaling"
      ],
      "id": 1093
    },
    {
      "name": "candle-vllm",
      "one_line_profile": "Efficient local LLM inference and serving platform",
      "detailed_description": "A platform for efficient inference and serving of local LLMs, written in Rust and providing an OpenAI-compatible API server.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "local_inference"
      ],
      "application_level": "service",
      "primary_language": "Rust",
      "repo_url": "https://github.com/EricLBuehler/candle-vllm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rust",
        "llm-serving",
        "inference"
      ],
      "id": 1094
    },
    {
      "name": "FaceONNX",
      "one_line_profile": "Face recognition library based on ONNX Runtime",
      "detailed_description": "A library for face recognition and analytics utilizing Deep Neural Networks and ONNX Runtime for inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "computer_vision",
        "biometrics",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/FaceONNX/FaceONNX",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "face-recognition",
        "onnx",
        "c-sharp"
      ],
      "id": 1095
    },
    {
      "name": "fasterai",
      "one_line_profile": "Model pruning and distillation library for FastAI/PyTorch",
      "detailed_description": "A library to prune and distill neural network models using FastAI and PyTorch, aiming to reduce model size and increase inference speed.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_pruning",
        "knowledge_distillation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/FasterAI-Labs/fasterai",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pruning",
        "distillation",
        "fastai",
        "optimization"
      ],
      "id": 1096
    },
    {
      "name": "RoboBrain",
      "one_line_profile": "Unified brain model for robotic manipulation",
      "detailed_description": "A unified model framework for robotic manipulation, bridging abstract reasoning to concrete control, useful for robotics research and simulation.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "robotics_modeling",
        "control_inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/FlagOpen/RoboBrain",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "robotics",
        "manipulation",
        "foundation-model"
      ],
      "id": 1097
    },
    {
      "name": "nano-vllm",
      "one_line_profile": "Lightweight implementation of vLLM for LLM inference",
      "detailed_description": "A lightweight version or implementation of the vLLM library designed for efficient Large Language Model serving and inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/GeeeekExplorer/nano-vllm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "inference",
        "vllm",
        "serving"
      ],
      "id": 1098
    },
    {
      "name": "Depths-CPP",
      "one_line_profile": "High-performance C++ inference for depth estimation models",
      "detailed_description": "A C++ application and header library for real-time metric depth estimation using Depth-Anything-V2 models, supporting ONNX Runtime and OpenCV.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "depth_estimation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/Geekgineer/Depths-CPP",
      "help_website": [],
      "license": null,
      "tags": [
        "depth-estimation",
        "cpp",
        "onnx",
        "inference"
      ],
      "id": 1099
    },
    {
      "name": "YOLOs-CPP",
      "one_line_profile": "C++ inference headers for YOLO object detection models",
      "detailed_description": "High-performance C++ headers for real-time object detection and segmentation using various YOLO model versions, leveraging ONNX Runtime.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "object_detection"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/Geekgineer/YOLOs-CPP",
      "help_website": [],
      "license": null,
      "tags": [
        "yolo",
        "object-detection",
        "cpp",
        "onnx"
      ],
      "id": 1100
    },
    {
      "name": "furnace",
      "one_line_profile": "Rust-based ML inference server using Burn framework",
      "detailed_description": "A machine learning inference server built with Rust and the Burn framework, designed for high performance.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving"
      ],
      "application_level": "service",
      "primary_language": "Rust",
      "repo_url": "https://github.com/Gilfeather/furnace",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rust",
        "inference-server",
        "burn-framework"
      ],
      "id": 1101
    },
    {
      "name": "BurstGPT",
      "one_line_profile": "Workload traces for optimizing LLM serving systems",
      "detailed_description": "A dataset of ChatGPT and GPT-4 workload traces designed to help researchers and developers optimize Large Language Model serving systems.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "benchmarking",
        "system_optimization"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/HPMLL/BurstGPT",
      "help_website": [],
      "license": "CC-BY-4.0",
      "tags": [
        "workload-trace",
        "llm-serving",
        "optimization",
        "dataset"
      ],
      "id": 1102
    },
    {
      "name": "YOLO-Multi-Backbones-Attention",
      "one_line_profile": "Compressed YOLOv3 with lightweight backbones and attention",
      "detailed_description": "A model compression tool/implementation for YOLOv3 incorporating multiple lightweight backbones (ShuffleNetV2, GhostNet), attention mechanisms, pruning, and quantization.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "object_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HaloTrouvaille/YOLO-Multi-Backbones-Attention",
      "help_website": [],
      "license": null,
      "tags": [
        "model-compression",
        "yolo",
        "pruning",
        "quantization"
      ],
      "id": 1103
    },
    {
      "name": "FlashTTS",
      "one_line_profile": "High-quality Chinese TTS and voice cloning service",
      "detailed_description": "A text-to-speech service and library based on SparkTTS and OrpheusTTS models, providing high-quality Chinese speech synthesis and voice cloning capabilities.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "text_to_speech"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/HuiResearch/FlashTTS",
      "help_website": [],
      "license": null,
      "tags": [
        "tts",
        "voice-cloning",
        "speech-synthesis"
      ],
      "id": 1104
    },
    {
      "name": "onnxmlir-triton-backend",
      "one_line_profile": "ONNX MLIR backend for Triton Inference Server",
      "detailed_description": "A backend component that allows the usage of ONNX MLIR compiled models with the Triton Inference Server, enabling optimized inference on supported hardware.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "compiler_backend"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/IBM/onnxmlir-triton-backend",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "triton-inference-server",
        "onnx",
        "mlir",
        "backend"
      ],
      "id": 1105
    },
    {
      "name": "gptq",
      "one_line_profile": "Post-training quantization for generative pretrained transformers",
      "detailed_description": "The official implementation of GPTQ, a method for accurate post-training quantization of generative pretrained transformers to reduce model size and inference cost.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IST-DASLab/gptq",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "llm",
        "compression",
        "gptq"
      ],
      "id": 1106
    },
    {
      "name": "gptq-gguf-toolkit",
      "one_line_profile": "Toolkit for GPTQ quantization with GGUF format",
      "detailed_description": "A toolkit for performing efficient non-uniform quantization using GPTQ specifically for models in the GGUF format.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "model_conversion"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IST-DASLab/gptq-gguf-toolkit",
      "help_website": [],
      "license": null,
      "tags": [
        "quantization",
        "gguf",
        "gptq"
      ],
      "id": 1107
    },
    {
      "name": "qmoe",
      "one_line_profile": "Sub-1-bit compression for trillion-parameter models",
      "detailed_description": "Implementation of QMoE, a compression method designed for practical sub-1-bit compression of massive Mixture-of-Experts (MoE) models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IST-DASLab/qmoe",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compression",
        "moe",
        "quantization",
        "llm"
      ],
      "id": 1108
    },
    {
      "name": "py-txi",
      "one_line_profile": "Python wrapper for HuggingFace TGI and TEI servers",
      "detailed_description": "A Python client wrapper for interacting with HuggingFace's Text Generation Inference (TGI) and Text Embedding Inference (TEI) servers.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_client",
        "api_wrapper"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IlyasMoutawwakil/py-txi",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tgi",
        "tei",
        "inference",
        "client"
      ],
      "id": 1109
    },
    {
      "name": "InferenceMAX",
      "one_line_profile": "Continuous inference benchmarking for AI hardware",
      "detailed_description": "An open-source benchmarking tool for continuous evaluation of inference performance across various AI hardware accelerators (GPUs, TPUs, etc.).",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/InferenceMAX/InferenceMAX",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmarking",
        "inference",
        "hardware-evaluation"
      ],
      "id": 1110
    },
    {
      "name": "nlp-architect",
      "one_line_profile": "Library for exploring NLP topologies and optimization techniques",
      "detailed_description": "A model library by Intel Labs for exploring state-of-the-art deep learning topologies and techniques for optimizing Natural Language Processing neural networks.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "modeling",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IntelLabs/nlp-architect",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "optimization",
        "deep-learning",
        "intel"
      ],
      "id": 1111
    },
    {
      "name": "gbnfgen",
      "one_line_profile": "TypeScript generator for llama.cpp grammars",
      "detailed_description": "A tool to generate GBNF grammars for llama.cpp directly from TypeScript interfaces, enabling structured output generation from LLMs.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_utility",
        "structured_generation"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/IntrinsicLabsAI/gbnfgen",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "grammar",
        "llama.cpp",
        "structured-output"
      ],
      "id": 1112
    },
    {
      "name": "chatglm-q",
      "one_line_profile": "ChatGLM2 implementation for GPTQ quantization",
      "detailed_description": "An implementation of ChatGLM2 specifically designed to support GPTQ quantization for efficient inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "inference_serving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/K024/chatglm-q",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chatglm",
        "gptq",
        "quantization"
      ],
      "id": 1113
    },
    {
      "name": "fastT5",
      "one_line_profile": "Inference speed optimization for T5 models",
      "detailed_description": "A tool to boost inference speed of T5 models by converting them to ONNX and quantizing them, reducing model size and latency.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Ki6an/fastT5",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "t5",
        "onnx",
        "optimization",
        "inference"
      ],
      "id": 1114
    },
    {
      "name": "csle",
      "one_line_profile": "Research platform for automated security policies using quantitative methods",
      "detailed_description": "A research platform for developing automated security policies using quantitative methods such as reinforcement learning, game theory, and causal inference.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "scientific_modeling",
        "simulation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Kim-Hammar/csle",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "security",
        "reinforcement-learning",
        "game-theory",
        "simulation"
      ],
      "id": 1115
    },
    {
      "name": "index-tts-vllm",
      "one_line_profile": "vLLM support integration for IndexTTS",
      "detailed_description": "A tool/library that adds vLLM support to IndexTTS, enabling faster inference for text-to-speech applications.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "text_to_speech"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Ksuriuri/index-tts-vllm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tts",
        "vllm",
        "inference"
      ],
      "id": 1116
    },
    {
      "name": "dds",
      "one_line_profile": "Server-driven video streaming for deep learning inference",
      "detailed_description": "A system for server-driven video streaming optimized for deep learning inference, balancing bandwidth and accuracy.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "video_processing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/KuntaiDu/dds",
      "help_website": [],
      "license": null,
      "tags": [
        "video-streaming",
        "inference",
        "deep-learning"
      ],
      "id": 1117
    },
    {
      "name": "DistServe",
      "one_line_profile": "Disaggregated serving system for Large Language Models",
      "detailed_description": "A disaggregated serving system for LLMs that separates the prefill and decoding phases to optimize performance and resource utilization.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "distributed_computing"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/LLMServe/DistServe",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-serving",
        "distributed-systems",
        "optimization"
      ],
      "id": 1118
    },
    {
      "name": "LMCache",
      "one_line_profile": "High-performance KV cache layer for LLMs",
      "detailed_description": "A specialized KV cache layer designed to supercharge Large Language Model inference by optimizing memory access and caching strategies.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "memory_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/LMCache/LMCache",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kv-cache",
        "llm",
        "optimization",
        "inference"
      ],
      "id": 1119
    },
    {
      "name": "AutoGPTQ.tvm",
      "one_line_profile": "TVM kernel for GPTQ inference",
      "detailed_description": "A TVM-based kernel implementation for efficient inference of GPTQ quantized models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "kernel_implementation"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/LeiWang1999/AutoGPTQ.tvm",
      "help_website": [],
      "license": null,
      "tags": [
        "tvm",
        "gptq",
        "cuda",
        "inference"
      ],
      "id": 1120
    },
    {
      "name": "VitsServer",
      "one_line_profile": "VITS ONNX TTS server for fast inference",
      "detailed_description": "A fast inference server for VITS Text-to-Speech models using ONNX Runtime.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "text_to_speech"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/LlmKira/VitsServer",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "tts",
        "onnx",
        "server",
        "vits"
      ],
      "id": 1121
    },
    {
      "name": "KokoroSharp",
      "one_line_profile": "Fast local TTS inference engine in C#",
      "detailed_description": "A multi-platform, multi-lingual Text-to-Speech inference engine implemented in C# using ONNX runtime.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "text_to_speech"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/Lyrcaxis/KokoroSharp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tts",
        "csharp",
        "onnx",
        "inference"
      ],
      "id": 1122
    },
    {
      "name": "mpeg-pcc-tmc13",
      "one_line_profile": "Geometry-based Point Cloud Compression (G-PCC) Test Model",
      "detailed_description": "The reference software implementation (Test Model) for the MPEG Geometry-based Point Cloud Compression (G-PCC) standard.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "compression",
        "point_cloud_processing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/MPEGGroup/mpeg-pcc-tmc13",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "point-cloud",
        "compression",
        "mpeg",
        "standard"
      ],
      "id": 1123
    },
    {
      "name": "mpeg-pcc-tmc2",
      "one_line_profile": "Video-based Point Cloud Compression (V-PCC) Test Model",
      "detailed_description": "The reference software implementation (Test Model) for the MPEG Video-based Point Cloud Compression (V-PCC) standard.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "compression",
        "point_cloud_processing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/MPEGGroup/mpeg-pcc-tmc2",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "point-cloud",
        "compression",
        "mpeg",
        "standard"
      ],
      "id": 1124
    },
    {
      "name": "dcsam",
      "one_line_profile": "Factored inference for discrete-continuous smoothing and mapping",
      "detailed_description": "A library for factored inference in discrete-continuous smoothing and mapping (SLAM) problems, useful in robotics and navigation.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "scientific_inference",
        "slam"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/MarineRoboticsGroup/dcsam",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slam",
        "inference",
        "robotics",
        "optimization"
      ],
      "id": 1125
    },
    {
      "name": "llama-cpp-agent",
      "one_line_profile": "Framework for structured interaction with LLMs",
      "detailed_description": "A framework designed to facilitate interaction with Large Language Models, supporting structured function calls and output generation.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_utility",
        "agent_framework"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Maximilian-Winter/llama-cpp-agent",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "agent",
        "function-calling",
        "inference"
      ],
      "id": 1126
    },
    {
      "name": "shimmy",
      "one_line_profile": "Rust-based OpenAI-compatible inference server",
      "detailed_description": "A high-performance, Python-free inference server written in Rust, compatible with the OpenAI API and supporting GGUF/SafeTensors models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving"
      ],
      "application_level": "service",
      "primary_language": "Rust",
      "repo_url": "https://github.com/Michael-A-Kuykendall/shimmy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "inference-server",
        "rust",
        "openai-api",
        "gguf"
      ],
      "id": 1127
    },
    {
      "name": "LightCompress",
      "one_line_profile": "Toolkit for compressing large models including LLMs and VLMs",
      "detailed_description": "A toolkit designed for compressing large-scale models such as Large Language Models (LLMs), Vision-Language Models (VLMs), and video generation models, aiming to reduce model size and improve inference efficiency.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ModelTC/LightCompress",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compression",
        "llm",
        "vlm",
        "model-optimization"
      ],
      "id": 1128
    },
    {
      "name": "LightLLM",
      "one_line_profile": "Lightweight and scalable LLM inference and serving framework",
      "detailed_description": "A Python-based framework for Large Language Model (LLM) inference and serving, featuring a lightweight design, easy scalability, and high-speed performance for deploying LLMs.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference",
        "serving"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ModelTC/LightLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference-server",
        "llm",
        "serving",
        "high-performance"
      ],
      "id": 1129
    },
    {
      "name": "MQBench",
      "one_line_profile": "Benchmark and toolkit for model quantization algorithms",
      "detailed_description": "A framework for evaluating and implementing model quantization techniques, providing a standardized benchmark for assessing the performance and accuracy of quantized models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ModelTC/MQBench",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "benchmark",
        "model-compression"
      ],
      "id": 1130
    },
    {
      "name": "flash-tokenizer",
      "one_line_profile": "High-performance tokenizer engine for LLM inference",
      "detailed_description": "An efficient and optimized tokenizer engine designed specifically for Large Language Model (LLM) inference serving, aiming to minimize tokenization latency.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "tokenization",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/NLPOptimize/flash-tokenizer",
      "help_website": [],
      "license": null,
      "tags": [
        "tokenizer",
        "llm",
        "inference",
        "optimization"
      ],
      "id": 1131
    },
    {
      "name": "nanoowl",
      "one_line_profile": "Optimized OWL-ViT inference with NVIDIA TensorRT",
      "detailed_description": "A project that optimizes the OWL-ViT (Open-Vocabulary Object Detection) model for real-time inference using NVIDIA TensorRT, enabling efficient deployment on edge devices.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "computer_vision"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA-AI-IOT/nanoowl",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tensorrt",
        "owl-vit",
        "object-detection",
        "optimization"
      ],
      "id": 1132
    },
    {
      "name": "Model-Optimizer",
      "one_line_profile": "Unified library for SOTA model optimization techniques",
      "detailed_description": "A library providing state-of-the-art model optimization techniques such as quantization, pruning, distillation, and speculative decoding to compress deep learning models for efficient deployment on NVIDIA hardware.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_optimization",
        "quantization",
        "pruning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/Model-Optimizer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "optimization",
        "compression",
        "tensorrt",
        "llm"
      ],
      "id": 1133
    },
    {
      "name": "TensorRT-LLM",
      "one_line_profile": "High-performance LLM inference library for NVIDIA GPUs",
      "detailed_description": "A library that provides an easy-to-use Python API to define Large Language Models (LLMs) and supports state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference",
        "serving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/TensorRT-LLM",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "inference",
        "llm",
        "nvidia",
        "gpu",
        "optimization"
      ],
      "id": 1134
    },
    {
      "name": "grps",
      "one_line_profile": "High-performance deep learning deployment framework",
      "detailed_description": "A deep learning deployment framework supporting multiple backends (TF, Torch, TRT, vLLM) with dynamic batching and streaming modes, compatible with Python and C++ for scalable service deployment.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "serving",
        "deployment"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/NetEase-Media/grps",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "serving",
        "inference",
        "deployment",
        "multi-backend"
      ],
      "id": 1135
    },
    {
      "name": "grps_trtllm",
      "one_line_profile": "High-performance OpenAI-compatible LLM service based on TensorRT-LLM",
      "detailed_description": "A C++ high-performance LLM service implementation using GRPS and TensorRT-LLM, supporting OpenAI API, chat, function calls, and distributed multi-GPU inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "serving",
        "inference"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/NetEase-Media/grps_trtllm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-serving",
        "tensorrt-llm",
        "openai-api",
        "inference"
      ],
      "id": 1136
    },
    {
      "name": "sparse_quant_llms",
      "one_line_profile": "SparseGPT and GPTQ compression tools for LLMs",
      "detailed_description": "A toolkit for applying SparseGPT and GPTQ compression techniques to Large Language Models like LLaMa, OPT, and Pythia to reduce model size and computational requirements.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "quantization",
        "sparsification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NolanoOrg/sparse_quant_llms",
      "help_website": [],
      "license": null,
      "tags": [
        "compression",
        "sparsegpt",
        "gptq",
        "llm"
      ],
      "id": 1137
    },
    {
      "name": "BMCook",
      "one_line_profile": "Model compression toolkit for large-scale models",
      "detailed_description": "A model compression toolkit designed for big models, providing methods for quantization, pruning, and distillation to optimize models for deployment.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "quantization",
        "pruning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenBMB/BMCook",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compression",
        "large-models",
        "optimization"
      ],
      "id": 1138
    },
    {
      "name": "CPM.cu",
      "one_line_profile": "Lightweight CUDA implementation for LLM inference on end-devices",
      "detailed_description": "A high-performance CUDA implementation for Large Language Models, optimized for end-device inference with support for sparse architectures, speculative sampling, and quantization.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference",
        "on-device_ai"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/OpenBMB/CPM.cu",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "cuda",
        "inference",
        "llm",
        "edge-computing"
      ],
      "id": 1139
    },
    {
      "name": "UltraRAG",
      "one_line_profile": "Framework for building complex RAG pipelines",
      "detailed_description": "A framework for constructing Retrieval Augmented Generation (RAG) pipelines, facilitating the integration of external knowledge bases with LLMs for enhanced inference and reasoning.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "rag",
        "inference_augmentation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenBMB/UltraRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "retrieval",
        "llm",
        "pipeline"
      ],
      "id": 1140
    },
    {
      "name": "EfficientQAT",
      "one_line_profile": "Efficient Quantization-Aware Training for LLMs",
      "detailed_description": "A library implementing efficient Quantization-Aware Training (QAT) techniques for Large Language Models, enabling the creation of high-performance quantized models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/EfficientQAT",
      "help_website": [],
      "license": null,
      "tags": [
        "qat",
        "quantization",
        "llm",
        "training"
      ],
      "id": 1141
    },
    {
      "name": "VideoChat-Flash",
      "one_line_profile": "Hierarchical compression for long-context video modeling",
      "detailed_description": "A tool and model implementation for efficient long-context video modeling using hierarchical compression techniques to manage memory and computational complexity.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "video_modeling",
        "compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/VideoChat-Flash",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "video",
        "compression",
        "long-context",
        "multimodal"
      ],
      "id": 1142
    },
    {
      "name": "CTranslate2",
      "one_line_profile": "Fast inference engine for Transformer models",
      "detailed_description": "A C++ and Python library for efficient inference with Transformer models, supporting quantization (INT8, INT16) and hardware acceleration on CPU and GPU.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/OpenNMT/CTranslate2",
      "help_website": [
        "https://opennmt.net/CTranslate2/"
      ],
      "license": "MIT",
      "tags": [
        "inference",
        "transformer",
        "quantization",
        "acceleration"
      ],
      "id": 1143
    },
    {
      "name": "Orion",
      "one_line_profile": "Orion-14B foundation model and inference tools",
      "detailed_description": "A repository providing the Orion-14B foundation LLM and associated tools for inference, quantization, and fine-tuning, including chat and RAG capabilities.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "modeling",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OrionStarAI/Orion",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "foundation-model",
        "inference",
        "quantization"
      ],
      "id": 1144
    },
    {
      "name": "simple-onnx-processing-tools",
      "one_line_profile": "Tools for manipulating and optimizing ONNX models",
      "detailed_description": "A collection of tools for splitting, merging, compressing, and modifying ONNX models, facilitating model optimization and deployment workflows.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_optimization",
        "onnx_manipulation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PINTO0309/simple-onnx-processing-tools",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "onnx",
        "model-processing",
        "optimization",
        "tools"
      ],
      "id": 1145
    },
    {
      "name": "tflite2tensorflow",
      "one_line_profile": "Converter for TFLite models to other formats",
      "detailed_description": "A tool to convert .tflite models to various formats including TensorFlow, ONNX, TensorRT, and OpenVINO, supporting quantization and inverse quantization.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_conversion",
        "interoperability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PINTO0309/tflite2tensorflow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "conversion",
        "tflite",
        "onnx",
        "tensorrt"
      ],
      "id": 1146
    },
    {
      "name": "FastDeploy",
      "one_line_profile": "High-performance inference and deployment toolkit",
      "detailed_description": "A comprehensive toolkit for deploying Large Language Models (LLMs) and Vision-Language Models (VLMs) based on PaddlePaddle, supporting various hardware backends.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "deployment",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PaddlePaddle/FastDeploy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deployment",
        "inference",
        "paddlepaddle",
        "llm"
      ],
      "id": 1147
    },
    {
      "name": "PaddleNLP",
      "one_line_profile": "Comprehensive NLP library with LLM support",
      "detailed_description": "A library for Natural Language Processing based on PaddlePaddle, providing a model zoo of LLMs and SLMs along with tools for training, fine-tuning, and inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "nlp",
        "modeling",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PaddlePaddle/PaddleNLP",
      "help_website": [
        "https://paddlenlp.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "llm",
        "paddlepaddle",
        "model-zoo"
      ],
      "id": 1148
    },
    {
      "name": "PaddleSlim",
      "one_line_profile": "Model compression and architecture search library",
      "detailed_description": "A library for deep model compression (quantization, pruning, distillation) and neural architecture search (NAS) based on PaddlePaddle.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "nas"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PaddlePaddle/PaddleSlim",
      "help_website": [
        "https://paddleslim.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "compression",
        "quantization",
        "pruning",
        "nas"
      ],
      "id": 1149
    },
    {
      "name": "MixQ_Tensorrt_LLM",
      "one_line_profile": "Mixed precision inference implementation using TensorRT-LLM",
      "detailed_description": "A tool enabling mixed precision inference for Large Language Models using NVIDIA's TensorRT-LLM, optimizing performance and memory usage.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "mixed_precision"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/Qcompiler/MixQ_Tensorrt_LLM",
      "help_website": [],
      "license": null,
      "tags": [
        "tensorrt-llm",
        "mixed-precision",
        "inference"
      ],
      "id": 1150
    },
    {
      "name": "MIVisionX",
      "one_line_profile": "AMD computer vision and machine intelligence toolkit",
      "detailed_description": "A comprehensive toolkit from AMD for computer vision and machine intelligence, including optimized implementations of OpenVX and utilities for model inference on AMD hardware.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "computer_vision",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/ROCm/MIVisionX",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "amd",
        "rocm",
        "openvx",
        "computer-vision"
      ],
      "id": 1151
    },
    {
      "name": "rwkv.cpp",
      "one_line_profile": "CPU inference engine for RWKV models",
      "detailed_description": "A C++ implementation for efficient inference of RWKV language models on CPUs, supporting INT4, INT5, INT8, and FP16 quantization.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/RWKV/rwkv.cpp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rwkv",
        "inference",
        "cpu",
        "quantization"
      ],
      "id": 1152
    },
    {
      "name": "redis-inference-optimization",
      "one_line_profile": "Redis module for serving tensors and executing DL graphs",
      "detailed_description": "A Redis module (RedisAI) designed for serving tensors and executing deep learning graphs directly within Redis, enabling high-performance inference pipelines.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "serving",
        "inference"
      ],
      "application_level": "service",
      "primary_language": "C",
      "repo_url": "https://github.com/RedisAI/redis-inference-optimization",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "redis",
        "serving",
        "inference",
        "deep-learning"
      ],
      "id": 1153
    },
    {
      "name": "PowerInfer",
      "one_line_profile": "High-speed LLM serving engine for local deployment",
      "detailed_description": "A high-speed inference engine for Large Language Models optimized for local deployment, leveraging activation sparsity to accelerate serving on consumer-grade hardware.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "serving",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/SJTU-IPADS/PowerInfer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "inference",
        "llm",
        "sparsity",
        "local-deployment"
      ],
      "id": 1154
    },
    {
      "name": "MLServer",
      "one_line_profile": "Multi-framework inference server for ML models",
      "detailed_description": "An open-source inference server that supports multiple machine learning frameworks, enabling standardized model serving and deployment in production environments.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "serving",
        "deployment"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/SeldonIO/MLServer",
      "help_website": [
        "https://mlserver.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "inference-server",
        "serving",
        "mlops",
        "multi-framework"
      ],
      "id": 1155
    },
    {
      "name": "ServerlessLLM",
      "one_line_profile": "Serverless serving framework for LLMs",
      "detailed_description": "A framework designed for serverless deployment of Large Language Models, optimizing cold-start times and resource utilization for efficient LLM serving.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "serving",
        "deployment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ServerlessLLM/ServerlessLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "serverless",
        "llm",
        "serving",
        "cloud-computing"
      ],
      "id": 1156
    },
    {
      "name": "Model Compression Toolkit (MCT)",
      "one_line_profile": "Neural network model optimization and compression toolkit",
      "detailed_description": "An open-source project providing advanced quantization and compression tools for optimizing neural network models for deployment on efficient, constrained hardware.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SonySemiconductorSolutions/mct-model-optimization",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compression",
        "quantization",
        "optimization",
        "neural-networks"
      ],
      "id": 1157
    },
    {
      "name": "YOLOv3v4-ModelCompression",
      "one_line_profile": "Model compression scripts for YOLO object detection models",
      "detailed_description": "A collection of scripts and tools for compressing YOLOv3 and YOLOv4 models, including pruning and quantization techniques for efficient inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "object_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SpursLipu/YOLOv3v4-ModelCompression-MultidatasetTraining-Multibackbone",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "yolo",
        "compression",
        "pruning",
        "quantization"
      ],
      "id": 1158
    },
    {
      "name": "Torch-TRTLLM",
      "one_line_profile": "Converter from HuggingFace models to TensorRT-LLM engines",
      "detailed_description": "A framework (Ditto) that enables direct conversion of HuggingFace PreTrainedModels into TensorRT-LLM engines, simplifying the optimization pipeline for LLMs.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_conversion",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SqueezeBits/Torch-TRTLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tensorrt-llm",
        "huggingface",
        "conversion",
        "optimization"
      ],
      "id": 1159
    },
    {
      "name": "EmbedAnything",
      "one_line_profile": "High-performance inference and ingestion pipeline in Rust",
      "detailed_description": "A modular and memory-safe library built in Rust for high-performance inference, data ingestion, and indexing, suitable for building efficient RAG and search pipelines.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference",
        "data_ingestion"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/StarlightSearch/EmbedAnything",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rust",
        "inference",
        "embedding",
        "rag"
      ],
      "id": 1160
    },
    {
      "name": "torch-model-compression",
      "one_line_profile": "Automated model structure analysis and compression toolset for PyTorch",
      "detailed_description": "A toolset designed for PyTorch models that provides automated model structure analysis and a library of model compression algorithms to optimize inference efficiency.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "structure_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/THU-MIG/torch-model-compression",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "model-compression",
        "optimization"
      ],
      "id": 1161
    },
    {
      "name": "AngelSlim",
      "one_line_profile": "Model compression toolkit for enhanced usability and efficiency",
      "detailed_description": "A comprehensive model compression toolkit developed by Tencent, designed to improve the usability and efficiency of deploying deep learning models through various compression techniques.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Tencent/AngelSlim",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "model-compression",
        "deep-learning",
        "tencent"
      ],
      "id": 1162
    },
    {
      "name": "PocketFlow",
      "one_line_profile": "Automatic Model Compression (AutoMC) framework",
      "detailed_description": "An open-source framework for automatic model compression (AutoMC) that integrates various compression algorithms to develop smaller and faster AI applications with minimal human effort.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "automl"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Tencent/PocketFlow",
      "help_website": [
        "https://pocketflow.github.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "automc",
        "model-compression",
        "tensorflow"
      ],
      "id": 1163
    },
    {
      "name": "TNN",
      "one_line_profile": "High-performance deep learning inference framework",
      "detailed_description": "A uniform deep learning inference framework for mobile, desktop, and server platforms, featuring cross-platform capability, high performance, and model compression support.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_engine",
        "model_serving"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/Tencent/TNN",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "inference",
        "cross-platform",
        "mobile-ai"
      ],
      "id": 1164
    },
    {
      "name": "ncnn",
      "one_line_profile": "High-performance neural network inference framework for mobile",
      "detailed_description": "A high-performance neural network inference framework optimized for mobile platforms, supporting various model formats and enabling efficient AI deployment on edge devices.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_engine",
        "edge_computing"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/Tencent/ncnn",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "inference",
        "mobile",
        "neural-network"
      ],
      "id": 1165
    },
    {
      "name": "AQLM",
      "one_line_profile": "Extreme Compression of LLMs via Additive Quantization",
      "detailed_description": "Official implementation of Additive Quantization for Language Models (AQLM), providing tools for extreme compression of Large Language Models while maintaining performance.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Vahe1994/AQLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "llm",
        "compression"
      ],
      "id": 1166
    },
    {
      "name": "voltaML",
      "one_line_profile": "Lightweight library for accelerating ML/DL models",
      "detailed_description": "A lightweight library designed to convert and run machine learning and deep learning models in high-performance inference runtimes like TensorRT, TorchScript, ONNX, and TVM.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "model_conversion"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/VoltaML/voltaML",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "acceleration",
        "tensorrt",
        "inference"
      ],
      "id": 1167
    },
    {
      "name": "MACE",
      "one_line_profile": "Mobile AI Compute Engine",
      "detailed_description": "A deep learning inference framework optimized for mobile heterogeneous computing platforms, supporting efficient execution of neural networks on mobile devices.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_engine",
        "mobile_computing"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/XiaoMi/mace",
      "help_website": [
        "https://mace.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mobile-ai",
        "inference",
        "heterogeneous-computing"
      ],
      "id": 1168
    },
    {
      "name": "Keras-inference-time-optimizer",
      "one_line_profile": "Keras model layer structure optimizer",
      "detailed_description": "A tool to optimize the layer structure of Keras models to reduce computation time and improve inference speed.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "model_profiling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ZFTurbo/Keras-inference-time-optimizer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "keras",
        "optimization",
        "inference"
      ],
      "id": 1169
    },
    {
      "name": "KVCache-Factory",
      "one_line_profile": "Unified KV Cache Compression Methods for Auto-Regressive Models",
      "detailed_description": "A unified framework and library for applying various Key-Value (KV) cache compression methods to auto-regressive models to optimize memory usage and inference speed.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "memory_optimization",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zefan-Cai/KVCache-Factory",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kv-cache",
        "compression",
        "llm"
      ],
      "id": 1170
    },
    {
      "name": "llama-cpp-python",
      "one_line_profile": "Python bindings for llama.cpp",
      "detailed_description": "Python bindings for llama.cpp, enabling the execution of quantized Large Language Models (LLMs) efficiently in Python environments.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_runtime",
        "model_serving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/abetlen/llama-cpp-python",
      "help_website": [
        "https://llama-cpp-python.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "llm",
        "inference",
        "quantization"
      ],
      "id": 1171
    },
    {
      "name": "ggify",
      "one_line_profile": "Huggingface to GGML/GGUF converter",
      "detailed_description": "A utility tool to download models from Huggingface Hub and convert them to GGML/GGUF formats for use with llama.cpp.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_conversion",
        "data_preparation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/akx/ggify",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gguf",
        "conversion",
        "llama.cpp"
      ],
      "id": 1172
    },
    {
      "name": "optillm",
      "one_line_profile": "Optimizing inference proxy for LLMs",
      "detailed_description": "An optimizing inference proxy that sits between LLM applications and providers, implementing techniques like mixture-of-agents and speculative decoding to improve performance and accuracy.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "proxy_service"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/algorithmicsuperintelligence/optillm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "proxy",
        "optimization"
      ],
      "id": 1173
    },
    {
      "name": "ServeGen",
      "one_line_profile": "LLM serving workload generator",
      "detailed_description": "A framework for generating realistic Large Language Model (LLM) serving workloads to benchmark and evaluate serving systems.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "benchmarking",
        "workload_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/alibaba/ServeGen",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmarking",
        "serving",
        "llm"
      ],
      "id": 1174
    },
    {
      "name": "TinyNeuralNetwork",
      "one_line_profile": "Efficient deep learning model compression framework",
      "detailed_description": "An efficient and easy-to-use framework for deep learning model compression, supporting techniques like pruning and quantization to optimize models for deployment.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "optimization"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/alibaba/TinyNeuralNetwork",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "compression",
        "pruning",
        "quantization"
      ],
      "id": 1175
    },
    {
      "name": "SQLFlow",
      "one_line_profile": "SQL-based machine learning bridge",
      "detailed_description": "A bridge that connects SQL engines with machine learning toolkits like TensorFlow, enabling users to perform model training, prediction, and inference using extended SQL syntax.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_training",
        "inference_interface"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/alipay/SQLFlow",
      "help_website": [
        "https://sqlflow.org/"
      ],
      "license": null,
      "tags": [
        "sql",
        "machine-learning",
        "interface"
      ],
      "id": 1176
    },
    {
      "name": "byzer-llm",
      "one_line_profile": "Full-lifecycle LLM toolchain",
      "detailed_description": "A comprehensive toolchain for pretraining, fine-tuning, and serving Large Language Models (LLMs), designed to make LLM deployment accessible and efficient.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "fine_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/allwefantasy/byzer-llm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "serving",
        "finetuning"
      ],
      "id": 1177
    },
    {
      "name": "Alpa",
      "one_line_profile": "Auto-parallelization for large-scale neural networks",
      "detailed_description": "A system for training and serving large-scale neural networks that automatically generates parallelization strategies for distributed execution.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "distributed_serving",
        "distributed_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/alpa-projects/alpa",
      "help_website": [
        "https://alpa.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-systems",
        "parallelization",
        "serving"
      ],
      "id": 1178
    },
    {
      "name": "cONNXr",
      "one_line_profile": "Pure C ONNX runtime for embedded devices",
      "detailed_description": "A pure C implementation of the ONNX runtime with zero dependencies, designed for inference on embedded devices.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_runtime",
        "embedded_ai"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/alrevuelta/cONNXr",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "onnx",
        "embedded",
        "c"
      ],
      "id": 1179
    },
    {
      "name": "RyzenAI-SW",
      "one_line_profile": "AMD Ryzen AI inference software",
      "detailed_description": "Software tools and runtime libraries provided by AMD for optimizing and deploying AI inference on Ryzen AI-powered hardware.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "hardware_acceleration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/amd/RyzenAI-SW",
      "help_website": [
        "https://ryzenai.docs.amd.com/"
      ],
      "license": "MIT",
      "tags": [
        "amd",
        "inference",
        "npu"
      ],
      "id": 1180
    },
    {
      "name": "flux-fp8-api",
      "one_line_profile": "Optimized Flux diffusion model serving implementation",
      "detailed_description": "An implementation of the Flux diffusion model using quantized FP8 matrix multiplication and optimized layers for faster inference on consumer devices, exposed via an API.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "quantization"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/aredden/flux-fp8-api",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion",
        "quantization",
        "serving"
      ],
      "id": 1181
    },
    {
      "name": "sqlite-lembed",
      "one_line_profile": "SQLite extension for GGUF embeddings",
      "detailed_description": "A SQLite extension that enables the generation of text embeddings directly within the database using GGUF models via llama.cpp, facilitating local vector search and data processing.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "data_processing",
        "embedding_generation"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/asg017/sqlite-lembed",
      "help_website": [],
      "license": null,
      "tags": [
        "sqlite",
        "embedding",
        "gguf"
      ],
      "id": 1182
    },
    {
      "name": "nos",
      "one_line_profile": "Fast and flexible PyTorch inference server for local and cloud deployment",
      "detailed_description": "A high-performance inference server designed to run PyTorch models efficiently on various hardware backends. It supports dynamic batching and hardware acceleration, facilitating the deployment of scientific AI models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_optimization"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/autonomi-ai/nos",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference-server",
        "pytorch",
        "gpu-acceleration"
      ],
      "id": 1183
    },
    {
      "name": "Multi Model Server",
      "one_line_profile": "Tool for serving neural net models for inference",
      "detailed_description": "A flexible and easy-to-use tool for serving deep learning models trained with various frameworks. It provides an HTTP frontend for inference requests and manages model loading and scaling.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving"
      ],
      "application_level": "service",
      "primary_language": "Java",
      "repo_url": "https://github.com/awslabs/multi-model-server",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference-serving",
        "model-deployment",
        "mxnet",
        "pytorch"
      ],
      "id": 1184
    },
    {
      "name": "llama-on-lambda",
      "one_line_profile": "Deployment tool for running llama.cpp compatible LLMs on AWS Lambda",
      "detailed_description": "A utility that enables the deployment of quantized Large Language Models (LLMs) using llama.cpp on serverless infrastructure (AWS Lambda), facilitating cost-effective inference for scientific NLP tasks.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "deployment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/baileytec-labs/llama-on-lambda",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "serverless",
        "llm-inference",
        "aws-lambda",
        "quantization"
      ],
      "id": 1185
    },
    {
      "name": "BentoLMDeploy",
      "one_line_profile": "Integration tool for self-hosting LLMs with LMDeploy and BentoML",
      "detailed_description": "A bridge tool that combines the high-performance inference capabilities of LMDeploy with the model serving infrastructure of BentoML, enabling efficient deployment of Large Language Models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_optimization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bentoml/BentoLMDeploy",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-serving",
        "bentoml",
        "lmdeploy"
      ],
      "id": 1186
    },
    {
      "name": "llm-optimizer",
      "one_line_profile": "Benchmark and optimize LLM inference across frameworks",
      "detailed_description": "A toolkit designed to profile, benchmark, and optimize the inference performance of Large Language Models across different serving frameworks, aiding in the efficient deployment of scientific models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bentoml/llm-optimizer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "optimization",
        "inference-benchmark"
      ],
      "id": 1187
    },
    {
      "name": "X-LLM",
      "one_line_profile": "Library for cutting edge and easy LLM finetuning",
      "detailed_description": "A library designed to simplify the fine-tuning process of Large Language Models, supporting various optimization techniques to adapt models for specific scientific or domain tasks.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "model_training",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bobazooba/xllm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "fine-tuning",
        "training-framework"
      ],
      "id": 1188
    },
    {
      "name": "ByteTransformer",
      "one_line_profile": "Optimized BERT transformer inference on NVIDIA GPU",
      "detailed_description": "A high-performance inference engine for Transformer models (like BERT), providing highly optimized CUDA kernels for variable-length sequence processing, significantly accelerating scientific text analysis tasks.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "model_serving"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/bytedance/ByteTransformer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "transformer",
        "inference-acceleration",
        "cuda",
        "bert"
      ],
      "id": 1189
    },
    {
      "name": "AutoAWQ",
      "one_line_profile": "Implementation of the AWQ algorithm for 4-bit quantization",
      "detailed_description": "A library implementing Activation-aware Weight Quantization (AWQ) for LLMs, enabling significant speedups and memory reduction during inference while maintaining model accuracy.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/casper-hansen/AutoAWQ",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "quantization",
        "awq",
        "llm-inference"
      ],
      "id": 1190
    },
    {
      "name": "LLMServingSim",
      "one_line_profile": "HW/SW Co-Simulation Infrastructure for LLM Inference Serving",
      "detailed_description": "A simulation framework designed to evaluate and optimize the hardware/software stack for Large Language Model inference serving at scale, aiding in system architecture research.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "simulation",
        "inference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/casys-kaist/LLMServingSim",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "simulation",
        "llm-serving",
        "system-architecture"
      ],
      "id": 1191
    },
    {
      "name": "flex-nano-vllm",
      "one_line_profile": "Minimal vllm-style inference engine for fast Gemma 2 inference",
      "detailed_description": "A lightweight inference engine leveraging FlexAttention to provide fast inference capabilities for specific LLM architectures (e.g., Gemma 2), serving as a specialized tool for model execution.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/changjonathanc/flex-nano-vllm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "inference-engine",
        "vllm",
        "gemma"
      ],
      "id": 1192
    },
    {
      "name": "model_compression",
      "one_line_profile": "Implementation of model compression with knowledge distilling",
      "detailed_description": "A toolkit implementing various model compression techniques, specifically knowledge distillation, to reduce model size and improve inference speed for deployment.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "distillation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chengshengchan/model_compression",
      "help_website": [],
      "license": null,
      "tags": [
        "model-compression",
        "knowledge-distillation"
      ],
      "id": 1193
    },
    {
      "name": "Comfy-WaveSpeed",
      "one_line_profile": "Inference optimization solution for ComfyUI",
      "detailed_description": "An optimization framework integrated into ComfyUI to accelerate the inference of generative AI models, facilitating faster image generation for research and creative workflows.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "image_generation"
      ],
      "application_level": "plugin",
      "primary_language": "Python",
      "repo_url": "https://github.com/chengzeyi/Comfy-WaveSpeed",
      "help_website": [
        "https://wavespeed.ai/"
      ],
      "license": "MIT",
      "tags": [
        "comfyui",
        "inference-acceleration",
        "stable-diffusion"
      ],
      "id": 1194
    },
    {
      "name": "stable-fast",
      "one_line_profile": "Inference performance optimization framework for HuggingFace Diffusers",
      "detailed_description": "A highly optimized inference framework for Stable Diffusion models on NVIDIA GPUs, providing significant speedups for diffusion-based generative tasks.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "image_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chengzeyi/stable-fast",
      "help_website": [
        "https://wavespeed.ai/"
      ],
      "license": "MIT",
      "tags": [
        "stable-diffusion",
        "inference-optimization",
        "cuda"
      ],
      "id": 1195
    },
    {
      "name": "ialacol",
      "one_line_profile": "Lightweight OpenAI drop-in replacement for Kubernetes",
      "detailed_description": "A serving infrastructure tool that allows deploying open-source LLMs on Kubernetes with an OpenAI-compatible API, facilitating scalable model inference in research environments.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "deployment"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/chenhunghan/ialacol",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kubernetes",
        "llm-serving",
        "openai-api"
      ],
      "id": 1196
    },
    {
      "name": "topicGPT",
      "one_line_profile": "Prompt-Based Framework for Topic Modeling",
      "detailed_description": "A framework that utilizes Large Language Models to perform topic modeling on text data, providing a tool for qualitative and quantitative text analysis in social and computational sciences.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "data_analysis",
        "text_mining"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chtmp223/topicGPT",
      "help_website": [],
      "license": null,
      "tags": [
        "topic-modeling",
        "llm",
        "nlp"
      ],
      "id": 1197
    },
    {
      "name": "ComfyUI-GGUF",
      "one_line_profile": "GGUF Quantization support for native ComfyUI models",
      "detailed_description": "A plugin for ComfyUI that enables the loading and inference of models quantized in the GGUF format, allowing for efficient execution of generative models on consumer hardware.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "inference_optimization"
      ],
      "application_level": "plugin",
      "primary_language": "Python",
      "repo_url": "https://github.com/city96/ComfyUI-GGUF",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gguf",
        "comfyui",
        "quantization"
      ],
      "id": 1198
    },
    {
      "name": "WhisperLive",
      "one_line_profile": "A nearly-live implementation of OpenAI's Whisper",
      "detailed_description": "A real-time implementation of the Whisper automatic speech recognition model, enabling live audio transcription and processing for research and application development.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_implementation",
        "speech_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/collabora/WhisperLive",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "whisper",
        "asr",
        "real-time-inference"
      ],
      "id": 1199
    },
    {
      "name": "ramalama",
      "one_line_profile": "Tool for local serving of AI models using containers",
      "detailed_description": "A command-line tool that simplifies the management and serving of AI models using container technology (OCI), making it easier to deploy inference services reproducibly.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "deployment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/containers/ramalama",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "containers",
        "inference-serving",
        "local-ai"
      ],
      "id": 1200
    },
    {
      "name": "cuckoo",
      "one_line_profile": "Decentralized AI Model-Serving Platform",
      "detailed_description": "A platform for decentralized serving of AI models, enabling distributed inference for generative AI and LLMs, potentially utilizing shared GPU resources.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "distributed_inference"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/cuckoo-network/cuckoo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "decentralized-ai",
        "model-serving",
        "gpu-sharing"
      ],
      "id": 1201
    },
    {
      "name": "Diffbot LLM Inference Server",
      "one_line_profile": "High-performance inference server for Large Language Models",
      "detailed_description": "A dedicated server implementation for deploying and serving Large Language Models, focusing on inference capabilities.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_server"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/diffbot/diffbot-llm-inference",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "inference-server",
        "serving"
      ],
      "id": 1202
    },
    {
      "name": "NanoLLM",
      "one_line_profile": "Optimized local inference library for LLMs and multimodal agents",
      "detailed_description": "A lightweight and optimized library for running Large Language Models locally, supporting quantization, vision-language models, and RAG pipelines, particularly suitable for edge computing in scientific data collection.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dusty-nv/NanoLLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "edge-ai",
        "quantization",
        "rag",
        "local-inference"
      ],
      "id": 1203
    },
    {
      "name": "mixtral-offloading",
      "one_line_profile": "Efficient inference of Mixtral-8x7B on consumer hardware via offloading",
      "detailed_description": "A tool enabling the execution of large Mixture-of-Experts models (like Mixtral-8x7B) on limited memory hardware (e.g., Colab, consumer GPUs) through efficient RAM/VRAM offloading strategies.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "memory_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dvmazur/mixtral-offloading",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "offloading",
        "mixture-of-experts",
        "inference-optimization"
      ],
      "id": 1204
    },
    {
      "name": "Atom",
      "one_line_profile": "Low-bit quantization framework for efficient LLM serving",
      "detailed_description": "A quantization library implementing low-bit techniques to maintain accuracy while significantly reducing the memory footprint and increasing the throughput of Large Language Model serving.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/efeslab/Atom",
      "help_website": [],
      "license": null,
      "tags": [
        "quantization",
        "llm-serving",
        "low-bit"
      ],
      "id": 1205
    },
    {
      "name": "Nanoflow",
      "one_line_profile": "High-throughput serving framework for Large Language Models",
      "detailed_description": "A high-performance serving system designed to maximize throughput for LLM inference, utilizing advanced scheduling and memory management techniques.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_acceleration"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/efeslab/Nanoflow",
      "help_website": [],
      "license": null,
      "tags": [
        "high-throughput",
        "serving-framework",
        "llm"
      ],
      "id": 1206
    },
    {
      "name": "cake",
      "one_line_profile": "Distributed inference engine for LLMs and StableDiffusion",
      "detailed_description": "A Rust-based distributed inference framework supporting both Large Language Models and image generation models, designed to run across diverse hardware including mobile, desktop, and servers.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "distributed_inference",
        "model_serving"
      ],
      "application_level": "service",
      "primary_language": "Rust",
      "repo_url": "https://github.com/evilsocket/cake",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "distributed-computing",
        "rust",
        "inference-engine"
      ],
      "id": 1207
    },
    {
      "name": "FBTT-Embedding",
      "one_line_profile": "Tensor Train compression library for sparse embedding tables",
      "detailed_description": "A library for compressing sparse embedding tables in large-scale machine learning models using Tensor Train decomposition, reducing memory footprint while maintaining model quality.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "embedding_optimization"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/facebookresearch/FBTT-Embedding",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tensor-train",
        "compression",
        "embeddings"
      ],
      "id": 1208
    },
    {
      "name": "LLM-QAT",
      "one_line_profile": "Data-free quantization aware training for LLMs",
      "detailed_description": "A toolkit for performing Quantization Aware Training (QAT) on Large Language Models without requiring original training data, enabling the creation of efficient quantized models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/LLM-QAT",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "qat",
        "quantization",
        "data-free"
      ],
      "id": 1209
    },
    {
      "name": "LayerSkip",
      "one_line_profile": "Early exit inference and self-speculative decoding for LLMs",
      "detailed_description": "An inference optimization tool that enables early exit strategies and self-speculative decoding to accelerate Large Language Model generation.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_acceleration",
        "speculative_decoding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/LayerSkip",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "early-exit",
        "acceleration",
        "inference"
      ],
      "id": 1210
    },
    {
      "name": "diffq",
      "one_line_profile": "Differentiable quantization library",
      "detailed_description": "A library for differentiable quantization using pseudo quantization noise, allowing automatic tuning of bit-width per weight to balance model size and accuracy.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/diffq",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "differentiable-quantization",
        "compression",
        "pytorch"
      ],
      "id": 1211
    },
    {
      "name": "GPTQ-triton",
      "one_line_profile": "Triton kernel implementation for GPTQ inference",
      "detailed_description": "A specialized Triton kernel implementation for running inference on models quantized with GPTQ, enabling efficient execution on GPUs.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/fpgaminer/GPTQ-triton",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gptq",
        "triton",
        "quantization"
      ],
      "id": 1212
    },
    {
      "name": "EvaDB",
      "one_line_profile": "Database system for AI-powered applications",
      "detailed_description": "A database system designed to facilitate the management and analysis of data using AI models, supporting SQL-like queries for video, image, and text analysis.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "data_management",
        "model_inference"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/georgia-tech-db/evadb",
      "help_website": [
        "https://evadb.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ai-database",
        "sql",
        "multimodal"
      ],
      "id": 1213
    },
    {
      "name": "llama.cpp",
      "one_line_profile": "Port of Facebook's LLaMA model in C/C++ for efficient local inference",
      "detailed_description": "A widely used C/C++ implementation for running Large Language Models efficiently on consumer hardware (CPU/GPU), supporting various quantization methods and model architectures.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_inference",
        "quantization"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ggml-org/llama.cpp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "inference",
        "quantization",
        "cpp",
        "local-llm"
      ],
      "id": 1214
    },
    {
      "name": "XNNPACK",
      "one_line_profile": "High-efficiency floating-point neural network inference operators",
      "detailed_description": "A library of highly optimized neural network inference operators for ARM, x86, and WebAssembly, serving as a backend for frameworks like TensorFlow Lite and PyTorch.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_acceleration",
        "kernel_optimization"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/google/XNNPACK",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "inference-operators",
        "optimization",
        "simd"
      ],
      "id": 1215
    },
    {
      "name": "llama.go",
      "one_line_profile": "Pure Golang implementation of llama.cpp",
      "detailed_description": "A pure Go implementation of the LLaMA inference engine, providing an alternative runtime for deploying LLMs in Go-based scientific or infrastructure environments.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_inference"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/gotzmann/llama.go",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "golang",
        "inference",
        "llm"
      ],
      "id": 1216
    },
    {
      "name": "gpustack",
      "one_line_profile": "GPU cluster manager for optimized AI model deployment",
      "detailed_description": "A platform for managing GPU clusters to efficiently deploy and serve AI models, handling scheduling and resource allocation for inference workloads.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/gpustack/gpustack",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu-cluster",
        "deployment",
        "serving"
      ],
      "id": 1217
    },
    {
      "name": "llama-box",
      "one_line_profile": "LM inference server implementation based on llama.cpp",
      "detailed_description": "A lightweight inference server wrapping llama.cpp, providing API endpoints for serving Large Language Models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_server"
      ],
      "application_level": "service",
      "primary_language": "C++",
      "repo_url": "https://github.com/gpustack/llama-box",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "inference-server",
        "llama.cpp",
        "api"
      ],
      "id": 1218
    },
    {
      "name": "llgtrt",
      "one_line_profile": "TensorRT-LLM server with Structured Outputs",
      "detailed_description": "A Rust-based server for TensorRT-LLM that specifically supports structured output generation (JSON), useful for extracting structured scientific data from LLMs.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "structured_generation"
      ],
      "application_level": "service",
      "primary_language": "Rust",
      "repo_url": "https://github.com/guidance-ai/llgtrt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tensorrt-llm",
        "structured-output",
        "rust"
      ],
      "id": 1219
    },
    {
      "name": "h2oGPT",
      "one_line_profile": "Private local GPT platform for document analysis",
      "detailed_description": "A platform for running LLMs locally to query documents, images, and videos privately, supporting RAG and various inference backends, highly relevant for secure scientific data analysis.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "rag_platform"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/h2oai/h2ogpt",
      "help_website": [
        "https://gpt-docs.h2o.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "local-gpt",
        "rag",
        "private-ai"
      ],
      "id": 1220
    },
    {
      "name": "Hailo Model Zoo",
      "one_line_profile": "Pre-trained models and evaluation environment for Hailo hardware",
      "detailed_description": "A collection of pre-trained models and tools for building, compiling, and evaluating models on Hailo AI processors, facilitating edge AI deployment.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_management",
        "inference_optimization"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/hailo-ai/hailo_model_zoo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "model-zoo",
        "edge-ai",
        "hailo"
      ],
      "id": 1221
    },
    {
      "name": "LLM-Pruner",
      "one_line_profile": "Structural pruning tool for Large Language Models",
      "detailed_description": "A tool for performing structural pruning on Large Language Models to reduce model size and inference cost while preserving performance, supporting various open-source models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "pruning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/horseee/LLM-Pruner",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pruning",
        "model-compression",
        "efficient-llm"
      ],
      "id": 1222
    },
    {
      "name": "FastFold",
      "one_line_profile": "Optimized training and inference for AlphaFold",
      "detailed_description": "A high-performance implementation for training and inference of AlphaFold, optimizing protein structure prediction workflows on GPU clusters.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "scientific_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hpcaitech/FastFold",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "alphafold",
        "protein-folding",
        "optimization"
      ],
      "id": 1223
    },
    {
      "name": "SINQ",
      "one_line_profile": "Fast and high-quality quantization method for LLMs",
      "detailed_description": "A quantization tool designed to compress Large Language Models while preserving accuracy, offering a balance between model size and performance.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huawei-csl/SINQ",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "compression",
        "llm"
      ],
      "id": 1224
    },
    {
      "name": "Huawei Noah Pretrained Language Model",
      "one_line_profile": "Pretrained models and optimization techniques from Huawei Noah's Ark Lab",
      "detailed_description": "A repository containing pretrained language models and associated optimization code (compression, quantization) developed by Huawei Noah's Ark Lab.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_management",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huawei-noah/Pretrained-Language-Model",
      "help_website": [],
      "license": null,
      "tags": [
        "pretrained-models",
        "optimization",
        "huawei"
      ],
      "id": 1225
    },
    {
      "name": "Inference Benchmarker",
      "one_line_profile": "Benchmarking tool for inference servers",
      "detailed_description": "A tool designed to benchmark the performance of various inference servers, helping to evaluate latency and throughput for model serving.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/huggingface/inference-benchmarker",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmarking",
        "inference",
        "latency"
      ],
      "id": 1226
    },
    {
      "name": "Optimum Intel",
      "one_line_profile": "Intel-specific optimization for Hugging Face models",
      "detailed_description": "A library that accelerates inference and training of Hugging Face models on Intel hardware using Intel's optimization tools like OpenVINO and Neural Compressor.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/huggingface/optimum-intel",
      "help_website": [
        "https://huggingface.co/docs/optimum/intel/index"
      ],
      "license": "Apache-2.0",
      "tags": [
        "intel",
        "openvino",
        "optimization"
      ],
      "id": 1227
    },
    {
      "name": "Optimum ONNX",
      "one_line_profile": "ONNX export and inference optimization tool",
      "detailed_description": "A tool to export Hugging Face models to ONNX format and run optimized inference using ONNX Runtime.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_conversion",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/optimum-onnx",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "onnx",
        "inference",
        "export"
      ],
      "id": 1228
    },
    {
      "name": "yzma",
      "one_line_profile": "Go bindings for local llama.cpp inference",
      "detailed_description": "A library enabling Go applications to directly integrate llama.cpp for local inference with hardware acceleration support.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "model_integration"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/hybridgroup/yzma",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "go",
        "llama.cpp",
        "inference"
      ],
      "id": 1229
    },
    {
      "name": "ik_llama.cpp",
      "one_line_profile": "Optimized fork of llama.cpp with SOTA quantization",
      "detailed_description": "A fork of the llama.cpp inference engine featuring additional state-of-the-art quantization methods and performance improvements for running LLMs locally.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_engine",
        "quantization"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ikawrakow/ik_llama.cpp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "quantization",
        "inference"
      ],
      "id": 1230
    },
    {
      "name": "ShaderNN",
      "one_line_profile": "Lightweight mobile inference framework for CNNs",
      "detailed_description": "A deep learning inference framework optimized for running Convolutional Neural Networks on mobile platforms using shader-based acceleration.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_engine",
        "mobile_inference"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/inferenceengine/shadernn",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "mobile",
        "cnn",
        "inference"
      ],
      "id": 1231
    },
    {
      "name": "Triton Co-Pilot",
      "one_line_profile": "Glue code generator for Triton Inference Server",
      "detailed_description": "A utility to generate configuration and glue code to simplify the deployment of models on Nvidia Triton Inference Server.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "deployment_automation",
        "serving_configuration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/inferless/triton-co-pilot",
      "help_website": [],
      "license": null,
      "tags": [
        "triton",
        "deployment",
        "code-generation"
      ],
      "id": 1232
    },
    {
      "name": "Semi-PD",
      "one_line_profile": "Disaggregated LLM serving framework",
      "detailed_description": "A serving framework that disaggregates prefill and decode phases for LLMs, featuring shared GPU memory and fine-grained compute isolation to optimize throughput.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "resource_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/infinigence/Semi-PD",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-serving",
        "distributed-systems",
        "optimization"
      ],
      "id": 1233
    },
    {
      "name": "Intel AI Reference Models",
      "one_line_profile": "Optimized deep learning reference implementations for Intel hardware",
      "detailed_description": "A collection of deep learning model implementations optimized for Intel Xeon processors and Data Center GPUs, serving as a reference for efficient inference and training.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "model_implementation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/intel/ai-reference-models",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "intel",
        "optimization",
        "reference-models"
      ],
      "id": 1234
    },
    {
      "name": "Auto-Round",
      "one_line_profile": "Advanced quantization toolkit for LLMs and VLMs",
      "detailed_description": "A toolkit providing advanced quantization schemes (WOQ, MXFP4, NVFP4, etc.) for Large Language Models and Vision Language Models, integrating with transformers and vLLM.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/intel/auto-round",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "llm",
        "compression"
      ],
      "id": 1235
    },
    {
      "name": "Intel Neural Compressor",
      "one_line_profile": "Model compression and quantization toolkit",
      "detailed_description": "A toolkit for low-bit quantization (INT8, FP8, etc.) and sparsity, providing model compression techniques for PyTorch, TensorFlow, and ONNX Runtime.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/intel/neural-compressor",
      "help_website": [
        "https://intel.github.io/neural-compressor/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "compression",
        "quantization",
        "sparsity"
      ],
      "id": 1236
    },
    {
      "name": "Paddler",
      "one_line_profile": "Load balancer and serving platform for LLMs",
      "detailed_description": "An open-source load balancer and serving platform designed for self-hosting Large Language Models at scale.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "load_balancing"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/intentee/paddler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "serving",
        "load-balancer",
        "llm"
      ],
      "id": 1237
    },
    {
      "name": "PKD-for-BERT-Model-Compression",
      "one_line_profile": "Patient Knowledge Distillation for BERT",
      "detailed_description": "A PyTorch implementation of Patient Knowledge Distillation (PKD) for compressing BERT models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "knowledge_distillation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/intersun/PKD-for-BERT-Model-Compression",
      "help_website": [],
      "license": null,
      "tags": [
        "bert",
        "compression",
        "distillation"
      ],
      "id": 1238
    },
    {
      "name": "IREE",
      "one_line_profile": "MLIR-based machine learning compiler and runtime",
      "detailed_description": "A retargetable compiler and runtime toolkit based on MLIR, designed to optimize and run machine learning models on various hardware backends.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "compiler",
        "inference_runtime"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/iree-org/iree",
      "help_website": [
        "https://iree.dev/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "compiler",
        "mlir",
        "runtime"
      ],
      "id": 1239
    },
    {
      "name": "ChatGPTQAG",
      "one_line_profile": "Automated QA pair generation using ChatGPT",
      "detailed_description": "A tool for automatically generating question-answer pairs using ChatGPT, applicable for creating training datasets for NLP tasks.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "data_generation",
        "dataset_synthesis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/itlubber/ChatGPTQAG",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "data-generation",
        "nlp",
        "qa"
      ],
      "id": 1240
    },
    {
      "name": "yolov5-onnxruntime",
      "one_line_profile": "C++ inference implementation for YOLOv5 using ONNX Runtime",
      "detailed_description": "A C++ implementation for running YOLOv5 object detection models using ONNX Runtime, serving as a reference solver for deployment.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_implementation",
        "object_detection"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/itsnine/yolov5-onnxruntime",
      "help_website": [],
      "license": null,
      "tags": [
        "yolo",
        "onnx",
        "inference"
      ],
      "id": 1241
    },
    {
      "name": "InferenceHelper",
      "one_line_profile": "C++ helper library for multiple inference frameworks",
      "detailed_description": "A C++ helper class that provides a unified interface for various deep learning inference frameworks including TensorFlow Lite, TensorRT, OpenVINO, and ONNX Runtime.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_integration",
        "framework_abstraction"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/iwatake2222/InferenceHelper",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "cpp",
        "wrapper"
      ],
      "id": 1242
    },
    {
      "name": "xllm",
      "one_line_profile": "High-performance LLM inference engine",
      "detailed_description": "A high-performance inference engine for Large Language Models, optimized for diverse AI accelerators.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_engine",
        "acceleration"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/jd-opensource/xllm",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "inference",
        "llm",
        "engine"
      ],
      "id": 1243
    },
    {
      "name": "GPTQ-for-LLaMa-CUDA",
      "one_line_profile": "Packaged CUDA version of GPTQ for LLaMa",
      "detailed_description": "A packaged distribution of the GPTQ-for-LLaMa tool with CUDA support, facilitating the quantization and inference of LLaMa models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "inference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jllllll/GPTQ-for-LLaMa-CUDA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gptq",
        "cuda",
        "quantization"
      ],
      "id": 1244
    },
    {
      "name": "openai-clip-js",
      "one_line_profile": "JavaScript port of OpenAI's CLIP model",
      "detailed_description": "A port of OpenAI's CLIP model to JavaScript using ONNX web runtime, enabling CLIP inference in web environments.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_implementation",
        "model_porting"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/josephrocca/openai-clip-js",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "clip",
        "javascript",
        "onnx"
      ],
      "id": 1245
    },
    {
      "name": "Sparrow",
      "one_line_profile": "Structured data extraction using LLMs",
      "detailed_description": "A tool for structured data extraction and instruction calling using Machine Learning and Large Language Models, suitable for processing scientific documents or data.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "data_extraction",
        "information_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/katanaml/sparrow",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "extraction",
        "llm",
        "data-processing"
      ],
      "id": 1246
    },
    {
      "name": "gpt-llama.cpp",
      "one_line_profile": "OpenAI API adapter for local llama.cpp models",
      "detailed_description": "A utility that acts as a drop-in replacement for OpenAI's GPT endpoints, allowing applications to interface with local llama.cpp models via standard APIs.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "api_adaptation"
      ],
      "application_level": "service",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/keldenl/gpt-llama.cpp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "api",
        "llama.cpp",
        "serving"
      ],
      "id": 1247
    },
    {
      "name": "search",
      "one_line_profile": "Embedded vector search library using llama.cpp",
      "detailed_description": "A Go library for embedded vector search and semantic embeddings utilizing llama.cpp, enabling semantic analysis and retrieval.",
      "domains": [
        "AI3"
      ],
      "subtask_category": [
        "vector_search",
        "embedding_generation"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/kelindar/search",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "search",
        "embeddings",
        "go"
      ],
      "id": 1248
    },
    {
      "name": "java-llama.cpp",
      "one_line_profile": "Java bindings for llama.cpp",
      "detailed_description": "Java bindings for the llama.cpp inference engine, enabling Java applications to run LLaMA models locally.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_integration",
        "language_binding"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/kherud/java-llama.cpp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "java",
        "llama.cpp",
        "inference"
      ],
      "id": 1249
    },
    {
      "name": "ONNX Runtime Server",
      "one_line_profile": "REST API server for ONNX inference",
      "detailed_description": "A server implementation that provides TCP and HTTP/HTTPS REST APIs for running inference using ONNX Runtime.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "model_deployment"
      ],
      "application_level": "service",
      "primary_language": "C++",
      "repo_url": "https://github.com/kibae/onnxruntime-server",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "onnx",
        "server",
        "rest-api"
      ],
      "id": 1250
    },
    {
      "name": "triton-grpc-proxy-rs",
      "one_line_profile": "Proxy server for Triton gRPC inference",
      "detailed_description": "A Rust-based proxy server for the Triton gRPC server, specifically designed for handling embedding model inference requests.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "proxy_service"
      ],
      "application_level": "service",
      "primary_language": "Rust",
      "repo_url": "https://github.com/kozistr/triton-grpc-proxy-rs",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "triton",
        "proxy",
        "rust"
      ],
      "id": 1251
    },
    {
      "name": "KServe",
      "one_line_profile": "Standardized AI inference platform for Kubernetes",
      "detailed_description": "A standardized, distributed inference platform for deploying generative and predictive AI models on Kubernetes, supporting scalable multi-framework deployment.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_serving",
        "model_deployment"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/kserve/kserve",
      "help_website": [
        "https://kserve.github.io/website/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "serving",
        "mlops"
      ],
      "id": 1252
    },
    {
      "name": "KubeAI",
      "one_line_profile": "Kubernetes operator for managing and scaling AI inference workloads",
      "detailed_description": "KubeAI is an AI Inference Operator for Kubernetes that simplifies serving machine learning models in production. It supports various model types including VLMs, LLMs, embeddings, and speech-to-text, providing auto-scaling and infrastructure management for AI services.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubeai-project/kubeai",
      "help_website": [
        "https://github.com/kubeai-project/kubeai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "inference-server",
        "llm-serving",
        "operator"
      ],
      "id": 1253
    },
    {
      "name": "Mooncake",
      "one_line_profile": "High-performance KVCache-centric LLM serving platform",
      "detailed_description": "Mooncake is a serving platform designed for Large Language Models (LLMs), utilizing a KVCache-centric architecture to optimize inference performance. It is used in production for the Kimi LLM service, focusing on efficient resource utilization and low-latency serving.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_optimization"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/kvcache-ai/Mooncake",
      "help_website": [
        "https://github.com/kvcache-ai/Mooncake"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-serving",
        "kv-cache",
        "inference-engine"
      ],
      "id": 1254
    },
    {
      "name": "ktransformers",
      "one_line_profile": "Framework for heterogeneous LLM inference and fine-tuning optimization",
      "detailed_description": "ktransformers is a flexible framework designed to optimize Large Language Model (LLM) inference and fine-tuning on heterogeneous hardware. It provides tools for experiencing and developing advanced optimization techniques for transformer-based models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "model_finetuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kvcache-ai/ktransformers",
      "help_website": [
        "https://github.com/kvcache-ai/ktransformers"
      ],
      "license": "Apache-2.0",
      "tags": [
        "transformers",
        "inference-optimization",
        "llm"
      ],
      "id": 1255
    },
    {
      "name": "Larq Compute Engine",
      "one_line_profile": "Highly optimized inference engine for Binarized Neural Networks (BNNs)",
      "detailed_description": "Larq Compute Engine (LCE) is a highly optimized inference engine specifically designed for Binarized Neural Networks (BNNs). It targets mobile and embedded devices, providing efficient execution of quantized models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_acceleration",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/larq/compute-engine",
      "help_website": [
        "https://docs.larq.dev/compute-engine/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "bnn",
        "inference-engine",
        "quantization",
        "mobile-ai"
      ],
      "id": 1256
    },
    {
      "name": "Mobile-ID",
      "one_line_profile": "Deep face model compression and acceleration toolkit",
      "detailed_description": "A MATLAB-based toolkit for compressing deep face recognition models. It implements algorithms for model compression to enable efficient deployment on mobile devices.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "quantization"
      ],
      "application_level": "solver",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/liuziwei7/mobile-id",
      "help_website": [
        "https://github.com/liuziwei7/mobile-id"
      ],
      "license": null,
      "tags": [
        "model-compression",
        "face-recognition",
        "matlab"
      ],
      "id": 1257
    },
    {
      "name": "LLMKit",
      "one_line_profile": "Toolkit for LLM prompt management, testing, and inference serving",
      "detailed_description": "LLMKit is a comprehensive toolkit and inference server for managing prompts, versioning, testing, and evaluating Large Language Models. It provides an OpenAI-compatible API and UI for model interaction.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "prompt_engineering"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/llmkit-ai/llmkit",
      "help_website": [
        "https://github.com/llmkit-ai/llmkit"
      ],
      "license": "MIT",
      "tags": [
        "llm-serving",
        "prompt-management",
        "inference-server"
      ],
      "id": 1258
    },
    {
      "name": "MLX Omni Server",
      "one_line_profile": "Local inference server for Apple Silicon using MLX framework",
      "detailed_description": "MLX Omni Server is a local inference server built on Apple's MLX framework, optimized for Apple Silicon. It provides OpenAI-compatible API endpoints for serving LLMs locally with high efficiency.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_server"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/madroidmaq/mlx-omni-server",
      "help_website": [
        "https://github.com/madroidmaq/mlx-omni-server"
      ],
      "license": "MIT",
      "tags": [
        "mlx",
        "apple-silicon",
        "inference-server",
        "llm"
      ],
      "id": 1259
    },
    {
      "name": "Altius",
      "one_line_profile": "Lightweight ONNX inference runtime in Rust",
      "detailed_description": "Altius is a small, efficient ONNX inference runtime written in Rust. It is designed to run ONNX models with low overhead, suitable for embedding in applications requiring fast inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_runtime",
        "model_execution"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/maekawatoshiki/altius",
      "help_website": [
        "https://github.com/maekawatoshiki/altius"
      ],
      "license": "MIT",
      "tags": [
        "onnx",
        "inference-runtime",
        "rust"
      ],
      "id": 1260
    },
    {
      "name": "rust-llama.cpp",
      "one_line_profile": "Rust bindings for llama.cpp inference engine",
      "detailed_description": "This library provides Rust bindings for llama.cpp, enabling Rust applications to leverage the efficient LLM inference capabilities of llama.cpp.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_runtime",
        "model_serving"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/mdrokz/rust-llama.cpp",
      "help_website": [
        "https://github.com/mdrokz/rust-llama.cpp"
      ],
      "license": "MIT",
      "tags": [
        "rust",
        "llama.cpp",
        "bindings",
        "inference"
      ],
      "id": 1261
    },
    {
      "name": "Sparsebit",
      "one_line_profile": "Model compression and acceleration toolbox",
      "detailed_description": "Sparsebit is a toolbox based on PyTorch for model compression and acceleration. It provides tools for quantization, pruning, and other optimization techniques to improve inference efficiency.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/megvii-research/Sparsebit",
      "help_website": [
        "https://github.com/megvii-research/Sparsebit"
      ],
      "license": "Apache-2.0",
      "tags": [
        "model-compression",
        "quantization",
        "pytorch"
      ],
      "id": 1262
    },
    {
      "name": "llama_ros",
      "one_line_profile": "ROS 2 integration for llama.cpp and llava.cpp",
      "detailed_description": "llama_ros provides a set of ROS 2 packages to integrate llama.cpp (for LLMs) and llava.cpp (for VLMs) into robotics systems, enabling on-robot inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_integration",
        "robotics_inference"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/mgonzs13/llama_ros",
      "help_website": [
        "https://github.com/mgonzs13/llama_ros"
      ],
      "license": "MIT",
      "tags": [
        "ros2",
        "robotics",
        "llama.cpp",
        "inference"
      ],
      "id": 1263
    },
    {
      "name": "Infinity",
      "one_line_profile": "High-throughput serving engine for embeddings and reranking models",
      "detailed_description": "Infinity is a high-performance serving engine specialized for text-embeddings, reranking models, and other vector-based models (CLIP, etc.). It focuses on high throughput and low latency for vector search applications.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "embedding_generation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/michaelfeil/infinity",
      "help_website": [
        "https://github.com/michaelfeil/infinity"
      ],
      "license": "MIT",
      "tags": [
        "embedding-server",
        "inference-engine",
        "vector-search"
      ],
      "id": 1264
    },
    {
      "name": "Olive",
      "one_line_profile": "Automated machine learning model optimization toolkit",
      "detailed_description": "Olive is a toolkit that simplifies the process of model fine-tuning, conversion, quantization, and optimization for deployment on various hardware targets (CPUs, GPUs, NPUs). It automates the optimization pipeline.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_optimization",
        "quantization",
        "model_conversion"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/Olive",
      "help_website": [
        "https://microsoft.github.io/Olive/"
      ],
      "license": "MIT",
      "tags": [
        "model-optimization",
        "onnx",
        "quantization",
        "automl"
      ],
      "id": 1265
    },
    {
      "name": "ParrotServe",
      "one_line_profile": "Efficient serving engine for LLM-based applications",
      "detailed_description": "ParrotServe is a serving system designed to optimize the execution of LLM-based applications by using semantic variables to manage context and requests efficiently.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_optimization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/ParrotServe",
      "help_website": [
        "https://github.com/microsoft/ParrotServe"
      ],
      "license": "MIT",
      "tags": [
        "llm-serving",
        "inference-system",
        "optimization"
      ],
      "id": 1266
    },
    {
      "name": "NNI",
      "one_line_profile": "AutoML toolkit for neural architecture search and model compression",
      "detailed_description": "Neural Network Intelligence (NNI) is an open-source AutoML toolkit that automates feature engineering, neural architecture search (NAS), hyper-parameter tuning, and model compression to optimize model performance and efficiency.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_optimization",
        "model_compression",
        "automl"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/nni",
      "help_website": [
        "https://nni.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "automl",
        "nas",
        "model-compression",
        "hyperparameter-tuning"
      ],
      "id": 1267
    },
    {
      "name": "ONNX Server Open Enclave",
      "one_line_profile": "Confidential inference server for ONNX models",
      "detailed_description": "This tool is a port of the ONNX inference server designed to run within Open Enclave, enabling confidential inference with data encryption and attestation capabilities, specifically for Azure Confidential Computing.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "confidential_computing"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/microsoft/onnx-server-openenclave",
      "help_website": [
        "https://github.com/microsoft/onnx-server-openenclave"
      ],
      "license": "MIT",
      "tags": [
        "confidential-computing",
        "onnx",
        "inference-server",
        "security"
      ],
      "id": 1268
    },
    {
      "name": "onnxruntime-extensions",
      "one_line_profile": "Custom operators and extensions for ONNX Runtime",
      "detailed_description": "A library providing custom operators and extensions for ONNX Runtime, enabling pre- and post-processing steps (like tokenization and image processing) to be embedded directly within the ONNX model graph.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "data_processing",
        "inference_support"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/microsoft/onnxruntime-extensions",
      "help_website": [
        "https://github.com/microsoft/onnxruntime-extensions"
      ],
      "license": "MIT",
      "tags": [
        "onnx",
        "extensions",
        "preprocessing",
        "custom-operators"
      ],
      "id": 1269
    },
    {
      "name": "Sarathi-Serve",
      "one_line_profile": "Low-latency and high-throughput LLM serving engine",
      "detailed_description": "Sarathi-Serve is a serving engine for Large Language Models designed to maximize throughput and minimize latency through techniques like chunked prefill and decode-maximal batching.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_optimization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/sarathi-serve",
      "help_website": [
        "https://github.com/microsoft/sarathi-serve"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-serving",
        "inference-engine",
        "optimization"
      ],
      "id": 1270
    },
    {
      "name": "vAttention",
      "one_line_profile": "Dynamic memory management system for LLM serving",
      "detailed_description": "vAttention is a system for dynamic memory management in LLM serving, enabling efficient handling of KV-cache without the need for PagedAttention, optimizing memory usage and performance.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "memory_management",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/microsoft/vattention",
      "help_website": [
        "https://github.com/microsoft/vattention"
      ],
      "license": "MIT",
      "tags": [
        "memory-management",
        "llm-serving",
        "cuda"
      ],
      "id": 1271
    },
    {
      "name": "Vidur",
      "one_line_profile": "Large-scale simulation framework for LLM inference",
      "detailed_description": "Vidur is a high-fidelity simulation framework for Large Language Model (LLM) inference. It allows researchers and practitioners to estimate the performance of LLM serving systems under various configurations and workloads.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "system_simulation",
        "performance_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/vidur",
      "help_website": [
        "https://github.com/microsoft/vidur"
      ],
      "license": "MIT",
      "tags": [
        "simulation",
        "llm-inference",
        "performance-modeling"
      ],
      "id": 1272
    },
    {
      "name": "AMC",
      "one_line_profile": "AutoML for Model Compression on mobile devices",
      "detailed_description": "AMC (AutoML for Model Compression) leverages reinforcement learning to automatically find the optimal compression strategy (pruning ratio, quantization bits) for deep neural networks, targeting mobile device constraints.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "automl"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mit-han-lab/amc",
      "help_website": [
        "https://github.com/mit-han-lab/amc"
      ],
      "license": "MIT",
      "tags": [
        "model-compression",
        "reinforcement-learning",
        "automl"
      ],
      "id": 1273
    },
    {
      "name": "LLM-AWQ",
      "one_line_profile": "Activation-aware Weight Quantization for LLMs",
      "detailed_description": "AWQ is a quantization toolkit for Large Language Models that protects salient weights based on activation magnitude. It enables efficient 4-bit quantization with minimal performance degradation.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_quantization",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mit-han-lab/llm-awq",
      "help_website": [
        "https://github.com/mit-han-lab/llm-awq"
      ],
      "license": "MIT",
      "tags": [
        "quantization",
        "llm",
        "compression"
      ],
      "id": 1274
    },
    {
      "name": "OmniServe",
      "one_line_profile": "Unified efficient serving system for LLMs",
      "detailed_description": "OmniServe (encompassing QServe and LServe) is a serving system designed for efficient LLM inference. It features advanced quantization (W4A8KV4) and system co-design, as well as optimizations for long-sequence serving.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_optimization"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/mit-han-lab/omniserve",
      "help_website": [
        "https://github.com/mit-han-lab/omniserve"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-serving",
        "quantization",
        "long-context"
      ],
      "id": 1275
    },
    {
      "name": "SmoothQuant",
      "one_line_profile": "Post-training quantization for Large Language Models",
      "detailed_description": "SmoothQuant is a post-training quantization framework that enables 8-bit weight, 8-bit activation (W8A8) quantization for LLMs by smoothing activation outliers, maintaining accuracy while improving efficiency.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_quantization",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mit-han-lab/smoothquant",
      "help_website": [
        "https://github.com/mit-han-lab/smoothquant"
      ],
      "license": "MIT",
      "tags": [
        "quantization",
        "llm",
        "post-training-optimization"
      ],
      "id": 1276
    },
    {
      "name": "MLC LLM",
      "one_line_profile": "Universal LLM deployment engine using machine learning compilation",
      "detailed_description": "A universal deployment solution that enables large language models to run natively on a diverse set of hardware backends and native applications, utilizing machine learning compilation technology (TVM).",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "model_deployment",
        "quantization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mlc-ai/mlc-llm",
      "help_website": [
        "https://llm.mlc.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "compilation",
        "inference",
        "edge-computing"
      ],
      "id": 1277
    },
    {
      "name": "Stopwatch",
      "one_line_profile": "Benchmarking tool for LLMs on Modal",
      "detailed_description": "A utility for benchmarking the performance (latency, throughput) of Large Language Models running on the Modal serverless platform.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/modal-labs/stopwatch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmarking",
        "llm",
        "latency"
      ],
      "id": 1278
    },
    {
      "name": "Mosec",
      "one_line_profile": "High-performance ML model serving framework",
      "detailed_description": "A machine learning model serving framework that offers dynamic batching and efficient CPU/GPU pipelines to maximize hardware utilization for inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_optimization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/mosecorg/mosec",
      "help_website": [
        "https://mosecorg.github.io/mosec/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "serving",
        "dynamic-batching",
        "inference"
      ],
      "id": 1279
    },
    {
      "name": "Llama Swap",
      "one_line_profile": "Model swapping utility for local LLM servers",
      "detailed_description": "A proxy service that enables reliable model swapping for OpenAI/Anthropic compatible local inference servers like llama.cpp or vllm, facilitating dynamic model management.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_management",
        "serving_utility"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/mostlygeek/llama-swap",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "proxy",
        "model-swapping",
        "llm-serving"
      ],
      "id": 1280
    },
    {
      "name": "Splitwise Sim",
      "one_line_profile": "LLM serving cluster simulator",
      "detailed_description": "A simulation tool for modeling and analyzing the behavior of LLM serving clusters, useful for research into scheduling and resource allocation strategies.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "simulation",
        "system_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mutinifni/splitwise-sim",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "simulation",
        "cluster",
        "llm-serving"
      ],
      "id": 1281
    },
    {
      "name": "AutoGPTQ-API",
      "one_line_profile": "API wrapper for AutoGPTQ inference",
      "detailed_description": "A tool to host GPTQ quantized models using AutoGPTQ as an API, compatible with text generation UI APIs, facilitating the serving of quantized models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "quantization"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/mzbac/AutoGPTQ-API",
      "help_website": [],
      "license": null,
      "tags": [
        "gptq",
        "api",
        "serving"
      ],
      "id": 1282
    },
    {
      "name": "GPTQ-for-LLaMa-API",
      "one_line_profile": "API for GPT-QLLama models",
      "detailed_description": "A lightweight API implementation for serving GPT-QLLama models, enabling programmatic access to quantized LLaMa inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "quantization"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/mzbac/GPTQ-for-LLaMa-API",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llama",
        "gptq",
        "api"
      ],
      "id": 1283
    },
    {
      "name": "MLX LLM Server",
      "one_line_profile": "Local LLM serving using MLX framework",
      "detailed_description": "A server implementation for inferring and serving local Large Language Models using Apple's MLX framework, optimized for Apple Silicon.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_optimization"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/mzbac/mlx-llm-server",
      "help_website": [],
      "license": null,
      "tags": [
        "mlx",
        "apple-silicon",
        "serving"
      ],
      "id": 1284
    },
    {
      "name": "MLX-Textgen",
      "one_line_profile": "OpenAI-compatible API for MLX LLM serving",
      "detailed_description": "A Python package for serving LLMs on OpenAI-compatible API endpoints with features like prompt caching, utilizing the MLX framework.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_optimization"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/nath1295/MLX-Textgen",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mlx",
        "api",
        "serving"
      ],
      "id": 1285
    },
    {
      "name": "onnxruntime-rs",
      "one_line_profile": "Rust wrapper for ONNX Runtime",
      "detailed_description": "A Rust language binding for Microsoft's ONNX Runtime, enabling high-performance inference of ONNX models within Rust applications.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_runtime",
        "language_binding"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/nbigaouette/onnxruntime-rs",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rust",
        "onnx",
        "inference"
      ],
      "id": 1286
    },
    {
      "name": "DeepSparse",
      "one_line_profile": "Sparsity-aware deep learning inference runtime",
      "detailed_description": "A CPU inference runtime that leverages sparsity to accelerate deep learning models, offering significant performance improvements for sparse models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "sparsity"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/neuralmagic/deepsparse",
      "help_website": [
        "https://docs.neuralmagic.com/deepsparse/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "sparsity",
        "cpu-inference",
        "acceleration"
      ],
      "id": 1287
    },
    {
      "name": "SparseZoo",
      "one_line_profile": "Repository for sparse and quantized models",
      "detailed_description": "A repository and tooling for accessing highly sparse and sparse-quantized neural network models, along with their sparsification recipes.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_repository",
        "model_management"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/neuralmagic/sparsezoo",
      "help_website": [
        "https://docs.neuralmagic.com/sparsezoo/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "sparse-models",
        "model-zoo",
        "quantization"
      ],
      "id": 1288
    },
    {
      "name": "Sparsify",
      "one_line_profile": "Model optimization tool for inference acceleration",
      "detailed_description": "A product and toolset for optimizing machine learning models through sparsification and quantization to accelerate inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_optimization",
        "quantization",
        "pruning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/neuralmagic/sparsify",
      "help_website": [
        "https://docs.neuralmagic.com/sparsify/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "optimization",
        "pruning",
        "inference"
      ],
      "id": 1289
    },
    {
      "name": "Wllama",
      "one_line_profile": "WebAssembly binding for llama.cpp",
      "detailed_description": "A WebAssembly binding for llama.cpp that enables running LLM inference directly in the browser or other Wasm runtimes, facilitating client-side scientific computing.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_runtime",
        "webassembly"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/ngxson/wllama",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wasm",
        "llama.cpp",
        "browser-inference"
      ],
      "id": 1290
    },
    {
      "name": "vLLM-gfx906",
      "one_line_profile": "vLLM port for AMD gfx906 GPUs",
      "detailed_description": "A specialized port of the vLLM serving engine optimized for AMD gfx906 GPUs (e.g., Radeon VII, MI50, MI60), enabling high-throughput serving on this hardware.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nlzy/vllm-gfx906",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "amd",
        "rocm",
        "vllm",
        "serving"
      ],
      "id": 1291
    },
    {
      "name": "pygpt4all",
      "one_line_profile": "Python bindings for llama.cpp and gpt4all",
      "detailed_description": "Official Python bindings for the gpt4all and llama.cpp ecosystem, allowing developers to run quantized LLMs locally via Python.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_runtime",
        "language_binding"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/nomic-ai/pygpt4all",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpt4all",
        "llama.cpp",
        "bindings"
      ],
      "id": 1292
    },
    {
      "name": "openai_trtllm",
      "one_line_profile": "OpenAI compatible API for TensorRT-LLM",
      "detailed_description": "A backend that exposes TensorRT-LLM via an OpenAI-compatible API, facilitating the integration of optimized TensorRT inference into standard LLM workflows.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_optimization"
      ],
      "application_level": "service",
      "primary_language": "Rust",
      "repo_url": "https://github.com/npuichigo/openai_trtllm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tensorrt-llm",
        "api",
        "serving"
      ],
      "id": 1293
    },
    {
      "name": "DeepCompressor",
      "one_line_profile": "Model compression toolbox for LLMs and Diffusion Models",
      "detailed_description": "A toolbox for compressing Large Language Models and Diffusion Models, enabling efficient storage and inference through advanced quantization and compression techniques.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "quantization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nunchaku-tech/deepcompressor",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compression",
        "llm",
        "diffusion"
      ],
      "id": 1294
    },
    {
      "name": "Whisper TFLite",
      "one_line_profile": "Optimized Whisper TFLite port for edge inference",
      "detailed_description": "A port of OpenAI's Whisper model to TensorFlow Lite, optimized for efficient offline inference on edge devices.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "edge_computing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/nyadla-sys/whisper.tflite",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "whisper",
        "tflite",
        "edge-inference"
      ],
      "id": 1295
    },
    {
      "name": "ORT Builder",
      "one_line_profile": "ONNX Runtime static library builder",
      "detailed_description": "A utility to build static libraries for ONNX Runtime, facilitating the embedding of the inference engine into various applications and systems.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "build_tool",
        "inference_deployment"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/olilarkin/ort-builder",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "onnx-runtime",
        "build-tool",
        "static-library"
      ],
      "id": 1296
    },
    {
      "name": "Anomalib",
      "one_line_profile": "Deep learning library for anomaly detection",
      "detailed_description": "A library comprising state-of-the-art algorithms for anomaly detection, including features for experiment management, hyper-parameter optimization, and edge inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "anomaly_detection",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/open-edge-platform/anomalib",
      "help_website": [
        "https://anomalib.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "anomaly-detection",
        "computer-vision",
        "edge-inference"
      ],
      "id": 1297
    },
    {
      "name": "OpenVINO Training Extensions",
      "one_line_profile": "Toolbox for training and optimizing CV models via OpenVINO",
      "detailed_description": "A toolkit to train, evaluate, optimize, and deploy computer vision models, specifically designed to work with the OpenVINO ecosystem for efficient inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_optimization",
        "training_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/open-edge-platform/training_extensions",
      "help_website": [
        "https://github.com/openvinotoolkit/training_extensions"
      ],
      "license": "Apache-2.0",
      "tags": [
        "openvino",
        "computer-vision",
        "optimization"
      ],
      "id": 1298
    },
    {
      "name": "MMRazor",
      "one_line_profile": "OpenMMLab model compression toolbox",
      "detailed_description": "A model compression toolbox that provides various algorithms for network pruning, knowledge distillation, and neural architecture search to optimize models for inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "pruning",
        "distillation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/open-mmlab/mmrazor",
      "help_website": [
        "https://mmrazor.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "compression",
        "openmmlab",
        "optimization"
      ],
      "id": 1299
    },
    {
      "name": "OpenVINO Model Server",
      "one_line_profile": "Scalable inference server for OpenVINO models",
      "detailed_description": "A high-performance system for serving machine learning models optimized with OpenVINO, supporting scalable inference via gRPC and REST endpoints.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_optimization"
      ],
      "application_level": "service",
      "primary_language": "C++",
      "repo_url": "https://github.com/openvinotoolkit/model_server",
      "help_website": [
        "https://docs.openvino.ai/latest/ovms_what_is_openvino_model_server.html"
      ],
      "license": "Apache-2.0",
      "tags": [
        "serving",
        "openvino",
        "inference"
      ],
      "id": 1300
    },
    {
      "name": "OpenVINO",
      "one_line_profile": "Toolkit for optimizing and deploying AI inference",
      "detailed_description": "An open-source toolkit for optimizing and deploying deep learning models across various hardware platforms, focusing on high-performance inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "model_deployment"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/openvinotoolkit/openvino",
      "help_website": [
        "https://docs.openvino.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "optimization",
        "intel"
      ],
      "id": 1301
    },
    {
      "name": "sd4j",
      "one_line_profile": "Stable Diffusion pipeline in Java using ONNX Runtime",
      "detailed_description": "A Java implementation of the Stable Diffusion pipeline leveraging ONNX Runtime for inference, enabling image generation within Java environments.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_pipeline",
        "image_generation"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/oracle/sd4j",
      "help_website": [],
      "license": "UPL-1.0",
      "tags": [
        "java",
        "stable-diffusion",
        "onnx"
      ],
      "id": 1302
    },
    {
      "name": "KVCached",
      "one_line_profile": "Virtualized elastic KV cache for LLM serving",
      "detailed_description": "A system for virtualized and elastic Key-Value (KV) cache management, designed to optimize dynamic GPU sharing and memory usage in LLM serving.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "memory_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ovg-project/kvcached",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kv-cache",
        "llm-serving",
        "optimization"
      ],
      "id": 1303
    },
    {
      "name": "ONNX Transformers",
      "one_line_profile": "Accelerated NLP pipelines using ONNX Runtime",
      "detailed_description": "A collection of pipelines and utilities for running fast NLP inference on CPUs using Hugging Face Transformers and ONNX Runtime.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "nlp_pipeline"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/patil-suraj/onnx_transformers",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "onnx",
        "transformers",
        "nlp"
      ],
      "id": 1304
    },
    {
      "name": "BambooAI",
      "one_line_profile": "LLM-powered library for data discovery and analysis",
      "detailed_description": "A Python library that uses Large Language Models to assist in conversational data discovery, analysis, and visualization, acting as an AI agent for data science tasks.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "data_analysis",
        "scientific_visualization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/pgalko/BambooAI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-analysis",
        "llm-agent",
        "pandas"
      ],
      "id": 1305
    },
    {
      "name": "llama.clj",
      "one_line_profile": "Clojure wrapper for llama.cpp",
      "detailed_description": "A Clojure language wrapper for llama.cpp, enabling the use of local Large Language Models within Clojure applications and research workflows.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_binding",
        "language_binding"
      ],
      "application_level": "library",
      "primary_language": "Clojure",
      "repo_url": "https://github.com/phronmophobic/llama.clj",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "clojure",
        "llama.cpp",
        "inference"
      ],
      "id": 1306
    },
    {
      "name": "Neural Imaging",
      "one_line_profile": "Toolbox for modeling photo acquisition pipelines",
      "detailed_description": "A Python toolbox for modeling and optimizing photo acquisition and distribution pipelines, including camera ISP, compression, and manipulation detection.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "image_processing",
        "simulation",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pkorus/neural-imaging",
      "help_website": [],
      "license": null,
      "tags": [
        "imaging",
        "isp",
        "simulation"
      ],
      "id": 1307
    },
    {
      "name": "PowerServe",
      "one_line_profile": "High-speed LLM serving framework",
      "detailed_description": "A high-performance framework for serving Large Language Models locally, designed for speed and ease of use in deployment scenarios.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_optimization"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/powerserve-project/PowerServe",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "serving",
        "llm",
        "inference"
      ],
      "id": 1308
    },
    {
      "name": "Prometheus-Eval",
      "one_line_profile": "Evaluation library for LLM responses using Prometheus and GPT-4",
      "detailed_description": "Prometheus-Eval provides tools to evaluate the quality of Large Language Model responses, serving as a critical component for validating scientific models and generated data.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "quality_assessment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/prometheus-eval/prometheus-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "llm",
        "benchmark"
      ],
      "id": 1309
    },
    {
      "name": "Punica",
      "one_line_profile": "System for serving multiple LoRA fine-tuned LLMs efficiently",
      "detailed_description": "Punica is a serving system designed to run multiple LoRA fine-tuned Large Language Models simultaneously on shared GPUs, optimizing throughput for diverse scientific inference tasks.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_optimization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/punica-ai/punica",
      "help_website": [
        "https://punica-ai.github.io/punica/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "lora",
        "multi-tenant",
        "serving"
      ],
      "id": 1310
    },
    {
      "name": "PyTorch-ORT",
      "one_line_profile": "Acceleration library for PyTorch models using ONNX Runtime",
      "detailed_description": "PyTorch-ORT enables the acceleration of PyTorch model training and inference by leveraging ONNX Runtime, optimizing computational efficiency for scientific AI workloads.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pytorch/ort",
      "help_website": [
        "https://cloudblogs.microsoft.com/opensource/2021/07/13/accelerate-pytorch-training-with-torch-ort/"
      ],
      "license": "MIT",
      "tags": [
        "onnx",
        "pytorch",
        "acceleration"
      ],
      "id": 1311
    },
    {
      "name": "Qualcomm AI Hub Models",
      "one_line_profile": "Library for accessing and deploying optimized ML models on Qualcomm devices",
      "detailed_description": "This tool provides a Python API to access, optimize, and deploy a collection of state-of-the-art machine learning models, facilitating edge AI inference for scientific data collection and processing.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_deployment",
        "edge_inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/quic/ai-hub-models",
      "help_website": [
        "https://aihub.qualcomm.com/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "edge-ai",
        "model-zoo",
        "optimization"
      ],
      "id": 1312
    },
    {
      "name": "AIMET",
      "one_line_profile": "AI Model Efficiency Toolkit for quantization and compression",
      "detailed_description": "AIMET (AI Model Efficiency Toolkit) provides advanced model quantization and compression techniques to optimize neural networks for efficient inference in scientific applications.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/quic/aimet",
      "help_website": [
        "https://quic.github.io/aimet-pages/index.html"
      ],
      "license": "NOASSERTION",
      "tags": [
        "quantization",
        "compression",
        "efficiency"
      ],
      "id": 1313
    },
    {
      "name": "GPTQ-for-LLaMa",
      "one_line_profile": "4-bit quantization implementation for LLaMA models using GPTQ",
      "detailed_description": "This tool implements the GPTQ algorithm for 4-bit quantization of LLaMA models, enabling efficient inference of large language models on consumer-grade hardware for research purposes.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "inference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/qwopqwop200/GPTQ-for-LLaMa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gptq",
        "quantization",
        "llama"
      ],
      "id": 1314
    },
    {
      "name": "Tritony",
      "one_line_profile": "Simplified client library for Triton Inference Server",
      "detailed_description": "Tritony is a helper library that simplifies the configuration and interaction with NVIDIA Triton Inference Server, facilitating the deployment of scientific models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_client"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rtzr/tritony",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "triton",
        "inference",
        "client"
      ],
      "id": 1315
    },
    {
      "name": "OpenCvSharp Mini Runtime",
      "one_line_profile": "Minimal runtime for OpenCVSharp optimized for server inference",
      "detailed_description": "A lightweight runtime library for OpenCVSharp, designed to facilitate computer vision model inference in server environments for image processing tasks.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "image_processing",
        "inference_runtime"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/sdcb/opencvsharp-mini-runtime",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "opencv",
        "runtime",
        "inference"
      ],
      "id": 1316
    },
    {
      "name": "GenAI-Bench",
      "one_line_profile": "Benchmark tool for evaluating LLM serving systems",
      "detailed_description": "GenAI-Bench is a benchmarking suite designed to evaluate the token-level performance, throughput, and latency of Large Language Model serving systems.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sgl-project/genai-bench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "serving",
        "llm"
      ],
      "id": 1317
    },
    {
      "name": "SGLang",
      "one_line_profile": "Fast serving framework for LLMs and VLMs",
      "detailed_description": "SGLang is a high-performance serving framework for large language and vision-language models, offering optimized runtime execution for scientific AI applications.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_engine"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/sgl-project/sglang",
      "help_website": [
        "https://sgl-project.github.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "serving",
        "inference",
        "vlm"
      ],
      "id": 1318
    },
    {
      "name": "GPT Server",
      "one_line_profile": "Production-grade serving framework for multimodal AI models",
      "detailed_description": "gpt_server is an open-source framework for deploying various AI models including LLMs, Embeddings, and Rerankers, facilitating the creation of scientific inference services.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "multimodal_inference"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/shell-nlp/gpt_server",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "serving",
        "deployment",
        "multimodal"
      ],
      "id": 1319
    },
    {
      "name": "llm-llama-cpp",
      "one_line_profile": "Plugin to run llama.cpp models via the LLM CLI",
      "detailed_description": "This tool is a plugin for the 'llm' command-line utility, enabling the execution of models using the llama.cpp backend, facilitating local inference for researchers.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_runtime",
        "model_execution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/simonw/llm-llama-cpp",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llama.cpp",
        "plugin",
        "inference"
      ],
      "id": 1320
    },
    {
      "name": "Nano-PEARL",
      "one_line_profile": "Parallel speculative decoding serving system",
      "detailed_description": "Nano-PEARL is a serving system implementing Draft-Target Disaggregation via Parallel Speculative Decoding, designed to accelerate LLM inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "speculative_decoding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/smart-lty/nano-PEARL",
      "help_website": [],
      "license": null,
      "tags": [
        "speculative-decoding",
        "serving",
        "acceleration"
      ],
      "id": 1321
    },
    {
      "name": "ArcticInference",
      "one_line_profile": "vLLM plugin for high-throughput inference of Arctic models",
      "detailed_description": "A specialized plugin for the vLLM serving engine designed to enable high-throughput and low-latency inference specifically for Snowflake's Arctic series of Large Language Models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/snowflakedb/ArcticInference",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vllm",
        "inference",
        "arctic-model"
      ],
      "id": 1322
    },
    {
      "name": "Cube Studio",
      "one_line_profile": "Cloud-native one-stop MLOps and AI platform",
      "detailed_description": "A comprehensive cloud-native AI platform supporting the full MLOps lifecycle, including distributed training, hyperparameter search, and inference serving for deep learning and large language models.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "mlops",
        "model_training",
        "model_serving"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/tencentmusic/cube-studio",
      "help_website": [
        "https://github.com/tencentmusic/cube-studio/wiki"
      ],
      "license": "NOASSERTION",
      "tags": [
        "mlops",
        "distributed-training",
        "inference-server"
      ],
      "id": 1323
    },
    {
      "name": "OpenModelZ",
      "one_line_profile": "Autoscaling infrastructure for LLM inference on Kubernetes",
      "detailed_description": "A deployment tool designed to automate the scaling and management of Large Language Model (LLM) inference servers (like vLLM and SGLang) on Kubernetes clusters.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "infrastructure_scaling"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/tensorchord/openmodelz",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "autoscaling",
        "llm-serving"
      ],
      "id": 1324
    },
    {
      "name": "TensorFlow Model Optimization Toolkit",
      "one_line_profile": "Toolkit to optimize ML models for deployment",
      "detailed_description": "A suite of tools for optimizing machine learning models for deployment and execution, supporting techniques such as quantization and pruning to reduce model size and improve latency.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_optimization",
        "quantization",
        "pruning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tensorflow/model-optimization",
      "help_website": [
        "https://www.tensorflow.org/model_optimization"
      ],
      "license": "Apache-2.0",
      "tags": [
        "tensorflow",
        "optimization",
        "quantization"
      ],
      "id": 1325
    },
    {
      "name": "Indexify",
      "one_line_profile": "Realtime serving engine for data-intensive AI applications",
      "detailed_description": "A serving engine and extraction framework designed for building data-intensive generative AI applications, facilitating the ingestion and processing of unstructured data for RAG and inference pipelines.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "data_extraction",
        "rag"
      ],
      "application_level": "service",
      "primary_language": "Rust",
      "repo_url": "https://github.com/tensorlakeai/indexify",
      "help_website": [
        "https://docs.getindexify.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "serving-engine",
        "rag",
        "unstructured-data"
      ],
      "id": 1326
    },
    {
      "name": "llamacpp-python",
      "one_line_profile": "Python bindings for llama.cpp inference engine",
      "detailed_description": "Python bindings for the llama.cpp library, enabling efficient local inference of Large Language Models directly within Python environments commonly used for scientific computing.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_inference",
        "local_deployment"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/thomasantony/llamacpp-python",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llama.cpp",
        "inference",
        "python-binding"
      ],
      "id": 1327
    },
    {
      "name": "SageAttention",
      "one_line_profile": "Quantized attention library for model acceleration",
      "detailed_description": "A library implementing quantized attention mechanisms to accelerate inference speed for language, image, and video models without significant loss in accuracy.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_acceleration",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/thu-ml/SageAttention",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "attention-mechanism",
        "quantization",
        "acceleration"
      ],
      "id": 1328
    },
    {
      "name": "SpargeAttention",
      "one_line_profile": "Training-free sparse attention for inference acceleration",
      "detailed_description": "A library providing a training-free sparse attention mechanism to accelerate the inference of transformer-based models by optimizing attention computation.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_acceleration",
        "sparse_attention"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/thu-ml/SpargeAttn",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sparse-attention",
        "inference",
        "optimization"
      ],
      "id": 1329
    },
    {
      "name": "llama.onnx",
      "one_line_profile": "Tools for converting and running LLaMA/RWKV models in ONNX",
      "detailed_description": "A utility toolkit for exporting LLaMA and RWKV language models to the ONNX format, including quantization support and test cases for verification.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_conversion",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tpoisonooo/llama.onnx",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "onnx",
        "model-conversion",
        "llama"
      ],
      "id": 1330
    },
    {
      "name": "Triton Core",
      "one_line_profile": "Core library for Triton Inference Server",
      "detailed_description": "The core library and API implementation for the NVIDIA Triton Inference Server, providing the fundamental infrastructure for model serving.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "infrastructure"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/triton-inference-server/core",
      "help_website": [
        "https://github.com/triton-inference-server/server/blob/main/docs/README.md"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "triton",
        "inference-server",
        "core"
      ],
      "id": 1331
    },
    {
      "name": "Triton FIL Backend",
      "one_line_profile": "Forest Inference Library backend for Triton",
      "detailed_description": "A backend for the Triton Inference Server that enables high-performance inference of tree-based models (e.g., XGBoost, LightGBM, Scikit-Learn) using the Forest Inference Library (FIL).",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_backend"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/triton-inference-server/fil_backend",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "triton",
        "xgboost",
        "random-forest"
      ],
      "id": 1332
    },
    {
      "name": "Triton Local Cache",
      "one_line_profile": "In-memory cache implementation for Triton",
      "detailed_description": "A local in-memory cache implementation for the Triton Inference Server, designed to reduce latency by caching inference responses.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "caching"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/triton-inference-server/local_cache",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "triton",
        "cache",
        "optimization"
      ],
      "id": 1333
    },
    {
      "name": "Triton Model Analyzer",
      "one_line_profile": "Profiling tool for Triton Inference Server models",
      "detailed_description": "A CLI tool for profiling and analyzing the compute and memory requirements of models served by Triton, helping to optimize configuration for performance.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "performance_profiling",
        "resource_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/triton-inference-server/model_analyzer",
      "help_website": [
        "https://github.com/triton-inference-server/model_analyzer/blob/main/docs/README.md"
      ],
      "license": "Apache-2.0",
      "tags": [
        "profiling",
        "triton",
        "optimization"
      ],
      "id": 1334
    },
    {
      "name": "Triton Model Navigator",
      "one_line_profile": "Toolkit for optimizing and deploying models on NVIDIA GPUs",
      "detailed_description": "An inference toolkit that automates the process of moving models from training to deployment, including optimization and conversion for NVIDIA GPUs within the Triton ecosystem.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_deployment",
        "model_optimization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/triton-inference-server/model_navigator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deployment",
        "optimization",
        "nvidia"
      ],
      "id": 1335
    },
    {
      "name": "Triton ONNX Runtime Backend",
      "one_line_profile": "ONNX Runtime backend for Triton",
      "detailed_description": "The backend integration that allows the Triton Inference Server to execute models using the ONNX Runtime engine.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_backend"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/triton-inference-server/onnxruntime_backend",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "triton",
        "onnx",
        "backend"
      ],
      "id": 1336
    },
    {
      "name": "Triton Inference Server",
      "one_line_profile": "High-performance inference serving software",
      "detailed_description": "An open-source inference serving software that streamlines AI inference by enabling teams to deploy, run, and scale trained AI models from any framework on any GPU- or CPU-based infrastructure.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_server"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/triton-inference-server/server",
      "help_website": [
        "https://developer.nvidia.com/nvidia-triton-inference-server"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "inference-server",
        "nvidia",
        "deployment"
      ],
      "id": 1337
    },
    {
      "name": "Triton TensorRT-LLM Backend",
      "one_line_profile": "TensorRT-LLM backend for Triton",
      "detailed_description": "The backend for Triton Inference Server that enables optimized serving of Large Language Models using NVIDIA's TensorRT-LLM library.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "llm_inference"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/triton-inference-server/tensorrtllm_backend",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tensorrt-llm",
        "triton",
        "backend"
      ],
      "id": 1338
    },
    {
      "name": "Triton CLI",
      "one_line_profile": "Command line interface for Triton Inference Server",
      "detailed_description": "A command-line tool to simplify the creation, deployment, and profiling of models served by the Triton Inference Server.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_management",
        "deployment_tools"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/triton-inference-server/triton_cli",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "cli",
        "triton",
        "management"
      ],
      "id": 1339
    },
    {
      "name": "TrustGraph",
      "one_line_profile": "Graph-based RAG tool for AI reliability",
      "detailed_description": "A tool designed to eliminate hallucinations in AI agents by constructing and utilizing knowledge graphs, enhancing the reliability of scientific information retrieval and inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "rag",
        "knowledge_graph",
        "inference_reliability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/trustgraph-ai/trustgraph",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "knowledge-graph",
        "hallucination-reduction"
      ],
      "id": 1340
    },
    {
      "name": "LLaVA C++ Server",
      "one_line_profile": "Server implementation for LLaVA multimodal models",
      "detailed_description": "A lightweight server implementation for LLaVA (Large Language-and-Vision Assistant) models based on llama.cpp, enabling multimodal inference.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "multimodal_inference"
      ],
      "application_level": "service",
      "primary_language": "C++",
      "repo_url": "https://github.com/trzy/llava-cpp-server",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llava",
        "multimodal",
        "inference-server"
      ],
      "id": 1341
    },
    {
      "name": "ExLlamaV3",
      "one_line_profile": "Optimized quantization and inference library for local LLMs",
      "detailed_description": "A highly optimized library for quantization and inference of Large Language Models on consumer-class GPUs, focusing on performance and memory efficiency.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_quantization",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/turboderp-org/exllamav3",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "quantization",
        "inference",
        "exllama"
      ],
      "id": 1342
    },
    {
      "name": "Pinferencia",
      "one_line_profile": "Simple Python model deployment library",
      "detailed_description": "A lightweight library for deploying Python machine learning models as inference services with minimal configuration.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "deployment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/underneathall/pinferencia",
      "help_website": [
        "https://pinferencia.underneathall.app"
      ],
      "license": "Apache-2.0",
      "tags": [
        "deployment",
        "inference",
        "python"
      ],
      "id": 1343
    },
    {
      "name": "Super JSON Mode",
      "one_line_profile": "Library for structured JSON generation from LLMs",
      "detailed_description": "A framework designed to ensure low-latency and reliable JSON output generation from Large Language Models, facilitating structured data extraction from scientific text.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "data_extraction",
        "structured_generation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/varunshenoy/super-json-mode",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "json",
        "llm-output",
        "structured-data"
      ],
      "id": 1344
    },
    {
      "name": "ScaleLLM",
      "one_line_profile": "High-performance LLM inference system",
      "detailed_description": "A high-performance inference system designed for deploying Large Language Models in production environments, optimizing throughput and latency.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_system"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/vectorch-ai/ScaleLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "llm",
        "production"
      ],
      "id": 1345
    },
    {
      "name": "Orkhon",
      "one_line_profile": "Rust-based ML inference framework",
      "detailed_description": "A machine learning inference framework and server runtime written in Rust, focusing on performance and safety for model deployment.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_runtime"
      ],
      "application_level": "framework",
      "primary_language": "Rust",
      "repo_url": "https://github.com/vertexclique/orkhon",
      "help_website": [
        "https://orkhon.neocities.org"
      ],
      "license": "MIT",
      "tags": [
        "rust",
        "inference",
        "machine-learning"
      ],
      "id": 1346
    },
    {
      "name": "LLM Compressor",
      "one_line_profile": "Library for LLM compression and optimization",
      "detailed_description": "A library compatible with Transformers for applying compression algorithms (quantization, pruning) to Large Language Models to optimize them for deployment with vLLM.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_compression",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vllm-project/llm-compressor",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compression",
        "quantization",
        "vllm"
      ],
      "id": 1347
    },
    {
      "name": "vLLM Production Stack",
      "one_line_profile": "Reference stack for K8s-native vLLM deployment",
      "detailed_description": "A reference implementation and toolkit for deploying vLLM on Kubernetes clusters, providing best practices for production-grade model serving.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_deployment",
        "infrastructure"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/vllm-project/production-stack",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "deployment",
        "vllm"
      ],
      "id": 1348
    },
    {
      "name": "Semantic Router",
      "one_line_profile": "Routing layer for LLM inference pipelines",
      "detailed_description": "A superfast decision-making layer for LLMs and agents that routes requests to the appropriate model or prompt based on semantic meaning, optimizing inference costs and performance.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_routing",
        "pipeline_optimization"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/vllm-project/semantic-router",
      "help_website": [
        "https://semantic-router.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "routing",
        "semantic-search",
        "inference"
      ],
      "id": 1349
    },
    {
      "name": "vLLM",
      "one_line_profile": "High-throughput LLM inference and serving engine",
      "detailed_description": "A state-of-the-art library for fast and memory-efficient inference and serving of Large Language Models, featuring PagedAttention and continuous batching.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "model_serving",
        "inference_engine"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/vllm-project/vllm",
      "help_website": [
        "https://docs.vllm.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "serving",
        "paged-attention"
      ],
      "id": 1350
    },
    {
      "name": "vllm-ascend",
      "one_line_profile": "Hardware backend plugin enabling vLLM execution on Huawei Ascend NPUs",
      "detailed_description": "A community-maintained hardware abstraction layer that extends the vLLM inference engine to support Huawei Ascend AI processors (NPUs), enabling high-throughput LLM serving on this specific hardware architecture.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "serving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vllm-project/vllm-ascend",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vllm",
        "ascend",
        "npu",
        "inference"
      ],
      "id": 1351
    },
    {
      "name": "vllm-omni",
      "one_line_profile": "Inference framework for omni-modality large models",
      "detailed_description": "An extension of the vLLM architecture designed to support efficient inference for multimodal models (audio, video, text), handling the complexities of cross-modal generation and serving.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "serving",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vllm-project/vllm-omni",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "inference",
        "vllm",
        "serving"
      ],
      "id": 1352
    },
    {
      "name": "QLLM",
      "one_line_profile": "Quantization toolbox for Large Language Models",
      "detailed_description": "A general-purpose quantization library supporting multiple algorithms (GPTQ, AWQ, HQQ, VPTQ) for compressing Large Language Models to 2-8 bits, with support for exporting to ONNX/ONNX Runtime.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wejoncy/QLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "gptq",
        "awq",
        "onnx"
      ],
      "id": 1353
    },
    {
      "name": "quantkit",
      "one_line_profile": "CLI tool for LLM quantization formats",
      "detailed_description": "A command-line interface utility for quantizing Large Language Models into various formats including GGUF, GPTQ, AWQ, HQQ, and EXL2, facilitating model deployment on consumer hardware.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "model_conversion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/xhedit/quantkit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cli",
        "quantization",
        "gguf",
        "gptq"
      ],
      "id": 1354
    },
    {
      "name": "onnx_runtime_cpp",
      "one_line_profile": "C++ wrapper for ONNX Runtime deployment",
      "detailed_description": "A lightweight C++ library designed to simplify the deployment of ONNX models using ONNX Runtime, providing an abstraction layer for inference integration in C++ applications.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "inference_optimization",
        "deployment"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/xmba15/onnx_runtime_cpp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "onnx",
        "cpp",
        "inference",
        "deployment"
      ],
      "id": 1355
    },
    {
      "name": "Xinference",
      "one_line_profile": "Unified inference serving platform for LLMs and multimodal models",
      "detailed_description": "A comprehensive inference server that supports running open-source LLMs, speech recognition, and multimodal models. It provides a unified API compatible with OpenAI's interface and supports distributed deployment.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "serving",
        "inference_optimization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/xorbitsai/inference",
      "help_website": [
        "https://inference.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "serving",
        "llm",
        "distributed-inference",
        "api"
      ],
      "id": 1356
    },
    {
      "name": "LOPQ",
      "one_line_profile": "Locally Optimized Product Quantization for ANN search",
      "detailed_description": "A library for training Locally Optimized Product Quantization (LOPQ) models, enabling efficient approximate nearest neighbor search for high-dimensional data, suitable for large-scale scientific data retrieval.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "quantization",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yahoo/lopq",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ann",
        "quantization",
        "search",
        "high-dimensional"
      ],
      "id": 1357
    },
    {
      "name": "ZhiLight",
      "one_line_profile": "High-performance inference engine for Llama models",
      "detailed_description": "A highly optimized inference acceleration engine specifically designed for Llama and its variants, focusing on high throughput and low latency serving in production environments.",
      "domains": [
        "AI3",
        "AI3-05"
      ],
      "subtask_category": [
        "serving",
        "inference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/zhihu/ZhiLight",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "llama",
        "acceleration",
        "serving"
      ],
      "id": 1358
    }
  ]
}