{
  "leaf_cluster_name": "数字健康-临床文本与多模态生态",
  "domain": "Digital Health",
  "typical_objects": "EHR/text+image",
  "task_chain": "抽取→标准化→检索→问答→评测",
  "tool_form": "NLP/检索 + 合规/脱敏",
  "total_tools": 471,
  "tools": [
    {
      "name": "ANTs",
      "one_line_profile": "Advanced Normalization Tools for medical image registration and segmentation",
      "detailed_description": "A state-of-the-art medical image processing toolkit providing advanced methods for image registration, segmentation, and statistical analysis, widely used in neuroimaging.",
      "domains": [
        "Digital Health",
        "Medical Imaging"
      ],
      "subtask_category": [
        "image_registration",
        "normalization",
        "segmentation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ANTsX/ANTs",
      "help_website": [
        "http://stnava.github.io/ANTs/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "medical-imaging",
        "registration",
        "normalization",
        "neuroimaging"
      ],
      "id": 1
    },
    {
      "name": "pymetamap",
      "one_line_profile": "Python wrapper for the NLM MetaMap medical NLP tool",
      "detailed_description": "A Python wrapper that facilitates the use of the National Library of Medicine's MetaMap tool, allowing for the extraction of Unified Medical Language System (UMLS) concepts from biomedical text within Python workflows.",
      "domains": [
        "Digital Health",
        "H2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "concept_normalization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AnthonyMRios/pymetamap",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "metamap",
        "umls",
        "nlp",
        "biomedical-text"
      ],
      "id": 2
    },
    {
      "name": "Clinical-ICD10-Code-Prediction",
      "one_line_profile": "BERT-based API for predicting ICD-10 codes from clinical descriptions",
      "detailed_description": "A tool providing an API to predict ICD-10 codes from clinical text descriptions using a Transformer-based model (BERT) fine-tuned on clinical data.",
      "domains": [
        "Digital Health",
        "H2-01"
      ],
      "subtask_category": [
        "icd_coding",
        "classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AsianZeus/Clinical-ICD10-Code-Prediction",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "icd-10",
        "bert",
        "clinical-nlp",
        "coding"
      ],
      "id": 3
    },
    {
      "name": "NLP2FHIR",
      "one_line_profile": "Pipeline for normalizing clinical NLP results to FHIR standard",
      "detailed_description": "A clinical data normalization pipeline that converts unstructured clinical text into structured HL7 FHIR resources, facilitating interoperability and secondary use of EHR data.",
      "domains": [
        "Digital Health",
        "H2-01"
      ],
      "subtask_category": [
        "normalization",
        "standardization",
        "interoperability"
      ],
      "application_level": "workflow",
      "primary_language": "Java",
      "repo_url": "https://github.com/BD2KOnFHIR/NLP2FHIR",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "fhir",
        "nlp",
        "clinical-data",
        "normalization"
      ],
      "id": 4
    },
    {
      "name": "bluima",
      "one_line_profile": "Natural Language Processing toolkit tailored for neuroscience",
      "detailed_description": "An NLP toolkit developed by the Blue Brain Project, specifically designed for extracting information from neuroscience literature, including entity recognition for brain regions and proteins.",
      "domains": [
        "Digital Health",
        "Neuroscience"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "information_extraction"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/BlueBrain/bluima",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "neuroscience",
        "nlp",
        "uima",
        "text-mining"
      ],
      "id": 5
    },
    {
      "name": "NERO-nlp",
      "one_line_profile": "Biomedical Named Entity Recognition and Ontology package",
      "detailed_description": "A Python package for biomedical Named Entity Recognition (NER) and ontology mapping, designed to facilitate the extraction of biomedical entities from text.",
      "domains": [
        "Digital Health",
        "H2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "ontology_mapping"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Bohdan-Khomtchouk/NERO-nlp",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ner",
        "biomedical",
        "ontology",
        "nlp"
      ],
      "id": 6
    },
    {
      "name": "astred",
      "one_line_profile": "Library for linguistic sentence comparison and word alignment",
      "detailed_description": "A library for linguistically comparing sentences, useful for analyzing translation quality, measuring syntactic distance, and word alignment in computational linguistics.",
      "domains": [
        "NLP",
        "Linguistics"
      ],
      "subtask_category": [
        "alignment",
        "comparison",
        "syntax_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BramVanroy/astred",
      "help_website": [
        "https://astred.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "linguistics",
        "alignment",
        "syntax",
        "translation"
      ],
      "id": 7
    },
    {
      "name": "spacy_conll",
      "one_line_profile": "SpaCy pipeline component for CoNLL-U formatting",
      "detailed_description": "A pipeline component for spaCy that adds CoNLL-U properties to documents, enabling interoperability with tools requiring CoNLL format for linguistic annotations.",
      "domains": [
        "NLP"
      ],
      "subtask_category": [
        "data_formatting",
        "annotation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BramVanroy/spacy_conll",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "spacy",
        "conll-u",
        "nlp",
        "pipeline"
      ],
      "id": 8
    },
    {
      "name": "Opioid_SUD_MHI_MedCodes",
      "one_line_profile": "ICD-10-CM code definitions for opioid and substance use disorders",
      "detailed_description": "A library of code definitions and logic to flag ICD-10-CM codes related to opioid involvement, substance use disorder, and mental health issues in structured hospital data, developed by the CDC.",
      "domains": [
        "Digital Health",
        "Public Health"
      ],
      "subtask_category": [
        "phenotyping",
        "classification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CDCgov/Opioid_SUD_MHI_MedCodes",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "icd-10",
        "opioid",
        "phenotyping",
        "cdc"
      ],
      "id": 9
    },
    {
      "name": "MedCAT",
      "one_line_profile": "Medical Concept Annotation Tool for EHR data",
      "detailed_description": "A highly efficient tool for extracting, linking, and normalizing medical concepts from Electronic Health Records (EHR) to knowledge bases like SNOMED-CT or UMLS, supporting unsupervised training.",
      "domains": [
        "Digital Health",
        "H2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "entity_linking",
        "normalization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CogStack/MedCAT",
      "help_website": [
        "https://medcat.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ehr",
        "nlp",
        "snomed-ct",
        "umls",
        "entity-linking"
      ],
      "id": 10
    },
    {
      "name": "MedCATtrainer",
      "one_line_profile": "Interface for inspecting and improving MedCAT models",
      "detailed_description": "A web-based interface designed to inspect, improve, and add concepts to biomedical Named Entity Recognition and Linking models, specifically tailored for the MedCAT ecosystem.",
      "domains": [
        "Digital Health",
        "H2-01"
      ],
      "subtask_category": [
        "annotation",
        "model_training",
        "active_learning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/CogStack/MedCATtrainer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "annotation",
        "medcat",
        "ner",
        "active-learning"
      ],
      "id": 11
    },
    {
      "name": "MetaMaps",
      "one_line_profile": "Tool for long-read metagenomic analysis",
      "detailed_description": "A tool for mapping long-read sequencing data (e.g., Nanopore) to reference databases for metagenomic analysis, enabling strain-level identification.",
      "domains": [
        "Bioinformatics",
        "Metagenomics"
      ],
      "subtask_category": [
        "sequence_mapping",
        "taxonomic_classification"
      ],
      "application_level": "solver",
      "primary_language": "Perl",
      "repo_url": "https://github.com/DiltheyLab/MetaMaps",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "metagenomics",
        "long-read",
        "nanopore",
        "mapping"
      ],
      "id": 12
    },
    {
      "name": "clinicalBERT",
      "one_line_profile": "Pre-trained BERT embeddings for clinical text",
      "detailed_description": "A repository providing publicly available BERT embeddings trained on clinical notes (MIMIC-III), serving as a foundational resource/model for clinical NLP tasks.",
      "domains": [
        "Digital Health",
        "H2-01"
      ],
      "subtask_category": [
        "representation_learning",
        "embedding"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/EmilyAlsentzer/clinicalBERT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bert",
        "embeddings",
        "clinical-nlp",
        "mimic-iii"
      ],
      "id": 13
    },
    {
      "name": "QuickUMLS",
      "one_line_profile": "Fast medical concept extraction and linking system",
      "detailed_description": "A fast, approximate dictionary matching system for medical concept extraction and linking to the UMLS, designed for efficiency in processing large clinical text corpora.",
      "domains": [
        "Digital Health",
        "H2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "entity_linking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Georgetown-IR-Lab/QuickUMLS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "umls",
        "ner",
        "entity-linking",
        "clinical-nlp"
      ],
      "id": 14
    },
    {
      "name": "BioBERTpt",
      "one_line_profile": "Biomedical and Clinical BERT models for the Portuguese language",
      "detailed_description": "A pre-trained language model based on BERT, specifically adapted for biomedical and clinical text in Portuguese, enabling named entity recognition and relation extraction tasks in this language domain.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "language_modeling",
        "named_entity_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/HAILab-PUCPR/BioBERTpt",
      "help_website": [],
      "license": null,
      "tags": [
        "bert",
        "nlp",
        "biomedical",
        "portuguese"
      ],
      "id": 15
    },
    {
      "name": "SNOMEDCT-ICD11-mapping",
      "one_line_profile": "Tools for generating SNOMED CT to ICD-11 mappings",
      "detailed_description": "Official coding approaches and utilities from IHTSDO for generating and managing maps between SNOMED CT concepts and ICD-11 classification codes.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "ontology_mapping",
        "normalization"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/IHTSDO/SNOMEDCT-ICD11-mapping",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "snomed-ct",
        "icd-11",
        "mapping",
        "interoperability"
      ],
      "id": 16
    },
    {
      "name": "AGATHA",
      "one_line_profile": "Deep learning system for hypothesis generation from biomedical graphs",
      "detailed_description": "Automatic Graph-mining And Transformer based Hypothesis generation Approach (AGATHA) is a tool that predicts potential connections in biomedical knowledge graphs to generate scientific hypotheses.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "hypothesis_generation",
        "knowledge_graph_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JSybrandt/agatha",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "graph-mining",
        "transformer",
        "hypothesis-generation",
        "biomedical"
      ],
      "id": 17
    },
    {
      "name": "Spark NLP",
      "one_line_profile": "State-of-the-art Natural Language Processing library for Spark",
      "detailed_description": "A comprehensive NLP library built on Apache Spark, widely used in healthcare for tasks such as clinical entity recognition, assertion status detection, and de-identification.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "relation_extraction",
        "deidentification"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/JohnSnowLabs/spark-nlp",
      "help_website": [
        "https://sparknlp.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "spark",
        "clinical-nlp",
        "ner"
      ],
      "id": 18
    },
    {
      "name": "Spark NLP Display",
      "one_line_profile": "Visualization library for Spark NLP annotations",
      "detailed_description": "A specialized visualization tool designed to display annotations generated by Spark NLP pipelines, such as dependency trees, NER entities, and assertion status in Jupyter notebooks.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "visualization",
        "annotation_viewing"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/JohnSnowLabs/spark-nlp-display",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "nlp",
        "spark-nlp"
      ],
      "id": 19
    },
    {
      "name": "CTakesParser.jl",
      "one_line_profile": "Julia parser for cTAKES clinical text analysis output",
      "detailed_description": "A Julia package designed to parse and process the XMI/XML output generated by the Apache cTAKES clinical text analysis system, facilitating downstream data analysis.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "data_parsing",
        "text_processing"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaHealth/CTakesParser.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "julia",
        "ctakes",
        "clinical-nlp",
        "parsing"
      ],
      "id": 20
    },
    {
      "name": "ICD_GEMs.jl",
      "one_line_profile": "ICD-9 to ICD-10 mapping tool using GEMs",
      "detailed_description": "A Julia package that enables translation between ICD-9 and ICD-10 medical codes using the General Equivalence Mappings (GEMs) standards.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "code_mapping",
        "normalization"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaHealth/ICD_GEMs.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "icd",
        "mapping",
        "julia",
        "gems"
      ],
      "id": 21
    },
    {
      "name": "deplacy",
      "one_line_profile": "CUI-based visualizer for NLP dependency trees",
      "detailed_description": "A tool for visualizing Universal Dependencies trees and Catena analysis in the terminal or notebooks, useful for inspecting linguistic structures in NLP tasks.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "visualization",
        "dependency_parsing"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/KoichiYasuoka/deplacy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "visualization",
        "dependency-parsing"
      ],
      "id": 22
    },
    {
      "name": "MetaMap",
      "one_line_profile": "Source code for NLM MetaMap Named Entity Recognizer",
      "detailed_description": "The source code (Prolog/C) for the National Library of Medicine's MetaMap system, which maps biomedical text to concepts in the UMLS Metathesaurus.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "concept_normalization"
      ],
      "application_level": "solver",
      "primary_language": "Prolog",
      "repo_url": "https://github.com/LHNCBC/MetaMap-src",
      "help_website": [
        "https://metamap.nlm.nih.gov/"
      ],
      "license": null,
      "tags": [
        "nlp",
        "umls",
        "metamap",
        "biomedical"
      ],
      "id": 23
    },
    {
      "name": "fda-ars",
      "one_line_profile": "Tools for processing FDA Structured Product Labels",
      "detailed_description": "A set of tools from the NLM for processing text within FDA Structured Product Labels (SPL) and handling adverse reaction data.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "text_processing",
        "regulatory_data_analysis"
      ],
      "application_level": "solver",
      "primary_language": "XSLT",
      "repo_url": "https://github.com/LHNCBC/fda-ars",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "fda",
        "spl",
        "text-processing",
        "nlm"
      ],
      "id": 24
    },
    {
      "name": "MetaMapLite",
      "one_line_profile": "Near real-time biomedical named-entity recognizer",
      "detailed_description": "A lightweight, high-speed version of MetaMap developed by NLM for real-time named entity recognition and UMLS concept mapping in biomedical text.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "concept_normalization"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/LHNCBC/metamaplite",
      "help_website": [
        "https://metamap.nlm.nih.gov/MetaMapLite.shtml"
      ],
      "license": "NOASSERTION",
      "tags": [
        "nlp",
        "ner",
        "umls",
        "fast"
      ],
      "id": 25
    },
    {
      "name": "PLM-ICD",
      "one_line_profile": "Automatic ICD coding tool using pretrained language models",
      "detailed_description": "A framework for automatic ICD coding from clinical text using pretrained language models (PLMs) with label-aware attention mechanisms.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "icd_coding",
        "classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MiuLab/PLM-ICD",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "icd-coding",
        "nlp",
        "clinical-text",
        "transformers"
      ],
      "id": 26
    },
    {
      "name": "ICD-9 to ICD-10 Conversion Function",
      "one_line_profile": "R function for converting ICD-9 codes to ICD-10",
      "detailed_description": "A development repository for functions incorporated into the R 'icd' package to convert International Classification of Diseases codes from Ninth to Tenth revisions.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "normalization",
        "coding_conversion"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/NCBI-Hackathons/Design-of-ICD-9-to-10-conversion-function-for-the-R-package-icd",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "icd-9",
        "icd-10",
        "conversion",
        "r-package"
      ],
      "id": 27
    },
    {
      "name": "medaCy",
      "one_line_profile": "Medical text mining and information extraction framework",
      "detailed_description": "A medical text mining and information extraction library built on top of spaCy, designed for clinical NLP tasks.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "ner",
        "information_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NLPatVCU/medaCy",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "clinical-nlp",
        "spacy",
        "ner",
        "text-mining"
      ],
      "id": 28
    },
    {
      "name": "UMLS-KG",
      "one_line_profile": "Knowledge graph builder from UMLS sources",
      "detailed_description": "A tool to build a knowledge graph from UMLS Knowledge Sources, enabling loading, visualization, and querying with Neo4j and Scispacy.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "visualization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Nguyendat-bit/UMLS-KG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "umls",
        "knowledge-graph",
        "neo4j",
        "scispacy"
      ],
      "id": 29
    },
    {
      "name": "biobert_embedding",
      "one_line_profile": "BioBERT embedding generator",
      "detailed_description": "A library to generate token and sentence level embeddings from the BioBERT model for biomedical text analysis.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "embedding_generation",
        "nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Overfitter/biobert_embedding",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "biobert",
        "embeddings",
        "biomedical-nlp"
      ],
      "id": 30
    },
    {
      "name": "node-MetaMap",
      "one_line_profile": "Node.js wrapper for MetaMap API",
      "detailed_description": "A package providing access to the MetaMap Web API for UMLS concept mapping from Node.js applications.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "concept_mapping",
        "api_wrapper"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/Planeshifter/node-MetaMap",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "metamap",
        "umls",
        "api-wrapper"
      ],
      "id": 31
    },
    {
      "name": "relna",
      "one_line_profile": "Biomedical relation extraction tool",
      "detailed_description": "A tool for biomedical relation extraction focusing on Transcription Factors and Gene/Gene Products.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "nlp"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/Rostlab/relna",
      "help_website": [],
      "license": null,
      "tags": [
        "relation-extraction",
        "biomedical-text",
        "gene-regulation"
      ],
      "id": 32
    },
    {
      "name": "medical-ner",
      "one_line_profile": "Clinical Named Entity Recognition with UMLS",
      "detailed_description": "A clinical Named Entity Recognition (NER) tool integrated with UMLS lookup for entity normalization.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "ner",
        "normalization"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/RyanDsilva/medical-ner",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "ner",
        "umls",
        "clinical-text"
      ],
      "id": 33
    },
    {
      "name": "CORD-19-ANN",
      "one_line_profile": "Semantic search for CORD-19 dataset",
      "detailed_description": "An Approximate Nearest Neighbor (ANN) search tool for the COVID-19 Open Research Dataset (CORD-19) using SBERT embeddings.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "literature_search",
        "semantic_search"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/SeanNaren/CORD-19-ANN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cord-19",
        "covid-19",
        "search",
        "sbert"
      ],
      "id": 34
    },
    {
      "name": "simple_icd_10",
      "one_line_profile": "Python library for ICD-10 codes",
      "detailed_description": "A simple Python library for validating, formatting, and querying ICD-10 codes.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "coding_validation",
        "normalization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/StefanoTrv/simple_icd_10",
      "help_website": [],
      "license": "CC0-1.0",
      "tags": [
        "icd-10",
        "medical-coding",
        "python-library"
      ],
      "id": 35
    },
    {
      "name": "simple_icd_10_CM",
      "one_line_profile": "Python library for ICD-10-CM codes",
      "detailed_description": "A simple Python library for validating, formatting, and querying ICD-10-CM (Clinical Modification) codes.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "coding_validation",
        "normalization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/StefanoTrv/simple_icd_10_CM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "icd-10-cm",
        "medical-coding",
        "python-library"
      ],
      "id": 36
    },
    {
      "name": "MetaMap-REST-API",
      "one_line_profile": "REST API wrapper for MetaMap",
      "detailed_description": "A REST API implementation for interacting with the MetaMap tool for biomedical text processing.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "concept_mapping",
        "api_wrapper"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/TelentiLab/MetaMap-REST-API",
      "help_website": [],
      "license": null,
      "tags": [
        "metamap",
        "rest-api",
        "biomedical-nlp"
      ],
      "id": 37
    },
    {
      "name": "ukb-ICD10-event-extraction",
      "one_line_profile": "ICD-10 extraction tools for UK Biobank",
      "detailed_description": "R functions for extracting diagnoses and first diagnosis dates from UK Biobank data fields based on ICD-10 codes.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "data_extraction",
        "phenotyping"
      ],
      "application_level": "library",
      "primary_language": null,
      "repo_url": "https://github.com/Trexgiantsalamanderdoublechickenturtle/ukb-ICD10-event-extraction",
      "help_website": [],
      "license": null,
      "tags": [
        "uk-biobank",
        "icd-10",
        "epidemiology",
        "r"
      ],
      "id": 38
    },
    {
      "name": "de.uke.iam.automapping",
      "one_line_profile": "Automatic mapping to SNOMED-CT",
      "detailed_description": "A tool for automatically mapping clinical terms into SNOMED-CT concepts.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "normalization",
        "mapping"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/UKEIAM/de.uke.iam.automapping",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "snomed-ct",
        "mapping",
        "clinical-terminology"
      ],
      "id": 39
    },
    {
      "name": "UMLS-EDA",
      "one_line_profile": "UMLS-based data augmentation for NLP",
      "detailed_description": "A light-weighted UMLS-based data augmentation tool for biomedical NLP tasks including Named Entity Recognition and sentence classification.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "data_augmentation",
        "nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/WengLab-InformaticsResearch/UMLS-EDA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-augmentation",
        "umls",
        "biomedical-nlp"
      ],
      "id": 40
    },
    {
      "name": "icd10",
      "one_line_profile": "Fast ICD-10 diagnosis code search library",
      "detailed_description": "A JavaScript library for fast searching and lookup of ICD-10 diagnosis codes.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "coding_lookup",
        "search"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/WhiteCoatAcademy/icd10",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "icd-10",
        "javascript",
        "medical-coding"
      ],
      "id": 41
    },
    {
      "name": "icdpicr",
      "one_line_profile": "Injury code classification in R",
      "detailed_description": "An R package for injury code classification and scoring based on ICD codes.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "classification",
        "scoring"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/ablack3/icdpicr",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "injury-coding",
        "icd",
        "r-package"
      ],
      "id": 42
    },
    {
      "name": "acq4",
      "one_line_profile": "Data acquisition platform for neurophysiology",
      "detailed_description": "A platform for data acquisition and device control in patch clamp electrophysiology, optogenetics, and imaging experiments.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "data_acquisition",
        "experiment_control"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/acq4/acq4",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "electrophysiology",
        "neuroscience",
        "data-acquisition"
      ],
      "id": 43
    },
    {
      "name": "metamap-snakemake",
      "one_line_profile": "Metagenomic mapping workflow",
      "detailed_description": "A Snakemake workflow to map and quantify microbial genomes in metagenomic reads (Note: distinct from NLM MetaMap).",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "metagenomics",
        "mapping"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/alexmsalmeida/metamap",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "metagenomics",
        "snakemake",
        "bioinformatics"
      ],
      "id": 44
    },
    {
      "name": "MetaMapR",
      "one_line_profile": "Network mapping and data integration tool for metabolomics and biochemical data",
      "detailed_description": "MetaMapR is a tool designed to integrate biochemical, structural, and spectral data for metabolomics analysis. It facilitates network mapping and visualization of metabolic pathways and connections.",
      "domains": [
        "H1",
        "H2"
      ],
      "subtask_category": [
        "network_analysis",
        "visualization",
        "data_integration"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/dgrapov/MetaMapR",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "metabolomics",
        "network-mapping",
        "visualization"
      ],
      "id": 45
    },
    {
      "name": "BERN",
      "one_line_profile": "Neural named entity recognition and multi-type normalization tool for biomedical text",
      "detailed_description": "BERN (Biomedical Entity Recognition and Normalization) is a tool for biomedical text mining that performs named entity recognition and normalization for various entity types including genes, diseases, and drugs.",
      "domains": [
        "H2-01"
      ],
      "subtask_category": [
        "ner",
        "normalization",
        "text_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dmis-lab/bern",
      "help_website": [
        "https://bern.korea.ac.kr/"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "biomedical-ner",
        "normalization",
        "nlp"
      ],
      "id": 46
    },
    {
      "name": "BioASQ-BioBERT",
      "one_line_profile": "Pre-trained BioBERT model fine-tuned for biomedical question answering",
      "detailed_description": "A biomedical question answering model based on BioBERT, pre-trained and fine-tuned on the BioASQ dataset to answer biomedical questions.",
      "domains": [
        "H2-01"
      ],
      "subtask_category": [
        "question_answering",
        "biomedical_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dmis-lab/bioasq-biobert",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "biobert",
        "qa",
        "bioasq"
      ],
      "id": 47
    },
    {
      "name": "BioBERT",
      "one_line_profile": "Pre-trained biomedical language representation model for biomedical text mining",
      "detailed_description": "BioBERT is a pre-trained language representation model for biomedical text mining. It is initialized with BERT and pre-trained on large-scale biomedical corpora (PubMed and PMC) to improve performance on biomedical NLP tasks.",
      "domains": [
        "H2-01"
      ],
      "subtask_category": [
        "language_model",
        "text_mining",
        "embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dmis-lab/biobert",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "bert",
        "biomedical-nlp",
        "pre-trained-model"
      ],
      "id": 48
    },
    {
      "name": "BioBERT-PyTorch",
      "one_line_profile": "PyTorch implementation of the BioBERT biomedical language model",
      "detailed_description": "A PyTorch implementation of BioBERT, facilitating the use of the pre-trained biomedical language model in PyTorch-based workflows for biomedical text mining.",
      "domains": [
        "H2-01"
      ],
      "subtask_category": [
        "language_model",
        "text_mining"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/dmis-lab/biobert-pytorch",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "pytorch",
        "biobert",
        "nlp"
      ],
      "id": 49
    },
    {
      "name": "Bio-LM",
      "one_line_profile": "Evaluation framework and pre-trained models for biomedical and clinical NLP tasks",
      "detailed_description": "A repository from Facebook Research that evaluates various models for biomedical and clinical NLP tasks and provides new pre-trained models optimized for these domains.",
      "domains": [
        "H2-01"
      ],
      "subtask_category": [
        "evaluation",
        "language_model",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/bio-lm",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "biomedical-nlp",
        "clinical-nlp",
        "evaluation"
      ],
      "id": 50
    },
    {
      "name": "HUNER",
      "one_line_profile": "Named Entity Recognition tool specifically designed for biomedical entities",
      "detailed_description": "HUNER is a Named Entity Recognition (NER) tool tailored for the biomedical domain, capable of identifying various biomedical entities in text.",
      "domains": [
        "H2-01"
      ],
      "subtask_category": [
        "ner",
        "biomedical_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hu-ner/huner",
      "help_website": [],
      "license": null,
      "tags": [
        "ner",
        "biomedical",
        "nlp"
      ],
      "id": 51
    },
    {
      "name": "icd-codex",
      "one_line_profile": "Python library for graphical and continuous representations of ICD9 and ICD10 codes",
      "detailed_description": "icd-codex is a Python library that provides tools for working with ICD-9 and ICD-10 medical codes, including generating graphical representations and continuous embeddings for healthcare data analysis.",
      "domains": [
        "H2-01"
      ],
      "subtask_category": [
        "coding",
        "normalization",
        "data_representation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/icd-codex/icd-codex",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "icd-codes",
        "medical-coding",
        "healthcare-data"
      ],
      "id": 52
    },
    {
      "name": "Kindred",
      "one_line_profile": "Python package for biomedical relation extraction using supervised learning",
      "detailed_description": "A Python package for biomedical relation extraction that uses a supervised approach. It simplifies the process of extracting relations from biomedical texts by providing a user-friendly interface for training and prediction.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jakelever/kindred",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "biomedical-nlp",
        "relation-extraction",
        "supervised-learning"
      ],
      "id": 53
    },
    {
      "name": "ICD-10-CSV",
      "one_line_profile": "Structured dataset of ICD-10 medical classification codes",
      "detailed_description": "A repository providing a comma-separated file of 2018 ICD-10 codes, facilitating the integration of standard medical coding into digital health applications and analysis pipelines.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "coding",
        "normalization"
      ],
      "application_level": "dataset",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/k4m1113/ICD-10-CSV",
      "help_website": [],
      "license": null,
      "tags": [
        "icd-10",
        "medical-coding",
        "dataset"
      ],
      "id": 54
    },
    {
      "name": "MedKnow",
      "one_line_profile": "Medical relations and entities extraction tool",
      "detailed_description": "A Python-based tool designed for extracting medical entities and relations from clinical text, supporting tasks such as named entity recognition and relation classification in the biomedical domain.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "relation_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kbogas/medknow",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-nlp",
        "ner",
        "relation-extraction"
      ],
      "id": 55
    },
    {
      "name": "clinspacy",
      "one_line_profile": "Clinical Natural Language Processing pipeline for R",
      "detailed_description": "An R package that performs clinical natural language processing using spaCy, scispacy, and medspacy. It enables R users to perform biomedical named entity recognition, UMLS mapping, and negation detection.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "normalization",
        "coding"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/kdpsingh/clinspacy",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "r-package",
        "clinical-nlp",
        "spacy",
        "umls"
      ],
      "id": 56
    },
    {
      "name": "ClinicalBERT",
      "one_line_profile": "Pre-trained BERT models for clinical notes and hospital readmission prediction",
      "detailed_description": "A repository containing code and pre-trained models for ClinicalBERT, designed to model clinical notes and predict hospital readmission. It adapts the BERT architecture to the clinical domain.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "embedding",
        "inference"
      ],
      "application_level": "model",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/kexinhuang12345/clinicalBERT",
      "help_website": [],
      "license": null,
      "tags": [
        "clinical-bert",
        "nlp",
        "readmission-prediction"
      ],
      "id": 57
    },
    {
      "name": "Clinical-NER",
      "one_line_profile": "Named Entity Recognition for Chinese Electronic Medical Records",
      "detailed_description": "A tool specifically designed for Named Entity Recognition (NER) in Chinese clinical texts and electronic medical records (EMR), utilizing deep learning techniques.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "named_entity_recognition"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/kyzhouhzau/Clinical-NER",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "chinese-nlp",
        "clinical-ner",
        "emr"
      ],
      "id": 58
    },
    {
      "name": "Bio-Relex",
      "one_line_profile": "Joint Biomedical Entity and Relation Extraction framework",
      "detailed_description": "A system for joint biomedical entity and relation extraction that employs knowledge-enhanced collective inference to improve performance on biomedical literature.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "named_entity_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/laituan245/bio_relex",
      "help_website": [],
      "license": null,
      "tags": [
        "biomedical-nlp",
        "relation-extraction",
        "deep-learning"
      ],
      "id": 59
    },
    {
      "name": "BiOnt",
      "one_line_profile": "Deep Learning for Relation Extraction using Biomedical Ontologies",
      "detailed_description": "BiOnt leverages multiple biomedical ontologies within a deep learning framework to enhance relation extraction from biomedical texts.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "normalization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lasigeBioTM/BiOnt",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ontology",
        "relation-extraction",
        "biomedical-nlp"
      ],
      "id": 60
    },
    {
      "name": "bio-ner",
      "one_line_profile": "Biomedical Named Entity Recognition and Normalization library",
      "detailed_description": "A library for Biomedical Named Entity Recognition and Normalization, focusing on diseases, chemicals, and genetic entities using state-of-the-art models.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "normalization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/librairy/bio-ner",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ner",
        "normalization",
        "biomedical-nlp"
      ],
      "id": 61
    },
    {
      "name": "icd",
      "one_line_profile": "Python library for working with ICD codes and comorbidities analysis",
      "detailed_description": "A Python library designed to handle International Classification of Diseases (ICD) codes, enabling validation, formatting, and analysis of comorbidities in medical datasets.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "coding",
        "normalization",
        "clinical_data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mark-hoffmann/icd",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "icd-codes",
        "medical-coding",
        "comorbidities"
      ],
      "id": 62
    },
    {
      "name": "medspaCy",
      "one_line_profile": "Clinical NLP library using spaCy for information extraction from medical text",
      "detailed_description": "A library for clinical natural language processing implemented with spaCy, offering tools for concept extraction, negation detection (ConText), and section detection in clinical notes.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "extraction",
        "clinical_nlp"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/medspacy/medspacy",
      "help_website": [
        "https://github.com/medspacy/medspacy"
      ],
      "license": "MIT",
      "tags": [
        "clinical-nlp",
        "spacy",
        "context",
        "extraction"
      ],
      "id": 63
    },
    {
      "name": "CLAMP-DrugDiscovery",
      "one_line_profile": "Contrastive Language-Assisted Molecule Pre-training for drug discovery",
      "detailed_description": "A framework enhancing activity prediction models in drug discovery by integrating the ability to understand human language, facilitating the alignment of chemical and linguistic representations.",
      "domains": [
        "H2",
        "Bioinformatics"
      ],
      "subtask_category": [
        "drug_discovery",
        "property_prediction",
        "molecular_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ml-jku/clamp",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "drug-discovery",
        "nlp",
        "molecular-activity"
      ],
      "id": 64
    },
    {
      "name": "BioMedICUS",
      "one_line_profile": "Biomedical and clinical NLP engine for information extraction",
      "detailed_description": "A biomedical and clinical natural language processing engine developed by the University of Minnesota, providing a pipeline for processing clinical text and extracting biomedical entities.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "extraction",
        "clinical_nlp",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Java",
      "repo_url": "https://github.com/nlpie/biomedicus",
      "help_website": [
        "http://nlpie.umn.edu/biomedicus/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "clinical-nlp",
        "uima",
        "information-extraction"
      ],
      "id": 65
    },
    {
      "name": "blabla",
      "one_line_profile": "Linguistic feature extraction library for clinical analysis",
      "detailed_description": "A library for extracting linguistic features from text, often used in clinical settings for analyzing speech patterns related to neurological or psychiatric conditions.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "feature_extraction",
        "linguistic_analysis",
        "clinical_assessment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/novoic/blabla",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "linguistics",
        "feature-extraction",
        "clinical-text"
      ],
      "id": 66
    },
    {
      "name": "BRAN",
      "one_line_profile": "Bi-affine Relation Attention Networks for biomedical relation extraction",
      "detailed_description": "Implementation of Bi-affine Relation Attention Networks (BRAN) for extracting relations between entities in biological texts, supporting full abstract processing.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "biomedical_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/patverga/bran",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "relation-extraction",
        "deep-learning",
        "biomedical-text"
      ],
      "id": 67
    },
    {
      "name": "GENIA Tagger",
      "one_line_profile": "C++ implementation of the GENIA tagger for biomedical text analysis",
      "detailed_description": "A tool for part-of-speech tagging, shallow parsing, and named entity recognition specifically tuned for biomedical text, derived from the GENIA corpus.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "pos_tagging"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/saffsd/geniatagger",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "nlp",
        "biomedical",
        "ner",
        "pos-tagging"
      ],
      "id": 68
    },
    {
      "name": "icd9",
      "one_line_profile": "Python library for managing and validating ICD-9 codes",
      "detailed_description": "A library for working with ICD-9 codes, providing functionality to traverse the code hierarchy, validate codes, and manage medical classification data.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "normalization",
        "coding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sirrice/icd9",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "icd9",
        "medical-coding",
        "healthcare",
        "informatics"
      ],
      "id": 69
    },
    {
      "name": "ICD-Mappings",
      "one_line_profile": "Tool for mapping ICD codes to clinical risk adjustment models",
      "detailed_description": "A Python tool that enables mapping of ICD-9 and ICD-10 codes to various medical concepts and risk scores such as CCS, CCI, and Elixhauser comorbidities.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "normalization",
        "coding",
        "risk_stratification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/snovaisg/ICD-Mappings",
      "help_website": [],
      "license": null,
      "tags": [
        "icd10",
        "icd9",
        "comorbidities",
        "clinical-informatics"
      ],
      "id": 70
    },
    {
      "name": "Stanza",
      "one_line_profile": "Python NLP library with state-of-the-art biomedical models",
      "detailed_description": "A Python natural language analysis package that includes a biomedical module with models trained on biomedical literature and clinical text for tasks like tokenization, NER, and parsing.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "tokenization",
        "parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanfordnlp/stanza",
      "help_website": [
        "https://stanfordnlp.github.io/stanza/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "biomedical",
        "clinical-nlp",
        "ner"
      ],
      "id": 71
    },
    {
      "name": "MedType",
      "one_line_profile": "Medical entity linking tool with semantic type prediction",
      "detailed_description": "A tool for improving medical entity linking by incorporating semantic type prediction, useful for normalizing medical entities in clinical text.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "entity_linking",
        "normalization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/svjan5/medtype",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "entity-linking",
        "medical-nlp",
        "normalization"
      ],
      "id": 72
    },
    {
      "name": "SWHLab",
      "one_line_profile": "Analysis tools for whole-cell patch-clamp electrophysiological data",
      "detailed_description": "A Python library designed for the analysis of ABF files and other data formats from whole-cell patch-clamp electrophysiology experiments.",
      "domains": [
        "Neuroscience",
        "Physiology"
      ],
      "subtask_category": [
        "data_analysis",
        "signal_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/swharden/SWHLab",
      "help_website": [
        "https://swharden.com/software/swhlab/"
      ],
      "license": "MIT",
      "tags": [
        "electrophysiology",
        "patch-clamp",
        "abf-files"
      ],
      "id": 73
    },
    {
      "name": "Annotated Twitter COVID-19 Dataset",
      "one_line_profile": "Biomedically oriented annotated Twitter COVID-19 dataset",
      "detailed_description": "A dataset of tweets related to COVID-19, automatically annotated for biomedical entities and events, useful for public health surveillance and NLP research.",
      "domains": [
        "H2",
        "Public Health"
      ],
      "subtask_category": [
        "dataset"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/thepanacealab/annotated_twitter_covid19_dataset",
      "help_website": [],
      "license": null,
      "tags": [
        "covid-19",
        "twitter",
        "dataset",
        "nlp"
      ],
      "id": 74
    },
    {
      "name": "PyCTakesParser",
      "one_line_profile": "Utilities to parse Apache cTAKES output",
      "detailed_description": "A Python utility library for parsing and processing the XMI output generated by the Apache cTAKES clinical NLP system.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "data_processing",
        "parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/titu1994/PyCTakesParser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ctakes",
        "clinical-nlp",
        "parser"
      ],
      "id": 75
    },
    {
      "name": "ctakes-ade",
      "one_line_profile": "cTAKES module for extracting drug adverse events",
      "detailed_description": "A module for the Apache cTAKES clinical NLP system specifically designed to extract mentions of adverse drug events from clinical text.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "adverse_event_detection"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/tmills/ctakes-ade",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ctakes",
        "adverse-events",
        "clinical-nlp"
      ],
      "id": 76
    },
    {
      "name": "ClinicalTransformerNER",
      "one_line_profile": "Library for clinical named entity recognition",
      "detailed_description": "A comprehensive library for training and deploying Transformer-based models for Named Entity Recognition (NER) in clinical text.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "ner",
        "information_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/uf-hobi-informatics-lab/ClinicalTransformerNER",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "clinical-ner",
        "transformers",
        "nlp"
      ],
      "id": 77
    },
    {
      "name": "dutch-medical-concepts",
      "one_line_profile": "Tool to create Dutch medical concept tables for NER",
      "detailed_description": "Code and instructions to generate tables of UMLS, SNOMED, or HPO concepts with Dutch names, enabling NER and entity linking in Dutch clinical text.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "resource_generation",
        "normalization"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/umcu/dutch-medical-concepts",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "snomed",
        "umls",
        "dutch",
        "ner"
      ],
      "id": 78
    },
    {
      "name": "spark-nkp",
      "one_line_profile": "Natural Korean Processor for Apache Spark",
      "detailed_description": "A library for processing Korean natural language text within the Apache Spark framework, suitable for large-scale NLP tasks.",
      "domains": [
        "NLP"
      ],
      "subtask_category": [
        "text_processing"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/uosdmlab/spark-nkp",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "spark",
        "korean-nlp",
        "nlp"
      ],
      "id": 79
    },
    {
      "name": "ClaMP",
      "one_line_profile": "Malware classifier dataset from PE headers",
      "detailed_description": "A dataset for malware classification built from header fields of Portable Executable (PE) files, used for cybersecurity research.",
      "domains": [
        "Cybersecurity"
      ],
      "subtask_category": [
        "dataset"
      ],
      "application_level": "dataset",
      "primary_language": "YARA",
      "repo_url": "https://github.com/urwithajit9/ClaMP",
      "help_website": [],
      "license": null,
      "tags": [
        "malware",
        "dataset",
        "security"
      ],
      "id": 80
    },
    {
      "name": "codelists",
      "one_line_profile": "Generator for medical code lists (SNOMED, ICD-10, ATC)",
      "detailed_description": "A tool to generate code lists for clinical research using combinations of SNOMED ECL, ICD-10, and ATC codes.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "data_standardization",
        "cohort_definition"
      ],
      "application_level": "library",
      "primary_language": "Clojure",
      "repo_url": "https://github.com/wardle/codelists",
      "help_website": [],
      "license": "EPL-2.0",
      "tags": [
        "snomed",
        "icd-10",
        "medical-coding"
      ],
      "id": 81
    },
    {
      "name": "EHRAgent",
      "one_line_profile": "LLM agent framework for tabular reasoning on EHR",
      "detailed_description": "A framework enabling Large Language Models to perform complex tabular reasoning on Electronic Health Records (EHR) through code generation.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "reasoning",
        "data_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wshi83/EhrAgent",
      "help_website": [],
      "license": null,
      "tags": [
        "ehr",
        "llm",
        "agent",
        "clinical-reasoning"
      ],
      "id": 82
    },
    {
      "name": "icdcoder",
      "one_line_profile": "R package for ICD-9 and ICD-10 code utilities",
      "detailed_description": "An R package providing utility functions and datasets for working with ICD-9 and ICD-10 medical billing codes.",
      "domains": [
        "H2",
        "H2-01"
      ],
      "subtask_category": [
        "normalization",
        "coding"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/wtcooper/icdcoder",
      "help_website": [],
      "license": null,
      "tags": [
        "icd-9",
        "icd-10",
        "r-package"
      ],
      "id": 83
    },
    {
      "name": "TidyStanza.jl",
      "one_line_profile": "Tidyverse-like data manipulation for Julia",
      "detailed_description": "A Julia library attempting to implement Tidyverse-style APIs for data manipulation, facilitating scientific data analysis in Julia.",
      "domains": [
        "Data Science"
      ],
      "subtask_category": [
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/xiaodaigh/TidyStanza.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "tidyverse",
        "data-analysis"
      ],
      "id": 84
    },
    {
      "name": "HBAM (HHH)",
      "one_line_profile": "Hierarchical Bi-directional Word Attention Model for medical question answering",
      "detailed_description": "An implementation of the Hierarchical Bi-directional Word Attention Model (HBAM) designed for online medical question answering systems. It serves as a solver for processing medical queries and retrieving relevant answers.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_qa",
        "natural_language_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/14H034160212/HHH-An-Online-Question-Answering-System-for-Medical-Questions",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-qa",
        "attention-model",
        "nlp"
      ],
      "id": 85
    },
    {
      "name": "MedResearcher-R1",
      "one_line_profile": "Deep research agent for medical scenarios with knowledge-informed trajectory synthesis",
      "detailed_description": "A deep research agent designed for medical scenarios that utilizes a knowledge-informed trajectory synthesis framework to conduct comprehensive medical research and reasoning tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_research_agent",
        "clinical_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AQ-MedAI/MedResearcher-R1",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent",
        "medical-research",
        "llm"
      ],
      "id": 86
    },
    {
      "name": "Med-VQA",
      "one_line_profile": "Medical Visual Question Answering via Conditional Reasoning",
      "detailed_description": "A PyTorch implementation of a Medical Visual Question Answering (VQA) model that utilizes conditional reasoning to answer questions based on medical images.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "visual_question_answering",
        "medical_imaging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Awenbocc/med-vqa",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vqa",
        "medical-imaging",
        "deep-learning"
      ],
      "id": 87
    },
    {
      "name": "Me-LLaMA",
      "one_line_profile": "Medical Large Language Model family (13/70B)",
      "detailed_description": "A family of medical large language models (13B and 70B parameters) fine-tuned for various medical tasks, providing state-of-the-art performance in medical reasoning and question answering.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_llm",
        "clinical_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/BIDS-Xu-Lab/Me-LLaMA",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "medical-nlp",
        "fine-tuning"
      ],
      "id": 88
    },
    {
      "name": "QiZhenGPT",
      "one_line_profile": "Open Source Chinese Medical Large Language Model",
      "detailed_description": "An open-source Chinese medical Large Language Model designed to assist in medical dialogue, diagnosis support, and health consultation.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_llm",
        "medical_dialogue"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CMKRG/QiZhenGPT",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "chinese-medical-llm",
        "nlp",
        "healthcare"
      ],
      "id": 89
    },
    {
      "name": "OpenGPT",
      "one_line_profile": "Framework for training conversational domain expert LLMs",
      "detailed_description": "A framework for creating grounded instruction-based datasets and training conversational domain expert Large Language Models (LLMs), specifically tailored for healthcare applications.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "llm_training",
        "dataset_generation"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/CogStack/OpenGPT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "instruction-tuning",
        "healthcare"
      ],
      "id": 90
    },
    {
      "name": "AMEGA-benchmark",
      "one_line_profile": "Autonomous Medical Evaluation for Guideline Adherence of LLMs",
      "detailed_description": "A benchmarking tool for evaluating the adherence of Large Language Models to medical guidelines, providing an autonomous evaluation framework for medical AI systems.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "guideline_adherence"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DATEXIS/AMEGA-benchmark",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "evaluation",
        "medical-guidelines"
      ],
      "id": 91
    },
    {
      "name": "Taiyi-LLM",
      "one_line_profile": "Bilingual (Chinese and English) Biomedical Large Language Model",
      "detailed_description": "Taiyi is a bilingual (Chinese and English) Large Language Model fine-tuned for diverse biomedical tasks, including information extraction and question answering in the medical domain.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_llm",
        "biomedical_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DUTIR-BioNLP/Taiyi-LLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "biomedical-llm",
        "bilingual",
        "nlp"
      ],
      "id": 92
    },
    {
      "name": "Medical_Image_Analysis",
      "one_line_profile": "Foundation models based medical image analysis toolkit",
      "detailed_description": "A collection of foundation model implementations and tools for medical image analysis, facilitating research in medical computer vision.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_image_analysis",
        "computer_vision"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Event-AHU/Medical_Image_Analysis",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "medical-imaging",
        "foundation-models",
        "deep-learning"
      ],
      "id": 93
    },
    {
      "name": "Medical-Image-Segmentation-Benchmarks",
      "one_line_profile": "PyTorch implementation of medical image segmentation benchmarks",
      "detailed_description": "A PyTorch library providing implementations of various U-shape architectures and benchmarks for medical image segmentation tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "image_segmentation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/FengheTan9/Medical-Image-Segmentation-Benchmarks",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "segmentation",
        "pytorch",
        "u-net"
      ],
      "id": 94
    },
    {
      "name": "Apollo",
      "one_line_profile": "Multilingual Medical LLM ecosystem (Model, Dataset, Benchmark)",
      "detailed_description": "A comprehensive project for multilingual medical LLMs, including model weights, training code, datasets, and benchmarks for evaluating medical language understanding across languages.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_llm",
        "multilingual_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FreedomIntelligence/Apollo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multilingual",
        "medical-llm",
        "benchmark"
      ],
      "id": 95
    },
    {
      "name": "ApolloMoE",
      "one_line_profile": "Mixture of Experts (MoE) Medical LLM for 50 languages",
      "detailed_description": "An efficient medical Large Language Model utilizing Mixture of Experts (MoE) architecture to support 50 languages, democratizing access to medical AI.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_llm",
        "moe_architecture"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FreedomIntelligence/ApolloMoE",
      "help_website": [],
      "license": null,
      "tags": [
        "moe",
        "medical-llm",
        "multilingual"
      ],
      "id": 96
    },
    {
      "name": "CMB",
      "one_line_profile": "Comprehensive Medical Benchmark in Chinese",
      "detailed_description": "A comprehensive benchmark suite for evaluating Chinese medical Large Language Models, including datasets and evaluation scripts for various medical competency tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmark"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FreedomIntelligence/CMB",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "chinese-medical",
        "evaluation"
      ],
      "id": 97
    },
    {
      "name": "Chain-of-Diagnosis",
      "one_line_profile": "Interpretable LLM framework for medical diagnosis",
      "detailed_description": "An interpretable Large Language Model framework designed to perform medical diagnosis through a chain-of-thought process, enhancing transparency in clinical decision support.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_diagnosis",
        "clinical_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FreedomIntelligence/Chain-of-Diagnosis",
      "help_website": [],
      "license": null,
      "tags": [
        "diagnosis",
        "interpretability",
        "llm"
      ],
      "id": 98
    },
    {
      "name": "HuatuoGPT",
      "one_line_profile": "Open Medical GPT for doctor-like consultation",
      "detailed_description": "An open-source medical Large Language Model trained to function as a doctor, providing medical consultation and answering health-related queries with high accuracy.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_llm",
        "medical_consultation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FreedomIntelligence/HuatuoGPT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-gpt",
        "consultation",
        "llm"
      ],
      "id": 99
    },
    {
      "name": "HuatuoGPT-II",
      "one_line_profile": "One-stage Training for Medical Adaption of LLMs",
      "detailed_description": "The second generation of HuatuoGPT, featuring a one-stage training approach for adapting Large Language Models to the medical domain.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_llm",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FreedomIntelligence/HuatuoGPT-II",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-llm",
        "training-strategy",
        "domain-adaptation"
      ],
      "id": 100
    },
    {
      "name": "HuatuoGPT-Vision",
      "one_line_profile": "Medical multimodal large language model for visual question answering and reasoning",
      "detailed_description": "A multimodal medical Large Language Model (LLM) designed to process and reason with both medical text and images, enabling tasks such as medical visual question answering (VQA) and report generation.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_vqa",
        "multimodal_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FreedomIntelligence/HuatuoGPT-Vision",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-llm",
        "multimodal",
        "vqa"
      ],
      "id": 101
    },
    {
      "name": "HuatuoGPT-o1",
      "one_line_profile": "Medical LLM optimized for complex clinical reasoning",
      "detailed_description": "A specialized medical Large Language Model focusing on complex reasoning capabilities in clinical scenarios, aiming to simulate doctor-like diagnostic logic.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "clinical_reasoning",
        "medical_diagnosis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FreedomIntelligence/HuatuoGPT-o1",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-llm",
        "reasoning",
        "clinical-decision-support"
      ],
      "id": 102
    },
    {
      "name": "DISC-MedLLM",
      "one_line_profile": "Conversational medical LLM solution for healthcare services",
      "detailed_description": "A comprehensive medical Large Language Model solution designed to provide accurate and truthful medical responses in end-to-end conversational healthcare settings, trained on high-quality medical datasets.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_dialogue",
        "health_consultation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FudanDISC/DISC-MedLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-llm",
        "chatbot",
        "healthcare"
      ],
      "id": 103
    },
    {
      "name": "ActiveSegmentation",
      "one_line_profile": "Simulation framework for active learning in medical image segmentation",
      "detailed_description": "A simulation framework designed to benchmark and evaluate active learning strategies specifically for 3D medical image segmentation tasks.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "image_segmentation",
        "active_learning",
        "simulation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HealthML/active-segmentation",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "medical-imaging",
        "active-learning",
        "segmentation"
      ],
      "id": 104
    },
    {
      "name": "MedMax",
      "one_line_profile": "Mixed-modal instruction tuning framework for biomedical assistants",
      "detailed_description": "A framework for mixed-modal instruction tuning aimed at training biomedical assistants, enabling models to handle diverse medical tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "instruction_tuning",
        "model_training"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Hritikbansal/medmax",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "instruction-tuning",
        "biomedical",
        "llm"
      ],
      "id": 105
    },
    {
      "name": "AIDoctor",
      "one_line_profile": "Training pipeline for medical GPT models including SFT and RLHF",
      "detailed_description": "A complete pipeline implementation for training medical GPT models, covering Pretraining, Supervised Fine-tuning (SFT), Reward Modeling, Reinforcement Learning (RLHF), and DPO.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "model_training",
        "rlhf",
        "fine_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Jerry-XDL/AIDoctor",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-training",
        "rlhf",
        "medical-gpt"
      ],
      "id": 106
    },
    {
      "name": "MCM",
      "one_line_profile": "Multimodal Chinese Medical Large Language Model",
      "detailed_description": "A multimodal Large Language Model specifically designed for Traditional Chinese Medicine (TCM) and general Chinese medical consultation.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_consultation",
        "tcm_diagnosis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JerryMazeyu/MCM",
      "help_website": [],
      "license": null,
      "tags": [
        "tcm",
        "medical-llm",
        "multimodal"
      ],
      "id": 107
    },
    {
      "name": "LLMAnonymizer",
      "one_line_profile": "Tool for anonymizing medical documents using LLMs",
      "detailed_description": "A utility leveraging Large Language Models to automatically anonymize and de-identify sensitive medical documents for privacy protection.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "de-identification",
        "data_privacy"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/KatherLab/LLMAnonymizer-Publication",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "anonymization",
        "privacy",
        "medical-records"
      ],
      "id": 108
    },
    {
      "name": "Medical_LLM",
      "one_line_profile": "Structured pipeline for LLM-based medical projects",
      "detailed_description": "A structured pipeline designed to facilitate the development and deployment of Large Language Model projects in the medical domain, provided by Kather Lab.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "pipeline_orchestration",
        "project_scaffolding"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/KatherLab/Medical_LLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pipeline",
        "medical-llm",
        "workflow"
      ],
      "id": 109
    },
    {
      "name": "FedFMS",
      "one_line_profile": "Federated learning framework for fine-tuning Segment Anything Model (SAM)",
      "detailed_description": "A framework enabling the fine-tuning of the Segment Anything Model (SAM) within a federated learning paradigm, specifically for medical image segmentation tasks.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "federated_learning",
        "image_segmentation",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/LIU-YUXI/FedFMS",
      "help_website": [],
      "license": null,
      "tags": [
        "federated-learning",
        "sam",
        "segmentation"
      ],
      "id": 110
    },
    {
      "name": "AI Hospital",
      "one_line_profile": "Interactive simulation environment for LLMs as clinical interns",
      "detailed_description": "A simulation platform that evaluates and enables collaboration among Large Language Models acting as intern doctors for clinical diagnosis in a virtual hospital setting.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "agent_simulation",
        "clinical_diagnosis",
        "evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/LibertFan/AI_Hospital",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "simulation",
        "medical-agent",
        "evaluation"
      ],
      "id": 111
    },
    {
      "name": "Medical-AGI",
      "one_line_profile": "Multi-agent platform for coordinating healthcare layers",
      "detailed_description": "An LLM-powered multi-agent platform designed to coordinate health information and services from global to individual levels.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "agent_coordination",
        "healthcare_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/LifestyleCorp/Medical-AGI",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "agi",
        "healthcare"
      ],
      "id": 112
    },
    {
      "name": "MedicalChatbot",
      "one_line_profile": "Dialogue system for disease identification",
      "detailed_description": "A medical-domain dialogue system designed to identify diseases through automated conversation and symptom analysis.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "disease_identification",
        "medical_dialogue"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LiuQL2/MedicalChatbot",
      "help_website": [],
      "license": null,
      "tags": [
        "chatbot",
        "diagnosis",
        "nlp"
      ],
      "id": 113
    },
    {
      "name": "Large-Scale-Medical",
      "one_line_profile": "Pre-training framework for 3D medical images with geometric priors",
      "detailed_description": "A framework for large-scale pre-training of 3D medical image models, incorporating geometric context priors to improve representation learning.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "model_pretraining",
        "image_representation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Luffy03/Large-Scale-Medical",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pre-training",
        "3d-imaging",
        "geometric-priors"
      ],
      "id": 114
    },
    {
      "name": "DiagGym",
      "one_line_profile": "Virtual clinical environment for training diagnostic agents",
      "detailed_description": "A virtual gym environment designed for training and evaluating self-evolving Large Language Model agents in clinical diagnostic tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "agent_training",
        "clinical_simulation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/MAGIC-AI4Med/DiagGym",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "reinforcement-learning",
        "medical-agent",
        "simulation"
      ],
      "id": 115
    },
    {
      "name": "MedMNIST",
      "one_line_profile": "Standardized datasets and tools for biomedical image classification",
      "detailed_description": "A large-scale collection of standardized biomedical image datasets for 2D and 3D classification, accompanied by a Python library for easy data loading and evaluation.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "image_classification",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/MedMNIST/MedMNIST",
      "help_website": [
        "https://medmnist.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dataset",
        "medical-imaging",
        "classification"
      ],
      "id": 116
    },
    {
      "name": "MING",
      "one_line_profile": "Chinese medical question answering large language model",
      "detailed_description": "A specialized Chinese medical Large Language Model (MING) designed for medical question answering and consultation tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_qa",
        "consultation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MediaBrain-SJTU/MING",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-llm",
        "chinese-nlp",
        "qa"
      ],
      "id": 117
    },
    {
      "name": "RAG-HPO",
      "one_line_profile": "Automated deep phenotype analysis of clinical information using LLMs and RAG",
      "detailed_description": "A Python-based tool for automated deep phenotype analysis of clinical information, leveraging Large Language Models (LLMs) and Retrieval Augmented Generation (RAG) to map clinical text to Human Phenotype Ontology (HPO) terms.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "phenotyping",
        "clinical_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/PoseyPod/RAG-HPO",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hpo",
        "phenotype",
        "rag",
        "clinical-text"
      ],
      "id": 118
    },
    {
      "name": "Huatuo-Llama-Med-Chinese",
      "one_line_profile": "Chinese medical instruction-tuning LLM based on LLaMA",
      "detailed_description": "A medical large language model (LLM) fine-tuned on Chinese medical knowledge graphs and dialogue data. It provides the model weights and code for instruction tuning, serving as a foundational solver for Chinese medical question answering and dialogue tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_llm",
        "instruction_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-llm",
        "chinese-nlp",
        "instruction-tuning",
        "ben-tsao"
      ],
      "id": 119
    },
    {
      "name": "AgentClinic",
      "one_line_profile": "Agent benchmark environment for medical diagnosis",
      "detailed_description": "A benchmark environment designed to evaluate LLM agents in a simulated clinical setting. It allows for the assessment of agents' capabilities in medical diagnosis and patient interaction.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "benchmarking",
        "agent_simulation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/SamuelSchmidgall/AgentClinic",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-agent",
        "benchmark",
        "diagnosis",
        "simulation"
      ],
      "id": 120
    },
    {
      "name": "CLUE",
      "one_line_profile": "Clinical Language Understanding Evaluation benchmark for LLMs",
      "detailed_description": "A benchmark suite designed to evaluate the performance of Large Language Models (LLMs) on clinical language understanding tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "benchmarking",
        "evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/TIO-IKIM/CLUE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "clinical-nlp",
        "evaluation"
      ],
      "id": 121
    },
    {
      "name": "Open-MAI-Dx-Orchestrator",
      "one_line_profile": "Orchestrator for sequential medical diagnosis with language models",
      "detailed_description": "An open-source implementation of a sequential diagnosis framework using Large Language Models (LLMs), designed to orchestrate the diagnostic process.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "diagnosis",
        "workflow_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/The-Swarm-Corporation/Open-MAI-Dx-Orchestrator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "diagnosis",
        "agent",
        "orchestrator"
      ],
      "id": 122
    },
    {
      "name": "MedXpertQA",
      "one_line_profile": "Benchmark for expert-level medical reasoning and understanding",
      "detailed_description": "A comprehensive benchmark designed to evaluate expert-level medical reasoning and understanding capabilities in Large Language Models.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "benchmarking",
        "medical_reasoning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/TsinghuaC3I/MedXpertQA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "qa",
        "medical-reasoning"
      ],
      "id": 123
    },
    {
      "name": "3DMed-RAG",
      "one_line_profile": "Multimodal RAG system for medical consultation",
      "detailed_description": "A multimodal Retrieval-Augmented Generation (RAG) system capable of processing text, image-text, and image queries for medical consultation and diagnosis. It features domain-aligned negative rejection and enhanced flowchart data processing.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_rag",
        "multimodal_qa"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Tsiphen/Multimodal-RAG-for-Medical-Consultation",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "multimodal",
        "medical-consultation"
      ],
      "id": 124
    },
    {
      "name": "MedReason",
      "one_line_profile": "Framework for eliciting medical reasoning in LLMs via Knowledge Graphs",
      "detailed_description": "A framework and dataset designed to improve and evaluate the factual medical reasoning steps of Large Language Models by leveraging Knowledge Graphs.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_reasoning",
        "knowledge_graph"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/UCSC-VLAA/MedReason",
      "help_website": [],
      "license": null,
      "tags": [
        "reasoning",
        "knowledge-graph",
        "llm"
      ],
      "id": 125
    },
    {
      "name": "m1",
      "one_line_profile": "Test-time scaling method for medical reasoning in LLMs",
      "detailed_description": "An implementation of test-time scaling techniques to enhance the medical reasoning capabilities of Large Language Models, as presented at ML4H 2025.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_reasoning",
        "inference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/UCSC-VLAA/m1",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "test-time-scaling",
        "reasoning",
        "medical-llm"
      ],
      "id": 126
    },
    {
      "name": "discharge-documentation-generator",
      "one_line_profile": "Tool for generating draft clinical discharge letters using LLMs",
      "detailed_description": "A utility tool designed to assist clinicians by generating draft versions of clinical discharge letters using Large Language Models, aiming to streamline clinical documentation workflows.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "clinical_documentation",
        "text_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/UMCU-Digital-Health/discharge-documentation-generator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ehr",
        "discharge-letter",
        "clinical-nlp"
      ],
      "id": 127
    },
    {
      "name": "LingYi",
      "one_line_profile": "Multi-modal Medical Conversational QA System based on Knowledge Graph",
      "detailed_description": "A medical conversational question answering system that integrates multi-modal data and knowledge graphs to provide accurate medical information.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_qa",
        "dialogue_system"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/WENGSYX/LingYi",
      "help_website": [],
      "license": null,
      "tags": [
        "qa",
        "knowledge-graph",
        "multimodal"
      ],
      "id": 128
    },
    {
      "name": "CareGPT",
      "one_line_profile": "Comprehensive open-source medical LLM toolkit",
      "detailed_description": "A comprehensive toolkit for Medical LLMs, including pre-trained models, fine-tuning datasets, training scripts, evaluation benchmarks, and deployment tools.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_llm",
        "model_training",
        "deployment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/WangRongsheng/CareGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-llm",
        "toolkit",
        "fine-tuning"
      ],
      "id": 129
    },
    {
      "name": "IvyGPT",
      "one_line_profile": "Interactive Chinese pathway language model in medical domain",
      "detailed_description": "An interactive medical Large Language Model designed for the Chinese medical domain, capable of handling medical dialogue and pathway reasoning.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_llm",
        "dialogue_system"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/WangRongsheng/IvyGPT",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-llm",
        "chinese-nlp",
        "pathway-model"
      ],
      "id": 130
    },
    {
      "name": "MedQA-ChatGLM",
      "one_line_profile": "Fine-tuning framework for ChatGLM on medical data",
      "detailed_description": "A framework for fine-tuning the ChatGLM model on real-world medical dialogue data using techniques like LoRA, P-Tuning V2, and RLHF.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "medical_llm"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/WangRongsheng/MedQA-ChatGLM",
      "help_website": [],
      "license": null,
      "tags": [
        "chatglm",
        "fine-tuning",
        "lora",
        "rlhf"
      ],
      "id": 131
    },
    {
      "name": "Sunsimiao",
      "one_line_profile": "Chinese Medical Large Language Model",
      "detailed_description": "A safe and reliable Chinese medical Large Language Model (Sunsimiao), providing model weights and inference code for medical consultation and knowledge retrieval.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_llm",
        "consultation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/X-D-Lab/Sunsimiao",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-llm",
        "chinese-nlp",
        "sunsimiao"
      ],
      "id": 132
    },
    {
      "name": "LLM-Pretrain-FineTune",
      "one_line_profile": "Workflow for pre-training and fine-tuning medical LLMs",
      "detailed_description": "A codebase providing workflows for pre-training and fine-tuning Large Language Models on medical dialogue data, utilizing DeepSpeed for efficiency.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "model_training",
        "fine_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/X-jun-0130/LLM-Pretrain-FineTune",
      "help_website": [],
      "license": null,
      "tags": [
        "deepspeed",
        "pretraining",
        "fine-tuning",
        "medical-llm"
      ],
      "id": 133
    },
    {
      "name": "medkit-learn",
      "one_line_profile": "Environment for medical decision modelling through simulation",
      "detailed_description": "A simulation environment for medical decision modeling, allowing for the development and evaluation of decision-making algorithms in a controlled medical setting.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "simulation",
        "decision_modeling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/XanderJC/medkit-learn",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "simulation",
        "decision-making",
        "medical-env"
      ],
      "id": 134
    },
    {
      "name": "EHRStruct",
      "one_line_profile": "Benchmark framework for evaluating LLMs on structured EHR tasks",
      "detailed_description": "A comprehensive benchmark framework designed to evaluate the performance of Large Language Models on tasks involving structured Electronic Health Records (EHR).",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "benchmarking",
        "ehr_analysis"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/YXNTU/EHRStruct",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ehr",
        "benchmark",
        "structured-data"
      ],
      "id": 135
    },
    {
      "name": "ECG-Expert-QA",
      "one_line_profile": "Benchmark for evaluating medical LLMs in heart disease diagnosis",
      "detailed_description": "A benchmark dataset and evaluation tool for assessing the capabilities of Medical Large Language Models specifically in the domain of heart disease diagnosis using ECG data.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "benchmarking",
        "diagnosis",
        "cardiology"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zaozzz/ECG-Expert-QA",
      "help_website": [],
      "license": null,
      "tags": [
        "ecg",
        "benchmark",
        "heart-disease"
      ],
      "id": 136
    },
    {
      "name": "Qwen3-Medical-SFT",
      "one_line_profile": "Fine-tuning scripts for Qwen3 on medical data",
      "detailed_description": "A repository containing scripts and tools for Supervised Fine-Tuning (SFT) of the Qwen3 model on medical datasets, aiming to create medical chat models.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "fine_tuning",
        "medical_llm"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zeyi-Lin/Qwen3-Medical-SFT",
      "help_website": [],
      "license": null,
      "tags": [
        "qwen",
        "fine-tuning",
        "sft"
      ],
      "id": 137
    },
    {
      "name": "MedEmbed",
      "one_line_profile": "Collection of embedding models fine-tuned for medical and clinical data",
      "detailed_description": "MedEmbed provides a suite of embedding models specifically fine-tuned on medical and clinical datasets, enabling improved performance in downstream tasks such as semantic search, clustering, and classification within the healthcare domain.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "scientific_data_processing",
        "embedding_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/abhinand5/MedEmbed",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-embeddings",
        "nlp",
        "clinical-data"
      ],
      "id": 138
    },
    {
      "name": "AI-Agents-for-Medical-Diagnostics",
      "one_line_profile": "Framework for creating LLM-based AI agents for medical diagnostics",
      "detailed_description": "A Python-based framework designed to build and deploy specialized AI agents that leverage Large Language Models (LLMs) for analyzing complex medical cases. It facilitates the integration of insights from various medical perspectives to provide comprehensive assessments.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "scientific_data_analysis",
        "medical_diagnostics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ahmadvh/AI-Agents-for-Medical-Diagnostics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-agents",
        "llm",
        "diagnostics"
      ],
      "id": 139
    },
    {
      "name": "MedEvalKit",
      "one_line_profile": "Unified evaluation framework for medical Large Language Models",
      "detailed_description": "MedEvalKit is a comprehensive toolkit developed by Alibaba DAMO Academy for evaluating medical LLMs. It supports various medical tasks and datasets, providing a standardized way to benchmark model performance in the biomedical domain.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "scientific_data_analysis",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/alibaba-damo-academy/MedEvalKit",
      "help_website": [],
      "license": null,
      "tags": [
        "evaluation",
        "medical-llm",
        "benchmark"
      ],
      "id": 140
    },
    {
      "name": "DeepSeek-R1-Distill-Qwen-32B-Medical-Fine-tune",
      "one_line_profile": "Medical fine-tuned version of DeepSeek-R1-Distill-Qwen-32B",
      "detailed_description": "A specialized Large Language Model fine-tuned on 2 million medical data points based on the DeepSeek-R1-Distill-Qwen-32B architecture. It serves as a solver for medical reasoning and question-answering tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "scientific_inference",
        "medical_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/beita6969/DeepSeek-R1-Distill-Qwen-32B-Medical-Fine-tune",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-llm",
        "fine-tuning",
        "deepseek"
      ],
      "id": 141
    },
    {
      "name": "PMC-LLaMA",
      "one_line_profile": "Open-source language model for medicine based on LLaMA",
      "detailed_description": "PMC-LLaMA is an open-source Large Language Model specifically adapted for the medical domain. It is fine-tuned on biomedical literature (PMC) and clinical notes, serving as a foundational model for various medical NLP tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "scientific_inference",
        "medical_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chaoyi-wu/PMC-LLaMA",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-llm",
        "llama",
        "nlp"
      ],
      "id": 142
    },
    {
      "name": "MultiMedEval",
      "one_line_profile": "Evaluation toolkit for Medical Vision-Language Models",
      "detailed_description": "MultiMedEval is a Python library designed to evaluate the performance of Vision-Language Models (VLMs) in the medical domain. It provides a unified interface for benchmarking models across multiple medical datasets and tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "scientific_data_analysis",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/corentin-ryr/MultiMedEval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vlm",
        "evaluation",
        "medical-imaging"
      ],
      "id": 143
    },
    {
      "name": "ClinicalTrials.gov MCP Server",
      "one_line_profile": "MCP server for retrieving clinical trial data for LLMs",
      "detailed_description": "A Model Context Protocol (MCP) server that acts as a bridge between Large Language Models and the ClinicalTrials.gov API, enabling AI agents to search and retrieve clinical study details for scientific analysis.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "information_retrieval",
        "data_acquisition"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/cyanheads/clinicaltrialsgov-mcp-server",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mcp",
        "clinical-trials",
        "llm-tool"
      ],
      "id": 144
    },
    {
      "name": "MedVidQACL",
      "one_line_profile": "Benchmark implementation for medical video classification and QA",
      "detailed_description": "Implementation of benchmark approaches for the MedVidCL (Medical Instructional Video Classification) and MedVidQA (Medical Video Question Answering) tasks, providing tools for analyzing medical instructional videos.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "video_classification",
        "visual_question_answering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepaknlp/MedVidQACL",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-video",
        "vqa",
        "classification"
      ],
      "id": 145
    },
    {
      "name": "pyomop",
      "one_line_profile": "Python toolkit for managing OHDSI clinical data models",
      "detailed_description": "A Python package for managing OHDSI clinical data models (CDM), supporting LLM-based plain text queries, MCP server integration, and FHIR data import for clinical informatics.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "data_management",
        "clinical_informatics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dermatologist/pyomop",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "ohdsi",
        "omop",
        "fhir",
        "clinical-data"
      ],
      "id": 146
    },
    {
      "name": "RAG2",
      "one_line_profile": "Rationale-guided RAG for medical question answering",
      "detailed_description": "Implementation of a Rationale-Guided Retrieval Augmented Generation framework for medical question answering, designed to improve the accuracy and explainability of LLM responses in healthcare contexts.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "question_answering",
        "rag"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dmis-lab/RAG2",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "medical-qa",
        "llm"
      ],
      "id": 147
    },
    {
      "name": "HealthChain",
      "one_line_profile": "Middleware framework for building healthcare AI applications",
      "detailed_description": "A Python framework designed as a middleware layer to facilitate the development and deployment of healthcare AI applications, connecting clinical data sources with AI models.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "workflow_management",
        "application_development"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dotimplement/HealthChain",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "healthcare-ai",
        "middleware",
        "pipeline"
      ],
      "id": 148
    },
    {
      "name": "gpt2-bert-medical-qa-chat",
      "one_line_profile": "Medical domain-focused GPT-2 fine-tuning implementation",
      "detailed_description": "A research repository providing code for fine-tuning, optimizing, and lightweighting GPT-2 models specifically for medical question-answering tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "model_training",
        "question_answering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dsdanielpark/gpt2-bert-medical-qa-chat",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpt-2",
        "fine-tuning",
        "medical-qa"
      ],
      "id": 149
    },
    {
      "name": "Expert-CFG",
      "one_line_profile": "Expert-controlled guidance for medical VQA",
      "detailed_description": "Implementation of Expert-Controlled Classifier-Free Guidance (Expert-CFG) to improve reliability and accuracy in Medical Visual Question Answering tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "visual_question_answering",
        "model_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ecoxial2007/Expert-CFG",
      "help_website": [],
      "license": null,
      "tags": [
        "vqa",
        "medical-imaging",
        "classifier-free-guidance"
      ],
      "id": 150
    },
    {
      "name": "LDCT Benchmark",
      "one_line_profile": "Benchmark for low dose CT image denoising",
      "detailed_description": "A benchmarking tool and framework for evaluating deep learning-based methods for low dose CT (LDCT) image denoising.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "image_denoising",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/eeulig/ldct-benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ct-imaging",
        "denoising",
        "benchmark"
      ],
      "id": 151
    },
    {
      "name": "CLIP Image Search",
      "one_line_profile": "Fine-tuned CLIP model for medical image search",
      "detailed_description": "A tool for fine-tuning OpenAI's CLIP model specifically for semantic search on medical images, enabling efficient retrieval of medical visual data.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "image_retrieval",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/elsevierlabs-os/clip-image-search",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "clip",
        "medical-image-search",
        "fine-tuning"
      ],
      "id": 152
    },
    {
      "name": "Meditron",
      "one_line_profile": "Suite of open-source medical Large Language Models",
      "detailed_description": "A comprehensive suite of open-source Large Language Models (LLMs) specifically pre-trained and fine-tuned for the medical domain, providing high-performance foundation models for healthcare applications.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "model_training",
        "inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/epfLLM/meditron",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-llm",
        "foundation-model",
        "llama"
      ],
      "id": 153
    },
    {
      "name": "SMMILE",
      "one_line_profile": "Benchmark for multimodal medical in-context learning",
      "detailed_description": "An expert-driven benchmark designed to evaluate Multimodal Medical In-Context Learning capabilities of AI models, developed by ETH Medical AI Lab.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "benchmarking",
        "multimodal_learning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/eth-medical-ai-lab/smmile",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "in-context-learning",
        "multimodal"
      ],
      "id": 154
    },
    {
      "name": "MedTsLLM",
      "one_line_profile": "LLM-based tool for medical time series analysis",
      "detailed_description": "A framework leveraging Large Language Models for the analysis of multimodal medical time series data, enabling advanced interpretation of temporal clinical data.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "time_series_analysis",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/flixpar/med-ts-llm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "time-series",
        "medical-llm",
        "multimodal"
      ],
      "id": 155
    },
    {
      "name": "BioMCP",
      "one_line_profile": "Biomedical Model Context Protocol implementation",
      "detailed_description": "An implementation of the Model Context Protocol (MCP) specifically tailored for biomedical data, facilitating standardized interaction between LLMs and biomedical data sources.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "data_integration",
        "interoperability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/genomoncology/biomcp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "biomedical",
        "protocol"
      ],
      "id": 156
    },
    {
      "name": "MedAgents",
      "one_line_profile": "Framework for zero-shot medical reasoning using LLM agents",
      "detailed_description": "A framework that utilizes Large Language Models as collaborating agents to perform complex zero-shot medical reasoning tasks, enhancing diagnostic and decision-making capabilities.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_reasoning",
        "agent_framework"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gersteinlab/MedAgents",
      "help_website": [],
      "license": null,
      "tags": [
        "agents",
        "medical-reasoning",
        "zero-shot"
      ],
      "id": 157
    },
    {
      "name": "MedAgentsBench",
      "one_line_profile": "Benchmark for medical reasoning agents",
      "detailed_description": "A benchmarking suite for evaluating thinking models and agent frameworks on complex medical reasoning tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "benchmarking",
        "medical_reasoning"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/gersteinlab/medagents-benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "agents",
        "reasoning"
      ],
      "id": 158
    },
    {
      "name": "CUFIT",
      "one_line_profile": "Curriculum fine-tuning for medical image classification",
      "detailed_description": "Implementation of a curriculum fine-tuning strategy for vision foundation models, specifically designed to handle label noise in medical image classification tasks.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "image_classification",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gist-ailab/CUFIT",
      "help_website": [],
      "license": null,
      "tags": [
        "fine-tuning",
        "medical-imaging",
        "label-noise"
      ],
      "id": 159
    },
    {
      "name": "CMSA-MTPT-4-MedicalVQA",
      "one_line_profile": "Multi-task pre-training for medical VQA",
      "detailed_description": "A framework for Medical Visual Question Answering utilizing multi-task pre-training and cross-modal self-attention mechanisms to improve performance.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "visual_question_answering",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/haifangong/CMSA-MTPT-4-MedicalVQA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vqa",
        "attention",
        "pre-training"
      ],
      "id": 160
    },
    {
      "name": "diseaseBERT",
      "one_line_profile": "BERT model infused with disease knowledge",
      "detailed_description": "A BERT-based model and toolkit that infuses disease knowledge for enhanced performance in health question answering, medical inference, and disease name recognition.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "question_answering",
        "named_entity_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/heyunh2015/diseaseBERT",
      "help_website": [],
      "license": null,
      "tags": [
        "bert",
        "knowledge-infusion",
        "ner"
      ],
      "id": 161
    },
    {
      "name": "viBioGPT",
      "one_line_profile": "Vietnamese medical LLM for question answering",
      "detailed_description": "A Vietnamese Large Language Model fine-tuned specifically for question answering tasks within the medical and healthcare domain.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "question_answering",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hungnlp/viBioGPT",
      "help_website": [],
      "license": null,
      "tags": [
        "vietnamese",
        "medical-llm",
        "qa"
      ],
      "id": 162
    },
    {
      "name": "Doctor-SAM",
      "one_line_profile": "Fine-tuned SAM for medical image segmentation",
      "detailed_description": "A fine-tuned version of the Segment Anything Model (SAM) optimized for medical image segmentation tasks.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "image_segmentation",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/huoxiangzuo/Doctor-SAM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sam",
        "segmentation",
        "medical-imaging"
      ],
      "id": 163
    },
    {
      "name": "LLM Meta-Analysis",
      "one_line_profile": "Tool for automating clinical trial meta-analysis",
      "detailed_description": "A Python tool designed to automate the process of performing meta-analysis on clinical trials (RCTs) using Large Language Models.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "meta_analysis",
        "data_synthesis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/hyesunyun/llm-meta-analysis",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "meta-analysis",
        "clinical-trials",
        "automation"
      ],
      "id": 164
    },
    {
      "name": "EHRNoteQA",
      "one_line_profile": "Benchmark for clinical practice using discharge summaries",
      "detailed_description": "A benchmark suite for evaluating Large Language Models on real-world clinical practice tasks using Electronic Health Record (EHR) discharge summaries.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "benchmarking",
        "question_answering"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/ji-youn-kim/EHRNoteQA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ehr",
        "benchmark",
        "discharge-summary"
      ],
      "id": 165
    },
    {
      "name": "PeFoMed",
      "one_line_profile": "Parameter efficient fine-tuning for medical VQA",
      "detailed_description": "Implementation of PeFoM-Med, a parameter-efficient fine-tuning method for Multi-modal Large Language Models applied to Medical Visual Question Answering.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "visual_question_answering",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jinlHe/PeFoMed",
      "help_website": [],
      "license": null,
      "tags": [
        "peft",
        "vqa",
        "multimodal"
      ],
      "id": 166
    },
    {
      "name": "medAlpaca",
      "one_line_profile": "LLM fine-tuned for medical question answering",
      "detailed_description": "An open-source Large Language Model fine-tuned on medical datasets to provide accurate answers to medical questions, serving as a specialized tool for healthcare NLP tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "question_answering",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kbressem/medAlpaca",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "alpaca",
        "medical-qa",
        "llm"
      ],
      "id": 167
    },
    {
      "name": "IMCS21 Benchmark",
      "one_line_profile": "Benchmark for automatic medical consultation systems",
      "detailed_description": "A benchmark toolkit containing datasets and frameworks for evaluating automatic medical consultation systems, focusing on dialogue understanding and generation in healthcare.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "benchmarking",
        "dialogue_system"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/lemuria-wchen/imcs21",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-dialogue",
        "benchmark",
        "consultation"
      ],
      "id": 168
    },
    {
      "name": "PreProcPipe",
      "one_line_profile": "LLM-automated pipeline for medical image preprocessing",
      "detailed_description": "A pipeline leveraging Large Language Models to automate the preprocessing of medical images, aiming to simplify and clarify the workflow for medical image analysis.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_image_preprocessing",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/lgy112112/PreProcPipe",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-imaging",
        "preprocessing",
        "llm-automation"
      ],
      "id": 169
    },
    {
      "name": "doctorwithbloom",
      "one_line_profile": "Fine-tuning scripts for Bloomz on medical dialogue datasets",
      "detailed_description": "Provides implementation for fine-tuning the Bloomz-7b1-mt model using LoRA on the ChatDoctor dataset to create a medical consultation assistant.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "model_finetuning",
        "medical_dialogue"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/linhduongtuan/doctorwithbloom",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bloomz",
        "lora",
        "medical-llm",
        "finetuning"
      ],
      "id": 170
    },
    {
      "name": "MedChain",
      "one_line_profile": "Framework bridging LLM agents with clinical decision making",
      "detailed_description": "Implementation of MedChain, a system designed to integrate Large Language Model agents into real-world clinical decision-making processes, enhancing reasoning and reliability.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "clinical_decision_support",
        "agent_framework"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ljwztc/MedChain",
      "help_website": [],
      "license": null,
      "tags": [
        "clinical-decision-making",
        "llm-agents",
        "medical-reasoning"
      ],
      "id": 171
    },
    {
      "name": "clinical-calculator-tooluse",
      "one_line_profile": "Training LLMs to use clinical calculators from patient history",
      "detailed_description": "Explores and implements methods to train open-source Large Language Models to extract patient history and correctly utilize clinical calculators (e.g., Wells' Criteria).",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "tool_use",
        "clinical_calculation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucidrains/clinical-calculator-tooluse",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "clinical-calculators",
        "tool-learning",
        "medical-llm"
      ],
      "id": 172
    },
    {
      "name": "openmed",
      "one_line_profile": "Open-source healthcare AI library",
      "detailed_description": "A library providing open-source tools and models for healthcare AI applications, facilitating the development and deployment of medical AI solutions.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "healthcare_ai",
        "model_deployment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/maziyarpanahi/openmed",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "healthcare-ai",
        "open-source",
        "medical-models"
      ],
      "id": 173
    },
    {
      "name": "finetune-SAM",
      "one_line_profile": "Fine-tuning Segment Anything Model (SAM) for medical images",
      "detailed_description": "Official repository for fine-tuning the Segment Anything Model (SAM) specifically for customized medical image segmentation tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_image_segmentation",
        "model_finetuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mazurowski-lab/finetune-SAM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sam",
        "segmentation",
        "medical-imaging",
        "fine-tuning"
      ],
      "id": 174
    },
    {
      "name": "failure_detection_benchmark",
      "one_line_profile": "Benchmark for failure detection in medical image classification",
      "detailed_description": "Code and benchmarking framework for evaluating failure detection methods in medical image classification, as presented in the TMLR 2022 paper.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "failure_detection",
        "benchmarking",
        "image_classification"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/melanibe/failure_detection_benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "failure-detection",
        "medical-imaging",
        "benchmarking"
      ],
      "id": 175
    },
    {
      "name": "clinical-self-verification",
      "one_line_profile": "Self-verification mechanisms for clinical LLMs",
      "detailed_description": "Implementation of self-verification techniques to improve the accuracy and reliability of Large Language Models in clinical contexts.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "verification",
        "hallucination_reduction"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/microsoft/clinical-self-verification",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "self-verification",
        "clinical-llm",
        "reliability"
      ],
      "id": 176
    },
    {
      "name": "Madrigal",
      "one_line_profile": "Multimodal AI for predicting drug combination outcomes",
      "detailed_description": "A multimodal AI framework (Madrigal) that predicts clinical outcomes of drug combinations by leveraging preclinical data.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "drug_response_prediction",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mims-harvard/Madrigal",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "drug-combinations",
        "clinical-outcomes",
        "multimodal-ai"
      ],
      "id": 177
    },
    {
      "name": "MDAgents",
      "one_line_profile": "Adaptive collaboration of LLMs for medical decision-making",
      "detailed_description": "Implementation of MDAgents, a framework enabling adaptive collaboration among multiple Large Language Models to enhance medical decision-making capabilities.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_decision_making",
        "multi_agent_system"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mitmedialab/MDAgents",
      "help_website": [],
      "license": null,
      "tags": [
        "multi-agent",
        "medical-decision-making",
        "collaboration"
      ],
      "id": 178
    },
    {
      "name": "MedPerf",
      "one_line_profile": "Open benchmarking platform for medical AI",
      "detailed_description": "An open benchmarking platform designed for medical artificial intelligence, utilizing federated evaluation to assess model performance across distributed datasets.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "benchmarking",
        "federated_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/mlcommons/medperf",
      "help_website": [
        "https://medperf.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "benchmarking",
        "federated-learning",
        "medical-ai"
      ],
      "id": 179
    },
    {
      "name": "FFA-IR",
      "one_line_profile": "Benchmark for explainable medical report generation",
      "detailed_description": "Official code for the FFA-IR benchmark, focusing on evaluating the explainability and reliability of medical report generation models.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "report_generation",
        "benchmarking",
        "explainability"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mlii0117/FFA-IR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-report-generation",
        "benchmark",
        "explainable-ai"
      ],
      "id": 180
    },
    {
      "name": "MedCalc-Bench",
      "one_line_profile": "Benchmark for evaluating LLMs on medical calculations",
      "detailed_description": "A benchmark suite designed to evaluate the performance of Large Language Models on medical calculation tasks, ensuring accuracy in clinical computations.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_calculation",
        "benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ncbi-nlp/MedCalc-Bench",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-calculations",
        "llm-evaluation",
        "benchmark"
      ],
      "id": 181
    },
    {
      "name": "annotateai",
      "one_line_profile": "Automated paper annotation using LLMs",
      "detailed_description": "A tool to automatically annotate scientific papers using Large Language Models, facilitating literature review and knowledge extraction.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "literature_annotation",
        "knowledge_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/neuml/annotateai",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "annotation",
        "literature-review",
        "llm"
      ],
      "id": 182
    },
    {
      "name": "INSIGHT",
      "one_line_profile": "Autonomous AI agent for medical research",
      "detailed_description": "An autonomous AI system designed to conduct medical research tasks, acting as a research assistant or agent.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_research_agent",
        "autonomous_research"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/oneil512/INSIGHT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "autonomous-agent",
        "medical-research",
        "ai-scientist"
      ],
      "id": 183
    },
    {
      "name": "MIMIC-Clinical-Decision-Making-Analysis",
      "one_line_profile": "Analysis code for LLM performance on MIMIC CDM dataset",
      "detailed_description": "A repository containing code to analyze the performance and results of selected Large Language Models using the MIMIC Clinical Decision Making (CDM) dataset.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "performance_analysis",
        "clinical_decision_making"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/paulhager/MIMIC-Clinical-Decision-Making-Analysis",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mimic",
        "clinical-decision-making",
        "llm-analysis"
      ],
      "id": 184
    },
    {
      "name": "RuMedBench",
      "one_line_profile": "Benchmark for Russian medical language understanding",
      "detailed_description": "A benchmark suite for evaluating Russian language models on medical tasks, as described in the associated arXiv paper.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "benchmarking",
        "multilingual_medical_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/pavel-blinov/RuMedBench",
      "help_website": [],
      "license": null,
      "tags": [
        "russian-nlp",
        "medical-benchmark",
        "evaluation"
      ],
      "id": 185
    },
    {
      "name": "M2I2",
      "one_line_profile": "Self-supervised pretraining for medical VQA",
      "detailed_description": "Implementation of M2I2, a self-supervised vision-language pretraining framework specifically designed for Medical Visual Question Answering tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_vqa",
        "vision_language_pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/pengfeiliHEU/M2I2",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vqa",
        "medical-imaging",
        "pretraining"
      ],
      "id": 186
    },
    {
      "name": "MUMC",
      "one_line_profile": "Masked vision and language pre-training for Medical VQA",
      "detailed_description": "Implementation of MUMC, a framework using masked vision and language pre-training with unimodal and multimodal contrastive losses for Medical Visual Question Answering.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_vqa",
        "contrastive_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/pengfeiliHEU/MUMC",
      "help_website": [],
      "license": null,
      "tags": [
        "vqa",
        "multimodal",
        "pretraining"
      ],
      "id": 187
    },
    {
      "name": "CARES",
      "one_line_profile": "Benchmark of trustworthiness in medical vision language models",
      "detailed_description": "A comprehensive benchmark suite for evaluating the trustworthiness (e.g., safety, fairness, reliability) of Medical Vision Language Models.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "trustworthiness_evaluation",
        "medical_vlm"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/richard-peng-xia/CARES",
      "help_website": [],
      "license": "CC-BY-4.0",
      "tags": [
        "trustworthiness",
        "benchmark",
        "medical-vlm"
      ],
      "id": 188
    },
    {
      "name": "BMRetriever",
      "one_line_profile": "Tuning LLMs as biomedical text retrievers",
      "detailed_description": "Implementation of BMRetriever, a method for tuning Large Language Models to function as effective retrievers for biomedical text data.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "information_retrieval",
        "biomedical_text_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ritaranx/BMRetriever",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "retrieval",
        "biomedical-nlp",
        "llm-tuning"
      ],
      "id": 189
    },
    {
      "name": "ClinGen",
      "one_line_profile": "Knowledge-infused prompting for clinical text generation",
      "detailed_description": "Code for ClinGen, a framework that uses knowledge-infused prompting to assess and advance the generation of clinical text data using Large Language Models.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "clinical_text_generation",
        "prompt_engineering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ritaranx/ClinGen",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "text-generation",
        "clinical-nlp",
        "knowledge-infusion"
      ],
      "id": 190
    },
    {
      "name": "RAM-EHR",
      "one_line_profile": "Retrieval augmentation for clinical predictions on EHR",
      "detailed_description": "Implementation of RAM-EHR, a method combining retrieval augmentation with clinical prediction models for Electronic Health Records.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "clinical_prediction",
        "retrieval_augmented_generation",
        "ehr_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ritaranx/RAM-EHR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ehr",
        "rag",
        "clinical-prediction"
      ],
      "id": 191
    },
    {
      "name": "LLM-From-Scratch",
      "one_line_profile": "Medical Language Model fine-tuning and alignment pipeline",
      "detailed_description": "A pipeline for creating medical language models, covering pretraining, instruction tuning, and Direct Preference Optimization (DPO) for improved alignment.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "model_training",
        "alignment",
        "dpo"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/samadon1/LLM-From-Scratch",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-llm",
        "dpo",
        "instruction-tuning"
      ],
      "id": 192
    },
    {
      "name": "MedicalGPT",
      "one_line_profile": "Comprehensive toolkit for training and fine-tuning medical Large Language Models",
      "detailed_description": "A complete pipeline for training medical LLMs, supporting incremental pre-training, supervised fine-tuning (SFT), RLHF, DPO, and other alignment techniques specifically adapted for the medical domain.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "model_training",
        "fine_tuning",
        "alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/shibing624/MedicalGPT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-llm",
        "rlhf",
        "sft",
        "dpo"
      ],
      "id": 193
    },
    {
      "name": "JMED-LLM",
      "one_line_profile": "Japanese Medical Evaluation Dataset for Large Language Models",
      "detailed_description": "A benchmark dataset designed to evaluate the performance of Large Language Models on Japanese medical tasks, facilitating the assessment of cross-lingual medical AI capabilities.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmark"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/sociocom/JMED-LLM",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "japanese-medical",
        "llm-evaluation"
      ],
      "id": 194
    },
    {
      "name": "factehr",
      "one_line_profile": "Fact verification tool for clinical notes using LLMs",
      "detailed_description": "A tool designed to verify factual correctness in clinical notes generated or processed by Large Language Models, addressing hallucination issues in medical text generation.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "fact_verification",
        "clinical_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/som-shahlab/factehr",
      "help_website": [],
      "license": null,
      "tags": [
        "fact-checking",
        "clinical-notes",
        "hallucination-detection"
      ],
      "id": 195
    },
    {
      "name": "MedAgentBench",
      "one_line_profile": "Realistic Virtual EHR Environment to Benchmark Medical LLM Agents",
      "detailed_description": "A benchmarking environment that simulates Electronic Health Records (EHR) interactions to evaluate the capability of medical LLM agents in performing clinical tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "agent_evaluation",
        "benchmark",
        "ehr_simulation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanfordmlgroup/MedAgentBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-agent",
        "ehr",
        "benchmark"
      ],
      "id": 196
    },
    {
      "name": "Asclepius",
      "one_line_profile": "Clinical Large Language Model built on synthetic clinical notes",
      "detailed_description": "Provides a clinical LLM trained on synthetic data to overcome privacy barriers, serving as a resource for clinical NLP research and model development.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "model_generation",
        "synthetic_data"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/starmpcc/Asclepius",
      "help_website": [],
      "license": null,
      "tags": [
        "synthetic-data",
        "clinical-llm",
        "privacy-preserving"
      ],
      "id": 197
    },
    {
      "name": "CAMEL",
      "one_line_profile": "Clinically Adapted Model Enhanced from LLaMA",
      "detailed_description": "A medical LLM adapted from LLaMA, designed to provide enhanced clinical reasoning and knowledge capabilities for medical NLP tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_llm",
        "inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/starmpcc/CAMEL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llama",
        "clinical-adaptation",
        "medical-llm"
      ],
      "id": 198
    },
    {
      "name": "ChiMed-GPT",
      "one_line_profile": "Chinese Medical Large Language Model with full training pipeline",
      "detailed_description": "A Chinese medical LLM developed through continual pre-training, SFT, and RLHF on Chinese medical data, providing a resource for Chinese clinical NLP.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_llm",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/synlp/ChiMed-GPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chinese-medical-llm",
        "rlhf",
        "sft"
      ],
      "id": 199
    },
    {
      "name": "GMAI-MMBench",
      "one_line_profile": "Comprehensive Multimodal Evaluation Benchmark for General Medical AI",
      "detailed_description": "A benchmark suite for evaluating multimodal medical AI models across various tasks and modalities, ensuring robust assessment of general medical AI capabilities.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "multimodal_evaluation",
        "benchmark"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/uni-medical/GMAI-MMBench",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "benchmark",
        "medical-ai"
      ],
      "id": 200
    },
    {
      "name": "IMIS-Bench",
      "one_line_profile": "Benchmark Dataset and Baseline for Interactive Medical Image Segmentation",
      "detailed_description": "Provides a benchmark dataset and baseline models for the task of interactive medical image segmentation, facilitating research in human-in-the-loop medical imaging.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "image_segmentation",
        "benchmark"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/uni-medical/IMIS-Bench",
      "help_website": [],
      "license": null,
      "tags": [
        "segmentation",
        "interactive-segmentation",
        "benchmark"
      ],
      "id": 201
    },
    {
      "name": "TREQS",
      "one_line_profile": "Text-to-SQL Generation for Question Answering on Electronic Medical Records",
      "detailed_description": "A specialized tool for converting natural language questions into SQL queries specifically for Electronic Medical Records (EMR), enabling data extraction and analysis.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "text_to_sql",
        "emr_analysis",
        "question_answering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wangpinggl/TREQS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "text-to-sql",
        "emr",
        "clinical-qa"
      ],
      "id": 202
    },
    {
      "name": "CMExam",
      "one_line_profile": "Chinese National Medical Licensing Examination dataset and benchmarks",
      "detailed_description": "A dataset and benchmark suite derived from the Chinese National Medical Licensing Examination to evaluate the medical knowledge and reasoning of LLMs.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmark",
        "medical_knowledge"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/williamliujl/CMExam",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "medical-exam",
        "chinese-medical"
      ],
      "id": 203
    },
    {
      "name": "EhrAgent",
      "one_line_profile": "Agent framework for complex tabular reasoning on Electronic Health Records",
      "detailed_description": "An agent-based framework that empowers LLMs to perform complex tabular reasoning tasks on Electronic Health Records (EHR) by generating and executing code.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "tabular_reasoning",
        "ehr_analysis",
        "agent"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wshi83/EhrAgent",
      "help_website": [],
      "license": null,
      "tags": [
        "ehr",
        "agent",
        "tabular-reasoning"
      ],
      "id": 204
    },
    {
      "name": "MedAdapter",
      "one_line_profile": "Efficient Test-Time Adaptation of LLMs for Medical Reasoning",
      "detailed_description": "A lightweight adapter module designed for efficient test-time adaptation of Large Language Models to improve their performance on medical reasoning tasks.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "model_adaptation",
        "medical_reasoning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wshi83/MedAdapter",
      "help_website": [],
      "license": null,
      "tags": [
        "adapter",
        "test-time-adaptation",
        "medical-reasoning"
      ],
      "id": 205
    },
    {
      "name": "MedAgentGym",
      "one_line_profile": "Training environment for LLM Agents in Code-Based Medical Reasoning",
      "detailed_description": "A training environment (Gym) designed to scale the training of LLM agents for code-based medical reasoning tasks, facilitating the development of autonomous medical agents.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "agent_training",
        "reinforcement_learning",
        "medical_reasoning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/wshi83/MedAgentGym",
      "help_website": [],
      "license": null,
      "tags": [
        "agent-gym",
        "medical-reasoning",
        "training-environment"
      ],
      "id": 206
    },
    {
      "name": "PMC-VQA",
      "one_line_profile": "Large-scale medical visual question-answering dataset",
      "detailed_description": "A large-scale dataset for medical Visual Question Answering (VQA) sourced from PubMed Central, covering various modalities and diseases to train and evaluate multimodal models.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "visual_question_answering",
        "dataset"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/xiaoman-zhang/PMC-VQA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vqa",
        "medical-imaging",
        "multimodal"
      ],
      "id": 207
    },
    {
      "name": "DoctorGLM",
      "one_line_profile": "Chinese medical consultation model based on ChatGLM-6B",
      "detailed_description": "A specialized Chinese medical LLM fine-tuned on ChatGLM-6B for medical consultation and dialogue tasks, providing a deployable solution for automated patient interaction.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "medical_consultation",
        "dialogue_system"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/xionghonglin/DoctorGLM",
      "help_website": [],
      "license": null,
      "tags": [
        "chatglm",
        "medical-dialogue",
        "chinese-medical"
      ],
      "id": 208
    },
    {
      "name": "BenchX",
      "one_line_profile": "Unified Benchmark Framework for Medical Vision-Language Pretraining on Chest X-Rays",
      "detailed_description": "A benchmarking framework designed to evaluate medical vision-language pretraining models specifically on Chest X-Ray data, standardizing the assessment of multimodal medical AI.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "vision_language_pretraining",
        "benchmark",
        "chest_xray"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/yangzhou12/BenchX",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chest-xray",
        "vision-language",
        "benchmark"
      ],
      "id": 209
    },
    {
      "name": "HealthFlow",
      "one_line_profile": "Self-evolving AI agent framework for autonomous healthcare research",
      "detailed_description": "HealthFlow is a self-evolving AI agent equipped with meta-planning capabilities designed to automate healthcare research tasks. It can perform data analysis, hypothesis generation, and workflow planning for medical research.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "scientific_modeling",
        "autonomous_research",
        "workflow_planning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yhzhu99/HealthFlow",
      "help_website": [],
      "license": null,
      "tags": [
        "ai-agent",
        "healthcare",
        "autonomous-research",
        "llm"
      ],
      "id": 210
    },
    {
      "name": "MedAgentBoard",
      "one_line_profile": "Benchmark suite for evaluating multi-agent collaboration in medical tasks",
      "detailed_description": "MedAgentBoard is a benchmarking framework designed to evaluate the performance of multi-agent systems in diverse medical scenarios, comparing them against conventional methods.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "benchmarking",
        "model_evaluation",
        "multi_agent_system"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yhzhu99/MedAgentBoard",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "multi-agent",
        "medical-ai",
        "evaluation"
      ],
      "id": 211
    },
    {
      "name": "llm4healthcare",
      "one_line_profile": "Framework for zero-shot clinical prediction using LLMs on EHR data",
      "detailed_description": "A library for prompting Large Language Models to perform zero-shot clinical prediction tasks using structured longitudinal Electronic Health Record (EHR) data.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "clinical_prediction",
        "ehr_analysis",
        "zero_shot_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yhzhu99/llm4healthcare",
      "help_website": [],
      "license": null,
      "tags": [
        "ehr",
        "clinical-prediction",
        "llm",
        "zero-shot"
      ],
      "id": 212
    },
    {
      "name": "MEDFAIR",
      "one_line_profile": "Benchmarking framework for fairness in medical imaging models",
      "detailed_description": "MEDFAIR is a codebase and benchmark suite for evaluating the fairness of machine learning models in medical imaging, providing standardized datasets and evaluation metrics.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "benchmarking",
        "fairness_evaluation",
        "medical_imaging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ys-zong/MEDFAIR",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-imaging",
        "fairness",
        "benchmark",
        "deep-learning"
      ],
      "id": 213
    },
    {
      "name": "STELLA",
      "one_line_profile": "Self-evolving LLM agent for biomedical research and coding",
      "detailed_description": "STELLA is a self-evolving Large Language Model agent designed to assist in biomedical research tasks, including literature mining and code generation for scientific discovery.",
      "domains": [
        "H2",
        "H2-02"
      ],
      "subtask_category": [
        "scientific_discovery",
        "literature_mining",
        "code_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zaixizhang/STELLA",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-agent",
        "biomedical-research",
        "self-evolving",
        "scientific-discovery"
      ],
      "id": 214
    },
    {
      "name": "MedSegBench",
      "one_line_profile": "Standardized library for medical image segmentation datasets and benchmarking",
      "detailed_description": "MedSegBench is a Python library that provides easy access to standardized medical segmentation datasets across different modalities and tools for benchmarking segmentation models.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "image_segmentation",
        "data_loading",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zekikus/MedSegBench",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-segmentation",
        "datasets",
        "benchmark",
        "computer-vision"
      ],
      "id": 215
    },
    {
      "name": "PapersChat",
      "one_line_profile": "Agentic AI application for chatting with and retrieving information from scientific papers (ArXiv/PubMed)",
      "detailed_description": "An agentic AI tool designed to facilitate interaction with scientific literature. It allows users to chat with local papers and automatically retrieves and processes information from ArXiv and PubMed, supporting literature review and information extraction tasks in scientific research.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "literature_review",
        "information_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/AstraBert/PapersChat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "arxiv",
        "pubmed",
        "literature-review",
        "agent"
      ],
      "id": 216
    },
    {
      "name": "text-to-sql-epi-ehr-naacl2024",
      "one_line_profile": "Retrieval-augmented text-to-SQL generation for epidemiological question answering on EHRs",
      "detailed_description": "A research code implementation for generating SQL queries from natural language questions specifically for epidemiological studies using Electronic Health Records (EHR). It utilizes retrieval-augmented generation to improve accuracy in clinical data querying.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "clinical_data_analysis",
        "epidemiology_qa"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Bayer-Group/text-to-sql-epi-ehr-naacl2024",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ehr",
        "text-to-sql",
        "epidemiology",
        "rag",
        "clinical-data"
      ],
      "id": 217
    },
    {
      "name": "LinearRAG",
      "one_line_profile": "Efficient relation-free graph construction method for GraphRAG",
      "detailed_description": "A tool implementing a relation-free graph construction method designed to enhance the efficiency of Graph Retrieval-Augmented Generation (GraphRAG) processes.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "graph_construction",
        "retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DEEP-PolyU/LinearRAG",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "graph-rag",
        "retrieval",
        "graph-construction"
      ],
      "id": 218
    },
    {
      "name": "GraphRAG-SDK",
      "one_line_profile": "SDK for building GraphRAG applications with FalkorDB",
      "detailed_description": "A software development kit designed to facilitate the construction of Graph Retrieval-Augmented Generation (GraphRAG) applications, leveraging knowledge graphs for enhanced LLM context.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "graph_rag",
        "knowledge_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/FalkorDB/GraphRAG-SDK",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-rag",
        "sdk",
        "knowledge-graph"
      ],
      "id": 219
    },
    {
      "name": "paper-qa",
      "one_line_profile": "High-accuracy RAG for scientific documents with citation grounding",
      "detailed_description": "A library for performing Retrieval-Augmented Generation (RAG) specifically on scientific literature, providing answers with precise citation grounding to ensure evidence-based outputs.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "scientific_qa",
        "citation_grounding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Future-House/paper-qa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "citation",
        "scientific-literature"
      ],
      "id": 220
    },
    {
      "name": "GraphRAG-Benchmark",
      "one_line_profile": "Benchmark suite for evaluating GraphRAG models",
      "detailed_description": "A comprehensive benchmark tool and dataset designed to evaluate the performance of Graph Retrieval-Augmented Generation (GraphRAG) models.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/GraphRAG-Bench/GraphRAG-Benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "graph-rag",
        "evaluation"
      ],
      "id": 221
    },
    {
      "name": "LightRAG",
      "one_line_profile": "Simple and fast Retrieval-Augmented Generation framework",
      "detailed_description": "A lightweight and efficient framework for Retrieval-Augmented Generation (RAG), optimizing the retrieval and generation process for speed and simplicity.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "retrieval",
        "generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUDS/LightRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "retrieval",
        "nlp"
      ],
      "id": 222
    },
    {
      "name": "Medical-Graph-RAG",
      "one_line_profile": "Graph RAG system for evidence-based medical information retrieval",
      "detailed_description": "A specialized Graph Retrieval-Augmented Generation system designed for the medical domain, facilitating evidence-based information retrieval from clinical texts.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "medical_retrieval",
        "evidence_chain"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ImprintLab/Medical-Graph-RAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-rag",
        "graph-rag",
        "evidence-based"
      ],
      "id": 223
    },
    {
      "name": "LettuceDetect",
      "one_line_profile": "Hallucination detection framework for RAG applications",
      "detailed_description": "A framework designed to detect hallucinations in Retrieval-Augmented Generation (RAG) applications, serving as a quality control tool for AI-generated scientific content.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "hallucination_detection",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KRLabsOrg/LettuceDetect",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination-detection",
        "rag",
        "quality-control"
      ],
      "id": 224
    },
    {
      "name": "Graph-R1",
      "one_line_profile": "Agentic GraphRAG framework using reinforcement learning for complex reasoning",
      "detailed_description": "A framework that implements an agentic approach to Graph Retrieval-Augmented Generation (GraphRAG) using end-to-end reinforcement learning. It is designed to enhance information retrieval and reasoning capabilities over knowledge graphs, suitable for complex scientific query answering.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "information_retrieval",
        "knowledge_graph_reasoning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/LHRLAB/Graph-R1",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graphrag",
        "reinforcement-learning",
        "agentic-rag",
        "knowledge-graph"
      ],
      "id": 225
    },
    {
      "name": "HyperGraphRAG",
      "one_line_profile": "Retrieval-Augmented Generation framework based on hypergraph knowledge representation",
      "detailed_description": "Official implementation of 'HyperGraphRAG', a method utilizing hypergraph-structured knowledge representations to improve retrieval-augmented generation. This approach allows for capturing high-order correlations in data, which is beneficial for complex scientific knowledge modeling.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "information_retrieval",
        "knowledge_representation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/LHRLAB/HyperGraphRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hypergraph",
        "rag",
        "knowledge-representation",
        "neurips-2025"
      ],
      "id": 226
    },
    {
      "name": "UniBiomed",
      "one_line_profile": "Universal foundation model for grounded biomedical image interpretation",
      "detailed_description": "A universal foundation model designed for grounded biomedical image interpretation. It supports tasks involving the analysis and understanding of biomedical imagery, facilitating multimodal research in digital health.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "image_analysis",
        "biomedical_interpretation"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/Luffy03/UniBiomed",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "biomedical-imaging",
        "foundation-model",
        "multimodal",
        "digital-health"
      ],
      "id": 227
    },
    {
      "name": "local-rag-llamaindex",
      "one_line_profile": "Local RAG tool for navigating and querying research papers",
      "detailed_description": "A local Retrieval-Augmented Generation (RAG) application built with LlamaIndex, specifically designed to assist researchers in navigating and querying scientific research papers efficiently without relying on external cloud services.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "literature_review",
        "information_retrieval"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Otman404/local-rag-llamaindex",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "literature-review",
        "llamaindex",
        "research-assistant"
      ],
      "id": 228
    },
    {
      "name": "BiRD",
      "one_line_profile": "A Refer-and-Ground Multimodal Large Language Model for Biomedicine",
      "detailed_description": "BiRD is a multimodal large language model designed for biomedical tasks, featuring capabilities to refer to and ground information within biomedical contexts, enhancing multimodal understanding in medical domains.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "multimodal_generation",
        "grounding",
        "biomedical_vqa"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ShawnHuang497/BiRD",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal-llm",
        "biomedicine",
        "grounding",
        "vqa"
      ],
      "id": 229
    },
    {
      "name": "MedRAG",
      "one_line_profile": "Toolkit for medical Retrieval-Augmented Generation (RAG)",
      "detailed_description": "MedRAG is a specialized toolkit designed to benchmark and implement Retrieval-Augmented Generation systems specifically for the medical domain, providing tools for handling medical documents and queries.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "medical_qa",
        "retrieval",
        "rag_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Teddy-XiongGZ/MedRAG",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "medical-qa",
        "benchmark",
        "nlp"
      ],
      "id": 230
    },
    {
      "name": "singleCellHaystack",
      "one_line_profile": "Method for finding differentially active genes in single-cell transcriptome data",
      "detailed_description": "A package for predicting differentially active genes in single-cell transcriptome data using a Kullback-Leibler divergence-based method, without relying on clustering of cells.",
      "domains": [
        "H1",
        "H2"
      ],
      "subtask_category": [
        "differential_expression_analysis",
        "single_cell_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/alexisvdb/singleCellHaystack",
      "help_website": [
        "https://alexisvdb.github.io/singleCellHaystack/"
      ],
      "license": "MIT",
      "tags": [
        "single-cell",
        "transcriptomics",
        "gene-expression"
      ],
      "id": 231
    },
    {
      "name": "CiteEval",
      "one_line_profile": "Evaluation framework for citation attribution in LLMs",
      "detailed_description": "A principle-driven citation evaluation framework designed to assess the quality and accuracy of source attribution in Large Language Models, specifically for RAG and scientific writing tasks.",
      "domains": [
        "H2-03"
      ],
      "subtask_category": [
        "citation_evaluation",
        "hallucination_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/amazon-science/CiteEval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "citation",
        "evaluation",
        "llm"
      ],
      "id": 232
    },
    {
      "name": "LTI_Neural_Navigator",
      "one_line_profile": "RAG framework for enhancing LLM factual accuracy",
      "detailed_description": "Implementation of a Retrieval-Augmented Generation approach designed to counter hallucinations and improve factual accuracy in domain-specific queries within private knowledge bases.",
      "domains": [
        "H2-03"
      ],
      "subtask_category": [
        "hallucination_reduction",
        "fact_checking"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/anlp-team/LTI_Neural_Navigator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "hallucination",
        "nlp"
      ],
      "id": 233
    },
    {
      "name": "Argilla",
      "one_line_profile": "Platform for data curation and feedback for LLMs",
      "detailed_description": "A collaboration tool for AI engineers and domain experts to build high-quality datasets for NLP, focusing on data annotation, curation, and reinforcement learning from human feedback (RLHF).",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "data_curation",
        "annotation",
        "rlhf"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/argilla-io/argilla",
      "help_website": [
        "https://docs.argilla.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dataset",
        "annotation",
        "nlp"
      ],
      "id": 234
    },
    {
      "name": "GraphRAG Toolkit",
      "one_line_profile": "Toolkit for building graph-enhanced GenAI applications",
      "detailed_description": "A Python toolkit that facilitates the implementation of Graph Retrieval-Augmented Generation (GraphRAG), enabling the integration of knowledge graphs with LLMs for structured knowledge retrieval.",
      "domains": [
        "H2-03"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "graph_construction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/awslabs/graphrag-toolkit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "graph-rag",
        "knowledge-graph",
        "genai"
      ],
      "id": 235
    },
    {
      "name": "EHRXQA",
      "one_line_profile": "Multi-modal QA dataset for EHR and Chest X-rays",
      "detailed_description": "A multi-modal question answering dataset that combines Electronic Health Records (EHR) with Chest X-ray images, designed for evaluating medical VQA and clinical reasoning models.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "dataset",
        "visual_question_answering"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/baeseongsu/ehrxqa",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ehr",
        "medical-vqa",
        "multimodal"
      ],
      "id": 236
    },
    {
      "name": "Biomedical GraphRAG",
      "one_line_profile": "GraphRAG system for biomedical research",
      "detailed_description": "A specialized Graph Retrieval-Augmented Generation system tailored for biomedical research, enabling structured querying and retrieval from biomedical knowledge sources.",
      "domains": [
        "H2-03"
      ],
      "subtask_category": [
        "biomedical_retrieval",
        "knowledge_discovery"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/benitomartin/biomedical-graphrag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "biomedical",
        "graph-rag",
        "retrieval"
      ],
      "id": 237
    },
    {
      "name": "Cadmus",
      "one_line_profile": "Full-text article retrieval pipeline for biomedical literature",
      "detailed_description": "A pipeline designed to retrieve full-text articles from biomedical literature, facilitating large-scale text mining and systematic reviews.",
      "domains": [
        "H2-03"
      ],
      "subtask_category": [
        "literature_retrieval",
        "text_mining"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/biomedicalinformaticsgroup/cadmus",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "retrieval",
        "biomedical-literature",
        "text-mining"
      ],
      "id": 238
    },
    {
      "name": "BABILong",
      "one_line_profile": "Benchmark for evaluating LLM long-context performance",
      "detailed_description": "A benchmark suite using the 'needle-in-a-haystack' approach to evaluate the ability of Large Language Models to retrieve and process information from long contexts, relevant for RAG system evaluation.",
      "domains": [
        "H2-03"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmark"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/booydar/babilong",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "llm",
        "long-context"
      ],
      "id": 239
    },
    {
      "name": "Virtues",
      "one_line_profile": "Foundation model framework for multiplexed tissue imaging analysis",
      "detailed_description": "A framework for analyzing multiplexed tissue imaging data across molecular, cellular, and tissue scales, enabling clinical diagnostics and biological discovery.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "image_analysis",
        "tissue_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bunnelab/virtues",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "bioimaging",
        "foundation-model",
        "pathology"
      ],
      "id": 240
    },
    {
      "name": "DeerFlow",
      "one_line_profile": "Deep research agent framework",
      "detailed_description": "A community-driven Deep Research framework that combines language models with tools like web search and crawling to automate complex information gathering and research tasks.",
      "domains": [
        "H2-03"
      ],
      "subtask_category": [
        "automated_research",
        "information_gathering"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bytedance/deer-flow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent",
        "research-automation",
        "rag"
      ],
      "id": 241
    },
    {
      "name": "LogicRAG",
      "one_line_profile": "Logic-enhanced Retrieval-Augmented Generation framework",
      "detailed_description": "Source code for LogicRAG, a framework that integrates logical reasoning capabilities into RAG systems to improve answer accuracy and reasoning chains.",
      "domains": [
        "H2-03"
      ],
      "subtask_category": [
        "reasoning",
        "retrieval_augmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chensyCN/LogicRAG",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "logic",
        "reasoning"
      ],
      "id": 242
    },
    {
      "name": "Fast GraphRAG",
      "one_line_profile": "Optimized Graph Retrieval-Augmented Generation library",
      "detailed_description": "A library for efficient and intelligent GraphRAG, designed to adapt to specific use cases and data for enhanced knowledge retrieval and reasoning.",
      "domains": [
        "H2-03"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "graph_rag"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/circlemind-ai/fast-graphrag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-rag",
        "retrieval",
        "knowledge-graph"
      ],
      "id": 243
    },
    {
      "name": "BioASQ2025-UNITOR",
      "one_line_profile": "Biomedical question answering pipeline for BioASQ 2025 challenge",
      "detailed_description": "A modular biomedical question answering pipeline developed for the BioASQ 2025 challenge (UniTor team). It features synthetic snippet generation and multi-task answer generation specifically designed for biomedical text.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "question_answering",
        "biomedical_inference"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/crux82/BioASQ2025-UNITOR",
      "help_website": [],
      "license": null,
      "tags": [
        "bioasq",
        "biomedical-qa",
        "question-answering"
      ],
      "id": 244
    },
    {
      "name": "FactMM-RAG",
      "one_line_profile": "Fact-aware multimodal RAG for radiology report generation",
      "detailed_description": "The official implementation of FactMM-RAG (NAACL 2025), a retrieval-augmented generation system designed to improve the factuality and accuracy of medical radiology report generation by leveraging multimodal evidence.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "report_generation",
        "multimodal_rag",
        "medical_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cxcscmu/FactMM-RAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "radiology-report",
        "rag",
        "multimodal",
        "medical-imaging"
      ],
      "id": 245
    },
    {
      "name": "OLAPH",
      "one_line_profile": "Framework for improving factuality in biomedical long-form QA",
      "detailed_description": "OLAPH is a tool designed to enhance the factuality of biomedical long-form question answering. It focuses on generating accurate and evidence-supported answers in the medical domain.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "question_answering",
        "factuality_checking",
        "biomedical_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dmis-lab/OLAPH",
      "help_website": [],
      "license": null,
      "tags": [
        "biomedical-qa",
        "factuality",
        "nlp"
      ],
      "id": 246
    },
    {
      "name": "SeqTagQA",
      "one_line_profile": "Sequence tagging for biomedical extractive question answering",
      "detailed_description": "A tool for biomedical extractive question answering that utilizes sequence tagging approaches to identify and extract answer spans from biomedical texts.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "question_answering",
        "information_extraction",
        "biomedical_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dmis-lab/SeqTagQA",
      "help_website": [],
      "license": null,
      "tags": [
        "biomedical-qa",
        "sequence-tagging",
        "extractive-qa"
      ],
      "id": 247
    },
    {
      "name": "bioasq-biobert",
      "one_line_profile": "Pre-trained BioBERT models for biomedical question answering",
      "detailed_description": "Provides pre-trained language models (BioBERT based) specifically fine-tuned for biomedical question answering tasks, serving as a foundational resource for BioQA research.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "modeling",
        "question_answering"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/dmis-lab/bioasq-biobert",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "biobert",
        "biomedical-qa",
        "pretrained-model"
      ],
      "id": 248
    },
    {
      "name": "Gilda",
      "one_line_profile": "Grounding of biomedical named entities with contextual disambiguation",
      "detailed_description": "A Python package and service for grounding (entity linking) biomedical named entities in text to standard identifiers (e.g., HGNC, GO, MESH) with contextual disambiguation capabilities.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "entity_grounding",
        "named_entity_recognition",
        "disambiguation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gyorilab/gilda",
      "help_website": [
        "https://gilda.readthedocs.io"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "biomedical-nlp",
        "entity-linking",
        "grounding",
        "bioinformatics"
      ],
      "id": 249
    },
    {
      "name": "Almanac",
      "one_line_profile": "Retrieval-Augmented Language Models for Clinical Medicine",
      "detailed_description": "A framework for retrieving and aggregating clinical evidence from medical databases to support language models in answering medical questions with citation grounding.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "clinical_retrieval",
        "evidence_aggregation",
        "qa_system"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hiesingerlab/almanac-retrieval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "clinical-nlp",
        "rag",
        "medical-qa",
        "evidence-retrieval"
      ],
      "id": 250
    },
    {
      "name": "OntologyRAG",
      "one_line_profile": "Biomedical code mapping with RAG and Ontology Knowledge Graphs",
      "detailed_description": "A tool leveraging Retrieval-Augmented Generation and Ontology Knowledge Graphs to improve biomedical code mapping and normalization tasks.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "ontology_mapping",
        "code_normalization",
        "knowledge_graph_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/iqvianlp/ontologyRAG",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "biomedical-ontology",
        "rag",
        "code-mapping",
        "knowledge-graph"
      ],
      "id": 251
    },
    {
      "name": "ScientificDiscourseTagging",
      "one_line_profile": "Scientific discourse tagging for evidence extraction",
      "detailed_description": "Implementation of a sequence tagging model specifically designed to extract evidence and discourse structure from scientific literature.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "evidence_extraction",
        "discourse_analysis",
        "scientific_text_mining"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jacklxc/ScientificDiscourseTagging",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "scientific-nlp",
        "evidence-extraction",
        "discourse-tagging"
      ],
      "id": 252
    },
    {
      "name": "Confabulations Benchmark",
      "one_line_profile": "Document-based benchmark for evaluating hallucinations in RAG systems",
      "detailed_description": "A benchmark dataset and evaluation framework designed to test Retrieval-Augmented Generation (RAG) systems for hallucinations (confabulations) using human-verified questions and answers based on documents.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "HTML",
      "repo_url": "https://github.com/lechmazur/confabulations",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "hallucination",
        "benchmark",
        "evaluation"
      ],
      "id": 253
    },
    {
      "name": "paperqa-zotero",
      "one_line_profile": "LLM-based tool for querying Zotero library documents",
      "detailed_description": "A tool that integrates Large Language Models with Zotero libraries to answer questions based on stored PDF documents and papers, facilitating literature review and evidence retrieval.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "literature_review",
        "evidence_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lejacobroy/paperqa-zotero",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "zotero",
        "literature-review",
        "rag",
        "qa"
      ],
      "id": 254
    },
    {
      "name": "InfoButtons",
      "one_line_profile": "Context-sensitive clinical decision support links for EHRs",
      "detailed_description": "An implementation of the HL7 Infobutton standard, providing context-sensitive links embedded in Electronic Health Records (EHR) to help clinicians find answers using online health information resources based on patient context.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "clinical_decision_support",
        "information_retrieval"
      ],
      "application_level": "service",
      "primary_language": "Java",
      "repo_url": "https://github.com/logicahealth/InfoButtons",
      "help_website": [],
      "license": null,
      "tags": [
        "ehr",
        "clinical-decision-support",
        "hl7",
        "infobutton"
      ],
      "id": 255
    },
    {
      "name": "Wenzhou Pack Degradation Data",
      "one_line_profile": "Dataset for battery pack degradation prognosis",
      "detailed_description": "A dataset containing randomized battery data for transfer-driven prognosis from battery cells to packs, supporting research in energy storage and battery lifetime prediction.",
      "domains": [
        "M2"
      ],
      "subtask_category": [
        "dataset",
        "prognosis"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/lvdongzhen/Wenzhou-Pack-Degradation-Data",
      "help_website": [],
      "license": null,
      "tags": [
        "battery",
        "dataset",
        "degradation",
        "energy"
      ],
      "id": 256
    },
    {
      "name": "Wenzhou Randomized Battery Data",
      "one_line_profile": "Dataset for battery cumulative lifetime prognostics",
      "detailed_description": "A dataset for battery cumulative lifetime prognostics, bridging laboratory and real-life scenarios, used for developing and validating battery degradation models.",
      "domains": [
        "M2"
      ],
      "subtask_category": [
        "dataset",
        "prognosis"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/lvdongzhen/Wenzhou-Randomized-Battery-Data",
      "help_website": [],
      "license": null,
      "tags": [
        "battery",
        "dataset",
        "lifetime-prediction"
      ],
      "id": 257
    },
    {
      "name": "Manubot",
      "one_line_profile": "Tool for open and automated scientific manuscript writing",
      "detailed_description": "A workflow and set of Python utilities for writing scientific manuscripts using Markdown, automating citations, and generating output formats (HTML, PDF) via continuous integration.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "manuscript_writing",
        "citation_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/manubot/manubot",
      "help_website": [
        "https://manubot.org"
      ],
      "license": "NOASSERTION",
      "tags": [
        "publishing",
        "reproducibility",
        "citation",
        "manuscript"
      ],
      "id": 258
    },
    {
      "name": "PhysioNet ECG Segmentation Data",
      "one_line_profile": "ECG data for deep learning segmentation",
      "detailed_description": "A repository containing human electrocardiogram (ECG) data sourced from PhysioNet, formatted for use in deep learning segmentation examples and signal processing research.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "dataset",
        "signal_processing"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/mathworks/physionet_ECG_segmentation",
      "help_website": [],
      "license": null,
      "tags": [
        "ecg",
        "physionet",
        "dataset",
        "signal-processing"
      ],
      "id": 259
    },
    {
      "name": "MIRA",
      "one_line_profile": "Multimodal medical RAG framework",
      "detailed_description": "A medical RAG framework that fuses image features and retrieved knowledge with dynamic context control to improve factual accuracy in multimodal medical reasoning.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "medical_reasoning",
        "multimodal_rag"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mbzuai-oryx/MIRA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-rag",
        "multimodal",
        "reasoning",
        "healthcare"
      ],
      "id": 260
    },
    {
      "name": "fid-med-eval",
      "one_line_profile": "Evaluation metrics for generative medical imaging",
      "detailed_description": "A library providing feature extraction and evaluation metrics (like FID) specifically adapted for generative medical imaging, addressing issues with standard metrics in the medical domain.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "evaluation",
        "medical_imaging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mckellwoodland/fid-med-eval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-imaging",
        "evaluation",
        "generative-models",
        "fid"
      ],
      "id": 261
    },
    {
      "name": "GraphRAG",
      "one_line_profile": "Graph-based Retrieval-Augmented Generation system",
      "detailed_description": "A modular graph-based Retrieval-Augmented Generation (RAG) system that uses knowledge graphs to improve the retrieval and synthesis of information from unstructured text, highly relevant for scientific literature mining and evidence chaining.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "evidence_chaining"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/graphrag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "knowledge-graph",
        "retrieval",
        "nlp"
      ],
      "id": 262
    },
    {
      "name": "Global Power Plant Database",
      "one_line_profile": "Comprehensive open source database of global power plants",
      "detailed_description": "A comprehensive, open-source database covering approximately 35,000 power plants from 167 countries, including thermal and renewable energy sources, with geolocation and generation data for energy research.",
      "domains": [
        "M2"
      ],
      "subtask_category": [
        "dataset",
        "energy_analysis"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mohittomar2008/Global-Power-Plant-Database",
      "help_website": [],
      "license": null,
      "tags": [
        "energy",
        "power-plants",
        "dataset",
        "geospatial"
      ],
      "id": 263
    },
    {
      "name": "MedCPT",
      "one_line_profile": "Zero-shot biomedical information retrieval model",
      "detailed_description": "A model and library for zero-shot biomedical information retrieval, designed to effectively search and rank biomedical literature and documents.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "information_retrieval",
        "biomedical_search"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ncbi/MedCPT",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "biomedical",
        "information-retrieval",
        "search",
        "nlp"
      ],
      "id": 264
    },
    {
      "name": "llm-graph-builder",
      "one_line_profile": "Tool to construct knowledge graphs from unstructured data",
      "detailed_description": "A tool that leverages Large Language Models to extract entities and relationships from unstructured text to construct Neo4j knowledge graphs, facilitating structured knowledge discovery in scientific domains.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "information_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/neo4j-labs/llm-graph-builder",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "neo4j",
        "llm",
        "extraction"
      ],
      "id": 265
    },
    {
      "name": "neo4j-graphrag-python",
      "one_line_profile": "Neo4j GraphRAG library for Python",
      "detailed_description": "The official Python library for implementing GraphRAG with Neo4j, enabling advanced retrieval strategies over knowledge graphs for scientific and other complex data domains.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "retrieval",
        "graph_rag"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/neo4j/neo4j-graphrag-python",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "neo4j",
        "graph-rag",
        "retrieval",
        "python"
      ],
      "id": 266
    },
    {
      "name": "vocalocator",
      "one_line_profile": "Sound source localization and vocalization attribution tool",
      "detailed_description": "A deep neural network-based tool for sound source localization and vocalization attribution, designed for analyzing audio data in neuroscience and bioacoustics research.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "bioacoustics",
        "localization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/neurostatslab/vocalocator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "neuroscience",
        "bioacoustics",
        "audio-analysis",
        "deep-learning"
      ],
      "id": 267
    },
    {
      "name": "BioASQ-OAQA",
      "one_line_profile": "Biomedical Question Answering system for the BioASQ challenge",
      "detailed_description": "A biomedical question answering system developed by the OAQA group, designed to participate in the BioASQ challenge tasks including biomedical semantic indexing and question answering.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "question_answering",
        "biomedical_ir"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/oaqa/bioasq",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bioasq",
        "question-answering",
        "biomedical-nlp"
      ],
      "id": 268
    },
    {
      "name": "OpenMovement",
      "one_line_profile": "Firmware and software for open source movement sensors",
      "detailed_description": "Source code for firmware and software associated with Open Movement devices, which are miniature sensors used for scientific data collection in movement and clinical studies.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "data_collection",
        "sensor_processing"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/openmovementproject/openmovement",
      "help_website": [
        "https://openmovement.co.uk/"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "wearables",
        "sensors",
        "movement-analysis",
        "firmware"
      ],
      "id": 269
    },
    {
      "name": "MMed-RAG",
      "one_line_profile": "Multimodal RAG system for medical vision-language models",
      "detailed_description": "A versatile multimodal Retrieval-Augmented Generation (RAG) system specifically designed for medical vision-language models, enabling retrieval of relevant medical context from multimodal sources.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "multimodal_rag",
        "medical_qa"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/richard-peng-xia/MMed-RAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-rag",
        "vlm",
        "multimodal"
      ],
      "id": 270
    },
    {
      "name": "RULE",
      "one_line_profile": "Reliable Multimodal RAG for factuality in medical VLMs",
      "detailed_description": "A framework for Reliable Multimodal Retrieval-Augmented Generation (RAG) aimed at improving factuality and reducing hallucinations in Medical Vision Language Models.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "hallucination_mitigation",
        "medical_rag"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/richard-peng-xia/RULE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "factuality",
        "medical-ai",
        "rag"
      ],
      "id": 271
    },
    {
      "name": "LlamaIndex",
      "one_line_profile": "Data framework for connecting custom data sources to large language models",
      "detailed_description": "LlamaIndex is a data framework for building LLM applications. It provides tools for data ingestion, indexing, and retrieval, allowing researchers to connect large language models with domain-specific scientific data (such as EHRs or papers) for RAG applications.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "data_ingestion",
        "retrieval",
        "indexing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/run-llama/llama_index",
      "help_website": [
        "https://docs.llamaindex.ai/"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "llm",
        "data-framework",
        "retrieval"
      ],
      "id": 272
    },
    {
      "name": "Summary of a Haystack",
      "one_line_profile": "Evaluation framework for long-context retrieval and summarization",
      "detailed_description": "Codebase accompanying the research paper on evaluating the ability of LLMs to retrieve and summarize information from large contexts. It serves as a benchmark for RAG and long-context capabilities in scientific text processing.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/salesforce/summary-of-a-haystack",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "long-context"
      ],
      "id": 273
    },
    {
      "name": "Multi-Agent Medical Assistant",
      "one_line_profile": "Multi-agent system for medical diagnostics and research assistance",
      "detailed_description": "A GenAI-powered chatbot designed for healthcare professionals and researchers. It utilizes a multi-agent architecture to perform medical diagnostics and assist with healthcare research tasks, acting as a clinical decision support prototype.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "clinical_diagnosis",
        "research_assistance"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/souvikmajumder26/Multi-Agent-Medical-Assistant",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-agent",
        "diagnosis",
        "healthcare"
      ],
      "id": 274
    },
    {
      "name": "WikiChat",
      "one_line_profile": "Robust RAG system for minimizing hallucination using Wikipedia",
      "detailed_description": "A retrieval-augmented generation system designed to stop LLM hallucinations by grounding responses in a corpus (Wikipedia). It represents a high-quality implementation of reliable RAG for factual queries, developed by Stanford OVAL.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "retrieval",
        "fact_verification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanford-oval/WikiChat",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "hallucination",
        "wikipedia"
      ],
      "id": 275
    },
    {
      "name": "LLM Structured Output Benchmarks",
      "one_line_profile": "Benchmark for evaluating LLM structured data extraction capabilities",
      "detailed_description": "A benchmarking tool to evaluate various frameworks (Instructor, LangChain, etc.) on their ability to generate structured outputs (JSON, etc.) from LLMs. This is crucial for extracting structured scientific data from unstructured text.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "benchmarking",
        "information_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/stephenleo/llm-structured-output-benchmarks",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "structured-output",
        "ner"
      ],
      "id": 276
    },
    {
      "name": "Verina",
      "one_line_profile": "Benchmark for verifiable code and specification generation",
      "detailed_description": "A benchmark enabling comprehensive evaluation of code, specification, and proof generation. While focused on code, verification is a key aspect of reliable AI for science (formal verification).",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "verification",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Lean",
      "repo_url": "https://github.com/sunblaze-ucb/verina",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "verification",
        "benchmark",
        "code-generation"
      ],
      "id": 277
    },
    {
      "name": "RAD",
      "one_line_profile": "Trustworthy retrieval-augmented multi-modal clinical diagnosis",
      "detailed_description": "Official implementation of the NeurIPS 2025 paper 'RAD'. It focuses on improving the reliability and trustworthiness of multi-modal clinical diagnosis using retrieval-augmented generation.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "clinical_diagnosis",
        "multimodal_rag"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tdlhl/RAD",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "clinical-diagnosis",
        "multimodal",
        "rag"
      ],
      "id": 278
    },
    {
      "name": "MNRE",
      "one_line_profile": "Multimodal dataset and code for neural relation extraction",
      "detailed_description": "Resources and code for Multimodal Neural Relation Extraction (MNRE) with visual evidence. Useful for extracting relationships from social media posts or other multimodal data sources in digital health contexts.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "relation_extraction",
        "multimodal_learning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/thecharm/MNRE",
      "help_website": [],
      "license": null,
      "tags": [
        "relation-extraction",
        "multimodal",
        "dataset"
      ],
      "id": 279
    },
    {
      "name": "ROAD Evaluation",
      "one_line_profile": "Benchmark for feature attribution methods in explainable AI",
      "detailed_description": "Source Code of the ROAD benchmark for feature attribution methods. Explainability is critical in clinical AI to understand model decisions and provide evidence.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "evaluation",
        "explainability"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/tleemann/road_evaluation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "xai",
        "benchmark",
        "feature-attribution"
      ],
      "id": 280
    },
    {
      "name": "ROGRAG",
      "one_line_profile": "Robustly Optimized GraphRAG Framework",
      "detailed_description": "A framework for GraphRAG (Graph Retrieval-Augmented Generation) that focuses on robust optimization. It enhances the ability to retrieve and reason over knowledge graphs, suitable for complex scientific query answering.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "retrieval",
        "knowledge_graph"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tpoisonooo/ROGRAG",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "graphrag",
        "optimization",
        "retrieval"
      ],
      "id": 281
    },
    {
      "name": "TrustGraph",
      "one_line_profile": "Tool for generating knowledge graphs to reduce AI hallucinations",
      "detailed_description": "A tool designed to eliminate hallucinations in AI agents by constructing and utilizing knowledge graphs. It supports the creation of reliable RAG systems by grounding generation in structured knowledge.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "knowledge_graph_generation",
        "hallucination_reduction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/trustgraph-ai/trustgraph",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "rag",
        "trustworthiness"
      ],
      "id": 282
    },
    {
      "name": "Ragas",
      "one_line_profile": "Evaluation framework for Retrieval Augmented Generation (RAG) pipelines",
      "detailed_description": "A framework for evaluating RAG pipelines. It provides metrics to assess the retrieval and generation components, helping to ensure the quality and accuracy of RAG-based applications in scientific domains.",
      "domains": [
        "H2",
        "H2-03"
      ],
      "subtask_category": [
        "evaluation",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vibrantlabsai/ragas",
      "help_website": [
        "https://docs.ragas.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "metrics"
      ],
      "id": 283
    },
    {
      "name": "Philter (UCSF)",
      "one_line_profile": "Open-source clinical text de-identification and PHI redaction tool",
      "detailed_description": "A Python-based clinical text de-identification software that removes Protected Health Information (PHI) from clinical notes. It uses a combination of regular expressions and dictionary-based lookups to identify and redact sensitive information.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de_identification",
        "text_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/BCHSI/philter-ucsf",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "nlp",
        "de-identification",
        "phi",
        "clinical-text"
      ],
      "id": 284
    },
    {
      "name": "DiSMed",
      "one_line_profile": "De-identification tool specifically for Spanish medical texts",
      "detailed_description": "A tool designed to de-identify Spanish medical texts, developed by the BIMCV (Medical Imaging Databank of the Valencia Region). It addresses the specific linguistic challenges of Spanish clinical narratives.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de_identification",
        "text_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/BIMCV-CSUSP/DiSMed",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "spanish",
        "medical-records",
        "anonymization"
      ],
      "id": 285
    },
    {
      "name": "Tide",
      "one_line_profile": "Tiled Interactive Display Environment for large-scale scientific visualization",
      "detailed_description": "Software developed by the Blue Brain Project for clustering display screens to create large-scale, high-resolution interactive visualization environments, commonly used for visualizing complex neurological data.",
      "domains": [
        "Neuroscience",
        "Visualization"
      ],
      "subtask_category": [
        "scientific_visualization"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/BlueBrain/Tide",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "visualization",
        "neuroscience",
        "display-wall"
      ],
      "id": 286
    },
    {
      "name": "FES (Finite Element Solution)",
      "one_line_profile": "Global tide model based on hydrodynamic equations and data assimilation",
      "detailed_description": "The Finite Element Solution (FES) tide model code, developed by CNES/LEGOS, used for computing global ocean tides. It is essential for oceanography and satellite altimetry data correction.",
      "domains": [
        "Earth Science",
        "Oceanography"
      ],
      "subtask_category": [
        "scientific_modeling",
        "simulation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/CNES/aviso-fes",
      "help_website": [
        "https://www.aviso.altimetry.fr/en/data/products/auxiliary-products/global-tide-fes.html"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "tides",
        "oceanography",
        "finite-element",
        "modeling"
      ],
      "id": 287
    },
    {
      "name": "DSA-WSI-DeID",
      "one_line_profile": "Workflow for redacting PHI from Whole Slide Images (WSI)",
      "detailed_description": "A tool integrated with the Digital Slide Archive ecosystem to detect and redact Protected Health Information (PHI) from the label regions of Whole Slide Images (pathology slides).",
      "domains": [
        "H2",
        "H2-04",
        "Pathology"
      ],
      "subtask_category": [
        "de_identification",
        "image_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/DigitalSlideArchive/DSA-WSI-DeID",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "wsi",
        "pathology",
        "de-identification",
        "medical-imaging"
      ],
      "id": 288
    },
    {
      "name": "TMD Matlab Toolbox",
      "one_line_profile": "Tide Model Driver (TMD) for accessing polar tide models",
      "detailed_description": "A Matlab toolbox provided by Earth & Space Research (ESR) to access specific polar tide models, output harmonic constants, and make tidal predictions. It is a standard tool in polar oceanography.",
      "domains": [
        "Earth Science",
        "Oceanography"
      ],
      "subtask_category": [
        "scientific_modeling",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/EarthAndSpaceResearch/TMD_Matlab_Toolbox_v2.5",
      "help_website": [
        "https://www.esr.org/research/polar-tide-models/tmd-software/"
      ],
      "license": "MIT",
      "tags": [
        "tides",
        "matlab",
        "oceanography",
        "polar-science"
      ],
      "id": 289
    },
    {
      "name": "pii-codex",
      "one_line_profile": "Tool for detecting, categorizing, and assessing PII severity",
      "detailed_description": "A research package designed to detect Personally Identifiable Information (PII) in text and assess its severity. It provides a framework for evaluating PII detection tools and managing data privacy risks.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de_identification",
        "risk_assessment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EdyVision/pii-codex",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "pii",
        "privacy",
        "nlp",
        "security"
      ],
      "id": 290
    },
    {
      "name": "noaa_coops",
      "one_line_profile": "Python wrapper for NOAA CO-OPS Tides & Currents Data API",
      "detailed_description": "A Python library that facilitates the retrieval of oceanographic data (tides, currents, water levels) from the NOAA CO-OPS API, enabling data acquisition for ocean science research.",
      "domains": [
        "Earth Science",
        "Oceanography"
      ],
      "subtask_category": [
        "data_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/GClunies/noaa_coops",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "noaa",
        "oceanography",
        "tides",
        "data-mining"
      ],
      "id": 291
    },
    {
      "name": "eo-tides",
      "one_line_profile": "Tide modelling tools for satellite Earth observation analysis",
      "detailed_description": "A Python toolkit developed by Geoscience Australia for modeling tides specifically in the context of large-scale satellite Earth observation (EO) data analysis, helping to correct or analyze tidal effects in satellite imagery.",
      "domains": [
        "Earth Science",
        "Remote Sensing"
      ],
      "subtask_category": [
        "scientific_modeling",
        "data_correction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/GeoscienceAustralia/eo-tides",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tides",
        "earth-observation",
        "satellite",
        "geoscience"
      ],
      "id": 292
    },
    {
      "name": "Dataflow DLP De-identification",
      "one_line_profile": "Scalable data tokenization workflow using Cloud Dataflow and DLP",
      "detailed_description": "A reference implementation and tool for creating a scalable de-identification pipeline using Google Cloud Dataflow and Cloud DLP. It is designed for processing large datasets containing sensitive information (PII/PHI) in a compliant manner.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de_identification",
        "data_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Java",
      "repo_url": "https://github.com/GoogleCloudPlatform/dlp-dataflow-deidentification",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "cloud-dlp",
        "de-identification",
        "tokenization",
        "dataflow"
      ],
      "id": 293
    },
    {
      "name": "Google Healthcare De-id Tools",
      "one_line_profile": "Tools for de-identifying medical records (DICOM/FHIR) on GCP",
      "detailed_description": "A collection of tools and scripts provided by Google Cloud Platform to facilitate the de-identification of healthcare data standards like DICOM and FHIR, ensuring compliance with regulations like HIPAA.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de_identification",
        "data_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/GoogleCloudPlatform/healthcare-deid",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dicom",
        "fhir",
        "healthcare",
        "de-identification"
      ],
      "id": 294
    },
    {
      "name": "Kitware DICOM Anonymizer",
      "one_line_profile": "Tool to anonymize DICOM files according to DICOM standards",
      "detailed_description": "A Python-based tool developed by Kitware Medical to anonymize DICOM files. It allows for customizable replacement of DICOM tags to ensure patient privacy while maintaining data integrity for research.",
      "domains": [
        "H2",
        "H2-04",
        "Medical Imaging"
      ],
      "subtask_category": [
        "de_identification",
        "image_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/KitwareMedical/dicom-anonymizer",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "dicom",
        "anonymization",
        "medical-imaging",
        "kitware"
      ],
      "id": 295
    },
    {
      "name": "MIDRC Deidentifier",
      "one_line_profile": "Medical imaging de-identification pipeline for MIDRC",
      "detailed_description": "A comprehensive de-identification pipeline developed by Stanford and Penn for the Medical Imaging and Data Resource Center (MIDRC). It handles the cleaning and redaction of DICOM metadata and pixel data for large-scale public datasets.",
      "domains": [
        "H2",
        "H2-04",
        "Medical Imaging"
      ],
      "subtask_category": [
        "de_identification",
        "workflow_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/MIDRC/Stanford_Penn_MIDRC_Deidentifier",
      "help_website": [
        "https://www.midrc.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "midrc",
        "dicom",
        "de-identification",
        "medical-imaging"
      ],
      "id": 296
    },
    {
      "name": "CVD Prevent Tool",
      "one_line_profile": "Pipeline for linking and curating cardiovascular disease audit data",
      "detailed_description": "A data processing pipeline used to link and curate CVD PREVENT audit data with Hospital Episode Statistics (HES) and death registration data, facilitating analysis and publication for public health auditing.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "data_curation",
        "data_linkage",
        "audit"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/NHSDigital/cvd-prevent-tool",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nhs",
        "cardiovascular-disease",
        "audit",
        "data-pipeline"
      ],
      "id": 297
    },
    {
      "name": "OpenSanitizer",
      "one_line_profile": "Privacy-focused module for scrubbing PII/PHI from screen data",
      "detailed_description": "A module designed to detect and redact Personally Identifiable Information (PII) and Protected Health Information (PHI) from screen data and user actions, supporting privacy compliance in data collection.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de-identification",
        "pii_redaction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenAdaptAI/OpenSanitizer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "privacy",
        "pii",
        "phi",
        "redaction"
      ],
      "id": 298
    },
    {
      "name": "SyferText",
      "one_line_profile": "Privacy-preserving NLP framework",
      "detailed_description": "A library for performing Natural Language Processing (NLP) tasks while preserving data privacy, enabling secure text analysis and processing in compliance with privacy standards.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "privacy_preserving_nlp",
        "text_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenMined/SyferText",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "privacy",
        "secure-computation",
        "openmined"
      ],
      "id": 299
    },
    {
      "name": "deidentify",
      "one_line_profile": "HIPAA-compliant PHI de-identification library",
      "detailed_description": "A JavaScript library for de-identifying Protected Health Information (PHI) in accordance with the HIPAA Privacy Rule, suitable for clinical data processing in web environments.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de-identification",
        "compliance"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/Planeshifter/deidentify",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "hipaa",
        "phi",
        "de-identification",
        "javascript"
      ],
      "id": 300
    },
    {
      "name": "RSNA DICOM Anonymizer",
      "one_line_profile": "DICOM anonymization tool by RSNA",
      "detailed_description": "A tool developed by the Radiological Society of North America (RSNA) to anonymize DICOM medical imaging files, ensuring patient privacy for research and data sharing.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "image_anonymization",
        "dicom_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RSNA/anonymizer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dicom",
        "rsna",
        "medical-imaging",
        "anonymization"
      ],
      "id": 301
    },
    {
      "name": "PteRedactyl",
      "one_line_profile": "Clinical free-text PII redaction tool",
      "detailed_description": "A Python module built on Presidio for redacting Personally Identifiable Information (PII) specifically in clinical free-text, designed for ease of use in healthcare data de-identification workflows.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "text_redaction",
        "clinical_nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SETT-Centre-Data-and-AI/PteRedactyl",
      "help_website": [],
      "license": null,
      "tags": [
        "clinical-text",
        "pii",
        "redaction",
        "presidio"
      ],
      "id": 302
    },
    {
      "name": "DicomAnonymizer",
      "one_line_profile": "Windows application for DICOM anonymization",
      "detailed_description": "A Windows application that anonymizes DICOM files and generates PNG and TIF versions, facilitating the safe sharing and visualization of medical imaging data.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "image_anonymization",
        "format_conversion"
      ],
      "application_level": "solver",
      "primary_language": "C#",
      "repo_url": "https://github.com/SoapySoftware/DicomAnonymizer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dicom",
        "windows",
        "anonymization",
        "medical-imaging"
      ],
      "id": 303
    },
    {
      "name": "Canonym",
      "one_line_profile": "Data anonymization package by Statistics Canada",
      "detailed_description": "A Python package for data anonymization developed by Statistics Canada, providing tools to protect confidentiality in statistical datasets.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "data_anonymization",
        "statistical_disclosure_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/StatCan/Canonym",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "statistics-canada",
        "anonymization",
        "privacy"
      ],
      "id": 304
    },
    {
      "name": "Medical Image De-identification",
      "one_line_profile": "Comprehensive tool for medical image de-identification",
      "detailed_description": "A tool designed for the de-identification of medical imaging data, ensuring patient privacy and compliance with data protection regulations for research datasets.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "image_de-identification",
        "privacy_protection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TIO-IKIM/medical_image_deidentification",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "medical-imaging",
        "de-identification",
        "privacy"
      ],
      "id": 305
    },
    {
      "name": "MedGuard",
      "one_line_profile": "HIPAA compliance library for healthcare LLM agents",
      "detailed_description": "A production-grade Python library that ensures HIPAA compliance for large language model (LLM) agents in healthcare, providing security and privacy frameworks for AI workflows.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "compliance",
        "llm_security",
        "hipaa"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/The-Swarm-Corporation/MedGuard",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "healthcare",
        "hipaa",
        "security"
      ],
      "id": 306
    },
    {
      "name": "Excel-Anonymizer",
      "one_line_profile": "Script for anonymizing Excel datasets",
      "detailed_description": "A Python script that anonymizes Excel files by replacing sensitive data with synthesized new data, useful for preparing datasets for sharing or analysis.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "data_anonymization",
        "synthetic_data_generation"
      ],
      "application_level": "script",
      "primary_language": "Python",
      "repo_url": "https://github.com/Welding-Torch/Excel-Anonymizer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "excel",
        "anonymization",
        "synthetic-data"
      ],
      "id": 307
    },
    {
      "name": "dicomedit",
      "one_line_profile": "JavaScript DICOM modification and anonymization library",
      "detailed_description": "A JavaScript library for modifying and anonymizing DICOM tags, suitable for use in web-based medical imaging applications and Node.js environments.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "dicom_editing",
        "anonymization"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/WoonchanCho/dicomedit",
      "help_website": [],
      "license": null,
      "tags": [
        "dicom",
        "javascript",
        "anonymization"
      ],
      "id": 308
    },
    {
      "name": "DICAT",
      "one_line_profile": "Tool to anonymize DICOM data headers",
      "detailed_description": "A Python-based tool designed to anonymize DICOM data headers, supporting the de-identification process for medical imaging research.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "deidentification",
        "medical_imaging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aces/DICAT",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "dicom",
        "anonymization",
        "medical-imaging"
      ],
      "id": 309
    },
    {
      "name": "bert-deid",
      "one_line_profile": "Patient notes de-identification using pre-trained BERT",
      "detailed_description": "A library for de-identifying clinical patient notes using pre-trained BERT models, developed by researchers associated with PhysioNet/MIMIC.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "deidentification",
        "clinical_nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/alistairewj/bert-deid",
      "help_website": [],
      "license": null,
      "tags": [
        "bert",
        "nlp",
        "clinical-notes",
        "deid"
      ],
      "id": 310
    },
    {
      "name": "ARX",
      "one_line_profile": "Comprehensive open source data anonymization tool",
      "detailed_description": "A comprehensive tool for data anonymization supporting various techniques like k-anonymity, l-diversity, t-closeness, and differential privacy, with risk analysis capabilities.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "deidentification",
        "privacy_risk_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/arx-deidentifier/arx",
      "help_website": [
        "https://arx.deidentifier.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "anonymization",
        "privacy",
        "k-anonymity",
        "differential-privacy"
      ],
      "id": 311
    },
    {
      "name": "ControlSystemIdentification.jl",
      "one_line_profile": "System Identification toolbox for Julia",
      "detailed_description": "A system identification toolbox for Julia, compatible with ControlSystems.jl, used for estimating models of dynamic systems from input-output data.",
      "domains": [
        "Physics",
        "Engineering"
      ],
      "subtask_category": [
        "system_identification",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/baggepinnen/ControlSystemIdentification.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "system-identification",
        "control-theory",
        "julia"
      ],
      "id": 312
    },
    {
      "name": "dicognito",
      "one_line_profile": "Library and CLI for anonymizing DICOM files",
      "detailed_description": "A Python library and command-line tool for anonymizing DICOM files, ensuring patient privacy in medical imaging datasets.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "deidentification",
        "medical_imaging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/blairconrad/dicognito",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dicom",
        "anonymization",
        "cli"
      ],
      "id": 313
    },
    {
      "name": "Maskwise",
      "one_line_profile": "Sensitive data redaction for LLM training datasets",
      "detailed_description": "A tool powered by Microsoft Presidio to detect, redact, mask, and anonymize sensitive data across text, images, and structured data, specifically for LLM training datasets.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "deidentification",
        "data_cleaning"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/bluewave-labs/maskwise",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "pii",
        "redaction",
        "presidio"
      ],
      "id": 314
    },
    {
      "name": "Tide Model Driver",
      "one_line_profile": "Tide Model Driver for MATLAB",
      "detailed_description": "A MATLAB toolbox for accessing and using ocean tide models, essential for oceanographic and geophysical research.",
      "domains": [
        "Earth Science",
        "Oceanography"
      ],
      "subtask_category": [
        "modeling",
        "simulation"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/chadagreene/Tide-Model-Driver",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tides",
        "oceanography",
        "matlab"
      ],
      "id": 315
    },
    {
      "name": "dicom-anon",
      "one_line_profile": "Python DICOM Anonymizer",
      "detailed_description": "A Python tool for anonymizing DICOM files, developed by the Department of Biomedical and Health Informatics at CHOP.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "deidentification",
        "medical_imaging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chop-dbhi/dicom-anon",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "dicom",
        "anonymization",
        "chop"
      ],
      "id": 316
    },
    {
      "name": "dicom-pipeline",
      "one_line_profile": "Pipeline for reviewing and anonymizing DICOM studies",
      "detailed_description": "An automated pipeline for reviewing, anonymizing, and publishing research DICOM studies, developed by CHOP.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "workflow_management",
        "deidentification"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/chop-dbhi/dicom-pipeline",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "dicom",
        "pipeline",
        "research-data-management"
      ],
      "id": 317
    },
    {
      "name": "image-deid-etl",
      "one_line_profile": "ETL pipeline for DICOM image de-identification and conversion",
      "detailed_description": "A tool developed by the Center for Data Driven Discovery in Biomedicine (D3b) to assist with reading DICOM images from Orthanc, converting them to anonymized NIfTI images, and uploading them to Flywheel, facilitating secure medical imaging research workflows.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de-identification",
        "image_conversion",
        "etl"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/d3b-center/image-deid-etl",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dicom",
        "de-identification",
        "nifti",
        "medical-imaging"
      ],
      "id": 318
    },
    {
      "name": "Amnesia",
      "one_line_profile": "Data anonymization tool for k-anonymity and km-anonymity",
      "detailed_description": "Amnesia is a data anonymization tool that transforms relational and transactional data to statistical guarantees (like k-anonymity and km-anonymity) by generalizing or suppressing values, allowing data sharing while preserving privacy.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "anonymization",
        "privacy_preservation"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/dTsitsigkos/Amnesia",
      "help_website": [
        "https://amnesia.openaire.eu/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "anonymization",
        "k-anonymity",
        "privacy",
        "gdpr"
      ],
      "id": 319
    },
    {
      "name": "TIDE",
      "one_line_profile": "General Toolbox for Identifying Object Detection Errors",
      "detailed_description": "A general toolbox for analyzing the sources of error in object detection and instance segmentation algorithms. It provides a detailed breakdown of error types (e.g., classification, localization, background) to help researchers improve computer vision models.",
      "domains": [
        "Computer Vision"
      ],
      "subtask_category": [
        "error_analysis",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dbolya/tide",
      "help_website": [
        "https://dbolya.github.io/tide/"
      ],
      "license": "MIT",
      "tags": [
        "object-detection",
        "error-analysis",
        "computer-vision",
        "evaluation"
      ],
      "id": 320
    },
    {
      "name": "deid2-runtime",
      "one_line_profile": "Runtime environment for NIST De-ID2 competition",
      "detailed_description": "The code execution runtime environment designed for the NIST De-ID2 competition, providing a standardized containerized setup for running and evaluating de-identification algorithms on clinical text data.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de-identification",
        "evaluation_environment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/drivendataorg/deid2-runtime",
      "help_website": [],
      "license": null,
      "tags": [
        "de-identification",
        "nlp",
        "clinical-text",
        "benchmarking"
      ],
      "id": 321
    },
    {
      "name": "SlicerBatchAnonymize",
      "one_line_profile": "3D Slicer extension for batch DICOM anonymization",
      "detailed_description": "A 3D Slicer extension designed to perform batch anonymization of DICOM images, enabling researchers to process large datasets of medical imaging for privacy compliance directly within the Slicer environment.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "anonymization",
        "image_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hina-shah/SlicerBatchAnonymize",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "3d-slicer",
        "dicom",
        "anonymization",
        "medical-imaging"
      ],
      "id": 322
    },
    {
      "name": "pygtide",
      "one_line_profile": "Python wrapper for ETERNA PREDICT to compute gravitational tides",
      "detailed_description": "A Python module and wrapper for the ETERNA PREDICT program, used to compute gravitational tides on Earth, supporting geophysics and earth science research.",
      "domains": [
        "Earth Science",
        "Geophysics"
      ],
      "subtask_category": [
        "simulation",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/hydrogeoscience/pygtide",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "tides",
        "geophysics",
        "gravity",
        "eterna"
      ],
      "id": 323
    },
    {
      "name": "PySolid",
      "one_line_profile": "Python wrapper for solid Earth tides calculation",
      "detailed_description": "A Python wrapper for computing solid Earth tides, used in geodetic and geophysical applications to model deformations caused by tidal forces.",
      "domains": [
        "Earth Science",
        "Geophysics"
      ],
      "subtask_category": [
        "modeling",
        "simulation"
      ],
      "application_level": "library",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/insarlab/PySolid",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "solid-earth-tides",
        "geodesy",
        "geophysics",
        "deformation"
      ],
      "id": 324
    },
    {
      "name": "presidio-cli",
      "one_line_profile": "CLI tool for PII analysis using Microsoft Presidio",
      "detailed_description": "A command-line interface tool developed by Insights Engineering to analyze text for Personally Identifiable Information (PII) entities using the Microsoft Presidio framework, facilitating integration into data processing pipelines.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "pii_detection",
        "de-identification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/insightsengineering/presidio-cli",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "presidio",
        "pii",
        "nlp",
        "cli"
      ],
      "id": 325
    },
    {
      "name": "DICOMClient",
      "one_line_profile": "DICOM utilities for anonymizing, viewing, and uploading",
      "detailed_description": "A set of Java-based utilities for handling DICOM files, including functionality for anonymization, viewing, and uploading to PACS systems, supporting medical imaging data management.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "anonymization",
        "data_management",
        "visualization"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/irrer/DICOMClient",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "dicom",
        "anonymization",
        "pacs",
        "medical-imaging"
      ],
      "id": 326
    },
    {
      "name": "deidentification",
      "one_line_profile": "Tool to deidentify names and gender-specific pronouns",
      "detailed_description": "A Python tool designed to de-identify text by detecting and replacing people's names and gender-specific pronouns, useful for basic text anonymization tasks.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de-identification",
        "text_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jftuga/deidentification",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "anonymization",
        "privacy",
        "text-mining"
      ],
      "id": 327
    },
    {
      "name": "CDISC-SDTM-deidentify-SAS-phuse",
      "one_line_profile": "SAS macros for de-identifying CDISC SDTM data",
      "detailed_description": "A collection of SAS macros to de-identify CDISC SDTM clinical trial data according to PhUSE rules, supporting regulatory compliance and data sharing in clinical research.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de-identification",
        "compliance"
      ],
      "application_level": "library",
      "primary_language": "SAS",
      "repo_url": "https://github.com/jmangori/CDISC-SDTM-deidentify-SAS-phuse",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sas",
        "cdisc",
        "sdtm",
        "clinical-trials",
        "phuse"
      ],
      "id": 328
    },
    {
      "name": "CTP",
      "one_line_profile": "Clinical Trial Processor for medical imaging data management and de-identification",
      "detailed_description": "A highly configurable, extensible application designed for processing and routing medical imaging data. It is widely used in clinical trials for secure transfer and comprehensive de-identification of DICOM objects.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de_identification",
        "data_transfer",
        "dicom_processing"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/johnperry/CTP",
      "help_website": [
        "http://mircwiki.rsna.org/index.php?title=CTP_The_Clinical_Trial_Processor"
      ],
      "license": null,
      "tags": [
        "dicom",
        "de-identification",
        "clinical-trials",
        "medical-imaging"
      ],
      "id": 329
    },
    {
      "name": "DicomAnonymizerTool",
      "one_line_profile": "Command-line utility for DICOM de-identification",
      "detailed_description": "A standalone command-line tool that invokes the MIRC DICOM Anonymizer engine on individual files, facilitating batch processing and automation of medical image anonymization tasks.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de_identification",
        "dicom_processing"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/johnperry/DicomAnonymizerTool",
      "help_website": [],
      "license": null,
      "tags": [
        "dicom",
        "anonymization",
        "cli"
      ],
      "id": 330
    },
    {
      "name": "Tools for Health Data Anonymization",
      "one_line_profile": "Tools for anonymizing FHIR health data",
      "detailed_description": "A comprehensive set of tools designed to facilitate the anonymization of health data, with a specific focus on the FHIR standard. It supports configuration-based anonymization rules to ensure compliance and privacy.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de_identification",
        "fhir_processing"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/microsoft/Tools-for-Health-Data-Anonymization",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fhir",
        "anonymization",
        "health-data",
        "privacy"
      ],
      "id": 331
    },
    {
      "name": "Presidio Evaluation Toolkit",
      "one_line_profile": "End-to-end toolkit for evaluating PII detection models",
      "detailed_description": "A toolkit designed to streamline the evaluation of PII detection frameworks, specifically Presidio. It integrates with Azure Language Service and AzureML to provide end-to-end assessment pipelines for different PII recognizers.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "pii_detection"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/dstoolkit-e2e-presidio-evaluation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation",
        "pii",
        "presidio",
        "nlp"
      ],
      "id": 332
    },
    {
      "name": "Presidio",
      "one_line_profile": "Context-aware PII detection and anonymization framework",
      "detailed_description": "An open-source framework for detecting, redacting, masking, and anonymizing sensitive data (PII) in text and images. It utilizes NLP and pattern matching to provide customizable and context-aware PII recognition.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de_identification",
        "pii_detection",
        "text_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/presidio",
      "help_website": [
        "https://microsoft.github.io/presidio/"
      ],
      "license": "MIT",
      "tags": [
        "pii",
        "de-identification",
        "nlp",
        "privacy",
        "security"
      ],
      "id": 333
    },
    {
      "name": "Presidio Research",
      "one_line_profile": "Research library for developing Presidio PII recognizers",
      "detailed_description": "A package dedicated to data science tasks for developing and evaluating new PII recognizers for the Presidio framework. It facilitates the creation of datasets, training of models, and benchmarking of detection performance.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "model_development",
        "model_evaluation",
        "pii_detection"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/microsoft/presidio-research",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "research",
        "pii",
        "evaluation",
        "data-science"
      ],
      "id": 334
    },
    {
      "name": "DICOMAnonymizer",
      "one_line_profile": "Multi-threaded anonymizer for DICOM files implementing DICOM PS 3.15 AnnexE",
      "detailed_description": "A C++ based tool designed for the anonymization of DICOM medical imaging files. It implements the standards set forth in DICOM PS 3.15 Annex E, ensuring compliance with de-identification protocols suitable for clinical and research data sharing.",
      "domains": [
        "H2",
        "H2-04",
        "Medical Imaging"
      ],
      "subtask_category": [
        "de-identification",
        "anonymization",
        "data_cleaning"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/mmiv-center/DICOMAnonymizer",
      "help_website": [],
      "license": "Unlicense",
      "tags": [
        "dicom",
        "anonymization",
        "medical-imaging",
        "cpp"
      ],
      "id": 335
    },
    {
      "name": "ttide_py",
      "one_line_profile": "Python implementation of the T_Tide harmonic tidal analysis package",
      "detailed_description": "A direct conversion of the classic T_Tide MATLAB toolbox to Python. It performs classical harmonic analysis of tidal currents and sea levels, widely used in oceanography and geophysics for analyzing tidal data.",
      "domains": [
        "Oceanography",
        "Geophysics"
      ],
      "subtask_category": [
        "tidal_analysis",
        "harmonic_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/moflaher/ttide_py",
      "help_website": [],
      "license": null,
      "tags": [
        "tides",
        "oceanography",
        "harmonic-analysis",
        "python"
      ],
      "id": 336
    },
    {
      "name": "ehr_deidentification",
      "one_line_profile": "De-identification of medical notes using transformer architectures",
      "detailed_description": "A Python-based tool leveraging transformer models (like BERT/RoBERTa) to perform robust de-identification of electronic health record (EHR) notes. It focuses on identifying and masking sensitive entities to ensure patient privacy in clinical text data.",
      "domains": [
        "H2",
        "H2-04",
        "Natural Language Processing"
      ],
      "subtask_category": [
        "de-identification",
        "ner",
        "clinical_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/obi-ml-public/ehr_deidentification",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ehr",
        "transformers",
        "de-identification",
        "medical-nlp"
      ],
      "id": 337
    },
    {
      "name": "svs-deidentifier",
      "one_line_profile": "Tool to strip identifying labels from Aperio SVS whole slide images",
      "detailed_description": "A Python utility specifically designed for digital pathology. It removes potentially identifying label and macro images from Aperio SVS whole slide image files, ensuring that pathological slides can be shared or analyzed without compromising patient anonymity.",
      "domains": [
        "H2",
        "H2-04",
        "Digital Pathology"
      ],
      "subtask_category": [
        "image_anonymization",
        "metadata_stripping"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/pearcetm/svs-deidentifier",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pathology",
        "svs",
        "whole-slide-imaging",
        "anonymization"
      ],
      "id": 338
    },
    {
      "name": "EDF_deidentify_toolbox",
      "one_line_profile": "Matlab and Python toolbox for de-identifying EDF (EEG) files",
      "detailed_description": "A toolbox developed by the Prerau Lab for de-identifying European Data Format (EDF) files, commonly used for EEG and sleep data. It allows researchers to strip headers and metadata to share physiological data compliantly.",
      "domains": [
        "H2",
        "H2-04",
        "Neuroscience"
      ],
      "subtask_category": [
        "signal_processing",
        "de-identification",
        "data_cleaning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/preraulab/EDF_deidentify_toolbox",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "eeg",
        "edf",
        "sleep-research",
        "de-identification"
      ],
      "id": 339
    },
    {
      "name": "Mist",
      "one_line_profile": "Adversarial watermarking tool to protect images from diffusion model mimicry",
      "detailed_description": "A preprocessing tool that applies adversarial watermarks to images (artworks) to disrupt the learning process of latent diffusion models (like Stable Diffusion). It is used in AI security and data protection research to prevent unauthorized style mimicry.",
      "domains": [
        "Computer Vision",
        "AI Security"
      ],
      "subtask_category": [
        "adversarial_attack",
        "data_protection",
        "image_preprocessing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/psyker-team/mist",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "adversarial-ml",
        "watermarking",
        "diffusion-models",
        "protection"
      ],
      "id": 340
    },
    {
      "name": "Mist-v2",
      "one_line_profile": "Improved watermarking tool for protecting artwork from synthetic mimicry",
      "detailed_description": "The second version of the Mist tool, providing enhanced adversarial watermarking capabilities to protect human artworks from being effectively used to train synthetic media generation models.",
      "domains": [
        "Computer Vision",
        "AI Security"
      ],
      "subtask_category": [
        "adversarial_attack",
        "data_protection",
        "image_preprocessing"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/psyker-team/mist-v2",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "adversarial-ml",
        "watermarking",
        "diffusion-models",
        "protection"
      ],
      "id": 341
    },
    {
      "name": "pydicom-deid",
      "one_line_profile": "Best-effort anonymization library for medical images (DICOM) in Python",
      "detailed_description": "A Python library built on top of pydicom for de-identifying DICOM files. It provides a framework for defining anonymization recipes and cleaning metadata to support medical imaging research and compliance.",
      "domains": [
        "H2",
        "H2-04",
        "Medical Imaging"
      ],
      "subtask_category": [
        "anonymization",
        "metadata_cleaning",
        "dicom_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pydicom/deid",
      "help_website": [
        "https://pydicom.github.io/deid/"
      ],
      "license": "MIT",
      "tags": [
        "dicom",
        "anonymization",
        "medical-imaging",
        "python"
      ],
      "id": 342
    },
    {
      "name": "dicom-cleaner",
      "one_line_profile": "Tool for detecting and cleaning burned-in pixels in DICOM images using OCR",
      "detailed_description": "A development tool associated with pydicom for detecting and removing burned-in text (pixel data) from DICOM images using Optical Character Recognition (OCR), addressing a critical gap in metadata-only anonymization.",
      "domains": [
        "H2",
        "H2-04",
        "Medical Imaging"
      ],
      "subtask_category": [
        "ocr",
        "pixel_anonymization",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "Limbo",
      "repo_url": "https://github.com/pydicom/dicom-cleaner",
      "help_website": [],
      "license": null,
      "tags": [
        "dicom",
        "ocr",
        "burned-in-text",
        "anonymization"
      ],
      "id": 343
    },
    {
      "name": "Pytides",
      "one_line_profile": "Python package for tidal analysis and prediction",
      "detailed_description": "A Python library for analyzing and predicting tides. It allows for the decomposition of tide levels into constituent components and the prediction of future tide heights, used in oceanographic research.",
      "domains": [
        "Oceanography"
      ],
      "subtask_category": [
        "tidal_prediction",
        "harmonic_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sam-cox/pytides",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tides",
        "oceanography",
        "prediction",
        "python"
      ],
      "id": 344
    },
    {
      "name": "Cumulus ETL",
      "one_line_profile": "ETL pipeline for extracting, de-identifying, and loading FHIR clinical data",
      "detailed_description": "A tool designed to extract FHIR data from healthcare systems, transform it using NLP and de-identification tools, and load it into a SQL database for research and analysis. Developed by the SMART on FHIR team.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "data_processing",
        "de_identification",
        "nlp"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/smart-on-fhir/cumulus-etl",
      "help_website": [
        "https://github.com/smart-on-fhir/cumulus-etl"
      ],
      "license": "Apache-2.0",
      "tags": [
        "fhir",
        "etl",
        "de-identification",
        "nlp",
        "clinical-data"
      ],
      "id": 345
    },
    {
      "name": "Stanford MIRC-CTP Scripts",
      "one_line_profile": "DICOM anonymization scripts based on MIRC CTP",
      "detailed_description": "A set of scripts and Docker configurations used by Stanford IRT/RIT for anonymizing medical imaging data (DICOM) using the MIRC Clinical Trial Processor (CTP).",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de_identification",
        "image_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Dockerfile",
      "repo_url": "https://github.com/susom/mirc-ctp",
      "help_website": [
        "https://github.com/susom/mirc-ctp"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dicom",
        "anonymization",
        "medical-imaging",
        "ctp"
      ],
      "id": 346
    },
    {
      "name": "Tideline",
      "one_line_profile": "Visualization library for diabetes data timelines",
      "detailed_description": "A JavaScript library developed by Tidepool for visualizing diabetes device data (e.g., blood glucose, bolus, basal rates) in a timeline format, supporting clinical data analysis.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "scientific_visualization",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/tidepool-org/tideline",
      "help_website": [
        "https://developer.tidepool.org/tideline/"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "diabetes",
        "visualization",
        "clinical-data",
        "health-informatics"
      ],
      "id": 347
    },
    {
      "name": "deidentifyr",
      "one_line_profile": "R package for de-identifying datasets with PII",
      "detailed_description": "An R package designed to identify and remove personally identifiable information (PII) from datasets, supporting data privacy compliance in research.",
      "domains": [
        "H2",
        "H2-04"
      ],
      "subtask_category": [
        "de_identification",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/wilkox/deidentifyr",
      "help_website": [
        "https://github.com/wilkox/deidentifyr"
      ],
      "license": "NOASSERTION",
      "tags": [
        "r-package",
        "de-identification",
        "privacy",
        "pii"
      ],
      "id": 348
    },
    {
      "name": "M3D",
      "one_line_profile": "Multi-modal large language model for 3D medical image analysis",
      "detailed_description": "A comprehensive suite for 3D medical image analysis, featuring a multi-modal large language model (M3D-LaMed), a massive dataset (M3D-Data), and a benchmark (M3D-Bench) for tasks like report generation and VQA.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "medical_vqa",
        "report_generation",
        "3d_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/BAAI-DCAI/M3D",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "3d-medical-imaging",
        "multimodal-llm",
        "foundation-model"
      ],
      "id": 349
    },
    {
      "name": "Chinese-LLaVA-Med",
      "one_line_profile": "Large Chinese language-and-vision assistant for biomedicine",
      "detailed_description": "A multimodal large language model specifically designed for the Chinese biomedical domain, capable of processing image-text inputs for tasks such as modality classification and report generation.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "multimodal_chat",
        "report_generation",
        "biomedical_vqa"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/BUAADreamer/Chinese-LLaVA-Med",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "multimodal",
        "chinese-medical-nlp"
      ],
      "id": 350
    },
    {
      "name": "Med-CLIP",
      "one_line_profile": "Contrastive language-image pretraining for medical data",
      "detailed_description": "An implementation of the CLIP framework adapted for medical imaging and text, enabling zero-shot classification and cross-modal retrieval in the medical domain.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "image_text_alignment",
        "zero_shot_classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CHB-learner/Med-CLIP",
      "help_website": [],
      "license": null,
      "tags": [
        "clip",
        "medical-imaging",
        "contrastive-learning"
      ],
      "id": 351
    },
    {
      "name": "RaDialog",
      "one_line_profile": "Large vision-language model for radiology report generation",
      "detailed_description": "A specialized vision-language model designed for generating radiology reports and engaging in conversational assistance regarding radiological images.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "radiology_assistant"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChantalMP/RaDialog",
      "help_website": [],
      "license": null,
      "tags": [
        "radiology",
        "report-generation",
        "vlm"
      ],
      "id": 352
    },
    {
      "name": "HealthGPT",
      "one_line_profile": "Medical large vision-language model for comprehension and generation",
      "detailed_description": "A medical multimodal foundation model that unifies comprehension and generation tasks via heterogeneous knowledge adaptation, suitable for various medical vision-language tasks.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "medical_vqa",
        "report_generation",
        "medical_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DCDmllm/HealthGPT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "foundation-model",
        "multimodal",
        "health-ai"
      ],
      "id": 353
    },
    {
      "name": "Med-MAT",
      "one_line_profile": "Compositional generalization framework for medical multimodal LLMs",
      "detailed_description": "A framework exploring and enhancing the compositional generalization capabilities of multimodal large language models specifically for medical imaging tasks.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "medical_vqa",
        "model_generalization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FreedomIntelligence/Med-MAT",
      "help_website": [],
      "license": null,
      "tags": [
        "multimodal-llm",
        "medical-imaging",
        "generalization"
      ],
      "id": 354
    },
    {
      "name": "COMG_model",
      "one_line_profile": "Complex organ mask guided radiology report generation",
      "detailed_description": "A model for generating radiology reports that utilizes complex organ masks to guide the generation process, improving anatomical accuracy.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "image_segmentation_guidance"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GaryGuTC/COMG_model",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "radiology",
        "report-generation",
        "mask-guided"
      ],
      "id": 355
    },
    {
      "name": "LaPA",
      "one_line_profile": "Latent prompt assist model for medical visual question answering",
      "detailed_description": "A medical VQA model that employs latent prompt assistance to improve question answering performance on medical images.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "medical_vqa",
        "prompt_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GaryGuTC/LaPA_model",
      "help_website": [],
      "license": null,
      "tags": [
        "vqa",
        "medical-imaging",
        "prompt-tuning"
      ],
      "id": 356
    },
    {
      "name": "HERGen",
      "one_line_profile": "Radiology report generation with longitudinal data",
      "detailed_description": "A framework for generating radiology reports that incorporates longitudinal patient data (historical records) to improve report quality and context.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "longitudinal_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/HKU-MedAI/HERGen",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "radiology",
        "longitudinal-data",
        "report-generation"
      ],
      "id": 357
    },
    {
      "name": "Federated-Retina-Screening",
      "one_line_profile": "Federated self-supervised multimodal retina screening framework",
      "detailed_description": "A research framework for federated learning in retinal disease screening, addressing challenges like label noise and differential privacy in a multimodal setting.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "federated_learning",
        "disease_screening",
        "retinal_imaging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Hazrat-Ali9/Federated-Self-Supervised-Multimodal-Retina-Screening-under-Label-Noise-and-Differential-Privacy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "federated-learning",
        "retina",
        "privacy"
      ],
      "id": 358
    },
    {
      "name": "MedCLIP-SAM",
      "one_line_profile": "Medical image segmentation using CLIP and SAM",
      "detailed_description": "A framework bridging MedCLIP and the Segment Anything Model (SAM) for text-guided medical image segmentation.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "image_segmentation",
        "text_guided_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HealthX-Lab/MedCLIP-SAM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "segmentation",
        "sam",
        "clip",
        "medical-imaging"
      ],
      "id": 359
    },
    {
      "name": "MedCLIP-SAMv2",
      "one_line_profile": "Advanced text-guided medical image segmentation model",
      "detailed_description": "The second version of MedCLIP-SAM, offering improved performance for text-prompted segmentation in medical imaging.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "image_segmentation",
        "text_guided_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HealthX-Lab/MedCLIP-SAMv2",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "segmentation",
        "sam",
        "clip"
      ],
      "id": 360
    },
    {
      "name": "EKAID",
      "one_line_profile": "Expert knowledge-aware difference-aware medical VQA",
      "detailed_description": "A medical VQA model focusing on difference-aware reasoning and expert knowledge integration for analyzing changes in medical images.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "medical_vqa",
        "difference_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Holipori/EKAID",
      "help_website": [],
      "license": null,
      "tags": [
        "vqa",
        "medical-imaging",
        "knowledge-graph"
      ],
      "id": 361
    },
    {
      "name": "TV-SAM",
      "one_line_profile": "Zero-shot segmentation for multimodal medical images",
      "detailed_description": "A zero-shot segmentation algorithm leveraging the Segment Anything Model (SAM) adapted for multimodal medical imaging tasks.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "image_segmentation",
        "zero_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JZK00/TV-SAM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "segmentation",
        "zero-shot",
        "multimodal"
      ],
      "id": 362
    },
    {
      "name": "MedCLIP",
      "one_line_profile": "Multi-modal CLIP model trained on the medical dataset ROCO",
      "detailed_description": "A vision-language pre-training model based on CLIP, fine-tuned on the ROCO (Radiology Objects in COntext) dataset to align medical images and textual descriptions for tasks like retrieval and classification.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "medical_vision_language_pretraining",
        "image_text_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Kaushalya/medclip",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medclip",
        "clip",
        "medical-imaging",
        "roco"
      ],
      "id": 363
    },
    {
      "name": "Self-Guided-Framework",
      "one_line_profile": "Self-guided framework for radiology report generation",
      "detailed_description": "Implementation of a self-guided framework for generating radiology reports from medical images, as presented at MICCAI 2022. It focuses on improving the accuracy and clinical relevance of generated text.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "radiology_report_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LijunRio/A-Self-Guided-Framework",
      "help_website": [],
      "license": null,
      "tags": [
        "radiology-report-generation",
        "miccai",
        "medical-imaging"
      ],
      "id": 364
    },
    {
      "name": "RaTEScore",
      "one_line_profile": "Metric for evaluating radiology report generation",
      "detailed_description": "A specialized metric designed to evaluate the quality of generated radiology reports. It assesses the alignment between generated reports and ground truth in terms of medical entities and relations.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "evaluation_metric",
        "radiology_report_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MAGIC-AI4Med/RaTEScore",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation-metric",
        "nlp",
        "radiology"
      ],
      "id": 365
    },
    {
      "name": "MediConfusion",
      "one_line_profile": "Dataset and evaluation code for probing reliability of multimodal medical models",
      "detailed_description": "A dataset and evaluation framework designed to test the reliability and hallucination tendencies of multimodal medical foundation models, specifically questioning whether AI radiologists can be trusted.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "hallucination_detection"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/MShahabSepehri/MediConfusion",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "reliability",
        "hallucination",
        "multimodal-medical-ai"
      ],
      "id": 366
    },
    {
      "name": "MSD-U-Net-GDC",
      "one_line_profile": "Generic U-Net implementation for Medical Segmentation Decathlon",
      "detailed_description": "A generic U-Net CNN architecture implementation using Generalized Dice Coefficient, designed for the Medical Segmentation Decathlon (MSD) challenge. It targets segmentation of organs like liver and spleen from 3D medical data.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "medical_image_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Maor-Oz/Medical-Segmentation-Decathlon-U-net-CNN-with-Generalized-Dice-Coefficient",
      "help_website": [],
      "license": null,
      "tags": [
        "u-net",
        "segmentation",
        "medical-segmentation-decathlon"
      ],
      "id": 367
    },
    {
      "name": "XProNet",
      "one_line_profile": "Cross-modal Prototype Driven Network for Radiology Report Generation",
      "detailed_description": "Official implementation of XProNet (ECCV 2022), a deep learning model that utilizes cross-modal prototypes to enhance radiology report generation from medical images.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "radiology_report_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Markin-Wang/XProNet",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "radiology-report-generation",
        "cross-modal",
        "deep-learning"
      ],
      "id": 368
    },
    {
      "name": "MedCLIP-Captioning",
      "one_line_profile": "Medical image captioning using OpenAI's CLIP",
      "detailed_description": "A project leveraging OpenAI's CLIP model adapted for medical image captioning tasks, enabling the generation of textual descriptions for medical imagery.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "medical_image_captioning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Mauville/MedCLIP",
      "help_website": [],
      "license": null,
      "tags": [
        "clip",
        "image-captioning",
        "medical-imaging"
      ],
      "id": 369
    },
    {
      "name": "MIU-VL",
      "one_line_profile": "Medical Image Understanding with Pretrained Vision Language Models",
      "detailed_description": "Code for the ICLR 2023 paper 'Medical Image Understanding with Pretrained Vision Language Models', providing a comprehensive study and models for applying VLMs to medical image analysis.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "medical_image_understanding",
        "vision_language_models"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MembrAI/MIU-VL",
      "help_website": [],
      "license": null,
      "tags": [
        "vlm",
        "medical-imaging",
        "iclr2023"
      ],
      "id": 370
    },
    {
      "name": "PLIP",
      "one_line_profile": "Pathology Language and Image Pre-Training foundation model",
      "detailed_description": "A large-scale vision and language foundation model specifically pre-trained for pathology. It enables extraction of visual and language features from pathology images and text descriptions, fine-tuned from CLIP.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "pathology_image_analysis",
        "vision_language_pretraining"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PathologyFoundation/plip",
      "help_website": [],
      "license": null,
      "tags": [
        "pathology",
        "foundation-model",
        "clip",
        "computational-pathology"
      ],
      "id": 371
    },
    {
      "name": "TransBTS",
      "one_line_profile": "Multimodal Brain Tumor Segmentation Using Transformer",
      "detailed_description": "Implementation of TransBTS and TransBTSV2, utilizing transformers for 3D multimodal brain tumor segmentation from MRI scans. It addresses the limitations of CNNs in modeling long-range dependencies.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "medical_image_segmentation",
        "brain_tumor_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Rubics-Xuan/TransBTS",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "transformer",
        "segmentation",
        "brain-tumor",
        "mri"
      ],
      "id": 372
    },
    {
      "name": "MedCLIP-Contrastive",
      "one_line_profile": "Contrastive Learning from Unpaired Medical Images and Texts",
      "detailed_description": "Implementation of MedCLIP (EMNLP 2022), a contrastive learning framework that decouples image-text pairing to leverage unpaired medical data for pre-training effective medical vision-language models.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "medical_vision_language_pretraining",
        "contrastive_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/RyanWangZf/MedCLIP",
      "help_website": [],
      "license": null,
      "tags": [
        "medclip",
        "contrastive-learning",
        "unpaired-data"
      ],
      "id": 373
    },
    {
      "name": "LABODOCK",
      "one_line_profile": "Colab-Based Molecular Docking Tools",
      "detailed_description": "A suite of Jupyter Notebooks designed to run molecular docking simulations (using tools like AutoDock Vina) directly in Google Colab, facilitating accessible drug discovery workflows.",
      "domains": [
        "H2"
      ],
      "subtask_category": [
        "molecular_docking",
        "drug_discovery"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/RyanZR/labodock",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "molecular-docking",
        "colab",
        "drug-discovery"
      ],
      "id": 374
    },
    {
      "name": "u2Tokenizer",
      "one_line_profile": "Multiscale multimodal large language models for radiology report generation",
      "detailed_description": "A framework utilizing multiscale multimodal large language models to generate radiology reports. It focuses on tokenizing visual information effectively to drive language generation.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "radiology_report_generation",
        "multimodal_llm"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Siyou-Li/u2Tokenizer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mllm",
        "radiology",
        "report-generation"
      ],
      "id": 375
    },
    {
      "name": "GREEN",
      "one_line_profile": "Radiology report generation metric using language models",
      "detailed_description": "A metric for evaluating radiology report generation that leverages the natural language understanding capabilities of large language models to identify and explain clinically significant errors.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "evaluation_metric",
        "radiology_report_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Stanford-AIMI/GREEN",
      "help_website": [],
      "license": null,
      "tags": [
        "evaluation",
        "llm",
        "radiology"
      ],
      "id": 376
    },
    {
      "name": "HC-LLM",
      "one_line_profile": "Framework for Longitudinal Radiology Report Generation",
      "detailed_description": "A framework designed for generating longitudinal radiology reports, taking into account the patient's history and changes over time, rather than just a single time-point image.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "longitudinal_report_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TengfeiLiu966/HC-LLM",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "longitudinal-analysis",
        "radiology",
        "report-generation"
      ],
      "id": 377
    },
    {
      "name": "Medical-Image-Fusion",
      "one_line_profile": "Laplacian Re-Decomposition for Multimodal Medical Image Fusion",
      "detailed_description": "MATLAB implementation of a Laplacian Re-Decomposition method for fusing multimodal medical images (e.g., CT and MRI) to combine complementary information.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "medical_image_fusion"
      ],
      "application_level": "solver",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/WHU-lab/Medical-Image-Fusion",
      "help_website": [],
      "license": null,
      "tags": [
        "image-fusion",
        "matlab",
        "medical-imaging"
      ],
      "id": 378
    },
    {
      "name": "CMCRL",
      "one_line_profile": "Cross-Modal Causal Representation Learning for Radiology Report Generation",
      "detailed_description": "Implementation of a cross-modal causal representation learning approach for radiology report generation, aiming to improve the logical consistency and causal reasoning in generated reports.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "radiology_report_generation",
        "causal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/WissingChen/CMCRL",
      "help_website": [],
      "license": null,
      "tags": [
        "causal-inference",
        "report-generation",
        "cross-modal"
      ],
      "id": 379
    },
    {
      "name": "Libra",
      "one_line_profile": "Temporally-aware MLLM toolkit for Biomedical Radiology Analysis",
      "detailed_description": "A flexible toolkit featuring a Temporally-aware Multimodal Large Language Model (MLLM) for biomedical radiology analysis and report generation. It supports real-time validation and smart model saving.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "radiology_analysis",
        "report_generation",
        "mllm"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/X-iZhang/Libra",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mllm",
        "toolkit",
        "radiology"
      ],
      "id": 380
    },
    {
      "name": "VQA-Med-2019",
      "one_line_profile": "Dataset and resources for Medical Visual Question Answering 2019",
      "detailed_description": "The official repository for the VQA-Med 2019 challenge, providing datasets and evaluation resources for visual question answering tasks in the medical domain.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "medical_vqa",
        "dataset"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/abachaa/VQA-Med-2019",
      "help_website": [],
      "license": null,
      "tags": [
        "vqa",
        "medical-dataset",
        "challenge"
      ],
      "id": 381
    },
    {
      "name": "cvt2distilgpt2",
      "one_line_profile": "Chest X-Ray Report Generation leveraging Warm-Starting",
      "detailed_description": "A model implementation for improving chest X-ray report generation by leveraging warm-starting techniques with CvT (Convolutional Vision Transformer) and DistilGPT2.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "radiology_report_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aehrc/cvt2distilgpt2",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "chest-x-ray",
        "report-generation",
        "transformer"
      ],
      "id": 382
    },
    {
      "name": "CXRMate",
      "one_line_profile": "Chest X-Ray report generation tool with longitudinal data support and semantic rewards",
      "detailed_description": "A framework for generating chest X-ray reports that incorporates longitudinal patient data and optimizes for semantic similarity, developed by the Australian e-Health Research Centre.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "medical_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aehrc/cxrmate",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "chest-x-ray",
        "report-generation",
        "longitudinal-data"
      ],
      "id": 383
    },
    {
      "name": "MMedPO",
      "one_line_profile": "Preference optimization framework for aligning medical vision-language models",
      "detailed_description": "A tool implementing Clinical-Aware Multimodal Preference Optimization to align medical vision-language models with clinical preferences, enhancing reliability and accuracy.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "model_alignment",
        "vlm_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aiming-lab/MMedPO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "preference-optimization",
        "medical-vlm",
        "alignment"
      ],
      "id": 384
    },
    {
      "name": "MedVQA (MICCAI19)",
      "one_line_profile": "Medical Visual Question Answering framework overcoming data limitations",
      "detailed_description": "Implementation of a Medical Visual Question Answering (MedVQA) system using Meta-Learning (MAML) and Denoising Auto-Encoders to handle limited medical data.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "visual_question_answering",
        "meta_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aioz-ai/MICCAI19-MedVQA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medvqa",
        "meta-learning",
        "medical-imaging"
      ],
      "id": 385
    },
    {
      "name": "MMQ (MICCAI21)",
      "one_line_profile": "Meta-model quantifying method for Medical Visual Question Answering",
      "detailed_description": "A framework for Medical VQA that utilizes multiple meta-models to quantify uncertainty and improve answer reliability.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "visual_question_answering",
        "uncertainty_quantification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aioz-ai/MICCAI21_MMQ",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medvqa",
        "meta-learning",
        "uncertainty"
      ],
      "id": 386
    },
    {
      "name": "MedICaT",
      "one_line_profile": "Large-scale dataset and toolkit for medical image captioning and text references",
      "detailed_description": "A dataset and associated tools for processing medical images, captions, subfigure annotations, and inline textual references to support multimodal medical AI research.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "dataset_access",
        "image_captioning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/medicat",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-dataset",
        "image-captioning",
        "multimodal"
      ],
      "id": 387
    },
    {
      "name": "APA2Seg-Net",
      "one_line_profile": "Anatomy-guided multimodal registration and segmentation network",
      "detailed_description": "A deep learning framework for joint segmentation and registration of multimodal medical images (e.g., CBCT/MR) without ground truth segmentation, using anatomy-guided priors.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "image_registration",
        "image_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bbbbbbzhou/APA2Seg-Net",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "registration",
        "segmentation",
        "multimodal-imaging"
      ],
      "id": 388
    },
    {
      "name": "MedGround-R1",
      "one_line_profile": "Medical image grounding tool via spatial-semantic rewarded policy optimization",
      "detailed_description": "A framework for medical image grounding that uses Group Relative Policy Optimization with spatial and semantic rewards to improve localization accuracy.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "image_grounding",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bio-mlhui/MedGround-R1",
      "help_website": [],
      "license": null,
      "tags": [
        "grounding",
        "reinforcement-learning",
        "medical-imaging"
      ],
      "id": 389
    },
    {
      "name": "RadFM",
      "one_line_profile": "Generalist foundation model for 2D and 3D radiology data",
      "detailed_description": "A multimodal foundation model capable of handling both 2D and 3D medical imaging data for various radiology tasks, leveraging web-scale data.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "foundation_model",
        "radiology_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chaoyi-wu/RadFM",
      "help_website": [
        "https://chaoyi-wu.github.io/RadFM/"
      ],
      "license": "MIT",
      "tags": [
        "foundation-model",
        "radiology",
        "3d-imaging"
      ],
      "id": 390
    },
    {
      "name": "FORTE",
      "one_line_profile": "Multimodal LLM framework for 3D brain CT report generation",
      "detailed_description": "A holistic framework designed for generating radiology reports from 3D brain CT scans using multimodal Large Language Models.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "3d_imaging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/charlierabea/FORTE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "brain-ct",
        "report-generation",
        "multimodal-llm"
      ],
      "id": 391
    },
    {
      "name": "MediCLIP",
      "one_line_profile": "Adapted CLIP model for few-shot medical image anomaly detection",
      "detailed_description": "A tool that adapts the CLIP vision-language model for the specific task of few-shot anomaly detection in medical images.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "anomaly_detection",
        "few_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cnulab/MediCLIP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "clip",
        "anomaly-detection",
        "few-shot"
      ],
      "id": 392
    },
    {
      "name": "Kedro Multimodal Healthcare",
      "one_line_profile": "Kedro template for multimodal healthcare machine learning pipelines",
      "detailed_description": "A project template for building multimodal machine learning pipelines in healthcare using Kedro, facilitating the combination of reports, tabular data, and images.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "pipeline_orchestration",
        "multimodal_fusion"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/dermatologist/kedro-multimodal",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kedro",
        "pipeline",
        "healthcare-ml"
      ],
      "id": 393
    },
    {
      "name": "ConVIRT-pytorch",
      "one_line_profile": "Contrastive learning framework for medical image-text pretraining",
      "detailed_description": "A PyTorch implementation of ConVIRT (Contrastive VIsual Representation Learning from Text), a method for learning medical visual representations by exploiting paired descriptive text.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "contrastive_learning",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/edreisMD/ConVIRT-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "contrastive-learning",
        "medical-imaging",
        "pretraining"
      ],
      "id": 394
    },
    {
      "name": "MICFormer",
      "one_line_profile": "Multimodal transformer for medical image segmentation",
      "detailed_description": "A transformer-based model designed for medical image segmentation that effectively interacts and fuses multimodal information.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "image_segmentation",
        "multimodal_fusion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/fxxJuses/MICFormer",
      "help_website": [],
      "license": null,
      "tags": [
        "transformer",
        "segmentation",
        "multimodal"
      ],
      "id": 395
    },
    {
      "name": "EKAGen",
      "one_line_profile": "Knowledge-enhanced radiology report generation model",
      "detailed_description": "A radiology report generation tool that incorporates instance-level expert knowledge and aggregate discriminative attention to improve report quality.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "knowledge_enhancement"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hnjzbss/EKAGen",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "radiology-report",
        "attention-mechanism",
        "expert-knowledge"
      ],
      "id": 396
    },
    {
      "name": "CT2Rep",
      "one_line_profile": "Automated radiology report generation for 3D CT imaging",
      "detailed_description": "A deep learning model specifically designed to generate comprehensive radiology reports from 3D CT volumes.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "3d_imaging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ibrahimethemhamamci/CT2Rep",
      "help_website": [],
      "license": null,
      "tags": [
        "ct-scan",
        "report-generation",
        "3d-medical-imaging"
      ],
      "id": 397
    },
    {
      "name": "OAProgression",
      "one_line_profile": "Multimodal prediction of knee osteoarthritis progression",
      "detailed_description": "A machine learning tool for predicting the progression of knee osteoarthritis by combining plain radiographs with clinical data.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "disease_progression_prediction",
        "multimodal_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/imedslab/OAProgression",
      "help_website": [],
      "license": null,
      "tags": [
        "osteoarthritis",
        "prognosis",
        "multimodal-learning"
      ],
      "id": 398
    },
    {
      "name": "Variational X-Ray Report Gen",
      "one_line_profile": "Variational topic inference for chest X-ray report generation",
      "detailed_description": "A model for generating chest X-ray reports that uses variational inference to model topics within the reports, improving diversity and accuracy.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "variational_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ivonajdenkoska/variational-xray-report-gen",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "topic-modeling",
        "variational-inference",
        "chest-x-ray"
      ],
      "id": 399
    },
    {
      "name": "StructuredLight_3DfreehandUS",
      "one_line_profile": "Multimodal 3D freehand ultrasound and structured light imaging tool",
      "detailed_description": "A software tool for a multimodal medical imaging technique that combines 3D freehand ultrasound with structured light scanning.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "image_reconstruction",
        "multimodal_imaging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jhacsonmeza/StructuredLight_3DfreehandUS",
      "help_website": [],
      "license": null,
      "tags": [
        "ultrasound",
        "structured-light",
        "3d-reconstruction"
      ],
      "id": 400
    },
    {
      "name": "Multimodal Clinical Pretraining",
      "one_line_profile": "Multimodal pretraining framework for medical time series and clinical notes",
      "detailed_description": "Official implementation of the MLHC 2023 paper 'Multimodal Pretraining of Medical Time Series and Notes'. It provides a framework for pretraining models on multimodal clinical data to improve downstream tasks.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "pretraining",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kingrc15/multimodal-clinical-pretraining",
      "help_website": [],
      "license": null,
      "tags": [
        "multimodal",
        "medical-time-series",
        "clinical-notes",
        "pretraining"
      ],
      "id": 401
    },
    {
      "name": "MHCA",
      "one_line_profile": "Multimodal Multi-Head Convolutional Attention for medical image super-resolution",
      "detailed_description": "Implementation of a multimodal attention mechanism designed to fuse features from different modalities for the task of medical image super-resolution.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "super_resolution",
        "image_fusion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lilygeorgescu/MHCA",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "super-resolution",
        "attention-mechanism",
        "multimodal-fusion"
      ],
      "id": 402
    },
    {
      "name": "GLoRIA",
      "one_line_profile": "Multimodal Global-Local Representation Learning for medical image recognition",
      "detailed_description": "A framework for label-efficient medical image recognition that learns global and local representations by contrasting image sub-regions and words in radiology reports.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "representation_learning",
        "image_classification",
        "zero_shot_classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/marshuang80/gloria",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "contrastive-learning",
        "multimodal",
        "medical-imaging",
        "representation-learning"
      ],
      "id": 403
    },
    {
      "name": "DeepGuide",
      "one_line_profile": "Deep multimodal guidance framework for medical image classification",
      "detailed_description": "Implementation of a deep multimodal guidance architecture that leverages auxiliary modalities to guide the learning process for medical image classification tasks.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "image_classification",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mayurmallya/DeepGuide",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-classification",
        "multimodal-guidance",
        "deep-learning"
      ],
      "id": 404
    },
    {
      "name": "UniMed-CLIP",
      "one_line_profile": "Unified image-text pretraining paradigm for diverse medical imaging modalities",
      "detailed_description": "A unified pretraining framework adapting CLIP for the medical domain, designed to handle diverse medical imaging modalities and align them with textual reports.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "pretraining",
        "representation_learning",
        "zero_shot_classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mbzuai-oryx/UniMed-CLIP",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "clip",
        "medical-pretraining",
        "multimodal-alignment"
      ],
      "id": 405
    },
    {
      "name": "CMC",
      "one_line_profile": "Cross-modality collaboration for semi-supervised medical image segmentation",
      "detailed_description": "Implementation of a robust semi-supervised multimodal medical image segmentation framework via Cross Modality Collaboration (CMC), as presented at MICCAI 2024.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "image_segmentation",
        "semi_supervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/med-air/CMC",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "segmentation",
        "multimodal",
        "semi-supervised"
      ],
      "id": 406
    },
    {
      "name": "LLaVA-Med",
      "one_line_profile": "Large Language-and-Vision Assistant for Biomedicine",
      "detailed_description": "A large language-and-vision model trained for the biomedical domain, capable of performing multimodal chat and visual question answering on biomedical images.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "visual_question_answering",
        "multimodal_chat",
        "biomedical_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/LLaVA-Med",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "vlm",
        "biomedicine",
        "multimodal-chat"
      ],
      "id": 407
    },
    {
      "name": "RadFact",
      "one_line_profile": "Factual correctness metric for radiology report generation",
      "detailed_description": "A metric suite leveraging the logical inference capabilities of LLMs to evaluate the factual correctness of generated radiology reports, supporting both grounded and ungrounded evaluation.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "evaluation",
        "report_generation",
        "metric_calculation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/RadFact",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation-metric",
        "radiology-reports",
        "factual-correctness"
      ],
      "id": 408
    },
    {
      "name": "MLRG",
      "one_line_profile": "Enhanced contrastive learning with multi-view longitudinal data for report generation",
      "detailed_description": "A framework for chest X-ray report generation that leverages multi-view longitudinal data and enhanced contrastive learning to improve report quality.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "contrastive_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mk-runner/MLRG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chest-x-ray",
        "report-generation",
        "longitudinal-data"
      ],
      "id": 409
    },
    {
      "name": "SEI",
      "one_line_profile": "Structural entities extraction and patient indications incorporation for report generation",
      "detailed_description": "A model for chest X-ray report generation that explicitly extracts structural entities and incorporates patient indications to generate more accurate and clinically relevant reports.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "entity_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mk-runner/SEI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chest-x-ray",
        "report-generation",
        "clinical-indications"
      ],
      "id": 410
    },
    {
      "name": "DCL",
      "one_line_profile": "Dynamic graph enhanced contrastive learning for chest X-ray report generation",
      "detailed_description": "Official implementation of the CVPR 2023 paper proposing a dynamic graph enhanced contrastive learning approach for automated chest X-ray report generation.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "contrastive_learning",
        "graph_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mlii0117/DCL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chest-x-ray",
        "report-generation",
        "dynamic-graph"
      ],
      "id": 411
    },
    {
      "name": "CDGPT2-CXR",
      "one_line_profile": "Automated radiology report generation using conditioned transformers",
      "detailed_description": "Implementation of the CDGPT2 model for automated radiology report generation, utilizing conditioned transformers to generate reports from chest X-ray images.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "text_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/omar-mohamed/GPT2-Chest-X-Ray-Report-Generation",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "gpt2",
        "radiology-report",
        "chest-x-ray"
      ],
      "id": 412
    },
    {
      "name": "Medical-AI (Template-based Report Gen)",
      "one_line_profile": "Clinically correct report generation from chest X-rays using templates",
      "detailed_description": "Code for the MLMI 2021 paper focusing on generating clinically correct radiology reports from chest X-rays using a template-based approach to ensure factual accuracy.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "template_based_generation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/pdpino/medical-ai",
      "help_website": [],
      "license": null,
      "tags": [
        "chest-x-ray",
        "report-generation",
        "clinical-accuracy"
      ],
      "id": 413
    },
    {
      "name": "ROCO",
      "one_line_profile": "Large-scale multimodal medical image dataset with radiology objects in context",
      "detailed_description": "The Radiology Objects in COntext (ROCO) dataset is a large-scale multimodal medical image dataset designed to support vision-language tasks in the medical domain. It contains image-caption pairs extracted from PubMed Central Open Access articles, enabling research in image retrieval, captioning, and multimodal pre-training.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "dataset",
        "multimodal_learning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/razorx89/roco-dataset",
      "help_website": [],
      "license": null,
      "tags": [
        "dataset",
        "radiology",
        "multimodal",
        "image-captioning"
      ],
      "id": 414
    },
    {
      "name": "GlorIA",
      "one_line_profile": "Global-Local Representations for Image-text Alignment in medical vision-language pre-training",
      "detailed_description": "GlorIA is a multimodal pre-training framework that learns global and local representations for medical image-text alignment. It is designed to improve performance on downstream tasks such as image retrieval, classification, and segmentation by capturing fine-grained semantic correspondences between radiology images and reports.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "multimodal_pretraining",
        "image_text_alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/rvalgreen/GlorIA",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "vision-language",
        "pre-training",
        "medical-imaging",
        "contrastive-learning"
      ],
      "id": 415
    },
    {
      "name": "PubMedCLIP",
      "one_line_profile": "CLIP model fine-tuned on the ROCO dataset for medical vision-language tasks",
      "detailed_description": "PubMedCLIP adapts the CLIP architecture to the medical domain by fine-tuning on the ROCO dataset (image-caption pairs from PubMed). It serves as a specialized foundation model for medical visual question answering (VQA) and image retrieval tasks.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "multimodal_pretraining",
        "visual_question_answering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sarahESL/PubMedCLIP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "clip",
        "medical-vqa",
        "fine-tuning",
        "roco"
      ],
      "id": 416
    },
    {
      "name": "Consistency-VQA",
      "one_line_profile": "Consistency-preserving Visual Question Answering in Medical Imaging",
      "detailed_description": "A framework for Medical Visual Question Answering (MedVQA) that incorporates a consistency-preserving module. It aims to improve the reliability of VQA models by ensuring that answers to semantically related questions are consistent, addressing a common failure mode in VQA systems.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "visual_question_answering",
        "model_consistency"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sergiotasconmorales/consistency_vqa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vqa",
        "medical-imaging",
        "consistency-learning"
      ],
      "id": 417
    },
    {
      "name": "BrainMVP",
      "one_line_profile": "Multimodal Vision-Language Pre-training for mpMRI brain image analysis",
      "detailed_description": "BrainMVP is a PyTorch implementation of a multimodal pre-training framework specifically designed for multi-parametric MRI (mpMRI) brain image analysis. It leverages vision-language techniques to learn robust representations for tasks like tumor segmentation and classification.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "multimodal_pretraining",
        "mri_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/shaohao011/BrainMVP",
      "help_website": [],
      "license": null,
      "tags": [
        "mri",
        "brain-tumor",
        "vision-language",
        "pre-training"
      ],
      "id": 418
    },
    {
      "name": "H-DenseFormer",
      "one_line_profile": "Hybrid Densely Connected Transformer for multimodal medical image segmentation",
      "detailed_description": "H-DenseFormer is a deep learning model that combines dense connections with transformer mechanisms for tumor segmentation using multimodal medical images. It aims to effectively fuse information from different imaging modalities to improve segmentation accuracy.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "image_segmentation",
        "multimodal_fusion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/shijun18/H-DenseFormer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "transformer",
        "segmentation",
        "multimodal",
        "tumor"
      ],
      "id": 419
    },
    {
      "name": "DilRAN",
      "one_line_profile": "Attention-based Multi-Scale Feature Learning Framework for Multimodal Medical Image Fusion",
      "detailed_description": "DilRAN (Dilated Residual Attention Network) is a framework for fusing multimodal medical images (e.g., MRI and CT). It utilizes attention mechanisms and multi-scale feature learning to synthesize fused images that retain complementary information from source modalities.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "image_fusion",
        "multimodal_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/simonZhou86/dilran",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "image-fusion",
        "attention-mechanism",
        "medical-imaging"
      ],
      "id": 420
    },
    {
      "name": "R2-LLM",
      "one_line_profile": "Bootstrapping Large Language Models for Radiology Report Generation",
      "detailed_description": "R2-LLM is a framework that leverages Large Language Models (LLMs) for generating radiology reports. It focuses on bootstrapping LLMs to handle the specific domain language and structure of medical reports, integrating visual features from radiology scans.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "multimodal_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/synlp/R2-LLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "radiology-report",
        "generation",
        "bootstrapping"
      ],
      "id": 421
    },
    {
      "name": "R2GenRL",
      "one_line_profile": "Reinforced Cross-modal Alignment for Radiology Report Generation",
      "detailed_description": "R2GenRL applies reinforcement learning techniques to improve cross-modal alignment in radiology report generation. It optimizes the generation process by rewarding the model for better alignment between image regions and generated text, aiming for more accurate and clinically relevant reports.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "reinforcement_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/synlp/R2GenRL",
      "help_website": [],
      "license": null,
      "tags": [
        "reinforcement-learning",
        "radiology-report",
        "cross-modal"
      ],
      "id": 422
    },
    {
      "name": "Medical-Report-Generation",
      "one_line_profile": "Multimodal Recurrent Model with Attention for Automated Radiology Report Generation",
      "detailed_description": "A PyTorch implementation of a multimodal recurrent model equipped with attention mechanisms for generating radiology reports. This tool focuses on automatically interpreting medical images and producing descriptive text reports.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "image_captioning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tengfeixue-victor/Medical-Report-Generation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "radiology",
        "rnn",
        "attention",
        "report-generation"
      ],
      "id": 423
    },
    {
      "name": "RGRG",
      "one_line_profile": "Interactive and Explainable Region-guided Radiology Report Generation",
      "detailed_description": "RGRG (Region-Guided Radiology Report Generation) is a framework that allows for interactive and explainable report generation. It enables users to guide the generation process by focusing on specific regions of interest in the radiology image, enhancing the clinical utility and interpretability of the automated reports.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "explainable_ai"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ttanida/rgrg",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "interactive",
        "explainable",
        "radiology",
        "region-guided"
      ],
      "id": 424
    },
    {
      "name": "MATR",
      "one_line_profile": "Multimodal Medical Image Fusion via Multiscale Adaptive Transformer",
      "detailed_description": "MATR is a deep learning model for multimodal medical image fusion that utilizes a multiscale adaptive transformer architecture. It is designed to merge information from different imaging modalities (e.g., MRI, CT, PET) into a single high-quality image for better clinical diagnosis.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "image_fusion",
        "multimodal_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tthinking/MATR",
      "help_website": [],
      "license": null,
      "tags": [
        "transformer",
        "image-fusion",
        "multiscale",
        "medical-imaging"
      ],
      "id": 425
    },
    {
      "name": "ARGON",
      "one_line_profile": "Progressive Transformer-Based Generation of Radiology Reports",
      "detailed_description": "ARGON is a transformer-based model for generating radiology reports in a progressive manner. It aims to improve the quality and coherence of generated reports by refining the generation process through progressive stages.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "transformer_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/uzh-dqbm-cmi/ARGON",
      "help_website": [],
      "license": null,
      "tags": [
        "transformer",
        "radiology",
        "progressive-generation"
      ],
      "id": 426
    },
    {
      "name": "R2GenGPT",
      "one_line_profile": "Radiology Report Generation with Frozen Large Language Models",
      "detailed_description": "R2GenGPT is a framework that utilizes frozen Large Language Models (LLMs) for radiology report generation. It aligns visual features from medical images with the input space of LLMs, allowing the powerful text generation capabilities of LLMs to be applied to medical reporting without extensive fine-tuning of the language model itself.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "llm_adaptation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wang-zhanyu/R2GenGPT",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "gpt",
        "llm",
        "radiology",
        "frozen-model"
      ],
      "id": 427
    },
    {
      "name": "Multimodal-Explanation",
      "one_line_profile": "Generating and Evaluating Post-Hoc Explanations for Multimodal Medical Image Analysis",
      "detailed_description": "This repository provides tools for generating and evaluating post-hoc explanations for deep neural networks used in multimodal medical image analysis. It focuses on interpretability, helping researchers and clinicians understand model decisions in tasks involving multiple imaging modalities.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "explainable_ai",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/weinajin/multimodal_explanation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "explainability",
        "post-hoc",
        "multimodal",
        "evaluation"
      ],
      "id": 428
    },
    {
      "name": "ORGAN",
      "one_line_profile": "Observation-Guided Radiology Report Generation via Tree Reasoning",
      "detailed_description": "ORGAN is a radiology report generation model that employs observation-guided tree reasoning. It structures the generation process by explicitly reasoning about observations in a tree structure, aiming to produce more logical and clinically accurate reports.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wjhou/ORGan",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tree-reasoning",
        "radiology",
        "observation-guided"
      ],
      "id": 429
    },
    {
      "name": "RADAR",
      "one_line_profile": "Enhancing Radiology Report Generation with Supplementary Knowledge Injection",
      "detailed_description": "RADAR is a framework for enhancing radiology report generation by injecting supplementary knowledge. It integrates external medical knowledge to support the generation process, improving the factual accuracy and completeness of the reports.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "knowledge_injection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wjhou/Radar",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "radiology",
        "report-generation"
      ],
      "id": 430
    },
    {
      "name": "RECAP",
      "one_line_profile": "Towards Precise Radiology Report Generation via Dynamic Disease Progression Reasoning",
      "detailed_description": "RECAP is a model for radiology report generation that incorporates dynamic disease progression reasoning. It focuses on capturing the temporal and logical progression of diseases to generate more precise and contextually aware reports.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "disease_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wjhou/Recap",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "disease-progression",
        "reasoning",
        "radiology"
      ],
      "id": 431
    },
    {
      "name": "IFCC",
      "one_line_profile": "Improving Factual Completeness and Consistency of Image-to-text Radiology Report Generation",
      "detailed_description": "IFCC is a method and codebase for improving the factual completeness and consistency of generated radiology reports. It addresses the hallucination problem in report generation by enforcing factual consistency between the image and the generated text.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "factual_consistency"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ysmiura/ifcc",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "factual-consistency",
        "radiology",
        "nlp",
        "generation"
      ],
      "id": 432
    },
    {
      "name": "MultiP-R2Gen",
      "one_line_profile": "Enhancing Radiology Report Generation via Multi-Phased Supervision",
      "detailed_description": "MultiP-R2Gen is a framework that enhances radiology report generation using multi-phased supervision. It employs a training strategy that guides the model through different phases of learning to improve the quality and accuracy of the generated medical reports.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "report_generation",
        "supervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zailongchen/MultiP-R2Gen",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "radiology",
        "report-generation",
        "multi-phased",
        "supervision"
      ],
      "id": 433
    },
    {
      "name": "LLM-RG4",
      "one_line_profile": "Flexible and factual radiology report generation framework using LLMs",
      "detailed_description": "An implementation of the LLM-RG4 framework (AAAI 2025) designed for generating radiology reports. It leverages Large Language Models to ensure factual accuracy and flexibility across diverse input contexts, serving as a solver for medical image captioning tasks.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "radiology_report_generation",
        "medical_image_captioning",
        "multimodal_fusion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zh-Wang-Med/LLM-RG4",
      "help_website": [],
      "license": null,
      "tags": [
        "radiology-report-generation",
        "llm",
        "medical-imaging",
        "aaai-2025"
      ],
      "id": 434
    },
    {
      "name": "R2GenCMN",
      "one_line_profile": "Cross-modal Memory Networks for radiology report generation",
      "detailed_description": "The official implementation of Cross-modal Memory Networks (CMN) for radiology report generation (ACL 2021). It provides a deep learning model that utilizes shared memory mechanisms to align visual and textual features for generating accurate medical reports from radiology images.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "radiology_report_generation",
        "vision_language_alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhjohnchan/R2GenCMN",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "radiology-report",
        "cross-modal",
        "memory-networks",
        "acl-2021"
      ],
      "id": 435
    },
    {
      "name": "WCL",
      "one_line_profile": "Weakly Supervised Contrastive Learning for Chest X-Ray Report Generation",
      "detailed_description": "A PyTorch implementation of Weakly Supervised Contrastive Learning (WCL) for chest X-ray report generation (EMNLP 2021). It serves as a solver for training models to generate medical reports using contrastive learning techniques on weakly labeled data.",
      "domains": [
        "H2",
        "H2-05"
      ],
      "subtask_category": [
        "radiology_report_generation",
        "contrastive_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zzxslp/WCL",
      "help_website": [],
      "license": null,
      "tags": [
        "chest-x-ray",
        "contrastive-learning",
        "emnlp-2021",
        "medical-report-generation"
      ],
      "id": 436
    },
    {
      "name": "MedSafetyBench",
      "one_line_profile": "Benchmark suite for evaluating the medical safety of Large Language Models",
      "detailed_description": "MedSafetyBench is an evaluation framework designed to assess and improve the safety of LLMs in medical contexts, focusing on preventing harmful or incorrect medical advice.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "safety_evaluation",
        "model_benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/AI4LIFE-GROUP/med-safety-bench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-safety",
        "llm-evaluation",
        "benchmark"
      ],
      "id": 437
    },
    {
      "name": "MedEQBench",
      "one_line_profile": "Evaluation suite for emotional perception and empathy in medical LLMs",
      "detailed_description": "MedEQBench assesses Large Language Models' capabilities in emotional perception and empathic expression within medical contexts, ensuring supportive and context-aware responses.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "emotional_intelligence_eval",
        "model_benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/AQ-MedAI/MedEQBench",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-llm",
        "empathy",
        "evaluation"
      ],
      "id": 438
    },
    {
      "name": "GEMeX",
      "one_line_profile": "Benchmark for groundable and explainable medical visual question answering",
      "detailed_description": "GEMeX is a large-scale benchmark designed for Chest X-ray diagnosis, focusing on evaluating the groundability and explainability of medical VQA models.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "medical_vqa",
        "model_benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Awenbocc/GEMeX-Project",
      "help_website": [],
      "license": null,
      "tags": [
        "chest-x-ray",
        "vqa",
        "explainable-ai"
      ],
      "id": 439
    },
    {
      "name": "Biomedical-NLP-Benchmarks",
      "one_line_profile": "Collection of benchmark datasets for Biomedical NLP tasks",
      "detailed_description": "A repository containing various benchmark datasets specifically curated for evaluating Biomedical Natural Language Processing models and tasks.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "model_benchmarking",
        "dataset_collection"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/BIDS-Xu-Lab/Biomedical-NLP-Benchmarks",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bionlp",
        "benchmark",
        "datasets"
      ],
      "id": 440
    },
    {
      "name": "Commander",
      "one_line_profile": "Gibbs sampling framework for CMB posterior exploration",
      "detailed_description": "Commander is an Optimal Monte-carlo Markov chAiN Driven EstimatoR implementing fast and efficient end-to-end Cosmic Microwave Background (CMB) posterior exploration through Gibbs sampling.",
      "domains": [
        "Physics",
        "Astrophysics"
      ],
      "subtask_category": [
        "posterior_estimation",
        "signal_separation"
      ],
      "application_level": "solver",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/Cosmoglobe/Commander",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "cmb",
        "gibbs-sampling",
        "astrophysics"
      ],
      "id": 441
    },
    {
      "name": "AMEGA-LLM",
      "one_line_profile": "Autonomous evaluation framework for medical guideline adherence",
      "detailed_description": "AMEGA-LLM (Autonomous Medical Evaluation for Guideline Adherence) is a benchmark and evaluation tool designed to assess how well Large Language Models adhere to medical guidelines.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "guideline_adherence",
        "model_evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/DATEXIS/AMEGA-benchmark",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-guidelines",
        "llm-evaluation",
        "clinical-nlp"
      ],
      "id": 442
    },
    {
      "name": "Hybrid-RAG",
      "one_line_profile": "Enterprise-grade RAG system for healthcare AI with safety checks",
      "detailed_description": "A full-stack RAG system designed for healthcare AI, featuring hybrid retrieval, multi-dimensional conflict detection, and dual-layer safety checks to ensure reliable medical information processing.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "information_retrieval",
        "safety_verification"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/EasonWong0327/Hybrid-RAG-System",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "healthcare-ai",
        "safety"
      ],
      "id": 443
    },
    {
      "name": "lm-evaluation-harness",
      "one_line_profile": "Framework for few-shot evaluation of language models",
      "detailed_description": "A widely used framework for evaluating Large Language Models on a variety of tasks. It serves as the foundation for many domain-specific benchmarks, including scientific and medical LLM evaluations.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/EleutherAI/lm-evaluation-harness",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "evaluation",
        "few-shot"
      ],
      "id": 444
    },
    {
      "name": "candl",
      "one_line_profile": "Differentiable Likelihood for CMB Analysis",
      "detailed_description": "A tool for Cosmic Microwave Background (CMB) analysis providing differentiable likelihoods, useful for cosmological inference and parameter estimation.",
      "domains": [
        "Physics",
        "Astrophysics"
      ],
      "subtask_category": [
        "likelihood_analysis",
        "cosmological_inference"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Lbalkenhol/candl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cmb",
        "cosmology",
        "differentiable-programming"
      ],
      "id": 445
    },
    {
      "name": "medplexity",
      "one_line_profile": "Evaluation framework for Large Language Models in medical applications",
      "detailed_description": "A Python library designed to evaluate the performance of Large Language Models (LLMs) on various medical benchmarks and tasks, facilitating the assessment of medical reasoning and knowledge.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/MaksymPetyak/medplexity",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-llm",
        "evaluation",
        "benchmark"
      ],
      "id": 446
    },
    {
      "name": "med-lm-envs",
      "one_line_profile": "Automated evaluation suite for medical language model tasks",
      "detailed_description": "A suite of environments and tools for automating the evaluation of Large Language Models on medical tasks, supporting various datasets and metrics.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MedARC-AI/med-lm-envs",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-ai",
        "llm-evaluation",
        "automation"
      ],
      "id": 447
    },
    {
      "name": "Omni-SafetyBench",
      "one_line_profile": "Benchmark for safety evaluation of audio-visual large language models",
      "detailed_description": "A comprehensive benchmark designed to evaluate the safety of Audio-Visual Large Language Models (AV-LLMs), covering various safety dimensions and multimodal inputs.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "safety_evaluation",
        "multimodal_benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/THU-BPM/Omni-SafetyBench",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "safety",
        "benchmark"
      ],
      "id": 448
    },
    {
      "name": "MultiCogEval",
      "one_line_profile": "Benchmark for evaluating LLMs across multi-cognitive levels in medicine",
      "detailed_description": "A benchmark suite for assessing Large Language Models' capabilities in the medical domain, ranging from knowledge mastery to scenario-based problem solving.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "model_evaluation",
        "cognitive_assessment"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/THUMLP/MultiCogEval",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-llm",
        "cognitive-evaluation",
        "benchmark"
      ],
      "id": 449
    },
    {
      "name": "PretexEval",
      "one_line_profile": "Evaluation framework for assessing medical knowledge mastery in LLMs",
      "detailed_description": "A tool and dataset for the reliable and diverse evaluation of Large Language Models' mastery of medical knowledge, focusing on pre-clinical and clinical contexts.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "model_evaluation",
        "knowledge_assessment"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/THUMLP/PretexEval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-knowledge",
        "llm-evaluation",
        "benchmark"
      ],
      "id": 450
    },
    {
      "name": "Adversarial Robustness Toolbox (ART)",
      "one_line_profile": "Python library for machine learning security and robustness evaluation",
      "detailed_description": "A Python library for machine learning security that provides tools for developers and researchers to defend and evaluate Machine Learning models and applications against adversarial threats (evasion, poisoning, extraction, and inference).",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "safety_checks",
        "adversarial_robustness"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox",
      "help_website": [
        "https://adversarial-robustness-toolbox.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "security",
        "adversarial-ml",
        "robustness"
      ],
      "id": 451
    },
    {
      "name": "MedKGEval",
      "one_line_profile": "Benchmark for evaluating medical knowledge coverage in LLMs",
      "detailed_description": "A benchmark designed to evaluate the coverage and accuracy of medical knowledge within Large Language Models using Knowledge Graphs as a reference.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "knowledge_graph_evaluation",
        "model_benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/ZihengZZH/MedKGEval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "medical-llm",
        "evaluation"
      ],
      "id": 452
    },
    {
      "name": "PySM",
      "one_line_profile": "Software for simulating the Galactic microwave sky for CMB experiments",
      "detailed_description": "PySM generates full-sky simulations of Galactic emissions in intensity and polarization, relevant for Cosmic Microwave Background (CMB) experiments.",
      "domains": [
        "Physics",
        "Astrophysics"
      ],
      "subtask_category": [
        "simulation",
        "data_generation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/b-thorne/PySM_public",
      "help_website": [],
      "license": null,
      "tags": [
        "cmb",
        "astrophysics",
        "simulation",
        "microwave-sky"
      ],
      "id": 453
    },
    {
      "name": "SynthEHRella",
      "one_line_profile": "Benchmarking package for evaluating synthetic Electronic Health Records (EHR) generation methods",
      "detailed_description": "SynthEHRella provides a suite of metrics and tools to assess the quality, utility, and privacy of synthetic electronic health records generated by various algorithms.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking",
        "synthetic_data"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chenxran/synthEHRella",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ehr",
        "synthetic-data",
        "evaluation",
        "healthcare"
      ],
      "id": 454
    },
    {
      "name": "UQLM",
      "one_line_profile": "Uncertainty Quantification for Language Models to detect hallucinations",
      "detailed_description": "UQLM is a Python package designed to detect hallucinations in Large Language Models (LLMs) using uncertainty quantification techniques, applicable in high-stakes domains like healthcare.",
      "domains": [
        "H2",
        "H2-06",
        "Computer Science"
      ],
      "subtask_category": [
        "uncertainty_quantification",
        "hallucination_detection",
        "safety_check"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cvs-health/uqlm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "uncertainty-quantification",
        "hallucination",
        "safety"
      ],
      "id": 455
    },
    {
      "name": "quicklens",
      "one_line_profile": "Flat-sky code for Cosmic Microwave Background (CMB) lensing estimation",
      "detailed_description": "A library for estimating gravitational lensing of the Cosmic Microwave Background (CMB) using flat-sky approximations, used in cosmological data analysis.",
      "domains": [
        "Physics",
        "Astrophysics"
      ],
      "subtask_category": [
        "data_analysis",
        "estimation",
        "lensing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dhanson/quicklens",
      "help_website": [],
      "license": null,
      "tags": [
        "cmb",
        "lensing",
        "cosmology",
        "astrophysics"
      ],
      "id": 456
    },
    {
      "name": "clinical-llm-evaluation",
      "one_line_profile": "Framework for evaluating Causal Language Models on medical datasets",
      "detailed_description": "A general framework to evaluate Large Language Models (LLMs) on clinical tasks including Question-Answer (QA), Summarization, NER, and Relation Extraction.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "evaluation",
        "qa",
        "ner",
        "relation_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/dsi-clinical-llm/clinical-llm-evaluation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "clinical-llm",
        "evaluation",
        "nlp",
        "medical-ai"
      ],
      "id": 457
    },
    {
      "name": "Video-SafetyBench",
      "one_line_profile": "Benchmark for safety evaluation of Video Large Vision-Language Models",
      "detailed_description": "A comprehensive benchmark designed to evaluate the safety of video-based Large Vision-Language Models (LVLMs), covering various safety dimensions.",
      "domains": [
        "H2-06",
        "Computer Science"
      ],
      "subtask_category": [
        "safety_evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/flageval-baai/Video-SafetyBench",
      "help_website": [],
      "license": null,
      "tags": [
        "video-llm",
        "safety",
        "benchmark",
        "lvlm"
      ],
      "id": 458
    },
    {
      "name": "MM-SafetyBench",
      "one_line_profile": "Safety evaluation benchmark for multimodal large language models",
      "detailed_description": "A benchmark framework for evaluating the safety of Multimodal Large Language Models (MLLMs) against various types of unsafe queries and inputs.",
      "domains": [
        "H2-06",
        "Computer Science"
      ],
      "subtask_category": [
        "safety_evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/isXinLiu/MM-SafetyBench",
      "help_website": [],
      "license": null,
      "tags": [
        "multimodal",
        "safety",
        "benchmark",
        "llm"
      ],
      "id": 459
    },
    {
      "name": "Pynkowski",
      "one_line_profile": "Tool to compute Minkowski Functionals for random fields in cosmology",
      "detailed_description": "A Python package to compute Minkowski Functionals and their expected values for different fields, primarily used in cosmological data analysis (e.g., CMB, Large Scale Structure).",
      "domains": [
        "Physics",
        "Astrophysics"
      ],
      "subtask_category": [
        "data_analysis",
        "topology",
        "statistics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/javicarron/pynkowski",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "cosmology",
        "minkowski-functionals",
        "topology",
        "random-fields"
      ],
      "id": 460
    },
    {
      "name": "HealthFC",
      "one_line_profile": "Framework for verifying health claims using evidence-based medical fact-checking",
      "detailed_description": "HealthFC is a tool and dataset for verifying health claims by retrieving and reasoning over evidence-based medical information.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "fact_checking",
        "verification",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jvladika/HealthFC",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "fact-checking",
        "medical-nlp",
        "health-claims",
        "evidence-based"
      ],
      "id": 461
    },
    {
      "name": "NorMedQA",
      "one_line_profile": "Benchmark for evaluating medical knowledge and reasoning of LLMs in Norwegian",
      "detailed_description": "NorMedQA is a benchmark dataset and evaluation suite designed to assess the medical knowledge and reasoning capabilities of Large Language Models in the Norwegian context.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "evaluation",
        "qa",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/kelkalot/normedqa",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-qa",
        "benchmark",
        "llm",
        "norwegian"
      ],
      "id": 462
    },
    {
      "name": "CMBLensing.jl",
      "one_line_profile": "Julia toolkit for Cosmic Microwave Background (CMB) lensing analysis",
      "detailed_description": "A next-generation tool for analysis of the Cosmic Microwave Background (CMB) lensing, written in Julia. It provides automatic differentiation and GPU compatibility for cosmological analysis.",
      "domains": [
        "Physics",
        "Cosmology"
      ],
      "subtask_category": [
        "simulation",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/marius311/CMBLensing.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "cosmology",
        "cmb",
        "lensing",
        "julia",
        "differentiable-programming"
      ],
      "id": 463
    },
    {
      "name": "PromptCBLUE",
      "one_line_profile": "Instruction-tuning benchmark dataset for Chinese medical LLMs",
      "detailed_description": "A large-scale instruction-tuning dataset and benchmark for multi-task and few-shot learning in the Chinese medical domain. It transforms the CBLUE benchmark into prompt-based formats to evaluate Large Language Models.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "evaluation",
        "benchmark"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/michael-wzhu/PromptCBLUE",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "medical-nlp",
        "benchmark",
        "instruction-tuning",
        "llm-evaluation"
      ],
      "id": 464
    },
    {
      "name": "medical_hallucination",
      "one_line_profile": "Evaluation framework for hallucination in medical foundation models",
      "detailed_description": "A research toolkit associated with the study 'Medical Hallucination in Foundation Models and Their Impact on Healthcare', providing resources to evaluate and analyze hallucinations in Large Language Models within the medical domain.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "evaluation",
        "safety_check"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mitmedialab/medical_hallucination",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hallucination",
        "medical-llm",
        "safety",
        "evaluation"
      ],
      "id": 465
    },
    {
      "name": "pyfisher",
      "one_line_profile": "Fisher matrix forecasting for cosmological surveys",
      "detailed_description": "A Python library for calculating Fisher matrices to forecast the performance of cosmological surveys, specifically for CMB and large-scale structure analysis.",
      "domains": [
        "Physics",
        "Cosmology"
      ],
      "subtask_category": [
        "forecasting",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/msyriac/pyfisher",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "cosmology",
        "fisher-matrix",
        "forecasting"
      ],
      "id": 466
    },
    {
      "name": "cmb_footprint",
      "one_line_profile": "Visualization library for cosmological survey footprints",
      "detailed_description": "A Python library designed to plot and visualize the observation footprints of various cosmological surveys (CMB experiments) on the sky.",
      "domains": [
        "Physics",
        "Cosmology"
      ],
      "subtask_category": [
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nasa-lambda/cmb_footprint",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "cosmology",
        "visualization",
        "survey-footprint"
      ],
      "id": 467
    },
    {
      "name": "BLUE_Benchmark",
      "one_line_profile": "Biomedical Language Understanding Evaluation benchmark",
      "detailed_description": "A comprehensive benchmark suite for evaluating biomedical text-mining models. It consists of five different tasks with ten corpora, covering named entity recognition, relation extraction, and other NLP tasks in biomedicine.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "evaluation",
        "benchmark"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ncbi-nlp/BLUE_Benchmark",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "biomedical-nlp",
        "benchmark",
        "text-mining"
      ],
      "id": 468
    },
    {
      "name": "med-eval",
      "one_line_profile": "Evaluation pipeline for medical NLP tasks",
      "detailed_description": "A pipeline designed to streamline the evaluation of models on various medical tasks, facilitating standardized testing and metric calculation.",
      "domains": [
        "H2",
        "H2-06"
      ],
      "subtask_category": [
        "evaluation",
        "workflow"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/nii-nlp/med-eval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "medical-nlp",
        "evaluation-pipeline"
      ],
      "id": 469
    },
    {
      "name": "MedAlign",
      "one_line_profile": "Clinician-generated dataset for instruction following with electronic medical records",
      "detailed_description": "MedAlign is a dataset and benchmark designed to evaluate instruction-following capabilities of Large Language Models (LLMs) in the context of Electronic Medical Records (EMRs). It includes clinician-generated instructions and ground truth data to assess how well AI models interpret and execute clinical tasks.",
      "domains": [
        "Digital Health",
        "Clinical NLP"
      ],
      "subtask_category": [
        "instruction_following",
        "clinical_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/som-shahlab/medalign",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ehr",
        "medical-nlp",
        "instruction-following",
        "benchmark"
      ],
      "id": 470
    },
    {
      "name": "SafetyBench",
      "one_line_profile": "Comprehensive benchmark for evaluating the safety of Large Language Models",
      "detailed_description": "SafetyBench is a comprehensive benchmark suite designed to evaluate the safety of Large Language Models (LLMs). It covers multiple safety dimensions and provides a framework for testing models against adversarial inputs and unsafe content generation, facilitating the development of safer AI systems.",
      "domains": [
        "AI Safety",
        "LLM Evaluation"
      ],
      "subtask_category": [
        "safety_evaluation",
        "adversarial_testing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-coai/SafetyBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-safety",
        "benchmark",
        "evaluation",
        "trustworthy-ai"
      ],
      "id": 471
    }
  ]
}