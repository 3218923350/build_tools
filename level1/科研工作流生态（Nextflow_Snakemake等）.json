{
  "leaf_cluster_name": "科研工作流生态（Nextflow/Snakemake等）",
  "domain": "Data/Workflow",
  "typical_objects": "pipelines",
  "task_chain": "组件→组合→执行→测试→复现",
  "tool_form": "workflow engine + modules",
  "total_tools": 644,
  "tools": [
    {
      "name": "4DN CWL Pipelines",
      "one_line_profile": "Collection of genomic processing pipelines in Common Workflow Language",
      "detailed_description": "A repository containing the Common Workflow Language (CWL) pipeline definitions used by the 4D Nucleome Data Coordination and Integration Center (4DN-DCIC) for genomic data processing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genomics_pipeline",
        "workflow_definition"
      ],
      "application_level": "workflow",
      "primary_language": "Common Workflow Language",
      "repo_url": "https://github.com/4dn-dcic/pipelines-cwl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cwl",
        "genomics",
        "bioinformatics",
        "pipeline"
      ],
      "id": 1
    },
    {
      "name": "Tibanna",
      "one_line_profile": "Execution engine for running genomic pipelines on AWS",
      "detailed_description": "Tibanna is a software tool that deploys and manages the execution of genomic pipelines (CWL/WDL/Snakemake) on Amazon Web Services (AWS), specifically designed for the 4D Nucleome project.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "cloud_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/4dn-dcic/tibanna",
      "help_website": [
        "https://tibanna.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "aws",
        "genomics",
        "workflow-engine",
        "cwl",
        "wdl"
      ],
      "id": 2
    },
    {
      "name": "DAGEE",
      "one_line_profile": "Directed Acyclic Graph Execution Engine for heterogeneous computing",
      "detailed_description": "A C++ library developed by AMD Research that enables the expression of computation and data movement as task graphs, scheduled concurrently and asynchronously on CPUs and GPUs for high-performance scientific computing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "task_scheduling",
        "parallel_computing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/AMDResearch/DAGEE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hpc",
        "gpu",
        "task-graph",
        "amd"
      ],
      "id": 3
    },
    {
      "name": "APPIAN",
      "one_line_profile": "Automated pipeline for PET/MRI image analysis",
      "detailed_description": "An open-source automated software pipeline designed for analyzing PET images in conjunction with MRI, facilitating tracer kinetic data analysis and reproducible medical imaging research.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "medical_imaging",
        "image_analysis",
        "pet_mri"
      ],
      "application_level": "workflow",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/APPIAN-PET/APPIAN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "neuroimaging",
        "pet",
        "mri",
        "pipeline"
      ],
      "id": 4
    },
    {
      "name": "toil-rnaseq",
      "one_line_profile": "Scalable RNA-seq analysis pipeline based on Toil",
      "detailed_description": "A comprehensive RNA-seq analysis pipeline developed by the UC Santa Cruz Computational Genomics Lab, built on the Toil workflow engine for scalability across cloud and local environments.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "rna_seq",
        "genomics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/BD2KGenomics/toil-rnaseq",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rna-seq",
        "bioinformatics",
        "toil",
        "pipeline"
      ],
      "id": 5
    },
    {
      "name": "toil-scripts",
      "one_line_profile": "Collection of genomic workflows for Toil",
      "detailed_description": "A repository containing various genomic pipelines and workflows (e.g., exome variant calling) implemented to run on the Toil workflow engine.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "genomics_pipeline",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/BD2KGenomics/toil-scripts",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "genomics",
        "bioinformatics",
        "toil"
      ],
      "id": 6
    },
    {
      "name": "GridBee Framework",
      "one_line_profile": "Browser-based distributed computing framework for BOINC",
      "detailed_description": "A JavaScript framework that enables web browsers to participate in volunteer distributed computing projects by communicating with BOINC servers, facilitating citizen science.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "distributed_computing",
        "volunteer_computing"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/BME-IK/gridbee-framework",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "boinc",
        "distributed-computing",
        "citizen-science"
      ],
      "id": 7
    },
    {
      "name": "iSkyLIMS",
      "one_line_profile": "LIMS for NGS sample and bioinformatics management",
      "detailed_description": "An open-source Laboratory Information Management System (LIMS) specifically designed for Next Generation Sequencing (NGS) centers to manage samples, wet-lab workflows, and bioinformatics analysis services.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "lab_management",
        "sample_tracking",
        "bioinformatics_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/BU-ISCIII/iskylims",
      "help_website": [
        "http://iskylims.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "lims",
        "ngs",
        "bioinformatics",
        "lab-management"
      ],
      "id": 8
    },
    {
      "name": "Cromwell Frontend",
      "one_line_profile": "Web interface for Cromwell workflow engine",
      "detailed_description": "A web-based frontend for the Cromwell job server, providing authentication and management capabilities for scientific workflow definitions and executions.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "job_monitoring"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/BiRG/cromwell-frontend",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cromwell",
        "workflow-gui",
        "bioinformatics"
      ],
      "id": 9
    },
    {
      "name": "CWL.jl",
      "one_line_profile": "Julia interface for Common Workflow Language",
      "detailed_description": "A Julia package providing utilities for working with the Common Workflow Language (CWL), enabling Julia-based scientific workflows to interact with the CWL ecosystem.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_definition",
        "interoperability"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/BioJulia/CWL.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "cwl",
        "bioinformatics",
        "workflow"
      ],
      "id": 10
    },
    {
      "name": "CmdParser",
      "one_line_profile": "Command line parser and CWL creator",
      "detailed_description": "A C++ tool designed to parse command line arguments and automatically generate or read Common Workflow Language (CWL) specifications, facilitating the integration of command-line tools into scientific workflows.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_generation",
        "tool_wrapping"
      ],
      "application_level": "tool",
      "primary_language": "C++",
      "repo_url": "https://github.com/CBICA/CmdParser",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "cwl",
        "cli",
        "workflow-automation"
      ],
      "id": 11
    },
    {
      "name": "CalliNGS-NF",
      "one_line_profile": "Nextflow pipeline for GATK RNA-Seq variant calling",
      "detailed_description": "A Nextflow pipeline implementing the GATK Best Practices for RNA-Seq variant calling, developed by CRG-CNAG for reproducible genomic analysis.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "variant_calling",
        "rna_seq",
        "genomics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/CRG-CNAG/CalliNGS-NF",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "nextflow",
        "gatk",
        "rna-seq",
        "bioinformatics"
      ],
      "id": 12
    },
    {
      "name": "ClarityNLP",
      "one_line_profile": "NLP framework for clinical phenotyping",
      "detailed_description": "A Natural Language Processing framework specifically designed for extracting clinical phenotypes from medical notes and reports, supporting healthcare research and data analysis.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "clinical_nlp",
        "phenotyping",
        "text_mining"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ClarityNLP/ClarityNLP",
      "help_website": [
        "http://claritynlp.readthedocs.io/en/latest/"
      ],
      "license": "MPL-2.0",
      "tags": [
        "nlp",
        "clinical-informatics",
        "phenotyping",
        "healthcare"
      ],
      "id": 13
    },
    {
      "name": "FogBus2",
      "one_line_profile": "Distributed framework for IoT-Edge-Cloud integration",
      "detailed_description": "A lightweight and distributed container-based framework designed for research in integrating IoT systems with Edge and Cloud computing environments, facilitating experimental evaluation of distributed architectures.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "distributed_computing",
        "edge_computing",
        "iot_simulation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Cloudslab/FogBus2",
      "help_website": [],
      "license": null,
      "tags": [
        "edge-computing",
        "iot",
        "distributed-systems",
        "research-framework"
      ],
      "id": 14
    },
    {
      "name": "ChIPseq_workflows",
      "one_line_profile": "CWL workflows for ChIP-seq and Cut&Run analysis",
      "detailed_description": "A collection of Common Workflow Language (CWL) workflows for processing ChIP-seq, ChIPmentation, and Cut&Run sequencing data, maintained by the Computational Epigenetics group.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "chip_seq",
        "epigenetics",
        "genomics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Common Workflow Language",
      "repo_url": "https://github.com/CompEpigen/ChIPseq_workflows",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "cwl",
        "chip-seq",
        "epigenetics",
        "bioinformatics"
      ],
      "id": 15
    },
    {
      "name": "Toil",
      "one_line_profile": "Scalable workflow engine for CWL, WDL and Python pipelines",
      "detailed_description": "A scalable, efficient, cross-platform workflow engine that supports Common Workflow Language (CWL), Workflow Description Language (WDL), and Python workflow definitions, widely used in genomic data processing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "pipeline_orchestration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DataBiosphere/toil",
      "help_website": [
        "https://toil.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "cwl",
        "wdl",
        "bioinformatics",
        "cloud-computing"
      ],
      "id": 16
    },
    {
      "name": "fold_tree",
      "one_line_profile": "Snakemake pipeline for creating phylogenetic trees from sequence sets",
      "detailed_description": "A Snakemake workflow designed to automate the generation of phylogenetic trees from sets of biological sequences, facilitating evolutionary analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "phylogenetics",
        "tree_building"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/DessimozLab/fold_tree",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "phylogenetics",
        "bioinformatics"
      ],
      "id": 17
    },
    {
      "name": "VIRify",
      "one_line_profile": "Pipeline for detection of phages and eukaryotic viruses from metagenomic assemblies",
      "detailed_description": "A bioinformatics pipeline developed by EBI for identifying viral signals (phages and eukaryotic viruses) in metagenomic and metatranscriptomic assembly data.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "metagenomics",
        "viral_detection"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/EBI-Metagenomics/emg-viral-pipeline",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "metagenomics",
        "virus",
        "bioinformatics"
      ],
      "id": 18
    },
    {
      "name": "REAT",
      "one_line_profile": "Robust Eukaryotic Annotation Toolkit for genome annotation",
      "detailed_description": "A toolkit designed to improve the robustness and accuracy of eukaryotic genome annotation, developed by the Earlham Institute.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genome_annotation",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/EI-CoreBioinformatics/reat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "annotation",
        "genomics",
        "eukaryotic"
      ],
      "id": 19
    },
    {
      "name": "Caper",
      "one_line_profile": "Python wrapper for Cromwell workflow engine to simplify cloud/HPC execution",
      "detailed_description": "A wrapper tool for the Cromwell workflow engine (WDL) that simplifies the configuration and execution of pipelines on various backends including Google Cloud and HPC clusters, widely used in the ENCODE project.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "pipeline_execution"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ENCODE-DCC/caper",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cromwell",
        "wdl",
        "workflow-management"
      ],
      "id": 20
    },
    {
      "name": "Croo",
      "one_line_profile": "Output organizer for Cromwell workflows",
      "detailed_description": "A utility tool designed to organize and manage the output files generated by Cromwell workflows, facilitating data management in large-scale genomic analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_utility",
        "data_organization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ENCODE-DCC/croo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cromwell",
        "workflow",
        "utility"
      ],
      "id": 21
    },
    {
      "name": "MAG_Snakemake_wf",
      "one_line_profile": "Pipeline for recovery of prokaryotic genomes from shotgun metagenomic data",
      "detailed_description": "A Snakemake workflow for the recovery of Metagenome-Assembled Genomes (MAGs) from shotgun sequencing data, automating assembly and binning steps.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "metagenomics",
        "genome_assembly"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/Finn-Lab/MAG_Snakemake_wf",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "snakemake",
        "metagenomics",
        "mag"
      ],
      "id": 22
    },
    {
      "name": "GalSim",
      "one_line_profile": "Modular galaxy image simulation toolkit for astronomy",
      "detailed_description": "A software library for simulating images of galaxies and stars, widely used in the weak lensing community for testing measurement algorithms.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "simulation",
        "astronomy"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/GalSim-developers/GalSim",
      "help_website": [
        "https://galsim-developers.github.io/GalSim/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "astronomy",
        "simulation",
        "image-processing"
      ],
      "id": 23
    },
    {
      "name": "sv-callers",
      "one_line_profile": "Snakemake workflow for detecting structural variants in genomic data",
      "detailed_description": "A comprehensive Snakemake-based workflow that integrates multiple structural variant calling tools for genomic data analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "variant_calling",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/GooglingTheCancerGenome/sv-callers",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "snakemake",
        "structural-variants",
        "genomics"
      ],
      "id": 24
    },
    {
      "name": "dropSeqPipe",
      "one_line_profile": "Snakemake workflow for SingleCell RNASeq pre-processing",
      "detailed_description": "A pipeline for processing Drop-Seq data, handling steps from raw reads to expression matrices, implemented using Snakemake.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "scRNA-seq",
        "preprocessing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Hoohm/dropSeqPipe",
      "help_website": [],
      "license": "CC-BY-SA-4.0",
      "tags": [
        "snakemake",
        "rnaseq",
        "single-cell"
      ],
      "id": 25
    },
    {
      "name": "HyperQueue",
      "one_line_profile": "Efficient sub-node task scheduler for HPC systems",
      "detailed_description": "A task scheduler designed for High Performance Computing (HPC) environments to efficiently execute a large number of sub-node tasks, reducing overhead on clusters like Slurm or PBS.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "task_scheduling",
        "hpc"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/It4innovations/hyperqueue",
      "help_website": [
        "https://it4innovations.github.io/hyperqueue/"
      ],
      "license": "MIT",
      "tags": [
        "hpc",
        "scheduler",
        "rust"
      ],
      "id": 26
    },
    {
      "name": "Dagger.jl",
      "one_line_profile": "Framework for out-of-core and parallel execution in Julia",
      "detailed_description": "A Julia library for parallel and out-of-core computing, enabling scalable scientific calculations by constructing and executing dynamic task graphs.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "parallel_computing",
        "scientific_computing"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaParallel/Dagger.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "julia",
        "parallel-computing",
        "dag"
      ],
      "id": 27
    },
    {
      "name": "pytest-workflow",
      "one_line_profile": "Test framework for scientific workflows/pipelines (Nextflow, Snakemake, etc.)",
      "detailed_description": "A pytest plugin designed to test scientific workflows (like Nextflow, Snakemake, WDL) by running them and validating the output files against expected results.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pipeline_testing",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/LUMC/pytest-workflow",
      "help_website": [
        "https://pytest-workflow.readthedocs.io/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "testing",
        "workflow",
        "bioinformatics",
        "pipeline-validation"
      ],
      "id": 28
    },
    {
      "name": "LuigiNLP",
      "one_line_profile": "Workflow system specifically designed for Natural Language Processing",
      "detailed_description": "A workflow system built on top of Luigi, providing specific functionality and abstractions for constructing and managing Natural Language Processing (NLP) pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "nlp_workflow",
        "text_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/LanguageMachines/LuigiNLP",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "nlp",
        "workflow",
        "luigi",
        "pipeline"
      ],
      "id": 29
    },
    {
      "name": "AWE",
      "one_line_profile": "Workflow and resource management system for bioinformatics",
      "detailed_description": "AWE (Shock) is a workflow and resource management system designed for scalable bioinformatics data analysis, often used in conjunction with MG-RAST.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "resource_scheduling"
      ],
      "application_level": "workflow",
      "primary_language": "Go",
      "repo_url": "https://github.com/MG-RAST/AWE",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "bioinformatics",
        "workflow-engine",
        "distributed-computing"
      ],
      "id": 30
    },
    {
      "name": "pgsc_calc",
      "one_line_profile": "Nextflow pipeline for polygenic score calculation",
      "detailed_description": "A reproducible Nextflow pipeline for calculating polygenic scores (PGS) from genomic data, integrating with the PGS Catalog.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "polygenic_score_calculation",
        "genomic_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/PGScatalog/pgsc_calc",
      "help_website": [
        "https://pgsc-calc.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nextflow",
        "bioinformatics",
        "genomics",
        "polygenic-scores"
      ],
      "id": 31
    },
    {
      "name": "HiFi-16S-workflow",
      "one_line_profile": "Nextflow pipeline for PacBio HiFi 16S rRNA analysis",
      "detailed_description": "A bioinformatics pipeline built with Nextflow for analyzing full-length 16S rRNA sequencing data generated by PacBio HiFi technology.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "16s_analysis",
        "metagenomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/PacificBiosciences/HiFi-16S-workflow",
      "help_website": [],
      "license": "BSD-3-Clause-Clear",
      "tags": [
        "nextflow",
        "pacbio",
        "16s",
        "microbiome"
      ],
      "id": 32
    },
    {
      "name": "PyPSA-Eur",
      "one_line_profile": "Sector-coupled open optimisation model of the European energy system",
      "detailed_description": "PyPSA-Eur is an open optimization model of the European energy system that includes electricity, transport, and heat sectors. It uses the PyPSA library to model and optimize energy flows, generation, and transmission across Europe.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "energy_modeling",
        "optimization",
        "simulation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/PyPSA/pypsa-eur",
      "help_website": [
        "https://pypsa-eur.readthedocs.io"
      ],
      "license": null,
      "tags": [
        "energy-system",
        "optimization",
        "pypsa",
        "simulation"
      ],
      "id": 33
    },
    {
      "name": "VesselExpress",
      "one_line_profile": "Automated analysis pipeline for 3D light-sheet images of blood vasculature",
      "detailed_description": "VesselExpress is a tool for the automated analysis of blood vasculature in 3D light-sheet image volumes. It performs segmentation, skeletonization, and quantitative analysis of vascular networks.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "image_analysis",
        "segmentation",
        "quantification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RUB-Bioinf/VesselExpress",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bioimage-analysis",
        "vasculature",
        "light-sheet-microscopy",
        "3d-imaging"
      ],
      "id": 34
    },
    {
      "name": "reticulatus",
      "one_line_profile": "Snakemake-based pipeline for assembling and polishing long genomes",
      "detailed_description": "Reticulatus is a bioinformatics pipeline built with Snakemake for assembling and polishing genomes using long nanopore reads. It automates the workflow from raw reads to polished assemblies.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genome_assembly",
        "polishing",
        "workflow"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/SamStudio8/reticulatus",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "nanopore",
        "genomics",
        "assembly"
      ],
      "id": 35
    },
    {
      "name": "QA-Board",
      "one_line_profile": "Experiment tracker and visualization platform for algorithm R&D",
      "detailed_description": "QA-Board is an experiment tracking tool designed for algorithm and performance R&D. It allows researchers to organize, visualize, compare, and share runs, specifically targeting tuning and optimization in scientific/engineering contexts.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "experiment_tracking",
        "visualization",
        "performance_analysis"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/Samsung/qaboard",
      "help_website": [
        "https://samsung.github.io/qaboard/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "experiment-tracking",
        "r-and-d",
        "visualization",
        "tuning"
      ],
      "id": 36
    },
    {
      "name": "Proteus",
      "one_line_profile": "Transpiler for converting Common Workflow Language (CWL) to Argo Workflows",
      "detailed_description": "Proteus is a utility that transpiles Common Workflow Language (CWL) definitions into Argo Workflow syntax, facilitating the execution of standard scientific workflows on Kubernetes-based Argo clusters.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_conversion",
        "pipeline_management"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/SerRichard/proteus",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "cwl",
        "argo-workflows",
        "transpiler",
        "scientific-workflow"
      ],
      "id": 37
    },
    {
      "name": "ACES",
      "one_line_profile": "Workflow for querying small sequences in large genomes with phylogenetic analysis",
      "detailed_description": "ACES is a bioinformatics workflow designed to query small sequences within a large set of genomes. It produces BLAST results, multiple sequence alignments, fragment assemblies, and phylogenetic trees.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "sequence_alignment",
        "phylogenetic_analysis",
        "assembly"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/TNTurnerLab/ACES",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "genomics",
        "phylogeny",
        "blast",
        "alignment"
      ],
      "id": 38
    },
    {
      "name": "Timefold Solver",
      "one_line_profile": "AI constraint solver for optimizing planning and scheduling problems",
      "detailed_description": "Timefold Solver is an open-source constraint satisfaction solver that optimizes complex planning and scheduling problems (e.g., vehicle routing, rostering) using AI algorithms. It is applicable to operations research and scientific optimization tasks.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "optimization",
        "scheduling",
        "planning"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/TimefoldAI/timefold-solver",
      "help_website": [
        "https://timefold.ai/docs/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "optimization",
        "solver",
        "operations-research",
        "constraint-satisfaction"
      ],
      "id": 39
    },
    {
      "name": "AkôFlow",
      "one_line_profile": "Middleware for orchestrating container-based scientific workflows",
      "detailed_description": "AkôFlow is a middleware designed for orchestrating and executing container-based scientific workflows across heterogeneous environments. It focuses on the specific needs of scientific computing and reproducibility.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "execution_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/UFFeScience/akoflow",
      "help_website": [],
      "license": null,
      "tags": [
        "scientific-workflow",
        "orchestration",
        "containers",
        "middleware"
      ],
      "id": 40
    },
    {
      "name": "snk",
      "one_line_profile": "CLI generation tool for Snakemake workflows",
      "detailed_description": "Snk is a tool that automatically generates a Command Line Interface (CLI) for Snakemake workflows, making scientific pipelines easier to distribute and execute as standalone applications.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "cli_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Wytamma/snk",
      "help_website": [
        "https://snk.wytamma.com"
      ],
      "license": "MIT",
      "tags": [
        "snakemake",
        "cli",
        "workflow",
        "reproducibility"
      ],
      "id": 41
    },
    {
      "name": "Oozie",
      "one_line_profile": "Workflow scheduler system to manage Apache Hadoop jobs",
      "detailed_description": "Oozie is a workflow scheduler system to manage Apache Hadoop jobs. It allows users to define actions (such as MapReduce, Spark, Hive, Pig) in a Directed Acyclic Graph (DAG) and orchestrate their execution. While primarily a big data tool, it is widely used in scientific data engineering pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "job_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/YahooArchive/oozie",
      "help_website": [
        "http://oozie.apache.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "hadoop",
        "scheduler",
        "etl"
      ],
      "id": 42
    },
    {
      "name": "yawn",
      "one_line_profile": "Lightweight subprocess-based DAG execution system",
      "detailed_description": "Yawn (Yet Another Workflow Engine) is a lightweight workflow engine designed to execute Directed Acyclic Graphs (DAGs) of subprocesses. It provides a simple PostgreSQL-backed queue and execution system for managing dependent tasks.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "task_execution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aclowes/yawn",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "workflow-engine",
        "dag",
        "python",
        "task-scheduler"
      ],
      "id": 43
    },
    {
      "name": "Wexflow",
      "one_line_profile": "Extensible workflow automation engine with a cross-platform backend",
      "detailed_description": "Wexflow is a high-performance, extensible workflow automation engine. It allows users to design and execute complex workflows involving file processing, database operations, and system interactions. It supports a wide range of tasks and provides a backend for orchestration.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_automation",
        "process_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "C#",
      "repo_url": "https://github.com/aelassas/wexflow",
      "help_website": [
        "https://wexflow.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "workflow-engine",
        "automation",
        "c-sharp",
        "etl"
      ],
      "id": 44
    },
    {
      "name": "BindFlow",
      "one_line_profile": "Snakemake workflow for FEP and MM(PB/GB)SA calculations with GROMACS",
      "detailed_description": "BindFlow is a scientific workflow built on Snakemake for automating Free Energy Perturbation (FEP) and Molecular Mechanics Poisson-Boltzmann/Generalized Born Surface Area (MM/PBSA, MM/GBSA) calculations using GROMACS. It streamlines molecular dynamics simulation analysis.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "molecular_dynamics",
        "free_energy_calculation",
        "workflow_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ale94mleon/BindFlow",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "snakemake",
        "gromacs",
        "molecular-dynamics",
        "bioinformatics"
      ],
      "id": 45
    },
    {
      "name": "Table-Computing",
      "one_line_profile": "High-performance distributed computing framework for relational operations",
      "detailed_description": "Table-Computing (TC) is a high-performance, low-latency distributed computing framework designed to handle complicated use cases faster than Flink. It focuses on relational operations and provides a lightweight, distributed engine for data processing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "distributed_computing",
        "data_processing"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/alibaba/table-computing",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-computing",
        "data-processing",
        "framework"
      ],
      "id": 46
    },
    {
      "name": "DependsWorkflow",
      "one_line_profile": "Workflow management system for dependency-based task execution",
      "detailed_description": "DependsWorkflow is a workflow management system designed to handle task dependencies and execution. It provides a framework for defining and running computational workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "task_execution"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/andrew-gardner/dependsworkflow",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "workflow-management",
        "python",
        "pipeline"
      ],
      "id": 47
    },
    {
      "name": "FedERA",
      "one_line_profile": "Modular and customizable Federated Learning framework",
      "detailed_description": "FedERA is an open-source Federated Learning (FL) framework designed for heterogeneous edge devices. It supports both standalone and distributed computing, enabling the orchestration of training workflows across decentralized data sources, which is critical for privacy-preserving scientific modeling.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "federated_learning",
        "distributed_training",
        "model_orchestration"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/anupamkliv/FedERA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "federated-learning",
        "distributed-computing",
        "edge-computing"
      ],
      "id": 48
    },
    {
      "name": "Apache Airflow",
      "one_line_profile": "Platform to programmatically author, schedule, and monitor workflows",
      "detailed_description": "Apache Airflow is a platform to programmatically author, schedule, and monitor workflows. It allows users to define workflows as code (DAGs), providing a rich user interface to visualize pipelines, monitor progress, and troubleshoot issues. It is a standard tool for orchestrating scientific and data engineering pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "pipeline_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/apache/airflow",
      "help_website": [
        "https://airflow.apache.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "orchestration",
        "python",
        "dag"
      ],
      "id": 49
    },
    {
      "name": "Auron",
      "one_line_profile": "Accelerator for distributed computing frameworks leveraging vectorized execution",
      "detailed_description": "Auron is an accelerator for distributed computing frameworks (like Apache Spark) that leverages native vectorized execution to speed up query processing and data transformation tasks. It enhances the performance of data-intensive scientific workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "data_processing_acceleration",
        "vectorized_execution"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/apache/auron",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "spark-accelerator",
        "distributed-computing",
        "rust",
        "performance"
      ],
      "id": 50
    },
    {
      "name": "ccwl",
      "one_line_profile": "Compiler for Concise Common Workflow Language (CWL)",
      "detailed_description": "A compiler and toolchain for a concise dialect of the Common Workflow Language (CWL), designed to simplify the creation of scientific workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_compilation",
        "pipeline_definition"
      ],
      "application_level": "solver",
      "primary_language": "Scheme",
      "repo_url": "https://github.com/arunisaac/ccwl",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "cwl",
        "workflow",
        "bioinformatics",
        "compiler"
      ],
      "id": 51
    },
    {
      "name": "nf-test",
      "one_line_profile": "Testing framework for Nextflow pipelines",
      "detailed_description": "A simple and powerful testing framework specifically designed for Nextflow pipelines, enabling developers to write and run tests for scientific workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_testing",
        "pipeline_validation"
      ],
      "application_level": "workflow",
      "primary_language": "Java",
      "repo_url": "https://github.com/askimed/nf-test",
      "help_website": [
        "https://www.nf-test.com"
      ],
      "license": "MIT",
      "tags": [
        "nextflow",
        "testing",
        "bioinformatics",
        "pipeline"
      ],
      "id": 52
    },
    {
      "name": "FlowCraft",
      "one_line_profile": "Component-based pipeline composer for omics analysis",
      "detailed_description": "A tool to build Nextflow pipelines for omics analysis by assembling pre-defined components, facilitating the creation of reproducible bioinformatics workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pipeline_composition",
        "omics_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/assemblerflow/flowcraft",
      "help_website": [
        "https://flowcraft.readthedocs.io"
      ],
      "license": "GPL-3.0",
      "tags": [
        "nextflow",
        "omics",
        "bioinformatics",
        "pipeline-builder"
      ],
      "id": 53
    },
    {
      "name": "Bactopia",
      "one_line_profile": "Flexible pipeline for complete analysis of bacterial genomes",
      "detailed_description": "A comprehensive and flexible workflow for bacterial genome analysis, integrating numerous bioinformatics tools for QC, assembly, annotation, and variant calling.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genome_analysis",
        "bacterial_genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/bactopia/bactopia",
      "help_website": [
        "https://bactopia.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "bacteria",
        "genomics",
        "nextflow"
      ],
      "id": 54
    },
    {
      "name": "Snaketool",
      "one_line_profile": "Cookiecutter profile for creating Snakemake-based bioinformatics tools",
      "detailed_description": "A scaffolding tool that helps researchers and developers create standardized, reproducible bioinformatics pipelines using Snakemake.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pipeline_development",
        "workflow_scaffolding"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/beardymcjohnface/Snaketool",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "bioinformatics",
        "cookiecutter",
        "reproducibility"
      ],
      "id": 55
    },
    {
      "name": "docker-galaxy",
      "one_line_profile": "Dockerized deployment for the Galaxy scientific workflow platform",
      "detailed_description": "A collection of Docker images designed to deploy and manage stable releases of the Galaxy bioinformatics platform, facilitating reproducible scientific workflow execution.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_deployment",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/bgruening/docker-galaxy",
      "help_website": [
        "https://github.com/bgruening/docker-galaxy"
      ],
      "license": "MIT",
      "tags": [
        "galaxy",
        "docker",
        "bioinformatics",
        "workflow"
      ],
      "id": 56
    },
    {
      "name": "kraken2_classification",
      "one_line_profile": "Snakemake workflow for metagenomic classification using Kraken2",
      "detailed_description": "A Snakemake-based pipeline designed for metagenomic classification tasks, automating the execution of Kraken2 for taxonomic sequence classification.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "metagenomics",
        "taxonomic_classification"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bhattlab/kraken2_classification",
      "help_website": [
        "https://github.com/bhattlab/kraken2_classification"
      ],
      "license": null,
      "tags": [
        "snakemake",
        "metagenomics",
        "kraken2",
        "bioinformatics"
      ],
      "id": 57
    },
    {
      "name": "ABFE_workflow",
      "one_line_profile": "Snakemake workflow for Absolute Binding Free Energy calculations",
      "detailed_description": "A scalable Snakemake workflow designed for high-throughput Absolute Binding Free Energy (ABFE) calculations in computational chemistry, supporting Slurm execution.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "molecular_dynamics",
        "free_energy_calculation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bigginlab/ABFE_workflow",
      "help_website": [
        "https://github.com/bigginlab/ABFE_workflow"
      ],
      "license": "GPL-3.0",
      "tags": [
        "snakemake",
        "computational-chemistry",
        "abfe",
        "molecular-dynamics"
      ],
      "id": 58
    },
    {
      "name": "master_of_pores",
      "one_line_profile": "Nextflow pipeline for direct RNA Nanopore sequencing analysis",
      "detailed_description": "A Nextflow pipeline specifically designed for the analysis of direct RNA sequencing data from Nanopore devices, handling alignment, quality control, and modification detection.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "rna_seq_analysis",
        "nanopore_sequencing"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/biocorecrg/master_of_pores",
      "help_website": [
        "https://github.com/biocorecrg/master_of_pores"
      ],
      "license": "MIT",
      "tags": [
        "nextflow",
        "nanopore",
        "rna-seq",
        "bioinformatics"
      ],
      "id": 59
    },
    {
      "name": "cromshell",
      "one_line_profile": "CLI tool for interacting with the Cromwell workflow engine",
      "detailed_description": "A command-line interface for submitting workflows, checking status, and retrieving metadata from a Cromwell server, streamlining scientific workflow management.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "job_submission"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/broadinstitute/cromshell",
      "help_website": [
        "https://github.com/broadinstitute/cromshell"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "cromwell",
        "wdl",
        "cli",
        "workflow-management"
      ],
      "id": 60
    },
    {
      "name": "Cromwell",
      "one_line_profile": "Scientific workflow engine for WDL and CWL",
      "detailed_description": "A workflow management system designed to simplify the definition and execution of scientific workflows, supporting both WDL and CWL standards, scalable from local to cloud environments.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "pipeline_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Scala",
      "repo_url": "https://github.com/broadinstitute/cromwell",
      "help_website": [
        "https://cromwell.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "wdl",
        "cwl",
        "workflow-engine",
        "bioinformatics"
      ],
      "id": 61
    },
    {
      "name": "cromwell-tools",
      "one_line_profile": "Python client library for the Cromwell workflow engine",
      "detailed_description": "A collection of Python clients and utility scripts for interacting with the Cromwell workflow engine API, facilitating programmatic workflow submission and monitoring.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "api_client"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/broadinstitute/cromwell-tools",
      "help_website": [
        "https://github.com/broadinstitute/cromwell-tools"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "cromwell",
        "python",
        "api-client",
        "workflow"
      ],
      "id": 62
    },
    {
      "name": "wdl-ide",
      "one_line_profile": "IDE support tools for Workflow Description Language (WDL)",
      "detailed_description": "Provides rich IDE features such as syntax highlighting, code completion, and validation for developing scientific workflows in WDL.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_authoring",
        "code_development"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/broadinstitute/wdl-ide",
      "help_website": [
        "https://github.com/broadinstitute/wdl-ide"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "wdl",
        "ide",
        "workflow-development"
      ],
      "id": 63
    },
    {
      "name": "calkit",
      "one_line_profile": "Project management tool for reproducible research pipelines",
      "detailed_description": "A command-line tool that simplifies version control, environment management, and pipeline execution specifically for reproducible scientific research projects.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "reproducibility_management",
        "pipeline_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/calkit/calkit",
      "help_website": [
        "https://github.com/calkit/calkit"
      ],
      "license": "MIT",
      "tags": [
        "reproducibility",
        "research-management",
        "pipeline",
        "git"
      ],
      "id": 64
    },
    {
      "name": "V-pipe",
      "one_line_profile": "Bioinformatics pipeline for viral genome analysis",
      "detailed_description": "A workflow designed for the analysis of next-generation sequencing (NGS) data from short viral genomes, facilitating variant calling and viral diversity analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "viral_genomics",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/cbg-ethz/V-pipe",
      "help_website": [
        "https://cbg-ethz.github.io/V-pipe/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "bioinformatics",
        "virus",
        "ngs",
        "snakemake"
      ],
      "id": 65
    },
    {
      "name": "exelixi",
      "one_line_profile": "Distributed framework for genetic algorithms",
      "detailed_description": "A distributed computing framework based on Apache Mesos, designed to run genetic algorithms and other partitioned batch jobs at scale using Python.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genetic_algorithm",
        "optimization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ceteri/exelixi",
      "help_website": [
        "https://github.com/ceteri/exelixi"
      ],
      "license": "Apache-2.0",
      "tags": [
        "genetic-algorithm",
        "distributed-computing",
        "mesos",
        "optimization"
      ],
      "id": 66
    },
    {
      "name": "miniwdl",
      "one_line_profile": "Local runner and developer toolkit for WDL workflows",
      "detailed_description": "A local runner and developer toolkit for the Workflow Description Language (WDL), enabling rapid development, testing, and execution of scientific workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "workflow_development"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chanzuckerberg/miniwdl",
      "help_website": [
        "https://miniwdl.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "wdl",
        "workflow-runner",
        "bioinformatics",
        "developer-tools"
      ],
      "id": 67
    },
    {
      "name": "Gleam",
      "one_line_profile": "Fast, scalable distributed map/reduce system and DAG execution engine",
      "detailed_description": "Gleam is a high-performance distributed execution system written in Go. It provides a MapReduce-like framework and DAG execution capabilities, allowing for scalable data processing in memory or on disk, suitable for large-scale scientific data analysis pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "distributed_computing",
        "dag_execution"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/chrislusf/gleam",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mapreduce",
        "distributed-computing",
        "dag",
        "go"
      ],
      "id": 68
    },
    {
      "name": "Parabricks WDL",
      "one_line_profile": "Accelerated genomics workflows using NVIDIA Parabricks in WDL",
      "detailed_description": "A collection of Workflow Description Language (WDL) scripts for running NVIDIA Clara Parabricks pipelines. These workflows enable accelerated genomic analysis, including germline and somatic variant calling, on GPU-enabled infrastructure.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genomics_pipeline",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/clara-parabricks-workflows/parabricks-wdl",
      "help_website": [
        "https://docs.nvidia.com/clara/parabricks/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "genomics",
        "wdl",
        "gpu-acceleration",
        "bioinformatics"
      ],
      "id": 69
    },
    {
      "name": "ClearML",
      "one_line_profile": "Integrated MLOps platform for experiment management and orchestration",
      "detailed_description": "ClearML is an open-source MLOps platform that automates the tracking, orchestration, and management of machine learning experiments and pipelines. It provides tools for data management, remote execution, and model serving, facilitating reproducible AI for Science workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "experiment_tracking",
        "pipeline_orchestration",
        "mlops"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/clearml/clearml",
      "help_website": [
        "https://clear.ml/docs/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "experiment-tracking",
        "orchestration",
        "reproducibility"
      ],
      "id": 70
    },
    {
      "name": "ClearML Server",
      "one_line_profile": "Backend server for the ClearML MLOps platform",
      "detailed_description": "The backend infrastructure for ClearML, handling the storage, synchronization, and management of experiment data, model artifacts, and workflow orchestration logic. It serves as the central engine for self-hosted ClearML deployments.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "experiment_tracking",
        "pipeline_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/clearml/clearml-server",
      "help_website": [
        "https://clear.ml/docs/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "mlops",
        "backend",
        "server",
        "orchestration"
      ],
      "id": 71
    },
    {
      "name": "CompareM2",
      "one_line_profile": "Microbial genomes-to-report analysis pipeline",
      "detailed_description": "A comprehensive bioinformatics pipeline for processing microbial genomes. It automates the workflow from raw genomic data to final analytical reports, facilitating comparative genomics and quality assessment.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "microbial_genomics",
        "comparative_genomics",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/cmkobel/CompareM2",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "microbiology",
        "genomics",
        "pipeline",
        "snakemake"
      ],
      "id": 72
    },
    {
      "name": "cwldep",
      "one_line_profile": "Dependency manager for Common Workflow Language documents",
      "detailed_description": "A utility tool for managing dependencies within Common Workflow Language (CWL) projects. It allows users to define, install, and manage external CWL tools and workflow references, streamlining the development of complex scientific workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "dependency_management"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/common-workflow-language/cwldep",
      "help_website": [
        "https://www.commonwl.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "cwl",
        "dependency-manager",
        "workflow"
      ],
      "id": 73
    },
    {
      "name": "cwljava",
      "one_line_profile": "Java SDK for Common Workflow Language standards",
      "detailed_description": "A Java library providing support for the Common Workflow Language (CWL) standards. It enables Java applications to parse, validate, and interact with CWL workflow definitions, facilitating the integration of CWL into Java-based scientific tools.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_development",
        "interoperability"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/common-workflow-language/cwljava",
      "help_website": [
        "https://www.commonwl.org/"
      ],
      "license": null,
      "tags": [
        "cwl",
        "java",
        "sdk",
        "workflow"
      ],
      "id": 74
    },
    {
      "name": "cwltool",
      "one_line_profile": "Reference implementation of the Common Workflow Language",
      "detailed_description": "The official reference implementation for the Common Workflow Language (CWL). It serves as a portable workflow runner that can execute CWL descriptions for data analysis pipelines, ensuring compliance with the CWL standard.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "pipeline_runner"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/common-workflow-language/cwltool",
      "help_website": [
        "https://cwltool.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "cwl",
        "workflow-engine",
        "reproducibility",
        "bioinformatics"
      ],
      "id": 75
    },
    {
      "name": "CWL Viewer",
      "one_line_profile": "Web application to view and visualize CWL workflows",
      "detailed_description": "A visualization tool that generates graphical representations of Common Workflow Language (CWL) workflows. It helps researchers understand workflow structure, inputs, and outputs, aiding in the documentation and sharing of scientific pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_visualization",
        "documentation"
      ],
      "application_level": "service",
      "primary_language": "Java",
      "repo_url": "https://github.com/common-workflow-language/cwlviewer",
      "help_website": [
        "https://view.commonwl.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "cwl",
        "visualization",
        "workflow",
        "web-tool"
      ],
      "id": 76
    },
    {
      "name": "ncov2019-artic-nf",
      "one_line_profile": "Nextflow pipeline for SARS-CoV-2 ARTIC field bioinformatics",
      "detailed_description": "A Nextflow pipeline designed for the analysis of SARS-CoV-2 sequencing data using the ARTIC network protocols. It automates alignment, variant calling, and consensus sequence generation for viral genomics surveillance.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "viral_genomics",
        "variant_calling",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/connor-lab/ncov2019-artic-nf",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "covid-19",
        "nextflow",
        "bioinformatics",
        "artic-network"
      ],
      "id": 77
    },
    {
      "name": "Couler",
      "one_line_profile": "Unified interface for constructing workflows on Argo, Tekton, and Airflow",
      "detailed_description": "Couler provides a unified Python API for defining and managing workflows across different execution engines like Argo Workflows, Tekton, and Apache Airflow. It simplifies the creation of complex machine learning and data processing pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_definition",
        "pipeline_orchestration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/couler-proj/couler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "workflow",
        "argo",
        "tekton",
        "airflow",
        "mlops"
      ],
      "id": 78
    },
    {
      "name": "pyflow-ATACseq",
      "one_line_profile": "Snakemake pipeline for ATAC-seq data analysis",
      "detailed_description": "A Snakemake-based bioinformatics pipeline for processing ATAC-seq data. It handles steps from raw read processing to peak calling and quality control, enabling reproducible chromatin accessibility analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "epigenomics",
        "atac-seq",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/crazyhottommy/pyflow-ATACseq",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "atac-seq",
        "snakemake",
        "bioinformatics",
        "reproducibility"
      ],
      "id": 79
    },
    {
      "name": "pyflow-ChIPseq",
      "one_line_profile": "Snakemake pipeline for ChIP-seq data analysis",
      "detailed_description": "A Snakemake pipeline designed for ChIP-seq data processing. It automates alignment, peak calling, and quality control for chromatin immunoprecipitation sequencing data analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "epigenomics",
        "chip-seq",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/crazyhottommy/pyflow-ChIPseq",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chip-seq",
        "snakemake",
        "bioinformatics",
        "pipeline"
      ],
      "id": 80
    },
    {
      "name": "LLMCompiler",
      "one_line_profile": "Agent architecture for parallel execution of LLM tasks via DAGs",
      "detailed_description": "LLMCompiler is an agent framework that optimizes the execution of Large Language Model tasks by compiling them into a Directed Acyclic Graph (DAG). This enables parallel execution and reduces redundant token usage, enhancing the efficiency of complex AI workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "llm_orchestration",
        "agent_workflow",
        "parallel_execution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/crazyyanchao/llmcompiler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "agents",
        "dag",
        "optimization",
        "ai4s"
      ],
      "id": 81
    },
    {
      "name": "ARMOR",
      "one_line_profile": "Snakemake workflow for RNA-seq analysis and quality control",
      "detailed_description": "ARMOR (Automated Reproducible MOdular RNA-seq analysis) is a lightweight Snakemake workflow for preprocessing, quality control, and statistical analysis of RNA-seq data, integrating various standard bioinformatics tools.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "transcriptomics",
        "rna-seq",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/csoneson/ARMOR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rna-seq",
        "snakemake",
        "bioinformatics",
        "reproducibility"
      ],
      "id": 82
    },
    {
      "name": "ATLAS MCP Server",
      "one_line_profile": "Neo4j-powered task management system for LLM Agents",
      "detailed_description": "A Model Context Protocol (MCP) server that implements a three-tier architecture (Projects, Tasks, Knowledge) using Neo4j. It serves as a backend for managing complex workflows and state for LLM-based autonomous agents.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "knowledge_graph",
        "task_management"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/cyanheads/atlas-mcp-server",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-agent",
        "neo4j",
        "mcp",
        "workflow-management"
      ],
      "id": 83
    },
    {
      "name": "Cylc",
      "one_line_profile": "General purpose workflow engine specialized for cycling workflows",
      "detailed_description": "Cylc is a workflow engine designed for cycling systems, widely used in meteorology and climate science for weather forecasting and climate modeling pipelines. It handles complex dependencies and infinite cycling workflows efficiently.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "climate_modeling",
        "weather_forecasting",
        "workflow_scheduling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cylc/cylc-flow",
      "help_website": [
        "https://cylc.org/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "meteorology",
        "climate-science",
        "workflow-engine",
        "cycling"
      ],
      "id": 84
    },
    {
      "name": "SOFA",
      "one_line_profile": "Performance profiler for heterogeneous computing and distributed ML",
      "detailed_description": "SOFA is a cross-framework performance profiler designed for heterogeneous computing systems and distributed machine learning. It helps researchers analyze and optimize the performance of AI and scientific computing workloads.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "performance_profiling",
        "hpc_optimization",
        "distributed_ml"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/cyliustack/sofa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "profiling",
        "hpc",
        "distributed-ml",
        "performance"
      ],
      "id": 85
    },
    {
      "name": "Dagu",
      "one_line_profile": "Lightweight, self-contained DAG workflow engine",
      "detailed_description": "Dagu is a lightweight, single-binary workflow engine for executing Directed Acyclic Graphs (DAGs). It supports container execution and SSH commands, making it a portable solution for orchestrating data processing and scientific tasks in various environments.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "dag_execution"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/dagu-org/dagu",
      "help_website": [
        "https://dagu.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "workflow-engine",
        "dag",
        "scheduler",
        "go"
      ],
      "id": 86
    },
    {
      "name": "Dask",
      "one_line_profile": "Parallel computing library with task scheduling for analytics",
      "detailed_description": "Dask is a flexible library for parallel computing in Python. It provides advanced parallelism for analytics, enabling users to scale scientific computing workflows from a single laptop to a cluster, integrating seamlessly with NumPy, Pandas, and Scikit-Learn.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "parallel_computing",
        "distributed_analytics",
        "task_scheduling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask",
      "help_website": [
        "https://dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "parallel-computing",
        "distributed-systems",
        "python",
        "data-science"
      ],
      "id": 87
    },
    {
      "name": "Dask Distributed",
      "one_line_profile": "Distributed task scheduler for Dask",
      "detailed_description": "The distributed scheduler for Dask, providing a lightweight and robust engine for executing task graphs on distributed clusters. It manages the execution of Dask computations across multiple machines, essential for large-scale scientific data processing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "distributed_scheduling",
        "cluster_computing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/distributed",
      "help_website": [
        "https://distributed.dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "distributed-computing",
        "scheduler",
        "dask",
        "python"
      ],
      "id": 88
    },
    {
      "name": "DBND",
      "one_line_profile": "Agile pipeline framework for data engineering orchestration",
      "detailed_description": "DBND (Databand) is an orchestration and observability framework for data pipelines. It helps data engineering teams build, track, and monitor data workflows, ensuring reliability and visibility in scientific and ML data processing pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pipeline_orchestration",
        "data_observability",
        "workflow_tracking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/databand-ai/dbnd",
      "help_website": [
        "https://docs.databand.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-engineering",
        "orchestration",
        "observability",
        "pipeline"
      ],
      "id": 89
    },
    {
      "name": "HiCExplorer",
      "one_line_profile": "Set of tools to process, normalize and visualize Hi-C data",
      "detailed_description": "HiCExplorer is a powerful and easy to use set of tools to process, normalize and visualize Hi-C data. It facilitates the analysis of chromosome conformation capture data.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "data_processing",
        "visualization",
        "normalization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/deeptools/HiCExplorer",
      "help_website": [
        "https://hicexplorer.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "hic",
        "genomics",
        "visualization",
        "bioinformatics"
      ],
      "id": 90
    },
    {
      "name": "dxWDL",
      "one_line_profile": "Compiler for running WDL workflows on DNAnexus",
      "detailed_description": "dxWDL is a compiler that takes a workflow written in Workflow Description Language (WDL) and compiles it to an applet that can run on the DNAnexus cloud platform, enabling scientific workflow portability.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_compilation",
        "cloud_execution"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/dnanexus/dxWDL",
      "help_website": [
        "https://github.com/dnanexus/dxWDL"
      ],
      "license": "Apache-2.0",
      "tags": [
        "wdl",
        "dnanexus",
        "bioinformatics",
        "workflow"
      ],
      "id": 91
    },
    {
      "name": "Dockstore",
      "one_line_profile": "Registry for scientific workflows and tools",
      "detailed_description": "Dockstore is an open platform used by the GA4GH for sharing Docker-based scientific tools and workflows (CWL, WDL, Nextflow, Galaxy). It serves as a central registry for the scientific community.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_sharing",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/dockstore/dockstore",
      "help_website": [
        "https://dockstore.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow-registry",
        "ga4gh",
        "bioinformatics",
        "cwl",
        "wdl"
      ],
      "id": 92
    },
    {
      "name": "KSVD",
      "one_line_profile": "High performance distributed SVD solver",
      "detailed_description": "The KAUST SVD (KSVD) is a high performance software framework for computing a dense Singular Value Decomposition (SVD) on distributed-memory manycore systems, essential for various scientific computing tasks.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "linear_algebra",
        "dimensionality_reduction"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/ecrc/ksvd",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "svd",
        "linear-algebra",
        "scientific-computing"
      ],
      "id": 93
    },
    {
      "name": "Elyra",
      "one_line_profile": "Visual pipeline editor and AI toolkit for JupyterLab",
      "detailed_description": "Elyra extends JupyterLab with an AI-centric approach, providing a visual editor for building and running data science and machine learning pipelines (e.g., Kubeflow, Airflow) directly from the notebook environment.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_design",
        "pipeline_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/elyra-ai/elyra",
      "help_website": [
        "https://elyra.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "jupyter",
        "workflow",
        "pipeline",
        "data-science"
      ],
      "id": 94
    },
    {
      "name": "Pipeline Builder",
      "one_line_profile": "JavaScript library for visualizing and constructing WDL workflows",
      "detailed_description": "A JavaScript library for visualizing and constructing bioinformatics workflows using Workflow Description Language (WDL), enabling the creation of visual workflow editors.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_visualization",
        "workflow_design"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/epam/pipeline-builder",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "bioinformatics",
        "visualization",
        "workflow-editor"
      ],
      "id": 95
    },
    {
      "name": "WDL Workspace",
      "one_line_profile": "Web UI for running WDL workflows via Cromwell",
      "detailed_description": "A Web-based User Interface to run WDL bioinformatics workflows using the Cromwell server, facilitating the management and execution of scientific pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "job_management"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/epam/wdl-workspace",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "cromwell",
        "bioinformatics",
        "ui"
      ],
      "id": 96
    },
    {
      "name": "MrBiomics",
      "one_line_profile": "Composable modules for bioinformatics multi-omics analyses",
      "detailed_description": "MrBiomics provides composable modules and recipes to automate bioinformatics for multi-omics analyses, built on top of Snakemake.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "multi_omics",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/epigen/MrBiomics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "multi-omics",
        "bioinformatics",
        "pipeline"
      ],
      "id": 97
    },
    {
      "name": "atacseq_pipeline",
      "one_line_profile": "Snakemake workflow for ATAC-seq data processing",
      "detailed_description": "A Snakemake workflow and MrBiomics module for ATAC-seq data processing, quantification, and annotation.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "data_processing",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/epigen/atacseq_pipeline",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "atac-seq",
        "snakemake",
        "bioinformatics"
      ],
      "id": 98
    },
    {
      "name": "dea_limma",
      "one_line_profile": "Snakemake workflow for differential expression analysis using limma",
      "detailed_description": "A Snakemake workflow and MrBiomics module for performing and visualizing differential analyses of NGS data powered by the R package limma.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "differential_expression",
        "statistical_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/epigen/dea_limma",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "limma",
        "rna-seq",
        "snakemake",
        "bioinformatics"
      ],
      "id": 99
    },
    {
      "name": "enrichment_analysis",
      "one_line_profile": "Snakemake workflow for genomic enrichment analysis",
      "detailed_description": "A Snakemake workflow and MrBiomics module for performing genomic region set and gene set enrichment analyses using tools like LOLA, GREAT, and GSEApy.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "enrichment_analysis",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/epigen/enrichment_analysis",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gsea",
        "snakemake",
        "bioinformatics",
        "enrichment"
      ],
      "id": 100
    },
    {
      "name": "genome_tracks",
      "one_line_profile": "Snakemake workflow for genome browser track visualization",
      "detailed_description": "A Snakemake workflow and MrBiomics module for easy visualization of genome browser tracks of aligned BAM files (RNA-seq, ATAC-seq, etc.) using pyGenomeTracks.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "visualization",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/epigen/genome_tracks",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "genome-browser",
        "snakemake",
        "bioinformatics"
      ],
      "id": 101
    },
    {
      "name": "scrnaseq_processing_seurat",
      "one_line_profile": "Snakemake workflow for scRNA-seq processing with Seurat",
      "detailed_description": "A Snakemake workflow and MrBiomics module for processing and visualizing sc/snRNA-seq data powered by the R package Seurat.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "single_cell_analysis",
        "data_processing"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/epigen/scrnaseq_processing_seurat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scRNA-seq",
        "seurat",
        "snakemake",
        "bioinformatics"
      ],
      "id": 102
    },
    {
      "name": "unsupervised_analysis",
      "one_line_profile": "Snakemake workflow for unsupervised dimensionality reduction and clustering",
      "detailed_description": "A general purpose Snakemake workflow and MrBiomics module to perform unsupervised analyses (dimensionality reduction & cluster analysis) and visualizations of high-dimensional data.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "dimensionality_reduction",
        "clustering"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/epigen/unsupervised_analysis",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pca",
        "clustering",
        "snakemake",
        "data-analysis"
      ],
      "id": 103
    },
    {
      "name": "slurm-replay",
      "one_line_profile": "Tool to replay job submissions for Slurm workload analysis",
      "detailed_description": "A tool developed by CSCS to replay job submissions from logs on Slurm clusters, aiding in HPC workload analysis and scheduler optimization.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "hpc_workload_analysis",
        "scheduler_simulation"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/eth-cscs/slurm-replay",
      "help_website": [],
      "license": "BSD-3-Clause-Clear",
      "tags": [
        "slurm",
        "hpc",
        "workload-analysis"
      ],
      "id": 104
    },
    {
      "name": "Flyte SDK",
      "one_line_profile": "Python SDK for Flyte, a workflow automation platform for complex data and ML processes",
      "detailed_description": "The Python SDK for Flyte, enabling the creation of type-safe, distributed scientific and machine learning workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "ml_pipeline"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/flyteorg/flyte-sdk",
      "help_website": [
        "https://flyte.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow",
        "machine-learning",
        "orchestration"
      ],
      "id": 105
    },
    {
      "name": "bacannot",
      "one_line_profile": "Comprehensive pipeline for prokaryotic genome annotation",
      "detailed_description": "A Nextflow pipeline designed for the annotation and interrogation of prokaryotic genomes, including interactive reporting features.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "genome_annotation",
        "prokaryotic_genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/fmalmeida/bacannot",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "nextflow",
        "bioinformatics",
        "annotation"
      ],
      "id": 106
    },
    {
      "name": "metaGEM",
      "one_line_profile": "Workflow for generating genome-scale metabolic models from metagenomic data",
      "detailed_description": "An integrated workflow for reconstructing context-specific genome-scale metabolic models and predicting interactions in microbial communities directly from metagenomes.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "metabolic_modeling",
        "metagenomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/franciscozorrilla/metaGEM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "metabolism",
        "microbiome",
        "reconstruction"
      ],
      "id": 107
    },
    {
      "name": "Galaxy",
      "one_line_profile": "Open, web-based platform for accessible computational research",
      "detailed_description": "A scientific workflow, data integration, and data analysis platform that aims to make computational biology accessible to research scientists that do not have computer programming experience.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_platform",
        "bioinformatics_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/galaxyproject/galaxy",
      "help_website": [
        "https://galaxyproject.org"
      ],
      "license": "AFL-3.0",
      "tags": [
        "bioinformatics",
        "reproducibility",
        "workflow-engine"
      ],
      "id": 108
    },
    {
      "name": "Planemo",
      "one_line_profile": "Command-line utilities for developing Galaxy tools and CWL artifacts",
      "detailed_description": "A command-line toolkit for building, testing, and publishing Galaxy tools and Common Workflow Language (CWL) workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_development",
        "tool_wrapping"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/galaxyproject/planemo",
      "help_website": [
        "https://planemo.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "galaxy",
        "cwl",
        "dev-tools"
      ],
      "id": 109
    },
    {
      "name": "hybracter",
      "one_line_profile": "Automated long-read first bacterial genome assembly pipeline",
      "detailed_description": "A Snakemake pipeline for bacterial genome assembly that prioritizes long reads, utilizing Snaketool for workflow management.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "genome_assembly",
        "bacterial_genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/gbouras13/hybracter",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "assembly",
        "long-read"
      ],
      "id": 110
    },
    {
      "name": "noWorkflow",
      "one_line_profile": "Provenance tracking infrastructure for scientific scripts",
      "detailed_description": "A tool to capture and analyze the provenance of scientific experiments and scripts without requiring a heavy-weight workflow management system.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "provenance_tracking",
        "reproducibility"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gems-uff/noworkflow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "provenance",
        "reproducibility",
        "experiment-tracking"
      ],
      "id": 111
    },
    {
      "name": "nanopype",
      "one_line_profile": "Snakemake pipelines for nanopore sequencing data processing",
      "detailed_description": "A collection of Snakemake pipelines designed for the archiving and processing of Oxford Nanopore sequencing data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "sequencing_processing",
        "basecalling"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/giesselmann/nanopype",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "nanopore",
        "ngs"
      ],
      "id": 112
    },
    {
      "name": "snpArcher",
      "one_line_profile": "Snakemake workflow for variant calling in non-model organisms",
      "detailed_description": "A reproducible and scalable Snakemake workflow designed for variant calling, specifically optimized for ease of use with non-model organisms.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "variant_calling",
        "population_genetics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/harvardinformatics/snpArcher",
      "help_website": [
        "https://snparcher.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "snakemake",
        "genomics",
        "variant-calling"
      ],
      "id": 113
    },
    {
      "name": "rnaflow",
      "one_line_profile": "A simple RNA-Seq differential gene expression pipeline using Nextflow",
      "detailed_description": "A bioinformatics pipeline built with Nextflow for RNA-Seq data analysis, specifically designed for differential gene expression profiling.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pipeline",
        "rna_seq",
        "differential_expression"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/hoelzer-lab/rnaflow",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "rna-seq",
        "nextflow",
        "bioinformatics",
        "pipeline"
      ],
      "id": 114
    },
    {
      "name": "JupyterFlow",
      "one_line_profile": "Tool to run workflows on Kubernetes via JupyterHub",
      "detailed_description": "A tool that enables data scientists to execute DAG-based workflows on Kubernetes clusters directly from JupyterHub, facilitating interactive scientific computing and batch processing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "interactive_computing"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/hongkunyoo/jupyterflow",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyterhub",
        "kubernetes",
        "workflow",
        "data-science"
      ],
      "id": 115
    },
    {
      "name": "nextNEOpi",
      "one_line_profile": "Comprehensive pipeline for computational neoantigen prediction",
      "detailed_description": "A bioinformatics pipeline implemented in Nextflow for the prediction of neoantigens from sequencing data, supporting cancer immunotherapy research.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pipeline",
        "neoantigen_prediction",
        "immunotherapy"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/icbi-lab/nextNEOpi",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "neoantigen",
        "nextflow",
        "cancer-research",
        "bioinformatics"
      ],
      "id": 116
    },
    {
      "name": "ICGC ARGO DNA-Seq Workflow",
      "one_line_profile": "Standardized DNA-Seq processing workflow for ICGC ARGO",
      "detailed_description": "The official DNA sequencing data processing workflow used by the International Cancer Genome Consortium (ICGC) ARGO project, implemented in Nextflow.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pipeline",
        "dna_seq",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/icgc-argo-workflows/dna-seq-processing-wfs",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "icgc",
        "dna-seq",
        "genomics",
        "nextflow"
      ],
      "id": 117
    },
    {
      "name": "redun",
      "one_line_profile": "Scientific workflow engine designed for complex biological data pipelines",
      "detailed_description": "A workflow engine developed by Insitro, designed to handle complex data dependencies and caching for biological discovery and data science pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_engine",
        "pipeline_orchestration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/insitro/redun",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "bioinformatics",
        "data-science",
        "caching"
      ],
      "id": 118
    },
    {
      "name": "ducttape",
      "one_line_profile": "Workflow management system for researchers",
      "detailed_description": "A workflow management system designed for researchers, particularly in NLP and machine translation, to manage experimental pipelines and hyperparameter tuning.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "experiment_tracking"
      ],
      "application_level": "solver",
      "primary_language": "Scala",
      "repo_url": "https://github.com/jhclark/ducttape",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "workflow",
        "research",
        "nlp",
        "experimentation"
      ],
      "id": 119
    },
    {
      "name": "multiPrime",
      "one_line_profile": "Mismatch-tolerant minimal primer set design tool",
      "detailed_description": "A tool for designing minimal primer sets that are mismatch-tolerant, suitable for detecting diverse sequences such as viruses.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "primer_design",
        "genomics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/joybio/multiPrime",
      "help_website": [
        "http://multiPrime.cn"
      ],
      "license": "MIT",
      "tags": [
        "primer-design",
        "bioinformatics",
        "virology",
        "pcr"
      ],
      "id": 120
    },
    {
      "name": "Katana Skipper",
      "one_line_profile": "Simple and flexible workflow engine for machine learning pipelines",
      "detailed_description": "A lightweight, event-driven workflow engine designed specifically for orchestrating machine learning tasks. It supports defining pipelines as code and managing dependencies between ML steps.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "ml_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/katanaml/katana-skipper",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "mlops",
        "pipeline"
      ],
      "id": 121
    },
    {
      "name": "Kestra",
      "one_line_profile": "Language-agnostic orchestration and scheduling platform",
      "detailed_description": "A scalable, event-driven orchestration platform that allows users to declare workflows as code (YAML). It is widely used for data orchestration, including scientific data pipelines and AI/ML workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "data_pipeline"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/kestra-io/kestra",
      "help_website": [
        "https://kestra.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "orchestration",
        "workflow-engine",
        "scheduler"
      ],
      "id": 122
    },
    {
      "name": "Ruigi",
      "one_line_profile": "Pipeline management system for R, inspired by Luigi",
      "detailed_description": "A workflow management tool designed for the R ecosystem, enabling the definition and execution of dependent tasks in data science and statistical pipelines. It mimics the functionality of Python's Luigi for R users.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/kirillseva/ruigi",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "r",
        "pipeline",
        "workflow"
      ],
      "id": 123
    },
    {
      "name": "Kueue",
      "one_line_profile": "Kubernetes-native job queueing system for batch workloads",
      "detailed_description": "A job queueing controller for Kubernetes that manages quotas and admission for batch jobs. It is critical infrastructure for running scientific workloads (AI/ML, HPC) on cloud-native platforms.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubernetes-sigs/kueue",
      "help_website": [
        "https://kueue.sigs.k8s.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "batch-processing",
        "hpc"
      ],
      "id": 124
    },
    {
      "name": "Godel Scheduler",
      "one_line_profile": "Unified scheduler for online and offline (batch) tasks on Kubernetes",
      "detailed_description": "A high-performance scheduler for Kubernetes designed to handle massive scale batch processing and AI training workloads, optimizing resource utilization for scientific and data-intensive tasks.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "job_scheduling",
        "batch_processing"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubewharf/godel-scheduler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "scheduler",
        "kubernetes",
        "batch-jobs"
      ],
      "id": 125
    },
    {
      "name": "LncPipe",
      "one_line_profile": "Nextflow-based pipeline for long non-coding RNA analysis",
      "detailed_description": "A comprehensive bioinformatics pipeline built with Nextflow for analyzing lncRNAs from RNA-seq data. It handles alignment, assembly, identification, and quantification.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "bioinformatics_pipeline",
        "rna_seq_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Groovy",
      "repo_url": "https://github.com/likelet/LncPipe",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "nextflow",
        "bioinformatics",
        "lncrna"
      ],
      "id": 126
    },
    {
      "name": "LLM Workflow Engine",
      "one_line_profile": "Workflow manager and CLI for Large Language Models",
      "detailed_description": "A tool designed to manage and execute workflows involving Large Language Models (LLMs). It facilitates the orchestration of LLM-based tasks, which are increasingly used in scientific reasoning and automated research agents.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "llm_inference"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/llm-workflow-engine/llm-workflow-engine",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "workflow",
        "ai-agents"
      ],
      "id": 127
    },
    {
      "name": "gokart",
      "one_line_profile": "Wrapper for Luigi workflow engine focusing on reproducibility and task dependencies for ML pipelines",
      "detailed_description": "Gokart is a wrapper for the Luigi workflow engine that addresses reproducibility, task dependencies, and ease of use specifically for Machine Learning pipelines. It simplifies the creation of complex data processing workflows common in data science.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "pipeline_orchestration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/m3dev/gokart",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "luigi",
        "pipeline",
        "machine-learning",
        "reproducibility"
      ],
      "id": 128
    },
    {
      "name": "redshells",
      "one_line_profile": "Collection of machine learning tasks and pipelines using luigi and gokart",
      "detailed_description": "Redshells provides a set of pre-defined machine learning tasks and pipeline components that work with the Luigi and Gokart frameworks, facilitating the construction of ML workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_tasks",
        "pipeline_components"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/m3dev/redshells",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "luigi",
        "gokart",
        "machine-learning",
        "pipeline"
      ],
      "id": 129
    },
    {
      "name": "snakepipes",
      "one_line_profile": "Best-practice NGS data analysis workflows based on Snakemake",
      "detailed_description": "SnakePipes provides a set of flexible and customizable workflows for the analysis of Next-Generation Sequencing (NGS) data, built on top of the Snakemake workflow management system.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "bioinformatics_pipeline",
        "ngs_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/maxplanck-ie/snakepipes",
      "help_website": [
        "https://snakepipes.readthedocs.io/"
      ],
      "license": null,
      "tags": [
        "snakemake",
        "ngs",
        "bioinformatics",
        "workflow"
      ],
      "id": 130
    },
    {
      "name": "TorchX",
      "one_line_profile": "Universal job launcher for PyTorch applications",
      "detailed_description": "TorchX is a universal job launcher for PyTorch applications that supports orchestrating distributed training and batch inference jobs on various schedulers (Kubernetes, Slurm, AWS Batch, etc.), facilitating scientific machine learning workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "job_orchestration",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/meta-pytorch/torchx",
      "help_website": [
        "https://pytorch.org/torchx/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "pytorch",
        "job-scheduler",
        "orchestration",
        "mlops"
      ],
      "id": 131
    },
    {
      "name": "ATLAS",
      "one_line_profile": "Metagenome assembly and binning pipeline",
      "detailed_description": "ATLAS is a robust and reproducible workflow for metagenome data analysis, automating tasks from quality control to assembly, binning, and annotation using Snakemake.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "metagenomics_pipeline",
        "assembly",
        "binning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/metagenome-atlas/atlas",
      "help_website": [
        "https://metagenome-atlas.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "metagenomics",
        "snakemake",
        "bioinformatics",
        "pipeline"
      ],
      "id": 132
    },
    {
      "name": "CromwellOnAzure",
      "one_line_profile": "Deployment of Cromwell workflow engine on Azure",
      "detailed_description": "This repository contains the implementation and configuration required to deploy and run the Broad Institute's Cromwell workflow engine on Microsoft Azure, enabling scalable genomic data analysis in the cloud.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "cloud_infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "C#",
      "repo_url": "https://github.com/microsoft/CromwellOnAzure",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cromwell",
        "azure",
        "genomics",
        "workflow-engine"
      ],
      "id": 133
    },
    {
      "name": "miniwdl-aws",
      "one_line_profile": "AWS Batch backend for miniwdl",
      "detailed_description": "An extension for miniwdl that allows running WDL (Workflow Description Language) workflows on AWS Batch and EFS, facilitating cloud-based scientific computing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "cloud_computing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/miniwdl-ext/miniwdl-aws",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "aws-batch",
        "bioinformatics",
        "workflow"
      ],
      "id": 134
    },
    {
      "name": "miniwdl-omics-run",
      "one_line_profile": "Launcher for WDL workflows on AWS HealthOmics",
      "detailed_description": "A tool to launch and manage WDL workflows on AWS HealthOmics service using miniwdl, bridging local development and cloud execution for omics data.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_submission",
        "omics_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/miniwdl-ext/miniwdl-omics-run",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "aws-healthomics",
        "wdl",
        "bioinformatics"
      ],
      "id": 135
    },
    {
      "name": "grenepipe",
      "one_line_profile": "Pipeline for variant calling from raw sequence reads",
      "detailed_description": "Grenepipe is a flexible, scalable, and reproducible Snakemake pipeline designed to automate variant calling from raw sequencing reads, supporting both sampled individuals and pool sequencing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "variant_calling",
        "bioinformatics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/moiexpositoalonsolab/grenepipe",
      "help_website": [
        "https://grenepipe.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "snakemake",
        "variant-calling",
        "genomics",
        "pipeline"
      ],
      "id": 136
    },
    {
      "name": "MOLGENIS Compute",
      "one_line_profile": "Framework for bioinformatics workflow management",
      "detailed_description": "MOLGENIS Compute is a framework designed for bioinformatics that enables large-scale data and computational workflow management in distributed execution environments.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "bioinformatics_infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/molgenis/molgenis-compute",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "bioinformatics",
        "workflow",
        "grid-computing"
      ],
      "id": 137
    },
    {
      "name": "mulinlab-pip",
      "one_line_profile": "Collection of bioinformatics pipelines from Mulin Lab",
      "detailed_description": "A repository containing various bioinformatics pipelines developed by Mulin Lab for reproducible research.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "bioinformatics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/mulinlab/mulinlab-pip",
      "help_website": [],
      "license": null,
      "tags": [
        "bioinformatics",
        "pipeline",
        "reproducibility"
      ],
      "id": 138
    },
    {
      "name": "JUDI",
      "one_line_profile": "Workflow management system for complex bioinformatics software development",
      "detailed_description": "A workflow management system designed to facilitate the development of complex bioinformatics software with numerous parameter settings, ensuring reproducibility and efficiency.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "pipeline_development"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ncbi/JUDI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "workflow-management",
        "bioinformatics",
        "reproducibility"
      ],
      "id": 139
    },
    {
      "name": "MayomicsVC",
      "one_line_profile": "Variant Calling Pipeline using Cromwell and WDL",
      "detailed_description": "A bioinformatics pipeline for variant calling, implemented in WDL and designed to run on the Cromwell execution engine.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/ncsa/MayomicsVC",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "variant-calling",
        "wdl",
        "cromwell",
        "bioinformatics"
      ],
      "id": 140
    },
    {
      "name": "argo-jupyter-scheduler",
      "one_line_profile": "Jupyter extension for scheduling notebooks via Argo Workflows",
      "detailed_description": "An extension for Jupyter-Scheduler that enables the execution of scheduled notebooks using Argo Workflows as the backend, facilitating scientific workflow automation.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_scheduling",
        "notebook_execution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nebari-dev/argo-jupyter-scheduler",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "jupyter",
        "argo-workflows",
        "scheduling",
        "data-science"
      ],
      "id": 141
    },
    {
      "name": "Nextflow",
      "one_line_profile": "Data-driven computational pipeline engine",
      "detailed_description": "A workflow engine and DSL for writing data-driven computational pipelines that are scalable, portable, and reproducible across various compute environments.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Groovy",
      "repo_url": "https://github.com/nextflow-io/nextflow",
      "help_website": [
        "https://www.nextflow.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "pipeline",
        "reproducibility",
        "bioinformatics"
      ],
      "id": 142
    },
    {
      "name": "nf-core/ampliseq",
      "one_line_profile": "Amplicon sequencing analysis workflow",
      "detailed_description": "A Nextflow pipeline for amplicon sequencing analysis, utilizing DADA2 and QIIME2 for processing and analyzing 16S, ITS, and other amplicon data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "amplicon_sequencing",
        "microbiome_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/ampliseq",
      "help_website": [
        "https://nf-co.re/ampliseq"
      ],
      "license": "MIT",
      "tags": [
        "amplicon",
        "16s",
        "qiime2",
        "dada2"
      ],
      "id": 143
    },
    {
      "name": "nf-core/atacseq",
      "one_line_profile": "ATAC-seq peak-calling and QC pipeline",
      "detailed_description": "A bioinformatics pipeline for ATAC-seq data analysis, including quality control, alignment, and peak calling.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "atac_seq",
        "peak_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/atacseq",
      "help_website": [
        "https://nf-co.re/atacseq"
      ],
      "license": "MIT",
      "tags": [
        "atac-seq",
        "epigenetics",
        "chromatin"
      ],
      "id": 144
    },
    {
      "name": "nf-core/bacass",
      "one_line_profile": "Bacterial assembly and annotation pipeline",
      "detailed_description": "A pipeline for the assembly and annotation of bacterial genomes from NGS data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "genome_assembly",
        "genome_annotation"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/bacass",
      "help_website": [
        "https://nf-co.re/bacass"
      ],
      "license": "MIT",
      "tags": [
        "bacteria",
        "assembly",
        "annotation"
      ],
      "id": 145
    },
    {
      "name": "nf-core/chipseq",
      "one_line_profile": "ChIP-seq analysis pipeline",
      "detailed_description": "A comprehensive pipeline for ChIP-seq data analysis, covering quality control, alignment, peak calling, and differential binding analysis.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "chip_seq",
        "peak_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/chipseq",
      "help_website": [
        "https://nf-co.re/chipseq"
      ],
      "license": "MIT",
      "tags": [
        "chip-seq",
        "epigenetics",
        "transcription-factors"
      ],
      "id": 146
    },
    {
      "name": "nf-core/cutandrun",
      "one_line_profile": "CUT&RUN and CUT&TAG analysis pipeline",
      "detailed_description": "A pipeline for analyzing CUT&RUN and CUT&TAG experiments, including QC, spike-in normalization, and peak calling.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "cut_and_run",
        "epigenetics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/cutandrun",
      "help_website": [
        "https://nf-co.re/cutandrun"
      ],
      "license": "MIT",
      "tags": [
        "cut-and-run",
        "cut-and-tag",
        "chromatin"
      ],
      "id": 147
    },
    {
      "name": "nf-core/differentialabundance",
      "one_line_profile": "Differential abundance analysis pipeline",
      "detailed_description": "A pipeline for performing differential abundance analysis on feature matrices (e.g., from RNA-seq), producing plots and tables.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "differential_expression",
        "statistical_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/differentialabundance",
      "help_website": [
        "https://nf-co.re/differentialabundance"
      ],
      "license": "MIT",
      "tags": [
        "rnaseq",
        "differential-abundance",
        "statistics"
      ],
      "id": 148
    },
    {
      "name": "nf-core/eager",
      "one_line_profile": "Ancient DNA analysis pipeline",
      "detailed_description": "A fully reproducible pipeline for ancient DNA (aDNA) analysis, handling preprocessing, mapping, and genotyping of ancient samples.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "ancient_dna",
        "genotyping"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/eager",
      "help_website": [
        "https://nf-co.re/eager"
      ],
      "license": "MIT",
      "tags": [
        "ancient-dna",
        "paleogenomics",
        "adna"
      ],
      "id": 149
    },
    {
      "name": "nf-core/fetchngs",
      "one_line_profile": "Pipeline to fetch NGS data from public databases",
      "detailed_description": "A utility pipeline to retrieve metadata and raw FastQ files from public repositories like SRA and ENA for downstream analysis.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "data_retrieval",
        "metadata_acquisition"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/fetchngs",
      "help_website": [
        "https://nf-co.re/fetchngs"
      ],
      "license": "MIT",
      "tags": [
        "sra",
        "ena",
        "data-download"
      ],
      "id": 150
    },
    {
      "name": "nf-core/funcscan",
      "one_line_profile": "Functional gene screening pipeline",
      "detailed_description": "A pipeline for screening (meta-)genomes for functional and natural product gene sequences.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "functional_screening",
        "metagenomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/funcscan",
      "help_website": [
        "https://nf-co.re/funcscan"
      ],
      "license": "MIT",
      "tags": [
        "biosynthetic-gene-clusters",
        "screening",
        "genomics"
      ],
      "id": 151
    },
    {
      "name": "nf-core/hic",
      "one_line_profile": "Hi-C data analysis pipeline",
      "detailed_description": "A pipeline for the analysis of Chromosome Conformation Capture (Hi-C) data, including mapping, filtering, and contact map generation.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "hic_analysis",
        "chromosome_conformation"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/hic",
      "help_website": [
        "https://nf-co.re/hic"
      ],
      "license": "MIT",
      "tags": [
        "hi-c",
        "3d-genome",
        "chromatin-interaction"
      ],
      "id": 152
    },
    {
      "name": "nf-core/mag",
      "one_line_profile": "Metagenome assembly and binning pipeline",
      "detailed_description": "A pipeline for the assembly, binning, and annotation of metagenomes (Metagenome-Assembled Genomes).",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "metagenome_assembly",
        "binning"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/mag",
      "help_website": [
        "https://nf-co.re/mag"
      ],
      "license": "MIT",
      "tags": [
        "metagenomics",
        "mag",
        "assembly"
      ],
      "id": 153
    },
    {
      "name": "nf-core/methylseq",
      "one_line_profile": "Bisulfite sequencing analysis pipeline",
      "detailed_description": "A pipeline for methylation analysis using Bisulfite-Sequencing data, supporting alignment and methylation calling.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "methylation_analysis",
        "bisulfite_sequencing"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/methylseq",
      "help_website": [
        "https://nf-co.re/methylseq"
      ],
      "license": "MIT",
      "tags": [
        "methylation",
        "epigenetics",
        "bisulfite"
      ],
      "id": 154
    },
    {
      "name": "nf-core/nanoseq",
      "one_line_profile": "Nanopore sequencing analysis pipeline",
      "detailed_description": "A pipeline for analyzing Nanopore sequencing data, including demultiplexing, QC, and alignment.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "nanopore_analysis",
        "long_read_sequencing"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/nanoseq",
      "help_website": [
        "https://nf-co.re/nanoseq"
      ],
      "license": "MIT",
      "tags": [
        "nanopore",
        "ont",
        "long-read"
      ],
      "id": 155
    },
    {
      "name": "nf-core/oncoanalyser",
      "one_line_profile": "Cancer DNA/RNA analysis pipeline",
      "detailed_description": "A comprehensive pipeline for cancer research, integrating DNA and RNA analysis for variant calling and reporting.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "cancer_genomics",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/oncoanalyser",
      "help_website": [
        "https://nf-co.re/oncoanalyser"
      ],
      "license": "MIT",
      "tags": [
        "cancer",
        "oncology",
        "genomics"
      ],
      "id": 156
    },
    {
      "name": "nf-core/pangenome",
      "one_line_profile": "Pangenome graph construction pipeline",
      "detailed_description": "A pipeline to render a collection of sequences into a pangenome graph.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "pangenomics",
        "graph_construction"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/pangenome",
      "help_website": [
        "https://nf-co.re/pangenome"
      ],
      "license": "MIT",
      "tags": [
        "pangenome",
        "graph-genome",
        "genomics"
      ],
      "id": 157
    },
    {
      "name": "nf-core/proteinfold",
      "one_line_profile": "Protein 3D structure prediction pipeline",
      "detailed_description": "A pipeline for protein 3D structure prediction using tools like AlphaFold2 and ColabFold.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "structure_prediction",
        "protein_folding"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/proteinfold",
      "help_website": [
        "https://nf-co.re/proteinfold"
      ],
      "license": "MIT",
      "tags": [
        "alphafold",
        "protein-structure",
        "folding"
      ],
      "id": 158
    },
    {
      "name": "nf-core/raredisease",
      "one_line_profile": "Rare disease variant calling pipeline",
      "detailed_description": "A pipeline for calling and scoring variants from WGS/WES data specifically for rare disease diagnosis.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "variant_calling",
        "rare_disease"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/raredisease",
      "help_website": [
        "https://nf-co.re/raredisease"
      ],
      "license": "MIT",
      "tags": [
        "rare-disease",
        "variant-calling",
        "clinical-genomics"
      ],
      "id": 159
    },
    {
      "name": "nf-core/rnafusion",
      "one_line_profile": "RNA-seq gene fusion detection pipeline",
      "detailed_description": "A pipeline for detecting gene fusions from RNA-seq data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "gene_fusion_detection",
        "rnaseq"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/rnafusion",
      "help_website": [
        "https://nf-co.re/rnafusion"
      ],
      "license": "MIT",
      "tags": [
        "rna-fusion",
        "transcriptomics",
        "cancer"
      ],
      "id": 160
    },
    {
      "name": "nf-core/rnaseq",
      "one_line_profile": "RNA sequencing analysis pipeline",
      "detailed_description": "A standard pipeline for RNA sequencing analysis, including alignment, quantification, and extensive quality control.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "rnaseq",
        "gene_expression"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/rnaseq",
      "help_website": [
        "https://nf-co.re/rnaseq"
      ],
      "license": "MIT",
      "tags": [
        "rnaseq",
        "transcriptomics",
        "expression"
      ],
      "id": 161
    },
    {
      "name": "nf-core/sarek",
      "one_line_profile": "Germline and somatic variant calling pipeline",
      "detailed_description": "A comprehensive pipeline for detecting germline or somatic variants from WGS or targeted sequencing data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "variant_calling",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/sarek",
      "help_website": [
        "https://nf-co.re/sarek"
      ],
      "license": "MIT",
      "tags": [
        "variant-calling",
        "wgs",
        "wes",
        "cancer"
      ],
      "id": 162
    },
    {
      "name": "nf-core/scdownstream",
      "one_line_profile": "Single-cell transcriptomics downstream analysis pipeline",
      "detailed_description": "A pipeline for the downstream analysis of single-cell transcriptomics data, including QC, integration, and visualization.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "single_cell_analysis",
        "transcriptomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/scdownstream",
      "help_website": [
        "https://nf-co.re/scdownstream"
      ],
      "license": "MIT",
      "tags": [
        "single-cell",
        "scrnaseq",
        "downstream"
      ],
      "id": 163
    },
    {
      "name": "nf-core/scrnaseq",
      "one_line_profile": "Single-cell RNA-Seq processing pipeline",
      "detailed_description": "A pipeline for processing single-cell RNA-Seq data (10x, SmartSeq, etc.) from raw reads to expression matrices.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "single_cell_processing",
        "rnaseq"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/scrnaseq",
      "help_website": [
        "https://nf-co.re/scrnaseq"
      ],
      "license": "MIT",
      "tags": [
        "single-cell",
        "scrnaseq",
        "10x"
      ],
      "id": 164
    },
    {
      "name": "nf-core/smrnaseq",
      "one_line_profile": "Small RNA sequencing analysis pipeline",
      "detailed_description": "A pipeline for the analysis of small RNA sequencing data, such as miRNAs.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "small_rna_analysis",
        "mirna"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/smrnaseq",
      "help_website": [
        "https://nf-co.re/smrnaseq"
      ],
      "license": "MIT",
      "tags": [
        "small-rna",
        "mirna",
        "sequencing"
      ],
      "id": 165
    },
    {
      "name": "nf-core/taxprofiler",
      "one_line_profile": "Multi-taxonomic profiling pipeline",
      "detailed_description": "A pipeline for highly parallelised multi-taxonomic profiling of shotgun metagenomic data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "taxonomic_profiling",
        "metagenomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/taxprofiler",
      "help_website": [
        "https://nf-co.re/taxprofiler"
      ],
      "license": "MIT",
      "tags": [
        "metagenomics",
        "taxonomy",
        "profiling"
      ],
      "id": 166
    },
    {
      "name": "nf-core/viralrecon",
      "one_line_profile": "Viral assembly and variant calling pipeline",
      "detailed_description": "A pipeline for the assembly and variant calling of viral samples, widely used for SARS-CoV-2 analysis.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "viral_genomics",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/viralrecon",
      "help_website": [
        "https://nf-co.re/viralrecon"
      ],
      "license": "MIT",
      "tags": [
        "virus",
        "covid-19",
        "assembly"
      ],
      "id": 167
    },
    {
      "name": "nlppln",
      "one_line_profile": "NLP pipeline generation tool using Common Workflow Language (CWL)",
      "detailed_description": "A Python library that facilitates the creation of Natural Language Processing (NLP) pipelines by wrapping NLP tools in Common Workflow Language (CWL) definitions, enabling reproducible text analysis workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "nlp_pipeline",
        "text_mining",
        "workflow_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nlppln/nlppln",
      "help_website": [
        "https://nlppln.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "cwl",
        "workflow",
        "text-analysis"
      ],
      "id": 168
    },
    {
      "name": "distiller-nf",
      "one_line_profile": "Modular Hi-C mapping pipeline using Nextflow",
      "detailed_description": "A bioinformatics pipeline built with Nextflow for processing Hi-C data, handling mapping, parsing, and filtering of contact pairs to generate contact matrices for 3D genome analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "hic_mapping",
        "genomics",
        "3d_genome"
      ],
      "application_level": "workflow",
      "primary_language": "Groovy",
      "repo_url": "https://github.com/open2c/distiller-nf",
      "help_website": [
        "https://github.com/open2c/distiller-nf"
      ],
      "license": "MIT",
      "tags": [
        "nextflow",
        "hic",
        "genomics",
        "bioinformatics"
      ],
      "id": 169
    },
    {
      "name": "Orchest",
      "one_line_profile": "Visual platform for building and orchestrating data science pipelines",
      "detailed_description": "A browser-based platform for creating data science pipelines where steps can be executable notebooks (Jupyter) or scripts, facilitating reproducible data analysis and machine learning workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pipeline_orchestration",
        "data_science",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/orchest/orchest",
      "help_website": [
        "https://www.orchest.io/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-science",
        "pipeline",
        "jupyter",
        "orchestration"
      ],
      "id": 170
    },
    {
      "name": "Panoptes",
      "one_line_profile": "Real-time monitoring service for computational workflows",
      "detailed_description": "A system for monitoring the execution of computational workflows (such as those in bioinformatics) in real-time, providing visibility into task status and resource usage across distributed environments.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_monitoring",
        "observability"
      ],
      "application_level": "service",
      "primary_language": "CSS",
      "repo_url": "https://github.com/panoptes-organization/panoptes",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "monitoring",
        "workflow",
        "bioinformatics"
      ],
      "id": 171
    },
    {
      "name": "Pegasus WMS",
      "one_line_profile": "Workflow management system for scientific high-performance computing",
      "detailed_description": "A Workflow Management System that automates the execution of complex scientific workflows on distributed infrastructures (HPC, cloud, grid), handling data management, error recovery, and job scheduling.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "hpc_workflow",
        "distributed_computing",
        "job_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/pegasus-isi/pegasus",
      "help_website": [
        "https://pegasus.isi.edu"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "workflow-engine",
        "distributed-systems"
      ],
      "id": 172
    },
    {
      "name": "dispy",
      "one_line_profile": "Distributed and parallel computing framework for Python",
      "detailed_description": "A comprehensive Python framework for distributed and parallel computing, allowing users to execute computations across clusters of machines, often used for scientific simulations and data analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "parallel_computing",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pgiri/dispy",
      "help_website": [
        "http://dispy.sourceforge.net"
      ],
      "license": "NOASSERTION",
      "tags": [
        "distributed-computing",
        "parallel-processing",
        "python"
      ],
      "id": 173
    },
    {
      "name": "sciluigi",
      "one_line_profile": "Helper library for writing scientific workflows in Luigi",
      "detailed_description": "A wrapper library around Spotify's Luigi workflow engine, adding features specifically useful for scientific workflows such as improved dependency management and modularity for bioinformatics pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_authoring",
        "bioinformatics_workflow"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pharmbio/sciluigi",
      "help_website": [
        "https://github.com/pharmbio/sciluigi"
      ],
      "license": "MIT",
      "tags": [
        "luigi",
        "workflow",
        "bioinformatics"
      ],
      "id": 174
    },
    {
      "name": "pitagora-cwl",
      "one_line_profile": "Collection of Common Workflow Language tools for bioinformatics",
      "detailed_description": "A repository of reusable Common Workflow Language (CWL) tool definitions and workflows, maintained by the Pitagora Network for bioinformatics analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "bioinformatics_workflow",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Common Workflow Language",
      "repo_url": "https://github.com/pitagora-network/pitagora-cwl",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "cwl",
        "bioinformatics",
        "workflow-library"
      ],
      "id": 175
    },
    {
      "name": "pytask",
      "one_line_profile": "Workflow management system for reproducible data analysis",
      "detailed_description": "pytask is a workflow management system designed to facilitate reproducible data analyses, particularly in economics and social sciences. It handles dependencies, parallel execution, and integrates with various data formats to ensure research reproducibility.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "reproducible_research",
        "workflow_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/pytask-dev/pytask",
      "help_website": [
        "https://pytask-dev.readthedocs.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "reproducibility",
        "workflow",
        "data-analysis"
      ],
      "id": 176
    },
    {
      "name": "SoapFilm3D",
      "one_line_profile": "Simulation of soap films and foams using vortex sheets",
      "detailed_description": "A C++ framework for simulating the dynamics of soap films and foams using discrete circulation-preserving vortex sheets. It is designed for physics-based modeling of surface tension and fluid dynamics.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "simulation",
        "fluid_dynamics"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/raymondyfei/SoapFilm3D",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "physics-simulation",
        "fluid-dynamics",
        "vortex-methods"
      ],
      "id": 177
    },
    {
      "name": "Refinery Platform",
      "one_line_profile": "Bioinformatics data management and analysis platform",
      "detailed_description": "A system for managing, analyzing, and visualizing bioinformatics data. It integrates a data repository with a workflow engine based on Galaxy, providing a comprehensive environment for computational biology applications.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "bioinformatics_workflow",
        "data_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/refinery-platform/refinery-platform",
      "help_website": [
        "http://refinery-platform.org/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "bioinformatics",
        "galaxy",
        "workflow-management"
      ],
      "id": 178
    },
    {
      "name": "What the Phage",
      "one_line_profile": "Phage identification pipeline using Nextflow",
      "detailed_description": "A bioinformatics pipeline for bacteriophage identification and annotation. It utilizes Nextflow for orchestration and supports Docker/Singularity for reproducible execution of analysis tasks.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "phage_identification",
        "genomics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/replikation/What_the_Phage",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "nextflow",
        "bioinformatics",
        "phage"
      ],
      "id": 179
    },
    {
      "name": "law",
      "one_line_profile": "Large-scale analysis workflow framework for High Energy Physics",
      "detailed_description": "A Python package that extends Luigi to build large-scale task workflows, specifically designed for High Energy Physics (HEP) analyses. It supports remote job submission (HTCondor, etc.) and environment sandboxing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "physics_analysis",
        "workflow_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/riga/law",
      "help_website": [
        "https://law.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "hep",
        "physics",
        "luigi",
        "workflow"
      ],
      "id": 180
    },
    {
      "name": "UCSCXenaTools",
      "one_line_profile": "R package for accessing UCSC Xena genomics data",
      "detailed_description": "An R package designed to access, download, and explore genomics data from the UCSC Xena platform. It facilitates the integration of multi-omics data (cancer, single-cell) into R analysis workflows.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "data_access",
        "genomics"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/ropensci/UCSCXenaTools",
      "help_website": [
        "https://cran.r-project.org/web/packages/UCSCXenaTools/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "genomics",
        "bioinformatics",
        "r-package"
      ],
      "id": 181
    },
    {
      "name": "SCIP",
      "one_line_profile": "Scalable Cytometry Image Processing pipeline using Dask",
      "detailed_description": "An open-source tool implementing an image processing pipeline for cytometry data, performing projection, illumination correction, segmentation, and feature extraction on top of the Dask distributed computing framework.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "image_processing",
        "segmentation",
        "feature_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/saeyslab/SCIP",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "cytometry",
        "image-processing",
        "dask",
        "bioinformatics"
      ],
      "id": 182
    },
    {
      "name": "wdlRunR",
      "one_line_profile": "R interface for running WDL workflows",
      "detailed_description": "A tool that allows running WDL (Workflow Description Language) genomic data science workflows directly from the R environment, leveraging cloud resources for elastic and reproducible analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "genomics"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/seandavi/wdlRunR",
      "help_website": [],
      "license": null,
      "tags": [
        "wdl",
        "genomics",
        "r",
        "workflow-runner"
      ],
      "id": 183
    },
    {
      "name": "Nextflow Tower",
      "one_line_profile": "Management platform for Nextflow workflows",
      "detailed_description": "The open-source core of the Nextflow Tower system, providing monitoring, logging, and management capabilities for Nextflow scientific workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "monitoring"
      ],
      "application_level": "platform",
      "primary_language": "Groovy",
      "repo_url": "https://github.com/seqeralabs/nf-tower",
      "help_website": [
        "https://tower.nf"
      ],
      "license": "MPL-2.0",
      "tags": [
        "nextflow",
        "workflow-management",
        "bioinformatics"
      ],
      "id": 184
    },
    {
      "name": "Sequana",
      "one_line_profile": "Collection of Snakemake NGS pipelines",
      "detailed_description": "A comprehensive set of Snakemake pipelines for Next-Generation Sequencing (NGS) analysis, including tools for quality control, variant calling, and coverage analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "ngs_analysis",
        "quality_control",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/sequana/sequana",
      "help_website": [
        "https://sequana.readthedocs.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "snakemake",
        "ngs",
        "bioinformatics",
        "pipeline"
      ],
      "id": 185
    },
    {
      "name": "hecatomb",
      "one_line_profile": "Viral metagenomics analysis pipeline",
      "detailed_description": "A bioinformatics pipeline designed for the analysis of viral metagenomes (viromes) from Illumina sequencing data, focusing on rigorous quality control and contaminant removal.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "metagenomics",
        "virology",
        "sequence_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/shandley/hecatomb",
      "help_website": [
        "https://hecatomb.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "virome",
        "metagenomics",
        "snakemake",
        "bioinformatics"
      ],
      "id": 186
    },
    {
      "name": "snakefiles",
      "one_line_profile": "Reusable Snakemake workflows for RNA-seq",
      "detailed_description": "A collection of Snakemake workflow definitions (Snakefiles) for common RNA-seq data analysis tasks, including alignment with STAR and quantification with Kallisto.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "rna_seq",
        "alignment",
        "quantification"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/slowkow/snakefiles",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "rna-seq",
        "bioinformatics",
        "workflow"
      ],
      "id": 187
    },
    {
      "name": "Snakemake GATK Workflow",
      "one_line_profile": "GATK best-practices pipeline using Snakemake",
      "detailed_description": "A standardized Snakemake implementation of the GATK best-practices workflow for DNA sequencing data variant calling.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "variant_calling",
        "dna_seq"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake-workflows/dna-seq-gatk-variant-calling",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gatk",
        "snakemake",
        "variant-calling",
        "genomics"
      ],
      "id": 188
    },
    {
      "name": "Snakemake Varlociraptor Workflow",
      "one_line_profile": "Variant calling workflow using Varlociraptor",
      "detailed_description": "A Snakemake workflow for calling small and structural variants using the Varlociraptor statistical model, supporting various scenarios like tumor/normal and pedigree analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "variant_calling",
        "structural_variation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake-workflows/dna-seq-varlociraptor",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "varlociraptor",
        "snakemake",
        "genomics",
        "variant-calling"
      ],
      "id": 189
    },
    {
      "name": "Snakemake Kallisto-Sleuth Workflow",
      "one_line_profile": "RNA-seq differential expression workflow",
      "detailed_description": "A Snakemake workflow for performing differential expression analysis on RNA-seq data using Kallisto for quantification and Sleuth for statistical analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "rna_seq",
        "differential_expression"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake-workflows/rna-seq-kallisto-sleuth",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kallisto",
        "sleuth",
        "rna-seq",
        "snakemake"
      ],
      "id": 190
    },
    {
      "name": "Snakemake STAR-DESeq2 Workflow",
      "one_line_profile": "RNA-seq workflow with STAR and DESeq2",
      "detailed_description": "A standard Snakemake workflow for RNA-seq analysis, utilizing STAR for alignment and DESeq2 for differential expression analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "rna_seq",
        "alignment",
        "differential_expression"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake-workflows/rna-seq-star-deseq2",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "star",
        "deseq2",
        "rna-seq",
        "snakemake"
      ],
      "id": 191
    },
    {
      "name": "Snakemake",
      "one_line_profile": "Scalable bioinformatics workflow management system",
      "detailed_description": "A workflow management system that aims to reduce the complexity of creating workflows by providing a fast and comfortable execution environment, together with a clean and modern specification language in Python.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "pipeline_orchestration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake/snakemake",
      "help_website": [
        "https://snakemake.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "workflow-engine",
        "reproducibility",
        "bioinformatics",
        "python"
      ],
      "id": 192
    },
    {
      "name": "Snakemake Wrappers",
      "one_line_profile": "Repository of reusable tool wrappers for the Snakemake workflow engine",
      "detailed_description": "The official repository containing wrapper scripts for Snakemake, allowing easy integration of various bioinformatics and scientific tools into Snakemake workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_composition",
        "tool_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake/snakemake-wrappers",
      "help_website": [
        "https://snakemake-wrappers.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "snakemake",
        "workflow",
        "bioinformatics",
        "wrappers"
      ],
      "id": 193
    },
    {
      "name": "ToolJig",
      "one_line_profile": "Web application for building simplified Common Workflow Language (CWL) descriptions",
      "detailed_description": "A web-based tool designed to assist researchers in creating tool and workflow descriptions in the Common Workflow Language (CWL) format, facilitating the creation of reproducible scientific workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_creation",
        "metadata_management"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/srp33/ToolJig",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "cwl",
        "workflow",
        "bioinformatics",
        "gui"
      ],
      "id": 194
    },
    {
      "name": "Steep",
      "one_line_profile": "Scientific workflow management system for cloud execution",
      "detailed_description": "A workflow management system specifically designed to run scientific workflows in cloud environments, handling task orchestration and execution.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "cloud_computing"
      ],
      "application_level": "workflow",
      "primary_language": "Kotlin",
      "repo_url": "https://github.com/steep-wms/steep",
      "help_website": [
        "https://steep-wms.github.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "cloud",
        "scientific-computing"
      ],
      "id": 195
    },
    {
      "name": "Sprocket",
      "one_line_profile": "Bioinformatics workflow engine for WDL",
      "detailed_description": "A bioinformatics-focused workflow engine built in Rust that executes workflows defined in the Workflow Description Language (WDL).",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "pipeline_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Rust",
      "repo_url": "https://github.com/stjude-rust-labs/sprocket",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "wdl",
        "bioinformatics",
        "workflow-engine",
        "rust"
      ],
      "id": 196
    },
    {
      "name": "wdl-crates",
      "one_line_profile": "Rust libraries for parsing and working with WDL documents",
      "detailed_description": "A collection of Rust crates providing functionality to parse, validate, and manipulate Workflow Description Language (WDL) documents, serving as foundational infrastructure for WDL-based scientific tools.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_parsing",
        "metadata_handling"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/stjude-rust-labs/wdl",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "wdl",
        "rust",
        "parser",
        "workflow"
      ],
      "id": 197
    },
    {
      "name": "wdldoc",
      "one_line_profile": "Documentation generator for WDL workflows",
      "detailed_description": "A utility tool that generates Markdown documentation from Workflow Description Language (WDL) files, helping researchers document their scientific pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "documentation",
        "workflow_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/stjudecloud/wdldoc",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "documentation",
        "bioinformatics"
      ],
      "id": 198
    },
    {
      "name": "St. Jude Cloud Workflows",
      "one_line_profile": "Collection of bioinformatics workflows for St. Jude Cloud",
      "detailed_description": "A repository of production-grade bioinformatics workflows (WDL) used for genomic analysis on the St. Jude Cloud platform.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genomic_analysis",
        "pipeline_execution"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/stjudecloud/workflows",
      "help_website": [
        "https://stjude.cloud"
      ],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "wdl",
        "genomics",
        "pipeline"
      ],
      "id": 199
    },
    {
      "name": "Sunbeam",
      "one_line_profile": "Extensible metagenomics pipeline",
      "detailed_description": "A robust and extensible pipeline for metagenomic sequencing analysis, built on Snakemake, handling quality control, assembly, and classification.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "metagenomics",
        "sequence_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/sunbeam-labs/sunbeam",
      "help_website": [
        "https://sunbeam.readthedocs.io"
      ],
      "license": null,
      "tags": [
        "metagenomics",
        "snakemake",
        "pipeline",
        "bioinformatics"
      ],
      "id": 200
    },
    {
      "name": "systemPipeShiny",
      "one_line_profile": "Shiny interface for systemPipeR workflow management",
      "detailed_description": "A Shiny-based graphical user interface for the systemPipeR workflow management system, enabling interactive design, control, and visualization of data analysis workflows in R.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_visualization",
        "interactive_analysis"
      ],
      "application_level": "platform",
      "primary_language": "R",
      "repo_url": "https://github.com/systemPipeR/systemPipeShiny",
      "help_website": [
        "https://systempipe.org/"
      ],
      "license": null,
      "tags": [
        "shiny",
        "workflow",
        "r",
        "visualization"
      ],
      "id": 201
    },
    {
      "name": "Jetstream",
      "one_line_profile": "Workflow management system for batch schedulers",
      "detailed_description": "A workflow management system developed by TGen, designed to model complex workflows as DAGs and execute them on batch schedulers, specifically for genomic data analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_execution",
        "job_scheduling"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/tgen/jetstream",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "workflow",
        "genomics",
        "hpc",
        "dag"
      ],
      "id": 202
    },
    {
      "name": "scib-pipeline",
      "one_line_profile": "Snakemake pipeline for benchmarking single-cell integration methods",
      "detailed_description": "A reproducible Snakemake pipeline designed to benchmark various data integration methods for single-cell RNA sequencing data, working in conjunction with the scIB package.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "benchmarking",
        "single_cell_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/theislab/scib-pipeline",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "single-cell",
        "benchmarking",
        "snakemake",
        "bioinformatics"
      ],
      "id": 203
    },
    {
      "name": "Paperboy",
      "one_line_profile": "Web frontend for scheduling Jupyter notebook reports",
      "detailed_description": "A web application that allows users to schedule and execute Jupyter notebooks as reports, managing the workflow of periodic scientific analysis and reporting.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "reporting",
        "notebook_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/tkp-archive/paperboy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jupyter",
        "scheduling",
        "reporting",
        "workflow"
      ],
      "id": 204
    },
    {
      "name": "cwl-inspector",
      "one_line_profile": "Tool to inspect CWL tool and workflow properties",
      "detailed_description": "A command-line utility for inspecting and validating Common Workflow Language (CWL) documents, aiding in the development and debugging of scientific workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_validation",
        "debugging"
      ],
      "application_level": "solver",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/tom-tan/cwl-inspector",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cwl",
        "workflow",
        "inspection",
        "utility"
      ],
      "id": 205
    },
    {
      "name": "seq2science",
      "one_line_profile": "Automated preprocessing workflows for NGS data (ATAC/ChIP/RNA-seq)",
      "detailed_description": "A user-friendly command-line tool that automates the preprocessing of Next-Generation Sequencing (NGS) data. It supports various protocols including ATAC-seq, ChIP-seq, and RNA-seq, handling downloading, alignment, and quantification.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "ngs_preprocessing",
        "alignment",
        "quantification"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/vanheeringen-lab/seq2science",
      "help_website": [
        "https://vanheeringen-lab.github.io/seq2science/"
      ],
      "license": "MIT",
      "tags": [
        "ngs",
        "snakemake",
        "bioinformatics",
        "rna-seq",
        "atac-seq"
      ],
      "id": 206
    },
    {
      "name": "toil-vg",
      "one_line_profile": "Distributed framework for running Variation Graph (vg) workflows",
      "detailed_description": "A framework that leverages Toil to run Variation Graph (vg) workflows at scale, supporting distributed and cloud computing environments for pangenomics analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pangenomics",
        "variant_calling",
        "graph_alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/vgteam/toil-vg",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pangenomics",
        "variation-graph",
        "toil",
        "bioinformatics"
      ],
      "id": 207
    },
    {
      "name": "vg_wdl",
      "one_line_profile": "WDL workflows for Variation Graph (vg) analysis",
      "detailed_description": "A collection of Workflow Description Language (WDL) scripts designed for executing common Variation Graph (vg) workflows, enabling portable and reproducible pangenomic analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "pangenomics",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/vgteam/vg_wdl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "pangenomics",
        "variation-graph",
        "workflows"
      ],
      "id": 208
    },
    {
      "name": "vsn-pipelines",
      "one_line_profile": "Nextflow pipelines for single-cell data analysis",
      "detailed_description": "A repository of scalable pipelines for processing single-cell sequencing data, implemented in Nextflow DSL2. It provides reproducible workflows for single-cell genomics and transcriptomics.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "single_cell_analysis",
        "scRNA-seq"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/vib-singlecell-nf/vsn-pipelines",
      "help_website": [
        "https://vsn-pipelines.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "single-cell",
        "nextflow",
        "bioinformatics",
        "pipelines"
      ],
      "id": 209
    },
    {
      "name": "nano-snakemake",
      "one_line_profile": "Snakemake pipeline for Nanopore structural variant analysis",
      "detailed_description": "A Snakemake-based workflow designed for the analysis of structural variants (SV) from Oxford Nanopore Technologies (ONT) genome sequencing data.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "structural_variant_calling",
        "nanopore_sequencing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/wdecoster/nano-snakemake",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nanopore",
        "snakemake",
        "structural-variants",
        "bioinformatics"
      ],
      "id": 210
    },
    {
      "name": "maestro",
      "one_line_profile": "Lightweight orchestrator for R data pipelines",
      "detailed_description": "A framework for orchestrating R-based data pipelines. It allows users to schedule and manage R scripts as organized workflows, facilitating reproducible data science and statistical analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "statistical_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/whipson/maestro",
      "help_website": [
        "https://whipson.github.io/maestro/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "r",
        "orchestration",
        "pipelines",
        "data-science"
      ],
      "id": 211
    },
    {
      "name": "FRACTAL",
      "one_line_profile": "Distributed computing framework for lineage tracing",
      "detailed_description": "A framework for distributed computing designed to trace large and accurate lineages, facilitating phylogenetic analysis and evolutionary biology studies.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "lineage_tracing",
        "phylogeny",
        "distributed_computing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yachielab/FRACTAL",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "phylogeny",
        "lineage-tracing",
        "distributed-computing",
        "bioinformatics"
      ],
      "id": 212
    },
    {
      "name": "tunnel",
      "one_line_profile": "Distributed computing framework for Torch 7",
      "detailed_description": "A data-driven framework for distributed computing built on Torch 7, designed to facilitate large-scale deep learning and scientific computing tasks (Legacy).",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "distributed_computing",
        "deep_learning"
      ],
      "application_level": "library",
      "primary_language": "Lua",
      "repo_url": "https://github.com/zhangxiangxiao/tunnel",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "torch7",
        "distributed-computing",
        "deep-learning",
        "legacy"
      ],
      "id": 213
    },
    {
      "name": "nextflow-template-repository",
      "one_line_profile": "Template repository for creating new Nextflow pipelines",
      "detailed_description": "GitHub template repository for creating new barebones Nextflow pipelines, using the Arcadia-Science/nextflow-template cookiecutter template.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "pipeline_development"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Arcadia-Science/nextflow-template-repository",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nextflow",
        "template",
        "bioinformatics"
      ],
      "id": 214
    },
    {
      "name": "Nextflow_DSL2_template",
      "one_line_profile": "Template for creating Nextflow DSL2 pipelines",
      "detailed_description": "Template for creating Nextflow DSL2 pipelines, provided by Australian BioCommons.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "pipeline_development"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/AustralianBioCommons/Nextflow_DSL2_template",
      "help_website": [],
      "license": null,
      "tags": [
        "nextflow",
        "dsl2",
        "template"
      ],
      "id": 215
    },
    {
      "name": "cromwell-frontend",
      "one_line_profile": "Web front-end for the Cromwell job server",
      "detailed_description": "A web front-end for the Cromwell job server, including authentication via PAM and rudimentary management of workflow definitions.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/BiRG/cromwell-frontend",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cromwell",
        "workflow-management",
        "gui"
      ],
      "id": 216
    },
    {
      "name": "BiaPy",
      "one_line_profile": "Library for building bioimage analysis pipelines",
      "detailed_description": "Open source Python library for building bioimage analysis pipelines, designed for generating, manipulating, and analyzing image data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "image_analysis",
        "segmentation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/BiaPyX/BiaPy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioimage",
        "deep-learning",
        "microscopy"
      ],
      "id": 217
    },
    {
      "name": "BioContainers Workflows",
      "one_line_profile": "Curated bioinformatics workflows using BioContainers tools",
      "detailed_description": "Bioinformatics curated workflows that use Biocontainers tools, facilitating reproducible analysis.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "bioinformatics_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/BioContainers/workflows",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "biocontainers",
        "workflows",
        "reproducibility"
      ],
      "id": 218
    },
    {
      "name": "BioFSharp",
      "one_line_profile": "Bioinformatics and computational biology toolbox for F#",
      "detailed_description": "Open source bioinformatics and computational biology toolbox written in F#. This is the core package containing type models and parsers/writers.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "sequence_analysis",
        "computational_biology"
      ],
      "application_level": "library",
      "primary_language": "F#",
      "repo_url": "https://github.com/BioFSharp/BioFSharp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "fsharp",
        "toolbox"
      ],
      "id": 219
    },
    {
      "name": "SUBATOMIC",
      "one_line_profile": "Subgraph Based Multi-Omics Clustering framework",
      "detailed_description": "The SUbgraph BAsed mulTI-OMIcs Clustering (SUBATOMIC) framework infers interpretable modules with a specific topology.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "clustering",
        "multi_omics_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CBIGR/SUBATOMIC",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "multi-omics",
        "clustering",
        "bioinformatics"
      ],
      "id": 220
    },
    {
      "name": "fluids",
      "one_line_profile": "Fluid dynamics component of Chemical Engineering Design Library",
      "detailed_description": "Fluid dynamics component of Chemical Engineering Design Library (ChEDL), providing routines for fluid dynamics calculations.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "fluid_dynamics",
        "engineering_simulation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CalebBell/fluids",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fluid-dynamics",
        "chemical-engineering",
        "physics"
      ],
      "id": 221
    },
    {
      "name": "dockstore-tool-bamstats",
      "one_line_profile": "BAMStats tool wrapper for Dockstore",
      "detailed_description": "A repo for the BAMStats command, used as a tutorial and functional tool wrapper for Dockstore.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "quality_control",
        "sequence_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Common Workflow Language",
      "repo_url": "https://github.com/CancerCollaboratory/dockstore-tool-bamstats",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bam",
        "statistics",
        "dockstore"
      ],
      "id": 222
    },
    {
      "name": "DeepTrack2",
      "one_line_profile": "Library for image data pipelines for microscopy and tracking",
      "detailed_description": "DeepTrack2 is a modular Python library for generating, manipulating, and analyzing image data pipelines for machine learning and experimental imaging.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "image_tracking",
        "microscopy_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/DeepTrackAI/DeepTrack2",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "deep-learning",
        "particle-tracking",
        "microscopy"
      ],
      "id": 223
    },
    {
      "name": "reat",
      "one_line_profile": "Robust Eukaryotic Annotation Toolkit",
      "detailed_description": "Robust Eukaryotic Annotation Toolkit for annotating eukaryotic genomes.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "genome_annotation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/EI-CoreBioinformatics/reat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "annotation",
        "genomics",
        "eukaryotes"
      ],
      "id": 224
    },
    {
      "name": "caper",
      "one_line_profile": "Cromwell/WDL wrapper for Python",
      "detailed_description": "Cromwell/WDL wrapper for Python, designed to simplify running pipelines on various backends.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ENCODE-DCC/caper",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cromwell",
        "wdl",
        "pipeline-manager"
      ],
      "id": 225
    },
    {
      "name": "croo",
      "one_line_profile": "Cromwell output organizer",
      "detailed_description": "Cromwell output organizer to help manage and structure outputs from WDL pipelines.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "data_management"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/ENCODE-DCC/croo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cromwell",
        "output-management",
        "wdl"
      ],
      "id": 226
    },
    {
      "name": "snakemake-workflows",
      "one_line_profile": "Snakemake rules and workflows for Metagenomic analysis",
      "detailed_description": "Common Snakemake rules and workflows mainly directed towards Metagenomic analysis.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "metagenomics_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/EnvGen/snakemake-workflows",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "metagenomics",
        "workflow"
      ],
      "id": 227
    },
    {
      "name": "redundans",
      "one_line_profile": "Pipeline for assembly of heterozygous/polymorphic genomes",
      "detailed_description": "Redundans is a pipeline that assists an assembly of heterozygous/polymorphic genomes.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "genome_assembly"
      ],
      "application_level": "workflow",
      "primary_language": "C++",
      "repo_url": "https://github.com/Gabaldonlab/redundans",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "assembly",
        "genomics",
        "heterozygous"
      ],
      "id": 228
    },
    {
      "name": "IsoTools",
      "one_line_profile": "Python module for Long Read Transcriptome Sequencing (LRTS) analysis",
      "detailed_description": "IsoTools is a python module designed for the analysis of Long Read Transcriptome Sequencing (LRTS) data. It provides functionalities for importing aligned reads (BAM), transcript reconstruction, quality control, and differential expression analysis.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "transcriptome_analysis",
        "long_read_sequencing"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/MatthiasLienhard/isotools",
      "help_website": [
        "https://isotools.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "transcriptomics",
        "long-read",
        "lrts",
        "isoforms"
      ],
      "id": 229
    },
    {
      "name": "Neuraxle",
      "one_line_profile": "Clean AutoML library for building production-ready deep learning pipelines",
      "detailed_description": "Neuraxle is a machine learning library for building clean, production-ready pipelines. It provides abstractions for hyperparameter tuning and pipeline steps, compatible with Scikit-Learn and TensorFlow, facilitating organized ML experiments.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "automl",
        "pipeline_orchestration",
        "hyperparameter_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Neuraxio/Neuraxle",
      "help_website": [
        "https://www.neuraxle.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "automl",
        "pipeline",
        "machine-learning",
        "hyperparameter-tuning"
      ],
      "id": 230
    },
    {
      "name": "NordicESMhub Galaxy Tools",
      "one_line_profile": "Collection of Galaxy tools for Earth System Modeling",
      "detailed_description": "A repository containing Galaxy tool wrappers and definitions maintained by the NordicESMHub, specifically designed for Earth System Modeling (ESM) workflows and climate data analysis.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "earth_system_modeling",
        "climate_analysis",
        "workflow_modules"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NordicESMhub/galaxy-tools",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "galaxy",
        "earth-system-modeling",
        "climate-science",
        "workflow"
      ],
      "id": 231
    },
    {
      "name": "SnakeVision",
      "one_line_profile": "Visualization tool for Snakemake rule graphs",
      "detailed_description": "SnakeVision is a tool designed to visualize Snakemake rule graphs, helping researchers understand and debug complex bioinformatics workflows and dependencies.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_visualization",
        "pipeline_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenOmics/snakevision",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "visualization",
        "workflow",
        "bioinformatics"
      ],
      "id": 232
    },
    {
      "name": "PurdueRCAC Biocontainers",
      "one_line_profile": "Containerized bioinformatics applications for cluster deployment",
      "detailed_description": "A collection of containerized bioinformatics applications and module definitions deployed in Purdue community clusters. It serves as a registry of scientific software containers facilitating reproducible research.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "software_containerization",
        "reproducibility",
        "bioinformatics_tools"
      ],
      "application_level": "platform",
      "primary_language": "Lua",
      "repo_url": "https://github.com/PurdueRCAC/Biocontainers",
      "help_website": [],
      "license": null,
      "tags": [
        "bioinformatics",
        "containers",
        "hpc",
        "singularity"
      ],
      "id": 233
    },
    {
      "name": "LLMBox",
      "one_line_profile": "Comprehensive library for implementing and evaluating LLMs",
      "detailed_description": "LLMBox is a comprehensive library for implementing Large Language Models (LLMs), offering a unified training pipeline and comprehensive model evaluation tools, suitable for AI research and development.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "llm_training",
        "model_evaluation",
        "nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/RUCAIBox/LLMBox",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "nlp",
        "training-pipeline",
        "evaluation"
      ],
      "id": 234
    },
    {
      "name": "container-mod",
      "one_line_profile": "Workflow to generate modulefiles from container registries for HPC",
      "detailed_description": "A workflow tool designed to pull containers from public registries and automatically generate modulefiles (Lmod/Environment Modules), facilitating the management of scientific software environments in HPC clusters.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "hpc_environment_management",
        "container_management"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/TuftsRT/container-mod",
      "help_website": [],
      "license": null,
      "tags": [
        "hpc",
        "containers",
        "lmod",
        "singularity"
      ],
      "id": 235
    },
    {
      "name": "UMCU Genetics Nextflow Modules",
      "one_line_profile": "Collection of Nextflow modules for genetics analysis",
      "detailed_description": "A registry of reusable Nextflow modules maintained by UMCU Genetics, providing standardized components for building bioinformatics pipelines.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_modules",
        "genetics_analysis"
      ],
      "application_level": "library",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/UMCUGenetics/NextflowModules",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nextflow",
        "modules",
        "bioinformatics",
        "genetics"
      ],
      "id": 236
    },
    {
      "name": "Hi-C Scaffolding Pipelines",
      "one_line_profile": "Automation of 3D_DNA and SALSA Hi-C scaffolding pipelines",
      "detailed_description": "A set of automated pipelines for genome scaffolding using Hi-C data, integrating tools like 3D_DNA and SALSA to facilitate genome assembly improvement.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "genome_scaffolding",
        "hi-c_analysis",
        "genome_assembly"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/ViriatoII/Hi-C-scaffolding-pipelines",
      "help_website": [],
      "license": null,
      "tags": [
        "hi-c",
        "scaffolding",
        "genome-assembly",
        "pipeline"
      ],
      "id": 237
    },
    {
      "name": "hic-scaffolding-nf",
      "one_line_profile": "Nextflow pipeline for scaffolding genome assemblies with Hi-C reads",
      "detailed_description": "A Nextflow pipeline designed for scaffolding genome assemblies using Hi-C sequencing reads, automating the process of ordering and orienting contigs.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "genome_scaffolding",
        "hi-c_analysis",
        "workflow"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/WarrenLab/hic-scaffolding-nf",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nextflow",
        "hi-c",
        "scaffolding",
        "genomics"
      ],
      "id": 238
    },
    {
      "name": "FusionGDA",
      "one_line_profile": "Gene-disease association prediction model using fusion module",
      "detailed_description": "FusionGDA is a model that utilizes a pre-training phase with a fusion module to enrich gene and disease semantic representations encoded by pre-trained language models for predicting gene-disease associations.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "gene_disease_association",
        "bioinformatics_modeling",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ZhaohanM/FusionGDA",
      "help_website": [],
      "license": null,
      "tags": [
        "bioinformatics",
        "deep-learning",
        "gene-disease-association",
        "nlp"
      ],
      "id": 239
    },
    {
      "name": "cstag",
      "one_line_profile": "Python module to manipulate and visualize minimap2's cs tag",
      "detailed_description": "cstag is a Python module designed to manipulate and visualize the 'cs' tag generated by minimap2, facilitating the analysis of alignment mutations and splicing events.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "alignment_analysis",
        "visualization",
        "genomics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/akikuno/cstag",
      "help_website": [
        "https://pypi.org/project/cstag/"
      ],
      "license": "MIT",
      "tags": [
        "minimap2",
        "alignment",
        "visualization",
        "bioinformatics"
      ],
      "id": 240
    },
    {
      "name": "cromwell-client",
      "one_line_profile": "Scala client for the Cromwell scientific workflow engine",
      "detailed_description": "A Scala client library for interacting with the Cromwell workflow engine, facilitating the submission and monitoring of scientific workflows.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_management",
        "job_submission"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/antonkulaga/cromwell-client",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "cromwell",
        "workflow",
        "scala",
        "bioinformatics"
      ],
      "id": 241
    },
    {
      "name": "nf-workflows",
      "one_line_profile": "Collection of Nextflow workflows with BioContainers",
      "detailed_description": "A repository containing various Nextflow workflows integrated with BioContainers for reproducible bioinformatics analysis.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_execution",
        "bioinformatics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/bigbio/nf-workflows",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "nextflow",
        "bioinformatics",
        "workflows",
        "biocontainers"
      ],
      "id": 242
    },
    {
      "name": "BioNextflow",
      "one_line_profile": "Modules and sub-workflows for Nextflow",
      "detailed_description": "A collection of reusable modules and sub-workflows for building Nextflow pipelines in bioinformatics.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_composition",
        "bioinformatics_pipeline"
      ],
      "application_level": "library",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/biocorecrg/BioNextflow",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "nextflow",
        "modules",
        "bioinformatics"
      ],
      "id": 243
    },
    {
      "name": "bionode-ncbi",
      "one_line_profile": "Node.js interface for NCBI E-utilities",
      "detailed_description": "A Node.js module for interacting with the NCBI API (E-utilities) to fetch and process biological data.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "data_retrieval",
        "bioinformatics"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/bionode/bionode-ncbi",
      "help_website": [
        "http://bionode.io"
      ],
      "license": "MIT",
      "tags": [
        "ncbi",
        "bioinformatics",
        "nodejs",
        "api-client"
      ],
      "id": 244
    },
    {
      "name": "bionode-seq",
      "one_line_profile": "Sequence manipulation library for DNA/RNA/Protein",
      "detailed_description": "A Node.js module for manipulating DNA, RNA, and protein sequences, providing stream-based processing capabilities.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "sequence_manipulation",
        "bioinformatics"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/bionode/bionode-seq",
      "help_website": [
        "http://bionode.io"
      ],
      "license": "MIT",
      "tags": [
        "dna",
        "rna",
        "protein",
        "bioinformatics",
        "nodejs"
      ],
      "id": 245
    },
    {
      "name": "biowasm",
      "one_line_profile": "WebAssembly modules for genomics tools",
      "detailed_description": "A project providing WebAssembly ports of popular genomics tools (like samtools, seqtk) to enable client-side bioinformatics analysis.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "genomics",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/biowasm/biowasm",
      "help_website": [
        "https://biowasm.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "webassembly",
        "genomics",
        "bioinformatics",
        "wasm"
      ],
      "id": 246
    },
    {
      "name": "BioWDL RNA-seq",
      "one_line_profile": "WDL pipeline for RNA-seq data processing",
      "detailed_description": "A BioWDL pipeline for processing RNA-seq data, from FASTQ files to expression measures and variant calling.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "rna_seq",
        "expression_analysis",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/biowdl/RNA-seq",
      "help_website": [
        "https://biowdl.github.io/RNA-seq"
      ],
      "license": "MIT",
      "tags": [
        "wdl",
        "rna-seq",
        "bioinformatics",
        "pipeline"
      ],
      "id": 247
    },
    {
      "name": "BioWDL germline-DNA",
      "one_line_profile": "WDL pipeline for germline DNA variant calling",
      "detailed_description": "A BioWDL pipeline for germline DNA variant calling, processing FASTQ files to produce VCF files.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "variant_calling",
        "germline",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/biowdl/germline-DNA",
      "help_website": [
        "https://biowdl.github.io/germline-DNA"
      ],
      "license": "MIT",
      "tags": [
        "wdl",
        "variant-calling",
        "bioinformatics",
        "pipeline"
      ],
      "id": 248
    },
    {
      "name": "BioWDL tasks",
      "one_line_profile": "Collection of reusable WDL tasks",
      "detailed_description": "A library of reusable WDL tasks for bioinformatics tools, used to construct BioWDL pipelines.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_composition",
        "bioinformatics"
      ],
      "application_level": "library",
      "primary_language": "WDL",
      "repo_url": "https://github.com/biowdl/tasks",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "tasks",
        "bioinformatics",
        "reusable-components"
      ],
      "id": 249
    },
    {
      "name": "cromwell-monitor",
      "one_line_profile": "Resource monitoring for Cromwell tasks",
      "detailed_description": "A tool to generate statistics for Cromwell task calls, including resource utilization and estimated costs (deprecated but functional tool).",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "resource_monitoring",
        "workflow_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/broadinstitute/cromwell-monitor-deprecated",
      "help_website": [],
      "license": null,
      "tags": [
        "cromwell",
        "monitoring",
        "resource-usage"
      ],
      "id": 250
    },
    {
      "name": "cromwell-task-monitor-bq",
      "one_line_profile": "Cromwell task monitoring to BigQuery",
      "detailed_description": "A scalable tool for reporting Cromwell task call resource monitoring data directly to Google BigQuery for analysis.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "resource_monitoring",
        "workflow_analytics"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/broadinstitute/cromwell-task-monitor-bq",
      "help_website": [],
      "license": null,
      "tags": [
        "cromwell",
        "bigquery",
        "monitoring",
        "bioinformatics"
      ],
      "id": 251
    },
    {
      "name": "lrma-cloud-utils",
      "one_line_profile": "Utilities for GCS, Cromwell, and Terra",
      "detailed_description": "A Python library for interacting with Google Cloud Storage, Cromwell, and Terra platforms, facilitating cloud-based scientific workflows.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "cloud_integration",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/broadinstitute/lrma-cloud-utils",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "terra",
        "cromwell",
        "gcs",
        "cloud-computing"
      ],
      "id": 252
    },
    {
      "name": "widdler",
      "one_line_profile": "CLI for managing WDL workflows on Cromwell",
      "detailed_description": "A command-line tool for executing, managing, and querying WDL workflows on Cromwell servers, providing a user-friendly interface.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_management",
        "job_submission"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/broadinstitute/widdler",
      "help_website": [],
      "license": null,
      "tags": [
        "wdl",
        "cromwell",
        "cli",
        "workflow"
      ],
      "id": 253
    },
    {
      "name": "dockstore-cgpmap",
      "one_line_profile": "CWL workflow for PCAP mapping",
      "detailed_description": "A Dockstore implementation of the Cancer Genome Project (CGP) mapping workflow using PCAP.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "genomics",
        "mapping",
        "cancer_research"
      ],
      "application_level": "workflow",
      "primary_language": "Common Workflow Language",
      "repo_url": "https://github.com/cancerit/dockstore-cgpmap",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "cwl",
        "dockstore",
        "cancer-genomics",
        "mapping"
      ],
      "id": 254
    },
    {
      "name": "dockstore-cgpwgs",
      "one_line_profile": "CGP core WGS analysis workflow",
      "detailed_description": "A Dockstore implementation of the Cancer Genome Project (CGP) core Whole Genome Sequencing (WGS) analysis pipeline.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "wgs",
        "cancer_genomics",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/cancerit/dockstore-cgpwgs",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "wgs",
        "cancer",
        "dockstore",
        "workflow"
      ],
      "id": 255
    },
    {
      "name": "GaussDCA.jl",
      "one_line_profile": "Multivariate Gaussian Direct Coupling Analysis",
      "detailed_description": "A Julia module for Multivariate Gaussian Direct Coupling Analysis (DCA) for residue contact prediction in protein families.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "protein_structure_prediction",
        "residue_contact_prediction"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/carlobaldassi/GaussDCA.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "julia",
        "protein-structure",
        "dca",
        "bioinformatics"
      ],
      "id": 256
    },
    {
      "name": "wdl-cell-ranger",
      "one_line_profile": "WDL wrapper for Cell Ranger pipelines",
      "detailed_description": "A WDL workflow for running Cell Ranger pipelines (10x Genomics) using Cromwell.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "single_cell_genomics",
        "pipeline_execution"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/chanzuckerberg/wdl-cell-ranger",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "cell-ranger",
        "single-cell",
        "genomics"
      ],
      "id": 257
    },
    {
      "name": "bfx-tools-wdl",
      "one_line_profile": "WDL tasks for bioinformatics tools",
      "detailed_description": "A collection of WDL tasks wrapping commonly used bioinformatics (BFX) tools for workflow construction.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_composition",
        "bioinformatics"
      ],
      "application_level": "library",
      "primary_language": "WDL",
      "repo_url": "https://github.com/chopdgd/bfx-tools-wdl",
      "help_website": [],
      "license": null,
      "tags": [
        "wdl",
        "bioinformatics",
        "tasks"
      ],
      "id": 258
    },
    {
      "name": "rhea",
      "one_line_profile": "RAG+MCP tool server for Galaxy Toolshed",
      "detailed_description": "A tool server integrating RAG and MCP capabilities into the Galaxy Toolshed, enhancing the scientific workflow platform with AI agents.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_enhancement",
        "ai_integration"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/chrisagrams/rhea",
      "help_website": [],
      "license": null,
      "tags": [
        "galaxy",
        "rag",
        "ai-agent",
        "scientific-workflow"
      ],
      "id": 259
    },
    {
      "name": "worcs",
      "one_line_profile": "Workflow for Open Reproducible Code in Science",
      "detailed_description": "An R package and project template providing a workflow and convenience functions for creating open and reproducible scientific code.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "reproducibility",
        "project_management"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/cjvanlissa/worcs",
      "help_website": [
        "https://cjvanlissa.github.io/worcs/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "reproducibility",
        "open-science",
        "r",
        "workflow"
      ],
      "id": 260
    },
    {
      "name": "active_sciencing",
      "one_line_profile": "Workflows for active learning and likelihood-free inference in physics",
      "detailed_description": "A repository containing reusable workflows and code for active learning and likelihood-free inference, primarily aimed at high-energy physics applications.",
      "domains": [
        "D2",
        "D4"
      ],
      "subtask_category": [
        "inference",
        "active_learning",
        "simulation"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/cranmer/active_sciencing",
      "help_website": [],
      "license": null,
      "tags": [
        "physics",
        "active-learning",
        "inference",
        "reproducibility"
      ],
      "id": 261
    },
    {
      "name": "CEMiTool",
      "one_line_profile": "Co-Expression Module Identification Tool",
      "detailed_description": "A tool for the identification and analysis of co-expression modules in transcriptomic data, integrating gene set enrichment and interaction network analysis.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "expression_analysis",
        "network_analysis"
      ],
      "application_level": "solver",
      "primary_language": "R",
      "repo_url": "https://github.com/csbl-usp/CEMiTool",
      "help_website": [
        "https://bioconductor.org/packages/release/bioc/html/CEMiTool.html"
      ],
      "license": null,
      "tags": [
        "transcriptomics",
        "co-expression",
        "systems-biology"
      ],
      "id": 262
    },
    {
      "name": "CK Autotuning",
      "one_line_profile": "Collective Knowledge workflows for program autotuning and benchmarking",
      "detailed_description": "Automation actions and reusable workflows for reproducible benchmarking, optimization, and hardware/software co-design within the Collective Knowledge framework.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "benchmarking",
        "optimization",
        "reproducibility"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ctuning/ck-autotuning",
      "help_website": [
        "http://cKnowledge.org"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "autotuning",
        "benchmarking",
        "reproducibility",
        "hpc"
      ],
      "id": 263
    },
    {
      "name": "CK Env",
      "one_line_profile": "Environment management components for Collective Knowledge workflows",
      "detailed_description": "Components and automation actions to enable portable workflows across diverse platforms, handling software detection and environment setup for scientific experiments.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "environment_management",
        "reproducibility"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ctuning/ck-env",
      "help_website": [
        "http://cKnowledge.org"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "environment-modules",
        "portability",
        "reproducibility"
      ],
      "id": 264
    },
    {
      "name": "CK TensorFlow",
      "one_line_profile": "Collective Knowledge components and workflows for TensorFlow",
      "detailed_description": "Reusable components (code, datasets, models) and workflows for benchmarking and optimizing TensorFlow workloads within the CK framework.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "machine_learning",
        "benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ctuning/ck-tensorflow",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "tensorflow",
        "benchmarking",
        "ai4s"
      ],
      "id": 265
    },
    {
      "name": "DDBJ Workflow Registry",
      "one_line_profile": "Workflow registry maintained by DNA Data Bank of Japan",
      "detailed_description": "A registry repository containing scientific workflow definitions published by the DNA Data Bank of Japan (DDBJ) for bioinformatics analysis.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_registry",
        "bioinformatics"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/ddbj/workflow-registry",
      "help_website": [
        "https://www.ddbj.nig.ac.jp/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ddbj",
        "bioinformatics",
        "workflow-registry"
      ],
      "id": 266
    },
    {
      "name": "WMCore",
      "one_line_profile": "Workflow management core for CMS experiment",
      "detailed_description": "Core workflow management components used by the CMS (Compact Muon Solenoid) experiment at CERN for handling large-scale physics data processing.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_management",
        "data_processing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/dmwm/WMCore",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "high-energy-physics",
        "cms",
        "cern",
        "workflow-management"
      ],
      "id": 267
    },
    {
      "name": "eFlows4HPC Workflow Registry",
      "one_line_profile": "Registry for HPC workflow descriptions",
      "detailed_description": "A registry developed by the eFlows4HPC project to store and manage workflow descriptions for High Performance Computing environments.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_registry",
        "hpc"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/eflows4hpc/workflow-registry",
      "help_website": [
        "https://eflows4hpc.eu/"
      ],
      "license": null,
      "tags": [
        "hpc",
        "workflow-registry",
        "supercomputing"
      ],
      "id": 268
    },
    {
      "name": "supereight",
      "one_line_profile": "High-performance volumetric SLAM pipeline and octree library",
      "detailed_description": "A dense volumetric SLAM pipeline implementation and template octree library for efficient 3D mapping and spatial analysis.",
      "domains": [
        "D2",
        "D4"
      ],
      "subtask_category": [
        "slam",
        "volumetric_mapping",
        "spatial_analysis"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/emanuelev/supereight",
      "help_website": [],
      "license": null,
      "tags": [
        "slam",
        "octree",
        "robotics",
        "computer-vision"
      ],
      "id": 269
    },
    {
      "name": "dea_seurat",
      "one_line_profile": "Single-cell differential expression analysis workflow",
      "detailed_description": "A Snakemake workflow and MrBiomics module for performing differential expression analyses on single-cell RNA-seq data using Seurat.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "single_cell_analysis",
        "differential_expression"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/epigen/dea_seurat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scRNA-seq",
        "seurat",
        "snakemake"
      ],
      "id": 270
    },
    {
      "name": "mixscape_seurat",
      "one_line_profile": "CRISPR screen analysis workflow using Mixscape",
      "detailed_description": "A Snakemake workflow and MrBiomics module for analyzing pooled CRISPR screens with scRNA-seq readout using Seurat's Mixscape method.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "crispr_analysis",
        "single_cell_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/epigen/mixscape_seurat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "crispr",
        "scRNA-seq",
        "seurat"
      ],
      "id": 271
    },
    {
      "name": "rnaseq_pipeline",
      "one_line_profile": "RNA-seq data processing workflow",
      "detailed_description": "A Snakemake workflow and MrBiomics module for RNA-seq data processing, quantification, and annotation.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "sequence_processing",
        "rna-seq"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/epigen/rnaseq_pipeline",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rna-seq",
        "snakemake",
        "bioinformatics"
      ],
      "id": 272
    },
    {
      "name": "spilterlize_integrate",
      "one_line_profile": "NGS count matrix processing and integration workflow",
      "detailed_description": "A Snakemake workflow and MrBiomics module to split, filter, normalize, and integrate count matrices from NGS experiments.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "data_integration",
        "normalization"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/epigen/spilterlize_integrate",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ngs",
        "normalization",
        "integration"
      ],
      "id": 273
    },
    {
      "name": "Seq",
      "one_line_profile": "High-performance bioinformatics language/library",
      "detailed_description": "A high-performance, Pythonic language and library designed specifically for bioinformatics and genomics data processing.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "sequence_analysis",
        "genomics"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/exaloop/seq",
      "help_website": [
        "https://seq-lang.org"
      ],
      "license": null,
      "tags": [
        "bioinformatics",
        "compiler",
        "high-performance"
      ],
      "id": 274
    },
    {
      "name": "fairworkflows",
      "one_line_profile": "Python library for constructing and publishing semantic scientific workflows",
      "detailed_description": "A Python library that facilitates the construction, manipulation, and publication of scientific workflows using semantic technologies to ensure FAIR (Findable, Accessible, Interoperable, Reusable) principles.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_construction",
        "semantic_annotation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fair-workflows/fairworkflows",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "workflow",
        "semantic-web",
        "fair-data",
        "rdf"
      ],
      "id": 275
    },
    {
      "name": "Assemble2",
      "one_line_profile": "Interactive RNA 2D structure design and 3D module assembly tool",
      "detailed_description": "A tool that allows interactive design of RNA 2D structures and the creation/assembly of corresponding RNA 3D modules directly within UCSF Chimera.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "rna_structure_design",
        "3d_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/fjossinet/assemble2",
      "help_website": [],
      "license": null,
      "tags": [
        "rna",
        "structure-prediction",
        "bioinformatics",
        "visualization"
      ],
      "id": 276
    },
    {
      "name": "p3d",
      "one_line_profile": "Python module for structural bioinformatics",
      "detailed_description": "A Python module designed for structural bioinformatics tasks, facilitating the analysis and processing of protein structure data.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "structural_bioinformatics",
        "protein_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fu/p3d",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bioinformatics",
        "protein-structure",
        "structural-biology"
      ],
      "id": 277
    },
    {
      "name": "Galaxy Tools DevTeam",
      "one_line_profile": "Collection of Galaxy tool wrappers and definitions",
      "detailed_description": "A repository containing a set of Galaxy Tools (wrappers and scripts) developed by the Galaxy Team, enabling various scientific analyses within the Galaxy platform.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "genomics_tools",
        "workflow_modules"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/galaxyproject/tools-devteam",
      "help_website": [
        "http://galaxyproject.org"
      ],
      "license": "NOASSERTION",
      "tags": [
        "galaxy",
        "bioinformatics",
        "genomics",
        "tool-wrappers"
      ],
      "id": 278
    },
    {
      "name": "GATK4 CNN Variant Filter",
      "one_line_profile": "Workflow for filtering variants using Convolutional Neural Networks",
      "detailed_description": "A WDL workflow for filtering genomic variants using deep learning (CNN) models, part of the GATK Best Practices.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "variant_filtering",
        "deep_learning_genomics"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/gatk-workflows/gatk4-cnn-variant-filter",
      "help_website": [
        "https://gatk.broadinstitute.org"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "gatk",
        "wdl",
        "variant-filtering",
        "cnn"
      ],
      "id": 279
    },
    {
      "name": "GATK4 Mitochondria Pipeline",
      "one_line_profile": "Workflow for calling variants on mitochondria",
      "detailed_description": "A WDL workflow designed specifically for calling variants in mitochondrial DNA, handling the unique characteristics of the mitochondrial genome.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "mitochondrial_analysis",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/gatk-workflows/gatk4-mitochondria-pipeline",
      "help_website": [
        "https://gatk.broadinstitute.org"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "gatk",
        "wdl",
        "mitochondria",
        "genomics"
      ],
      "id": 280
    },
    {
      "name": "GATK4 PathSeq",
      "one_line_profile": "Pipeline for detecting microbial pathogens in host sequencing data",
      "detailed_description": "A WDL workflow for the PathSeq pipeline, which detects microbial pathogens in short-read sequencing data from host organisms.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "pathogen_detection",
        "metagenomics"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/gatk-workflows/gatk4-pathseq",
      "help_website": [
        "https://gatk.broadinstitute.org"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "gatk",
        "wdl",
        "pathogen-detection",
        "microbiome"
      ],
      "id": 281
    },
    {
      "name": "GATK4 Somatic CNVs",
      "one_line_profile": "Workflow for somatic copy number variation detection",
      "detailed_description": "A WDL workflow for detecting somatic copy number variations (CNVs) in tumor/normal sample pairs using GATK4 tools.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "copy_number_variation",
        "somatic_variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/gatk-workflows/gatk4-somatic-cnvs",
      "help_website": [
        "https://gatk.broadinstitute.org"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "gatk",
        "wdl",
        "cnv",
        "cancer-genomics"
      ],
      "id": 282
    },
    {
      "name": "GATK4 Somatic SNVs Indels",
      "one_line_profile": "Workflow for somatic SNV and Indel calling",
      "detailed_description": "A WDL workflow for calling somatic single nucleotide variants (SNVs) and insertions/deletions (Indels) using Mutect2.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "somatic_variant_calling",
        "snv_indel_detection"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/gatk-workflows/gatk4-somatic-snvs-indels",
      "help_website": [
        "https://gatk.broadinstitute.org"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "gatk",
        "wdl",
        "mutect2",
        "cancer-genomics"
      ],
      "id": 283
    },
    {
      "name": "FluentDNA",
      "one_line_profile": "Zooming visualization tool for DNA sequence data",
      "detailed_description": "A tool for browsing sequence data of any size using a zooming visualization interface, usable as a standalone program or Python module.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "sequence_visualization",
        "genomics"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/josiahseaman/FluentDNA",
      "help_website": [],
      "license": null,
      "tags": [
        "visualization",
        "dna",
        "genomics",
        "bioinformatics"
      ],
      "id": 284
    },
    {
      "name": "pybgen",
      "one_line_profile": "Python library for reading BGEN genetic data files",
      "detailed_description": "A Python module designed to parse and process BGEN (Binary GENetic) files, commonly used for storing large-scale imputed genotype data in genome-wide association studies (GWAS).",
      "domains": [
        "D1",
        "D4"
      ],
      "subtask_category": [
        "data_io",
        "genetics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lemieuxl/pybgen",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bgen",
        "genetics",
        "bioinformatics",
        "gwas"
      ],
      "id": 285
    },
    {
      "name": "pyplink",
      "one_line_profile": "Python library for reading PLINK binary files",
      "detailed_description": "A Python module for reading binary PLINK files (BED/BIM/FAM), which are standard formats for storing genotype data in population genetics and bioinformatics.",
      "domains": [
        "D1",
        "D4"
      ],
      "subtask_category": [
        "data_io",
        "genetics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lemieuxl/pyplink",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "plink",
        "genetics",
        "bioinformatics",
        "genotyping"
      ],
      "id": 286
    },
    {
      "name": "altocumulus",
      "one_line_profile": "CLI tool for submitting WDL workflows to Cromwell/Terra",
      "detailed_description": "A command-line interface designed to facilitate the submission and management of WDL (Workflow Description Language) jobs to Cromwell servers or the Terra platform, streamlining bioinformatics workflow execution.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_management",
        "job_submission"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/lilab-bcb/altocumulus",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "wdl",
        "cromwell",
        "terra",
        "bioinformatics",
        "workflow"
      ],
      "id": 287
    },
    {
      "name": "mod_bio",
      "one_line_profile": "Apache2 modules for bioinformatics data handling",
      "detailed_description": "A collection of Apache2 modules specifically designed for bioinformatics applications, enabling the web server to handle and serve biological data formats directly.",
      "domains": [
        "D2",
        "D4"
      ],
      "subtask_category": [
        "data_serving",
        "bioinformatics_web"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/lindenb/mod_bio",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "apache2",
        "bioinformatics",
        "web-server"
      ],
      "id": 288
    },
    {
      "name": "pumbaa",
      "one_line_profile": "CLI utilities for interacting with Cromwell Server",
      "detailed_description": "A command-line tool providing utilities to interact with the Cromwell workflow engine server, aiding in the monitoring and management of bioinformatics workflows.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_management",
        "monitoring"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/lmtani/pumbaa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "cromwell",
        "cli",
        "bioinformatics",
        "workflow"
      ],
      "id": 289
    },
    {
      "name": "luslab-nf-modules",
      "one_line_profile": "Collection of Nextflow modules for bioinformatics",
      "detailed_description": "A repository containing reusable Nextflow modules developed by Luslab, designed to be integrated into bioinformatics analysis pipelines for various omics data processing tasks.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "pipeline_component",
        "bioinformatics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/luslab/luslab-nf-modules",
      "help_website": [],
      "license": null,
      "tags": [
        "nextflow",
        "bioinformatics",
        "modules",
        "pipeline"
      ],
      "id": 290
    },
    {
      "name": "py-nf",
      "one_line_profile": "Python interface for running nf-core modules",
      "detailed_description": "A Python library that allows users to execute nf-core Nextflow modules directly from Python scripts, facilitating the integration of bioinformatics workflow components into Python-based analysis environments.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_integration",
        "bioinformatics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mathysgrapotte/py-nf",
      "help_website": [],
      "license": null,
      "tags": [
        "nextflow",
        "nf-core",
        "python",
        "bioinformatics"
      ],
      "id": 291
    },
    {
      "name": "medspacy",
      "one_line_profile": "Clinical NLP library using spaCy",
      "detailed_description": "A library for performing clinical Natural Language Processing (NLP) tasks using spaCy. It includes components for context detection (ConText), section detection, and other clinical text processing needs.",
      "domains": [
        "D4",
        "D5"
      ],
      "subtask_category": [
        "clinical_nlp",
        "text_mining"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/medspacy/medspacy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "clinical",
        "spacy",
        "healthcare",
        "text-mining"
      ],
      "id": 292
    },
    {
      "name": "bioGUI",
      "one_line_profile": "GUI creator and installer for bioinformatics tools",
      "detailed_description": "A framework that allows developers to script graphical user interfaces for command-line bioinformatics applications and provides installation modules for users, simplifying tool accessibility.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "gui_wrapper",
        "software_management"
      ],
      "application_level": "tool",
      "primary_language": "C",
      "repo_url": "https://github.com/mjoppich/bioGUI",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "gui",
        "bioinformatics",
        "usability",
        "installer"
      ],
      "id": 293
    },
    {
      "name": "mskcc-omics-workflows/modules",
      "one_line_profile": "Nextflow DSL2 modules for MSKCC omics workflows",
      "detailed_description": "A repository hosting Nextflow DSL2 module files containing tool-specific process definitions and documentation, used for building omics analysis pipelines at Memorial Sloan Kettering Cancer Center.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "pipeline_component",
        "omics_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/mskcc-omics-workflows/modules",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "nextflow",
        "dsl2",
        "omics",
        "bioinformatics",
        "mskcc"
      ],
      "id": 294
    },
    {
      "name": "PyReQTL",
      "one_line_profile": "Python toolkit for eQTL analysis",
      "detailed_description": "A collection of Python modules designed to identify associations between expressed SNVs and gene expression (eQTL analysis) using RNA-sequencing data, equivalent to the R ReQTL Toolkit.",
      "domains": [
        "D4",
        "D5"
      ],
      "subtask_category": [
        "eqtl_analysis",
        "genomics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nalomran/PyReQTL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "eqtl",
        "rna-seq",
        "genomics",
        "bioinformatics"
      ],
      "id": 295
    },
    {
      "name": "nf-core/airrflow",
      "one_line_profile": "Pipeline for B-cell and T-cell repertoire sequencing analysis",
      "detailed_description": "A bioinformatics pipeline for Adaptive Immune Receptor Repertoire (AIRR) sequencing data analysis, utilizing the Immcantation framework for processing B-cell and T-cell data.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "immunoinformatics",
        "sequence_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/airrflow",
      "help_website": [
        "https://nf-co.re/airrflow"
      ],
      "license": "MIT",
      "tags": [
        "airr-seq",
        "immunology",
        "b-cell",
        "t-cell"
      ],
      "id": 296
    },
    {
      "name": "nf-core/bactmap",
      "one_line_profile": "Mapping-based pipeline for bacterial phylogeny",
      "detailed_description": "A pipeline for creating a phylogeny from bacterial whole genome sequences using a mapping-based approach.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "phylogenetics",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/bactmap",
      "help_website": [
        "https://nf-co.re/bactmap"
      ],
      "license": "MIT",
      "tags": [
        "bacteria",
        "phylogeny",
        "wgs"
      ],
      "id": 297
    },
    {
      "name": "nf-core/bamtofastq",
      "one_line_profile": "BAM/CRAM to FastQ conversion and QC pipeline",
      "detailed_description": "A utility pipeline to convert BAM or CRAM files to FastQ format while performing quality control checks.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "data_conversion",
        "quality_control"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/bamtofastq",
      "help_website": [
        "https://nf-co.re/bamtofastq"
      ],
      "license": "MIT",
      "tags": [
        "bam",
        "fastq",
        "utility"
      ],
      "id": 298
    },
    {
      "name": "nf-core/circdna",
      "one_line_profile": "Pipeline for extrachromosomal circular DNA identification",
      "detailed_description": "A pipeline to identify extrachromosomal circular DNA (ecDNA) from Circle-seq, WGS, and ATAC-seq data.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "genomics",
        "structural_variant_detection"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/nf-core/circdna",
      "help_website": [
        "https://nf-co.re/circdna"
      ],
      "license": "MIT",
      "tags": [
        "ecdna",
        "cancer-genomics",
        "circle-seq"
      ],
      "id": 299
    },
    {
      "name": "nf-core/circrna",
      "one_line_profile": "circRNA quantification and differential expression pipeline",
      "detailed_description": "A pipeline for the identification, quantification, and differential expression analysis of circular RNAs (circRNAs) from RNA-Seq data, including miRNA target prediction.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "transcriptomics",
        "rna_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/circrna",
      "help_website": [
        "https://nf-co.re/circrna"
      ],
      "license": "MIT",
      "tags": [
        "circrna",
        "rna-seq",
        "mirna"
      ],
      "id": 300
    },
    {
      "name": "nf-core/crisprseq",
      "one_line_profile": "Pipeline for analysis of CRISPR edited data",
      "detailed_description": "A pipeline for evaluating gene editing quality from targeted NGS data and discovering genes from CRISPR-Cas9 knockout or activation screens.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "genome_editing_analysis",
        "screening"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/crisprseq",
      "help_website": [
        "https://nf-co.re/crisprseq"
      ],
      "license": "MIT",
      "tags": [
        "crispr",
        "gene-editing",
        "screening"
      ],
      "id": 301
    },
    {
      "name": "nf-core/demultiplex",
      "one_line_profile": "Demultiplexing pipeline for sequencing data",
      "detailed_description": "A pipeline for demultiplexing raw sequencing data (BCL files) into FastQ files, supporting various sequencing platforms.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "data_processing",
        "demultiplexing"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/demultiplex",
      "help_website": [
        "https://nf-co.re/demultiplex"
      ],
      "license": "MIT",
      "tags": [
        "sequencing",
        "bcl",
        "fastq"
      ],
      "id": 302
    },
    {
      "name": "nf-core/diseasemodulediscovery",
      "one_line_profile": "Network-based disease module identification pipeline",
      "detailed_description": "A pipeline for identifying disease modules in biological networks, integrating molecular interaction data with disease-associated genes.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "network_biology",
        "systems_biology"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/nf-core/diseasemodulediscovery",
      "help_website": [
        "https://nf-co.re/diseasemodulediscovery"
      ],
      "license": "MIT",
      "tags": [
        "network-biology",
        "disease-modules",
        "graph"
      ],
      "id": 303
    },
    {
      "name": "nf-core/epitopeprediction",
      "one_line_profile": "Epitope prediction and annotation pipeline",
      "detailed_description": "A bioinformatics pipeline for predicting epitopes from sequencing data, useful for vaccine design and immunology studies.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "immunoinformatics",
        "prediction"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/epitopeprediction",
      "help_website": [
        "https://nf-co.re/epitopeprediction"
      ],
      "license": "MIT",
      "tags": [
        "epitope",
        "immunology",
        "vaccine"
      ],
      "id": 304
    },
    {
      "name": "nf-core/genomeassembler",
      "one_line_profile": "Long-read genome assembly pipeline",
      "detailed_description": "A pipeline for the assembly and scaffolding of haploid/unphased genomes using long reads from Oxford Nanopore or PacBio HiFi.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "genome_assembly",
        "long_read_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/genomeassembler",
      "help_website": [
        "https://nf-co.re/genomeassembler"
      ],
      "license": "MIT",
      "tags": [
        "assembly",
        "ont",
        "pacbio"
      ],
      "id": 305
    },
    {
      "name": "nf-core/hlatyping",
      "one_line_profile": "HLA typing pipeline from NGS data",
      "detailed_description": "A pipeline for precision HLA typing using next-generation sequencing data, supporting various HLA typing tools.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "immunoinformatics",
        "genotyping"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/hlatyping",
      "help_website": [
        "https://nf-co.re/hlatyping"
      ],
      "license": "MIT",
      "tags": [
        "hla",
        "immunology",
        "genotyping"
      ],
      "id": 306
    },
    {
      "name": "nf-core/isoseq",
      "one_line_profile": "PacBio Iso-Seq analysis pipeline",
      "detailed_description": "A pipeline for processing PacBio Iso-Seq data, generating Full Length Non-Chimeric (FLNC) sequences and genome annotations.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "transcriptomics",
        "long_read_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/isoseq",
      "help_website": [
        "https://nf-co.re/isoseq"
      ],
      "license": "MIT",
      "tags": [
        "isoseq",
        "pacbio",
        "transcriptomics"
      ],
      "id": 307
    },
    {
      "name": "nf-core/metatdenovo",
      "one_line_profile": "Metatranscriptome/Metagenome assembly and annotation pipeline",
      "detailed_description": "A pipeline for de novo assembly and annotation of metatranscriptomic or metagenomic data covering prokaryotes, eukaryotes, and viruses.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "metagenomics",
        "metatranscriptomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/metatdenovo",
      "help_website": [
        "https://nf-co.re/metatdenovo"
      ],
      "license": "MIT",
      "tags": [
        "assembly",
        "annotation",
        "microbiome"
      ],
      "id": 308
    },
    {
      "name": "nf-core/mhcquant",
      "one_line_profile": "MHC peptide identification and quantification pipeline",
      "detailed_description": "A pipeline to identify and quantify MHC eluted peptides from mass spectrometry raw data, used in immunopeptidomics.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "proteomics",
        "immunoinformatics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/mhcquant",
      "help_website": [
        "https://nf-co.re/mhcquant"
      ],
      "license": "MIT",
      "tags": [
        "mass-spectrometry",
        "immunopeptidomics",
        "mhc"
      ],
      "id": 309
    },
    {
      "name": "nf-core/modules",
      "one_line_profile": "Repository of Nextflow DSL2 modules for bioinformatics",
      "detailed_description": "A centralized collection of single-tool wrapper modules for Nextflow DSL2, serving as the building blocks for nf-core pipelines.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_development",
        "bioinformatics_tools"
      ],
      "application_level": "library",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/modules",
      "help_website": [
        "https://nf-co.re/modules"
      ],
      "license": "MIT",
      "tags": [
        "nextflow",
        "dsl2",
        "modules"
      ],
      "id": 310
    },
    {
      "name": "nf-core/multiplesequencealign",
      "one_line_profile": "Multiple Sequence Alignment (MSA) evaluation pipeline",
      "detailed_description": "A pipeline to run and systematically evaluate various Multiple Sequence Alignment (MSA) methods.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "sequence_alignment",
        "benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/multiplesequencealign",
      "help_website": [
        "https://nf-co.re/multiplesequencealign"
      ],
      "license": "MIT",
      "tags": [
        "msa",
        "alignment",
        "evaluation"
      ],
      "id": 311
    },
    {
      "name": "nf-core/pathogensurveillance",
      "one_line_profile": "Pathogen surveillance pipeline",
      "detailed_description": "A pipeline for the surveillance of pathogens using population genomics and sequencing data.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "epidemiology",
        "pathogen_genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/pathogensurveillance",
      "help_website": [
        "https://nf-co.re/pathogensurveillance"
      ],
      "license": "MIT",
      "tags": [
        "surveillance",
        "pathogen",
        "epidemiology"
      ],
      "id": 312
    },
    {
      "name": "nf-core/proteomicslfq",
      "one_line_profile": "Proteomics label-free quantification pipeline",
      "detailed_description": "A pipeline for label-free quantification (LFQ) analysis of proteomics data.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "proteomics",
        "quantification"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/proteomicslfq",
      "help_website": [
        "https://nf-co.re/proteomicslfq"
      ],
      "license": "MIT",
      "tags": [
        "proteomics",
        "lfq",
        "mass-spectrometry"
      ],
      "id": 313
    },
    {
      "name": "nf-core/readsimulator",
      "one_line_profile": "Sequencing read simulation pipeline",
      "detailed_description": "A pipeline to simulate sequencing reads for various applications such as Amplicon, Target Capture, Metagenome, and Whole Genome data.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "data_simulation",
        "benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/readsimulator",
      "help_website": [
        "https://nf-co.re/readsimulator"
      ],
      "license": "MIT",
      "tags": [
        "simulation",
        "ngs",
        "synthetic-data"
      ],
      "id": 314
    },
    {
      "name": "nf-core/rnasplice",
      "one_line_profile": "RNA-seq alternative splicing analysis pipeline",
      "detailed_description": "A bioinformatics pipeline for analyzing alternative splicing events from RNA-seq data.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "transcriptomics",
        "splicing_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/rnasplice",
      "help_website": [
        "https://nf-co.re/rnasplice"
      ],
      "license": "MIT",
      "tags": [
        "splicing",
        "rna-seq",
        "isoforms"
      ],
      "id": 315
    },
    {
      "name": "nf-core/rnavar",
      "one_line_profile": "RNA variant calling pipeline",
      "detailed_description": "A pipeline for variant calling from RNA-seq data, following GATK best practices for RNA-seq.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "transcriptomics",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/rnavar",
      "help_website": [
        "https://nf-co.re/rnavar"
      ],
      "license": "MIT",
      "tags": [
        "rna-seq",
        "variants",
        "gatk"
      ],
      "id": 316
    },
    {
      "name": "nf-core/scnanoseq",
      "one_line_profile": "Single-cell Nanopore sequencing pipeline",
      "detailed_description": "A pipeline for analyzing single-cell or single-nuclei data derived from Oxford Nanopore and 10X Genomics protocols.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "single_cell",
        "long_read_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/scnanoseq",
      "help_website": [
        "https://nf-co.re/scnanoseq"
      ],
      "license": "MIT",
      "tags": [
        "single-cell",
        "nanopore",
        "10x"
      ],
      "id": 317
    },
    {
      "name": "nf-core/spatialvi",
      "one_line_profile": "Spatial transcriptomics analysis pipeline",
      "detailed_description": "A pipeline for processing spatially-resolved gene counts and image data, designed for 10x Genomics Visium.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "spatial_transcriptomics",
        "image_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/spatialvi",
      "help_website": [
        "https://nf-co.re/spatialvi"
      ],
      "license": "MIT",
      "tags": [
        "spatial-transcriptomics",
        "visium",
        "10x"
      ],
      "id": 318
    },
    {
      "name": "nf-core/tools",
      "one_line_profile": "Helper tools for the nf-core community to create and manage Nextflow pipelines",
      "detailed_description": "A Python package providing command-line tools to assist in the creation, linting, and management of Nextflow pipelines within the nf-core framework. It ensures adherence to community standards and facilitates the development of reproducible bioinformatics workflows.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "pipeline_development",
        "workflow_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nf-core/tools",
      "help_website": [
        "https://nf-co.re/tools"
      ],
      "license": "MIT",
      "tags": [
        "nextflow",
        "bioinformatics",
        "pipeline-development",
        "nf-core"
      ],
      "id": 319
    },
    {
      "name": "nf-core/variantbenchmarking",
      "one_line_profile": "Pipeline to evaluate and validate the accuracy of variant calling methods",
      "detailed_description": "A Nextflow pipeline designed to benchmark small variant calling methods in genomic research. It automates the comparison of variant callers against truth sets, generating performance metrics to validate analysis strategies.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "variant_calling",
        "benchmarking",
        "quality_control"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/variantbenchmarking",
      "help_website": [
        "https://nf-co.re/variantbenchmarking"
      ],
      "license": "MIT",
      "tags": [
        "genomics",
        "benchmarking",
        "variant-calling",
        "nextflow"
      ],
      "id": 320
    },
    {
      "name": "nf-neuro/modules",
      "one_line_profile": "Nextflow neuroimaging library maintained by the SCIL team",
      "detailed_description": "A collection of Nextflow modules specifically designed for neuroimaging analysis pipelines. Maintained by the Sherbrooke Connectivity Imaging Lab (SCIL), it provides reusable components for processing brain imaging data.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "neuroimaging",
        "image_processing"
      ],
      "application_level": "library",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-neuro/modules",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "neuroimaging",
        "nextflow",
        "modules",
        "scil"
      ],
      "id": 321
    },
    {
      "name": "pyiron/pyiron_base",
      "one_line_profile": "Core components of the pyiron IDE for computational materials science",
      "detailed_description": "The base framework for pyiron, an integrated development environment for computational materials science. It provides the workflow management, job submission, and data storage infrastructure required to run complex atomistic simulations and workflows.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "materials_modeling",
        "workflow_management",
        "simulation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/pyiron/pyiron_base",
      "help_website": [
        "https://pyiron.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "materials-science",
        "workflow",
        "simulation",
        "ide"
      ],
      "id": 322
    },
    {
      "name": "refinery-platform/refinery-platform",
      "one_line_profile": "Data management, analysis and visualization system for bioinformatics",
      "detailed_description": "A comprehensive platform for bioinformatics that integrates data repository capabilities with a workflow engine (based on Galaxy) and visualization tools. It facilitates the management and analysis of complex biological datasets.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "data_management",
        "workflow_execution",
        "bioinformatics"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/refinery-platform/refinery-platform",
      "help_website": [
        "http://refinery-platform.org/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "bioinformatics",
        "galaxy",
        "data-management",
        "visualization"
      ],
      "id": 323
    },
    {
      "name": "sapporo-wes/yevis-cli",
      "one_line_profile": "CLI tool to support building and maintaining Yevis workflow registry",
      "detailed_description": "A command-line tool designed to assist in the creation and maintenance of the Yevis workflow registry. It supports the validation and testing of workflows to ensure they meet GA4GH standards and are reproducible across different environments.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_registry",
        "reproducibility",
        "validation"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/sapporo-wes/yevis-cli",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ga4gh",
        "workflow-registry",
        "wes",
        "bioinformatics"
      ],
      "id": 324
    },
    {
      "name": "scipipe/scipipe",
      "one_line_profile": "Robust, flexible and resource-efficient pipelines using Go",
      "detailed_description": "A workflow library for writing scientific pipelines in Go. It emphasizes simplicity, robustness, and reproducibility, providing features like automatic audit logging and resource management for complex computational tasks.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_management",
        "pipeline_execution"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/scipipe/scipipe",
      "help_website": [
        "http://scipipe.org/"
      ],
      "license": "MIT",
      "tags": [
        "workflow-engine",
        "go",
        "reproducibility",
        "scientific-computing"
      ],
      "id": 325
    },
    {
      "name": "seandavi/wdlRunR",
      "one_line_profile": "Elastic, reproducible, and reusable genomic data science tools from R",
      "detailed_description": "An R package that provides an interface to manage and execute WDL (Workflow Description Language) workflows. It allows researchers to run genomic data science pipelines backed by cloud resources directly from an R environment.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_management",
        "genomics"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/seandavi/wdlRunR",
      "help_website": [],
      "license": null,
      "tags": [
        "r",
        "wdl",
        "genomics",
        "workflow"
      ],
      "id": 326
    },
    {
      "name": "snakemake-workflows/snakemake-workflow-template",
      "one_line_profile": "A template for standard compliant snakemake-workflows",
      "detailed_description": "The official template for creating Snakemake workflows that adhere to best practices. It provides a standardized directory structure and configuration setup to ensure workflows are reproducible, distributable, and easy to maintain.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "pipeline_development",
        "workflow_template"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake-workflows/snakemake-workflow-template",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "template",
        "reproducibility",
        "workflow"
      ],
      "id": 327
    },
    {
      "name": "snakemake/snakemake-wrappers",
      "one_line_profile": "Repository of reusable Snakemake wrappers",
      "detailed_description": "A centralized repository of wrappers for common bioinformatics and scientific tools, designed to be easily integrated into Snakemake workflows. These wrappers simplify the process of calling external software and managing dependencies.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "pipeline_development",
        "module_registry"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake/snakemake-wrappers",
      "help_website": [
        "https://snakemake-wrappers.readthedocs.io/"
      ],
      "license": null,
      "tags": [
        "snakemake",
        "wrappers",
        "bioinformatics",
        "modules"
      ],
      "id": 328
    },
    {
      "name": "cromwell-cli",
      "one_line_profile": "Command-line interface for the Cromwell workflow engine",
      "detailed_description": "A Ruby-based command-line wrapper for the Cromwell execution engine, designed to simplify the submission, monitoring, and management of WDL/CWL scientific workflows.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_execution",
        "job_management"
      ],
      "application_level": "solver",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/szeryf/cromwell",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cromwell",
        "wdl",
        "workflow-management",
        "cli"
      ],
      "id": 329
    },
    {
      "name": "ALLHiC",
      "one_line_profile": "Genome scaffolding tool based on Hi-C data",
      "detailed_description": "A bioinformatics tool designed to scaffold genomes using Hi-C data, specifically optimized for handling the complexity of heterozygous and high-ploidy plant genomes.",
      "domains": [
        "D1"
      ],
      "subtask_category": [
        "genome_assembly",
        "scaffolding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tanghaibao/allhic",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "genomics",
        "hi-c",
        "assembly",
        "polyploid"
      ],
      "id": 330
    },
    {
      "name": "PetroPy",
      "one_line_profile": "Petrophysics and formation evaluation library",
      "detailed_description": "A Python package for processing and analyzing wireline log data (LAS files) to perform conventional and unconventional formation evaluation in geoscience contexts.",
      "domains": [
        "D1"
      ],
      "subtask_category": [
        "formation_evaluation",
        "log_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/toddheitmann/PetroPy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "geoscience",
        "petrophysics",
        "las-files",
        "formation-evaluation"
      ],
      "id": 331
    },
    {
      "name": "pyani",
      "one_line_profile": "Average Nucleotide Identity (ANI) analysis tool",
      "detailed_description": "A Python module and application for calculating Average Nucleotide Identity (ANI) between whole genomic sequences, widely used for the classification and identification of bacteria and archaea.",
      "domains": [
        "D1"
      ],
      "subtask_category": [
        "taxonomic_classification",
        "comparative_genomics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/widdowquinn/pyani",
      "help_website": [
        "https://pyani.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "genomics",
        "bacteria",
        "ani",
        "classification"
      ],
      "id": 332
    },
    {
      "name": "Scaff10X",
      "one_line_profile": "Pipeline for scaffolding genome assemblies using 10x Genomics linked-reads",
      "detailed_description": "A bioinformatics pipeline designed to scaffold and break genome assemblies using 10x Genomics linked-reads data. It helps in improving the contiguity and correctness of genome assemblies by leveraging the long-range information from linked-reads.",
      "domains": [
        "D2",
        "D2-02",
        "Genomics"
      ],
      "subtask_category": [
        "genome_assembly",
        "scaffolding"
      ],
      "application_level": "workflow",
      "primary_language": "C",
      "repo_url": "https://github.com/wtsi-hpag/Scaff10X",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "genomics",
        "assembly",
        "scaffolding",
        "10x-genomics",
        "bioinformatics"
      ],
      "id": 333
    },
    {
      "name": "scaffHiC",
      "one_line_profile": "Pipeline for genome scaffolding by modelling distributions of Hi-C pairs",
      "detailed_description": "A genome scaffolding pipeline that models the distribution of Hi-C pairs to order and orient contigs. It utilizes chromatin interaction data to construct chromosome-scale assemblies from fragmented contigs.",
      "domains": [
        "D2",
        "D2-02",
        "Genomics"
      ],
      "subtask_category": [
        "genome_assembly",
        "scaffolding"
      ],
      "application_level": "workflow",
      "primary_language": "C",
      "repo_url": "https://github.com/wtsi-hpag/scaffHiC",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "genomics",
        "assembly",
        "scaffolding",
        "hi-c",
        "bioinformatics"
      ],
      "id": 334
    },
    {
      "name": "bindz-rbp",
      "one_line_profile": "RBP module for bindz to detect regulators' binding sites on RNA sequences",
      "detailed_description": "A specific module for the bindz bioinformatics tool, designed to detect binding sites of RNA-binding proteins (RBPs) on RNA sequences. It serves as a component within the broader bindz analysis framework.",
      "domains": [
        "D2-02",
        "Bioinformatics"
      ],
      "subtask_category": [
        "binding_site_prediction",
        "sequence_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Roff",
      "repo_url": "https://github.com/zavolanlab/bindz-rbp",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rna",
        "rbp",
        "binding-sites",
        "bioinformatics",
        "module"
      ],
      "id": 335
    },
    {
      "name": "omnipkg",
      "one_line_profile": "Python environment manager wrapper for Conda/Pip",
      "detailed_description": "A tool to manage Python environments and dependencies, leveraging conda-forge to resolve conflicts and ensure reproducibility in scientific computing setups.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "dependency_resolution"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/1minds3t/omnipkg",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "conda",
        "python-environment",
        "reproducibility"
      ],
      "id": 336
    },
    {
      "name": "ACCESS-OM2",
      "one_line_profile": "Global coupled ocean-sea ice model",
      "detailed_description": "The ACCESS-OM2 (Australian Community Climate and Earth System Simulator - Ocean Model 2) is a global coupled ocean-sea ice model used for climate research and simulation.",
      "domains": [
        "D1",
        "D1-02"
      ],
      "subtask_category": [
        "climate_modeling",
        "simulation"
      ],
      "application_level": "solver",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/ACCESS-NRI/ACCESS-OM2",
      "help_website": [
        "https://access-om2.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "oceanography",
        "climate-model",
        "sea-ice"
      ],
      "id": 337
    },
    {
      "name": "access-spack-packages",
      "one_line_profile": "Spack package repository for ACCESS-NRI models",
      "detailed_description": "A Spack package repository maintained by ACCESS-NRI, containing package recipes for building Australian climate and earth system simulator models and dependencies.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "hpc_deployment"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/ACCESS-NRI/access-spack-packages",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "spack",
        "hpc",
        "climate-science"
      ],
      "id": 338
    },
    {
      "name": "mSSA",
      "one_line_profile": "Multivariate Singular Spectrum Analysis algorithm",
      "detailed_description": "An implementation of Multivariate Singular Spectrum Analysis (mSSA) for forecasting and imputation of multivariate time series data, applicable in various scientific data analysis contexts.",
      "domains": [
        "D4",
        "D4-02"
      ],
      "subtask_category": [
        "time_series_analysis",
        "imputation",
        "forecasting"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/AbdullahO/mSSA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "time-series",
        "mssa",
        "forecasting"
      ],
      "id": 339
    },
    {
      "name": "nbdev",
      "one_line_profile": "Literate programming environment for Jupyter Notebooks",
      "detailed_description": "A system that allows researchers to develop, document, test, and distribute software directly from Jupyter Notebooks, promoting literate programming and reproducibility in scientific computing.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "literate_programming",
        "documentation",
        "reproducibility"
      ],
      "application_level": "tool",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/AnswerDotAI/nbdev",
      "help_website": [
        "https://nbdev.fast.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "jupyter",
        "literate-programming",
        "python"
      ],
      "id": 340
    },
    {
      "name": "boltz_apptainer",
      "one_line_profile": "Apptainer definition for Boltz-1 model",
      "detailed_description": "Configuration files to build an Apptainer (Singularity) container image for the Boltz-1 biomolecular modeling tool, facilitating reproducible deployment in HPC environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "containerization",
        "deployment"
      ],
      "application_level": "dataset",
      "primary_language": "Dockerfile",
      "repo_url": "https://github.com/Australian-Structural-Biology-Computing/boltz_apptainer",
      "help_website": [],
      "license": null,
      "tags": [
        "apptainer",
        "structural-biology",
        "hpc"
      ],
      "id": 341
    },
    {
      "name": "Batch Shipyard",
      "one_line_profile": "HPC and Batch workload management on Azure",
      "detailed_description": "A tool to provision and execute Docker and Singularity container-based batch processing and HPC workloads on Azure Batch, supporting complex scientific workflows.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "hpc_scheduling",
        "cloud_computing",
        "container_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Azure/batch-shipyard",
      "help_website": [
        "https://batch-shipyard.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "azure",
        "hpc",
        "docker",
        "singularity"
      ],
      "id": 342
    },
    {
      "name": "PiGx",
      "one_line_profile": "Reproducible genomics pipelines",
      "detailed_description": "A collection of genomics pipelines (RNA-seq, ChIP-seq, BS-seq, etc.) built with GNU Guix for reproducibility and ease of use in bioinformatics analysis.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genomics_pipeline",
        "workflow_management"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/BIMSBbioinfo/pigx",
      "help_website": [
        "http://pigx.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "genomics",
        "pipeline",
        "guix",
        "reproducibility"
      ],
      "id": 343
    },
    {
      "name": "PiGx RNA-seq",
      "one_line_profile": "Bulk RNA-seq analysis pipeline",
      "detailed_description": "A dedicated pipeline within the PiGx ecosystem for processing, quality control, and downstream analysis of bulk RNA-seq data.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "rna_seq_analysis",
        "quality_control"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/BIMSBbioinfo/pigx_rnaseq",
      "help_website": [
        "http://pigx.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "rna-seq",
        "bioinformatics",
        "pipeline"
      ],
      "id": 344
    },
    {
      "name": "swineherd",
      "one_line_profile": "Guix System container manager for PiGx",
      "detailed_description": "A tool to manage GNU Guix System containers, specifically designed to support the execution and isolation of PiGx genomics pipelines.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "container_management",
        "environment_isolation"
      ],
      "application_level": "tool",
      "primary_language": "TeX",
      "repo_url": "https://github.com/BIMSBbioinfo/swineherd",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "guix",
        "containers",
        "bioinformatics"
      ],
      "id": 345
    },
    {
      "name": "DGBench",
      "one_line_profile": "Benchmark for robotic grasping in dynamic environments",
      "detailed_description": "An open-source, reproducible benchmark suite for evaluating robotic grasping algorithms in dynamic settings, providing simulation environments and metrics.",
      "domains": [
        "D1",
        "D1-06"
      ],
      "subtask_category": [
        "robotic_grasping",
        "benchmarking",
        "simulation"
      ],
      "application_level": "dataset",
      "primary_language": "C",
      "repo_url": "https://github.com/BenBurgessLimerick/DGBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "robotics",
        "benchmark",
        "grasping"
      ],
      "id": 346
    },
    {
      "name": "mulled",
      "one_line_profile": "Automated container generation for bioinformatics",
      "detailed_description": "A tool used by the BioContainers project to automatically generate Docker and Singularity containers from Conda packages, ensuring software availability for bioinformatics workflows.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "container_generation",
        "package_encapsulation"
      ],
      "application_level": "tool",
      "primary_language": "Shell",
      "repo_url": "https://github.com/BioContainers/mulled",
      "help_website": [],
      "license": null,
      "tags": [
        "biocontainers",
        "docker",
        "singularity",
        "bioinformatics"
      ],
      "id": 347
    },
    {
      "name": "BlueBrain Spack Packages",
      "one_line_profile": "Spack packages for Blue Brain Project",
      "detailed_description": "A repository of Spack package recipes maintained by the Blue Brain Project, facilitating the deployment of neuroscience simulation software on HPC systems.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "hpc_deployment"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/BlueBrain/spack-packages",
      "help_website": [],
      "license": null,
      "tags": [
        "spack",
        "neuroscience",
        "hpc"
      ],
      "id": 348
    },
    {
      "name": "spack-c2sm",
      "one_line_profile": "Spack configuration for C2SM",
      "detailed_description": "Spack configuration and package repository for the Center for Climate Systems Modeling (C2SM), managing software environments for climate research.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "environment_configuration"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/C2SM/spack-c2sm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "spack",
        "climate-modeling",
        "hpc"
      ],
      "id": 349
    },
    {
      "name": "HPK",
      "one_line_profile": "Kubernetes to HPC translator",
      "detailed_description": "A tool that allows running Kubernetes-native applications within HPC environments by translating deployments to Slurm jobs and Singularity/Apptainer containers.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "workload_translation",
        "hpc_integration"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/CARV-ICS-FORTH/HPK",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "hpc",
        "slurm",
        "singularity"
      ],
      "id": 350
    },
    {
      "name": "envmodule_setup",
      "one_line_profile": "Lmod setup scripts",
      "detailed_description": "Scripts to assist in setting up Lmod, a Lua-based environment module system widely used in HPC to manage software dependencies.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_modules",
        "hpc_setup"
      ],
      "application_level": "tool",
      "primary_language": "Lua",
      "repo_url": "https://github.com/CLIUtils/envmodule_setup",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lmod",
        "hpc",
        "environment-modules"
      ],
      "id": 351
    },
    {
      "name": "CSC Singularity Recipes",
      "one_line_profile": "Apptainer recipes for CSC HPC",
      "detailed_description": "A collection of Apptainer/Singularity recipe files for building scientific software containers used on CSC (IT Center for Science) HPC environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "container_recipes",
        "hpc_software"
      ],
      "application_level": "dataset",
      "primary_language": "R",
      "repo_url": "https://github.com/CSCfi/singularity-recipes",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "singularity",
        "apptainer",
        "hpc",
        "csc"
      ],
      "id": 352
    },
    {
      "name": "jupyter_environment_kernels",
      "one_line_profile": "Conda/Virtualenv kernel detection for Jupyter",
      "detailed_description": "A Jupyter plugin that automatically detects Conda and Virtualenv environments and makes them available as kernels, simplifying environment management for data scientists.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "kernel_management",
        "environment_integration"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/Cadair/jupyter_environment_kernels",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "jupyter",
        "conda",
        "virtualenv"
      ],
      "id": 353
    },
    {
      "name": "ChangeMamba",
      "one_line_profile": "Remote sensing change detection model",
      "detailed_description": "A deep learning model based on Spatio-Temporal State Space Model (Mamba architecture) for change detection in remote sensing imagery.",
      "domains": [
        "D4",
        "D4-03"
      ],
      "subtask_category": [
        "change_detection",
        "remote_sensing",
        "image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChenHongruixuan/ChangeMamba",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "remote-sensing",
        "mamba",
        "change-detection"
      ],
      "id": 354
    },
    {
      "name": "dodola",
      "one_line_profile": "CMIP6 bias-adjustment workflow tool",
      "detailed_description": "A containerized application for performing bias adjustment and downscaling tasks on CMIP6 climate data, designed to run within larger orchestrated workflows.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "bias_adjustment",
        "climate_downscaling",
        "workflow_task"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/ClimateImpactLab/dodola",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "cmip6",
        "climate-data",
        "bias-correction"
      ],
      "id": 355
    },
    {
      "name": "KCES",
      "one_line_profile": "Workflow containerization scheduling scheme",
      "detailed_description": "A research implementation of a scheduling scheme for containerized workflows in a cloud-edge collaboration framework, optimizing task execution.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_scheduling",
        "cloud_edge_computing"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/CloudControlSystems/KCES",
      "help_website": [],
      "license": null,
      "tags": [
        "scheduling",
        "workflow",
        "cloud-edge"
      ],
      "id": 356
    },
    {
      "name": "KubeAdaptor",
      "one_line_profile": "Cloud-native workflow engine adaptor",
      "detailed_description": "A framework to implement workflow containerization on Kubernetes, connecting workflow systems to K8s and ensuring consistency in task scheduling.",
      "domains": [
        "D2",
        "D2-02"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "kubernetes_integration"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/CloudControlSystems/KubeAdaptor",
      "help_website": [],
      "license": null,
      "tags": [
        "kubernetes",
        "workflow",
        "cloud-native"
      ],
      "id": 357
    },
    {
      "name": "ZigMa",
      "one_line_profile": "Mamba-based diffusion model",
      "detailed_description": "Implementation of 'ZigMa: A DiT-Style Mamba-based Diffusion Model', a generative model architecture for computer vision tasks.",
      "domains": [
        "D4",
        "D4-03"
      ],
      "subtask_category": [
        "generative_modeling",
        "image_synthesis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CompVis/zigma",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-model",
        "mamba",
        "computer-vision"
      ],
      "id": 358
    },
    {
      "name": "EasyBuild ComputeCanada Config",
      "one_line_profile": "EasyBuild configuration for Compute Canada",
      "detailed_description": "Custom configuration and recipes for EasyBuild, used by Compute Canada to manage software builds and modules on their HPC clusters.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "software_build",
        "hpc_configuration"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/ComputeCanada/easybuild-computecanada-config",
      "help_website": [],
      "license": null,
      "tags": [
        "easybuild",
        "hpc",
        "software-management"
      ],
      "id": 359
    },
    {
      "name": "private-conda-repo",
      "one_line_profile": "Private Conda package repository server",
      "detailed_description": "A tool to host a private Conda channel/repository, allowing organizations to manage and serve custom or private scientific software packages.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_hosting",
        "environment_infrastructure"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/DanielBok/private-conda-repo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "conda",
        "repository",
        "package-management"
      ],
      "id": 360
    },
    {
      "name": "mach-nix",
      "one_line_profile": "Reproducible Python environments with Nix",
      "detailed_description": "A tool that simplifies the creation of highly reproducible Python environments using the Nix package manager, solving dependency hell in scientific computing.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "reproducibility"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/DavHau/mach-nix",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nix",
        "python",
        "reproducibility"
      ],
      "id": 361
    },
    {
      "name": "cotainr",
      "one_line_profile": "User-space Apptainer container builder",
      "detailed_description": "A tool that allows users to build Apptainer/Singularity containers in user space (without root privileges) from Conda environments, tailored for HPC usage.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "container_building",
        "hpc_deployment"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/DeiC-HPC/cotainr",
      "help_website": [
        "https://cotainr.readthedocs.io/"
      ],
      "license": "EUPL-1.2",
      "tags": [
        "apptainer",
        "singularity",
        "hpc",
        "conda"
      ],
      "id": 362
    },
    {
      "name": "Dugong",
      "one_line_profile": "Scientific Linux Container",
      "detailed_description": "A Docker container definition designed for scientific computing, pre-configured with bioinformatics and data science tools.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "container_environment",
        "bioinformatics_setup"
      ],
      "application_level": "dataset",
      "primary_language": "Dockerfile",
      "repo_url": "https://github.com/DugongBioinformatics/Dugong",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "docker",
        "bioinformatics",
        "scientific-computing"
      ],
      "id": 363
    },
    {
      "name": "E4S",
      "one_line_profile": "Extreme-scale Scientific Software Stack",
      "detailed_description": "The Extreme-scale Scientific Software Stack (E4S) is a community effort to provide a comprehensive suite of open-source software packages for HPC, integrated with Spack.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "software_stack",
        "hpc_environment"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/E4S-Project/e4s",
      "help_website": [
        "https://e4s.io"
      ],
      "license": "MIT",
      "tags": [
        "hpc",
        "spack",
        "scientific-software"
      ],
      "id": 364
    },
    {
      "name": "E4S à la carte",
      "one_line_profile": "Custom HPC container image builder",
      "detailed_description": "A tool that allows users to customize E4S container images by adding specific system and Spack packages, tailoring the environment for specific scientific workflows.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "container_customization",
        "image_building"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/E4S-Project/e4s-alc",
      "help_website": [
        "https://e4s-alc.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "hpc",
        "container",
        "spack"
      ],
      "id": 365
    },
    {
      "name": "e4s-cl",
      "one_line_profile": "Container launcher for E4S",
      "detailed_description": "A tool to simplify the launch of MPI applications inside E4S containers on HPC systems, handling library binding and environment setup.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "container_runtime",
        "mpi_execution"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/E4S-Project/e4s-cl",
      "help_website": [
        "https://e4s-cl.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "hpc",
        "mpi",
        "container-launcher"
      ],
      "id": 366
    },
    {
      "name": "ESCOMP-Containers",
      "one_line_profile": "Containerized versions of ESCOMP Earth System modeling software",
      "detailed_description": "Provides Docker and Singularity containers for the Community Earth System Model (CESM) and other ESCOMP software, facilitating reproducible climate simulations.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "simulation",
        "environment_management"
      ],
      "application_level": "platform",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/ESCOMP/ESCOMP-Containers",
      "help_website": [],
      "license": null,
      "tags": [
        "climate-modeling",
        "containers",
        "cesm",
        "hpc"
      ],
      "id": 367
    },
    {
      "name": "EXP-container",
      "one_line_profile": "Container recipes for the EXP N-body simulation code",
      "detailed_description": "Provides recipes and build configurations for creating Docker and Apptainer/Singularity containers for the EXP galaxy formation simulation software.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "simulation",
        "environment_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/EXP-code/EXP-container",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "n-body",
        "astrophysics",
        "containers",
        "apptainer"
      ],
      "id": 368
    },
    {
      "name": "bioconda_recipepod",
      "one_line_profile": "Gitpod environment for developing Bioconda recipes",
      "detailed_description": "A development environment configuration for creating, testing, and maintaining Bioconda recipes, streamlining the bioinformatics software supply chain.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "bioinformatics"
      ],
      "application_level": "workflow",
      "primary_language": "Dockerfile",
      "repo_url": "https://github.com/FloWuenne/bioconda_recipepod",
      "help_website": [],
      "license": null,
      "tags": [
        "bioconda",
        "gitpod",
        "packaging"
      ],
      "id": 369
    },
    {
      "name": "openfoam-apptainer-packaging",
      "one_line_profile": "Automated Apptainer container builds for OpenFOAM CFD software",
      "detailed_description": "Automates the packaging of OpenFOAM and related HPC packages into Apptainer containers, ensuring portability for Computational Fluid Dynamics workflows.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "simulation",
        "environment_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/FoamScience/openfoam-apptainer-packaging",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "openfoam",
        "cfd",
        "apptainer",
        "hpc"
      ],
      "id": 370
    },
    {
      "name": "EBcb",
      "one_line_profile": "Docker container for building scientific software with EasyBuild",
      "detailed_description": "A containerized environment designed to run EasyBuild, facilitating the building and installation of scientific software stacks in a reproducible manner.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "build_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/FredHutch/EBcb",
      "help_website": [],
      "license": null,
      "tags": [
        "easybuild",
        "hpc",
        "containers"
      ],
      "id": 371
    },
    {
      "name": "MARS",
      "one_line_profile": "Containerized bioinformatics workflow integration and management tool",
      "detailed_description": "Simplifies bioinformatics workflows by providing a containerized approach to tool integration and management, ensuring reproducibility in genomic analysis.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "workflow_management",
        "pipeline_integration"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/GenomicAI/mars",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "containers",
        "workflow"
      ],
      "id": 372
    },
    {
      "name": "hep-spack",
      "one_line_profile": "Spack package manager overlay for High Energy Physics software",
      "detailed_description": "A Spack overlay repository containing package recipes specifically for the High Energy Physics (HEP) community, enabling the build of complex HEP software stacks.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/HSF/hep-spack",
      "help_website": [],
      "license": null,
      "tags": [
        "hep",
        "spack",
        "hpc",
        "physics"
      ],
      "id": 373
    },
    {
      "name": "maru",
      "one_line_profile": "CLI for containerizing scientific applications",
      "detailed_description": "A command-line interface designed to quickly and easily containerize scientific applications, simplifying the creation of reproducible research environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "containerization",
        "environment_management"
      ],
      "application_level": "workflow",
      "primary_language": "Go",
      "repo_url": "https://github.com/JaneliaSciComp/maru",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "containers",
        "reproducibility",
        "science-ops"
      ],
      "id": 374
    },
    {
      "name": "IterativeSolvers.jl",
      "one_line_profile": "Julia library for iterative linear algebra solvers",
      "detailed_description": "Provides iterative algorithms for solving linear systems, eigensystems, and singular value problems, essential for scientific simulation and modeling.",
      "domains": [
        "D1",
        "D1-01"
      ],
      "subtask_category": [
        "numerical_solver"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaLinearAlgebra/IterativeSolvers.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "linear-algebra",
        "julia",
        "scientific-computing"
      ],
      "id": 375
    },
    {
      "name": "Conda.jl",
      "one_line_profile": "Julia package for managing Conda binary dependencies",
      "detailed_description": "Allows Julia packages to manage and install binary dependencies via Conda, bridging the gap between Julia and the Python/Conda scientific ecosystem.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "dependency_management"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaPy/Conda.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "julia",
        "conda",
        "package-management"
      ],
      "id": 376
    },
    {
      "name": "KrylovKit.jl",
      "one_line_profile": "Julia library for Krylov methods in linear algebra",
      "detailed_description": "A Julia library providing Krylov methods for solving linear problems, eigenvalues, and singular values, widely used in physics simulations (e.g., quantum mechanics).",
      "domains": [
        "D1",
        "D1-01"
      ],
      "subtask_category": [
        "numerical_solver"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/Jutho/KrylovKit.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "krylov",
        "linear-algebra",
        "julia"
      ],
      "id": 377
    },
    {
      "name": "Benchpark",
      "one_line_profile": "Framework for reproducible HPC benchmarking specifications",
      "detailed_description": "An open collaborative repository and framework for defining reproducible specifications of HPC benchmarks, aiding in the performance analysis of scientific computing environments.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/LLNL/benchpark",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "benchmarking",
        "llnl"
      ],
      "id": 378
    },
    {
      "name": "Uberenv",
      "one_line_profile": "Automation tool for Spack-based software deployment",
      "detailed_description": "Automates the process of using Spack to build and deploy scientific software stacks, simplifying dependency management on HPC systems.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "deployment"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/LLNL/uberenv",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "spack",
        "hpc",
        "deployment"
      ],
      "id": 379
    },
    {
      "name": "PSCondaEnvs",
      "one_line_profile": "PowerShell scripts for Conda environment management",
      "detailed_description": "Provides drop-in replacement scripts to replicate Conda's activate/deactivate commands in PowerShell, enabling scientific Python workflows on Windows.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management"
      ],
      "application_level": "library",
      "primary_language": "PowerShell",
      "repo_url": "https://github.com/Liquidmantis/PSCondaEnvs",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "conda",
        "powershell",
        "windows"
      ],
      "id": 380
    },
    {
      "name": "LUMI-SoftwareStack",
      "one_line_profile": "Setup tools for the LUMI supercomputer software environment",
      "detailed_description": "Provides the setup scripts and configurations for the LMOD-based module system and EasyBuild environment on the LUMI supercomputer.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_setup"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lumi-supercomputer/LUMI-SoftwareStack",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "hpc",
        "lumi",
        "easybuild",
        "lmod"
      ],
      "id": 381
    },
    {
      "name": "dsatools",
      "one_line_profile": "Digital signal analysis and processing library",
      "detailed_description": "A Python library for digital signal analysis, including SSA, DMD, and EMD methods, used for processing experimental data in physics and engineering.",
      "domains": [
        "D3",
        "D3-01"
      ],
      "subtask_category": [
        "signal_processing",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/MVRonkin/dsatools",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "signal-processing",
        "ssa",
        "dmd",
        "time-series"
      ],
      "id": 382
    },
    {
      "name": "facemap",
      "one_line_profile": "Framework for predicting neural activity from mouse orofacial movements",
      "detailed_description": "A framework for analyzing behavioral videos to predict neural activity in mice. It tracks orofacial movements using pose estimation and includes singular value decomposition (SVD) for behavioral video analysis.",
      "domains": [
        "Neuroscience",
        "Data/Analysis"
      ],
      "subtask_category": [
        "neural_activity_prediction",
        "pose_estimation",
        "behavioral_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MouseLand/facemap",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "neuroscience",
        "pose-estimation",
        "neural-activity",
        "svd"
      ],
      "id": 383
    },
    {
      "name": "LightM-UNet",
      "one_line_profile": "Lightweight Mamba-assisted UNet for medical image segmentation",
      "detailed_description": "A PyTorch implementation of LightM-UNet, integrating Mamba (State Space Models) into a lightweight UNet architecture specifically designed for medical image segmentation tasks.",
      "domains": [
        "Medical Imaging",
        "Computer Vision"
      ],
      "subtask_category": [
        "image_segmentation",
        "medical_image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MrBlankness/LightM-UNet",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-imaging",
        "segmentation",
        "mamba",
        "unet"
      ],
      "id": 384
    },
    {
      "name": "Remote Sensing Mamba",
      "one_line_profile": "Mamba-based model for remote sensing image analysis",
      "detailed_description": "Official implementation of Remote Sensing Mamba, applying State Space Models to the analysis and processing of remote sensing imagery.",
      "domains": [
        "Remote Sensing",
        "Computer Vision"
      ],
      "subtask_category": [
        "image_analysis",
        "remote_sensing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NJU-LHRS/Official_Remote_Sensing_Mamba",
      "help_website": [],
      "license": null,
      "tags": [
        "remote-sensing",
        "mamba",
        "deep-learning"
      ],
      "id": 385
    },
    {
      "name": "HPC Container Maker",
      "one_line_profile": "Tool to generate HPC container specifications",
      "detailed_description": "HPC Container Maker (HPCCM) generates container specification files (Dockerfiles, Singularity definition files) optimized for High Performance Computing (HPC) environments, simplifying the deployment of scientific applications.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "containerization",
        "environment_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/hpc-container-maker",
      "help_website": [
        "https://github.com/NVIDIA/hpc-container-maker"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "containers",
        "docker",
        "singularity",
        "reproducibility"
      ],
      "id": 386
    },
    {
      "name": "Nix",
      "one_line_profile": "Purely functional package manager for reproducible builds",
      "detailed_description": "A powerful package manager for Linux and other Unix systems that makes package management reliable and reproducible. It is widely used in scientific computing to create reproducible research environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "environment_reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/NixOS/nix",
      "help_website": [
        "https://nixos.org/"
      ],
      "license": "LGPL-2.1",
      "tags": [
        "package-manager",
        "reproducibility",
        "build-system"
      ],
      "id": 387
    },
    {
      "name": "Nixtla",
      "one_line_profile": "Time series forecasting and anomaly detection library",
      "detailed_description": "A library for time series forecasting and anomaly detection, providing access to foundation models like TimeGPT. It supports various domains including scientific monitoring (IoT, energy).",
      "domains": [
        "Data/Analysis"
      ],
      "subtask_category": [
        "time_series_forecasting",
        "anomaly_detection"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Nixtla/nixtla",
      "help_website": [
        "https://docs.nixtla.io/"
      ],
      "license": null,
      "tags": [
        "time-series",
        "forecasting",
        "foundation-model"
      ],
      "id": 388
    },
    {
      "name": "envkernel",
      "one_line_profile": "Jupyter kernel manager for various environments",
      "detailed_description": "A tool to run Jupyter kernels in different environments such as Conda, Virtualenv, Docker, Singularity, and Lmod, facilitating interactive scientific computing across isolated environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_integration",
        "interactive_computing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NordicHPC/envkernel",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyter",
        "hpc",
        "singularity",
        "conda",
        "lmod"
      ],
      "id": 389
    },
    {
      "name": "pixi-pack",
      "one_line_profile": "Tool to pack and unpack pixi/conda environments",
      "detailed_description": "A utility to pack and unpack Conda environments created with Pixi, enabling reproducible environment distribution for scientific workflows.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_packaging",
        "reproducibility"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/Quantco/pixi-pack",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "pixi",
        "environment-management",
        "reproducibility"
      ],
      "id": 390
    },
    {
      "name": "pssa",
      "one_line_profile": "Singular Spectrum Analysis library for time series forecasting",
      "detailed_description": "A Python implementation of Singular Spectrum Analysis (SSA) for decomposing and forecasting time series data, commonly used in signal processing and econometrics.",
      "domains": [
        "Data",
        "Modeling"
      ],
      "subtask_category": [
        "time_series_analysis",
        "forecasting"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aj-cloete/pssa",
      "help_website": [],
      "license": null,
      "tags": [
        "ssa",
        "time-series",
        "forecasting"
      ],
      "id": 391
    },
    {
      "name": "mamba.py",
      "one_line_profile": "Efficient implementation of the Mamba state-space model architecture",
      "detailed_description": "A simple and efficient implementation of the Mamba architecture in pure PyTorch and MLX, enabling scientific modeling and sequence processing tasks.",
      "domains": [
        "Modeling",
        "AI"
      ],
      "subtask_category": [
        "model_architecture",
        "sequence_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/alxndrTL/mamba.py",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "deep-learning",
        "mamba",
        "ssm",
        "pytorch"
      ],
      "id": 392
    },
    {
      "name": "AuctionGym",
      "one_line_profile": "Simulation environment for auction algorithms and reinforcement learning",
      "detailed_description": "A simulation environment designed for the reproducible evaluation of bandit and reinforcement learning methods in the context of online advertising auctions.",
      "domains": [
        "Modeling",
        "Simulation"
      ],
      "subtask_category": [
        "simulation",
        "reinforcement_learning"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/amazon-science/auction-gym",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "simulation",
        "reinforcement-learning",
        "auctions"
      ],
      "id": 393
    },
    {
      "name": "conda-merge",
      "one_line_profile": "Utility to merge Conda environment files",
      "detailed_description": "A tool to merge multiple Conda environment specification files into a single file, facilitating complex scientific environment management.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/amitbeka/conda-merge",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "conda",
        "environment-management",
        "reproducibility"
      ],
      "id": 394
    },
    {
      "name": "nb_conda",
      "one_line_profile": "Conda environment management extension for Jupyter",
      "detailed_description": "An extension for Jupyter Notebooks that allows users to manage Conda environments and packages directly from the Jupyter interface.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "interactive_computing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/anaconda/nb_conda",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyter",
        "conda",
        "environment-management"
      ],
      "id": 395
    },
    {
      "name": "nb_conda_kernels",
      "one_line_profile": "Automatic Conda environment kernel detection for Jupyter",
      "detailed_description": "A package that enables Jupyter to automatically detect and use kernels from other Conda environments, streamlining scientific workflows across multiple environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "interactive_computing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/anaconda/nb_conda_kernels",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyter",
        "conda",
        "kernels"
      ],
      "id": 396
    },
    {
      "name": "Apptainer",
      "one_line_profile": "Container system for High Performance Computing (HPC)",
      "detailed_description": "The open-source container system (formerly Singularity) designed for HPC environments, enabling reproducible scientific computing with support for MPI and GPUs.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "containerization",
        "hpc_execution"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/apptainer/apptainer",
      "help_website": [
        "https://apptainer.org/docs/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "containers",
        "singularity",
        "reproducibility"
      ],
      "id": 397
    },
    {
      "name": "Singularity",
      "one_line_profile": "Container platform for scientific and HPC workloads (Legacy)",
      "detailed_description": "The original repository for Singularity (now Apptainer), a container platform optimized for scientific workloads, HPC, and reproducible research.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "containerization",
        "hpc_execution"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/apptainer/singularity",
      "help_website": [
        "https://sylabs.io/docs/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "containers",
        "legacy"
      ],
      "id": 398
    },
    {
      "name": "unidep",
      "one_line_profile": "Unified dependency management for Pip and Conda",
      "detailed_description": "A tool that manages Python project dependencies by maintaining a single source of truth for both pip and conda requirements, simplifying scientific environment setup.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/basnijholt/unidep",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "dependency-management",
        "conda",
        "pip",
        "reproducibility"
      ],
      "id": 399
    },
    {
      "name": "Binder",
      "one_line_profile": "Service for reproducible executable environments",
      "detailed_description": "The core software powering mybinder.org, allowing users to create reproducible, interactive computing environments from code repositories.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "reproducibility",
        "environment_provisioning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/binder-project/binder",
      "help_website": [
        "https://mybinder.readthedocs.io/"
      ],
      "license": null,
      "tags": [
        "reproducibility",
        "jupyter",
        "docker",
        "science-sharing"
      ],
      "id": 400
    },
    {
      "name": "bioconda-utils",
      "one_line_profile": "Utilities for building and managing Bioconda recipes",
      "detailed_description": "A set of utilities used to build, test, and manage recipes for the Bioconda channel, essential for the distribution of bioinformatics software.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "build_system"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bioconda/bioconda-utils",
      "help_website": [
        "https://bioconda.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "conda",
        "packaging"
      ],
      "id": 401
    },
    {
      "name": "Master of Pores",
      "one_line_profile": "Nextflow pipeline for direct RNA Nanopore read analysis",
      "detailed_description": "A Nextflow pipeline designed for the analysis of direct RNA sequencing data from Oxford Nanopore technologies, including preprocessing, mapping, and modification detection.",
      "domains": [
        "Bioinformatics",
        "D2"
      ],
      "subtask_category": [
        "sequence_analysis",
        "pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/biocorecrg/master_of_pores",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nanopore",
        "rna-seq",
        "nextflow",
        "bioinformatics"
      ],
      "id": 402
    },
    {
      "name": "Graph-Mamba",
      "one_line_profile": "Long-range graph sequence modelling with selective state spaces",
      "detailed_description": "A deep learning framework adapting Mamba (Selective State Spaces) for graph data, enabling efficient modeling of long-range dependencies in graph sequences, applicable to molecular and structural biology tasks.",
      "domains": [
        "D1",
        "D5"
      ],
      "subtask_category": [
        "graph_modeling",
        "sequence_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bowang-lab/Graph-Mamba",
      "help_website": [],
      "license": null,
      "tags": [
        "graph-neural-networks",
        "mamba",
        "deep-learning",
        "molecular-modeling"
      ],
      "id": 403
    },
    {
      "name": "U-Mamba",
      "one_line_profile": "Hybrid CNN-SSM architecture for biomedical image segmentation",
      "detailed_description": "A biomedical image segmentation tool that integrates State Space Models (SSM) with U-Net architectures to capture long-range dependencies in high-resolution biomedical images.",
      "domains": [
        "D1",
        "D5"
      ],
      "subtask_category": [
        "image_segmentation",
        "biomedical_imaging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bowang-lab/U-Mamba",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-imaging",
        "segmentation",
        "mamba",
        "u-net"
      ],
      "id": 404
    },
    {
      "name": "lmodule",
      "one_line_profile": "Python API for Lmod environment modules",
      "detailed_description": "A Python library that provides an interface to interact with the Lmod environment module system, facilitating the management of scientific software environments in HPC settings.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "hpc_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/buildtesters/lmodule",
      "help_website": [
        "https://lmodule.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "lmod",
        "hpc",
        "environment-modules",
        "python-api"
      ],
      "id": 405
    },
    {
      "name": "irlba",
      "one_line_profile": "Fast truncated singular value decomposition (SVD) library",
      "detailed_description": "An R package for implicitly restarted Lanczos bidiagonalization, enabling fast computation of partial SVD for large sparse matrices common in scientific data analysis.",
      "domains": [
        "D3"
      ],
      "subtask_category": [
        "dimensionality_reduction",
        "matrix_factorization"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/bwlewis/irlba",
      "help_website": [],
      "license": null,
      "tags": [
        "svd",
        "pca",
        "sparse-matrix",
        "linear-algebra"
      ],
      "id": 406
    },
    {
      "name": "Calkit",
      "one_line_profile": "Project management and reproducibility tool for research",
      "detailed_description": "A command-line tool designed to simplify version control, environment management, and pipeline execution specifically for reproducible research projects.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "reproducibility",
        "project_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/calkit/calkit",
      "help_website": [
        "https://calkit.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "reproducible-research",
        "git",
        "pipeline",
        "data-management"
      ],
      "id": 407
    },
    {
      "name": "cmcrameri",
      "one_line_profile": "Perceptually uniform colourmaps for geosciences",
      "detailed_description": "A Python library providing Fabio Crameri's perceptually uniform scientific colormaps, designed to accurately represent data in geosciences and other scientific fields without visual distortion.",
      "domains": [
        "D4"
      ],
      "subtask_category": [
        "scientific_visualization",
        "plotting"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/callumrollo/cmcrameri",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "visualization",
        "colormaps",
        "geoscience",
        "matplotlib"
      ],
      "id": 408
    },
    {
      "name": "jupyter-lmod",
      "one_line_profile": "Jupyter extension for Lmod environment modules",
      "detailed_description": "A Jupyter notebook extension that allows users to interact with Lmod environment modules directly from the Jupyter interface, bridging interactive data science with HPC environment management.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "interactive_computing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cmd-ntrf/jupyter-lmod",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "jupyter",
        "lmod",
        "hpc",
        "environment-modules"
      ],
      "id": 409
    },
    {
      "name": "Community Collections",
      "one_line_profile": "Research Computing Framework based on Singularity and Lmod",
      "detailed_description": "A framework for managing and deploying research software stacks using Singularity containers and Lmod modules, facilitating reproducible research computing environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "containerization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/community-collections/community-collections",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "singularity",
        "lmod",
        "hpc",
        "reproducibility"
      ],
      "id": 410
    },
    {
      "name": "conda-env",
      "one_line_profile": "Unified interface for managing Conda environments",
      "detailed_description": "A tool (now integrated into conda) for managing isolated package environments, allowing export and recreation of scientific computing environments via YAML configuration.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda-archive/conda-env",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "conda",
        "environment-management",
        "reproducibility"
      ],
      "id": 411
    },
    {
      "name": "Miniforge",
      "one_line_profile": "Minimal Conda installer with conda-forge pre-configured",
      "detailed_description": "A distribution of the Conda package manager configured to use the community-driven conda-forge channel, essential for setting up scientific environments on various architectures (including Apple Silicon).",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_provisioning"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/conda-forge/miniforge",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "conda",
        "mamba",
        "distribution",
        "scientific-computing"
      ],
      "id": 412
    },
    {
      "name": "conda-docker",
      "one_line_profile": "Tool to create Docker images from Conda environments",
      "detailed_description": "A library and command-line tool that generates minimal Docker images directly from Conda environments without requiring a Docker daemon, facilitating containerization of scientific workflows.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "containerization",
        "environment_export"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda-incubator/conda-docker",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "docker",
        "conda",
        "containerization",
        "reproducibility"
      ],
      "id": 413
    },
    {
      "name": "conda-env-builder",
      "one_line_profile": "Builder for multiple custom Conda environments",
      "detailed_description": "A tool to build and maintain multiple Conda environments from a single configuration source, streamlining the management of complex dependency sets for research projects.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "build_automation"
      ],
      "application_level": "solver",
      "primary_language": "Scala",
      "repo_url": "https://github.com/conda-incubator/conda-env-builder",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "conda",
        "environment-management",
        "automation"
      ],
      "id": 414
    },
    {
      "name": "conda-project",
      "one_line_profile": "Tool for encapsulating and reproducing Conda projects",
      "detailed_description": "A tool designed to lock down and reproduce entire projects by managing the Conda environment and project-specific commands, ensuring portability of scientific work.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "reproducibility",
        "project_encapsulation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda-incubator/conda-project",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "reproducibility",
        "conda",
        "project-management"
      ],
      "id": 415
    },
    {
      "name": "conda-store",
      "one_line_profile": "Data science environment management server",
      "detailed_description": "A server application that builds and serves Conda environments, providing a centralized way to manage and share reproducible data science environments across teams (e.g., via JupyterHub).",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_serving",
        "collaboration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda-incubator/conda-store",
      "help_website": [
        "https://conda-store.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "jupyterhub",
        "environment-management",
        "collaboration"
      ],
      "id": 416
    },
    {
      "name": "conda-tree",
      "one_line_profile": "Dependency tree viewer for Conda environments",
      "detailed_description": "A utility to inspect the dependency tree of Conda environments, helping users understand package relationships and debug version conflicts in scientific stacks.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "dependency_analysis",
        "environment_debugging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda-incubator/conda-tree",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "conda",
        "dependency-tree",
        "debugging"
      ],
      "id": 417
    },
    {
      "name": "condacolab",
      "one_line_profile": "Conda integration for Google Colab",
      "detailed_description": "A Python package that simplifies the installation and usage of Conda/Mamba on Google Colab, enabling the use of scientific packages not available in the default Colab runtime.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_integration",
        "cloud_computing"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/conda-incubator/condacolab",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "google-colab",
        "conda",
        "mamba",
        "data-science"
      ],
      "id": 418
    },
    {
      "name": "conda-execute",
      "one_line_profile": "Execute scripts in temporary Conda environments",
      "detailed_description": "A tool that allows scripts to define their own execution environment requirements in metadata, automatically creating a temporary Conda environment to run the script reproducibly.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "reproducibility",
        "script_execution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda-tools/conda-execute",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "reproducibility",
        "scripting"
      ],
      "id": 419
    },
    {
      "name": "Conda",
      "one_line_profile": "Package and environment manager for scientific computing",
      "detailed_description": "The de facto standard package and environment management system for data science and scientific computing, handling binary dependencies and isolated environments across languages (Python, R, etc.).",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "environment_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda/conda",
      "help_website": [
        "https://docs.conda.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "package-manager",
        "environment-manager",
        "data-science",
        "python"
      ],
      "id": 420
    },
    {
      "name": "conda-libmamba-solver",
      "one_line_profile": "Fast libmamba-based solver for the Conda package manager",
      "detailed_description": "A solver plug-in for Conda that utilizes the libmamba library to significantly speed up dependency resolution in scientific environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "dependency_resolution",
        "environment_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda/conda-libmamba-solver",
      "help_website": [
        "https://conda.github.io/conda-libmamba-solver/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "dependency-solver",
        "mamba",
        "package-management"
      ],
      "id": 421
    },
    {
      "name": "conda-lock",
      "one_line_profile": "Lightweight lockfile generator for Conda environments",
      "detailed_description": "A tool to generate fully reproducible lockfiles for Conda environments, ensuring consistent package versions across different platforms and installations.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "reproducibility",
        "environment_management"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda/conda-lock",
      "help_website": [
        "https://conda-incubator.github.io/conda-lock/"
      ],
      "license": "MIT",
      "tags": [
        "conda",
        "reproducibility",
        "lockfile",
        "environment"
      ],
      "id": 422
    },
    {
      "name": "conda-pack",
      "one_line_profile": "Tool for packaging and redistributing Conda environments",
      "detailed_description": "A command-line tool that archives Conda environments into portable formats (tarballs/zip) for deployment on systems without Conda installed, such as HPC nodes.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "deployment",
        "environment_portability"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda/conda-pack",
      "help_website": [
        "https://conda.github.io/conda-pack/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "hpc",
        "deployment",
        "portability"
      ],
      "id": 423
    },
    {
      "name": "constructor",
      "one_line_profile": "Installer creation tool for Conda packages",
      "detailed_description": "A tool for constructing cross-platform installers (like Anaconda or Miniforge) from Conda packages, facilitating the distribution of scientific software stacks.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "software_distribution",
        "installer_generation"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda/constructor",
      "help_website": [
        "https://github.com/conda/constructor"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "installer",
        "distribution",
        "packaging"
      ],
      "id": 424
    },
    {
      "name": "grayskull",
      "one_line_profile": "Automatic recipe generator for Conda packages",
      "detailed_description": "A tool that generates Conda recipes from PyPI packages, streamlining the process of packaging scientific software for the Conda ecosystem.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "packaging",
        "recipe_generation"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda/grayskull",
      "help_website": [
        "https://github.com/conda/grayskull"
      ],
      "license": "Apache-2.0",
      "tags": [
        "conda",
        "pypi",
        "packaging",
        "automation"
      ],
      "id": 425
    },
    {
      "name": "rattler",
      "one_line_profile": "Rust library for interacting with the Conda ecosystem",
      "detailed_description": "A high-performance Rust library that provides functionality to work with Conda packages, environments, and repodata, serving as a building block for next-gen scientific package managers.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "library"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/conda/rattler",
      "help_website": [
        "https://docs.rs/rattler/latest/rattler/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "rust",
        "conda",
        "package-management",
        "performance"
      ],
      "id": 426
    },
    {
      "name": "MambaIR",
      "one_line_profile": "Image restoration model based on State-Space Models",
      "detailed_description": "A deep learning framework and model implementation for low-level vision tasks (image restoration) utilizing the Mamba architecture.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "image_restoration",
        "scientific_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/csguoh/MambaIR",
      "help_website": [
        "https://github.com/csguoh/MambaIR"
      ],
      "license": "Apache-2.0",
      "tags": [
        "computer-vision",
        "image-restoration",
        "mamba",
        "deep-learning"
      ],
      "id": 427
    },
    {
      "name": "mrs_apptainer",
      "one_line_profile": "Apptainer environment wrappers for UAV research",
      "detailed_description": "A set of tools and wrappers to manage Apptainer (Singularity) containers specifically for the MRS UAV system research workflows.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "robotics_simulation",
        "environment_management"
      ],
      "application_level": "tool",
      "primary_language": "Shell",
      "repo_url": "https://github.com/ctu-mrs/mrs_apptainer",
      "help_website": [
        "https://github.com/ctu-mrs/mrs_apptainer"
      ],
      "license": "NOASSERTION",
      "tags": [
        "uav",
        "robotics",
        "apptainer",
        "singularity"
      ],
      "id": 428
    },
    {
      "name": "poetry2conda",
      "one_line_profile": "Converter from Poetry projects to Conda environments",
      "detailed_description": "A tool that converts Python `pyproject.toml` configuration files into Conda `environment.yaml` files, bridging general Python development with scientific computing environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_conversion",
        "interoperability"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/dojeda/poetry2conda",
      "help_website": [
        "https://github.com/dojeda/poetry2conda"
      ],
      "license": "MIT",
      "tags": [
        "poetry",
        "conda",
        "conversion",
        "environment"
      ],
      "id": 429
    },
    {
      "name": "EasyBuild",
      "one_line_profile": "Software build and installation framework for HPC",
      "detailed_description": "A software installation framework that automates the management of scientific software stacks on High Performance Computing (HPC) systems in an efficient and reproducible way.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "software_building",
        "hpc_management"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/easybuilders/easybuild",
      "help_website": [
        "https://easybuild.io/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "hpc",
        "build-automation",
        "scientific-software",
        "reproducibility"
      ],
      "id": 430
    },
    {
      "name": "easybuild-easyblocks",
      "one_line_profile": "Build logic collection for EasyBuild",
      "detailed_description": "A collection of Python scripts ('easyblocks') that implement the specific build procedures for various scientific software packages within the EasyBuild framework.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "build_logic",
        "software_installation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/easybuilders/easybuild-easyblocks",
      "help_website": [
        "https://docs.easybuild.io/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "hpc",
        "easybuild",
        "build-scripts"
      ],
      "id": 431
    },
    {
      "name": "easybuild-framework",
      "one_line_profile": "Core framework for EasyBuild",
      "detailed_description": "The core Python framework of EasyBuild that provides the functionality to parse build specifications and execute build procedures for scientific software.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "software_building",
        "framework"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/easybuilders/easybuild-framework",
      "help_website": [
        "https://easybuild.io/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "hpc",
        "python",
        "framework",
        "installation"
      ],
      "id": 432
    },
    {
      "name": "eb-singularity",
      "one_line_profile": "Integration tools for EasyBuild and Singularity",
      "detailed_description": "Tools and scripts to facilitate the integration of the EasyBuild software management system with Singularity containers for HPC environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "container_integration",
        "hpc_workflow"
      ],
      "application_level": "tool",
      "primary_language": "Roff",
      "repo_url": "https://github.com/easybuilders/eb-singularity",
      "help_website": [
        "https://easybuild.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "singularity",
        "easybuild",
        "hpc",
        "containers"
      ],
      "id": 433
    },
    {
      "name": "guix-genomics",
      "one_line_profile": "Guix package definitions for bioinformatics software",
      "detailed_description": "A channel providing GNU Guix package definitions specifically for bioinformatics software, enabling reproducible deployment of genomics tools.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "reproducibility"
      ],
      "application_level": "dataset",
      "primary_language": "Scheme",
      "repo_url": "https://github.com/ekg/guix-genomics",
      "help_website": [],
      "license": null,
      "tags": [
        "guix",
        "bioinformatics",
        "genomics",
        "reproducibility"
      ],
      "id": 434
    },
    {
      "name": "gym-wind-turbine",
      "one_line_profile": "Wind turbine simulation environment for OpenAI Gym",
      "detailed_description": "An OpenAI Gym environment that realistically reproduces the behavior of a wind turbine using CCBlade aeroelastic code, designed for reinforcement learning research in energy systems.",
      "domains": [
        "D2",
        "D4"
      ],
      "subtask_category": [
        "simulation",
        "reinforcement_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/emerrf/gym-wind-turbine",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "wind-energy",
        "simulation",
        "reinforcement-learning",
        "openai-gym"
      ],
      "id": 435
    },
    {
      "name": "Environment Modules",
      "one_line_profile": "Dynamic modification of a user's environment for HPC",
      "detailed_description": "A standard tool in High Performance Computing (HPC) for dynamically modifying a user's environment via modulefiles, managing paths and environment variables for scientific software.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management"
      ],
      "application_level": "workflow",
      "primary_language": "Tcl",
      "repo_url": "https://github.com/envmodules/modules",
      "help_website": [
        "http://modules.sourceforge.net"
      ],
      "license": "GPL-2.0",
      "tags": [
        "hpc",
        "environment-management",
        "modules"
      ],
      "id": 436
    },
    {
      "name": "svd3",
      "one_line_profile": "Fast singular value decomposition for 3x3 matrices",
      "detailed_description": "A library for fast singular value decomposition (SVD), diagonalization, and QR decomposition specifically optimized for 3x3 matrices, useful in physics simulations and graphics.",
      "domains": [
        "D1"
      ],
      "subtask_category": [
        "matrix_decomposition",
        "numerical_analysis"
      ],
      "application_level": "library",
      "primary_language": "Mathematica",
      "repo_url": "https://github.com/ericjang/svd3",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "svd",
        "linear-algebra",
        "mathematica"
      ],
      "id": 437
    },
    {
      "name": "py2spack",
      "one_line_profile": "Convert Python packages to Spack recipes",
      "detailed_description": "A utility tool to automatically convert standard Python packages into Spack package recipes, facilitating the deployment of Python software in HPC environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_conversion",
        "hpc_deployment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/eth-cscs/py2spack",
      "help_website": [],
      "license": null,
      "tags": [
        "spack",
        "python",
        "hpc",
        "packaging"
      ],
      "id": 438
    },
    {
      "name": "HumEnv",
      "one_line_profile": "SMPL humanoid environment for model comparison",
      "detailed_description": "A simulation environment for SMPL humanoids enabling systematic model comparison and reproducibility in human motion research.",
      "domains": [
        "D2",
        "D4"
      ],
      "subtask_category": [
        "simulation",
        "human_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/humenv",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "smpl",
        "simulation",
        "humanoid",
        "reproducibility"
      ],
      "id": 439
    },
    {
      "name": "helmod",
      "one_line_profile": "Harvard Extensions for Lmod deployment",
      "detailed_description": "A set of tools and Ruby scripts used to generate module files and manage Lmod deployments, developed by Harvard Research Computing.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_deployment",
        "hpc_admin"
      ],
      "application_level": "workflow",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/fasrc/helmod",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "lmod",
        "hpc",
        "modulefiles"
      ],
      "id": 440
    },
    {
      "name": "easy_update",
      "one_line_profile": "Update EasyBuild package configuration files",
      "detailed_description": "A utility script to automate the updating of EasyBuild package configuration files (easyconfigs), specifically for R and Python bundles.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_maintenance",
        "hpc_admin"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/fizwit/easy_update",
      "help_website": [],
      "license": null,
      "tags": [
        "easybuild",
        "hpc",
        "automation"
      ],
      "id": 441
    },
    {
      "name": "nixpack",
      "one_line_profile": "Integration of Nix and Spack package managers",
      "detailed_description": "A tool that combines the reproducibility of Nix with the scientific software ecosystem of Spack, allowing Spack environments to be driven by Nix.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "environment_integration"
      ],
      "application_level": "solver",
      "primary_language": "Nix",
      "repo_url": "https://github.com/flatironinstitute/nixpack",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nix",
        "spack",
        "hpc",
        "reproducibility"
      ],
      "id": 442
    },
    {
      "name": "copip",
      "one_line_profile": "Environment Development Overlays for Conda",
      "detailed_description": "A tool to manage development overlays for Conda environments, facilitating the mixing of pip-installed packages with conda environments for scientific workflows.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/fperez/copip",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "pip",
        "environment-management"
      ],
      "id": 443
    },
    {
      "name": "SegMamba",
      "one_line_profile": "3D Medical Image Segmentation using Mamba",
      "detailed_description": "A deep learning model and tool for 3D medical image segmentation that utilizes the Mamba architecture for long-range sequential modeling.",
      "domains": [
        "D4"
      ],
      "subtask_category": [
        "image_segmentation",
        "medical_imaging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ge-xing/SegMamba",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-imaging",
        "segmentation",
        "mamba",
        "deep-learning"
      ],
      "id": 444
    },
    {
      "name": "Popper",
      "one_line_profile": "Container-native task automation engine for reproducibility",
      "detailed_description": "A container-native task automation engine designed to implement scientific experimentation pipelines that are reproducible and portable.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "workflow_automation",
        "reproducibility"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/getpopper/popper",
      "help_website": [
        "https://popper.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "reproducibility",
        "workflow",
        "containers",
        "automation"
      ],
      "id": 445
    },
    {
      "name": "kliko",
      "one_line_profile": "Scientific Compute Container Specification and Library",
      "detailed_description": "A specification and support library for defining scientific compute containers, enabling standardized execution of scientific code in containerized environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "container_specification",
        "workflow_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gijzelaerr/kliko",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "containers",
        "specification",
        "scientific-computing"
      ],
      "id": 446
    },
    {
      "name": "HOOMD-blue",
      "one_line_profile": "Molecular dynamics and Monte Carlo simulation on GPUs",
      "detailed_description": "A general-purpose particle simulation toolkit optimized for GPUs, supporting molecular dynamics (MD) and Monte Carlo (MC) simulations for soft matter research.",
      "domains": [
        "D4"
      ],
      "subtask_category": [
        "molecular_dynamics",
        "monte_carlo_simulation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/glotzerlab/hoomd-blue",
      "help_website": [
        "https://hoomd-blue.readthedocs.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "molecular-dynamics",
        "gpu",
        "simulation",
        "soft-matter"
      ],
      "id": 447
    },
    {
      "name": "containerize-conda",
      "one_line_profile": "Turn conda environments into Singularity containers",
      "detailed_description": "A tool to automatically build Singularity/Apptainer containers from existing Conda environments, facilitating the transport of scientific environments to HPC systems.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "container_generation",
        "environment_portability"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/grst/containerize-conda",
      "help_website": [],
      "license": null,
      "tags": [
        "conda",
        "singularity",
        "hpc",
        "containers"
      ],
      "id": 448
    },
    {
      "name": "rstudio-server-conda",
      "one_line_profile": "Integration of RStudio Server with Conda environments via Docker",
      "detailed_description": "A specialized Docker image and wrapper that allows running RStudio Server within a specific Conda environment, facilitating reproducible data science workflows by managing R dependencies through Conda.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/grst/rstudio-server-conda",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rstudio",
        "conda",
        "docker",
        "reproducibility"
      ],
      "id": 449
    },
    {
      "name": "guix-science",
      "one_line_profile": "Scientific software channel for the GNU Guix package manager",
      "detailed_description": "A dedicated channel for the GNU Guix transactional package manager, providing a collection of free scientific software packages aimed at reproducible research and high-performance computing.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "reproducibility"
      ],
      "application_level": "service",
      "primary_language": "Scheme",
      "repo_url": "https://github.com/guix-science/guix-science",
      "help_website": [
        "https://guix-science.org/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "guix",
        "package-manager",
        "reproducible-research",
        "hpc"
      ],
      "id": 450
    },
    {
      "name": "HyperFlow",
      "one_line_profile": "Scientific workflow management system for distributed environments",
      "detailed_description": "A workflow engine designed for executing scientific workflows in distributed environments like clouds and grids, focusing on complex task dependencies and resource management.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "distributed_computing"
      ],
      "application_level": "workflow",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/hyperflow-wms/hyperflow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "workflow-engine",
        "distributed-computing",
        "cloud-computing"
      ],
      "id": 451
    },
    {
      "name": "GPU-Jupyter",
      "one_line_profile": "GPU-accelerated JupyterLab environment for deep learning",
      "detailed_description": "A specialized Docker environment providing a GPU-enabled JupyterLab instance pre-configured with major data science and deep learning libraries (TensorFlow, PyTorch) for reproducible experiments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "interactive_computing",
        "environment_provisioning"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/iot-salzburg/gpu-jupyter",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jupyter",
        "gpu",
        "docker",
        "deep-learning"
      ],
      "id": 452
    },
    {
      "name": "conda-minify",
      "one_line_profile": "Tool to minify Conda environment specifications",
      "detailed_description": "A utility library and CLI to create minified or relaxed versions of Conda environment specification files, facilitating easier cross-platform sharing and reproducibility of scientific environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "reproducibility"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jamespreed/conda-minify",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "conda",
        "reproducibility",
        "environment-management"
      ],
      "id": 453
    },
    {
      "name": "Berryconda",
      "one_line_profile": "Conda distribution for Raspberry Pi",
      "detailed_description": "A Conda-based Python distribution specifically built for the Raspberry Pi (ARMv7), enabling the deployment of scientific Python stacks on edge devices.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "edge_computing"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/jjhelmus/berryconda",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "raspberry-pi",
        "arm",
        "python-distribution"
      ],
      "id": 454
    },
    {
      "name": "AQME",
      "one_line_profile": "Automated Quantum Mechanical Environments for chemistry workflows",
      "detailed_description": "A suite of automated workflows for computational chemistry, including conformer generation, QM input creation, and post-processing, integrating tools like RDKit, CREST, and xTB.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "computational_chemistry",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/jvalegre/aqme",
      "help_website": [
        "https://aqme.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "cheminformatics",
        "quantum-chemistry",
        "automation",
        "rdkit"
      ],
      "id": 455
    },
    {
      "name": "apptainer-in-docker",
      "one_line_profile": "Utility to run Apptainer within Docker containers",
      "detailed_description": "A tool enabling the execution of Apptainer (formerly Singularity) containers inside Docker environments, facilitating CI/CD pipelines and cross-platform compatibility for scientific HPC workflows.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "containerization",
        "interoperability"
      ],
      "application_level": "solver",
      "primary_language": "Dockerfile",
      "repo_url": "https://github.com/kaczmarj/apptainer-in-docker",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "apptainer",
        "singularity",
        "docker",
        "hpc"
      ],
      "id": 456
    },
    {
      "name": "key4hep-spack",
      "one_line_profile": "Spack package recipes for the Key4hep software stack",
      "detailed_description": "The official Spack recipe repository for Key4hep, a turnkey software stack for High Energy Physics, enabling the consistent build and deployment of HEP software across different computing environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "high_energy_physics"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/key4hep/key4hep-spack",
      "help_website": [
        "https://key4hep.github.io/key4hep-doc/"
      ],
      "license": null,
      "tags": [
        "spack",
        "hep",
        "high-energy-physics",
        "package-manager"
      ],
      "id": 457
    },
    {
      "name": "pymssa",
      "one_line_profile": "Multivariate Singular Spectrum Analysis (MSSA) implementation",
      "detailed_description": "A Python library implementing Multivariate Singular Spectrum Analysis, a technique used for time series analysis, decomposition, and forecasting in scientific domains like geophysics and climate science.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "time_series_analysis",
        "statistical_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kieferk/pymssa",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mssa",
        "time-series",
        "statistics",
        "forecasting"
      ],
      "id": 458
    },
    {
      "name": "libigl-python-bindings",
      "one_line_profile": "Python bindings for libigl, a simple C++ geometry processing library",
      "detailed_description": "Provides Python access to libigl, a library for geometry processing tasks such as meshing, parametrization, and geometric analysis, widely used in computer graphics and physical simulation research.",
      "domains": [
        "D4",
        "D4-01"
      ],
      "subtask_category": [
        "geometry_processing",
        "meshing",
        "simulation"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/libigl/libigl-python-bindings",
      "help_website": [
        "https://libigl.github.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "geometry-processing",
        "meshing",
        "python-bindings"
      ],
      "id": 459
    },
    {
      "name": "Crocoddyl",
      "one_line_profile": "Optimal control library for robot control under contact sequence",
      "detailed_description": "An optimal control library for robot control based on Differential Dynamic Programming (DDP). It allows for efficient computation of optimal trajectories and control policies for complex dynamic systems.",
      "domains": [
        "D4",
        "D4-02"
      ],
      "subtask_category": [
        "optimal_control",
        "robotics",
        "dynamics_simulation"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/loco-3d/crocoddyl",
      "help_website": [
        "https://gepettoweb.laas.fr/doc/loco-3d/crocoddyl/master/doxygen-html/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "optimal-control",
        "robotics",
        "ddp"
      ],
      "id": 460
    },
    {
      "name": "nixml",
      "one_line_profile": "Tool to generate Nix expressions from YAML for reproducible environments",
      "detailed_description": "Simplifies the creation of reproducible development environments using Nix by allowing users to define dependencies in a YAML format, specifically targeting scientific reproducibility.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "reproducibility"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/luispedro/nixml",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nix",
        "reproducibility",
        "environment-management"
      ],
      "id": 461
    },
    {
      "name": "boa",
      "one_line_profile": "Fast conda package builder based on mamba",
      "detailed_description": "A package builder for the Conda ecosystem that utilizes Mamba for dependency resolution, significantly speeding up the creation of scientific software packages.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_building",
        "dependency_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mamba-org/boa",
      "help_website": [
        "https://github.com/mamba-org/boa"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "mamba",
        "packaging"
      ],
      "id": 462
    },
    {
      "name": "gator",
      "one_line_profile": "Conda environment management extension for Jupyter",
      "detailed_description": "A JupyterLab extension that provides a graphical interface for managing Conda environments and packages directly within the scientific notebook interface.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "interactive_computing"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/mamba-org/gator",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "jupyter",
        "conda",
        "environment-management"
      ],
      "id": 463
    },
    {
      "name": "mamba",
      "one_line_profile": "Fast cross-platform package manager compatible with Conda",
      "detailed_description": "A reimplementation of the Conda package manager in C++, offering significantly faster dependency resolution and package installation for scientific environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "environment_management"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/mamba-org/mamba",
      "help_website": [
        "https://mamba.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "package-manager",
        "conda",
        "hpc"
      ],
      "id": 464
    },
    {
      "name": "micromamba-docker",
      "one_line_profile": "Docker images for micromamba",
      "detailed_description": "Provides official Docker images for Micromamba, a tiny and fast Conda-compatible package manager, facilitating containerized scientific workflows.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "containerization",
        "environment_management"
      ],
      "application_level": "service",
      "primary_language": "Shell",
      "repo_url": "https://github.com/mamba-org/micromamba-docker",
      "help_website": [
        "https://mamba.readthedocs.io/en/latest/user_guide/micromamba.html"
      ],
      "license": "Apache-2.0",
      "tags": [
        "docker",
        "micromamba",
        "containers"
      ],
      "id": 465
    },
    {
      "name": "quetz",
      "one_line_profile": "Open-source server for Conda packages",
      "detailed_description": "A server implementation for hosting Conda channels and packages, enabling organizations to manage their own scientific software repositories.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_hosting",
        "repository_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/mamba-org/quetz",
      "help_website": [
        "https://quetz.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "conda-server",
        "package-repository",
        "infrastructure"
      ],
      "id": 466
    },
    {
      "name": "condax",
      "one_line_profile": "Install and run Conda applications in isolated environments",
      "detailed_description": "A utility to install and execute applications packaged with Conda in their own isolated environments, similar to pipx, streamlining the use of scientific CLI tools.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "application_management",
        "environment_isolation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mariusvniekerk/condax",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "conda",
        "isolation",
        "cli-tools"
      ],
      "id": 467
    },
    {
      "name": "conda-move",
      "one_line_profile": "Utility to move Conda environments to different directories",
      "detailed_description": "A tool that enables the relocation of Conda environments by handling the necessary path updates, useful for managing scientific environments on HPC or local systems.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "deployment"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/matthuska/conda-move",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "conda",
        "environment-relocation",
        "utility"
      ],
      "id": 468
    },
    {
      "name": "Syndeo",
      "one_line_profile": "Run Ray workloads on Slurm clusters using Apptainer",
      "detailed_description": "A tool developed by MIT Lincoln Laboratory to facilitate running massively parallel jobs using the Ray framework on SLURM-managed HPC clusters via secure Apptainer containers.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "distributed_computing",
        "hpc_integration",
        "workflow_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/mit-ll/Syndeo",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "ray",
        "slurm",
        "apptainer",
        "hpc"
      ],
      "id": 469
    },
    {
      "name": "Dockflow",
      "one_line_profile": "Tool to containerize Bioconductor workflows for reproducible bioinformatics",
      "detailed_description": "Dockflow provides a streamlined approach to containerize Bioconductor workflows, ensuring reproducibility and ease of deployment in bioinformatics research.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "reproducibility",
        "containerization"
      ],
      "application_level": "workflow",
      "primary_language": "Dockerfile",
      "repo_url": "https://github.com/nanxstats/dockflow",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bioconductor",
        "docker",
        "bioinformatics"
      ],
      "id": 470
    },
    {
      "name": "repo2apptainer",
      "one_line_profile": "Converts git repositories into Apptainer/Singularity images for HPC",
      "detailed_description": "A wrapper around repo2docker that produces Jupyter-enabled Apptainer/Singularity images, facilitating the deployment of reproducible research environments on High Performance Computing (HPC) systems.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "reproducibility",
        "environment_deployment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ncar-xdev/repo2apptainer",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "apptainer",
        "singularity",
        "reproducibility"
      ],
      "id": 471
    },
    {
      "name": "Neurocommand",
      "one_line_profile": "Data analysis environment manager for reproducible neuroimaging",
      "detailed_description": "A flexible and scalable data analysis environment designed for reproducible neuroimaging, managing containers and dependencies for neuroscience workflows.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "neuroimaging",
        "environment_management"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/neurodesk/neurocommand",
      "help_website": [
        "https://neurodesk.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "neuroscience",
        "neuroimaging",
        "reproducibility"
      ],
      "id": 472
    },
    {
      "name": "Nextstrain CLI",
      "one_line_profile": "CLI for managing Nextstrain pathogen analysis environments",
      "detailed_description": "The command-line interface for Nextstrain that provides a consistent way to run and visualize pathogen builds across different computing environments like Docker, Conda, and AWS Batch.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "pathogen_analysis",
        "environment_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nextstrain/cli",
      "help_website": [
        "https://docs.nextstrain.org/en/latest/guides/install/cli.html"
      ],
      "license": "MIT",
      "tags": [
        "epidemiology",
        "pathogen-genomics",
        "visualization"
      ],
      "id": 473
    },
    {
      "name": "conda-depgraph",
      "one_line_profile": "CLI to visualize Conda environment dependencies",
      "detailed_description": "A command-line utility to generate and plot the dependency graph of a Conda environment, aiding in the management and debugging of scientific software environments.",
      "domains": [
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "dependency_visualization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/omegacen/conda-depgraph",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "conda",
        "dependency-graph",
        "visualization"
      ],
      "id": 474
    },
    {
      "name": "Open-CE",
      "one_line_profile": "Build recipes for the Open Cognitive Environment AI stack",
      "detailed_description": "Provides the environment files and version definitions to build the Open-CE software stack, enabling the deployment of open-source AI and machine learning frameworks on various hardware architectures.",
      "domains": [
        "D2-03"
      ],
      "subtask_category": [
        "environment_building",
        "ai_infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/open-ce/open-ce",
      "help_website": [
        "https://open-ce.github.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "ai",
        "machine-learning",
        "conda"
      ],
      "id": 475
    },
    {
      "name": "OpenHPC",
      "one_line_profile": "Integration and packaging for the OpenHPC stack",
      "detailed_description": "The integration, packaging, and testing repository for OpenHPC, a community effort to provide a comprehensive, integrated collection of HPC-centric components.",
      "domains": [
        "D2-03"
      ],
      "subtask_category": [
        "hpc_deployment",
        "cluster_management"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/openhpc/ohpc",
      "help_website": [
        "https://openhpc.community/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "cluster",
        "supercomputing"
      ],
      "id": 476
    },
    {
      "name": "mk",
      "one_line_profile": "Environment modules manager for scientific computing libraries",
      "detailed_description": "A tool to manage environment modules for scientific computing libraries and packages, providing portable x86-64 Linux binaries, developed at MOX (Politecnico di Milano).",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/pcafrica/mk",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "environment-modules",
        "scientific-computing"
      ],
      "id": 477
    },
    {
      "name": "PLIP",
      "one_line_profile": "Protein-Ligand Interaction Profiler",
      "detailed_description": "A tool to analyze and visualize non-covalent protein-ligand interactions in PDB files, detecting hydrogen bonds, hydrophobic contacts, and other interactions.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "structure_analysis",
        "interaction_profiling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/pharmai/plip",
      "help_website": [
        "https://plip-tool.biotec.tu-dresden.de/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "bioinformatics",
        "protein-ligand",
        "molecular-docking"
      ],
      "id": 478
    },
    {
      "name": "logrx",
      "one_line_profile": "Logging tool for clinical data reproducibility",
      "detailed_description": "Tools to facilitate logging in a clinical environment to make code easily traceable and reproducible, supporting pharmaverse workflows.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "reproducibility",
        "clinical_data_management"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/pharmaverse/logrx",
      "help_website": [
        "https://pharmaverse.github.io/logrx/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "pharma",
        "clinical-trials",
        "reproducibility"
      ],
      "id": 479
    },
    {
      "name": "Archiconda3",
      "one_line_profile": "Anaconda distribution for ARM64 devices",
      "detailed_description": "A lightweight Anaconda environment specifically designed for ARM64 devices (like Raspberry Pi, Jetson), enabling scientific Python stacks on edge devices.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/piyoki/archiconda3",
      "help_website": [],
      "license": null,
      "tags": [
        "conda",
        "arm64",
        "scientific-python"
      ],
      "id": 480
    },
    {
      "name": "nix-no-root",
      "one_line_profile": "Rootless Nix/Guix environment manager for HPC",
      "detailed_description": "A utility to empower Nix and Guix usage without root privileges, facilitating reproducible environments in HPC and restricted systems.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/pjotrp/nix-no-root",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hpc",
        "nix",
        "reproducibility"
      ],
      "id": 481
    },
    {
      "name": "pixi",
      "one_line_profile": "Fast package manager for scientific ecosystems",
      "detailed_description": "A package manager built on the conda ecosystem that simplifies environment management and reproducibility for scientific projects.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "package_management"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/prefix-dev/pixi",
      "help_website": [
        "https://pixi.sh"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "package-manager",
        "reproducibility"
      ],
      "id": 482
    },
    {
      "name": "rattler-build",
      "one_line_profile": "Fast Conda package builder",
      "detailed_description": "A universal Conda package builder for Windows, macOS, and Linux, designed to be faster than conda-build, facilitating scientific software distribution.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "build_tool"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/prefix-dev/rattler-build",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "build-tool",
        "packaging"
      ],
      "id": 483
    },
    {
      "name": "alphafold_singularity",
      "one_line_profile": "Singularity container definition for AlphaFold",
      "detailed_description": "A Singularity recipe to build and deploy AlphaFold, facilitating the use of this complex protein structure prediction tool in HPC environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "structure_prediction",
        "deployment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/prehensilecode/alphafold_singularity",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "alphafold",
        "singularity",
        "protein-structure"
      ],
      "id": 484
    },
    {
      "name": "PRIMME",
      "one_line_profile": "High-performance eigensolver library",
      "detailed_description": "PReconditioned Iterative MultiMethod Eigensolver for solving symmetric/Hermitian eigenvalue problems and singular value problems in scientific computing.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "numerical_solver",
        "linear_algebra"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/primme/primme",
      "help_website": [
        "https://www.cs.wm.edu/~andreas/software/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "eigenvalues",
        "numerical-methods",
        "hpc"
      ],
      "id": 485
    },
    {
      "name": "PackIt",
      "one_line_profile": "Virtual environment for geometric planning simulation",
      "detailed_description": "A virtual environment and dataset generation tool for geometric planning tasks, used for training and evaluating packing algorithms.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "simulation",
        "geometric_planning"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/princeton-vl/PackIt",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "simulation",
        "robotics",
        "packing-problem"
      ],
      "id": 486
    },
    {
      "name": "PyAMG",
      "one_line_profile": "Algebraic Multigrid Solvers in Python",
      "detailed_description": "A library of Algebraic Multigrid (AMG) solvers for solving large sparse linear systems, commonly used in scientific simulations.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "numerical_solver",
        "linear_algebra"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pyamg/pyamg",
      "help_website": [
        "https://pyamg.org"
      ],
      "license": "MIT",
      "tags": [
        "multigrid",
        "sparse-matrices",
        "scientific-computing"
      ],
      "id": 487
    },
    {
      "name": "PyMTL3",
      "one_line_profile": "Hardware generation and simulation framework",
      "detailed_description": "An open-source Python-based framework for hardware generation, simulation, and verification, enabling multi-level modeling of hardware systems.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "simulation",
        "hardware_modeling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/pymtl/pymtl3",
      "help_website": [
        "https://pymtl3.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "eda",
        "hardware-simulation",
        "verilog"
      ],
      "id": 488
    },
    {
      "name": "qp2-singularity",
      "one_line_profile": "Singularity container for Quantum Package",
      "detailed_description": "Definition files to build Singularity containers for Quantum Package, a software for quantum chemistry calculations.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "quantum_chemistry",
        "deployment"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/q-posev/qp2-singularity",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "quantum-chemistry",
        "singularity",
        "hpc"
      ],
      "id": 489
    },
    {
      "name": "radioconda-installer",
      "one_line_profile": "Software radio distribution for Conda",
      "detailed_description": "A software distribution and installer for software-defined radio (SDR) tools within the Conda ecosystem, facilitating engineering and signal processing workflows.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "signal_processing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/radioconda/radioconda-installer",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "sdr",
        "conda",
        "radio-astronomy"
      ],
      "id": 490
    },
    {
      "name": "poetry-conda",
      "one_line_profile": "Poetry plugin for Conda environment integration",
      "detailed_description": "A Poetry plugin that allows creating virtual environments using Poetry without interfering with the active Conda environment, bridging Python dev and scientific stacks.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/renan-r-santos/poetry-conda",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "poetry",
        "conda",
        "python-env"
      ],
      "id": 491
    },
    {
      "name": "rix",
      "one_line_profile": "Reproducible R environments with Nix",
      "detailed_description": "A tool to create reproducible data science environments for R using Nix, ensuring consistent execution across different systems.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "reproducibility"
      ],
      "application_level": "solver",
      "primary_language": "R",
      "repo_url": "https://github.com/ropensci/rix",
      "help_website": [
        "https://docs.ropensci.org/rix/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "r",
        "nix",
        "reproducibility"
      ],
      "id": 492
    },
    {
      "name": "Spack Manager",
      "one_line_profile": "Deployment workflow manager for Spack environments in HPC",
      "detailed_description": "A project and machine deployment model using Spack, designed to manage complex Spack stacks and environments across different HPC facilities.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "deployment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/sandialabs/spack-manager",
      "help_website": [
        "https://github.com/sandialabs/spack-manager"
      ],
      "license": "NOASSERTION",
      "tags": [
        "spack",
        "hpc",
        "deployment",
        "environment-modules"
      ],
      "id": 493
    },
    {
      "name": "Wave CLI",
      "one_line_profile": "CLI for Wave container provisioning service in scientific workflows",
      "detailed_description": "Command line tool for the Wave container provisioning service, often used in conjunction with Nextflow to dynamically build and deploy containers for scientific pipelines.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "container_provisioning",
        "workflow_integration"
      ],
      "application_level": "service",
      "primary_language": "Java",
      "repo_url": "https://github.com/seqeralabs/wave-cli",
      "help_website": [
        "https://github.com/seqeralabs/wave-cli"
      ],
      "license": "Apache-2.0",
      "tags": [
        "containers",
        "nextflow",
        "provisioning",
        "bioinformatics"
      ],
      "id": 494
    },
    {
      "name": "docker2singularity",
      "one_line_profile": "Converter for Docker images to Singularity format",
      "detailed_description": "A tool packaged as a Docker image that converts Docker images into Singularity images, facilitating the use of containerized scientific applications in HPC environments.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "container_conversion",
        "interoperability"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/singularityhub/docker2singularity",
      "help_website": [
        "https://github.com/singularityhub/docker2singularity"
      ],
      "license": "MIT",
      "tags": [
        "docker",
        "singularity",
        "hpc",
        "conversion"
      ],
      "id": 495
    },
    {
      "name": "Singularity-HPC",
      "one_line_profile": "HPC container registry and module management tool",
      "detailed_description": "A tool to manage a local filesystem registry for containers, specifically intended for HPC environments using Lmod or Environment Modules to expose containers to users.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "container_registry"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/singularityhub/singularity-hpc",
      "help_website": [
        "https://singularity-hpc.readthedocs.io"
      ],
      "license": "MPL-2.0",
      "tags": [
        "hpc",
        "singularity",
        "lmod",
        "modules"
      ],
      "id": 496
    },
    {
      "name": "sregistry",
      "one_line_profile": "Singularity Image Registry Server",
      "detailed_description": "An open source registry server for the storage and management of Singularity images, enabling institutions to host their own scientific container collections.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "container_storage",
        "image_management"
      ],
      "application_level": "service",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/singularityhub/sregistry",
      "help_website": [
        "https://singularityhub.github.io/sregistry"
      ],
      "license": "MPL-2.0",
      "tags": [
        "singularity",
        "registry",
        "hpc",
        "containers"
      ],
      "id": 497
    },
    {
      "name": "LModeA-nano",
      "one_line_profile": "Chemical bond strength calculator for solids and molecules",
      "detailed_description": "A tool to calculate chemical bond strength in solids, surfaces, and molecules using local mode analysis, aiding in computational chemistry and materials science research.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "bond_strength_calculation",
        "chemical_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/smutao/LModeA-nano",
      "help_website": [
        "https://github.com/smutao/LModeA-nano"
      ],
      "license": null,
      "tags": [
        "chemistry",
        "materials-science",
        "bond-strength",
        "local-mode-analysis"
      ],
      "id": 498
    },
    {
      "name": "Spack",
      "one_line_profile": "Flexible package manager for HPC and scientific computing",
      "detailed_description": "A multi-platform package manager that supports multiple versions, configurations, platforms, and compilers, specifically designed to handle the complex dependency graphs of scientific software.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "package_management",
        "dependency_resolution"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/spack/spack",
      "help_website": [
        "https://spack.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "package-manager",
        "scientific-computing",
        "dependencies"
      ],
      "id": 499
    },
    {
      "name": "SSRS",
      "one_line_profile": "Semantic Segmentation for Remote Sensing",
      "detailed_description": "A deep learning tool specifically designed for semantic segmentation tasks in remote sensing imagery, enabling analysis of satellite and aerial data.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "image_segmentation",
        "remote_sensing_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sstary/SSRS",
      "help_website": [
        "https://github.com/sstary/SSRS"
      ],
      "license": "Apache-2.0",
      "tags": [
        "remote-sensing",
        "semantic-segmentation",
        "deep-learning",
        "satellite-imagery"
      ],
      "id": 500
    },
    {
      "name": "Pinocchio",
      "one_line_profile": "Rigid Body Dynamics algorithms library",
      "detailed_description": "A fast and flexible C++ library for rigid body dynamics algorithms and their analytical derivatives, widely used in robotics, biomechanics, and physics simulations.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "dynamics_simulation",
        "motion_analysis"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/stack-of-tasks/pinocchio",
      "help_website": [
        "https://stack-of-tasks.github.io/pinocchio"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "dynamics",
        "robotics",
        "biomechanics",
        "physics-simulation"
      ],
      "id": 501
    },
    {
      "name": "SingularityCE",
      "one_line_profile": "Container platform for HPC and scientific computing",
      "detailed_description": "The Community Edition of Singularity, an open source container platform designed to be simple, fast, and secure, specifically optimized for High Performance Computing (HPC) workloads.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "container_runtime",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/sylabs/singularity",
      "help_website": [
        "https://sylabs.io/singularity"
      ],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "containers",
        "reproducibility",
        "scientific-computing"
      ],
      "id": 502
    },
    {
      "name": "Konda",
      "one_line_profile": "Lightweight wrapper to install and manage Conda environments within Google Colab",
      "detailed_description": "Konda provides a simple interface to install Anaconda/Miniconda and manage Python environments directly within Google Colab notebooks. It bridges the gap between Colab's default environment and the custom dependency requirements often needed in scientific data analysis and AI4S workflows.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "dependency_resolution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tamnguyenvan/konda",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "conda",
        "google-colab",
        "python-environment",
        "reproducibility"
      ],
      "id": 503
    },
    {
      "name": "envd",
      "one_line_profile": "Reproducible development environment manager for AI/Data Science",
      "detailed_description": "envd is a command-line tool that simplifies the creation of containerized development environments for data science and AI. It abstracts Dockerfile complexity, supports Conda/pip natively, and integrates with Jupyter, ensuring reproducibility across local and cloud infrastructure.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_provisioning",
        "containerization"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/tensorchord/envd",
      "help_website": [
        "https://envd.tensorchord.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "development-environment",
        "docker",
        "data-science",
        "reproducibility",
        "python"
      ],
      "id": 504
    },
    {
      "name": "Banpei",
      "one_line_profile": "Anomaly detection library using Singular Spectrum Transformation (SST)",
      "detailed_description": "Banpei is a Python library for anomaly detection in time-series data based on Singular Spectrum Transformation (SST). It is used for monitoring and analyzing change points in continuous data streams, applicable in scientific signal processing and system monitoring.",
      "domains": [
        "D1"
      ],
      "subtask_category": [
        "anomaly_detection",
        "time_series_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tsurubee/banpei",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "anomaly-detection",
        "singular-spectrum-transformation",
        "time-series",
        "signal-processing"
      ],
      "id": 505
    },
    {
      "name": "Jupyenv",
      "one_line_profile": "Declarative and reproducible Jupyter environments powered by Nix",
      "detailed_description": "Jupyenv allows scientists to define Jupyter environments declaratively using Nix. It ensures that kernels, extensions, and system dependencies are bit-for-bit reproducible, addressing the 'works on my machine' problem in scientific computing.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "environment_management",
        "reproducibility"
      ],
      "application_level": "workflow",
      "primary_language": "Nix",
      "repo_url": "https://github.com/tweag/jupyenv",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nix",
        "jupyter",
        "reproducibility",
        "scientific-computing"
      ],
      "id": 506
    },
    {
      "name": "SCIF",
      "one_line_profile": "Scientific Filesystem standard and client for modular container discovery",
      "detailed_description": "SCIF (Scientific Filesystem) is a standard and Python client for organizing scientific software within containers. It allows for the installation of multiple applications in a single container with consistent entry points, environment discovery, and metadata management, facilitating complex scientific workflows.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "container_management",
        "metadata_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/vsoch/scif",
      "help_website": [
        "https://sci-f.github.io"
      ],
      "license": "MPL-2.0",
      "tags": [
        "containers",
        "reproducibility",
        "scientific-filesystem",
        "hpc"
      ],
      "id": 507
    },
    {
      "name": "Mamba-UNet",
      "one_line_profile": "Mamba-based U-Net architecture zoo for medical image segmentation",
      "detailed_description": "A deep learning library and model zoo that integrates the Mamba (State Space Model) architecture with U-Net for medical image analysis. It provides implementations of various Mamba-UNet hybrids to enhance long-range dependency modeling in medical image segmentation tasks.",
      "domains": [
        "D3",
        "D1"
      ],
      "subtask_category": [
        "medical_image_segmentation",
        "image_segmentation",
        "scientific_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ziyangwang007/Mamba-UNet",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-imaging",
        "deep-learning",
        "mamba",
        "u-net",
        "segmentation"
      ],
      "id": 508
    },
    {
      "name": "ALLBioTC2",
      "one_line_profile": "Benchmark pipeline for Structural Variation analyses in bioinformatics",
      "detailed_description": "A benchmarking pipeline designed for Structural Variation (SV) analyses, funded by ALLBio. It provides a workflow to evaluate different SV detection tools or parameters.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "structural_variation_analysis",
        "bioinformatics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ALLBio/allbiotc2",
      "help_website": [],
      "license": null,
      "tags": [
        "bioinformatics",
        "structural-variation",
        "benchmarking",
        "pipeline"
      ],
      "id": 509
    },
    {
      "name": "ContextCheck",
      "one_line_profile": "Testing framework for LLMs, RAGs, and Chatbots integration in CI pipelines",
      "detailed_description": "A framework designed for automated testing of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) systems, and chatbots. It is configurable via YAML and integrates into CI pipelines to ensure model performance and reliability.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "model_testing",
        "llm_evaluation",
        "ci_integration"
      ],
      "application_level": "harness",
      "primary_language": "Python",
      "repo_url": "https://github.com/Addepto/contextcheck",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "rag",
        "testing-framework",
        "ci-cd"
      ],
      "id": 510
    },
    {
      "name": "Optimum Transformers",
      "one_line_profile": "Accelerated NLP pipelines for fast inference on CPU and GPU",
      "detailed_description": "A library that provides accelerated NLP pipelines for fast inference, built with Transformers, Optimum, and ONNX Runtime. It focuses on optimizing the performance of transformer models for scientific and general AI applications.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "inference_optimization",
        "nlp_pipeline",
        "model_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AlekseyKorshuk/optimum-transformers",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "nlp",
        "transformers",
        "optimization",
        "onnx"
      ],
      "id": 511
    },
    {
      "name": "MMSearch",
      "one_line_profile": "Multimodal Search Engine Pipeline and Benchmark for LMMs",
      "detailed_description": "A comprehensive pipeline and benchmark designed for evaluating Large Multimodal Models (LMMs) in the context of multimodal search tasks. It serves as a tool for assessing model performance in information retrieval.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "multimodal_retrieval",
        "model_evaluation"
      ],
      "application_level": "harness",
      "primary_language": "Python",
      "repo_url": "https://github.com/CaraJ7/MMSearch",
      "help_website": [],
      "license": null,
      "tags": [
        "multimodal",
        "benchmark",
        "search-engine",
        "lmm"
      ],
      "id": 512
    },
    {
      "name": "Bird-SQL Pipeline",
      "one_line_profile": "Text-to-SQL pipeline for BIRD benchmark",
      "detailed_description": "A pipeline implementation for the BIRD benchmark, facilitating the conversion of natural language text to SQL queries. It is used for evaluating and developing models for database interaction tasks in research.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "text_to_sql",
        "benchmarking",
        "pipeline_implementation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ContextualAI/bird-sql",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "text-to-sql",
        "benchmark",
        "bird",
        "nlp"
      ],
      "id": 513
    },
    {
      "name": "Pavilion",
      "one_line_profile": "Unreal Engine-based alternative to Gazebo for robotics simulation",
      "detailed_description": "A robotics simulation environment built on Unreal Engine, designed as an alternative to Gazebo. It provides high-fidelity rendering and physics for testing and validating robotics algorithms.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "robotics_simulation",
        "environment_simulation",
        "testing_harness"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/CoreRC/Pavilion",
      "help_website": [],
      "license": null,
      "tags": [
        "robotics",
        "simulation",
        "unreal-engine",
        "gazebo-alternative"
      ],
      "id": 514
    },
    {
      "name": "Reads2Map",
      "one_line_profile": "WDL workflows to benchmark genetic markers using linkage map quality",
      "detailed_description": "A collection of WDL (Workflow Description Language) bioinformatics workflows designed to benchmark genetic markers derived from different pipelines. It uses linkage map quality as a diagnostic metric for evaluation.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "bioinformatics_benchmarking",
        "genetic_mapping",
        "workflow_validation"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/Cristianetaniguti/Reads2Map",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "bioinformatics",
        "benchmarking",
        "genetics"
      ],
      "id": 515
    },
    {
      "name": "KITE",
      "one_line_profile": "End-to-end benchmark for RAG pipelines evaluation",
      "detailed_description": "KITE (Knowledge-Intensive Task Evaluation) is a benchmarking tool designed to evaluate Retrieval-Augmented Generation (RAG) pipelines. It assesses the performance of RAG systems on knowledge-intensive tasks.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "benchmarking",
        "nlp_testing"
      ],
      "application_level": "harness",
      "primary_language": "Python",
      "repo_url": "https://github.com/D-Star-AI/KITE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "benchmark",
        "evaluation",
        "nlp"
      ],
      "id": 516
    },
    {
      "name": "wdl-ci",
      "one_line_profile": "CI/CD tools for validating and testing WDL-based bioinformatics workflows",
      "detailed_description": "A set of tools designed to validate and test Workflow Description Language (WDL) repositories. It is intended for use within Continuous Integration/Continuous Deployment (CI/CD) pipelines to ensure the integrity and correctness of scientific workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "workflow_validation",
        "ci_cd",
        "bioinformatics_pipeline"
      ],
      "application_level": "harness",
      "primary_language": "Python",
      "repo_url": "https://github.com/DNAstack/wdl-ci",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "wdl",
        "ci",
        "bioinformatics",
        "workflow-testing"
      ],
      "id": 517
    },
    {
      "name": "EMODnetBiocheck",
      "one_line_profile": "Quality control tool for checking IPT resources against OBIS guidelines",
      "detailed_description": "A tool developed by EMODnet to check if Integrated Publishing Toolkit (IPT) resources comply with the guidelines of the Ocean Biodiversity Information System (OBIS). It ensures data quality and standardization for marine biological data.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "data_quality_control",
        "marine_biology",
        "compliance_checking"
      ],
      "application_level": "solver",
      "primary_language": "R",
      "repo_url": "https://github.com/EMODnet/EMODnetBiocheck",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "obis",
        "marine-biology",
        "quality-control",
        "biodiversity"
      ],
      "id": 518
    },
    {
      "name": "ETH3D Dataset Pipeline",
      "one_line_profile": "Pipeline for creating multi-view benchmark datasets from laser scans",
      "detailed_description": "A C++ pipeline used to create high-quality multi-view benchmark datasets for 3D reconstruction, combining laser scans and images. It is a tool for generating ground truth data for computer vision research.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "dataset_generation",
        "3d_reconstruction",
        "benchmarking"
      ],
      "application_level": "pipeline",
      "primary_language": "C++",
      "repo_url": "https://github.com/ETH3D/dataset-pipeline",
      "help_website": [
        "https://www.eth3d.net/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "computer-vision",
        "3d-reconstruction",
        "dataset-generation",
        "benchmark"
      ],
      "id": 519
    },
    {
      "name": "precisionFDA",
      "one_line_profile": "Cloud-based platform for benchmarking NGS analysis pipelines",
      "detailed_description": "A platform developed by the FDA to provide an environment for testing, piloting, and benchmarking new approaches to validating next-generation sequencing (NGS) analysis pipelines. It facilitates community collaboration and standardization in genomics.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "ngs_benchmarking",
        "bioinformatics_validation",
        "genomics_platform"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/FDA/precisionFDA",
      "help_website": [
        "https://precision.fda.gov/"
      ],
      "license": "CC0-1.0",
      "tags": [
        "ngs",
        "fda",
        "benchmarking",
        "bioinformatics"
      ],
      "id": 520
    },
    {
      "name": "FloTorch",
      "one_line_profile": "Optimization tool for Generative AI workloads and RAG pipelines",
      "detailed_description": "An open-source tool designed to optimize Generative AI workloads, specifically automating RAG proof-of-concept development. It includes features for hyperparameter tuning, vector database optimization, and LLM integration to accelerate AI research and deployment.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "ai_optimization",
        "rag_automation",
        "hyperparameter_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/FissionAI/FloTorch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "generative-ai",
        "rag",
        "optimization",
        "mlops"
      ],
      "id": 521
    },
    {
      "name": "LAGraph",
      "one_line_profile": "Library and test harness for GraphBLAS based graph algorithms",
      "detailed_description": "A library and test harness for collecting and benchmarking algorithms that use the GraphBLAS standard, facilitating the development and testing of high-performance graph algorithms used in scientific computing.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "graph_algorithms",
        "benchmarking",
        "algorithm_testing"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/GraphBLAS/LAGraph",
      "help_website": [
        "https://lagraph.readthedocs.org",
        "https://graphblas.org/LAGraph/"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "graphblas",
        "graph-algorithms",
        "hpc",
        "benchmarking"
      ],
      "id": 522
    },
    {
      "name": "SVsim",
      "one_line_profile": "Synthetic Structural Variant generator for benchmarking pipelines",
      "detailed_description": "A tool designed to generate synthetic Structural Variant (SV) calls to serve as ground truth benchmarks for testing and evaluating the performance of SV calling pipelines in genomics.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "synthetic_data_generation",
        "benchmarking",
        "variant_calling_validation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GregoryFaust/SVsim",
      "help_website": [],
      "license": null,
      "tags": [
        "genomics",
        "structural-variants",
        "simulation",
        "benchmarking"
      ],
      "id": 523
    },
    {
      "name": "SQuADDS",
      "one_line_profile": "Design database and simulation workflow for superconducting quantum hardware",
      "detailed_description": "A validated design database and simulation workflow software specifically for superconducting quantum hardware, enabling researchers to generate and simulate quantum device designs.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "simulation",
        "hardware_design",
        "quantum_physics"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/LFL-Lab/SQuADDS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "quantum-computing",
        "simulation",
        "superconducting-circuits",
        "workflow"
      ],
      "id": 524
    },
    {
      "name": "LW-BenchHub",
      "one_line_profile": "Unified benchmark hub for embodied AI and robotics simulation",
      "detailed_description": "A benchmark hub built on Isaac Lab-Arena for embodied AI, providing consistent interfaces, realistic environments, and multi-robot support for evaluating robot policies in scientific simulations.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "robotics_simulation",
        "benchmarking",
        "embodied_ai"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/LightwheelAI/LW-BenchHub",
      "help_website": [],
      "license": null,
      "tags": [
        "robotics",
        "isaac-sim",
        "benchmarking",
        "reinforcement-learning"
      ],
      "id": 525
    },
    {
      "name": "B4PPI",
      "one_line_profile": "Benchmarking pipeline for Protein-Protein Interaction prediction",
      "detailed_description": "A benchmarking pipeline designed to evaluate methods for the prediction of Protein-Protein Interactions (PPI), facilitating comparative analysis of computational biology tools.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "protein_interaction_prediction",
        "bioinformatics"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Llannelongue/B4PPI",
      "help_website": [],
      "license": null,
      "tags": [
        "ppi",
        "benchmarking",
        "proteomics",
        "computational-biology"
      ],
      "id": 526
    },
    {
      "name": "PRBench",
      "one_line_profile": "CUDA implementation of the PageRank Pipeline Benchmark",
      "detailed_description": "A high-performance CUDA implementation of the PageRank pipeline benchmark, used for evaluating graph analytics performance in scientific computing and HPC contexts.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "graph_analytics",
        "benchmarking",
        "hpc"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/NVIDIA/PRBench",
      "help_website": [],
      "license": null,
      "tags": [
        "cuda",
        "pagerank",
        "graph-algorithms",
        "benchmarking"
      ],
      "id": 527
    },
    {
      "name": "DBS-Gym",
      "one_line_profile": "RL Environment and Benchmark for Deep Brain Stimulation",
      "detailed_description": "A reinforcement learning environment and benchmarking pipeline for comparing adaptive Deep Brain Stimulation (DBS) algorithms, facilitating neurophysiological research and medical AI development.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "neuroscience_simulation",
        "reinforcement_learning",
        "benchmarking"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/NevVerVer/DBS-Gym",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "neuroscience",
        "reinforcement-learning",
        "deep-brain-stimulation",
        "simulation"
      ],
      "id": 528
    },
    {
      "name": "seurigiotto-benchmark-framework",
      "one_line_profile": "Benchmarking framework for Spatial Transcriptomics analysis",
      "detailed_description": "A framework optimizing pipelines for Spatial Transcriptomics (ST) data analysis using Seurat and Giotto, designed for reproducible benchmarking and generating biological insights.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "spatial_transcriptomics",
        "benchmarking",
        "bioinformatics"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/Nuiter/seurigiotto-benchmark-framework",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "spatial-transcriptomics",
        "seurat",
        "giotto",
        "benchmarking"
      ],
      "id": 529
    },
    {
      "name": "Modelling-Urban-Heat-Islands-from-Satellite-Imagery",
      "one_line_profile": "Synthetic modeling of Urban Heat Islands using satellite-like data",
      "detailed_description": "A tool for synthetic modeling of Urban Heat Islands (UHI) that generates spectral bands, vegetation/urban indices, and land surface temperature (LST) for testing machine learning models and validating geospatial workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "synthetic_data_generation",
        "remote_sensing",
        "environmental_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Okes2024/Modelling-Urban-Heat-Islands-from-Satellite-Imagery",
      "help_website": [],
      "license": null,
      "tags": [
        "remote-sensing",
        "urban-heat-island",
        "synthetic-data",
        "earth-science"
      ],
      "id": 530
    },
    {
      "name": "pecheck",
      "one_line_profile": "Integrity checker for paired-end FASTQ data",
      "detailed_description": "A tool to check the integrity of paired-end FASTQ data, ensuring data quality for downstream bioinformatics analysis.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "quality_control",
        "data_integrity",
        "bioinformatics"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/OpenGene/pecheck",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fastq",
        "quality-control",
        "ngs",
        "bioinformatics"
      ],
      "id": 531
    },
    {
      "name": "Project-Eucalyptus",
      "one_line_profile": "Pipelines for satellite-based methane detection and benchmarking",
      "detailed_description": "Open-source pipelines for satellite-based methane detection, including trained segmentation models, a synthetic plume generator, and benchmarking tools for Sentinel-2, Landsat, and EMIT data.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "remote_sensing",
        "methane_detection",
        "benchmarking",
        "environmental_science"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Orbio-Earth/Project-Eucalyptus",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "remote-sensing",
        "methane",
        "satellite-imagery",
        "benchmarking"
      ],
      "id": 532
    },
    {
      "name": "CATD_snakemake",
      "one_line_profile": "Snakemake pipeline for benchmarking cell-type deconvolution methods",
      "detailed_description": "A Snakemake pipeline designed to benchmark cell-type deconvolution methods and deconvolve real bulk RNA-seq data using scRNA-seq datasets as references.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "deconvolution",
        "transcriptomics"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/Papatheodorou-Group/CATD_snakemake",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "snakemake",
        "deconvolution",
        "rna-seq",
        "benchmarking"
      ],
      "id": 533
    },
    {
      "name": "MONAI Deploy App SDK",
      "one_line_profile": "Framework to develop and verify AI-driven healthcare imaging applications",
      "detailed_description": "A framework and set of tools designed to design, develop, and verify AI-driven applications in the healthcare imaging domain, facilitating the deployment of medical AI models.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "medical_imaging",
        "model_verification",
        "deployment",
        "healthcare_ai"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Project-MONAI/monai-deploy-app-sdk",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-imaging",
        "monai",
        "healthcare",
        "verification"
      ],
      "id": 534
    },
    {
      "name": "ProteoBench",
      "one_line_profile": "Community-curated benchmarking platform for proteomics pipelines",
      "detailed_description": "An open and collaborative platform for community-curated benchmarks of proteomics data analysis pipelines, enabling continuous and controlled comparison of different analysis workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "proteomics",
        "workflow_comparison"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Proteobench/ProteoBench",
      "help_website": [
        "https://proteobench.cubimed.rub.de/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "proteomics",
        "benchmarking",
        "bioinformatics",
        "community-platform"
      ],
      "id": 535
    },
    {
      "name": "CITE-seq_optimization",
      "one_line_profile": "Benchmarking and optimization scripts for CITE-seq antibody titration pipelines",
      "detailed_description": "A set of scripts and workflows designed to optimize and benchmark TotalSeqC antibody titration pipelines for CITE-seq experiments, aiding in the quality control and parameter tuning of single-cell multi-omics data processing.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "optimization",
        "pipeline_validation"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/Terkild/CITE-seq_optimization",
      "help_website": [],
      "license": null,
      "tags": [
        "cite-seq",
        "single-cell",
        "antibody-titration",
        "bioinformatics"
      ],
      "id": 536
    },
    {
      "name": "nextflow-test-pipelines",
      "one_line_profile": "Bioinformatics pipeline test suite for platform monitoring",
      "detailed_description": "A collection of Nextflow and WDL bioinformatics pipelines used as a test harness to validate the functionality and performance of pipeline monitoring platforms, ensuring reproducibility and stability of scientific workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "pipeline_testing",
        "workflow_validation"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/Tracer-Cloud/nextflow-test-pipelines",
      "help_website": [],
      "license": null,
      "tags": [
        "nextflow",
        "wdl",
        "bioinformatics",
        "testing"
      ],
      "id": 537
    },
    {
      "name": "gptoss20b-redteam-harness",
      "one_line_profile": "Safety evaluation harness for GPT-OSS-20B model",
      "detailed_description": "A testing harness designed to probe and reproduce safety failures in the GPT-OSS-20B large language model, serving as a tool for AI safety research and model evaluation.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "safety_testing",
        "red_teaming"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/VietHann/gptoss20b-redteam-harness",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "ai-safety",
        "evaluation",
        "red-teaming"
      ],
      "id": 538
    },
    {
      "name": "BenchPOTS",
      "one_line_profile": "Benchmarking toolbox for partially-observed time series analysis",
      "detailed_description": "A Python toolbox designed to benchmark machine learning algorithms on partially-observed time series (POTS) data, supporting pipelines for 172 public datasets, facilitating standardized evaluation in time-series research.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "time_series_analysis",
        "algorithm_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/WenjieDu/BenchPOTS",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "time-series",
        "benchmarking",
        "machine-learning",
        "missing-data"
      ],
      "id": 539
    },
    {
      "name": "acwf-verification-scripts",
      "one_line_profile": "Verification scripts for AiiDA common workflows in materials science",
      "detailed_description": "A set of scripts for running and analyzing data from the AiiDA Common Workflows (ACWF) verification project, ensuring the reliability and consistency of computational materials science simulations.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "workflow_verification",
        "data_analysis",
        "materials_science"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/aiidateam/acwf-verification-scripts",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "aiida",
        "materials-science",
        "verification",
        "workflow"
      ],
      "id": 540
    },
    {
      "name": "aiida-sssp-workflow",
      "one_line_profile": "Verification workflows for Standard Solid State Pseudopotentials",
      "detailed_description": "AiiDA workflows designed for the verification of Standard Solid State Pseudopotentials (SSSP), providing automated testing and validation for materials science calculations.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "pseudopotential_verification",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/aiidateam/aiida-sssp-workflow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "aiida",
        "sssp",
        "pseudopotentials",
        "verification"
      ],
      "id": 541
    },
    {
      "name": "RefChecker",
      "one_line_profile": "Pipeline for detecting hallucinations in Large Language Models",
      "detailed_description": "An automatic checking pipeline and benchmark dataset designed to detect fine-grained hallucinations generated by Large Language Models (LLMs), facilitating rigorous evaluation of AI model reliability.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/amazon-science/RefChecker",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "hallucination",
        "evaluation",
        "benchmark"
      ],
      "id": 542
    },
    {
      "name": "bcbio-nextgen",
      "one_line_profile": "Validated, scalable, community developed variant calling and RNA-seq analysis pipeline",
      "detailed_description": "A python toolkit providing best-practice pipelines for automated high-throughput sequencing analysis, including variant calling, RNA-seq, and small RNA analysis. It handles data processing, quality control, and integrates various bioinformatics tools into a cohesive workflow.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "variant_calling",
        "rna_seq_analysis",
        "pipeline_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bcbio/bcbio-nextgen",
      "help_website": [
        "https://bcbio-nextgen.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "genomics",
        "variant-calling",
        "rna-seq",
        "pipeline"
      ],
      "id": 543
    },
    {
      "name": "bcbio_validation_workflows",
      "one_line_profile": "Automated validation workflows for the bcbio-nextgen pipeline",
      "detailed_description": "A collection of automated workflows designed to validate variant calling and other analyses performed by bcbio-nextgen. It uses the Common Workflow Language (CWL) to ensure reproducibility and correctness of the pipeline's outputs against standard benchmarks.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "pipeline_validation",
        "benchmarking",
        "quality_assurance"
      ],
      "application_level": "workflow",
      "primary_language": "Common Workflow Language",
      "repo_url": "https://github.com/bcbio/bcbio_validation_workflows",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "validation",
        "benchmarking",
        "cwl",
        "bioinformatics",
        "variant-calling"
      ],
      "id": 544
    },
    {
      "name": "WES-Benchmarking-Pipeline",
      "one_line_profile": "Benchmarking pipeline for Whole Exome Sequencing aligners and variant callers",
      "detailed_description": "A shell-based pipeline designed to benchmark the performance of various aligners and variant callers specifically for Whole Exome Sequencing (WES) data. It facilitates the evaluation of bioinformatics tools for accuracy and efficiency.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "variant_calling",
        "alignment_evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/bharani-lab/WES-Benchmarking-Pipeline_Manoj",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmarking",
        "wes",
        "variant-calling",
        "bioinformatics",
        "pipeline"
      ],
      "id": 545
    },
    {
      "name": "biobakery_workflows",
      "one_line_profile": "Standardized workflows for microbial community analysis",
      "detailed_description": "A collection of workflows and tasks for executing common microbial community analyses (microbiome) using standardized, validated tools and parameters. It simplifies the process of running complex bioBakery toolchains.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "microbiome_analysis",
        "metagenomics",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/biobakery/biobakery_workflows",
      "help_website": [
        "https://github.com/biobakery/biobakery_workflows/wiki"
      ],
      "license": "NOASSERTION",
      "tags": [
        "microbiome",
        "metagenomics",
        "workflow",
        "biobakery"
      ],
      "id": 546
    },
    {
      "name": "mapping-benchmarking",
      "one_line_profile": "Snakemake pipeline for benchmarking read mappers",
      "detailed_description": "A Snakemake-based pipeline designed to benchmark the performance of various DNA read mappers. It automates the execution and evaluation of mapping tools, facilitating comparative analysis in bioinformatics.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "read_mapping",
        "performance_evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bioinf-benchmarking/mapping-benchmarking",
      "help_website": [],
      "license": null,
      "tags": [
        "snakemake",
        "benchmarking",
        "read-mapping",
        "bioinformatics"
      ],
      "id": 547
    },
    {
      "name": "docker-benchmarks",
      "one_line_profile": "Benchmarks of genomic pipelines running in Docker containers",
      "detailed_description": "A repository containing benchmarks for evaluating the performance of genomic pipelines when executed within Docker containers. It provides a framework for assessing the overhead and efficiency of containerized bioinformatics workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "container_performance",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/cbcrg/docker-benchmarks",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmarking",
        "docker",
        "genomics",
        "bioinformatics"
      ],
      "id": 548
    },
    {
      "name": "ReFramed",
      "one_line_profile": "Metabolic modeling package",
      "detailed_description": "A Python package for metabolic modeling, supporting constraint-based analysis of metabolic networks. It allows for the simulation and analysis of cellular metabolism.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "metabolic_modeling",
        "systems_biology",
        "constraint_based_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cdanielmachado/reframed",
      "help_website": [
        "https://reframed.readthedocs.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "metabolic-modeling",
        "systems-biology",
        "python"
      ],
      "id": 549
    },
    {
      "name": "miniwdl-plugins",
      "one_line_profile": "Plugins for the miniwdl workflow runner",
      "detailed_description": "A collection of plugins to extend the functionality of the miniwdl workflow runner, enhancing its capabilities for scientific workflow execution and management.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_extension",
        "pipeline_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chanzuckerberg/miniwdl-plugins",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wdl",
        "plugins",
        "workflow",
        "bioinformatics"
      ],
      "id": 550
    },
    {
      "name": "snakescale",
      "one_line_profile": "Non-strict wrappers for Snakemake",
      "detailed_description": "A library providing non-strict wrappers for Snakemake, a popular workflow management system in bioinformatics. It aims to simplify the creation and management of data pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_utility",
        "pipeline_development"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/clintval/snakescale",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "workflow",
        "bioinformatics",
        "wrapper"
      ],
      "id": 551
    },
    {
      "name": "benchmark_scrnaseq_cnv_callers",
      "one_line_profile": "Benchmark pipeline for scRNA-seq CNV callers",
      "detailed_description": "An analysis pipeline designed to benchmark Copy Number Variant (CNV) callers specifically for single-cell RNA sequencing (scRNA-seq) data. It enables the comparative evaluation of different CNV detection tools.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "cnv_calling",
        "scrna_seq_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "R",
      "repo_url": "https://github.com/colomemaria/benchmark_scrnaseq_cnv_callers",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmarking",
        "scrna-seq",
        "cnv",
        "bioinformatics"
      ],
      "id": 552
    },
    {
      "name": "ck-scc18",
      "one_line_profile": "Collective Knowledge workflow for SeisSol application",
      "detailed_description": "A Collective Knowledge (CK) workflow designed to automate the installation, execution, and validation of the SeisSol application (seismology simulation) across different platforms. It facilitates reproducibility in high-performance computing for science.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_automation",
        "reproducibility",
        "seismology_simulation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ctuning/ck-scc18",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "collective-knowledge",
        "seissol",
        "hpc",
        "reproducibility",
        "seismology"
      ],
      "id": 553
    },
    {
      "name": "poreTally",
      "one_line_profile": "Benchmark MinION assembler pipelines",
      "detailed_description": "A tool to benchmark various assembler pipelines for MinION sequencing data. It automates the execution and reporting of assembly performance, aiding in the selection of optimal tools for nanopore sequencing analysis.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "genome_assembly",
        "nanopore_sequencing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/cvdelannoy/poreTally",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmarking",
        "minion",
        "assembly",
        "bioinformatics"
      ],
      "id": 554
    },
    {
      "name": "snakemake-wrappers",
      "one_line_profile": "Snakemake wrappers for bioinformatics tools",
      "detailed_description": "A collection of wrappers for Snakemake, facilitating the integration of various bioinformatics tools into Snakemake workflows. It simplifies the process of building reproducible data analysis pipelines.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "workflow_integration",
        "bioinformatics_utility"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dohlee/snakemake-wrappers",
      "help_website": [],
      "license": null,
      "tags": [
        "snakemake",
        "bioinformatics",
        "wrappers",
        "workflow"
      ],
      "id": 555
    },
    {
      "name": "BayesicFitting",
      "one_line_profile": "Bayesian fitting package for data analysis",
      "detailed_description": "A Python package for performing Bayesian fitting on data. It provides tools for statistical modeling and inference, suitable for scientific data analysis tasks requiring Bayesian approaches.",
      "domains": [
        "D2",
        "D2-03"
      ],
      "subtask_category": [
        "statistical_inference",
        "curve_fitting",
        "bayesian_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dokester/BayesicFitting",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bayesian",
        "fitting",
        "statistics",
        "data-analysis"
      ],
      "id": 556
    },
    {
      "name": "Evidently",
      "one_line_profile": "ML and LLM observability and evaluation framework",
      "detailed_description": "An open-source ML and LLM observability framework to evaluate, test, and monitor AI-powered systems or data pipelines. It provides metrics for data drift, model performance, and data quality, suitable for scientific ML workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "data_validation",
        "drift_detection"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/evidentlyai/evidently",
      "help_website": [
        "https://docs.evidentlyai.com"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "evaluation",
        "monitoring",
        "data-quality"
      ],
      "id": 557
    },
    {
      "name": "NitroML",
      "one_line_profile": "Model-quality benchmarking framework for ML and AutoML pipelines",
      "detailed_description": "A modular, portable, and scalable model-quality benchmarking framework for Machine Learning and Automated Machine Learning (AutoML) pipelines, facilitating reproducible evaluation of ML models.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "automl",
        "model_evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/google/nitroml",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmarking",
        "ml-pipelines",
        "automl",
        "reproducibility"
      ],
      "id": 558
    },
    {
      "name": "scArchon",
      "one_line_profile": "Benchmarking pipeline for single-cell perturbation prediction tools",
      "detailed_description": "A benchmarking pipeline designed to evaluate single-cell perturbation prediction tools, facilitating comparative analysis in computational biology.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "single_cell",
        "perturbation_prediction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/hdsu-bioquant/scArchon",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "single-cell",
        "benchmarking",
        "bioinformatics",
        "perturbation"
      ],
      "id": 559
    },
    {
      "name": "immune_deconvolution_benchmark",
      "one_line_profile": "Reproducible pipeline for evaluating cell-type quantification methods",
      "detailed_description": "A reproducible pipeline for the comprehensive evaluation of cell-type quantification methods for immuno-oncology, supporting the benchmarking of immune deconvolution algorithms.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "immuno_oncology",
        "deconvolution"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/icbi-lab/immune_deconvolution_benchmark",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "bioinformatics",
        "benchmarking",
        "immunology",
        "reproducibility"
      ],
      "id": 560
    },
    {
      "name": "HPC Challenge Benchmark",
      "one_line_profile": "Benchmark suite for High Performance Computing systems",
      "detailed_description": "The HPC Challenge Benchmark is a suite of tests that examine the performance of HPC architectures using kernels with more challenging memory access patterns than standard benchmarks.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_evaluation",
        "hpc"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/icl-utk-edu/hpcc",
      "help_website": [
        "http://icl.cs.utk.edu/hpcc/"
      ],
      "license": null,
      "tags": [
        "hpc",
        "benchmark",
        "performance",
        "supercomputing"
      ],
      "id": 561
    },
    {
      "name": "gwas-assoc",
      "one_line_profile": "GWAS Association Testing Pipeline",
      "detailed_description": "The IKMB GWAS Association Testing Pipeline, designed to streamline genome-wide association studies.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "gwas",
        "association_testing",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ikmb/gwas-assoc",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gwas",
        "genomics",
        "pipeline",
        "bioinformatics"
      ],
      "id": 562
    },
    {
      "name": "cellmap-segmentation-challenge",
      "one_line_profile": "Toolkit for 3D cell segmentation model training and evaluation",
      "detailed_description": "A repository containing scripts and workflows to facilitate participation in CellMap's segmentation challenge, including data downloading, training setups for 2D/3D models, and evaluation pipelines for biological image segmentation.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "image_segmentation",
        "model_evaluation",
        "bioimage_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/janelia-cellmap/cellmap-segmentation-challenge",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "segmentation",
        "microscopy",
        "benchmark"
      ],
      "id": 563
    },
    {
      "name": "Archer-GIS-AI-Assistant",
      "one_line_profile": "AI assistant for automating GIS workflows in ArcGIS Pro",
      "detailed_description": "An AI-powered tool that transforms natural language commands into automated GIS workflows within ArcGIS Pro, streamlining spatial analysis and reducing manual effort in geospatial research.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "spatial_analysis",
        "workflow_automation",
        "gis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/korporalK/Archer-GIS-AI-Assitant",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gis",
        "llm-agent",
        "arcgis"
      ],
      "id": 564
    },
    {
      "name": "BenchmarkDatasetCreator",
      "one_line_profile": "Pipeline for creating standardized bioacoustic datasets",
      "detailed_description": "A standardized pipeline for creating, storing, sharing, and using expert-labeled bioacoustic datasets to train and test AI models for biological sound analysis.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "dataset_creation",
        "bioacoustics",
        "data_standardization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/leabouffaut/BenchmarkDatasetCreator",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "bioacoustics",
        "dataset",
        "benchmark"
      ],
      "id": 565
    },
    {
      "name": "Simscape-Electrical-Power-Plant-Model-Validation",
      "one_line_profile": "Workflow for power plant model validation using PMU data",
      "detailed_description": "A workflow and set of tools for validating Simscape Electrical power plant models against phasor measurement unit (PMU) data, supporting online performance monitoring and model verification.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "model_validation",
        "power_system_simulation",
        "performance_monitoring"
      ],
      "application_level": "workflow",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/mathworks/Simscape-Electrical-Power-Plant-Model-Validation",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "simscape",
        "power-systems",
        "model-validation"
      ],
      "id": 566
    },
    {
      "name": "nextflow_for_nextstrain",
      "one_line_profile": "Nextflow pipeline for Nextstrain viral evolution analysis",
      "detailed_description": "A Nextflow-based pipeline for parallelizing Nextstrain builds and parameter testing, facilitating efficient viral evolution analysis and phylogenetics workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "workflow_management",
        "viral_evolution",
        "phylogenetics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/matt-sd-watson/nextflow_for_nextstrain",
      "help_website": [],
      "license": null,
      "tags": [
        "nextflow",
        "nextstrain",
        "bioinformatics"
      ],
      "id": 567
    },
    {
      "name": "RBFE-Benchmark",
      "one_line_profile": "Workflows for benchmarking alchemical binding free energy calculations",
      "detailed_description": "A collection of modular and interoperable workflows and datasets for benchmarking alchemical relative binding free energy (RBFE) calculation methodologies in computational chemistry.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "binding_free_energy",
        "benchmarking",
        "molecular_dynamics"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/michellab/RBFE-Benchmark",
      "help_website": [],
      "license": null,
      "tags": [
        "free-energy",
        "computational-chemistry",
        "benchmark"
      ],
      "id": 568
    },
    {
      "name": "WeatherReal-Benchmark",
      "one_line_profile": "Benchmark for weather forecast verification",
      "detailed_description": "Evaluation pipelines and components for the WeatherReal benchmark dataset, designed to support the verification and benchmarking of weather forecasting models.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "weather_forecasting",
        "benchmark",
        "model_verification"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/WeatherReal-Benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "weather",
        "benchmark",
        "meteorology"
      ],
      "id": 569
    },
    {
      "name": "nf-schema",
      "one_line_profile": "Schema validation library for Nextflow pipelines",
      "detailed_description": "A plugin and library for validating input parameters and sample sheets in Nextflow scientific pipelines against a defined JSON schema, ensuring data integrity before workflow execution.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "data_validation",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "Groovy",
      "repo_url": "https://github.com/nextflow-io/nf-schema",
      "help_website": [
        "https://nextflow-io.github.io/nf-schema/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nextflow",
        "schema-validation",
        "workflow",
        "bioinformatics"
      ],
      "id": 570
    },
    {
      "name": "nf-core/deepmodeloptim",
      "one_line_profile": "Pipeline for stochastic testing and optimization of learning systems",
      "detailed_description": "A Nextflow pipeline designed for the stochastic testing and input manipulation of unbiased learning systems, facilitating model evaluation and optimization in scientific machine learning contexts.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "optimization"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/deepmodeloptim",
      "help_website": [
        "https://nf-co.re/deepmodeloptim"
      ],
      "license": "MIT",
      "tags": [
        "machine-learning",
        "optimization",
        "testing",
        "nextflow"
      ],
      "id": 571
    },
    {
      "name": "nf-core/drugresponseeval",
      "one_line_profile": "Pipeline for evaluating drug response prediction models",
      "detailed_description": "A bioinformatics pipeline for testing and benchmarking drug response prediction models using statistically and biologically sound methods.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "drug_response_prediction"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/drugresponseeval",
      "help_website": [
        "https://nf-co.re/drugresponseeval"
      ],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "drug-discovery",
        "benchmarking",
        "nextflow"
      ],
      "id": 572
    },
    {
      "name": "nf-core/nft-utils",
      "one_line_profile": "Utility functions for testing Nextflow pipelines",
      "detailed_description": "A library of utility functions designed to be used with nf-test, facilitating the creation of robust tests for Nextflow pipelines and modules.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "testing",
        "validation"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/nf-core/nft-utils",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nextflow",
        "testing",
        "nf-test",
        "utils"
      ],
      "id": 573
    },
    {
      "name": "Geospatial Analysis Integrity Tool (GAIT)",
      "one_line_profile": "Geospatial data integrity and validation tool",
      "detailed_description": "A tool that validates geospatial data against defined data models (MGCP, GIFD, TDS, VMap), checking geometry, feature codes, attributes, and metadata integrity.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "data_validation",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/ngageoint/Geospatial-Analysis-Integrity-Tool",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gis",
        "geospatial",
        "data-integrity",
        "validation"
      ],
      "id": 574
    },
    {
      "name": "NMDP Consensus Pipeline",
      "one_line_profile": "Consensus assembly and allele interpretation pipeline",
      "detailed_description": "A bioinformatics pipeline for consensus assembly and allele interpretation, developed by the National Marrow Donor Program bioinformatics group.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "sequence_assembly",
        "allele_interpretation"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/nmdp-bioinformatics/pipeline",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "bioinformatics",
        "assembly",
        "genomics",
        "hla"
      ],
      "id": 575
    },
    {
      "name": "nft-bam",
      "one_line_profile": "nf-test plugin for BAM/SAM/CRAM file assertions",
      "detailed_description": "A plugin for the nf-test framework that enables assertions on the contents of SAM, BAM, and CRAM files, facilitating automated testing of bioinformatics pipelines involving alignment data.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "testing",
        "data_validation"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/nvnieuwk/nft-bam",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "testing",
        "nf-test",
        "bam"
      ],
      "id": 576
    },
    {
      "name": "Atlas Checks",
      "one_line_profile": "OpenStreetMap data integrity checks framework",
      "detailed_description": "A framework for performing data integrity checks on OpenStreetMap data using the Atlas library, used for validating geospatial data quality.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "data_validation",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/osmlab/atlas-checks",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "geospatial",
        "osm",
        "data-quality",
        "validation"
      ],
      "id": 577
    },
    {
      "name": "pipeComp",
      "one_line_profile": "Benchmark framework for bioinformatics pipelines",
      "detailed_description": "An R framework for benchmarking bioinformatics pipelines, with a specific focus on single-cell RNA-seq data analysis workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "pipeline_evaluation"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/plger/pipeComp",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bioinformatics",
        "benchmarking",
        "scrnaseq",
        "r"
      ],
      "id": 578
    },
    {
      "name": "Skore",
      "one_line_profile": "ML model evaluation and reporting library",
      "detailed_description": "A Python library that accelerates machine learning model development by providing automated evaluation reports, methodological guidance, and cross-validation analysis.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "reporting"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/probabl-ai/skore",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "machine-learning",
        "evaluation",
        "data-science",
        "visualization"
      ],
      "id": 579
    },
    {
      "name": "ReFrame",
      "one_line_profile": "HPC regression testing and benchmarking framework",
      "detailed_description": "A framework for writing and running portable regression tests and benchmarks for High Performance Computing (HPC) systems, ensuring the reliability of scientific computing infrastructure.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "hpc_testing",
        "benchmarking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/reframe-hpc/reframe",
      "help_website": [
        "https://reframe-hpc.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "testing",
        "benchmarking",
        "supercomputing"
      ],
      "id": 580
    },
    {
      "name": "GRETA",
      "one_line_profile": "Benchmarking pipeline for Gene Regulatory Network (GRN) inference methods",
      "detailed_description": "A pipeline designed to benchmark Gene Regulatory Network (GRN) inference methods. It facilitates the evaluation of different algorithms for inferring regulatory interactions from gene expression data.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "network_inference"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/saezlab/greta",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "gene-regulatory-networks",
        "benchmarking",
        "bioinformatics"
      ],
      "id": 581
    },
    {
      "name": "tonkaz",
      "one_line_profile": "CLI tool to verify reproducibility of scientific workflows via GA4GH WES",
      "detailed_description": "A command-line tool designed to verify the reproducibility of scientific workflows (such as CWL, WDL, and Nextflow) by executing them through a GA4GH Workflow Execution Service (WES) interface and comparing outputs.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "reproducibility_verification",
        "workflow_testing"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/sapporo-wes/tonkaz",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reproducibility",
        "ga4gh",
        "workflow-execution-service",
        "wes"
      ],
      "id": 582
    },
    {
      "name": "BayesianSafetyValidation.jl",
      "one_line_profile": "Bayesian optimization library for safety validation of critical systems",
      "detailed_description": "A Julia library for estimating the probability of failure in safety-critical systems using Bayesian optimization. It is used for validation and verification tasks in engineering and control systems.",
      "domains": [
        "D2-04",
        "D4"
      ],
      "subtask_category": [
        "safety_validation",
        "bayesian_optimization",
        "risk_estimation"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/sisl/BayesianSafetyValidation.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bayesian-optimization",
        "safety-critical-systems",
        "validation"
      ],
      "id": 583
    },
    {
      "name": "tool-NFTest",
      "one_line_profile": "CLI automation tool for testing Nextflow pipelines",
      "detailed_description": "A command-line interface developed by UCLA Health CDS to automate the testing and validation of Nextflow-based scientific workflows, ensuring pipeline reliability and reproducibility.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "pipeline_testing",
        "workflow_validation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/uclahs-cds/tool-NFTest",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "nextflow",
        "testing",
        "ci",
        "workflow-automation"
      ],
      "id": 584
    },
    {
      "name": "WfCommons",
      "one_line_profile": "Framework for enabling scientific workflow research and benchmarking",
      "detailed_description": "A framework designed to facilitate research and development in scientific workflows by providing tools to generate, analyze, and simulate workflow execution instances for benchmarking Workflow Management Systems (WMS).",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "workflow_benchmarking",
        "simulation",
        "performance_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wfcommons/WfCommons",
      "help_website": [
        "https://wfcommons.org"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "scientific-workflows",
        "benchmarking",
        "simulation",
        "reproducibility"
      ],
      "id": 585
    },
    {
      "name": "ZnTrack",
      "one_line_profile": "DVC-based framework for creating and benchmarking scientific pipelines",
      "detailed_description": "A Python interface for DVC (Data Version Control) that facilitates the creation, visualization, execution, and benchmarking of scientific data pipelines, enhancing reproducibility in ML and data science workflows.",
      "domains": [
        "D2",
        "D2-04"
      ],
      "subtask_category": [
        "pipeline_management",
        "benchmarking",
        "reproducibility"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zincware/ZnTrack",
      "help_website": [
        "https://zntrack.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dvc",
        "pipeline",
        "benchmarking",
        "machine-learning"
      ],
      "id": 586
    },
    {
      "name": "DFFRAM",
      "one_line_profile": "Memory compiler for standard cell libraries",
      "detailed_description": "A compiler that generates memory macros using standard cells (flip-flops and latches), serving as a synthesis tool in digital integrated circuit design workflows.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "synthesis",
        "circuit_design"
      ],
      "application_level": "solver",
      "primary_language": "Verilog",
      "repo_url": "https://github.com/AUCOHL/DFFRAM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "eda",
        "memory-compiler",
        "synthesis"
      ],
      "id": 587
    },
    {
      "name": "iskyLIMS",
      "one_line_profile": "LIMS for NGS sample and analysis management",
      "detailed_description": "An open-source Laboratory Information Management System designed for managing Next Generation Sequencing samples, wet-lab workflows, and bioinformatics analysis services.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "lab_management",
        "sample_tracking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/BU-ISCIII/iskylims",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "lims",
        "ngs",
        "bioinformatics"
      ],
      "id": 588
    },
    {
      "name": "BioWardrobe-Airflow",
      "one_line_profile": "Airflow-based backend for BioWardrobe epigenomics analysis",
      "detailed_description": "A reimplementation of the BioWardrobe experimental data analysis platform's backend using Apache Airflow to orchestrate bioinformatics workflows for epigenomics data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "epigenomics_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "TSQL",
      "repo_url": "https://github.com/Barski-lab/biowardrobe-airflow-analysis",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "airflow",
        "bioinformatics",
        "epigenomics"
      ],
      "id": 589
    },
    {
      "name": "CWL HTS Pipelines",
      "one_line_profile": "CWL workflows for High-Throughput Sequencing data",
      "detailed_description": "A collection of Common Workflow Language (CWL) pipelines and wrappers for processing RNA-Seq, ChIP-Seq, and Germline Variant calling data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "sequence_analysis",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "Common Workflow Language",
      "repo_url": "https://github.com/BiodataAnalysisGroup/CWL_HTS_pipelines",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cwl",
        "ngs",
        "bioinformatics"
      ],
      "id": 590
    },
    {
      "name": "BlenderRL",
      "one_line_profile": "Deep Reinforcement Learning interface for Blender",
      "detailed_description": "A tool that connects Blender's internal controls to external AI agents, enabling the use of Blender as a simulation environment for reinforcement learning research.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "simulation",
        "reinforcement_learning"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/BlenderAI/BlenderRL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "blender",
        "reinforcement-learning",
        "simulation"
      ],
      "id": 591
    },
    {
      "name": "CaPTk",
      "one_line_profile": "Cancer Imaging Phenomics Toolkit",
      "detailed_description": "A software platform for medical image analysis, featuring tools for segmentation, feature extraction, and predictive modeling of cancer imaging data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "image_analysis",
        "phenomics"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/CBICA/CaPTk",
      "help_website": [
        "https://cbica.github.io/CaPTk"
      ],
      "license": "NOASSERTION",
      "tags": [
        "medical-imaging",
        "cancer-research",
        "radiomics"
      ],
      "id": 592
    },
    {
      "name": "RobustFlow",
      "one_line_profile": "Framework for robust agentic workflow generation",
      "detailed_description": "A research tool designed to generate robust workflows using AI agents, addressing the challenges of reliability in automated agentic processes.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DEFENSE-SEU/RobustFlow",
      "help_website": [],
      "license": null,
      "tags": [
        "agentic-workflow",
        "ai-agents",
        "workflow-generation"
      ],
      "id": 593
    },
    {
      "name": "TOPMed GWAS WDL",
      "one_line_profile": "WDL workflows for GWAS analysis",
      "detailed_description": "A collection of WDL workflows implementing the University of Washington TOPMed DCC Best Practices for Genome-Wide Association Studies (GWAS).",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "gwas",
        "genetic_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/DataBiosphere/analysis_pipeline_WDL",
      "help_website": [],
      "license": null,
      "tags": [
        "wdl",
        "gwas",
        "genomics"
      ],
      "id": 594
    },
    {
      "name": "Strwythura",
      "one_line_profile": "Knowledge graph construction from unstructured data",
      "detailed_description": "A library for constructing knowledge graphs from unstructured data sources, implementing GraphRAG and ontology pipelines for domain-specific AI applications.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "graph_construction"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/DerwenAI/strwythura",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "graphrag",
        "unstructured-data"
      ],
      "id": 595
    },
    {
      "name": "VCF Annotation Pipeline",
      "one_line_profile": "Snakemake workflow for VCF annotation",
      "detailed_description": "A Snakemake-based workflow to filter and annotate Variant Call Format (VCF) data using tools like GATK4, SnpSift, and VEP.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "variant_annotation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ESR-NZ/vcf_annotation_pipeline",
      "help_website": [],
      "license": null,
      "tags": [
        "snakemake",
        "vcf",
        "bioinformatics"
      ],
      "id": 596
    },
    {
      "name": "TPOT",
      "one_line_profile": "Automated Machine Learning using Genetic Programming",
      "detailed_description": "A Python Automated Machine Learning (AutoML) tool that optimizes machine learning pipelines using genetic programming to discover the best model for a given dataset.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "automl",
        "pipeline_optimization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/EpistasisLab/tpot",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "automl",
        "genetic-programming",
        "data-science"
      ],
      "id": 597
    },
    {
      "name": "TPOT2",
      "one_line_profile": "Next-generation TPOT AutoML tool",
      "detailed_description": "The successor to TPOT, providing automated machine learning pipeline optimization with improved performance and features.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "automl",
        "pipeline_optimization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/EpistasisLab/tpot2",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "automl",
        "genetic-programming",
        "data-science"
      ],
      "id": 598
    },
    {
      "name": "AFlow",
      "one_line_profile": "Automated Agentic Workflow Generation Framework",
      "detailed_description": "A framework for automating the generation of agentic workflows, optimizing the construction of AI agent interactions for complex tasks.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/FoundationAgents/AFlow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agentic-workflow",
        "ai-agents",
        "workflow-automation"
      ],
      "id": 599
    },
    {
      "name": "HuntsmanCancerInstitute/Workflows",
      "one_line_profile": "Snakemake workflows for genomic analysis best practices",
      "detailed_description": "A collection of Snakemake workflows designed for best-practice genomic analysis, maintained by the Huntsman Cancer Institute. It provides reproducible pipelines for processing sequencing data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "genomic_analysis",
        "workflow_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/HuntsmanCancerInstitute/Workflows",
      "help_website": [],
      "license": null,
      "tags": [
        "snakemake",
        "genomics",
        "bioinformatics",
        "pipeline"
      ],
      "id": 600
    },
    {
      "name": "BRAD",
      "one_line_profile": "LLM-powered agent for bioinformatics tasks",
      "detailed_description": "A Language Model powered agent specifically designed for bioinformatics. It assists researchers by automating tasks, retrieving information, and potentially executing bioinformatics workflows through natural language interaction.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "bioinformatics_agent",
        "workflow_automation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Jpickard1/BRAD",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-agent",
        "bioinformatics",
        "automation"
      ],
      "id": 601
    },
    {
      "name": "InferOpt.jl",
      "one_line_profile": "Combinatorial optimization layers for machine learning pipelines",
      "detailed_description": "A Julia library that enables the integration of combinatorial optimization problems as differentiable layers within machine learning pipelines. This is crucial for 'decision-focused learning' in scientific modeling and operations research.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "optimization",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaDecisionFocusedLearning/InferOpt.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "optimization",
        "machine-learning",
        "combinatorial-optimization"
      ],
      "id": 602
    },
    {
      "name": "claude-scientific-skills",
      "one_line_profile": "Scientific toolset and skills for Claude LLM",
      "detailed_description": "A comprehensive set of tools and prompts designed to equip the Claude LLM with scientific capabilities, enabling it to perform tasks such as data analysis, mathematical reasoning, and scientific literature processing.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "scientific_reasoning",
        "data_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/K-Dense-AI/claude-scientific-skills",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "claude",
        "scientific-tools",
        "agent-skills"
      ],
      "id": 603
    },
    {
      "name": "DNAscan",
      "one_line_profile": "Fast and efficient bioinformatics pipeline for DNA NGS analysis",
      "detailed_description": "A bioinformatics pipeline optimized for speed and efficiency in analyzing DNA Next Generation Sequencing (NGS) data. It handles the entire workflow from raw data to variant calling with minimal computational resource usage.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "ngs_analysis",
        "variant_calling"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/KHP-Informatics/DNAscan",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "ngs",
        "pipeline",
        "dna-analysis"
      ],
      "id": 604
    },
    {
      "name": "RefTrace",
      "one_line_profile": "Linter for Nextflow pipelines to ensure code quality and best practices",
      "detailed_description": "RefTrace is a static analysis tool designed specifically for Nextflow pipelines. It helps developers identify potential issues, enforce coding standards, and maintain the quality of scientific workflows written in Nextflow.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_linting",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/RefTrace/RefTrace",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "nextflow",
        "linting",
        "workflow-management"
      ],
      "id": 605
    },
    {
      "name": "doped",
      "one_line_profile": "Python toolkit for managing and analyzing solid-state defect calculations",
      "detailed_description": "doped is a Python package for the generation, pre-processing, and post-processing of defect supercell calculations in materials science. It streamlines the workflow for defect simulation, interfacing with codes like VASP.",
      "domains": [
        "D2",
        "M1"
      ],
      "subtask_category": [
        "simulation_setup",
        "defect_analysis",
        "structure_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SMTG-Bham/doped",
      "help_website": [
        "https://doped.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "materials-science",
        "defects",
        "dft",
        "vasp"
      ],
      "id": 606
    },
    {
      "name": "The AI Scientist",
      "one_line_profile": "Fully automated open-ended scientific discovery agent",
      "detailed_description": "The AI Scientist is a framework for automated scientific discovery. It uses LLMs to generate research ideas, write code, execute experiments, visualize results, and draft scientific papers, demonstrating an end-to-end AI-driven research workflow.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "hypothesis_generation",
        "experiment_automation",
        "paper_writing"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/SakanaAI/AI-Scientist",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "automated-science",
        "llm-agent",
        "research-automation"
      ],
      "id": 607
    },
    {
      "name": "linter-rules-for-nextflow",
      "one_line_profile": "Collection of linting rules for Nextflow DSL scripts",
      "detailed_description": "This repository provides a set of linter rules for Nextflow DSL, helping developers ensure their scientific workflows adhere to best practices and syntax correctness.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_linting",
        "code_quality"
      ],
      "application_level": "library",
      "primary_language": "Groovy",
      "repo_url": "https://github.com/awslabs/linter-rules-for-nextflow",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nextflow",
        "linting",
        "dsl"
      ],
      "id": 608
    },
    {
      "name": "wdl-aid",
      "one_line_profile": "Automatic documentation generator for WDL scientific workflows",
      "detailed_description": "A tool that automatically generates documentation for workflows written in the Workflow Description Language (WDL), facilitating the maintenance and sharing of bioinformatics pipelines.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "documentation",
        "workflow_management"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/biowdl/wdl-aid",
      "help_website": [
        "https://wdl-aid.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "wdl",
        "documentation",
        "bioinformatics",
        "workflow"
      ],
      "id": 609
    },
    {
      "name": "syn-cerebral-octa-seg",
      "one_line_profile": "Synthesis pipeline for blood vessel segmentation in cerebral 3D OCTA images",
      "detailed_description": "A deep learning-based synthesis pipeline designed for annotation-free segmentation of blood vessels in cerebral 3D Optical Coherence Tomography Angiography (OCTA) images.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "image_segmentation",
        "medical_imaging",
        "data_synthesis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bwittmann/syn-cerebral-octa-seg",
      "help_website": [],
      "license": null,
      "tags": [
        "octa",
        "segmentation",
        "medical-imaging",
        "synthesis"
      ],
      "id": 610
    },
    {
      "name": "doepipeline",
      "one_line_profile": "Pipeline optimization using Design of Experiments (DoE)",
      "detailed_description": "A Python package for optimizing scientific processing pipelines using statistical Design of Experiments (DoE) methodologies to find optimal parameters.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "pipeline_optimization",
        "experimental_design"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/clicumu/doepipeline",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "doe",
        "optimization",
        "pipeline"
      ],
      "id": 611
    },
    {
      "name": "wdl-cwl-translator",
      "one_line_profile": "Translator between WDL and CWL scientific workflow standards",
      "detailed_description": "A tool to translate workflows defined in WDL (Workflow Description Language) to CWL (Common Workflow Language), facilitating interoperability in bioinformatics.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_conversion"
      ],
      "application_level": "tool",
      "primary_language": "Common Workflow Language",
      "repo_url": "https://github.com/common-workflow-lab/wdl-cwl-translator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "wdl",
        "cwl",
        "bioinformatics",
        "interoperability"
      ],
      "id": 612
    },
    {
      "name": "Auto-QChem",
      "one_line_profile": "Automated workflow for DFT calculations of organic molecules",
      "detailed_description": "An automated workflow tool for the generation, management, and storage of Density Functional Theory (DFT) calculations specifically for organic molecules.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "dft_calculation",
        "molecular_modeling",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/doyle-lab-ucla/auto-qchem",
      "help_website": [
        "https://auto-qchem.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "chemistry",
        "dft",
        "automation",
        "organic-molecules"
      ],
      "id": 613
    },
    {
      "name": "WASS",
      "one_line_profile": "Stereo processing pipeline for sea waves 3D reconstruction",
      "detailed_description": "Waves Acquisition Stereo System (WASS) is an optimized stereo processing pipeline designed specifically for the 3D reconstruction of sea waves from image data, used in oceanography.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "3d_reconstruction",
        "oceanography",
        "image_processing"
      ],
      "application_level": "workflow",
      "primary_language": "C++",
      "repo_url": "https://github.com/fbergama/wass",
      "help_website": [
        "http://www.bergamasco.net/wass/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "oceanography",
        "stereo-vision",
        "3d-reconstruction"
      ],
      "id": 614
    },
    {
      "name": "SPORTS1.1",
      "one_line_profile": "Annotation pipeline optimized for rRNA- and tRNA-derived small RNAs",
      "detailed_description": "A small non-coding RNA annotation pipeline specifically optimized for analyzing rRNA- and tRNA-derived small RNAs from sequencing data.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "sequence_annotation",
        "rna_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Perl",
      "repo_url": "https://github.com/junchaoshi/sports1.1",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bioinformatics",
        "rna-seq",
        "annotation"
      ],
      "id": 615
    },
    {
      "name": "Latch SDK",
      "one_line_profile": "Python framework for defining and deploying bioinformatics workflows",
      "detailed_description": "A software development kit (SDK) that allows users to define, upload, and execute bioinformatics workflows on the LatchBio platform using Python.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "bioinformatics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/latchbio/latch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "workflow-management",
        "cloud-computing"
      ],
      "id": 616
    },
    {
      "name": "NIPT-human-genetics",
      "one_line_profile": "Workflow for analysis of ultra-low-pass NIPT sequencing data",
      "detailed_description": "A semi-automated bioinformatics workflow designed for the analysis of large-scale ultra-low-pass non-invasive prenatal test (NIPT) sequencing data in human genetic studies.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "variant_calling",
        "genomic_analysis",
        "prenatal_testing"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/liusylab/NIPT-human-genetics",
      "help_website": [],
      "license": null,
      "tags": [
        "genomics",
        "nipt",
        "bioinformatics-pipeline"
      ],
      "id": 617
    },
    {
      "name": "ERP_CORE",
      "one_line_profile": "Optimized paradigms and analysis pipelines for Event-Related Potential (ERP) research",
      "detailed_description": "A comprehensive resource and toolset for neuroscience research containing optimized experiment control scripts, data processing pipelines, and analysis scripts for 7 different ERP components.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "data_processing",
        "experiment_control",
        "neuroscience_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/lucklab/ERP_CORE",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "neuroscience",
        "erp",
        "eeg",
        "pipeline"
      ],
      "id": 618
    },
    {
      "name": "Magpie",
      "one_line_profile": "Synthetic data generation pipeline for aligning Large Language Models",
      "detailed_description": "A pipeline for generating high-quality synthetic alignment data by prompting aligned LLMs, serving as a methodology tool for AI research and model development.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "data_synthesis",
        "model_alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/magpie-align/magpie",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "synthetic-data",
        "llm-alignment",
        "ai-research"
      ],
      "id": 619
    },
    {
      "name": "nf-linter",
      "one_line_profile": "Linter for Nextflow scientific workflows",
      "detailed_description": "A code linting tool specifically designed for Nextflow, helping scientists maintain quality and correctness in their bioinformatics and data analysis pipelines.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_validation",
        "code_quality"
      ],
      "application_level": "solver",
      "primary_language": "Groovy",
      "repo_url": "https://github.com/mberacochea/nf-linter",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nextflow",
        "linter",
        "workflow-dev"
      ],
      "id": 620
    },
    {
      "name": "openMVG-LATCH",
      "one_line_profile": "OpenMVG extension with LATCH descriptors for 3D reconstruction",
      "detailed_description": "An extension of the OpenMVG library integrating LATCH descriptors and GPU-based matchers for photogrammetry and computer vision tasks in scientific imaging.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "image_processing",
        "3d_reconstruction",
        "photogrammetry"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/mdaiter/openMVG",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "computer-vision",
        "photogrammetry",
        "3d-reconstruction"
      ],
      "id": 621
    },
    {
      "name": "NUWA",
      "one_line_profile": "Unified 3D Transformer pipeline for visual synthesis",
      "detailed_description": "A multimodal pre-trained model and pipeline for generating and manipulating visual data (images/video), serving as a research tool for computer vision and generative AI.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "visual_synthesis",
        "generative_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/NUWA",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "computer-vision",
        "generative-ai",
        "transformer"
      ],
      "id": 622
    },
    {
      "name": "Osprey",
      "one_line_profile": "Hyperparameter optimization for scientific machine learning pipelines",
      "detailed_description": "A tool for hyperparameter optimization designed for machine learning pipelines, particularly associated with the MSMBuilder ecosystem for molecular dynamics.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "hyperparameter_optimization",
        "model_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/msmbuilder/osprey",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "machine-learning",
        "molecular-dynamics",
        "optimization"
      ],
      "id": 623
    },
    {
      "name": "NeuralLambda",
      "one_line_profile": "Differentiable Lambda Calculus framework for neuro-symbolic AI",
      "detailed_description": "A research framework implementing fully differentiable Lambda Calculus and neural data structures (stacks, queues) for neuro-symbolic reasoning and modeling.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "scientific_modeling",
        "neuro_symbolic_reasoning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/neurallambda/neurallambda",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "neuro-symbolic",
        "differentiable-programming",
        "ai-research"
      ],
      "id": 624
    },
    {
      "name": "Nextflow Hyperopt",
      "one_line_profile": "Nextflow pipeline for ML hyperparameter optimization",
      "detailed_description": "A Nextflow-based pipeline designed to automate hyperparameter optimization for machine learning models, facilitating reproducible scientific ML workflows.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "hyperparameter_optimization",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/nextflow-io/hyperopt",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "nextflow",
        "machine-learning",
        "optimization"
      ],
      "id": 625
    },
    {
      "name": "vscode-dag-preview",
      "one_line_profile": "Nextflow DAG visualization for VSCode",
      "detailed_description": "A Visual Studio Code extension that renders the execution Directed Acyclic Graph (DAG) of Nextflow pipelines, aiding in scientific workflow design and debugging.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_visualization",
        "pipeline_development"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/nextflow-io/vscode-dag-preview",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nextflow",
        "visualization",
        "vscode-extension"
      ],
      "id": 626
    },
    {
      "name": "vscode-language-nextflow",
      "one_line_profile": "Nextflow language support for VSCode",
      "detailed_description": "A Visual Studio Code extension providing syntax highlighting and language support for Nextflow, essential for developing scientific workflows.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_development",
        "code_editing"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/nextflow-io/vscode-language-nextflow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nextflow",
        "ide-support",
        "bioinformatics"
      ],
      "id": 627
    },
    {
      "name": "HiC-Pro",
      "one_line_profile": "Optimized pipeline for Hi-C data processing",
      "detailed_description": "An optimized and flexible pipeline for processing Hi-C data, from raw reads to normalized contact maps.",
      "domains": [
        "D2",
        "Bioinformatics"
      ],
      "subtask_category": [
        "hic_processing",
        "contact_map_generation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/nservant/HiC-Pro",
      "help_website": [
        "https://nservant.github.io/HiC-Pro/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "hic",
        "genomics",
        "pipeline"
      ],
      "id": 628
    },
    {
      "name": "MinerU",
      "one_line_profile": "High-quality data extraction tool for complex scientific documents",
      "detailed_description": "A comprehensive data extraction tool designed to transform complex documents like PDFs (containing formulas, tables, and diagrams) into LLM-ready formats (Markdown/JSON), specifically optimized for scientific literature mining and agentic workflows.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "data_extraction",
        "literature_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/opendatalab/MinerU",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "pdf-parsing",
        "ocr",
        "llm-data-prep",
        "scientific-literature"
      ],
      "id": 629
    },
    {
      "name": "neural-imaging",
      "one_line_profile": "Modeling and optimization toolbox for photo acquisition pipelines",
      "detailed_description": "A Python toolbox for modeling, simulation, and optimization of photo acquisition and distribution pipelines, covering camera ISP, compression, forensics, and manipulation detection. Used in CVPR/ICLR research.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "imaging_pipeline_simulation",
        "image_forensics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pkorus/neural-imaging",
      "help_website": [],
      "license": null,
      "tags": [
        "computational-photography",
        "isp",
        "image-processing",
        "simulation"
      ],
      "id": 630
    },
    {
      "name": "nf-aggregate",
      "one_line_profile": "Metrics aggregation pipeline for Nextflow runs",
      "detailed_description": "A specialized pipeline designed to aggregate pertinent metrics across multiple pipeline runs on the Seqera Platform, aiding in the monitoring and optimization of scientific workflows.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_monitoring",
        "metrics_aggregation"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/seqeralabs/nf-aggregate",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "nextflow",
        "workflow-metrics",
        "bioinformatics-ops"
      ],
      "id": 631
    },
    {
      "name": "Versatile-OCR-Program",
      "one_line_profile": "Multi-modal OCR pipeline for scientific documents",
      "detailed_description": "An OCR pipeline optimized for machine learning training data preparation, capable of handling text, figures, math formulas, tables, and diagrams, suitable for extracting structured data from scientific papers.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "ocr",
        "data_extraction"
      ],
      "application_level": "pipeline",
      "primary_language": "Python",
      "repo_url": "https://github.com/ses4255/Versatile-OCR-Program",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ocr",
        "scientific-data-extraction",
        "multimodal"
      ],
      "id": 632
    },
    {
      "name": "DermSynth3D",
      "one_line_profile": "Synthesis pipeline for dermatological images",
      "detailed_description": "A data generation pipeline for creating photorealistic, in-the-wild synthetic dermatological data with rich multi-task annotations, supporting skin-analysis research and model training.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "image_synthesis",
        "data_augmentation"
      ],
      "application_level": "pipeline",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/sfu-mial/DermSynth3D",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "medical-imaging",
        "dermatology",
        "synthetic-data",
        "3d-synthesis"
      ],
      "id": 633
    },
    {
      "name": "auto-docking-vessels",
      "one_line_profile": "Simulation environment for autonomous robotic vessels",
      "detailed_description": "A Webots-based simulation environment and vision-based autonomous docking algorithm for robotic vessels, supporting research in marine robotics and control systems.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "robotics_simulation",
        "autonomous_control"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/silvery107/auto-docking-vessels",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "robotics",
        "simulation",
        "webots",
        "marine-systems"
      ],
      "id": 634
    },
    {
      "name": "snakefmt",
      "one_line_profile": "Code formatter for Snakemake workflows",
      "detailed_description": "The standard code formatter for Snakemake files, essential for maintaining code quality and readability in scientific workflow development.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "code_formatting",
        "workflow_maintenance"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake/snakefmt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "formatter",
        "workflow-dev-tools"
      ],
      "id": 635
    },
    {
      "name": "genpei",
      "one_line_profile": "GA4GH Workflow Execution Service implementation",
      "detailed_description": "A microservice implementation of the GA4GH (Global Alliance for Genomics and Health) Workflow Execution Service Standard, facilitating standardized execution of genomics workflows.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_execution",
        "genomics_standard"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/suecharo/genpei",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ga4gh",
        "genomics",
        "workflow-service",
        "wes"
      ],
      "id": 636
    },
    {
      "name": "4KAgent",
      "one_line_profile": "Agentic image super-resolution and restoration tool",
      "detailed_description": "An intelligent computer vision agent (NeurIPS 2025) capable of restoring images to 4K resolution, applicable in scientific imaging enhancement and microscopy data restoration.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "image_restoration",
        "super_resolution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/taco-group/4KAgent",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "computer-vision",
        "image-restoration",
        "super-resolution",
        "agentic-workflow"
      ],
      "id": 637
    },
    {
      "name": "HLS_FPGA",
      "one_line_profile": "High-Level Synthesis projects for signal processing",
      "detailed_description": "A collection of real-time High-Level Synthesis (HLS) compute cores and pipelines for UltraScale+ FPGAs, focusing on signal processing for SDR and 5G applications.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "signal_processing",
        "fpga_synthesis"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/taitashaw/HLS_FPGA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fpga",
        "hls",
        "signal-processing",
        "sdr"
      ],
      "id": 638
    },
    {
      "name": "Tuplex",
      "one_line_profile": "Parallel big data processing framework for data science",
      "detailed_description": "A high-performance parallel data processing framework that compiles Python data science pipelines into optimized LLVM bytecode, accelerating data cleaning and transformation tasks.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "data_processing",
        "pipeline_optimization"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/tuplex/tuplex",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-science",
        "etl",
        "compiler",
        "parallel-computing"
      ],
      "id": 639
    },
    {
      "name": "DocETL",
      "one_line_profile": "Agentic LLM-powered data processing system",
      "detailed_description": "A system for defining and executing complex data processing and ETL pipelines using LLM agents, suitable for unstructured scientific data curation and transformation.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "data_etl",
        "data_curation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/ucbepic/docetl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "etl",
        "llm-agents",
        "data-processing",
        "unstructured-data"
      ],
      "id": 640
    },
    {
      "name": "workflow-testing",
      "one_line_profile": "Automated testing tool for Galaxy workflows",
      "detailed_description": "A utility for automated testing of scientific workflows against the Galaxy platform, ensuring reproducibility and correctness of bioinformatics pipelines.",
      "domains": [
        "D2"
      ],
      "subtask_category": [
        "workflow_testing",
        "quality_assurance"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/usegalaxy-eu/workflow-testing",
      "help_website": [],
      "license": null,
      "tags": [
        "galaxy",
        "bioinformatics",
        "workflow-testing"
      ],
      "id": 641
    },
    {
      "name": "analysis-wdls",
      "one_line_profile": "Scalable genomic analysis pipelines using WDL",
      "detailed_description": "A collection of scalable genomic analysis pipelines written in Workflow Description Language (WDL), covering alignment, variant calling, and quality control tasks for oncology research.",
      "domains": [
        "D2",
        "D2-01"
      ],
      "subtask_category": [
        "genomic_analysis",
        "variant_calling",
        "workflow_management"
      ],
      "application_level": "workflow",
      "primary_language": "WDL",
      "repo_url": "https://github.com/wustl-oncology/analysis-wdls",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "genomics",
        "wdl",
        "bioinformatics",
        "pipeline"
      ],
      "id": 642
    },
    {
      "name": "PHOTONAI",
      "one_line_profile": "High-level Python API for designing and optimizing machine learning pipelines",
      "detailed_description": "A high-level machine learning library designed for rapid prototyping and optimization of pipelines in scientific research, with specific features for neuroimaging and medical data analysis.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "pipeline_optimization",
        "model_selection",
        "machine_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wwu-mmll/photonai",
      "help_website": [
        "https://www.photon-ai.com"
      ],
      "license": "GPL-3.0",
      "tags": [
        "machine-learning",
        "neuroimaging",
        "pipeline-optimization",
        "scientific-research"
      ],
      "id": 643
    },
    {
      "name": "WorfBench",
      "one_line_profile": "Benchmark for Agentic Workflow Generation",
      "detailed_description": "A benchmarking framework designed to evaluate the capability of Large Language Models (LLMs) in generating agentic workflows, supporting research in AI-driven workflow synthesis and automation.",
      "domains": [
        "D2",
        "D2-05"
      ],
      "subtask_category": [
        "workflow_generation",
        "benchmarking",
        "agent_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/WorfBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agents",
        "workflow-generation",
        "benchmark",
        "llm"
      ],
      "id": 644
    }
  ]
}