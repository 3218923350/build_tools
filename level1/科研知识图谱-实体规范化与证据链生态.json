{
  "leaf_cluster_name": "科研知识图谱-实体规范化与证据链生态",
  "domain": "Sci Knowledge/KG",
  "typical_objects": "entities/relations",
  "task_chain": "抽取→对齐→融合→推理→版本→评测",
  "tool_form": "图DB/ETL + 推理/评测",
  "total_tools": 1159,
  "tools": [
    {
      "name": "knowledge-extraction",
      "one_line_profile": "Java library for extracting knowledge graphs from natural language text",
      "detailed_description": "A Java-based pipeline that converts natural language text into graph database structures, facilitating knowledge extraction and graph construction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "graph_construction"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/5agado/knowledge-extraction",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "nlp",
        "java"
      ],
      "id": 1
    },
    {
      "name": "NER-RE",
      "one_line_profile": "SpaCy-based pipeline for NER, Entity Linking, and Relation Extraction",
      "detailed_description": "A comprehensive NLP pipeline built on spaCy v3 that performs Named Entity Recognition, Entity Linking to a Knowledge Base, and Relation Extraction to normalize and structure text data.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "ner",
        "entity_linking",
        "relation_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/AdirthaBorgohain/NER-RE",
      "help_website": [],
      "license": null,
      "tags": [
        "spacy",
        "pipeline",
        "information-extraction"
      ],
      "id": 2
    },
    {
      "name": "KAZU",
      "one_line_profile": "High-performance biomedical Named Entity Recognition and Linking framework",
      "detailed_description": "A production-ready biomedical NER and Entity Linking framework developed by AstraZeneca, designed for fast and accurate extraction of biomedical concepts from text.",
      "domains": [
        "G2",
        "G2-01",
        "Biomedical"
      ],
      "subtask_category": [
        "bioner",
        "entity_linking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AstraZeneca/KAZU",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "biomedical",
        "ner",
        "entity-linking"
      ],
      "id": 3
    },
    {
      "name": "REBEL",
      "one_line_profile": "Seq2Seq model for end-to-end Relation Extraction",
      "detailed_description": "A sequence-to-sequence model that simplifies relation extraction by translating raw text directly into relation triplets, widely used as a component in knowledge graph construction pipelines.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "knowledge_graph"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Babelscape/rebel",
      "help_website": [],
      "license": null,
      "tags": [
        "seq2seq",
        "relation-extraction",
        "transformer"
      ],
      "id": 4
    },
    {
      "name": "astred",
      "one_line_profile": "Library for linguistic comparison and word alignment analysis",
      "detailed_description": "A Python library designed to linguistically compare sentences and analyze word alignments, useful for translation studies and syntactic analysis.",
      "domains": [
        "Linguistics",
        "NLP"
      ],
      "subtask_category": [
        "linguistic_analysis",
        "alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BramVanroy/astred",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "linguistics",
        "alignment",
        "syntax"
      ],
      "id": 5
    },
    {
      "name": "spacy_conll",
      "one_line_profile": "SpaCy pipeline component for CoNLL-U formatting",
      "detailed_description": "A pipeline component for spaCy that adds CoNLL-U properties to documents, facilitating interoperability with standard linguistic data formats.",
      "domains": [
        "NLP",
        "Linguistics"
      ],
      "subtask_category": [
        "data_formatting",
        "parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BramVanroy/spacy_conll",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "spacy",
        "conll-u",
        "nlp-pipeline"
      ],
      "id": 6
    },
    {
      "name": "flair",
      "one_line_profile": "Full-Length Alternative Isoform analysis of RNA",
      "detailed_description": "A tool for the correction, isoform definition, and quantification of full-length RNA sequencing data, specifically designed for nanopore cDNA reads.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "rna_analysis",
        "isoform_quantification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/BrooksLabUCSC/flair",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rna-seq",
        "nanopore",
        "isoforms"
      ],
      "id": 7
    },
    {
      "name": "uniflow",
      "one_line_profile": "LLM-based unstructured data extraction and cleaning tool",
      "detailed_description": "A unified interface for extracting, cleaning, and transforming text from unstructured data sources like PDFs and HTMLs using LLMs, aiding in scientific knowledge base construction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "text_extraction",
        "data_cleaning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "pdf-extraction",
        "etl"
      ],
      "id": 8
    },
    {
      "name": "chemdataextractor",
      "one_line_profile": "Automated extraction of chemical properties from scientific documents",
      "detailed_description": "A toolkit for automatically extracting chemical names, properties, and spectra from scientific text, facilitating chemical database construction.",
      "domains": [
        "Chemistry",
        "G2"
      ],
      "subtask_category": [
        "chemical_extraction",
        "text_mining"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CambridgeMolecularEngineering/chemdataextractor",
      "help_website": [
        "http://chemdataextractor.org/docs"
      ],
      "license": "MIT",
      "tags": [
        "chemistry",
        "text-mining",
        "property-extraction"
      ],
      "id": 9
    },
    {
      "name": "tuna",
      "one_line_profile": "Hyperparameter optimization for AllenNLP using Ray Tune",
      "detailed_description": "A library that integrates Ray Tune with AllenNLP to enable efficient hyperparameter search for NLP models.",
      "domains": [
        "NLP",
        "MLOps"
      ],
      "subtask_category": [
        "hyperparameter_optimization",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChristophAlt/tuna",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "allennlp",
        "ray-tune",
        "optimization"
      ],
      "id": 10
    },
    {
      "name": "cogcomp-nlp",
      "one_line_profile": "Comprehensive Java-based NLP library by CogComp",
      "detailed_description": "A suite of NLP tools including lemmatizer, NER, POS tagger, and relation extraction modules, providing foundational text processing capabilities.",
      "domains": [
        "NLP",
        "G2-01"
      ],
      "subtask_category": [
        "nlp_pipeline",
        "annotation"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/CogComp/cogcomp-nlp",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "java",
        "nlp",
        "core-nlp"
      ],
      "id": 11
    },
    {
      "name": "MedCATtrainer",
      "one_line_profile": "Interface for training and improving MedCAT biomedical NER models",
      "detailed_description": "A web-based interface designed to inspect, improve, and add concepts to MedCAT models, facilitating the creation of high-quality biomedical named entity recognition systems.",
      "domains": [
        "Biomedical",
        "G2-01"
      ],
      "subtask_category": [
        "annotation",
        "model_training"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/CogStack/MedCATtrainer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "biomedical",
        "annotation",
        "active-learning"
      ],
      "id": 12
    },
    {
      "name": "chem_scanner",
      "one_line_profile": "Tool for extracting chemical information from ChemDraw files",
      "detailed_description": "A Ruby-based tool for extracting and reusing chemical structure information embedded in ChemDraw files found in scientific documents.",
      "domains": [
        "Chemistry",
        "G2"
      ],
      "subtask_category": [
        "chemical_extraction",
        "file_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/ComPlat/chem_scanner",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "chemdraw",
        "chemistry",
        "extraction"
      ],
      "id": 13
    },
    {
      "name": "RelEx",
      "one_line_profile": "Relation Extraction framework built on AllenNLP",
      "detailed_description": "A framework developed by DFKI for relation extraction tasks, leveraging AllenNLP to provide a structured approach to training and evaluating RE models.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "model_framework"
      ],
      "application_level": "library",
      "primary_language": "Jsonnet",
      "repo_url": "https://github.com/DFKI-NLP/RelEx",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "allennlp",
        "relation-extraction",
        "dfki"
      ],
      "id": 14
    },
    {
      "name": "deepsearch-glm",
      "one_line_profile": "Graph language models for scientific document knowledge extraction",
      "detailed_description": "A library for creating fast graph language models from converted PDF documents, enabling advanced knowledge extraction and Q&A on scientific literature.",
      "domains": [
        "G2",
        "Scientific Literature"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "document_analysis"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/DS4SD/deepsearch-glm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-model",
        "pdf-analysis",
        "scientific-discovery"
      ],
      "id": 15
    },
    {
      "name": "dewy",
      "one_line_profile": "Knowledge extraction and retrieval for Gen AI applications",
      "detailed_description": "An opinionated framework for knowledge extraction and semantic retrieval, designed to structure information for Generative AI and RAG workflows.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/DewyKB/dewy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "knowledge-base",
        "extraction"
      ],
      "id": 16
    },
    {
      "name": "NeuroNER",
      "one_line_profile": "Neural network-based named-entity recognition tool",
      "detailed_description": "A program for named-entity recognition (NER) using neural networks, widely used in biomedical text mining and general NLP tasks. It provides an easy-to-use interface for training and deploying NER models.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "sequence_labeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Franck-Dernoncourt/NeuroNER",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ner",
        "neural-networks",
        "biomedical-nlp"
      ],
      "id": 17
    },
    {
      "name": "ReMine",
      "one_line_profile": "Open information extraction tool integrating local context and global cohesiveness",
      "detailed_description": "A system for Open Information Extraction (OpenIE) that extracts entity relations from large corpora by integrating local context and global cohesiveness, suitable for scientific text mining.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "open_ie"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/GentleZhu/ReMine",
      "help_website": [],
      "license": null,
      "tags": [
        "open-ie",
        "relation-extraction",
        "text-mining"
      ],
      "id": 18
    },
    {
      "name": "uie_pytorch",
      "one_line_profile": "PyTorch implementation of Universal Information Extraction (UIE) model",
      "detailed_description": "A PyTorch implementation of the UIE model originally from PaddleNLP, providing a unified framework for named entity recognition, relation extraction, and event extraction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "ner",
        "relation_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HUSTAI/uie_pytorch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "uie",
        "pytorch",
        "information-extraction"
      ],
      "id": 19
    },
    {
      "name": "anago",
      "one_line_profile": "Sequence labeling library for NER and POS tagging",
      "detailed_description": "A Python library for sequence labeling tasks such as Named-Entity Recognition (NER) and Part-of-Speech (POS) tagging, implementing Bidirectional LSTM-CRF and ELMo models.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "sequence_labeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Hironsan/anago",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ner",
        "lstm-crf",
        "nlp-library"
      ],
      "id": 20
    },
    {
      "name": "udify",
      "one_line_profile": "Universal Dependencies parsing tool for 75 languages",
      "detailed_description": "A single model capable of parsing Universal Dependencies across 75 languages, jointly predicting POS tags, morphology, lemmas, and dependency trees, serving as a foundational tool for multilingual information extraction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "dependency_parsing",
        "pos_tagging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Hyperparticle/udify",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dependency-parsing",
        "multilingual",
        "nlp"
      ],
      "id": 21
    },
    {
      "name": "Grapher",
      "one_line_profile": "Knowledge graph extraction from textual descriptions",
      "detailed_description": "A tool that implements efficient knowledge graph extraction from textual descriptions, facilitating the construction of structured knowledge from unstructured text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/IBM/Grapher",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "extraction",
        "nlp"
      ],
      "id": 22
    },
    {
      "name": "zshot",
      "one_line_profile": "Zero and Few shot named entity and relationship recognition library",
      "detailed_description": "A Python library for zero-shot and few-shot named entity recognition (NER) and relation extraction (RE), compatible with spaCy and Hugging Face pipelines.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "ner",
        "relation_extraction",
        "zero_shot_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IBM/zshot",
      "help_website": [
        "https://ibm.github.io/zshot/"
      ],
      "license": "MIT",
      "tags": [
        "zero-shot",
        "ner",
        "spacy-extension"
      ],
      "id": 23
    },
    {
      "name": "KnowCoder",
      "one_line_profile": "LLM-based framework for universal information extraction",
      "detailed_description": "A framework that codes structured knowledge into Large Language Models (LLMs) for universal information extraction, enabling extraction of entities, relations, and events via code generation paradigms.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "llm_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ICT-GoKnow/KnowCoder",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "information-extraction",
        "knowledge-graph"
      ],
      "id": 24
    },
    {
      "name": "USC-DS-RelationExtraction",
      "one_line_profile": "Distantly Supervised Relation Extraction system",
      "detailed_description": "A C++ implementation for distantly supervised relation extraction, a technique widely used to extract relations from large text corpora using knowledge bases as supervision.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "distant_supervision"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/INK-USC/USC-DS-RelationExtraction",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "relation-extraction",
        "distant-supervision",
        "c++"
      ],
      "id": 25
    },
    {
      "name": "AGATHA",
      "one_line_profile": "Automatic Graph-mining And Transformer based Hypothesis generation",
      "detailed_description": "A deep learning system for hypothesis generation that mines knowledge graphs to predict plausible connections, aiding in scientific discovery and evidence chain construction.",
      "domains": [
        "G2",
        "G3"
      ],
      "subtask_category": [
        "hypothesis_generation",
        "link_prediction",
        "graph_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JSybrandt/agatha",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "hypothesis-generation",
        "knowledge-graph",
        "transformer"
      ],
      "id": 26
    },
    {
      "name": "DeCLUTR",
      "one_line_profile": "Deep Contrastive Learning for Unsupervised Textual Representations",
      "detailed_description": "A library for training universal sentence embeddings using contrastive learning, useful for entity normalization, clustering, and semantic search in scientific knowledge graphs.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "representation_learning",
        "embedding",
        "entity_normalization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/JohnGiorgi/DeCLUTR",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "contrastive-learning",
        "embeddings",
        "nlp"
      ],
      "id": 27
    },
    {
      "name": "seq2rel",
      "one_line_profile": "Sequence-to-sequence approach for document-level relation extraction",
      "detailed_description": "A library for document-level relation extraction using a sequence-to-sequence paradigm, capable of extracting complex relations from scientific texts.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "document_level_ie"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/JohnGiorgi/seq2rel",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "relation-extraction",
        "seq2seq",
        "biomedical-nlp"
      ],
      "id": 28
    },
    {
      "name": "MEL-TNNT",
      "one_line_profile": "Metadata Extractor & Loader and NLP-NER Toolkit",
      "detailed_description": "A toolkit comprising a Metadata Extractor & Loader (MEL) and The NLP-NER Toolkit (TNNT), designed to facilitate named entity recognition and metadata management in text processing pipelines.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "ner",
        "metadata_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/KGCP/MEL-TNNT",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ner",
        "metadata",
        "toolkit"
      ],
      "id": 29
    },
    {
      "name": "BioDEX",
      "one_line_profile": "Large-scale biomedical adverse drug event extraction dataset and benchmark",
      "detailed_description": "BioDEX is a resource for real-world pharmacovigilance, providing a large-scale dataset and methodology for extracting adverse drug events (ADEs) from biomedical text.",
      "domains": [
        "G2",
        "G2-01",
        "Biomedicine"
      ],
      "subtask_category": [
        "event_extraction",
        "adverse_drug_event_extraction"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/KarelDO/BioDEX",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pharmacovigilance",
        "adverse-drug-events",
        "biomedical-nlp"
      ],
      "id": 30
    },
    {
      "name": "deplacy",
      "one_line_profile": "CUI-based tree visualizer for Universal Dependencies",
      "detailed_description": "A terminal-based visualization tool for displaying Universal Dependencies trees and immediate catena analysis, aiding in linguistic structure analysis.",
      "domains": [
        "Linguistics",
        "NLP"
      ],
      "subtask_category": [
        "visualization",
        "dependency_parsing"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/KoichiYasuoka/deplacy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "dependency-parsing",
        "linguistics"
      ],
      "id": 31
    },
    {
      "name": "brain-segmentation",
      "one_line_profile": "Deep learning tool for brain MRI skull stripping and segmentation",
      "detailed_description": "A deep learning implementation using U-Net for skull stripping and FLAIR abnormality segmentation in brain MRI scans.",
      "domains": [
        "Medical Imaging",
        "Neuroscience"
      ],
      "subtask_category": [
        "image_segmentation",
        "skull_stripping"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MaciejMazurowski/brain-segmentation",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "mri",
        "brain-segmentation",
        "u-net"
      ],
      "id": 32
    },
    {
      "name": "allennlp-light",
      "one_line_profile": "Lightweight version of AllenNLP core modules",
      "detailed_description": "A standalone port of AllenNLP's core modules and neural network components, providing essential NLP building blocks with minimum dependencies.",
      "domains": [
        "G2",
        "NLP"
      ],
      "subtask_category": [
        "nlp_modeling",
        "text_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MaksymDel/allennlp-light",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "deep-learning",
        "allennlp"
      ],
      "id": 33
    },
    {
      "name": "MixedEmotions-KG",
      "one_line_profile": "Knowledge graph creation module from text and emotion data",
      "detailed_description": "A tool to create knowledge graphs by processing information from entity extraction, linking, and emotion recognition modules.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "entity_linking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/MixedEmotions/knowledge-graph",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "emotion-recognition",
        "entity-extraction"
      ],
      "id": 34
    },
    {
      "name": "Relation_Extraction_KGE",
      "one_line_profile": "C++ implementation for Knowledge Base Embedding",
      "detailed_description": "A C++ library/tool for Knowledge Base Embedding, likely implementing algorithms for relation extraction and link prediction in KGs.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/Mrlyk423/Relation_Extraction",
      "help_website": [],
      "license": null,
      "tags": [
        "kge",
        "embedding",
        "c++"
      ],
      "id": 35
    },
    {
      "name": "SARS-CoV2-mRNA-Assemblies",
      "one_line_profile": "Assemblies of putative SARS-CoV2 spike-encoding mRNA sequences",
      "detailed_description": "Experimental sequence information and assemblies for the RNA components of Moderna and Pfizer/BioNTech COVID-19 vaccines.",
      "domains": [
        "Genomics",
        "Virology"
      ],
      "subtask_category": [
        "sequence_assembly",
        "vaccine_research"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/NAalytics/Assemblies-of-putative-SARS-CoV2-spike-encoding-mRNA-sequences-for-vaccines-BNT-162b2-and-mRNA-1273",
      "help_website": [],
      "license": null,
      "tags": [
        "covid-19",
        "mrna",
        "sequence-data"
      ],
      "id": 36
    },
    {
      "name": "medaCy",
      "one_line_profile": "Medical text mining and information extraction framework",
      "detailed_description": "A medical text mining and information extraction library built on top of spaCy, designed for clinical NLP tasks.",
      "domains": [
        "G2",
        "G2-01",
        "Medical NLP"
      ],
      "subtask_category": [
        "medical_text_mining",
        "information_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NLPatVCU/medaCy",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "spacy",
        "clinical-nlp",
        "text-mining"
      ],
      "id": 37
    },
    {
      "name": "UMLS-KG",
      "one_line_profile": "Tool to build knowledge graphs from UMLS sources",
      "detailed_description": "A utility to load, visualize, and query a knowledge graph built from UMLS Knowledge Sources using Neo4j and Scispacy.",
      "domains": [
        "G2",
        "Biomedical Informatics"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "data_loading"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Nguyendat-bit/UMLS-KG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "umls",
        "neo4j",
        "knowledge-graph"
      ],
      "id": 38
    },
    {
      "name": "NEMO-Corpus",
      "one_line_profile": "Hebrew Treebank Named Entity Recognition corpus",
      "detailed_description": "A dataset containing Named Entity (NER) annotations for the Hebrew Treebank, including morpheme and token level labels.",
      "domains": [
        "G2",
        "NLP"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "corpus_annotation"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/OnlpLab/NEMO-Corpus",
      "help_website": [],
      "license": null,
      "tags": [
        "ner",
        "hebrew",
        "corpus"
      ],
      "id": 39
    },
    {
      "name": "OneKE",
      "one_line_profile": "Large model-based knowledge extraction framework",
      "detailed_description": "A knowledge extraction framework leveraging large language models, capable of generalized extraction in Chinese and English across multiple fields.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "relation_extraction"
      ],
      "application_level": "platform",
      "primary_language": "HTML",
      "repo_url": "https://github.com/OpenSPG/OneKE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "knowledge-extraction",
        "bilingual"
      ],
      "id": 40
    },
    {
      "name": "Orphadata_aggregated",
      "one_line_profile": "Aggregated dataset from Orphanet knowledge base",
      "detailed_description": "Partial extraction of the Orphanet knowledge base on Rare Diseases, provided as aggregated files for research.",
      "domains": [
        "Biomedicine",
        "Rare Diseases"
      ],
      "subtask_category": [
        "data_access",
        "knowledge_base"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/Orphanet/Orphadata_aggregated",
      "help_website": [],
      "license": null,
      "tags": [
        "orphanet",
        "rare-diseases",
        "knowledge-base"
      ],
      "id": 41
    },
    {
      "name": "DOCRED-FE",
      "one_line_profile": "Document-level fine-grained entity and relation extraction dataset",
      "detailed_description": "A dataset and associated codes for document-level fine-grained entity and relation extraction, presented at ICASSP 2023.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "entity_extraction"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/PKU-TANGENT/DOCRED-FE",
      "help_website": [],
      "license": null,
      "tags": [
        "docred",
        "relation-extraction",
        "dataset"
      ],
      "id": 42
    },
    {
      "name": "PaddleNLP",
      "one_line_profile": "Comprehensive NLP library based on PaddlePaddle",
      "detailed_description": "A powerful NLP library providing easy-to-use interfaces for LLMs and SLMs, including a rich model zoo for various information extraction tasks.",
      "domains": [
        "G2",
        "NLP"
      ],
      "subtask_category": [
        "nlp_modeling",
        "information_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PaddlePaddle/PaddleNLP",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "paddlepaddle",
        "nlp",
        "llm"
      ],
      "id": 43
    },
    {
      "name": "docai",
      "one_line_profile": "Library for structured information extraction from documents",
      "detailed_description": "A Python library designed for extracting structured information from various document formats, facilitating document AI workflows.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "document_extraction",
        "information_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PragmaticMachineLearning/docai",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "document-ai",
        "extraction",
        "structured-data"
      ],
      "id": 44
    },
    {
      "name": "transformer-srl",
      "one_line_profile": "BERT-based Semantic Role Labeling implementation",
      "detailed_description": "A reimplementation of a BERT-based model for Semantic Role Labeling (SRL), including predicate disambiguation, serving as a robust extraction tool.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "semantic_role_labeling",
        "relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Perl",
      "repo_url": "https://github.com/Riccorl/transformer-srl",
      "help_website": [],
      "license": null,
      "tags": [
        "srl",
        "bert",
        "extraction"
      ],
      "id": 45
    },
    {
      "name": "transformers-embedder",
      "one_line_profile": "Word-level Transformer layer library",
      "detailed_description": "A library providing a Word Level Transformer layer based on PyTorch and Hugging Face Transformers, useful for building NLP models.",
      "domains": [
        "G2",
        "NLP"
      ],
      "subtask_category": [
        "embedding",
        "model_building"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Riccorl/transformers-embedder",
      "help_website": [],
      "license": null,
      "tags": [
        "transformers",
        "pytorch",
        "embeddings"
      ],
      "id": 46
    },
    {
      "name": "GDAP",
      "one_line_profile": "Prompt-based framework for disentangled event argument extraction",
      "detailed_description": "A simple yet effective event extraction framework that uses prompts to generate disentangled arguments, addressing the issue of argument overlap and interaction in event extraction tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction",
        "argument_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RingBDStack/GDAP",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "event-extraction",
        "prompt-learning",
        "nlp"
      ],
      "id": 47
    },
    {
      "name": "TestNER",
      "one_line_profile": "Toolkit for testing and improving Named Entity Recognition models",
      "detailed_description": "A software testing toolkit designed to evaluate the robustness of NER models and improve their performance through targeted testing strategies.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "model_testing",
        "named_entity_recognition"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/RobustNLP/TestNER",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ner",
        "robustness-testing",
        "nlp"
      ],
      "id": 48
    },
    {
      "name": "GIT",
      "one_line_profile": "Graph-based Interaction Model with Tracker for Document-level Event Extraction",
      "detailed_description": "Implementation of a heterogeneous graph-based interaction model with a tracker for extracting events from documents, capturing global interactions among events.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction",
        "document_level_ie"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RunxinXu/GIT",
      "help_website": [],
      "license": null,
      "tags": [
        "event-extraction",
        "graph-neural-networks",
        "document-level"
      ],
      "id": 49
    },
    {
      "name": "TSAR",
      "one_line_profile": "Two-Stream AMR-enhanced Model for Event Argument Extraction",
      "detailed_description": "A model leveraging Abstract Meaning Representation (AMR) to enhance document-level event argument extraction through a two-stream approach.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_argument_extraction",
        "document_level_ie"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RunxinXu/TSAR",
      "help_website": [],
      "license": null,
      "tags": [
        "amr",
        "event-extraction",
        "nlp"
      ],
      "id": 50
    },
    {
      "name": "KEEL",
      "one_line_profile": "Software tool for Knowledge Extraction based on Evolutionary Learning",
      "detailed_description": "An open source Java software tool to assess evolutionary algorithms for Data Mining problems including regression, classification, clustering, and pattern mining.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "evolutionary_learning"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/SCI2SUGR/KEEL",
      "help_website": [
        "http://www.keel.es"
      ],
      "license": "GPL-3.0",
      "tags": [
        "data-mining",
        "evolutionary-algorithms",
        "machine-learning"
      ],
      "id": 51
    },
    {
      "name": "ReLiK",
      "one_line_profile": "Fast and accurate Entity Linking and Relation Extraction toolkit",
      "detailed_description": "A retriever-reader pipeline for fast and accurate entity linking and relation extraction, optimized for efficiency on academic budgets.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_linking",
        "relation_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SapienzaNLP/relik",
      "help_website": [],
      "license": null,
      "tags": [
        "entity-linking",
        "relation-extraction",
        "retrieval-augmented"
      ],
      "id": 52
    },
    {
      "name": "OpenNRE_for_Chinese",
      "one_line_profile": "OpenNRE implementation for Chinese relation extraction",
      "detailed_description": "A PyTorch implementation of the OpenNRE framework specifically adapted for Chinese open relation extraction tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "chinese_nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Schlampig/OpenNRE_for_Chinese",
      "help_website": [],
      "license": null,
      "tags": [
        "opennre",
        "chinese-re",
        "pytorch"
      ],
      "id": 53
    },
    {
      "name": "CORD-19-ANN",
      "one_line_profile": "Semantic search tool for COVID-19 CORD-19 dataset",
      "detailed_description": "An Approximate Nearest Neighbor (ANN) search tool using SBERT embeddings to explore and retrieve relevant documents from the COVID-19 Open Research Dataset (CORD-19).",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "semantic_search",
        "information_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SeanNaren/CORD-19-ANN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "covid-19",
        "semantic-search",
        "sbert"
      ],
      "id": 54
    },
    {
      "name": "Attention-Based-BiLSTM-RE",
      "one_line_profile": "Attention-Based BiLSTM for Relation Classification",
      "detailed_description": "A TensorFlow implementation of Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification, serving as a reference implementation for this classic architecture.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_classification",
        "relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SeoSangwoo/Attention-Based-BiLSTM-relation-extraction",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bilstm",
        "attention-mechanism",
        "relation-classification"
      ],
      "id": 55
    },
    {
      "name": "MRC-NER",
      "one_line_profile": "Unified MRC framework for Flat and Nested NER",
      "detailed_description": "Implementation of a Machine Reading Comprehension (MRC) framework that unifies flat and nested Named Entity Recognition tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "nested_ner"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ShannonAI/mrc-for-flat-nested-ner",
      "help_website": [],
      "license": null,
      "tags": [
        "mrc",
        "ner",
        "nested-ner"
      ],
      "id": 56
    },
    {
      "name": "pytorch-pcnn",
      "one_line_profile": "PyTorch implementation of PCNN for relation extraction",
      "detailed_description": "A PyTorch implementation of the Piecewise Convolutional Neural Networks (PCNN) model for supervised relation extraction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "supervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Perl",
      "repo_url": "https://github.com/ShomyLiu/pytorch-pcnn",
      "help_website": [],
      "license": null,
      "tags": [
        "pcnn",
        "relation-extraction",
        "pytorch"
      ],
      "id": 57
    },
    {
      "name": "pytorch-relation-extraction",
      "one_line_profile": "Distant supervised relation extraction models in PyTorch",
      "detailed_description": "Implementations of distant supervised relation extraction models including PCNN-MIL and PCNN+ATT.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "distant_supervision"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ShomyLiu/pytorch-relation-extraction",
      "help_website": [],
      "license": null,
      "tags": [
        "distant-supervision",
        "relation-extraction",
        "pcnn"
      ],
      "id": 58
    },
    {
      "name": "OpenNRE-PyTorch",
      "one_line_profile": "Neural Relation Extraction library in PyTorch",
      "detailed_description": "A PyTorch implementation of Neural Relation Extraction (OpenNRE), providing a framework for training and evaluating RE models.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "neural_networks"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ShulinCao/OpenNRE-PyTorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "opennre",
        "relation-extraction",
        "pytorch"
      ],
      "id": 59
    },
    {
      "name": "ArabicNER",
      "one_line_profile": "Nested Named Entity Recognition for Arabic",
      "detailed_description": "A tool for performing nested named entity recognition specifically designed for the Arabic language.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "arabic_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SinaLab/ArabicNER",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arabic",
        "ner",
        "nested-ner"
      ],
      "id": 60
    },
    {
      "name": "DocEE",
      "one_line_profile": "Toolkit for document-level event extraction",
      "detailed_description": "A comprehensive toolkit containing implementations of state-of-the-art models for document-level event extraction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction",
        "document_level_ie"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Spico197/DocEE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "event-extraction",
        "toolkit",
        "sota"
      ],
      "id": 61
    },
    {
      "name": "BiLSTM-Tree-RE",
      "one_line_profile": "Relation Classification using BiLSTM on Sequences and Tree Structures",
      "detailed_description": "TensorFlow implementation of end-to-end relation extraction using LSTMs on sequences and tree structures, and shortest dependency paths.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_classification",
        "dependency_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Sshanu/Relation-Classification-using-Bidirectional-LSTM-Tree",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lstm",
        "relation-classification",
        "dependency-tree"
      ],
      "id": 62
    },
    {
      "name": "iFeatureOmega-CLI",
      "one_line_profile": "CLI tool for biological sequence feature extraction",
      "detailed_description": "Command-line interface for iFeatureOmega, a platform for generating, analyzing, and visualizing representations for biological sequences, 3D structures, and ligands.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "feature_extraction",
        "bioinformatics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Superzchen/iFeatureOmega-CLI",
      "help_website": [
        "http://ifeature2.erc.monash.edu"
      ],
      "license": null,
      "tags": [
        "bioinformatics",
        "feature-extraction",
        "protein-structure"
      ],
      "id": 63
    },
    {
      "name": "iFeatureOmega-GUI",
      "one_line_profile": "GUI platform for biological sequence feature extraction",
      "detailed_description": "Graphical User Interface for iFeatureOmega, facilitating the generation and analysis of features for biological sequences and structures without programming.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "feature_extraction",
        "bioinformatics"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Superzchen/iFeatureOmega-GUI",
      "help_website": [
        "http://ifeature2.erc.monash.edu"
      ],
      "license": null,
      "tags": [
        "bioinformatics",
        "gui",
        "feature-analysis"
      ],
      "id": 64
    },
    {
      "name": "CLEVE",
      "one_line_profile": "Contrastive Pre-training for Event Extraction",
      "detailed_description": "Implementation of a contrastive pre-training framework for improving event extraction performance.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction",
        "pre_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/THU-KEG/CLEVE",
      "help_website": [],
      "license": null,
      "tags": [
        "contrastive-learning",
        "event-extraction",
        "nlp"
      ],
      "id": 65
    },
    {
      "name": "MAVEN-ERE",
      "one_line_profile": "Unified dataset and code for Event Relation Extraction",
      "detailed_description": "Source code and dataset for a unified large-scale framework handling event coreference, temporal, causal, and subevent relation extraction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_relation_extraction",
        "dataset_utility"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/THU-KEG/MAVEN-ERE",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "event-relations",
        "coreference",
        "temporal-extraction"
      ],
      "id": 66
    },
    {
      "name": "OmniEvent",
      "one_line_profile": "Comprehensive modular event extraction toolkit",
      "detailed_description": "A unified and modular toolkit for event extraction, supporting various paradigms and models to facilitate research and deployment.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction",
        "nlp_toolkit"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/THU-KEG/OmniEvent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "event-extraction",
        "toolkit",
        "modular"
      ],
      "id": 67
    },
    {
      "name": "CrossLingualContextualEmb",
      "one_line_profile": "Cross-Lingual Alignment of Contextual Word Embeddings",
      "detailed_description": "Tools for aligning contextual word embeddings across different languages, facilitating cross-lingual NLP tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "embedding_alignment",
        "cross_lingual_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TalSchuster/CrossLingualContextualEmb",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "embeddings",
        "cross-lingual",
        "alignment"
      ],
      "id": 68
    },
    {
      "name": "MRC4ERE_plus",
      "one_line_profile": "MRC-based framework for Joint Entity-Relation Extraction",
      "detailed_description": "Implementation of a Machine Reading Comprehension framework for joint entity and relation extraction, focusing on effective question generation.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "joint_extraction",
        "entity_relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TanyaZhao/MRC4ERE_plus",
      "help_website": [],
      "license": null,
      "tags": [
        "mrc",
        "joint-extraction",
        "nlp"
      ],
      "id": 69
    },
    {
      "name": "PharmaCoNER-Tagger",
      "one_line_profile": "Neural NER tagger for Spanish medical texts",
      "detailed_description": "A Neural Named Entity Recognition program targeting domain adaptation for Spanish medical texts, based on NeuroNER.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "medical_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TeMU-BSC/PharmaCoNER-Tagger",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ner",
        "clinical-nlp",
        "spanish"
      ],
      "id": 70
    },
    {
      "name": "MatSciE",
      "one_line_profile": "Automated IE tool for Material Science documents",
      "detailed_description": "An automated tool designed for information extraction specifically from Material Science scientific documents.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "material_science"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TeamMatSciE/MatSciE",
      "help_website": [],
      "license": null,
      "tags": [
        "material-science",
        "information-extraction",
        "scientific-literature"
      ],
      "id": 71
    },
    {
      "name": "RAAT",
      "one_line_profile": "Relation-Augmented Attention Transformer for Event Extraction",
      "detailed_description": "Implementation of the RAAT model, which uses relation-augmented attention transformers for relation modeling in document-level event extraction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction",
        "relation_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TencentYoutuResearch/EventExtraction-RAAT",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "transformer",
        "event-extraction",
        "document-level"
      ],
      "id": 72
    },
    {
      "name": "Context-Aware-RE",
      "one_line_profile": "Context-Aware Representations for KB Relation Extraction",
      "detailed_description": "Implementation of context-aware representations for relation extraction in knowledge bases, as presented at EMNLP 2017.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "knowledge_base_completion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/UKPLab/emnlp2017-relation-extraction",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "relation-extraction",
        "knowledge-graph",
        "nlp"
      ],
      "id": 73
    },
    {
      "name": "ieturk",
      "one_line_profile": "Annotation tool for Information Extraction",
      "detailed_description": "An intuitive annotation tool for Information Extraction and Named Entity Recognition, supporting localturk and Amazon Mechanical Turk workflows.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "data_annotation",
        "information_extraction"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/Varal7/ieturk",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "annotation-tool",
        "ner",
        "crowdsourcing"
      ],
      "id": 74
    },
    {
      "name": "Kairos",
      "one_line_profile": "Scientific conference metadata extraction engine",
      "detailed_description": "A system combining a focused crawler and information extraction engine to harvest and extract metadata from scientific conference websites.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "metadata_extraction",
        "web_crawling"
      ],
      "application_level": "workflow",
      "primary_language": "Java",
      "repo_url": "https://github.com/WING-NUS/Kairos",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "scientific-literature",
        "crawler",
        "information-extraction"
      ],
      "id": 75
    },
    {
      "name": "OpenJERE",
      "one_line_profile": "Joint Entity and Relation Extraction model",
      "detailed_description": "Implementation of a Seq2Seq model for Joint Entity and Relation Extraction, designed to minimize exposure bias.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "joint_extraction",
        "entity_relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/WindChimeRan/OpenJERE",
      "help_website": [],
      "license": null,
      "tags": [
        "seq2seq",
        "joint-extraction",
        "nlp"
      ],
      "id": 76
    },
    {
      "name": "pytorch_multi_head_selection_re",
      "one_line_profile": "Multi-head selection for Joint Entity-Relation Extraction",
      "detailed_description": "A PyTorch implementation of the multi-head selection problem approach for joint entity recognition and relation extraction, supporting BERT.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "joint_extraction",
        "relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/WindChimeRan/pytorch_multi_head_selection_re",
      "help_website": [],
      "license": null,
      "tags": [
        "bert",
        "joint-extraction",
        "multi-head-selection"
      ],
      "id": 77
    },
    {
      "name": "xf_event_extraction_system",
      "one_line_profile": "Complete event extraction system (Challenge Top 1)",
      "detailed_description": "A complete event extraction system and solution that won 1st place in the iFlytek 2020 Event Extraction Challenge.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction",
        "system_integration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/WuHuRestaurant/xf_event_extraction2020Top1",
      "help_website": [],
      "license": null,
      "tags": [
        "event-extraction",
        "competition-solution",
        "chinese-nlp"
      ],
      "id": 78
    },
    {
      "name": "EntityRelationExtraction-Pipeline",
      "one_line_profile": "Pipeline for entity and relation extraction using BiLSTM, CRF, and BERT",
      "detailed_description": "A complete pipeline implementation for named entity recognition and relation extraction tasks, integrating BiLSTM, CRF, and BERT models for information extraction from text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Xie-Minghui/EntityRelationExtraction",
      "help_website": [],
      "license": null,
      "tags": [
        "ner",
        "relation-extraction",
        "bilstm-crf",
        "bert"
      ],
      "id": 79
    },
    {
      "name": "Multilingual_Event_Extraction",
      "one_line_profile": "Tool for ACE-style event extraction on English, Chinese, and Spanish texts",
      "detailed_description": "A Python-based solver for performing event extraction tasks following the ACE (Automatic Content Extraction) schema, supporting multiple languages including English, Chinese, and Spanish.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ahsi/Multilingual_Event_Extraction",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "event-extraction",
        "ace",
        "multilingual-nlp"
      ],
      "id": 80
    },
    {
      "name": "WhisperNER",
      "one_line_profile": "Unified model for open named entity recognition and speech recognition",
      "detailed_description": "The official implementation of WhisperNER, a model that unifies Automatic Speech Recognition (ASR) and Named Entity Recognition (NER), allowing for entity extraction directly from speech or text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "speech_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aiola-lab/whisper-ner",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ner",
        "asr",
        "whisper",
        "speech-to-text"
      ],
      "id": 81
    },
    {
      "name": "DeepEventMine",
      "one_line_profile": "End-to-end neural nested event extraction system for biomedical texts",
      "detailed_description": "A deep learning-based system designed for extracting nested events from biomedical literature, capable of handling complex event structures and achieving state-of-the-art performance on biomedical benchmarks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction",
        "biomedical_ie"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aistairc/DeepEventMine",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "biomedical-nlp",
        "event-extraction",
        "nested-events"
      ],
      "id": 82
    },
    {
      "name": "Unsupervised_NER",
      "one_line_profile": "Unsupervised named entity recognition prototype using pretrained BERT models",
      "detailed_description": "A self-supervised Named Entity Recognition tool that utilizes pretrained BERT models without fine-tuning to extract entities, particularly focused on biomedical datasets.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ajitrajasekharan/unsupervised_NER",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ner",
        "unsupervised-learning",
        "bert",
        "biomedical-nlp"
      ],
      "id": 83
    },
    {
      "name": "pytorch_neural_crf",
      "one_line_profile": "PyTorch implementation of CRF layers for named entity recognition models",
      "detailed_description": "A robust PyTorch implementation of Conditional Random Fields (CRF), commonly used on top of LSTM or BERT models for sequence labeling tasks like Named Entity Recognition.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "sequence_labeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/allanj/pytorch_neural_crf",
      "help_website": [],
      "license": null,
      "tags": [
        "crf",
        "pytorch",
        "ner",
        "sequence-labeling"
      ],
      "id": 84
    },
    {
      "name": "AllenNLP",
      "one_line_profile": "Research library for designing and evaluating deep learning models for NLP",
      "detailed_description": "A comprehensive open-source NLP research library built on PyTorch, providing high-level abstractions and reference implementations for a wide range of NLP tasks including information extraction, semantic parsing, and question answering.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "nlp_framework",
        "information_extraction"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/allennlp",
      "help_website": [
        "https://allennlp.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "deep-learning",
        "pytorch",
        "research-platform"
      ],
      "id": 85
    },
    {
      "name": "AllenNLP Models",
      "one_line_profile": "Collection of state-of-the-art NLP models implemented with AllenNLP",
      "detailed_description": "The official repository containing implementations of core NLP models supported by AllenNLP, including models for NER, constituency parsing, dependency parsing, and semantic role labeling.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "semantic_role_labeling",
        "parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/allennlp-models",
      "help_website": [
        "https://docs.allennlp.org/models/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp-models",
        "ner",
        "srl",
        "pretrained-models"
      ],
      "id": 86
    },
    {
      "name": "AllenNLP Semparse",
      "one_line_profile": "Framework for building semantic parsers and neural module networks",
      "detailed_description": "A specialized library within the AllenNLP ecosystem for constructing semantic parsers, which translate natural language into machine-executable logical forms or SQL.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "semantic_parsing",
        "text_to_sql"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/allennlp-semparse",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "semantic-parsing",
        "nlp",
        "logical-forms"
      ],
      "id": 87
    },
    {
      "name": "AllenTune",
      "one_line_profile": "Hyperparameter search and optimization tool for AllenNLP models",
      "detailed_description": "A library that integrates Ray Tune with AllenNLP to facilitate distributed hyperparameter search and optimization for NLP models.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "hyperparameter_optimization",
        "model_training"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/allentune",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hyperparameter-search",
        "ray-tune",
        "nlp-optimization"
      ],
      "id": 88
    },
    {
      "name": "OpenIE Standalone",
      "one_line_profile": "Scalable open information extraction system for extracting relational tuples",
      "detailed_description": "A standalone Scala-based tool for Open Information Extraction (OpenIE), capable of extracting relational tuples (argument, relation, argument) from massive web-scale text corpora.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "open_information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Scala",
      "repo_url": "https://github.com/allenai/openie-standalone",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "openie",
        "information-extraction",
        "scala"
      ],
      "id": 89
    },
    {
      "name": "scispacy",
      "one_line_profile": "SpaCy pipeline and models specifically designed for biomedical and scientific text",
      "detailed_description": "A comprehensive library containing spaCy pipelines and models optimized for processing biomedical, scientific, and clinical text, including specialized tokenizers, NER models, and entity linkers.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "biomedical_nlp",
        "named_entity_recognition",
        "entity_linking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/scispacy",
      "help_website": [
        "https://allenai.github.io/scispacy/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "spacy",
        "biomedical-nlp",
        "ner",
        "clinical-nlp"
      ],
      "id": 90
    },
    {
      "name": "Amazon Weak NER Needle",
      "one_line_profile": "Named entity recognition model training with weak supervision",
      "detailed_description": "A tool/solver for training Named Entity Recognition (NER) models using a combination of small strongly labeled data and large weakly labeled data, developed by Amazon Science.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "weak_supervision"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/amzn/amazon-weak-ner-needle",
      "help_website": [],
      "license": "MIT-0",
      "tags": [
        "ner",
        "weak-supervision",
        "noise-robustness"
      ],
      "id": 91
    },
    {
      "name": "MindMapper",
      "one_line_profile": "Tool for extracting knowledge graphs and performing network analysis using LLMs",
      "detailed_description": "A Python library that leverages Large Language Models (LLMs) to extract entities and relations from text, construct knowledge graphs, and perform network analysis.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "network_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/andrea-dagostino/mind_mapper",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "knowledge-graph",
        "network-analysis"
      ],
      "id": 92
    },
    {
      "name": "lightspeedGPT",
      "one_line_profile": "High-throughput wrapper for GPT models to perform tasks like NER on large datasets",
      "detailed_description": "A tool designed to process unlimited size inputs using GPT-3.5/4 via multithreading, specifically optimized for tasks like Named Entity Recognition and information extraction on large documents.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "text_processing",
        "named_entity_recognition"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/andrewgcodes/lightspeedGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpt",
        "ner",
        "large-scale-processing",
        "llm-wrapper"
      ],
      "id": 93
    },
    {
      "name": "sift",
      "one_line_profile": "Tool for extracting structured knowledge from web data",
      "detailed_description": "A library/tool for performing knowledge extraction from web pages, facilitating the conversion of unstructured web data into structured formats.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "web_information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/andychisholm/sift",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "web-scraping",
        "information-extraction",
        "structured-data"
      ],
      "id": 94
    },
    {
      "name": "biome-text",
      "one_line_profile": "NLP library for training and deploying custom extraction models",
      "detailed_description": "A library built on AllenNLP and Transformers to facilitate the training and deployment of custom NLP models for tasks like entity extraction and classification.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "text_classification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/argilla-io/biome-text",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "nlp",
        "transformers",
        "allennlp"
      ],
      "id": 95
    },
    {
      "name": "T-NER",
      "one_line_profile": "Transformer-based Named Entity Recognition library",
      "detailed_description": "A Python library for named entity recognition (NER) model training and evaluation, featuring easy-to-use interfaces for transformer-based models and cross-domain evaluation capabilities.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/asahi417/tner",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ner",
        "transformers",
        "nlp"
      ],
      "id": 96
    },
    {
      "name": "GraphRAG-rs",
      "one_line_profile": "Rust implementation of GraphRAG for knowledge graph construction",
      "detailed_description": "A high-performance Rust implementation of the GraphRAG methodology, designed to build knowledge graphs from documents and support retrieval augmented generation tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "rag"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/automataIA/graphrag-rs",
      "help_website": [],
      "license": null,
      "tags": [
        "rust",
        "graphrag",
        "knowledge-graph"
      ],
      "id": 97
    },
    {
      "name": "TweetNLP",
      "one_line_profile": "NLP toolkit specialized for social media text analysis",
      "detailed_description": "A Python library providing state-of-the-art language models for analyzing tweets, including tasks such as named entity recognition, sentiment analysis, and emoji prediction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "social_media_analysis",
        "named_entity_recognition"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cardiffnlp/tweetnlp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "twitter",
        "nlp",
        "ner"
      ],
      "id": 98
    },
    {
      "name": "seqeval",
      "one_line_profile": "Evaluation framework for sequence labeling tasks",
      "detailed_description": "A Python framework specifically designed for evaluating sequence labeling tasks such as named entity recognition (NER) and POS tagging, providing standard metrics like F1 score.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chakki-works/seqeval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation",
        "ner",
        "sequence-labeling"
      ],
      "id": 99
    },
    {
      "name": "CLTK",
      "one_line_profile": "Natural language processing toolkit for classical languages",
      "detailed_description": "The Classical Language Toolkit (CLTK) is a Python library offering NLP support for historical and classical languages, including tokenization, lemmatization, and entity recognition.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "text_processing",
        "linguistics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cltk/cltk",
      "help_website": [
        "http://cltk.org"
      ],
      "license": "MIT",
      "tags": [
        "classical-languages",
        "nlp",
        "digital-humanities"
      ],
      "id": 100
    },
    {
      "name": "semantic-llama",
      "one_line_profile": "LLM-based semantic information extraction tool",
      "detailed_description": "A tool that leverages large language models to extract structured semantic information from text, developed by researchers at LBNL.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "semantic_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cmungall/semantic-llama",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "llm",
        "extraction",
        "semantics"
      ],
      "id": 101
    },
    {
      "name": "GPT4IE",
      "one_line_profile": "GPT-based Information Extraction toolkit",
      "detailed_description": "An open-source toolkit designed to leverage GPT models for various information extraction tasks, simplifying the process of extracting structured data from text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "gpt"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/cocacola-lab/GPT4IE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpt",
        "information-extraction",
        "toolkit"
      ],
      "id": 102
    },
    {
      "name": "am-parser",
      "one_line_profile": "AM dependency parser implementation in AllenNLP",
      "detailed_description": "A modular implementation of an AM (Apply-Modify) dependency parser built on top of the AllenNLP framework, used for linguistic structure analysis.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "dependency_parsing",
        "linguistics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/coli-saar/am-parser",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "parsing",
        "allennlp",
        "dependency-parsing"
      ],
      "id": 103
    },
    {
      "name": "TextRank",
      "one_line_profile": "Python implementation of TextRank for keyword extraction",
      "detailed_description": "A widely used Python implementation of the TextRank algorithm for automatic keyword extraction and text summarization.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "keyword_extraction",
        "summarization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/davidadamojr/TextRank",
      "help_website": [],
      "license": null,
      "tags": [
        "textrank",
        "summarization",
        "nlp"
      ],
      "id": 104
    },
    {
      "name": "crosslingual-coreference",
      "one_line_profile": "Multi-lingual coreference resolution wrapper for AllenNLP and spaCy",
      "detailed_description": "A Python library that provides a multi-lingual approach to Coreference Resolution using AllenNLP models, wrapped for easy integration with the spaCy NLP pipeline.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "coreference_resolution",
        "entity_linking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/davidberenstein1957/crosslingual-coreference",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "coreference-resolution",
        "spacy-extension",
        "allennlp",
        "multilingual"
      ],
      "id": 105
    },
    {
      "name": "flaiR",
      "one_line_profile": "R wrapper for the Flair NLP library",
      "detailed_description": "An R package that provides an interface to the state-of-the-art Flair NLP library (Python), enabling R users to perform named entity recognition, part-of-speech tagging, and text classification.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "pos_tagging"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/davidycliao/flaiR",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "r-package",
        "flair",
        "nlp",
        "ner"
      ],
      "id": 106
    },
    {
      "name": "DeepPavlov NER",
      "one_line_profile": "Named Entity Recognition component of the DeepPavlov framework",
      "detailed_description": "A dedicated repository/component for Named Entity Recognition within the DeepPavlov conversational AI framework, providing pre-trained models and pipelines for extracting entities from text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deeppavlov/ner",
      "help_website": [
        "http://docs.deeppavlov.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ner",
        "deeppavlov",
        "nlp",
        "entity-extraction"
      ],
      "id": 107
    },
    {
      "name": "rsnltk",
      "one_line_profile": "Rust-based Natural Language Toolkit with Python bindings",
      "detailed_description": "A Natural Language Processing toolkit written in Rust, offering high-performance text processing capabilities with Python bindings for integration into Python-based research workflows.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "text_processing",
        "nlp_toolkit"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/dhchenx/rsnltk",
      "help_website": [],
      "license": null,
      "tags": [
        "rust",
        "nlp",
        "python-bindings",
        "text-processing"
      ],
      "id": 108
    },
    {
      "name": "FOX",
      "one_line_profile": "Federated Knowledge Extraction Framework",
      "detailed_description": "A framework for Federated Knowledge Extraction that integrates various Named Entity Recognition and Relation Extraction algorithms to extract RDF triples from natural language text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "rdf_extraction"
      ],
      "application_level": "framework",
      "primary_language": "Java",
      "repo_url": "https://github.com/dice-group/FOX",
      "help_website": [
        "http://aksw.org/Projects/FOX"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "knowledge-extraction",
        "rdf",
        "semantic-web",
        "ner"
      ],
      "id": 109
    },
    {
      "name": "dket",
      "one_line_profile": "Deep Knowledge Extraction from Text library",
      "detailed_description": "A Python library designed for Deep Knowledge Extraction from text, facilitating the extraction of structured information for knowledge graph construction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "ie"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dkmfbk/dket",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "knowledge-extraction",
        "nlp",
        "deep-learning"
      ],
      "id": 110
    },
    {
      "name": "Bio-Epidemiology-NER",
      "one_line_profile": "Biomedical entity recognition tool",
      "detailed_description": "A specialized Named Entity Recognition tool designed to recognize bio-medical entities from text corpora, useful for epidemiological research and biomedical text mining.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "biomedical_ner",
        "entity_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dreji18/Bio-Epidemiology-NER",
      "help_website": [],
      "license": null,
      "tags": [
        "biomedical-ner",
        "epidemiology",
        "nlp",
        "bioinformatics"
      ],
      "id": 111
    },
    {
      "name": "dygiepp",
      "one_line_profile": "Span-based system for entity, relation, and event extraction",
      "detailed_description": "A robust, span-based information extraction system capable of performing named entity recognition, relation extraction, and event extraction jointly. It serves as a reference implementation for several state-of-the-art IE models.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "event_extraction",
        "ner"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dwadden/dygiepp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "information-extraction",
        "relation-extraction",
        "event-extraction",
        "nlp"
      ],
      "id": 112
    },
    {
      "name": "pytorch-bert-crf-ner",
      "one_line_profile": "BERT-CRF based Named Entity Recognition for Korean",
      "detailed_description": "A PyTorch implementation of a Named Entity Recognition model using KoBERT and CRF, serving as a practical tool for extracting entities from Korean text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/eagle705/pytorch-bert-crf-ner",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "korean-nlp",
        "ner",
        "bert",
        "crf"
      ],
      "id": 113
    },
    {
      "name": "TextEE",
      "one_line_profile": "Benchmark toolkit for Event Extraction",
      "detailed_description": "A standardized, fair, and reproducible benchmark toolkit for evaluating event extraction approaches, providing unified data processing and model evaluation interfaces.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction",
        "benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ej0cl6/TextEE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "event-extraction",
        "benchmark",
        "nlp",
        "evaluation"
      ],
      "id": 114
    },
    {
      "name": "SpikeX",
      "one_line_profile": "SpaCy pipes for Knowledge Extraction",
      "detailed_description": "A collection of spaCy pipes and extensions designed to facilitate Knowledge Extraction tasks, including pattern matching and graph-based extraction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "pattern_matching"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/erre-quadro/spikex",
      "help_website": [
        "https://erre-quadro.github.io/spikex/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "spacy-extension",
        "knowledge-extraction",
        "nlp",
        "pattern-matching"
      ],
      "id": 115
    },
    {
      "name": "productner",
      "one_line_profile": "Product categorization and NER tool",
      "detailed_description": "A library providing algorithms to categorize products and perform named entity recognition on words in product descriptions, useful for e-commerce knowledge graph construction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "product_categorization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/etano/productner",
      "help_website": [],
      "license": null,
      "tags": [
        "ner",
        "product-categorization",
        "nlp",
        "e-commerce"
      ],
      "id": 116
    },
    {
      "name": "spacy-stanza",
      "one_line_profile": "Stanza wrapper for spaCy pipeline",
      "detailed_description": "A wrapper library that allows using the latest Stanza (StanfordNLP) research models directly within the spaCy NLP pipeline, combining Stanza's accuracy with spaCy's usability.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "nlp_pipeline",
        "named_entity_recognition",
        "dependency_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/explosion/spacy-stanza",
      "help_website": [
        "https://spacy.io/universe/project/spacy-stanza"
      ],
      "license": "MIT",
      "tags": [
        "spacy",
        "stanza",
        "stanfordnlp",
        "wrapper"
      ],
      "id": 117
    },
    {
      "name": "GLiNER2",
      "one_line_profile": "Unified Schema-Based Information Extraction",
      "detailed_description": "A tool for Generalist and Lightweight Named Entity Recognition (GLiNER) that enables unified schema-based information extraction, allowing for flexible and efficient entity extraction across various domains.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/fastino-ai/GLiNER2",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ner",
        "information-extraction",
        "gliner",
        "nlp"
      ],
      "id": 118
    },
    {
      "name": "cocoNLP",
      "one_line_profile": "Chinese information extraction tool",
      "detailed_description": "A comprehensive Chinese information extraction tool capable of extracting various entities such as names, times, locations, and phone numbers from text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "chinese_ner"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/fighting41love/cocoNLP",
      "help_website": [],
      "license": null,
      "tags": [
        "chinese-nlp",
        "information-extraction",
        "ner",
        "text-mining"
      ],
      "id": 119
    },
    {
      "name": "Flair",
      "one_line_profile": "State-of-the-art Natural Language Processing framework",
      "detailed_description": "A powerful and simple NLP framework that provides state-of-the-art models for named entity recognition (NER), part-of-speech tagging (PoS), and text classification, often used for building knowledge extraction pipelines.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "pos_tagging",
        "text_classification"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/flairNLP/flair",
      "help_website": [
        "https://github.com/flairNLP/flair"
      ],
      "license": "NOASSERTION",
      "tags": [
        "nlp",
        "ner",
        "deep-learning",
        "pytorch"
      ],
      "id": 120
    },
    {
      "name": "flair-lms",
      "one_line_profile": "Language Models extension for Flair library",
      "detailed_description": "A repository providing language models and integration scripts for the Flair NLP library, extending its capabilities with pre-trained embeddings and models.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "language_modeling",
        "model_hosting"
      ],
      "application_level": "library",
      "primary_language": null,
      "repo_url": "https://github.com/flairNLP/flair-lms",
      "help_website": [],
      "license": null,
      "tags": [
        "flair",
        "language-models",
        "embeddings"
      ],
      "id": 121
    },
    {
      "name": "BenchIE",
      "one_line_profile": "Comprehensive evaluation framework for Open Information Extraction systems",
      "detailed_description": "BenchIE is a benchmarking framework designed to evaluate Open Information Extraction (OIE) systems. It provides metrics and protocols to assess the quality of extracted facts, facilitating comparative analysis of different OIE models.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/gkiril/benchie",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "open-information-extraction",
        "evaluation",
        "benchmark",
        "nlp"
      ],
      "id": 122
    },
    {
      "name": "LSTM-CRF Tagger",
      "one_line_profile": "Classic Named Entity Recognition tool using LSTM and CRF",
      "detailed_description": "A standalone implementation of the LSTM-CRF architecture for Named Entity Recognition (NER). It serves as a robust baseline and tool for sequence tagging tasks in NLP research.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "sequence_tagging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/glample/tagger",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ner",
        "lstm-crf",
        "sequence-tagging",
        "nlp"
      ],
      "id": 123
    },
    {
      "name": "T-REx",
      "one_line_profile": "Large scale alignment pipeline for Relation Extraction datasets",
      "detailed_description": "A pipeline tool for aligning natural language text with Knowledge Base triples (Wikidata). It is used to generate large-scale datasets for relation extraction and natural language generation tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "data_alignment",
        "dataset_generation"
      ],
      "application_level": "workflow",
      "primary_language": "HTML",
      "repo_url": "https://github.com/hadyelsahar/t-rex",
      "help_website": [],
      "license": null,
      "tags": [
        "relation-extraction",
        "knowledge-base",
        "alignment",
        "dataset-generation"
      ],
      "id": 124
    },
    {
      "name": "HanLP",
      "one_line_profile": "Multilingual NLP library for extraction and parsing",
      "detailed_description": "A comprehensive Natural Language Processing library supporting multiple languages. It provides efficient tools for lexical analysis, named entity recognition, dependency parsing, and text classification.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "parsing",
        "tokenization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hankcs/HanLP",
      "help_website": [
        "https://hanlp.hankcs.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "ner",
        "parsing",
        "multilingual"
      ],
      "id": 125
    },
    {
      "name": "Chatbot NER",
      "one_line_profile": "Named Entity Recognition library for conversational AI",
      "detailed_description": "A specialized Named Entity Recognition library designed for chatbots and conversational agents. It focuses on extracting entities from short, informal, and conversational text inputs.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hellohaptik/chatbot_ner",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "ner",
        "chatbot",
        "conversational-ai"
      ],
      "id": 126
    },
    {
      "name": "AllenNLP Optuna",
      "one_line_profile": "Hyperparameter optimization plugin for AllenNLP",
      "detailed_description": "A plugin for the AllenNLP framework that integrates Optuna, enabling efficient hyperparameter optimization for Natural Language Processing models, including those used for extraction tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "optimization",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/himkt/allennlp-optuna",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "allennlp",
        "optuna",
        "hyperparameter-optimization"
      ],
      "id": 127
    },
    {
      "name": "GoLLIE",
      "one_line_profile": "Guideline-following Large Language Model for Information Extraction",
      "detailed_description": "A Large Language Model fine-tuned to follow annotation guidelines for Information Extraction. It allows for zero-shot extraction of entities and relations by defining tasks through guidelines.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "relation_extraction",
        "zero_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hitz-zentroa/GoLLIE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "information-extraction",
        "zero-shot",
        "guideline-following"
      ],
      "id": 128
    },
    {
      "name": "EventMiner",
      "one_line_profile": "Pipeline for event extraction from text",
      "detailed_description": "A software pipeline for extracting events from unstructured text, developed by the HLTCOE. It processes text to identify event triggers and arguments.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/hltcoe/EventMiner",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "event-extraction",
        "nlp",
        "pipeline"
      ],
      "id": 129
    },
    {
      "name": "Golden Horse",
      "one_line_profile": "Named Entity Recognition for Chinese social media",
      "detailed_description": "A Named Entity Recognition tool specifically optimized for Chinese social media text (e.g., Weibo). It addresses the challenges of noisy, informal text in entity extraction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hltcoe/golden-horse",
      "help_website": [],
      "license": null,
      "tags": [
        "ner",
        "chinese-nlp",
        "social-media"
      ],
      "id": 130
    },
    {
      "name": "HuNER",
      "one_line_profile": "Named Entity Recognition for biomedical entities",
      "detailed_description": "A lightweight Named Entity Recognition tool tailored for the biomedical domain. It is designed to extract specific biomedical entities from scientific literature.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "bio_ner"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hu-ner/huner",
      "help_website": [],
      "license": null,
      "tags": [
        "ner",
        "biomedical",
        "nlp"
      ],
      "id": 131
    },
    {
      "name": "HMTL",
      "one_line_profile": "Hierarchical Multi-Task Learning for NLP",
      "detailed_description": "A neural network framework for Hierarchical Multi-Task Learning (HMTL) based on PyTorch and AllenNLP. It enables the simultaneous training of multiple NLP tasks, such as NER, relation extraction, and mention detection.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "multi_task_learning",
        "entity_extraction",
        "relation_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/hmtl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multi-task-learning",
        "nlp",
        "allennlp",
        "pytorch"
      ],
      "id": 132
    },
    {
      "name": "Dedoc",
      "one_line_profile": "Universal document parsing and structure extraction library",
      "detailed_description": "A library for automating document parsing and content extraction. It converts various document formats (PDF, DOCX, HTML) into a uniform structure, extracting text, tables, and metadata, which is essential for downstream IE and KG tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "document_parsing",
        "structure_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ispras/dedoc",
      "help_website": [
        "https://dedoc.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "document-parsing",
        "pdf-extraction",
        "structure-extraction"
      ],
      "id": 133
    },
    {
      "name": "Zero-Shot Entity Linking",
      "one_line_profile": "Tool for Zero-Shot Entity Linking with bi-encoders",
      "detailed_description": "A tool designed for Zero-Shot Entity Linking, enabling the linking of entities to a knowledge base without domain-specific training. It includes implementations for hard negative mining and entity encoding.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_linking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/izuna385/Zero-Shot-Entity-Linking",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "entity-linking",
        "zero-shot",
        "bi-encoder"
      ],
      "id": 134
    },
    {
      "name": "GLiREL",
      "one_line_profile": "Generalist and Lightweight Model for Relation Extraction",
      "detailed_description": "A generalist model for Relation Extraction that can extract arbitrary relationship types from text. It is designed to be lightweight and applicable to various domains without extensive retraining.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jackboyla/GLiREL",
      "help_website": [],
      "license": null,
      "tags": [
        "relation-extraction",
        "zero-shot",
        "nlp"
      ],
      "id": 135
    },
    {
      "name": "Kindred",
      "one_line_profile": "Biomedical relation extraction package",
      "detailed_description": "A Python package specifically for biomedical relation extraction. It uses a supervised learning approach to identify relationships between biomedical entities in text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "bio_nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jakelever/kindred",
      "help_website": [
        "http://kindred.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "relation-extraction",
        "biomedical",
        "nlp"
      ],
      "id": 136
    },
    {
      "name": "TEES",
      "one_line_profile": "Turku Event Extraction System for biomedical text mining",
      "detailed_description": "A renowned biomedical event extraction system that detects complex events and relations in scientific literature, widely used in BioNLP shared tasks.",
      "domains": [
        "G2",
        "G2-01",
        "BioNLP"
      ],
      "subtask_category": [
        "event_extraction",
        "relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jbjorne/TEES",
      "help_website": [],
      "license": null,
      "tags": [
        "bionlp",
        "event-extraction",
        "biomedical-text-mining"
      ],
      "id": 137
    },
    {
      "name": "NCRF++",
      "one_line_profile": "Neural Sequence Labeling Toolkit for NER and POS tagging",
      "detailed_description": "A flexible and efficient neural sequence labeling toolkit that supports various character/word-level neural encoders (LSTM/CNN) and CRF decoding for tasks like Named Entity Recognition.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "sequence_labeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jiesutd/NCRFpp",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ner",
        "sequence-labeling",
        "pytorch"
      ],
      "id": 138
    },
    {
      "name": "Biaffine NER",
      "one_line_profile": "Named Entity Recognition model treating NER as dependency parsing",
      "detailed_description": "An implementation of NER that reformulates the task as dependency parsing using biaffine attention mechanisms, offering high performance on nested and flat entities.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "dependency_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/juntaoy/biaffine-ner",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ner",
        "biaffine-attention",
        "nlp"
      ],
      "id": 139
    },
    {
      "name": "FLAIR (Retina)",
      "one_line_profile": "Foundation Language-Image model for fundus image understanding",
      "detailed_description": "A foundation model designed for analyzing retinal fundus images by integrating language and image modalities, useful for medical diagnosis and analysis.",
      "domains": [
        "Medical Imaging",
        "G2"
      ],
      "subtask_category": [
        "medical_image_analysis",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jusiro/FLAIR",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "retina",
        "fundus-image",
        "foundation-model"
      ],
      "id": 140
    },
    {
      "name": "ACES",
      "one_line_profile": "Automatic Cohort Extraction System for Event-Streams",
      "detailed_description": "A system for automatically extracting patient cohorts from electronic health record event streams, facilitating clinical research and data analysis.",
      "domains": [
        "Healthcare",
        "G2"
      ],
      "subtask_category": [
        "cohort_extraction",
        "clinical_data_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/justin13601/ACES",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ehr",
        "cohort-extraction",
        "healthcare"
      ],
      "id": 141
    },
    {
      "name": "BERT-NER (Pytorch)",
      "one_line_profile": "PyTorch implementation of BERT for Named Entity Recognition",
      "detailed_description": "A widely used PyTorch implementation for fine-tuning BERT models on Named Entity Recognition tasks, serving as a standard tool for NER.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kamalkraj/BERT-NER",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "bert",
        "ner",
        "pytorch"
      ],
      "id": 142
    },
    {
      "name": "BERT-NER-TF",
      "one_line_profile": "TensorFlow 2.0 implementation of BERT for Named Entity Recognition",
      "detailed_description": "A TensorFlow 2.0 implementation for performing Named Entity Recognition using BERT embeddings, providing a tool for NER tasks in TF environments.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kamalkraj/BERT-NER-TF",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bert",
        "ner",
        "tensorflow"
      ],
      "id": 143
    },
    {
      "name": "BiLSTM-CNN-NER",
      "one_line_profile": "Bi-directional LSTM and CNN architecture for Named Entity Recognition",
      "detailed_description": "An implementation of the classic BiLSTM-CNN-CRF architecture for Named Entity Recognition, serving as a baseline tool for sequence labeling.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kamalkraj/Named-Entity-Recognition-with-Bidirectional-LSTM-CNNs",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bilstm",
        "cnn",
        "ner"
      ],
      "id": 144
    },
    {
      "name": "clinspacy",
      "one_line_profile": "Clinical Natural Language Processing pipeline for R",
      "detailed_description": "An R package that interfaces with spaCy, scispacy, and medspacy to perform clinical natural language processing tasks such as entity recognition and negation detection.",
      "domains": [
        "G2",
        "G2-01",
        "Clinical NLP"
      ],
      "subtask_category": [
        "clinical_nlp",
        "named_entity_recognition"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/kdpsingh/clinspacy",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "r",
        "clinical-nlp",
        "spacy"
      ],
      "id": 145
    },
    {
      "name": "GROBID",
      "one_line_profile": "Machine learning software for extracting information from scholarly documents",
      "detailed_description": "A powerful machine learning library for extracting, parsing, and restructuring raw documents (PDFs) into structured XML/TEI, focusing on technical and scientific publications.",
      "domains": [
        "G2",
        "G2-01",
        "Scientific Literature"
      ],
      "subtask_category": [
        "document_parsing",
        "information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/kermitt2/grobid",
      "help_website": [
        "https://grobid.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "pdf-parsing",
        "scientific-literature",
        "tei"
      ],
      "id": 146
    },
    {
      "name": "StrainFLAIR",
      "one_line_profile": "Strain-level abundance estimation in metagenomic samples",
      "detailed_description": "A bioinformatics tool for estimating strain-level abundances in metagenomic samples using variation graphs, aiding in microbiome analysis.",
      "domains": [
        "Bioinformatics",
        "G2"
      ],
      "subtask_category": [
        "metagenomic_profiling",
        "abundance_estimation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kevsilva/StrainFLAIR",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "metagenomics",
        "strain-quantification",
        "variation-graphs"
      ],
      "id": 147
    },
    {
      "name": "OpenIE",
      "one_line_profile": "Web-scale Open Information Extraction system",
      "detailed_description": "A system for extracting relational tuples from text without requiring a pre-specified schema, designed for web-scale information extraction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "open_information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Scala",
      "repo_url": "https://github.com/knowitall/openie",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "openie",
        "information-extraction",
        "scala"
      ],
      "id": 148
    },
    {
      "name": "ReVerb",
      "one_line_profile": "Web-Scale Open Information Extraction tool",
      "detailed_description": "An open information extraction tool that identifies and extracts binary relationships from English sentences, optimized for web-scale processing.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "open_information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/knowitall/reverb",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "openie",
        "relation-extraction",
        "java"
      ],
      "id": 149
    },
    {
      "name": "BERT-NER (Google BERT)",
      "one_line_profile": "BERT-based Named Entity Recognition implementation",
      "detailed_description": "A popular implementation of Named Entity Recognition using Google's BERT model, widely used as a baseline and tool for extracting entities from text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kyzhouhzau/BERT-NER",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bert",
        "ner",
        "nlp"
      ],
      "id": 150
    },
    {
      "name": "Clinical-NER",
      "one_line_profile": "Named Entity Recognition for Chinese Electronic Medical Records",
      "detailed_description": "A tool designed for extracting named entities from Chinese electronic medical records (EMR), supporting clinical informatics research.",
      "domains": [
        "G2",
        "G2-01",
        "Clinical NLP"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "clinical_nlp"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/kyzhouhzau/Clinical-NER",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "clinical-ner",
        "emr",
        "chinese-nlp"
      ],
      "id": 151
    },
    {
      "name": "JEREX",
      "one_line_profile": "Joint Entity-Level Relation Extractor",
      "detailed_description": "A PyTorch implementation for joint entity and relation extraction, capable of handling multi-label relations and entity overlaps.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "joint_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lavis-nlp/jerex",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "relation-extraction",
        "joint-learning",
        "pytorch"
      ],
      "id": 152
    },
    {
      "name": "SpERT",
      "one_line_profile": "Span-based Entity and Relation Transformer",
      "detailed_description": "A span-based joint entity and relation extraction model using BERT, widely used for extracting structured information from text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "named_entity_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lavis-nlp/spert",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "spert",
        "relation-extraction",
        "bert"
      ],
      "id": 153
    },
    {
      "name": "NERRE",
      "one_line_profile": "Structured information extraction from scientific text",
      "detailed_description": "A tool for extracting structured information (entities and relations) from scientific texts, developed by LBNL, utilizing large language models.",
      "domains": [
        "G2",
        "G2-01",
        "Scientific Literature"
      ],
      "subtask_category": [
        "information_extraction",
        "scientific_text_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lbnlp/NERRE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scientific-ie",
        "llm",
        "material-science"
      ],
      "id": 154
    },
    {
      "name": "NER-BERT-pytorch",
      "one_line_profile": "PyTorch solution for Named Entity Recognition using BERT",
      "detailed_description": "A PyTorch-based solution for Named Entity Recognition tasks leveraging pre-trained BERT models, providing a reusable pipeline for NER.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lemonhu/NER-BERT-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ner",
        "bert",
        "pytorch"
      ],
      "id": 155
    },
    {
      "name": "Open Entity Relation Extraction",
      "one_line_profile": "Knowledge triple extraction based on dependency syntax",
      "detailed_description": "A tool for extracting knowledge triples and constructing knowledge bases from open-domain text using dependency syntax analysis.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "open_information_extraction",
        "knowledge_graph_construction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lemonhu/open-entity-relation-extraction",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "openie",
        "dependency-parsing",
        "knowledge-graph"
      ],
      "id": 156
    },
    {
      "name": "OpenIE-Spider",
      "one_line_profile": "Web corpus information extraction spider",
      "detailed_description": "A tool designed to crawl and extract information from web corpora using Open Information Extraction techniques, suitable for building large-scale knowledge bases.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "open_information_extraction",
        "web_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liaoziyang/OpenIE-Spider",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "openie",
        "spider",
        "web-mining"
      ],
      "id": 157
    },
    {
      "name": "bio-ner",
      "one_line_profile": "Biomedical Named Entity Recognition and Normalization library",
      "detailed_description": "A library for Biomedical Named Entity Recognition and Normalization of Diseases, Chemicals, and Genetic entity classes using state-of-the-art models.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "entity_normalization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/librairy/bio-ner",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bio-ner",
        "biomedical",
        "entity-normalization"
      ],
      "id": 158
    },
    {
      "name": "Event-Extraction",
      "one_line_profile": "Comprehensive collection of event extraction models and implementations",
      "detailed_description": "A toolkit summarizing and implementing various event extraction methods including Chinese, Open Domain, Cross-lingual, and Few-shot event extraction using models like DMCNN, JMEE, and PLMEE.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction",
        "relation_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/liqian-bio/Event-Extraction",
      "help_website": [],
      "license": null,
      "tags": [
        "event-extraction",
        "nlp",
        "chinese-nlp"
      ],
      "id": 159
    },
    {
      "name": "NER-LSTM-CRF",
      "one_line_profile": "Easy-to-use Bi-LSTM+CRF toolkit for Named Entity Recognition",
      "detailed_description": "A TensorFlow-based toolkit implementing the Bi-LSTM+CRF model for Named Entity Recognition tasks, designed for ease of use.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liu-nlper/NER-LSTM-CRF",
      "help_website": [],
      "license": null,
      "tags": [
        "ner",
        "bi-lstm-crf",
        "tensorflow"
      ],
      "id": 160
    },
    {
      "name": "BaikeInfoExtraction",
      "one_line_profile": "Structured information extraction tool for Chinese encyclopedias",
      "detailed_description": "A tool for extracting structured infobox information from Chinese encyclopedias (Baidu Baike, Hudong Baike, Sogou Baike) to support knowledge fusion.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "infobox_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liuhuanyong/BaikeInfoExtraction",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-extraction",
        "baike",
        "infobox"
      ],
      "id": 161
    },
    {
      "name": "CausalityEventExtraction",
      "one_line_profile": "Causality event extraction and knowledge graph construction tool",
      "detailed_description": "A project for extracting causal events based on explicit patterns and large-scale corpora, enabling the construction of causality event knowledge graphs.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction",
        "causality_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liuhuanyong/CausalityEventExtraction",
      "help_website": [],
      "license": null,
      "tags": [
        "causality",
        "event-extraction",
        "knowledge-graph"
      ],
      "id": 162
    },
    {
      "name": "ComplexEventExtraction",
      "one_line_profile": "Chinese complex event extraction and logic graph construction tool",
      "detailed_description": "A tool for extracting Chinese compound events (conditional, causal, sequential, reversal) based on explicit patterns to form an event logic graph.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction",
        "logic_graph"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liuhuanyong/ComplexEventExtraction",
      "help_website": [],
      "license": null,
      "tags": [
        "complex-event",
        "chinese-nlp",
        "event-logic"
      ],
      "id": 163
    },
    {
      "name": "EventTriplesExtraction",
      "one_line_profile": "Event triple extraction tool based on dependency parsing",
      "detailed_description": "A tool for extracting event triples using dependency parsing and semantic role labeling, useful for constructing event chains and topic graphs.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "triple_extraction",
        "event_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liuhuanyong/EventTriplesExtraction",
      "help_website": [],
      "license": null,
      "tags": [
        "triple-extraction",
        "dependency-parsing",
        "event-chain"
      ],
      "id": 164
    },
    {
      "name": "MedicalNamedEntityRecognition",
      "one_line_profile": "Medical Named Entity Recognition tool for Chinese EMRs",
      "detailed_description": "A medical NER implementation using Bi-LSTM+CRF with character embeddings, originally for CCKS2017 but widely used as a baseline tool for Chinese electronic medical records.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "medical_ner"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liuhuanyong/MedicalNamedEntityRecognition",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-ner",
        "emr",
        "bi-lstm-crf"
      ],
      "id": 165
    },
    {
      "name": "PersonRelationKnowledgeGraph",
      "one_line_profile": "Chinese person relation extraction and knowledge graph tool",
      "detailed_description": "A project for constructing Chinese person relation graphs, including relation extraction based on remote supervision and bootstrapping methods.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "knowledge_graph_construction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liuhuanyong/PersonRelationKnowledgeGraph",
      "help_website": [],
      "license": null,
      "tags": [
        "relation-extraction",
        "knowledge-graph",
        "person-relation"
      ],
      "id": 166
    },
    {
      "name": "transformers-ner",
      "one_line_profile": "PyTorch NER toolkit using Transformers",
      "detailed_description": "A PyTorch-based Named Entity Recognition toolkit leveraging Transformer models, providing a standard interface for NER tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liuyukid/transformers-ner",
      "help_website": [],
      "license": null,
      "tags": [
        "ner",
        "transformers",
        "pytorch"
      ],
      "id": 167
    },
    {
      "name": "ace2005chinese_preprocess",
      "one_line_profile": "Preprocessing scripts for ACE 2005 Chinese corpus",
      "detailed_description": "A utility tool for preprocessing the ACE 2005 corpus specifically for Event Extraction tasks, facilitating data preparation.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "data_preprocessing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ll0ruc/ace2005chinese_preprocess",
      "help_website": [],
      "license": null,
      "tags": [
        "ace2005",
        "preprocessing",
        "event-extraction"
      ],
      "id": 168
    },
    {
      "name": "BERT-NER-Pytorch",
      "one_line_profile": "Chinese NER toolkit using BERT",
      "detailed_description": "A widely used toolkit for Chinese Named Entity Recognition implementing BERT with various decoding layers (Softmax, CRF, Span).",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lonePatient/BERT-NER-Pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ner",
        "bert",
        "chinese-nlp"
      ],
      "id": 169
    },
    {
      "name": "DeepIE",
      "one_line_profile": "Deep Learning toolkit for Information Extraction",
      "detailed_description": "A comprehensive deep learning framework/toolkit designed for various Information Extraction tasks, including entity and relation extraction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "relation_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/loujie0822/DeepIE",
      "help_website": [],
      "license": null,
      "tags": [
        "information-extraction",
        "deep-learning",
        "nlp"
      ],
      "id": 170
    },
    {
      "name": "Odinson",
      "one_line_profile": "Fast rule-based information extraction framework",
      "detailed_description": "A powerful and highly optimized open-source framework for rule-based information extraction, featuring a pattern language and near real-time runtime system.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "rule_based_extraction"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/lum-ai/odinson",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "information-extraction",
        "rule-based",
        "scala"
      ],
      "id": 171
    },
    {
      "name": "named_entity_recognition",
      "one_line_profile": "Collection of Chinese NER model implementations",
      "detailed_description": "A toolkit containing implementations of various models for Chinese Named Entity Recognition, including HMM, CRF, BiLSTM, and BiLSTM+CRF.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/luopeixiang/named_entity_recognition",
      "help_website": [],
      "license": null,
      "tags": [
        "ner",
        "chinese-nlp",
        "bilstm-crf"
      ],
      "id": 172
    },
    {
      "name": "IEPY",
      "one_line_profile": "Information Extraction framework in Python",
      "detailed_description": "An open-source tool for Information Extraction focused on Relation Extraction, providing a framework for building custom extraction pipelines.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "relation_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/machinalis/iepy",
      "help_website": [
        "http://iepy.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "information-extraction",
        "python",
        "relation-extraction"
      ],
      "id": 173
    },
    {
      "name": "Malaya",
      "one_line_profile": "Natural Language Toolkit for Malaysian language",
      "detailed_description": "A comprehensive Natural Language Toolkit for the Malaysian language, including modules for entity extraction and other NLP tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "nlp_toolkit"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/malaysia-ai/malaya",
      "help_website": [
        "https://malaya.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "malaysian-nlp",
        "nlp-toolkit",
        "entity-extraction"
      ],
      "id": 174
    },
    {
      "name": "brain-segmentation-pytorch",
      "one_line_profile": "U-Net implementation for brain MRI segmentation",
      "detailed_description": "A PyTorch implementation of U-Net specifically designed for FLAIR abnormality segmentation in brain MRI datasets.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "image_segmentation",
        "medical_imaging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mateuszbuda/brain-segmentation-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "brain-mri",
        "segmentation",
        "u-net"
      ],
      "id": 175
    },
    {
      "name": "pytorch-truecaser",
      "one_line_profile": "Neural truecasing tool for NLP preprocessing",
      "detailed_description": "A simple neural truecaser implemented in PyTorch and AllenNLP, useful for text preprocessing in NLP pipelines.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "text_normalization",
        "preprocessing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mayhewsw/pytorch-truecaser",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "truecasing",
        "preprocessing",
        "nlp"
      ],
      "id": 176
    },
    {
      "name": "Conversation-Knowledge-Mining-Solution-Accelerator",
      "one_line_profile": "Knowledge mining solution accelerator using Azure AI",
      "detailed_description": "A solution accelerator leveraging Azure AI for extracting insights, key phrases, and topics from conversational data, enabling knowledge mining.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_mining",
        "keyphrase_extraction"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/Conversation-Knowledge-Mining-Solution-Accelerator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-mining",
        "azure-ai",
        "nlp"
      ],
      "id": 177
    },
    {
      "name": "Presidio Research",
      "one_line_profile": "Evaluation and development package for PII detection models",
      "detailed_description": "A Python package containing data-science tasks for developing, evaluating, and improving PII (Personally Identifiable Information) recognizers within the Presidio ecosystem. It facilitates the creation of synthetic datasets and the benchmarking of PII detection models.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "pii_detection",
        "model_evaluation",
        "data_anonymization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/microsoft/presidio-research",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pii",
        "privacy",
        "evaluation",
        "nlp"
      ],
      "id": 178
    },
    {
      "name": "VERT",
      "one_line_profile": "Versatile Entity Recognition and Disambiguation Toolkit",
      "detailed_description": "A toolkit and collection of code/datasets for entity recognition and disambiguation, developed by Microsoft Research Asia. It supports research into versatile entity linking and knowledge extraction tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_recognition",
        "entity_disambiguation",
        "knowledge_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/vert-papers",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ner",
        "entity-linking",
        "knowledge-graph"
      ],
      "id": 179
    },
    {
      "name": "MALLET",
      "one_line_profile": "Machine Learning for Language Toolkit",
      "detailed_description": "A Java-based package for statistical natural language processing, document classification, clustering, topic modeling, information extraction, and other machine learning applications to text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "topic_modeling",
        "information_extraction",
        "document_classification"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/mimno/Mallet",
      "help_website": [
        "http://mallet.cs.umass.edu/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "nlp",
        "topic-modeling",
        "machine-learning",
        "java"
      ],
      "id": 180
    },
    {
      "name": "TweebankNLP",
      "one_line_profile": "Pre-trained NLP toolkit for Social Media (Tweets)",
      "detailed_description": "An off-the-shelf pre-trained NLP toolkit specifically designed for processing tweets. It supports Named Entity Recognition (NER), tokenization, lemmatization, POS tagging, and dependency parsing on social media text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "social_media_mining",
        "ner",
        "pos_tagging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mit-ccc/TweebankNLP",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "twitter",
        "nlp",
        "ner",
        "social-media"
      ],
      "id": 181
    },
    {
      "name": "MITIE",
      "one_line_profile": "Library and tools for information extraction",
      "detailed_description": "A C++ library (with Python, R, Java, C bindings) for information extraction, providing state-of-the-art named entity recognition and binary relation detection capabilities.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "ner",
        "relation_extraction"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/mit-nlp/MITIE",
      "help_website": [],
      "license": "Boost Software License",
      "tags": [
        "c++",
        "information-extraction",
        "ner"
      ],
      "id": 182
    },
    {
      "name": "spacy-clausie",
      "one_line_profile": "ClausIE information extraction system for spaCy",
      "detailed_description": "A Python implementation of the ClausIE (Clause-based Open Information Extraction) system, integrated with the spaCy NLP library to extract propositions and relations from text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "open_information_extraction",
        "relation_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mmxgn/spacy-clausie",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "spacy",
        "open-ie",
        "clausie"
      ],
      "id": 183
    },
    {
      "name": "infoboxer",
      "one_line_profile": "Wikipedia information extraction library",
      "detailed_description": "A Ruby library designed to extract structured data from Wikipedia Infoboxes and other semantic parts of MediaWiki pages, useful for constructing knowledge bases from Wikipedia.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "wikipedia_mining"
      ],
      "application_level": "library",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/molybdenum-99/infoboxer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wikipedia",
        "extraction",
        "ruby"
      ],
      "id": 184
    },
    {
      "name": "ner-lstm",
      "one_line_profile": "Bi-LSTM based Named Entity Recognition",
      "detailed_description": "An implementation of Named Entity Recognition using multilayered bidirectional LSTMs. It serves as a reusable baseline or tool for training custom NER models.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "ner",
        "sequence_labeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/monikkinom/ner-lstm",
      "help_website": [],
      "license": null,
      "tags": [
        "lstm",
        "ner",
        "deep-learning"
      ],
      "id": 185
    },
    {
      "name": "SalIE",
      "one_line_profile": "Salient Open Information Extraction",
      "detailed_description": "A Java implementation of SalIE, a system for Open Information Extraction that focuses on extracting salient facts from text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "open_information_extraction",
        "fact_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/mponza/SalIE",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "open-ie",
        "java",
        "information-extraction"
      ],
      "id": 186
    },
    {
      "name": "spacy-lookup",
      "one_line_profile": "Dictionary-based Named Entity Recognition for spaCy",
      "detailed_description": "A spaCy extension that performs Named Entity Recognition based on provided dictionaries or lists of terms, useful for extracting specific entities not covered by statistical models.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "ner",
        "dictionary_matching"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mpuig/spacy-lookup",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "spacy",
        "ner",
        "dictionary"
      ],
      "id": 187
    },
    {
      "name": "holmes-extractor",
      "one_line_profile": "Predicate logic based information extraction",
      "detailed_description": "A Python library for information extraction from English and German texts. It uses predicate logic to analyze sentence structures and extract relationships.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "relation_extraction",
        "logic_based_ie"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/msg-systems/holmes-extractor",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "information-extraction",
        "german",
        "english"
      ],
      "id": 188
    },
    {
      "name": "KGPool",
      "one_line_profile": "Dynamic Knowledge Graph Context Selection for Relation Extraction",
      "detailed_description": "Implementation of the KGPool model (ACL 2021) for relation extraction, which dynamically selects relevant context from knowledge graphs to improve extraction performance.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "knowledge_graph_augmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nadgeri14/KGPool",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "relation-extraction",
        "knowledge-graph",
        "acl2021"
      ],
      "id": 189
    },
    {
      "name": "LSR",
      "one_line_profile": "Latent Structure Refinement for Document-Level Relation Extraction",
      "detailed_description": "PyTorch implementation of the LSR model (ACL 2020) for document-level relation extraction, which induces latent document-level graphs to support reasoning.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "document_level_re"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nanguoshun/LSR",
      "help_website": [],
      "license": null,
      "tags": [
        "relation-extraction",
        "nlp",
        "acl2020"
      ],
      "id": 190
    },
    {
      "name": "AIONER",
      "one_line_profile": "All-in-One Named Entity Recognition",
      "detailed_description": "A Named Entity Recognition tool developed by NCBI, likely focused on biomedical entities given the organization's domain.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "ner",
        "biomedical_ner"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ncbi/AIONER",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ner",
        "ncbi",
        "biomedical"
      ],
      "id": 191
    },
    {
      "name": "llm-graph-builder",
      "one_line_profile": "Neo4j graph construction from unstructured data using LLMs",
      "detailed_description": "A tool by Neo4j Labs that leverages Large Language Models (LLMs) to extract entities and relationships from unstructured text and construct a Neo4j knowledge graph.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "entity_extraction",
        "relation_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/neo4j-labs/llm-graph-builder",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "neo4j",
        "llm",
        "knowledge-graph",
        "extraction"
      ],
      "id": 192
    },
    {
      "name": "AREkit",
      "one_line_profile": "Document level Attitude and Relation Extraction toolkit",
      "detailed_description": "A toolkit designed for sampling and processing large text collections for document-level attitude and relation extraction tasks, supporting machine learning workflows.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "sentiment_analysis",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nicolay-r/AREkit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "relation-extraction",
        "toolkit",
        "nlp"
      ],
      "id": 193
    },
    {
      "name": "FREDo",
      "one_line_profile": "Few-Shot Document-Level Relation Extraction",
      "detailed_description": "Implementation of a Few-Shot Document-Level Relation Extraction model (NAACL 2022), providing tools to perform relation extraction with limited labeled data.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "few_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nicpopovic/FREDo",
      "help_website": [],
      "license": null,
      "tags": [
        "relation-extraction",
        "few-shot",
        "naacl2022"
      ],
      "id": 194
    },
    {
      "name": "GLRE",
      "one_line_profile": "Global-to-Local Neural Networks for Document-Level Relation Extraction",
      "detailed_description": "Implementation of the GLRE model (EMNLP 2020) for document-level relation extraction, utilizing global and local representations.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "document_level_re"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nju-websoft/GLRE",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "relation-extraction",
        "emnlp2020",
        "nlp"
      ],
      "id": 195
    },
    {
      "name": "gr-nlp-toolkit",
      "one_line_profile": "Greek NLP toolkit",
      "detailed_description": "A comprehensive NLP toolkit specifically for the Greek language, supporting Named Entity Recognition (NER), Dependency Parsing, POS tagging, and transliteration.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "ner",
        "pos_tagging",
        "dependency_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nlpaueb/gr-nlp-toolkit",
      "help_website": [
        "https://huggingface.co/spaces/AUEB-NLP/greek-nlp-toolkit-demo"
      ],
      "license": "Apache-2.0",
      "tags": [
        "greek",
        "nlp",
        "ner",
        "toolkit"
      ],
      "id": 196
    },
    {
      "name": "ace2005-preprocessing",
      "one_line_profile": "ACE 2005 corpus preprocessing for Event Extraction",
      "detailed_description": "A set of tools and scripts for preprocessing the ACE 2005 corpus, a standard dataset for Event Extraction research, converting it into formats suitable for model training.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "data_preprocessing",
        "event_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/nlpcl-lab/ace2005-preprocessing",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ace2005",
        "preprocessing",
        "event-extraction"
      ],
      "id": 197
    },
    {
      "name": "bert-event-extraction",
      "one_line_profile": "BERT-based Event Extraction",
      "detailed_description": "A PyTorch implementation for Event Extraction tasks using BERT, specifically tailored for the ACE 2005 corpus.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction",
        "information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nlpcl-lab/bert-event-extraction",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bert",
        "event-extraction",
        "nlp"
      ],
      "id": 198
    },
    {
      "name": "DialogRE",
      "one_line_profile": "Dialogue-Based Relation Extraction",
      "detailed_description": "A repository containing the DialogRE dataset and baseline models for relation extraction in dialogue settings, serving as a benchmark tool for this specific task.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "dialogue_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nlpdata/dialogre",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "relation-extraction",
        "dialogue",
        "benchmark"
      ],
      "id": 199
    },
    {
      "name": "blabla",
      "one_line_profile": "Linguistic feature extraction library",
      "detailed_description": "A library for extracting linguistic features from text, useful for clinical linguistics and other NLP analyses.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "feature_extraction",
        "linguistic_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/novoic/blabla",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "linguistics",
        "feature-extraction",
        "nlp"
      ],
      "id": 200
    },
    {
      "name": "PtrNetDecoding4JERE",
      "one_line_profile": "Pointer Network for Joint Entity and Relation Extraction",
      "detailed_description": "Implementation of an encoder-decoder architecture with pointer networks for joint entity and relation extraction (AAAI 2020).",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "ner",
        "joint_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nusnlp/PtrNetDecoding4JERE",
      "help_website": [],
      "license": null,
      "tags": [
        "relation-extraction",
        "ner",
        "aaai2020"
      ],
      "id": 201
    },
    {
      "name": "trapper",
      "one_line_profile": "NLP transformer models wrapper and toolkit",
      "detailed_description": "A library that provides a modular design and consistent APIs for state-of-the-art NLP transformer models, facilitating their use in information extraction and other tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "nlp_modeling",
        "information_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/obss/trapper",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "transformers",
        "nlp",
        "huggingface"
      ],
      "id": 202
    },
    {
      "name": "PDF-Extract-Kit",
      "one_line_profile": "Comprehensive Toolkit for PDF Content Extraction",
      "detailed_description": "A high-quality toolkit for extracting content from PDFs, including layout analysis, formula detection, and table extraction. Essential for mining scientific literature.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "document_parsing",
        "pdf_extraction",
        "layout_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/opendatalab/PDF-Extract-Kit",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "pdf",
        "ocr",
        "layout-analysis",
        "scientific-literature"
      ],
      "id": 203
    },
    {
      "name": "open-semantic-entity-search-api",
      "one_line_profile": "REST API for named entity extraction and linking",
      "detailed_description": "An open-source REST API for named entity extraction, linking, disambiguation, and reconciliation, facilitating semantic tagging of documents using knowledge graphs.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "entity_linking",
        "semantic_search"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/opensemanticsearch/open-semantic-entity-search-api",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "entity-extraction",
        "entity-linking",
        "rest-api"
      ],
      "id": 204
    },
    {
      "name": "open-semantic-etl",
      "one_line_profile": "ETL tools for semantic document processing",
      "detailed_description": "A set of ETL tools for crawling, text extraction, OCR, and named entity recognition, designed to enrich data for semantic search and knowledge graph ingestion.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "etl",
        "document_processing",
        "ner"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/opensemanticsearch/open-semantic-etl",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "etl",
        "ocr",
        "ner",
        "semantic-search"
      ],
      "id": 205
    },
    {
      "name": "open-semantic-search",
      "one_line_profile": "Semantic Search Engine and Text Mining Platform",
      "detailed_description": "An integrated research tool and platform for searching, browsing, and analyzing large document collections using semantic search, text mining, and named entity recognition.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "text_mining",
        "semantic_search",
        "knowledge_discovery"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/opensemanticsearch/open-semantic-search",
      "help_website": [
        "https://www.opensemanticsearch.org/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "search-engine",
        "text-mining",
        "knowledge-graph"
      ],
      "id": 206
    },
    {
      "name": "dehyphen",
      "one_line_profile": "Tool for dehyphenation of broken text extracted from PDFs",
      "detailed_description": "A Python library designed to reconstruct words broken by hyphenation in text extracted from PDF documents, facilitating better downstream NLP tasks like entity extraction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "data_cleaning",
        "text_normalization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pd3f/dehyphen",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "text-processing",
        "pdf-extraction",
        "nlp-utility"
      ],
      "id": 207
    },
    {
      "name": "stanford-openie-python",
      "one_line_profile": "Python wrapper for Stanford Open Information Extraction",
      "detailed_description": "A Python interface to the Stanford OpenIE library, enabling easy extraction of open-domain relation triples from text for knowledge graph construction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "open_ie"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/philipperemy/stanford-openie-python",
      "help_website": [],
      "license": "ISC",
      "tags": [
        "openie",
        "stanford-nlp",
        "relation-extraction"
      ],
      "id": 208
    },
    {
      "name": "StanzaGraphs",
      "one_line_profile": "Graph-based summary and keyword extractor using Stanza",
      "detailed_description": "A multilingual system that uses Stanza for dependency parsing and TextGraphs for graph-based keyword and summary extraction, supporting question answering.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "keyword_extraction",
        "summarization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ptarau/StanzaGraphs",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "stanza",
        "graph-algorithms",
        "nlp"
      ],
      "id": 209
    },
    {
      "name": "qKnow",
      "one_line_profile": "Enterprise knowledge graph platform",
      "detailed_description": "An open-source platform for knowledge graph construction, fusion, and visualization, providing tools for structured knowledge extraction and management.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "knowledge_fusion"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/qiantongtech/qKnow",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "knowledge-graph",
        "enterprise-platform",
        "visualization"
      ],
      "id": 210
    },
    {
      "name": "DeepSeg",
      "one_line_profile": "Deep learning framework for brain tumor segmentation",
      "detailed_description": "A deep neural network framework designed for automatic segmentation of brain tumors from MRI FLAIR images, supporting medical imaging analysis.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "image_segmentation",
        "medical_imaging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/razeineldin/DeepSeg",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-imaging",
        "brain-tumor",
        "segmentation"
      ],
      "id": 211
    },
    {
      "name": "OLLIE",
      "one_line_profile": "Open Language Learning for Information Extraction",
      "detailed_description": "An open information extraction system that extracts binary relations from dependency parse graphs, improving upon ReVerb by handling non-verb mediated relations.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "open_ie",
        "relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Scala",
      "repo_url": "https://github.com/rbart/ollie",
      "help_website": [],
      "license": null,
      "tags": [
        "openie",
        "dependency-parsing",
        "scala"
      ],
      "id": 212
    },
    {
      "name": "Chatito",
      "one_line_profile": "DSL for generating NLP training datasets",
      "detailed_description": "A tool using a simple DSL to generate synthetic training datasets for Named Entity Recognition (NER) and text classification tasks, aiding in model training.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "data_generation",
        "synthetic_data"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/rodrigopivi/Chatito",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dataset-generation",
        "ner",
        "nlp-tools"
      ],
      "id": 213
    },
    {
      "name": "OpenIE-Persian",
      "one_line_profile": "Open information extraction for Persian",
      "detailed_description": "A Python-based open information extraction tool specifically designed for the Persian language, enabling relation extraction from Persian web text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "open_ie",
        "relation_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/roshan-research/openie",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "persian-nlp",
        "openie",
        "information-extraction"
      ],
      "id": 214
    },
    {
      "name": "BNLP",
      "one_line_profile": "Natural language processing toolkit for Bengali",
      "detailed_description": "A comprehensive NLP toolkit for the Bengali language, including tokenization, embedding, POS tagging, and NER capabilities.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "nlp_toolkit",
        "ner",
        "pos_tagging"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/sagorbrur/bnlp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bengali-nlp",
        "toolkit",
        "tokenization"
      ],
      "id": 215
    },
    {
      "name": "ThamizhiMorph",
      "one_line_profile": "Tamil morphological analyser and generator",
      "detailed_description": "A tool for morphological analysis and generation of Tamil words, supporting linguistic research and NLP applications for the Tamil language.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "morphological_analysis",
        "linguistics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sarves/thamizhi-morph",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tamil-nlp",
        "morphology",
        "linguistics"
      ],
      "id": 216
    },
    {
      "name": "webstruct",
      "one_line_profile": "NER toolkit for HTML data",
      "detailed_description": "A library for building Named Entity Recognition systems that operate on HTML data, leveraging structural information for better extraction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "ner",
        "web_extraction"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/scrapinghub/webstruct",
      "help_website": [],
      "license": null,
      "tags": [
        "html-ner",
        "scraping",
        "structure-extraction"
      ],
      "id": 217
    },
    {
      "name": "TextAnalyzer",
      "one_line_profile": "Java-based text analysis library",
      "detailed_description": "A Java library providing various text analysis functions including word segmentation, POS tagging, NER, and text classification, primarily for Chinese text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "nlp_toolkit",
        "text_analysis"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/sea-boat/TextAnalyzer",
      "help_website": [],
      "license": null,
      "tags": [
        "java",
        "nlp",
        "chinese-nlp"
      ],
      "id": 218
    },
    {
      "name": "nexmon_csi",
      "one_line_profile": "Wi-Fi Channel State Information extraction tool",
      "detailed_description": "A firmware patch and toolset for extracting Channel State Information (CSI) from Broadcom Wi-Fi chips, enabling physical layer wireless research and sensing applications.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "signal_processing",
        "data_acquisition"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/seemoo-lab/nexmon_csi",
      "help_website": [],
      "license": null,
      "tags": [
        "wifi-sensing",
        "csi-extraction",
        "firmware"
      ],
      "id": 219
    },
    {
      "name": "MELBench",
      "one_line_profile": "Multimodal entity linking datasets and construction framework",
      "detailed_description": "A comprehensive benchmark and dataset construction approach for Multimodal Entity Linking (MEL), including tools for multimodal information extraction and mention/entity extraction from social media and encyclopedias.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_linking",
        "multimodal_extraction",
        "dataset_construction"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/seukgcode/MELBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "entity-linking",
        "multimodal",
        "knowledge-graph",
        "benchmark"
      ],
      "id": 220
    },
    {
      "name": "cross-lingual-open-ie",
      "one_line_profile": "Cross-lingual Open Information Extraction model",
      "detailed_description": "Implementation of Cross-lingual Open Information Extraction using Neural Sequence-to-Sequence Models, enabling information extraction across different languages.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "open_information_extraction",
        "cross_lingual_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sheng-z/cross-lingual-open-ie",
      "help_website": [],
      "license": null,
      "tags": [
        "open-ie",
        "seq2seq",
        "cross-lingual"
      ],
      "id": 221
    },
    {
      "name": "BioFLAIR",
      "one_line_profile": "Biomedical sequence labeling embeddings",
      "detailed_description": "Pretrained Pooled Contextualized Embeddings specifically designed for Biomedical Sequence Labeling Tasks, built upon the Flair framework.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "sequence_labeling",
        "biomedical_nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shreyashub/BioFLAIR",
      "help_website": [],
      "license": null,
      "tags": [
        "biomedical",
        "embeddings",
        "flair",
        "ner"
      ],
      "id": 222
    },
    {
      "name": "KegNet",
      "one_line_profile": "Knowledge Extraction with No Observable Data",
      "detailed_description": "Implementation of KegNet (Knowledge Extraction with No Observable Data) from NeurIPS 2019, facilitating knowledge extraction in data-scarce scenarios.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "zero_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/snudatalab/KegNet",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-extraction",
        "neurips",
        "model"
      ],
      "id": 223
    },
    {
      "name": "trove",
      "one_line_profile": "Weakly supervised medical named entity classification",
      "detailed_description": "A framework for weakly supervised medical named entity classification, designed to extract medical entities with limited labeled data.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "medical_nlp",
        "weak_supervision"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/som-shahlab/trove",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-ner",
        "weak-supervision",
        "entity-classification"
      ],
      "id": 224
    },
    {
      "name": "Stanza",
      "one_line_profile": "Python NLP library for many human languages",
      "detailed_description": "A Python natural language analysis package that features a language-agnostic pipeline for tokenization, multi-word token expansion, lemmatization, POS and morphological features tagging, dependency parsing, and named entity recognition.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "dependency_parsing",
        "tokenization",
        "pos_tagging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanfordnlp/stanza",
      "help_website": [
        "https://stanfordnlp.github.io/stanza/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "nlp",
        "ner",
        "multilingual",
        "stanford-nlp"
      ],
      "id": 225
    },
    {
      "name": "MMORE",
      "one_line_profile": "Massive Multimodal Open RAG & Extraction pipeline",
      "detailed_description": "A scalable multimodal pipeline for processing, indexing, and querying multimodal documents (PDFs, videos, spreadsheets) to create knowledge bases for LLMs.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "rag",
        "multimodal_processing",
        "document_parsing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/swiss-ai/mmore",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "multimodal",
        "extraction",
        "pipeline"
      ],
      "id": 226
    },
    {
      "name": "LocalKnowledgeGraphExtraction",
      "one_line_profile": "Unstructured text to Knowledge Graph extractor",
      "detailed_description": "A tool to extract Knowledge Graphs from normal, unstructured text and visualize the resulting graph structure.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "relation_extraction",
        "visualization"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/syrom/LocalKnowledgeGraphExtraction",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "extraction",
        "visualization"
      ],
      "id": 227
    },
    {
      "name": "BERT-Event-Extraction",
      "one_line_profile": "Event extraction using BERT",
      "detailed_description": "Implementation of event extraction tasks using the BERT model, focusing on Chinese language processing.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction",
        "chinese_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/taishan1994/BERT-Event-Extraction",
      "help_website": [],
      "license": null,
      "tags": [
        "bert",
        "event-extraction",
        "chinese"
      ],
      "id": 228
    },
    {
      "name": "BERT-Relation-Extraction",
      "one_line_profile": "Relation triplet extraction using BERT",
      "detailed_description": "A tool for extracting relation triplets (subject, predicate, object) from text using BERT-based models.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "triplet_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/taishan1994/BERT-Relation-Extraction",
      "help_website": [],
      "license": null,
      "tags": [
        "bert",
        "relation-extraction",
        "triplet"
      ],
      "id": 229
    },
    {
      "name": "PointerNet_Chinese_Information_Extraction",
      "one_line_profile": "Pointer Network for Chinese Information Extraction",
      "detailed_description": "Information extraction tool utilizing Pointer Networks for Named Entity Recognition (NER), Relation Extraction, and Event Extraction in Chinese.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "named_entity_recognition",
        "relation_extraction",
        "event_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/taishan1994/PointerNet_Chinese_Information_Extraction",
      "help_website": [],
      "license": null,
      "tags": [
        "pointer-network",
        "ie",
        "chinese"
      ],
      "id": 230
    },
    {
      "name": "Qwen2-UIE",
      "one_line_profile": "Universal Information Extraction based on Qwen2",
      "detailed_description": "A Universal Information Extraction (UIE) implementation based on the Qwen2 model, supporting entity, relation, and event extraction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "universal_information_extraction",
        "entity_extraction",
        "relation_extraction",
        "event_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/taishan1994/Qwen2-UIE",
      "help_website": [],
      "license": null,
      "tags": [
        "qwen2",
        "uie",
        "llm"
      ],
      "id": 231
    },
    {
      "name": "SpERT_chinese",
      "one_line_profile": "Chinese SpERT implementation",
      "detailed_description": "Implementation of SpERT (Span-based Entity and Relation Transformer) adapted for Chinese relation extraction, capable of jointly extracting entities and relations.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "entity_extraction",
        "joint_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/taishan1994/SpERT_chinese",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "spert",
        "relation-extraction",
        "chinese"
      ],
      "id": 232
    },
    {
      "name": "chinese_information_extraction",
      "one_line_profile": "Comprehensive Chinese Information Extraction Toolkit",
      "detailed_description": "A toolkit for Chinese Information Extraction covering entity extraction, relation extraction, and event extraction tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "named_entity_recognition",
        "relation_extraction",
        "event_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/taishan1994/chinese_information_extraction",
      "help_website": [],
      "license": null,
      "tags": [
        "chinese-nlp",
        "ie",
        "toolkit"
      ],
      "id": 233
    },
    {
      "name": "pytorch_bert_event_extraction",
      "one_line_profile": "PyTorch BERT Event Extraction",
      "detailed_description": "A PyTorch-based implementation for Chinese event extraction using BERT models.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction",
        "chinese_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/taishan1994/pytorch_bert_event_extraction",
      "help_website": [],
      "license": null,
      "tags": [
        "pytorch",
        "bert",
        "event-extraction"
      ],
      "id": 234
    },
    {
      "name": "pytorch_uie_ner",
      "one_line_profile": "PyTorch implementation of Baidu UIE for NER",
      "detailed_description": "A PyTorch implementation of Baidu's Universal Information Extraction (UIE) framework specifically focused on Named Entity Recognition tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "universal_information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/taishan1994/pytorch_uie_ner",
      "help_website": [],
      "license": null,
      "tags": [
        "uie",
        "ner",
        "pytorch"
      ],
      "id": 235
    },
    {
      "name": "ner-annotator",
      "one_line_profile": "NER Annotation tool for SpaCy",
      "detailed_description": "A web-based annotation tool for Named Entity Recognition (NER) that generates training data in JSON format compatible with SpaCy.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "data_annotation",
        "named_entity_recognition"
      ],
      "application_level": "platform",
      "primary_language": "Vue",
      "repo_url": "https://github.com/tecoholic/ner-annotator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "annotation-tool",
        "ner",
        "spacy",
        "gui"
      ],
      "id": 236
    },
    {
      "name": "boundary-aware-nested-ner",
      "one_line_profile": "Boundary-aware Nested NER model",
      "detailed_description": "Implementation of the 'Boundary-aware Neural Model for Nested Named Entity Recognition' (EMNLP 2019), designed to handle nested entity structures.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "nested_ner"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/thecharm/boundary-aware-nested-ner",
      "help_website": [],
      "license": null,
      "tags": [
        "nested-ner",
        "emnlp",
        "neural-network"
      ],
      "id": 237
    },
    {
      "name": "NRE",
      "one_line_profile": "C++ toolkit for Neural Relation Extraction with various neural architectures",
      "detailed_description": "A toolkit for neural relation extraction implementing models like CNN, PCNN, and their attention-based variants. It provides a framework for training and testing relation extraction models on large-scale datasets.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/thunlp/NRE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "relation-extraction",
        "neural-networks",
        "cnn",
        "pcnn"
      ],
      "id": 238
    },
    {
      "name": "OpenNRE",
      "one_line_profile": "Open-source package for Neural Relation Extraction",
      "detailed_description": "A comprehensive and extensible toolkit for neural relation extraction (NRE). It supports various models, datasets, and training paradigms, designed to facilitate research and deployment of RE systems.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "model_training",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/thunlp/OpenNRE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "relation-extraction",
        "nlp",
        "pytorch",
        "knowledge-graph"
      ],
      "id": 239
    },
    {
      "name": "oknlp",
      "one_line_profile": "Open and Knowledgeable NLP Toolkit",
      "detailed_description": "A natural language processing toolkit that integrates knowledge into NLP tasks. It supports Chinese Word Segmentation, POS Tagging, Named Entity Recognition, and Entity Typing.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "pos_tagging",
        "entity_typing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/thunlp/oknlp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "ner",
        "cws",
        "entity-typing"
      ],
      "id": 240
    },
    {
      "name": "zhopenie",
      "one_line_profile": "Chinese Open Information Extraction System",
      "detailed_description": "A tree-based triple relation extraction module for Chinese Open Information Extraction (OpenIE). It extracts structured triples from unstructured Chinese text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "open_information_extraction",
        "triple_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tim5go/zhopenie",
      "help_website": [],
      "license": null,
      "tags": [
        "openie",
        "chinese-nlp",
        "relation-extraction"
      ],
      "id": 241
    },
    {
      "name": "detecting-scientific-claim",
      "one_line_profile": "Scientific claim extraction from biomedical abstracts",
      "detailed_description": "A tool powered by AllenNLP for extracting scientific claims (discourse analysis) from biomedical abstracts. It helps in structuring scientific literature for downstream analysis.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "claim_extraction",
        "scientific_text_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/titipata/detecting-scientific-claim",
      "help_website": [],
      "license": null,
      "tags": [
        "biomedical-nlp",
        "claim-extraction",
        "allennlp"
      ],
      "id": 242
    },
    {
      "name": "metastanza",
      "one_line_profile": "Standard visualization components for TogoStanza",
      "detailed_description": "A collection of generic stanzas (web components) for TogoStanza, a framework used for creating semantic web data visualizations in life sciences (Bioinformatics).",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "scientific_visualization",
        "semantic_web"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/togostanza/metastanza",
      "help_website": [
        "http://togostanza.org/"
      ],
      "license": null,
      "tags": [
        "visualization",
        "semantic-web",
        "bioinformatics",
        "togostanza"
      ],
      "id": 243
    },
    {
      "name": "SpanMarkerNER",
      "one_line_profile": "SpanMarker for Named Entity Recognition",
      "detailed_description": "A library for Named Entity Recognition (NER) that uses the SpanMarker architecture. It is compatible with Hugging Face Transformers and provides an easy-to-use interface for training and inference.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "entity_extraction"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/tomaarsen/SpanMarkerNER",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ner",
        "transformers",
        "nlp"
      ],
      "id": 244
    },
    {
      "name": "relationfactory",
      "one_line_profile": "End-to-end relation extraction pipeline",
      "detailed_description": "A pipeline for end-to-end relation extraction and knowledge base population. It processes input text to extract entities and relations, suitable for constructing knowledge bases.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "knowledge_base_population"
      ],
      "application_level": "workflow",
      "primary_language": "Java",
      "repo_url": "https://github.com/uds-lsv/relationfactory",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "relation-extraction",
        "kbp",
        "pipeline"
      ],
      "id": 245
    },
    {
      "name": "ClinicalTransformerNER",
      "one_line_profile": "Library for clinical named entity recognition",
      "detailed_description": "A library for named entity recognition (NER) in the clinical domain, featuring state-of-the-art algorithms tailored for biomedical text processing.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "clinical_ner",
        "biomedical_text_mining"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/uf-hobi-informatics-lab/ClinicalTransformerNER",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "clinical-nlp",
        "ner",
        "biomedical"
      ],
      "id": 246
    },
    {
      "name": "MinIE",
      "one_line_profile": "Open Information Extraction system",
      "detailed_description": "An Open Information Extraction (OpenIE) system that provides compact and semantically rich extractions. It minimizes the output to produce more useful triples for downstream tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "open_information_extraction",
        "triple_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/uma-pi1/minie",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "openie",
        "information-extraction",
        "nlp"
      ],
      "id": 247
    },
    {
      "name": "Underthesea",
      "one_line_profile": "Vietnamese NLP Toolkit",
      "detailed_description": "A comprehensive NLP toolkit for the Vietnamese language, providing modules for word segmentation, POS tagging, chunking, and named entity recognition (NER).",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "pos_tagging",
        "text_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/undertheseanlp/underthesea",
      "help_website": [
        "https://underthesea.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "vietnamese-nlp",
        "ner",
        "toolkit"
      ],
      "id": 248
    },
    {
      "name": "UIE",
      "one_line_profile": "Unified Structure Generation for Universal Information Extraction",
      "detailed_description": "A unified framework for universal information extraction (UIE) that can model various IE tasks (entity extraction, relation extraction, event extraction, sentiment analysis) as a structure generation problem.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "relation_extraction",
        "event_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/universal-ie/UIE",
      "help_website": [],
      "license": null,
      "tags": [
        "information-extraction",
        "generation",
        "unified-model"
      ],
      "id": 249
    },
    {
      "name": "GLiNER",
      "one_line_profile": "Generalist and Lightweight Model for Named Entity Recognition",
      "detailed_description": "A generalist model for Named Entity Recognition (NER) capable of identifying any entity type using a bidirectional transformer encoder. It is designed to be lightweight and effective for zero-shot NER tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition",
        "zero_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/urchade/GLiNER",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ner",
        "zero-shot",
        "nlp"
      ],
      "id": 250
    },
    {
      "name": "VnCoreNLP",
      "one_line_profile": "Vietnamese natural language processing toolkit",
      "detailed_description": "A Java-based toolkit for Vietnamese natural language processing, providing a pipeline for word segmentation, POS tagging, named entity recognition (NER), and dependency parsing.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "pos_tagging",
        "dependency_parsing"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/vncorenlp/VnCoreNLP",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "nlp",
        "vietnamese",
        "ner",
        "pos-tagging"
      ],
      "id": 251
    },
    {
      "name": "GraphGen4Code",
      "one_line_profile": "Toolkit for creating code knowledge graphs",
      "detailed_description": "A toolkit designed to construct knowledge graphs from source code by leveraging WALA for code analysis and extracting information from documentation and forums.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "code_analysis"
      ],
      "application_level": "toolkit",
      "primary_language": "Java",
      "repo_url": "https://github.com/wala/graph4code",
      "help_website": [],
      "license": "EPL-2.0",
      "tags": [
        "knowledge-graph",
        "code-analysis",
        "wala"
      ],
      "id": 252
    },
    {
      "name": "Wandora",
      "one_line_profile": "Information extraction and knowledge graph management application",
      "detailed_description": "A general-purpose application based on Topic Maps and Java for information extraction, knowledge management, and publishing. It supports various data formats and extraction capabilities.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "knowledge_management"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/wandora-team/wandora",
      "help_website": [
        "http://wandora.org"
      ],
      "license": "GPL-3.0",
      "tags": [
        "topic-maps",
        "information-extraction",
        "knowledge-graph"
      ],
      "id": 253
    },
    {
      "name": "YAYI-UIE",
      "one_line_profile": "Large language model for unified information extraction",
      "detailed_description": "A large-scale pre-trained model fine-tuned on high-quality instruction data for universal information extraction tasks, including named entity recognition and relation extraction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "relation_extraction",
        "information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wenge-research/YAYI-UIE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "information-extraction",
        "ner",
        "relation-extraction"
      ],
      "id": 254
    },
    {
      "name": "Macropodus",
      "one_line_profile": "Chinese natural language processing toolkit",
      "detailed_description": "An NLP toolkit based on Albert+BiLSTM+CRF architecture, supporting Chinese word segmentation, POS tagging, named entity recognition (NER), keyword extraction, and text summarization.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "text_summarization",
        "pos_tagging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yongzhuo/Macropodus",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "chinese-nlp",
        "ner",
        "summarization"
      ],
      "id": 255
    },
    {
      "name": "Pytorch-NLU",
      "one_line_profile": "Pytorch-based toolkit for Chinese text classification and sequence labeling",
      "detailed_description": "A toolkit supporting multi-class and multi-label text classification, as well as sequence labeling tasks such as Named Entity Recognition (NER) and POS tagging for Chinese text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "entity_extraction",
        "text_classification",
        "sequence_labeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yongzhuo/Pytorch-NLU",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pytorch",
        "nlp",
        "ner",
        "text-classification"
      ],
      "id": 256
    },
    {
      "name": "RIFRE",
      "one_line_profile": "Heterogeneous Graph Neural Network model for Joint Entity and Relation Extraction",
      "detailed_description": "An implementation of the RIFRE model which uses representation iterative fusion on heterogeneous graph neural networks to perform joint entity and relation extraction tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "named_entity_recognition",
        "joint_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhao9797/RIFRE",
      "help_website": [],
      "license": null,
      "tags": [
        "graph-neural-networks",
        "relation-extraction",
        "entity-extraction"
      ],
      "id": 257
    },
    {
      "name": "kg-baseline-pytorch",
      "one_line_profile": "PyTorch baseline implementation for Joint Relation Extraction",
      "detailed_description": "A PyTorch implementation of a baseline model for the 2019 Baidu Relation Extraction competition, focusing on joint relation extraction tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "joint_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhengyima/kg-baseline-pytorch",
      "help_website": [],
      "license": null,
      "tags": [
        "pytorch",
        "relation-extraction",
        "competition-baseline"
      ],
      "id": 258
    },
    {
      "name": "DeepEE",
      "one_line_profile": "Deep learning-based Event Extraction algorithm gallery",
      "detailed_description": "A collection of deep learning algorithms for Chinese event extraction, providing implementations for various models to extract events from text.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "event_extraction",
        "information_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/DeepEE",
      "help_website": [],
      "license": null,
      "tags": [
        "event-extraction",
        "deep-learning",
        "nlp"
      ],
      "id": 259
    },
    {
      "name": "DeepKE",
      "one_line_profile": "Open toolkit for Knowledge Graph Extraction and Construction",
      "detailed_description": "A comprehensive open-source toolkit for knowledge graph extraction and construction, supporting named entity recognition, relation extraction, and attribute extraction with various deep learning models.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "named_entity_recognition",
        "relation_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/DeepKE",
      "help_website": [
        "https://zjunlp.github.io/DeepKE/"
      ],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "information-extraction",
        "toolkit"
      ],
      "id": 260
    },
    {
      "name": "DocuNet",
      "one_line_profile": "Document-level Relation Extraction model treating extraction as semantic segmentation",
      "detailed_description": "An implementation of DocuNet, a model that approaches document-level relation extraction as a semantic segmentation task to capture global dependencies.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "document_level_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/DocuNet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "document-level-re",
        "semantic-segmentation",
        "nlp"
      ],
      "id": 261
    },
    {
      "name": "IEPile",
      "one_line_profile": "Large-scale Information Extraction corpus and dataset",
      "detailed_description": "A comprehensive, large-scale corpus designed for training and evaluating information extraction models, aggregating various IE tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "information_extraction",
        "dataset_generation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/IEPile",
      "help_website": [
        "https://huggingface.co/datasets/zjunlp/iepile"
      ],
      "license": "NOASSERTION",
      "tags": [
        "dataset",
        "information-extraction",
        "corpus"
      ],
      "id": 262
    },
    {
      "name": "KnowPrompt",
      "one_line_profile": "Knowledge-aware Prompt-tuning framework for Relation Extraction",
      "detailed_description": "A framework for relation extraction that utilizes knowledge-aware prompt-tuning with synergistic optimization to improve performance on RE tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "relation_extraction",
        "prompt_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/KnowPrompt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-learning",
        "relation-extraction",
        "knowledge-injection"
      ],
      "id": 263
    },
    {
      "name": "ChineseNER",
      "one_line_profile": "Neural network model for Chinese Named Entity Recognition",
      "detailed_description": "A neural network-based implementation specifically designed for performing named entity recognition on Chinese text data.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjy-ucas/ChineseNER",
      "help_website": [],
      "license": null,
      "tags": [
        "ner",
        "chinese-nlp",
        "neural-network"
      ],
      "id": 264
    },
    {
      "name": "Word-Embedding",
      "one_line_profile": "Collection of pre-trained word embeddings and training scripts",
      "detailed_description": "A resource and toolkit providing access to various pre-trained word embeddings (Word2vec, Fasttext, Glove, BERT, etc.) and scripts for their usage in NLP tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "feature_extraction",
        "embedding_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zlsdu/Word-Embedding",
      "help_website": [],
      "license": null,
      "tags": [
        "word-embedding",
        "nlp",
        "pretrained-models"
      ],
      "id": 265
    },
    {
      "name": "OpenNER",
      "one_line_profile": "Toolkit for open-domain Named Entity Recognition",
      "detailed_description": "A toolkit designed to facilitate open-domain named entity recognition tasks, providing models and utilities for extracting entities from diverse text sources.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "named_entity_recognition"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zmd971202/OpenNER",
      "help_website": [],
      "license": null,
      "tags": [
        "ner",
        "open-domain",
        "toolkit"
      ],
      "id": 266
    },
    {
      "name": "ICDAR-2019-SROIE",
      "one_line_profile": "Dataset and benchmark for Scanned Receipts OCR and Information Extraction",
      "detailed_description": "The official dataset and evaluation resources for the ICDAR 2019 Robust Reading Challenge on Scanned Receipts OCR and Information Extraction.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "optical_character_recognition",
        "information_extraction"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/zzzDavid/ICDAR-2019-SROIE",
      "help_website": [
        "https://rrc.cvc.uab.es/?ch=13"
      ],
      "license": "MIT",
      "tags": [
        "ocr",
        "receipt-processing",
        "dataset"
      ],
      "id": 267
    },
    {
      "name": "DS-JedAI",
      "one_line_profile": "Distributed Spatial JedAI for holistic geospatial interlinking on Spark",
      "detailed_description": "A distributed system for Holistic Geospatial Interlinking that discovers topological relations between geospatial datasets using Apache Spark.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "geospatial_interlinking"
      ],
      "application_level": "solver",
      "primary_language": "Scala",
      "repo_url": "https://github.com/AI-team-UoA/DS-JedAI",
      "help_website": [],
      "license": null,
      "tags": [
        "entity-resolution",
        "geospatial",
        "spark",
        "interlinking"
      ],
      "id": 268
    },
    {
      "name": "JedAI-spatial",
      "one_line_profile": "Three-dimensional geospatial interlinking tool",
      "detailed_description": "A module of the JedAI toolkit focused on performing geospatial interlinking and entity resolution for three-dimensional spatial data.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "geospatial_interlinking"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/AI-team-UoA/JedAI-spatial",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "spatial-data",
        "entity-resolution",
        "interlinking"
      ],
      "id": 269
    },
    {
      "name": "pyJedAI",
      "one_line_profile": "Python library for end-to-end Entity Resolution workflows",
      "detailed_description": "An open-source library leveraging the Python data science ecosystem to build and execute powerful end-to-end Entity Resolution workflows.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "data_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AI-team-UoA/pyJedAI",
      "help_website": [
        "https://pyjedai.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "entity-resolution",
        "data-integration",
        "deduplication"
      ],
      "id": 270
    },
    {
      "name": "QuitStore",
      "one_line_profile": "Distributed version control system for RDF knowledge bases",
      "detailed_description": "A tool that enables distributed version control for RDF Knowledge Bases by managing Quads in Git, facilitating provenance and collaboration.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "version_control",
        "provenance",
        "rdf_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AKSW/QuitStore",
      "help_website": [
        "https://aksw.org/Projects/QuitStore.html"
      ],
      "license": "GPL-3.0",
      "tags": [
        "rdf",
        "version-control",
        "git",
        "knowledge-graph"
      ],
      "id": 271
    },
    {
      "name": "Spline",
      "one_line_profile": "Data lineage tracking and visualization solution for Spark",
      "detailed_description": "A data lineage tracking and visualization tool that captures and visualizes data processing workflows, essential for data provenance in scientific pipelines.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "lineage_tracking"
      ],
      "application_level": "platform",
      "primary_language": "Scala",
      "repo_url": "https://github.com/AbsaOSS/spline",
      "help_website": [
        "https://absaoss.github.io/spline/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-lineage",
        "provenance",
        "spark",
        "visualization"
      ],
      "id": 272
    },
    {
      "name": "AgreementMakerLight",
      "one_line_profile": "Automated ontology matching system",
      "detailed_description": "A scalable and automated ontology matching system designed to handle large ontologies, widely used in OAEI competitions for alignment tasks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "ontology_matching",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/AgreementMakerLight/AML-Project",
      "help_website": [
        "http://agreementmaker.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ontology-matching",
        "alignment",
        "semantic-web"
      ],
      "id": 273
    },
    {
      "name": "Kelpie",
      "one_line_profile": "XAI framework for interpreting Link Predictions on Knowledge Graphs",
      "detailed_description": "An explainable AI framework designed to interpret and explain link predictions within knowledge graphs, aiding in model transparency and analysis.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "interpretation",
        "link_prediction_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AndRossi/Kelpie",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "xai",
        "knowledge-graph",
        "interpretability"
      ],
      "id": 274
    },
    {
      "name": "OntoMerger",
      "one_line_profile": "Ontology alignment library for deduplicating knowledge graph nodes",
      "detailed_description": "A library developed by AstraZeneca for ontology alignment and node deduplication, facilitating the merging of overlapping concepts in knowledge graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "ontology_alignment",
        "deduplication"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/AstraZeneca/onto_merger",
      "help_website": [
        "https://astrazeneca.github.io/onto_merger/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ontology",
        "alignment",
        "deduplication",
        "knowledge-graph"
      ],
      "id": 275
    },
    {
      "name": "Blue Brain Nexus",
      "one_line_profile": "Knowledge graph and data management platform for data-driven science",
      "detailed_description": "A comprehensive knowledge graph and data management platform designed to support data-driven science by enabling data integration, provenance tracking, and search.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_management",
        "provenance",
        "knowledge_graph"
      ],
      "application_level": "platform",
      "primary_language": "Scala",
      "repo_url": "https://github.com/BlueBrain/nexus",
      "help_website": [
        "https://bluebrainnexus.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "provenance",
        "neuroscience",
        "data-management"
      ],
      "id": 276
    },
    {
      "name": "GraphRAG Workbench",
      "one_line_profile": "Interactive 3D visualization tool for Microsoft GraphRAG knowledge graphs",
      "detailed_description": "A visual analytics tool for exploring entities, relationships, and communities in knowledge graphs generated by GraphRAG, supporting scientific data interpretation.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "visualization",
        "graph_analytics"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/ChristopherLyon/graphrag-workbench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "knowledge-graph",
        "rag",
        "3d-viz"
      ],
      "id": 277
    },
    {
      "name": "DagsHub Client",
      "one_line_profile": "Python client for DagsHub data collaboration and versioning",
      "detailed_description": "Client library for DagsHub, enabling data scientists to version control data and models, supporting reproducibility and provenance in scientific workflows.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "version_control",
        "provenance",
        "data_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DagsHub/client",
      "help_website": [
        "https://dagshub.com/docs/"
      ],
      "license": "MIT",
      "tags": [
        "data-versioning",
        "provenance",
        "collaboration"
      ],
      "id": 278
    },
    {
      "name": "Fast Data Science (fds)",
      "one_line_profile": "CLI tool for data and code version control",
      "detailed_description": "A command-line interface that wraps Git and DVC to streamline version control for data and code, facilitating scientific data management and reproducibility.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "version_control",
        "provenance"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DagsHub/fds",
      "help_website": [
        "https://dagshub.com/fds"
      ],
      "license": "MIT",
      "tags": [
        "dvc",
        "git",
        "version-control",
        "cli"
      ],
      "id": 279
    },
    {
      "name": "matlab-dataone",
      "one_line_profile": "Matlab Toolbox for DataONE repository interaction and provenance management",
      "detailed_description": "A Matlab Toolbox that provides functions to interact with data repositories that implement the DataONE service API. It includes client-side functions for managing provenance (the history) of derived data products, facilitating scientific data reproducibility.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance_tracking",
        "data_access"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/DataONEorg/matlab-dataone",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "dataone",
        "provenance",
        "matlab",
        "scientific-data"
      ],
      "id": 280
    },
    {
      "name": "Strwythura",
      "one_line_profile": "Knowledge graph construction and entity resolution pipeline",
      "detailed_description": "A tool to construct knowledge graphs from unstructured data sources, organized by results from entity resolution. It implements an enhanced GraphRAG approach and an ontology pipeline for optimizing AI application outcomes within specific domains.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "kg_construction",
        "graph_rag"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/DerwenAI/strwythura",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "entity-resolution",
        "graphrag",
        "unstructured-data"
      ],
      "id": 281
    },
    {
      "name": "CEA",
      "one_line_profile": "Collective Entity Alignment via Adaptive Features",
      "detailed_description": "Implementation of the Collective Entity Alignment via Adaptive Features (CEA) algorithm. It serves as a solver for aligning entities across different knowledge graphs, a key task in knowledge fusion.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "knowledge_fusion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DexterZeng/CEA",
      "help_website": [],
      "license": null,
      "tags": [
        "entity-alignment",
        "knowledge-graph",
        "icde-2020"
      ],
      "id": 282
    },
    {
      "name": "pile_dedupe",
      "one_line_profile": "Deduplication tool for large-scale language model datasets",
      "detailed_description": "Code used for deduplicating The Pile, a massive dataset for training large language models. It handles near-deduplication to improve data quality for scientific modeling in NLP.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "deduplication",
        "data_cleaning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/EleutherAI/pile_dedupe",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "deduplication",
        "nlp",
        "llm",
        "data-processing"
      ],
      "id": 283
    },
    {
      "name": "SparkER",
      "one_line_profile": "Entity Resolution framework for Apache Spark",
      "detailed_description": "A framework for performing Entity Resolution on large datasets using Apache Spark. It enables scalable record linkage and deduplication for scientific data processing.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "record_linkage"
      ],
      "application_level": "framework",
      "primary_language": "Scala",
      "repo_url": "https://github.com/Gaglia88/sparker",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "spark",
        "entity-resolution",
        "big-data",
        "scala"
      ],
      "id": 284
    },
    {
      "name": "CG-MuAlign",
      "one_line_profile": "Collective Multi-type Entity Alignment solver",
      "detailed_description": "Implementation of 'Collective Multi-type Entity Alignment Between Knowledge Graphs'. It provides a method for aligning entities of multiple types across knowledge graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "knowledge_graph"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GentleZhu/CG-MuAlign",
      "help_website": [],
      "license": null,
      "tags": [
        "entity-alignment",
        "knowledge-graph",
        "multi-type"
      ],
      "id": 285
    },
    {
      "name": "GraphFusion-NMN",
      "one_line_profile": "Neural Memory Networks combined with Knowledge Graphs",
      "detailed_description": "An open-source platform that combines Neural Memory Networks with knowledge graphs for real-time, adaptive, and intelligent systems, useful for scientific reasoning and QA.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "knowledge_reasoning",
        "graph_fusion"
      ],
      "application_level": "solver",
      "primary_language": "Rich Text Format",
      "repo_url": "https://github.com/GraphFusion/GraphFusion-NMN",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "neural-memory-networks",
        "knowledge-graph",
        "reasoning"
      ],
      "id": 286
    },
    {
      "name": "LMP-EA",
      "one_line_profile": "Entity Alignment with Matchable Prior Learning",
      "detailed_description": "Implementation of 'Learning Matchable Prior For Entity Alignment with Unlabeled Dangling Cases' (NeurIPS 2024). A solver for aligning entities in knowledge graphs, handling dangling cases.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "knowledge_graph"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Handon112358/NeurIPS_2024_Learning-Matchable-Prior-For-Entity-Alignment-with-Unlabeled-Dangling-Cases",
      "help_website": [],
      "license": null,
      "tags": [
        "entity-alignment",
        "neurips-2024",
        "knowledge-graph"
      ],
      "id": 287
    },
    {
      "name": "CMF",
      "one_line_profile": "Metadata and lineage tracking for ML pipelines",
      "detailed_description": "CMF (Common Metadata Framework) library helps to collect and store information associated with ML pipelines. It tracks the lineages for artifacts and executions of distributed AI pipelines, ensuring reproducibility and provenance.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "lineage_tracking",
        "metadata_management",
        "ml_provenance"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HewlettPackard/cmf",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "provenance",
        "lineage",
        "metadata"
      ],
      "id": 288
    },
    {
      "name": "GWL",
      "one_line_profile": "Gromov-Wasserstein Learning for Graph Matching",
      "detailed_description": "Implementation of Gromov-Wasserstein Learning for Graph Matching and Node Embedding. Useful for aligning structures in scientific graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "node_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HongtengXu/gwl",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "optimal-transport",
        "graph-matching",
        "embedding"
      ],
      "id": 289
    },
    {
      "name": "s-gwl",
      "one_line_profile": "Scalable Gromov-Wasserstein Learning",
      "detailed_description": "Scalable Gromov-Wasserstein Learning for Graph Partitioning and Matching. An extension of GWL for larger graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "graph_partitioning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HongtengXu/s-gwl",
      "help_website": [],
      "license": null,
      "tags": [
        "optimal-transport",
        "graph-matching",
        "scalable"
      ],
      "id": 290
    },
    {
      "name": "multi-data-lineage-capture-py",
      "one_line_profile": "IBM Multi-Lineage Data System capture library",
      "detailed_description": "Python client library for the IBM Multi-Lineage Data System, facilitating the capture of data lineage information for governance and provenance.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "lineage_capture",
        "provenance"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IBM/multi-data-lineage-capture-py",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lineage",
        "ibm",
        "provenance"
      ],
      "id": 291
    },
    {
      "name": "AKE",
      "one_line_profile": "Adversarial Knowledge Embedding for Entity Alignment",
      "detailed_description": "Implementation of 'Guiding Entity Alignment via Adversarial Knowledge Embedding'. A solver for aligning entities across knowledge graphs using adversarial learning.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "knowledge_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/IIEdm/AKE",
      "help_website": [],
      "license": null,
      "tags": [
        "entity-alignment",
        "adversarial-learning",
        "knowledge-graph"
      ],
      "id": 292
    },
    {
      "name": "pycellin",
      "one_line_profile": "Cell lineage analysis framework",
      "detailed_description": "Graph-based framework to manipulate and analyze cell lineages from cell tracking data. It allows for the reconstruction and analysis of biological developmental paths.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "cell_lineage",
        "biological_network_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Image-Analysis-Hub/pycellin",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "cell-lineage",
        "biology",
        "graph-analysis"
      ],
      "id": 293
    },
    {
      "name": "CGPrompt",
      "one_line_profile": "Concept Graph Recovery using LLMs",
      "detailed_description": "Leveraging Large Language Models for Concept Graph Recovery and Question Answering. Useful for constructing and aligning educational knowledge graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_recovery",
        "concept_alignment"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/IreneZihuiLi/CGPrompt",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "knowledge-graph",
        "education"
      ],
      "id": 294
    },
    {
      "name": "FEBRL-fork",
      "one_line_profile": "Freely Extensible Biomedical Record Linkage",
      "detailed_description": "Fork of the Freely Extensible Biomedical Record Linkage (FEBRL) program. A tool specifically designed for data cleaning, standardization, and record linkage in biomedical datasets.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "biomedical_data_cleaning"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/J535D165/FEBRL-fork-v0.4.2",
      "help_website": [],
      "license": null,
      "tags": [
        "record-linkage",
        "biomedical",
        "data-cleaning"
      ],
      "id": 295
    },
    {
      "name": "recordlinkage",
      "one_line_profile": "Python toolkit for record linkage and deduplication",
      "detailed_description": "A powerful and modular toolkit for record linkage and duplicate detection in Python. It provides tools for indexing, comparing, and classifying record pairs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "deduplication",
        "entity_resolution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/J535D165/recordlinkage",
      "help_website": [
        "https://recordlinkage.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "record-linkage",
        "deduplication",
        "python",
        "data-matching"
      ],
      "id": 296
    },
    {
      "name": "recordlinkage-review",
      "one_line_profile": "Annotation tool for record linkage validation",
      "detailed_description": "A tool to make golden data or validate record linkage results. It provides a user interface for manual review of potential matches.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "validation",
        "annotation",
        "record_linkage"
      ],
      "application_level": "application",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/J535D165/recordlinkage-review",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "annotation",
        "validation",
        "record-linkage"
      ],
      "id": 297
    },
    {
      "name": "SMAT",
      "one_line_profile": "Schema Matching Model",
      "detailed_description": "Model and datasets for schema matching, a critical step in data integration and alignment.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "schema_matching",
        "data_integration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JZCS2018/SMAT",
      "help_website": [],
      "license": null,
      "tags": [
        "schema-matching",
        "data-integration"
      ],
      "id": 298
    },
    {
      "name": "niprov",
      "one_line_profile": "Provenance for neuroimaging data",
      "detailed_description": "A library for tracking provenance in neuroimaging data processing pipelines. It helps manage the history of files and transformations in neuroscience research.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance_tracking",
        "neuroimaging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/JasperVanDenBosch/niprov",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "neuroimaging",
        "provenance",
        "neuroscience"
      ],
      "id": 299
    },
    {
      "name": "GEN",
      "one_line_profile": "Transductive Few-shot Link Prediction",
      "detailed_description": "Official Code Repository for 'Learning to Extrapolate Knowledge: Transductive Few-shot Out-of-Graph Link Prediction'. A solver for predicting links in knowledge graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "knowledge_graph"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JinheonBaek/GEN",
      "help_website": [],
      "license": null,
      "tags": [
        "link-prediction",
        "knowledge-graph",
        "few-shot-learning"
      ],
      "id": 300
    },
    {
      "name": "RGCN",
      "one_line_profile": "Relational Graph Convolutional Network for Link Prediction",
      "detailed_description": "Pytorch implementation of a Relational Graph Convolutional Network (RGCN) Link Prediction Model. Used for modeling relational data and predicting missing links in knowledge graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "graph_neural_network"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JinheonBaek/RGCN",
      "help_website": [],
      "license": null,
      "tags": [
        "rgcn",
        "link-prediction",
        "knowledge-graph"
      ],
      "id": 301
    },
    {
      "name": "SpineBasedRecordLinkage.jl",
      "one_line_profile": "Record linkage library for Julia",
      "detailed_description": "A library for performing record linkage in the Julia programming language, suitable for scientific data integration tasks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "entity_resolution"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JockLawrie/SpineBasedRecordLinkage.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "julia",
        "record-linkage"
      ],
      "id": 302
    },
    {
      "name": "BERTMap",
      "one_line_profile": "BERT-Based Ontology Alignment System",
      "detailed_description": "A system for ontology alignment that utilizes BERT embeddings to find correspondences between concepts in different ontologies.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "ontology_alignment",
        "semantic_matching"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/KRR-Oxford/BERTMap",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ontology-alignment",
        "bert",
        "nlp"
      ],
      "id": 303
    },
    {
      "name": "OntoAlign",
      "one_line_profile": "Ontology Alignment Utilities",
      "detailed_description": "A collection of codes and utilities relevant to ontology alignment tasks, supporting research in semantic interoperability.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "ontology_alignment",
        "semantic_web"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KRR-Oxford/OntoAlign",
      "help_website": [],
      "license": null,
      "tags": [
        "ontology-alignment",
        "utilities"
      ],
      "id": 304
    },
    {
      "name": "OpenTLP",
      "one_line_profile": "Unified framework and implementations for temporal link prediction methods",
      "detailed_description": "A comprehensive library and benchmark for temporal link prediction in dynamic graphs, providing implementations of various methods and a taxonomy for the field.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "temporal_graph_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KuroginQin/OpenTLP",
      "help_website": [],
      "license": null,
      "tags": [
        "temporal-graphs",
        "link-prediction",
        "benchmark"
      ],
      "id": 305
    },
    {
      "name": "Gremlinator",
      "one_line_profile": "Translator for converting SPARQL queries to Gremlin traversals",
      "detailed_description": "A tool designed to bridge the gap between RDF/SPARQL and Property Graph/Gremlin ecosystems by automatically converting SPARQL queries into Gremlin graph pattern matching traversals.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "query_translation",
        "interoperability"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/LITMUS-Benchmark-Suite/sparql-to-gremlin",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sparql",
        "gremlin",
        "graph-database"
      ],
      "id": 306
    },
    {
      "name": "Kosh",
      "one_line_profile": "Data store and query API for scientific codes",
      "detailed_description": "A Python API developed by LLNL that sits on top of Sina, allowing scientific codes to store, query, and share data efficiently, facilitating data provenance and access.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_management",
        "provenance"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/LLNL/kosh",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hpc",
        "data-management",
        "llnl"
      ],
      "id": 307
    },
    {
      "name": "PIRL",
      "one_line_profile": "Point-of-contact Interactive Record Linkage software",
      "detailed_description": "Software developed by LSHTM for interactive record linkage, designed to resolve entities and link records in demographic and health surveillance data.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "entity_resolution"
      ],
      "application_level": "solver",
      "primary_language": "C#",
      "repo_url": "https://github.com/LSHTM-ALPHAnetwork/PIRL_RecordLinkageSoftware",
      "help_website": [
        "http://alpha.lshtm.ac.uk/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "record-linkage",
        "demography",
        "health-data"
      ],
      "id": 308
    },
    {
      "name": "GMNet",
      "one_line_profile": "Graph Matching Network for semantic segmentation",
      "detailed_description": "Implementation of a Graph Matching Network (GMNet) that leverages graph matching techniques for large-scale part semantic segmentation, applicable in computer vision and image analysis.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "image_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LTTM/GMNet",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "graph-matching",
        "deep-learning",
        "segmentation"
      ],
      "id": 309
    },
    {
      "name": "horizon",
      "one_line_profile": "Map matching and routing library",
      "detailed_description": "A Go library for map matching (snapping GPS points to a road graph) and routing, serving as an entity resolution tool for geospatial trajectory data.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "map_matching",
        "geospatial_alignment"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/LdDl/horizon",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gis",
        "map-matching",
        "routing"
      ],
      "id": 310
    },
    {
      "name": "Graph-Matching-Networks",
      "one_line_profile": "Implementations of Graph Matching Networks for graph similarity",
      "detailed_description": "PyTorch implementations of deep graph matching methods (GMN, COMMON) for learning similarity and alignment between graph-structured objects.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "graph_alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lin-Yijie/Graph-Matching-Networks",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "graph-neural-networks",
        "graph-matching",
        "pytorch"
      ],
      "id": 311
    },
    {
      "name": "pandas-dedupe",
      "one_line_profile": "Pandas integration for the Dedupe library",
      "detailed_description": "A utility that simplifies the use of the Dedupe library for entity resolution and deduplication directly within Pandas DataFrames, facilitating data cleaning workflows.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "deduplication",
        "entity_resolution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lyonk71/pandas-dedupe",
      "help_website": [],
      "license": null,
      "tags": [
        "pandas",
        "deduplication",
        "data-cleaning"
      ],
      "id": 312
    },
    {
      "name": "KG-TACT",
      "one_line_profile": "Topology-Aware Correlations for Inductive Link Prediction",
      "detailed_description": "Implementation of the TACT model for inductive link prediction in knowledge graphs, focusing on topology-aware correlations between relations.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "inductive_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MIRALab-USTC/KG-TACT",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "link-prediction",
        "inductive"
      ],
      "id": 313
    },
    {
      "name": "KGE-HAKE",
      "one_line_profile": "Hierarchy-Aware Knowledge Graph Embeddings",
      "detailed_description": "Implementation of the HAKE model for learning hierarchy-aware knowledge graph embeddings, useful for link prediction and modeling semantic hierarchies.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "knowledge_representation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MIRALab-USTC/KGE-HAKE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kge",
        "hierarchy",
        "link-prediction"
      ],
      "id": 314
    },
    {
      "name": "RREA",
      "one_line_profile": "Relational Reflection Entity Alignment",
      "detailed_description": "Implementation of the RREA method for entity alignment in cross-lingual knowledge graphs, leveraging relational reflection.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "cross_lingual_kg"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MaoXinn/RREA",
      "help_website": [],
      "license": null,
      "tags": [
        "entity-alignment",
        "knowledge-graph",
        "embedding"
      ],
      "id": 315
    },
    {
      "name": "SimplE",
      "one_line_profile": "SimplE Embedding for Link Prediction",
      "detailed_description": "Implementation of the SimplE model for knowledge graph embedding and link prediction, providing a simple yet effective baseline for KG completion.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "kg_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Mehran-k/SimplE",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "knowledge-graph",
        "embedding",
        "link-prediction"
      ],
      "id": 316
    },
    {
      "name": "RelationPrediction",
      "one_line_profile": "R-GCNs for Relational Link Prediction",
      "detailed_description": "Implementation of Relational Graph Convolutional Networks (R-GCNs) specifically for the task of relational link prediction in knowledge graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "graph_neural_networks"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MichSchli/RelationPrediction",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rgcn",
        "link-prediction",
        "knowledge-graph"
      ],
      "id": 317
    },
    {
      "name": "semhash",
      "one_line_profile": "Fast Semantic Text Deduplication & Filtering",
      "detailed_description": "A library for fast semantic text deduplication and filtering, useful for curating large-scale text datasets for scientific NLP or knowledge extraction.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "deduplication",
        "text_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MinishLab/semhash",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "deduplication",
        "hashing"
      ],
      "id": 318
    },
    {
      "name": "recordr",
      "one_line_profile": "Provenance tracking for R",
      "detailed_description": "An R package developed by NCEAS for tracking data provenance, allowing researchers to record and query the history of data processing steps.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "reproducibility"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/NCEAS/recordr",
      "help_website": [],
      "license": null,
      "tags": [
        "provenance",
        "r-package",
        "reproducibility"
      ],
      "id": 319
    },
    {
      "name": "NeMo Curator",
      "one_line_profile": "Scalable data preprocessing and curation toolkit for LLMs",
      "detailed_description": "A scalable toolkit for curating large-scale datasets for Large Language Models, including modules for deduplication, filtering, and data quality control.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_curation",
        "deduplication",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA-NeMo/Curator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "data-curation",
        "deduplication"
      ],
      "id": 320
    },
    {
      "name": "mismo",
      "one_line_profile": "SQL/Ibis powered record linkage library",
      "detailed_description": "A record linkage library that leverages SQL and Ibis for scalable entity resolution, aiming to provide an sklearn-like interface for linking tasks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "entity_resolution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NickCrews/mismo",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "record-linkage",
        "sql",
        "ibis"
      ],
      "id": 321
    },
    {
      "name": "flowcept",
      "one_line_profile": "Runtime provenance for AI and scientific workflows",
      "detailed_description": "A tool from ORNL for capturing, enriching, and querying runtime provenance data in AI and scientific workflows across edge, cloud, and HPC environments.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "workflow_monitoring"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ORNL/flowcept",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "provenance",
        "hpc",
        "workflow"
      ],
      "id": 322
    },
    {
      "name": "er-evaluation",
      "one_line_profile": "End-to-End Evaluation Framework for Entity Resolution",
      "detailed_description": "A framework designed to evaluate entity resolution systems end-to-end, providing metrics and tools for assessing performance.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "evaluation",
        "entity_resolution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OlivierBinette/er-evaluation",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "entity-resolution",
        "evaluation",
        "benchmark"
      ],
      "id": 323
    },
    {
      "name": "OpenBioLink",
      "one_line_profile": "Evaluation framework for biomedical link prediction",
      "detailed_description": "A resource and evaluation framework specifically for link prediction models on heterogeneous biomedical graph data, including benchmarks and datasets.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "benchmark",
        "biomedical_kg"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenBioLink/OpenBioLink",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "biomedical",
        "link-prediction",
        "benchmark"
      ],
      "id": 324
    },
    {
      "name": "SAFRAN",
      "one_line_profile": "Scalable rule application for link prediction",
      "detailed_description": "A scalable and fast engine for applying non-redundant rules for link prediction in knowledge graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "rule_mining"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/OpenBioLink/SAFRAN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "link-prediction",
        "rule-learning",
        "knowledge-graph"
      ],
      "id": 325
    },
    {
      "name": "online_place_recognition",
      "one_line_profile": "Graph-based visual place recognition",
      "detailed_description": "A graph-based image sequence matching tool for visual place recognition in changing environments, used in robotics and SLAM.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "visual_place_recognition"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/PRBonn/online_place_recognition",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "slam",
        "robotics",
        "graph-matching"
      ],
      "id": 326
    },
    {
      "name": "prov-cpl",
      "one_line_profile": "C++ library for collecting and manipulating data provenance (W3C PROV)",
      "detailed_description": "A Core Provenance Library (CPL) that provides a C++ implementation for collecting, storing, and querying data provenance, supporting the W3C PROV standard for scientific reproducibility.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "data_lineage"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/ProvTools/prov-cpl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "provenance",
        "w3c-prov",
        "reproducibility"
      ],
      "id": 327
    },
    {
      "name": "rapidfuzz-duckdb",
      "one_line_profile": "DuckDB extension for fuzzy string matching and deduplication",
      "detailed_description": "A DuckDB community extension that integrates RapidFuzz algorithms, enabling efficient fuzzy search, deduplication, and record linkage directly within database queries for data cleaning workflows.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "deduplication",
        "record_linkage",
        "data_cleaning"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/Query-farm/rapidfuzz",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "duckdb",
        "fuzzy-matching",
        "deduplication"
      ],
      "id": 328
    },
    {
      "name": "ContinuousSubgraphMatching",
      "one_line_profile": "High-performance continuous subgraph matching solver",
      "detailed_description": "An in-depth implementation of continuous subgraph matching algorithms (CSM), providing a solver for detecting complex patterns in evolving graph data, relevant for network analysis.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "pattern_recognition"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/RapidsAtHKUST/ContinuousSubgraphMatching",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "subgraph-matching",
        "graph-algorithms",
        "vldb"
      ],
      "id": 329
    },
    {
      "name": "OpenEars",
      "one_line_profile": "Real-time audio classification sensor for bioacoustics",
      "detailed_description": "A software sensor designed to classify sounds in real-time, used in ecological monitoring and bioacoustics to detect and identify species or events from audio streams.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "classification",
        "data_collection",
        "bioacoustics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SensingClues/OpenEars",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bioacoustics",
        "audio-classification",
        "ecology"
      ],
      "id": 330
    },
    {
      "name": "EAkit",
      "one_line_profile": "Comprehensive toolkit for Entity Alignment in Knowledge Graphs",
      "detailed_description": "A lightweight and extensible PyTorch-based toolkit that implements multiple entity alignment algorithms, facilitating the comparison and application of EA methods in knowledge graph research.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "knowledge_graph_fusion"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/THU-KEG/EAkit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "entity-alignment",
        "knowledge-graph",
        "pytorch"
      ],
      "id": 331
    },
    {
      "name": "TeleMem",
      "one_line_profile": "Memory system for AI agents with semantic deduplication",
      "detailed_description": "A high-performance memory system for AI agents featuring semantic deduplication and long-term dialogue memory, supporting complex reasoning tasks in AI-driven scientific workflows.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "deduplication",
        "memory_management",
        "agent_reasoning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TeleAI-UAGI/telemem",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-memory",
        "deduplication",
        "agents"
      ],
      "id": 332
    },
    {
      "name": "ThinkMatch",
      "one_line_profile": "Research protocol and benchmark for deep graph matching",
      "detailed_description": "A comprehensive research protocol and benchmarking framework for deep graph matching, providing standardized evaluation and implementation of various graph matching algorithms.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Thinklab-SJTU/ThinkMatch",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "graph-matching",
        "benchmark",
        "deep-learning"
      ],
      "id": 333
    },
    {
      "name": "pygmtools",
      "one_line_profile": "Python toolkit for graph matching algorithms",
      "detailed_description": "A Python toolkit dedicated to graph matching, offering efficient implementations of standard and deep learning-based graph matching algorithms for structure analysis.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "structure_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Thinklab-SJTU/pygmtools",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "graph-matching",
        "python",
        "toolkit"
      ],
      "id": 334
    },
    {
      "name": "trrackjs",
      "one_line_profile": "Provenance tracking library for web-based visualizations",
      "detailed_description": "A library designed to track interaction history and data provenance in web-based scientific visualizations, enabling reproducibility and undo/redo capabilities in analysis tools.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "visualization",
        "history_tracking"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/Trrack/trrackjs",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "provenance",
        "visualization",
        "reproducibility"
      ],
      "id": 335
    },
    {
      "name": "Magneto-Matcher",
      "one_line_profile": "Schema matching tool combining small and large language models",
      "detailed_description": "Magneto is a schema matching system that leverages both small and large language models to perform cost-effective and accurate schema alignment, developed by the VIDA lab at NYU.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "schema_matching",
        "entity_resolution"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/VIDA-NYU/magneto-matcher",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "schema-matching",
        "llm",
        "data-integration"
      ],
      "id": 336
    },
    {
      "name": "VisTrails",
      "one_line_profile": "Scientific workflow and provenance management system",
      "detailed_description": "VisTrails is an open-source scientific workflow management system that provides comprehensive provenance infrastructure to maintain detailed history of steps and data derived during exploratory tasks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance_tracking",
        "workflow_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/VisTrails/VisTrails",
      "help_website": [
        "https://vistrails.org"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "provenance",
        "workflow",
        "reproducibility"
      ],
      "id": 337
    },
    {
      "name": "SoptSC",
      "one_line_profile": "Single-cell RNA-seq data analysis toolkit",
      "detailed_description": "SoptSC is a MATLAB tool for single cell data analysis, enabling unsupervised inference of clustering, cell lineage, pseudotime, and cell-cell communication networks from scRNA-seq data.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "clustering",
        "lineage_inference",
        "network_analysis"
      ],
      "application_level": "solver",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/WangShuxiong/SoptSC",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scrna-seq",
        "single-cell",
        "clustering"
      ],
      "id": 338
    },
    {
      "name": "YADL",
      "one_line_profile": "Yet Another Dedupe Library for data deduplication",
      "detailed_description": "YADL is a C library designed for efficient data deduplication tasks, providing core functionality for identifying and removing duplicate records.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "deduplication",
        "entity_resolution"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/YADL/yadl",
      "help_website": [],
      "license": null,
      "tags": [
        "deduplication",
        "record-linkage",
        "c-library"
      ],
      "id": 339
    },
    {
      "name": "elasticsearch-entity-resolution",
      "one_line_profile": "Elasticsearch plugin for entity resolution",
      "detailed_description": "A plugin for Elasticsearch that implements entity resolution capabilities based on the Duke engine, allowing for deduplication and record linkage directly within the search engine.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "deduplication"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/YannBrrd/elasticsearch-entity-resolution",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "elasticsearch",
        "entity-resolution",
        "duke"
      ],
      "id": 340
    },
    {
      "name": "LineagePulse",
      "one_line_profile": "Differential expression analysis for single-cell RNA-seq",
      "detailed_description": "LineagePulse is an R package for performing differential expression analysis on single-cell RNA-seq data, accounting for dropout and other technical noise.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "differential_expression",
        "single-cell_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/YosefLab/LineagePulse",
      "help_website": [],
      "license": null,
      "tags": [
        "scrna-seq",
        "differential-expression",
        "r-package"
      ],
      "id": 341
    },
    {
      "name": "map-matching-2",
      "one_line_profile": "High performance map matching with MDPs and HMMs",
      "detailed_description": "A C++ library for high-performance map matching of GPS trajectories to road networks using Markov Decision Processes (MDPs) and Hidden Markov Models (HMMs), useful for geospatial data analysis.",
      "domains": [
        "Geospatial Science",
        "Transportation"
      ],
      "subtask_category": [
        "map_matching",
        "trajectory_analysis"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/addy90/map-matching-2",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "map-matching",
        "hmm",
        "geospatial"
      ],
      "id": 342
    },
    {
      "name": "AgreementMaker",
      "one_line_profile": "Automated ontology matching system",
      "detailed_description": "AgreementMaker is a comprehensive system for automated ontology matching, capable of aligning complex ontologies to facilitate semantic interoperability and data integration.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "ontology_matching",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/agreementmaker/agreementmaker",
      "help_website": [
        "http://agreementmaker.org"
      ],
      "license": "NOASSERTION",
      "tags": [
        "ontology-matching",
        "semantic-web",
        "alignment"
      ],
      "id": 343
    },
    {
      "name": "AiiDA WorkGraph",
      "one_line_profile": "Workflow management extension for AiiDA",
      "detailed_description": "AiiDA WorkGraph allows for efficient design and management of flexible scientific workflows within the AiiDA ecosystem, featuring GUI support, checkpointing, and provenance tracking.",
      "domains": [
        "Materials Science",
        "G2-02"
      ],
      "subtask_category": [
        "workflow_management",
        "provenance_tracking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/aiidateam/aiida-workgraph",
      "help_website": [
        "https://aiida-workgraph.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "aiida",
        "workflow",
        "provenance"
      ],
      "id": 344
    },
    {
      "name": "CoReNer",
      "one_line_profile": "Multi-task model for NER, relation extraction, and coreference",
      "detailed_description": "CoReNer is a multi-task learning model designed for named-entity recognition, relation extraction, entity mention detection, and coreference resolution, facilitating knowledge extraction and entity normalization.",
      "domains": [
        "G2",
        "G2-02",
        "NLP"
      ],
      "subtask_category": [
        "coreference_resolution",
        "entity_extraction",
        "relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aiola-lab/corener",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ner",
        "coreference-resolution",
        "relation-extraction"
      ],
      "id": 345
    },
    {
      "name": "graphical-record-linkage",
      "one_line_profile": "Graphical record linkage system encapsulation",
      "detailed_description": "A Python encapsulation of the graphical record linkage system proposed by Steorts et al., providing tools for probabilistic entity resolution and deduplication.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "entity_resolution"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/aldengolab/graphical-record-linkage",
      "help_website": [],
      "license": "CC0-1.0",
      "tags": [
        "record-linkage",
        "entity-resolution",
        "probabilistic-matching"
      ],
      "id": 346
    },
    {
      "name": "multilink",
      "one_line_profile": "R package for multifile record linkage",
      "detailed_description": "multilink is an R package implementing multifile partitioning methodology for record linkage and duplicate detection, enabling linkage across multiple datasets.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "duplicate_detection"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/aleshing/multilink",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "record-linkage",
        "r-package",
        "deduplication"
      ],
      "id": 347
    },
    {
      "name": "DeepMatcher",
      "one_line_profile": "Deep learning-based entity and text matching package",
      "detailed_description": "A Python package for performing entity and text matching using deep learning, developed to handle fuzzy matching and record linkage tasks in knowledge graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "record_linkage"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/anhaidgroup/deepmatcher",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "deep-learning",
        "entity-matching",
        "record-linkage"
      ],
      "id": 348
    },
    {
      "name": "py_labeler",
      "one_line_profile": "Labeling tool for the Magellan entity matching system",
      "detailed_description": "A labeling tool designed for the Magellan entity matching ecosystem, facilitating the creation of labeled datasets for training entity resolution models.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_labeling",
        "entity_resolution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/anhaidgroup/py_labeler",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "labeling",
        "magellan",
        "entity-matching"
      ],
      "id": 349
    },
    {
      "name": "Hamilton",
      "one_line_profile": "Dataflow definition framework with built-in lineage and metadata tracking",
      "detailed_description": "A framework for defining testable, modular, and self-documenting dataflows that automatically encodes lineage, tracing, and metadata, suitable for scientific data pipelines.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "workflow_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/apache/hamilton",
      "help_website": [
        "https://hamilton.dagworks.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dataflow",
        "lineage",
        "pipeline"
      ],
      "id": 350
    },
    {
      "name": "FutureOfAIviaAI",
      "one_line_profile": "Link prediction implementation for growing knowledge networks",
      "detailed_description": "Implements high-quality link prediction methods for exponentially growing knowledge networks, specifically applied to predicting trends in AI research.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "network_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/artificial-scientist-lab/FutureOfAIviaAI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "link-prediction",
        "knowledge-network",
        "citation-analysis"
      ],
      "id": 351
    },
    {
      "name": "museum_provenance",
      "one_line_profile": "Library for extracting structured data from museum provenance records",
      "detailed_description": "A Ruby library designed to parse and extract structured data from unstructured museum provenance records, supporting digital humanities and art history research.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "information_extraction"
      ],
      "application_level": "library",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/arttracks/museum_provenance",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "digital-humanities",
        "provenance",
        "parsing"
      ],
      "id": 352
    },
    {
      "name": "dbt-colibri",
      "one_line_profile": "Column lineage extraction tool for dbt projects",
      "detailed_description": "A lightweight tool for extracting and analyzing column-level lineage within dbt projects, aiding in data provenance and impact analysis.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "lineage_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/b-ned/dbt-colibri",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "dbt",
        "lineage",
        "data-engineering"
      ],
      "id": 353
    },
    {
      "name": "dedupe (bakdata)",
      "one_line_profile": "Java DSL for online data deduplication",
      "detailed_description": "A Java Domain Specific Language (DSL) for performing online deduplication of data streams or datasets.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "deduplication",
        "entity_resolution"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/bakdata/dedupe",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "java",
        "deduplication",
        "dsl"
      ],
      "id": 354
    },
    {
      "name": "rensa",
      "one_line_profile": "High-performance MinHash implementation for deduplication",
      "detailed_description": "A Rust-based, high-performance implementation of MinHash with Python bindings, designed for efficient similarity estimation and deduplication of large datasets.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "deduplication",
        "similarity_estimation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/beowolx/rensa",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "minhash",
        "rust",
        "deduplication"
      ],
      "id": 355
    },
    {
      "name": "Bigraph",
      "one_line_profile": "Bipartite-network link prediction library",
      "detailed_description": "A Python library for performing link prediction specifically in bipartite networks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "network_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bi-graph/Bigraph",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "bipartite-network",
        "link-prediction"
      ],
      "id": 356
    },
    {
      "name": "FlexMatcher",
      "one_line_profile": "Schema matching package for mediated schemas",
      "detailed_description": "A Python package for schema matching that handles the problem of matching multiple source schemas to a single mediated schema.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "schema_matching",
        "data_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/biggorilla-gh/flexmatcher",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "schema-matching",
        "data-integration"
      ],
      "id": 357
    },
    {
      "name": "a-la-mode",
      "one_line_profile": "Data pipeline tool with incrementality and provenance",
      "detailed_description": "A tool for describing pure data pipelines that enables incrementality (avoiding repeated work) and maintains data provenance.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/binaryaffairs/a-la-mode",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pipeline",
        "provenance",
        "incrementality"
      ],
      "id": 358
    },
    {
      "name": "wit",
      "one_line_profile": "Algorithms for schema matching",
      "detailed_description": "A collection of algorithms and tools for performing schema matching tasks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "schema_matching"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bkj/wit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "schema-matching",
        "algorithms"
      ],
      "id": 359
    },
    {
      "name": "coref-ee",
      "one_line_profile": "Coreference resolution with entity equalization",
      "detailed_description": "A tool for coreference resolution that implements an entity equalization approach to improve accuracy.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "coreference_resolution",
        "entity_resolution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bkntr/coref-ee",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "coreference",
        "entity-resolution"
      ],
      "id": 360
    },
    {
      "name": "calkit",
      "one_line_profile": "Reproducible pipeline and version control tool for research",
      "detailed_description": "A tool designed to simplify version control, environment management, and reproducible pipelines specifically for research projects.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "reproducibility"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/calkit/calkit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "reproducibility",
        "version-control",
        "research-management"
      ],
      "id": 361
    },
    {
      "name": "EVA",
      "one_line_profile": "Visual pivoting for unsupervised entity alignment",
      "detailed_description": "Implementation of the EVA model for unsupervised entity alignment in knowledge graphs using visual pivoting.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "knowledge_graph"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cambridgeltl/eva",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "entity-alignment",
        "visual-pivoting",
        "unsupervised-learning"
      ],
      "id": 362
    },
    {
      "name": "SapBERT",
      "one_line_profile": "Self-alignment pretraining for biomedical entity linking",
      "detailed_description": "A model and tool for cross-lingual biomedical entity linking, utilizing self-alignment pretraining for BERT.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_linking",
        "biomedical_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cambridgeltl/sapbert",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "biomedical",
        "entity-linking",
        "bert"
      ],
      "id": 363
    },
    {
      "name": "dbt-column-lineage-extractor",
      "one_line_profile": "Column lineage extractor for dbt",
      "detailed_description": "A tool for extracting and analyzing column-level data lineage from dbt projects, supporting data governance and provenance.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "lineage_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/canva-public/dbt-column-lineage-extractor",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dbt",
        "lineage",
        "data-governance"
      ],
      "id": 364
    },
    {
      "name": "ontology-matching-service",
      "one_line_profile": "LLM-based ontology matching service",
      "detailed_description": "A service leveraging Large Language Models (LLMs) to facilitate ontology matching and metadata extraction for scientific data.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "ontology_matching",
        "metadata_extraction"
      ],
      "application_level": "service",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/catalystneuro/ontology-matching-service",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "ontology-matching",
        "neuroscience"
      ],
      "id": 365
    },
    {
      "name": "neonstore",
      "one_line_profile": "Local content-based storage system for NEON data",
      "detailed_description": "A tool for managing and storing data from the National Ecological Observatory Network (NEON) locally, ensuring data persistence and provenance.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_management",
        "provenance"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/cboettig/neonstore",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ecology",
        "neon",
        "data-storage"
      ],
      "id": 366
    },
    {
      "name": "MultiTensor",
      "one_line_profile": "Multilayer network tensor factorization library",
      "detailed_description": "A C++ library for multilayer network tensor factorization, supporting community detection and link prediction tasks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "community_detection"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/cdebacco/MultiTensor",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "tensor-factorization",
        "network-analysis",
        "link-prediction"
      ],
      "id": 367
    },
    {
      "name": "dblink",
      "one_line_profile": "Distributed Bayesian Entity Resolution library for Apache Spark",
      "detailed_description": "A Scala library for performing distributed Bayesian entity resolution (record linkage) on large datasets using Apache Spark, enabling probabilistic deduplication and linking.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "record_linkage"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/cleanzr/dblink",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "entity-resolution",
        "spark",
        "bayesian-inference"
      ],
      "id": 368
    },
    {
      "name": "GetUrRecon",
      "one_line_profile": "Data-centric entity matching and reconciliation toolkit",
      "detailed_description": "A Python toolkit for entity matching, resolution, normalization, and reconciliation, focusing on data processing workflows independent of specific platforms.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "data_normalization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cmharlow/GetUrRecon",
      "help_website": [],
      "license": "Unknown",
      "tags": [
        "entity-matching",
        "reconciliation",
        "normalization"
      ],
      "id": 369
    },
    {
      "name": "PyTrack",
      "one_line_profile": "Map-matching toolbox for vehicle trajectory reconstruction",
      "detailed_description": "A Python toolbox for reconstructing vehicle trajectories using map-matching algorithms, facilitating the alignment of raw GPS data with road networks for transportation research.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "trajectory_alignment",
        "map_matching"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cosbidev/PyTrack",
      "help_website": [],
      "license": "BSD-3-Clause-Clear",
      "tags": [
        "trajectory-reconstruction",
        "map-matching",
        "gps-data"
      ],
      "id": 370
    },
    {
      "name": "RecordLinkage",
      "one_line_profile": "R package for record linkage and data deduplication",
      "detailed_description": "A comprehensive R package providing functions for linking and deduplicating data sets, including methods for blocking, comparison, and classification.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "deduplication"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/cran/RecordLinkage",
      "help_website": [
        "https://cran.r-project.org/package=RecordLinkage"
      ],
      "license": "GPL",
      "tags": [
        "r-package",
        "record-linkage",
        "deduplication"
      ],
      "id": 371
    },
    {
      "name": "DataTracer",
      "one_line_profile": "Library for tracing data lineage and provenance",
      "detailed_description": "A Python library designed to trace the lineage of data, helping to identify the source and processing history of datasets, developed by the Data to AI Lab.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance_tracking",
        "data_lineage"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/data-dev/DataTracer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-lineage",
        "provenance",
        "database"
      ],
      "id": 372
    },
    {
      "name": "Data Prep Kit",
      "one_line_profile": "Toolkit for preparing unstructured data for Generative AI",
      "detailed_description": "An open-source toolkit for processing and preparing unstructured data (text, code, etc.) for Generative AI applications, including deduplication, filtering, and normalization modules.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_preparation",
        "deduplication",
        "normalization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/data-prep-kit/data-prep-kit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-preparation",
        "genai",
        "deduplication"
      ],
      "id": 373
    },
    {
      "name": "Anonlink Entity Service",
      "one_line_profile": "Privacy-preserving record linkage (PPRL) service",
      "detailed_description": "A service for privacy-preserving record linkage, allowing entities to be matched across datasets without revealing sensitive information, developed by CSIRO's Data61.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "privacy_preserving_linkage"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/data61/anonlink-entity-service",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pprl",
        "record-linkage",
        "privacy"
      ],
      "id": 374
    },
    {
      "name": "blocklib",
      "one_line_profile": "Library implementing blocking techniques for record linkage",
      "detailed_description": "A Python library providing implementations of various blocking techniques to reduce the search space for record linkage tasks, developed by CSIRO's Data61.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "blocking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/data61/blocklib",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "blocking",
        "record-linkage",
        "entity-resolution"
      ],
      "id": 375
    },
    {
      "name": "Databricks ARC",
      "one_line_profile": "Automated entity resolution and data linkage solution",
      "detailed_description": "A solution accelerator and library for automated entity resolution and data linkage on the Databricks Lakehouse platform, facilitating intra and inter data linking.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "data_linkage"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/databricks-industry-solutions/auto-data-linkage",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "databricks",
        "entity-resolution",
        "data-fusion"
      ],
      "id": 376
    },
    {
      "name": "PPRL Toolkit",
      "one_line_profile": "Privacy-preserving record linkage toolkit for official statistics",
      "detailed_description": "A toolkit for privacy-preserving record linkage developed by the ONS Data Science Campus, demonstrating next-generation data linkage techniques for official statistics.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "privacy_preserving_linkage"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/datasciencecampus/pprl_toolkit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pprl",
        "official-statistics",
        "data-linkage"
      ],
      "id": 377
    },
    {
      "name": "csvdedupe",
      "one_line_profile": "Command line tool for deduplicating CSV files using the dedupe library",
      "detailed_description": "A command line utility that uses the dedupe library to perform fuzzy matching and deduplication on CSV datasets. It allows users to train the deduplication model interactively and apply it to clean data.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "data_cleaning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dedupeio/csvdedupe",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "deduplication",
        "csv",
        "entity-resolution",
        "cli"
      ],
      "id": 378
    },
    {
      "name": "dedupe",
      "one_line_profile": "Python library for accurate and scalable fuzzy matching and entity resolution",
      "detailed_description": "A python library that uses machine learning (active learning) to perform fuzzy matching, record deduplication, and entity resolution on structured data. It learns from user labeling to improve matching accuracy.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "record_linkage"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dedupeio/dedupe",
      "help_website": [
        "https://dedupe.io/"
      ],
      "license": "MIT",
      "tags": [
        "fuzzy-matching",
        "entity-resolution",
        "machine-learning",
        "deduplication"
      ],
      "id": 379
    },
    {
      "name": "Valentine",
      "one_line_profile": "Experiment suite and framework for schema matching and dataset discovery",
      "detailed_description": "A tool facilitating matching for dataset discovery methods and an extensible experiment suite for evaluating state-of-the-art schema matching methods.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "schema_matching",
        "data_integration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/delftdata/valentine",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "schema-matching",
        "dataset-discovery",
        "benchmark"
      ],
      "id": 380
    },
    {
      "name": "RaceID3_StemID2_package",
      "one_line_profile": "Algorithm for inference of cell types and lineage trees from single-cell RNA-seq data",
      "detailed_description": "An R package implementing the RaceID3 and StemID2 algorithms for the identification of cell types and the inference of lineage trees from single-cell RNA-seq data.",
      "domains": [
        "Bioinformatics"
      ],
      "subtask_category": [
        "cell_type_inference",
        "lineage_tracing"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/dgrun/RaceID3_StemID2_package",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "scrna-seq",
        "bioinformatics",
        "lineage-inference"
      ],
      "id": 381
    },
    {
      "name": "LSHDB",
      "one_line_profile": "Parallel and distributed data engine for record linkage and similarity search",
      "detailed_description": "A parallel and distributed data engine relying on Locality-Sensitive Hashing (LSH) and NoSQL systems to perform record linkage and privacy-preserving record linkage tasks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "similarity_search"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/dimkar121/LSHDB",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "lsh",
        "record-linkage",
        "distributed-systems"
      ],
      "id": 382
    },
    {
      "name": "reclin",
      "one_line_profile": "Probabilistic Record Linkage in R",
      "detailed_description": "An R package for performing probabilistic record linkage, allowing users to link records from different datasets based on probabilistic matching.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "data_integration"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/djvanderlaan/reclin",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "record-linkage",
        "r-package",
        "probabilistic-matching"
      ],
      "id": 383
    },
    {
      "name": "reclin2",
      "one_line_profile": "Record Linkage Toolkit for R (Successor to reclin)",
      "detailed_description": "An improved toolkit for record linkage in R, providing functions for comparing records, generating pairs, and scoring matches.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "data_integration"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/djvanderlaan/reclin2",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "record-linkage",
        "r-package",
        "data-matching"
      ],
      "id": 384
    },
    {
      "name": "kiez",
      "one_line_profile": "Hubness reduced nearest neighbor search for entity alignment",
      "detailed_description": "A Python library for performing hubness-reduced nearest neighbor search, specifically designed for entity alignment tasks using knowledge graph embeddings.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "nearest_neighbor_search"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dobraczka/kiez",
      "help_website": [
        "https://kiez.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "entity-alignment",
        "knowledge-graph",
        "hubness-reduction"
      ],
      "id": 385
    },
    {
      "name": "Dolt",
      "one_line_profile": "SQL database with Git-like version control for data provenance",
      "detailed_description": "Dolt is a SQL database that supports Git-like functionality (clone, fork, branch, merge) for data. It is a critical tool for data provenance, versioning, and collaboration in scientific data management.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_versioning",
        "provenance"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/dolthub/dolt",
      "help_website": [
        "https://www.dolthub.com/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-versioning",
        "sql",
        "provenance",
        "database"
      ],
      "id": 386
    },
    {
      "name": "DoltgreSQL",
      "one_line_profile": "Version controlled PostgreSQL compatible database",
      "detailed_description": "DoltgreSQL brings Dolt's version control capabilities (branching, merging, diffing) to the PostgreSQL ecosystem, enabling data provenance and versioning for Postgres users.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_versioning",
        "provenance"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/dolthub/doltgresql",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "postgresql",
        "data-versioning",
        "provenance"
      ],
      "id": 387
    },
    {
      "name": "doltpy",
      "one_line_profile": "Python API for Dolt database",
      "detailed_description": "A Python library that provides an interface to interact with Dolt databases, facilitating the integration of data versioning and provenance features into Python-based scientific workflows.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_versioning",
        "data_access"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dolthub/doltpy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "python",
        "dolt",
        "data-versioning"
      ],
      "id": 388
    },
    {
      "name": "pgdedupe",
      "one_line_profile": "CLI for deduplicating PostgreSQL records using dedupe library",
      "detailed_description": "A command line interface that applies the datamade/dedupe library to deduplicate records directly within a PostgreSQL database.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "database_cleaning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dssg/pgdedupe",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "postgresql",
        "deduplication",
        "entity-resolution"
      ],
      "id": 389
    },
    {
      "name": "paleotree",
      "one_line_profile": "R library for analyzing and simulating phylogenies of extinct lineages",
      "detailed_description": "An R package for analyzing, time-scaling, and simulating phylogenies of extinct/fossil lineages, including plotting diversity curves for stratigraphic range data.",
      "domains": [
        "Paleontology",
        "Evolutionary Biology"
      ],
      "subtask_category": [
        "phylogenetics",
        "simulation"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/dwbapst/paleotree",
      "help_website": [],
      "license": "CC0-1.0",
      "tags": [
        "phylogeny",
        "paleontology",
        "r-package"
      ],
      "id": 390
    },
    {
      "name": "GraMi",
      "one_line_profile": "Framework for frequent subgraph mining in large graphs",
      "detailed_description": "A framework for frequent subgraph mining in a single large graph, supporting the discovery of frequent patterns and subgraphs with user-defined constraints.",
      "domains": [
        "Graph Mining",
        "Data Analysis"
      ],
      "subtask_category": [
        "subgraph_mining",
        "pattern_discovery"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/ehab-abdelhamid/GraMi",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "graph-mining",
        "subgraph-matching",
        "frequent-pattern-mining"
      ],
      "id": 391
    },
    {
      "name": "LogMap",
      "one_line_profile": "Scalable ontology alignment and repair system with logic-based reasoning",
      "detailed_description": "LogMap is a highly scalable ontology matching system that implements logic-based reasoning to ensure the logical consistency of the generated mappings. It is designed to handle large-scale biomedical ontologies.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": "ontology_alignment",
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/ernestojimenezruiz/logmap-matcher",
      "help_website": [
        "https://github.com/ernestojimenezruiz/logmap-matcher"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ontology-alignment",
        "semantic-web",
        "logic-reasoning"
      ],
      "id": 392
    },
    {
      "name": "Python-Schema-Matching",
      "one_line_profile": "Schema matching tool using XGBoost and Sentence Transformers",
      "detailed_description": "A Python tool designed to perform schema matching tasks on tables by leveraging XGBoost for classification and sentence-transformers for semantic feature extraction.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": "schema_matching",
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fireindark707/Python-Schema-Matching",
      "help_website": [
        "https://github.com/fireindark707/Python-Schema-Matching"
      ],
      "license": "Apache-2.0",
      "tags": [
        "schema-matching",
        "xgboost",
        "sentence-transformers"
      ],
      "id": 393
    },
    {
      "name": "Flyte DataCatalog",
      "one_line_profile": "Service for indexing and versioning parameterized data artifacts",
      "detailed_description": "Data Catalog is a core service within the Flyte ecosystem for indexing parameterized, strongly-typed data artifacts across revisions. It enables data provenance, memoization, and artifact discovery in ML/data workflows.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": "data_provenance",
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/flyteorg/datacatalog",
      "help_website": [
        "https://flyte.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-catalog",
        "provenance",
        "mlops"
      ],
      "id": 394
    },
    {
      "name": "Deduplipy",
      "one_line_profile": "Entity resolution library using active learning",
      "detailed_description": "A Python package for deduplication and entity resolution that uses active learning to train a logistic regression model on pairs of records, minimizing the need for manual labeling.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": "entity_resolution",
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fritshermans/deduplipy",
      "help_website": [
        "https://github.com/fritshermans/deduplipy"
      ],
      "license": "MIT",
      "tags": [
        "deduplication",
        "active-learning",
        "entity-resolution"
      ],
      "id": 395
    },
    {
      "name": "Graphiti",
      "one_line_profile": "Library for building dynamic knowledge graphs from unstructured data",
      "detailed_description": "Graphiti is a Python library designed to build and manage dynamic, temporally-aware knowledge graphs from unstructured text, enabling AI agents to maintain long-term memory and context.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": "knowledge_graph_construction",
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/getzep/graphiti",
      "help_website": [
        "https://github.com/getzep/graphiti"
      ],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "unstructured-data",
        "ai-memory"
      ],
      "id": 396
    },
    {
      "name": "Berkeley Entity Resolution System",
      "one_line_profile": "Joint entity resolution, coreference, and linking system",
      "detailed_description": "The Berkeley Entity Resolution System is a Scala-based tool that jointly solves named entity recognition, coreference resolution, and entity linking problems using a feature-rich discriminative model.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": "entity_resolution",
      "application_level": "solver",
      "primary_language": "Scala",
      "repo_url": "https://github.com/gregdurrett/berkeley-entity",
      "help_website": [
        "https://github.com/gregdurrett/berkeley-entity"
      ],
      "license": "GPL-3.0",
      "tags": [
        "entity-resolution",
        "coreference",
        "nlp"
      ],
      "id": 397
    },
    {
      "name": "Ground",
      "one_line_profile": "Data context service for managing data lineage and versioning",
      "detailed_description": "Ground is an open-source data context service that manages the lineage, versioning, and metadata of data artifacts, providing a vendor-neutral platform for data provenance.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": "data_provenance",
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/ground-context/ground",
      "help_website": [
        "https://github.com/ground-context/ground"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-provenance",
        "metadata-management",
        "data-context"
      ],
      "id": 398
    },
    {
      "name": "Magellan",
      "one_line_profile": "Geospatial data analytics and optimization engine for Spark",
      "detailed_description": "Magellan is a distributed execution engine for geospatial analytics on Apache Spark, providing efficient spatial joins, intersections, and geometric operations for large-scale spatial data.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": "geospatial_analytics",
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/harsha2010/magellan",
      "help_website": [
        "https://github.com/harsha2010/magellan"
      ],
      "license": "Apache-2.0",
      "tags": [
        "geospatial",
        "spark",
        "spatial-join"
      ],
      "id": 399
    },
    {
      "name": "prov-io",
      "one_line_profile": "Provenance management framework for scientific data I/O libraries",
      "detailed_description": "A C library designed to capture and manage provenance information specifically for high-performance computing (HPC) scientific data I/O, enabling traceability of data generation processes.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance_tracking",
        "scientific_io"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/hpc-io/prov-io",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "provenance",
        "hpc",
        "scientific-data"
      ],
      "id": 400
    },
    {
      "name": "raccoon",
      "one_line_profile": "Massively parallel FEM code for phase-field fracture modeling",
      "detailed_description": "A C++ finite element method (FEM) code developed by Dolbow Lab for simulating phase-field fracture mechanics on massively parallel architectures.",
      "domains": [
        "Physics",
        "Materials Science"
      ],
      "subtask_category": [
        "simulation",
        "finite_element_analysis"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/hugary1995/raccoon",
      "help_website": [],
      "license": "LGPL-2.1",
      "tags": [
        "fem",
        "fracture-mechanics",
        "phase-field"
      ],
      "id": 401
    },
    {
      "name": "dataset-dedupe-estimator",
      "one_line_profile": "Estimator for deduplication in large parquet datasets",
      "detailed_description": "A tool to estimate the amount of duplication in large datasets (parquet format), essential for data cleaning and preparation in scientific machine learning pipelines.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_cleaning",
        "deduplication"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/huggingface/dataset-dedupe-estimator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deduplication",
        "dataset-curation",
        "parquet"
      ],
      "id": 402
    },
    {
      "name": "dedupe_estimator",
      "one_line_profile": "Chunk-based deduplication estimation tool",
      "detailed_description": "A C++ implementation for estimating duplication rates in data chunks, serving as a high-performance component for dataset curation and quality control.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_cleaning",
        "deduplication"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/huggingface/dedupe_estimator",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "deduplication",
        "data-quality"
      ],
      "id": 403
    },
    {
      "name": "learned-string-alignments",
      "one_line_profile": "Learning string alignments for entity alias resolution",
      "detailed_description": "A Python library for learning string alignment models to identify entity aliases, supporting entity resolution and normalization tasks in knowledge graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "string_alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/iesl/learned-string-alignments",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "entity-resolution",
        "string-matching",
        "nlp"
      ],
      "id": 404
    },
    {
      "name": "easylink",
      "one_line_profile": "Configurable record linkage and entity resolution pipeline tool",
      "detailed_description": "A tool from IHME for building and running highly configurable record linkage (entity resolution) pipelines, designed for processing public health and demographic data.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "record_linkage"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ihmeuw/easylink",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "record-linkage",
        "entity-resolution",
        "data-pipeline"
      ],
      "id": 405
    },
    {
      "name": "pseudopeople",
      "one_line_profile": "Generator of realistic simulated population data for entity resolution testing",
      "detailed_description": "A Python package that generates realistic simulated data about a fictional US population, specifically designed to test and benchmark entity resolution and record linkage algorithms.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_generation",
        "simulation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ihmeuw/pseudopeople",
      "help_website": [
        "https://pseudopeople.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "simulation",
        "synthetic-data",
        "record-linkage"
      ],
      "id": 406
    },
    {
      "name": "spark-matcher",
      "one_line_profile": "Scalable record matching and entity resolution on Spark",
      "detailed_description": "A Python library for performing record matching and entity resolution at scale using Apache Spark, suitable for processing large scientific or administrative datasets.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "record_matching"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ing-bank/spark-matcher",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "spark",
        "entity-resolution",
        "big-data"
      ],
      "id": 407
    },
    {
      "name": "hlink",
      "one_line_profile": "Hierarchical record linkage tool at scale",
      "detailed_description": "A Python tool developed by IPUMS for performing hierarchical record linkage on large-scale census and demographic datasets.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "entity_resolution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ipums/hlink",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "record-linkage",
        "demography",
        "census-data"
      ],
      "id": 408
    },
    {
      "name": "GMatch4py",
      "one_line_profile": "Graph matching library for Python",
      "detailed_description": "A library implementing various graph matching algorithms (GED, etc.) in Python/Cython, useful for structural analysis and alignment in scientific graph data.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "structure_analysis"
      ],
      "application_level": "library",
      "primary_language": "Cython",
      "repo_url": "https://github.com/jacquesfize/GMatch4py",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-matching",
        "graph-edit-distance",
        "network-analysis"
      ],
      "id": 409
    },
    {
      "name": "graph_matching",
      "one_line_profile": "Maximum matchings finder for undirected graphs",
      "detailed_description": "A Ruby library for finding maximum matchings in undirected graphs, applicable in combinatorial optimization and network analysis tasks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "network_analysis"
      ],
      "application_level": "library",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/jaredbeck/graph_matching",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-theory",
        "matching-algorithm"
      ],
      "id": 410
    },
    {
      "name": "MAGELLAN",
      "one_line_profile": "Automated generation of interpretable computational models for biological reasoning",
      "detailed_description": "A computational tool for generating interpretable models for biological reasoning, supporting hypothesis generation and systems biology analysis.",
      "domains": [
        "Biology",
        "Systems Biology"
      ],
      "subtask_category": [
        "modeling",
        "biological_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jfisher-lab/MAGELLAN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "systems-biology",
        "computational-modeling",
        "reasoning"
      ],
      "id": 411
    },
    {
      "name": "gnn4lp",
      "one_line_profile": "Graph Neural Networks for Link Prediction",
      "detailed_description": "A Python library implementing Graph Neural Networks (GNN) specifically for link prediction tasks in graphs, applicable to knowledge graph completion.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "graph_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jiangnanboy/gnn4lp",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gnn",
        "link-prediction",
        "knowledge-graph"
      ],
      "id": 412
    },
    {
      "name": "GCN-GAN-pytorch",
      "one_line_profile": "GCN-GAN implementation for temporal link prediction",
      "detailed_description": "A PyTorch implementation of GCN-GAN (Graph Convolutional Network - Generative Adversarial Network) for predicting links in temporal graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "temporal_graph_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jiangqn/GCN-GAN-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "temporal-graphs",
        "link-prediction",
        "gan"
      ],
      "id": 413
    },
    {
      "name": "GMTracker",
      "one_line_profile": "Learnable Graph Matching for Multiple Object Tracking",
      "detailed_description": "A PyTorch implementation of a learnable graph matching approach for multiple object tracking, incorporating graph partitioning with deep feature learning.",
      "domains": [
        "Computer Vision",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "object_tracking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jiaweihe1996/GMTracker",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "graph-matching",
        "tracking",
        "deep-learning"
      ],
      "id": 414
    },
    {
      "name": "deep_learn_entity_level_distributed_representation_coreference_chinese",
      "one_line_profile": "Chinese coreference resolution implementation",
      "detailed_description": "An implementation of entity-level distributed representation for coreference resolution in Chinese text, based on Stanford's research.",
      "domains": [
        "NLP",
        "G2-02"
      ],
      "subtask_category": [
        "coreference_resolution",
        "entity_resolution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jingyuanz/deep_learn_entity_level_distributed_representation_coreference_chinese",
      "help_website": [],
      "license": null,
      "tags": [
        "coreference-resolution",
        "nlp",
        "chinese"
      ],
      "id": 415
    },
    {
      "name": "loops",
      "one_line_profile": "JupyterLab extension for iterative and exploratory data analysis",
      "detailed_description": "A JupyterLab extension that supports provenance tracking and iterative workflows for exploratory data analysis in computational notebooks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance_tracking",
        "data_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/jku-vds-lab/loops",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyterlab-extension",
        "provenance",
        "exploratory-analysis"
      ],
      "id": 416
    },
    {
      "name": "fuzzylink",
      "one_line_profile": "Probabilistic record linkage using pretrained text embeddings",
      "detailed_description": "An R package for probabilistic record linkage that leverages pretrained text embeddings to improve matching accuracy, developed for social science research.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "entity_resolution"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/joeornstein/fuzzylink",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "record-linkage",
        "embeddings",
        "r-package"
      ],
      "id": 417
    },
    {
      "name": "Meta-Graph",
      "one_line_profile": "Meta-learning framework for few-shot link prediction",
      "detailed_description": "A Python implementation of meta-learning algorithms designed for few-shot link prediction tasks in graphs, enabling inference on sparse networks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "meta_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/joeybose/Meta-Graph",
      "help_website": [],
      "license": null,
      "tags": [
        "meta-learning",
        "link-prediction",
        "graph-neural-networks"
      ],
      "id": 418
    },
    {
      "name": "OpenHHEA",
      "one_line_profile": "Highly heterogeneous entity alignment toolkit",
      "detailed_description": "An open-source toolkit for highly heterogeneous entity alignment (HHEA) in knowledge graphs, providing methods to align entities across diverse data sources.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "knowledge_graph_fusion"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jxh4945777/OpenHHEA",
      "help_website": [],
      "license": null,
      "tags": [
        "entity-alignment",
        "knowledge-graph",
        "heterogeneous-data"
      ],
      "id": 419
    },
    {
      "name": "fastLink",
      "one_line_profile": "Fast Probabilistic Record Linkage R package",
      "detailed_description": "An R package implementing fast probabilistic record linkage methods for large datasets, capable of handling missing data and providing uncertainty estimates for merged data.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "entity_resolution",
        "data_fusion"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/kosukeimai/fastLink",
      "help_website": [],
      "license": "Unknown",
      "tags": [
        "record-linkage",
        "r-package",
        "probabilistic-matching"
      ],
      "id": 420
    },
    {
      "name": "Kurator-Akka",
      "one_line_profile": "Provenance-enabled workflow platform for biodiversity data",
      "detailed_description": "A workflow platform and toolkit based on Akka actors, specifically designed to curate biodiversity data while automatically tracking and managing data provenance.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance_tracking",
        "data_curation",
        "workflow_management"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/kurator-org/kurator-akka",
      "help_website": [
        "https://doi.org/10.5281/zenodo.1068311"
      ],
      "license": "Unknown",
      "tags": [
        "biodiversity",
        "provenance",
        "workflow",
        "akka"
      ],
      "id": 421
    },
    {
      "name": "Lamindb",
      "one_line_profile": "Data framework for biology with lineage and FAIR principles",
      "detailed_description": "A comprehensive data framework for biology that manages data lineage, ontologies, and reproducibility, integrating with lakehouses, ELNs, and LIMS systems.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_lineage",
        "data_management",
        "provenance",
        "fair_data"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/laminlabs/lamindb",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "biology",
        "data-lineage",
        "fair-data",
        "reproducibility"
      ],
      "id": 422
    },
    {
      "name": "Duke",
      "one_line_profile": "Fast and flexible deduplication engine",
      "detailed_description": "A high-performance deduplication and record linkage engine written in Java, supporting various comparators (Levenshtein, Jaro-Winkler, etc.) and database backends for entity resolution.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "deduplication",
        "entity_resolution",
        "record_linkage"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/larsga/Duke",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deduplication",
        "entity-resolution",
        "java",
        "record-linkage"
      ],
      "id": 423
    },
    {
      "name": "ProvToolbox",
      "one_line_profile": "Toolkit for W3C PROV data model",
      "detailed_description": "A Java toolkit for creating, manipulating, and converting provenance data compliant with the W3C PROV standard, supporting multiple serializations and bindings.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance_management",
        "data_conversion",
        "standard_compliance"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/lucmoreau/ProvToolbox",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "provenance",
        "w3c-prov",
        "java",
        "interoperability"
      ],
      "id": 424
    },
    {
      "name": "DataTracker",
      "one_line_profile": "Pin tool for high-fidelity data provenance",
      "detailed_description": "A binary instrumentation tool using Intel Pin to collect fine-grained data provenance from unmodified executables, enabling detailed lineage tracking of data processing.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance_collection",
        "dynamic_analysis",
        "lineage_tracking"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/m000/dtracker",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "provenance",
        "intel-pin",
        "binary-instrumentation",
        "lineage"
      ],
      "id": 425
    },
    {
      "name": "SuperGlue",
      "one_line_profile": "Graph Neural Network for feature matching",
      "detailed_description": "A pretrained graph neural network model and solver for feature matching and correspondence problems in computer vision, widely used for geometric alignment and registration.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "feature_matching",
        "alignment",
        "image_registration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/magicleap/SuperGluePretrainedNetwork",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "feature-matching",
        "gnn",
        "computer-vision",
        "alignment"
      ],
      "id": 426
    },
    {
      "name": "SingleCellLineage",
      "one_line_profile": "Pipeline for processing GESTALT single-cell lineage tracing data",
      "detailed_description": "A set of scripts and pipelines designed for processing GESTALT (Genome Editing of Synthetic Target Arrays for Lineage Tracing) data at single-cell resolution, enabling lineage reconstruction in developmental biology.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "lineage_tracing",
        "data_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Scala",
      "repo_url": "https://github.com/mckennalab/SingleCellLineage",
      "help_website": [],
      "license": null,
      "tags": [
        "single-cell",
        "lineage-tracing",
        "gestalt",
        "bioinformatics"
      ],
      "id": 427
    },
    {
      "name": "GraphRAG",
      "one_line_profile": "Modular graph-based Retrieval-Augmented Generation system",
      "detailed_description": "A system that uses LLMs to build knowledge graphs from unstructured text and perform retrieval-augmented generation. In scientific contexts, it is used for literature review, evidence extraction, and synthesizing knowledge from scientific corpora.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "question_answering",
        "evidence_synthesis"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/graphrag",
      "help_website": [
        "https://microsoft.github.io/graphrag/"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "knowledge-graph",
        "llm",
        "information-retrieval"
      ],
      "id": 428
    },
    {
      "name": "Decagon",
      "one_line_profile": "Graph Convolutional Neural Network for polypharmacy side effect prediction",
      "detailed_description": "A model implementation for modeling polypharmacy side effects using graph convolutional neural networks on multimodal graphs. It predicts links (side effects) between drug pairs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "interaction_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mims-harvard/decagon",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gnn",
        "polypharmacy",
        "drug-interaction",
        "link-prediction"
      ],
      "id": 429
    },
    {
      "name": "LLAMAS Pyjamas",
      "one_line_profile": "Data reduction pipeline for the Magellan LLAMAS spectrograph",
      "detailed_description": "A data reduction pipeline designed for the LLAMAS (Large Lenslet Array Magellan Spectrograph) instrument, handling the processing of integral field spectrograph data.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_reduction",
        "image_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/mit-kavli-institute/llamas-pyjamas",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "astronomy",
        "spectroscopy",
        "pipeline",
        "data-reduction"
      ],
      "id": 430
    },
    {
      "name": "RSoptSC",
      "one_line_profile": "Cell-cell communication and lineage inference from scRNA-seq data",
      "detailed_description": "An R package for inferring cell-cell communication networks and reconstructing lineage trajectories from single-cell RNA sequencing data using optimization-based approaches.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "lineage_inference",
        "network_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/mkarikom/RSoptSC",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "scrna-seq",
        "lineage-inference",
        "cell-communication",
        "bioinformatics"
      ],
      "id": 431
    },
    {
      "name": "Splink",
      "one_line_profile": "Probabilistic record linkage and entity resolution library",
      "detailed_description": "A Python library for probabilistic record linkage (entity resolution) that allows deduplication and linking of large datasets. It supports multiple SQL backends (DuckDB, Spark, Athena) and is widely used in social science, demography, and epidemiology.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "record_linkage",
        "deduplication"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/moj-analytical-services/splink",
      "help_website": [
        "https://moj-analytical-services.github.io/splink/"
      ],
      "license": "MIT",
      "tags": [
        "entity-resolution",
        "record-linkage",
        "probabilistic-matching",
        "data-linkage"
      ],
      "id": 432
    },
    {
      "name": "CellTagR",
      "one_line_profile": "Analysis tools for CellTagging lineage reconstruction",
      "detailed_description": "An R package designed to analyze data from CellTagging experiments, facilitating clone calling and lineage reconstruction to track cell fate in biological systems.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "lineage_reconstruction",
        "clonal_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/morris-lab/CellTagR",
      "help_website": [],
      "license": null,
      "tags": [
        "lineage-tracing",
        "clonal-analysis",
        "single-cell",
        "r-package"
      ],
      "id": 433
    },
    {
      "name": "LinkPrediction",
      "one_line_profile": "Implementation of Weisfeiler-Lehman Neural Machine for graph link prediction",
      "detailed_description": "A MATLAB/C implementation of the Weisfeiler-Lehman Neural Machine (WLNM) algorithm for link prediction in knowledge graphs and social networks, as presented in KDD 2017.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "graph_learning"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/muhanzhang/LinkPrediction",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "link-prediction",
        "graph-neural-networks",
        "kdd"
      ],
      "id": 434
    },
    {
      "name": "SEAL",
      "one_line_profile": "Graph Neural Network framework for link prediction using subgraph embeddings",
      "detailed_description": "SEAL (Subgraphs, Embeddings, and Attributes for Link prediction) is a framework that extracts enclosing subgraphs around target links to learn heuristics for link prediction in knowledge graphs, as presented in NeurIPS 2018.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "graph_learning"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/muhanzhang/SEAL",
      "help_website": [],
      "license": null,
      "tags": [
        "gnn",
        "link-prediction",
        "neurips"
      ],
      "id": 435
    },
    {
      "name": "Giovanni",
      "one_line_profile": "Web-based environment for analysis and visualization of NASA geophysical data",
      "detailed_description": "An online platform developed by NASA for the display, analysis, and provenance tracking of geophysical parameters from Earth science remote sensing data.",
      "domains": [
        "G2",
        "G2-02",
        "Earth Science"
      ],
      "subtask_category": [
        "data_visualization",
        "provenance_tracking",
        "data_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Perl",
      "repo_url": "https://github.com/nasa/Giovanni",
      "help_website": [
        "https://giovanni.gsfc.nasa.gov/giovanni/"
      ],
      "license": null,
      "tags": [
        "earth-science",
        "nasa",
        "provenance",
        "visualization"
      ],
      "id": 436
    },
    {
      "name": "ncats-adme",
      "one_line_profile": "Prediction models for ADME properties in drug discovery",
      "detailed_description": "Source code for the ADME@NCATS application, hosting QSAR prediction models for Absorption, Distribution, Metabolism, and Excretion (ADME) properties of chemical compounds.",
      "domains": [
        "Chemistry",
        "Pharmacology"
      ],
      "subtask_category": [
        "property_prediction",
        "adme_modeling"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/ncats/ncats-adme",
      "help_website": [
        "https://opendata.ncats.nih.gov/adme/home"
      ],
      "license": null,
      "tags": [
        "drug-discovery",
        "adme",
        "qsar",
        "chemoinformatics"
      ],
      "id": 437
    },
    {
      "name": "BlockingPy",
      "one_line_profile": "Python library for blocking records in entity resolution using ANN",
      "detailed_description": "A Python library that implements blocking techniques for record linkage and data deduplication, utilizing Approximate Nearest Neighbors (ANN) algorithms to scale entity resolution tasks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "blocking",
        "deduplication"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ncn-foreigners/BlockingPy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "record-linkage",
        "deduplication",
        "ann",
        "blocking"
      ],
      "id": 438
    },
    {
      "name": "blocking",
      "one_line_profile": "R package for blocking records in record linkage",
      "detailed_description": "An R package designed for blocking records in record linkage and data deduplication workflows, leveraging approximate nearest neighbours algorithms.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "blocking"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/ncn-foreigners/blocking",
      "help_website": [],
      "license": null,
      "tags": [
        "r-package",
        "record-linkage",
        "deduplication"
      ],
      "id": 439
    },
    {
      "name": "git-mind",
      "one_line_profile": "Protocol for version-controlled semantic knowledge graphs using Git",
      "detailed_description": "A toolkit that leverages Git to create database-less, version-controlled semantic knowledge graphs, enabling distributed cognition and provenance tracking for evolving interpretations.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "knowledge_graph_versioning",
        "provenance"
      ],
      "application_level": "tool",
      "primary_language": "C",
      "repo_url": "https://github.com/neuroglyph/git-mind",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "knowledge-graph",
        "git",
        "version-control",
        "semantic-web"
      ],
      "id": 440
    },
    {
      "name": "comparator",
      "one_line_profile": "R library for similarity measures in record linkage",
      "detailed_description": "An R package providing various similarity and distance measures specifically designed for clustering and record linkage applications.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "similarity_measurement"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/ngmarchant/comparator",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "r",
        "record-linkage",
        "clustering",
        "string-distance"
      ],
      "id": 441
    },
    {
      "name": "NHSE_probabilistic_linkage",
      "one_line_profile": "Pipeline for probabilistic record linkage of healthcare data",
      "detailed_description": "A pipeline used at NHS England to create and evaluate probabilistic linkage models using the Splink package for deduplicating and linking record-level healthcare data.",
      "domains": [
        "G2",
        "G2-02",
        "Healthcare"
      ],
      "subtask_category": [
        "record_linkage",
        "deduplication"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/nhsengland/NHSE_probabilistic_linkage",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nhs",
        "splink",
        "record-linkage",
        "healthcare-data"
      ],
      "id": 442
    },
    {
      "name": "PMF-MMEA",
      "one_line_profile": "Multi-modal entity alignment with progressive modality freezing",
      "detailed_description": "Implementation of the Progressively Modality Freezing method for Multi-Modal Entity Alignment (MMEA), as presented at ACL 2024.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "multi_modal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ninibymilk/PMF-MMEA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "entity-alignment",
        "knowledge-graph",
        "multi-modal",
        "acl2024"
      ],
      "id": 443
    },
    {
      "name": "AliNet",
      "one_line_profile": "Knowledge Graph Alignment Network with Gated Multi-hop Neighborhood Aggregation",
      "detailed_description": "Implementation of AliNet, a neural network model for entity alignment in knowledge graphs that aggregates multi-hop neighborhood information, presented at AAAI 2020.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "graph_neural_networks"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nju-websoft/AliNet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "entity-alignment",
        "knowledge-graph",
        "aaai"
      ],
      "id": 444
    },
    {
      "name": "BootEA",
      "one_line_profile": "Bootstrapping Entity Alignment with Knowledge Graph Embedding",
      "detailed_description": "A bootstrapping approach for entity alignment that iteratively labels likely alignment pairs to improve knowledge graph embedding and alignment performance (IJCAI 2018).",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "bootstrapping"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nju-websoft/BootEA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "entity-alignment",
        "knowledge-graph",
        "ijcai"
      ],
      "id": 445
    },
    {
      "name": "ContEA",
      "one_line_profile": "Continual Entity Alignment for Growing Knowledge Graphs",
      "detailed_description": "A framework for continual entity alignment designed to handle growing knowledge graphs and evolving data, presented at ISWC 2022.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "continual_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nju-websoft/ContEA",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "entity-alignment",
        "continual-learning",
        "knowledge-graph"
      ],
      "id": 446
    },
    {
      "name": "EventEA",
      "one_line_profile": "Benchmarking Entity Alignment for Event-centric Knowledge Graphs",
      "detailed_description": "A benchmarking tool and dataset collection for evaluating entity alignment methods specifically on event-centric knowledge graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nju-websoft/EventEA",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "entity-alignment",
        "event-centric",
        "benchmark"
      ],
      "id": 447
    },
    {
      "name": "JAPE",
      "one_line_profile": "Cross-Lingual Entity Alignment via Joint Attribute-Preserving Embedding",
      "detailed_description": "Implementation of JAPE, a model for cross-lingual entity alignment that jointly embeds structures and attributes of knowledge graphs (ISWC 2017).",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "cross_lingual"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nju-websoft/JAPE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "entity-alignment",
        "knowledge-graph",
        "embedding"
      ],
      "id": 448
    },
    {
      "name": "MultiKE",
      "one_line_profile": "Multi-view Knowledge Graph Embedding for Entity Alignment",
      "detailed_description": "A multi-view embedding framework for entity alignment that combines multiple views of knowledge graphs (name, relation, attribute) to improve alignment accuracy (IJCAI 2019).",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "multi_view_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nju-websoft/MultiKE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "entity-alignment",
        "knowledge-graph",
        "embedding"
      ],
      "id": 449
    },
    {
      "name": "OpenEA",
      "one_line_profile": "Benchmarking library for embedding-based entity alignment",
      "detailed_description": "A comprehensive benchmarking library and framework for evaluating embedding-based entity alignment approaches for knowledge graphs, as published in VLDB 2020.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nju-websoft/OpenEA",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "entity-alignment",
        "benchmark",
        "knowledge-graph",
        "vldb"
      ],
      "id": 450
    },
    {
      "name": "MDGAT-matcher",
      "one_line_profile": "Keypoint matching for point cloud registration using Graph Attention Networks",
      "detailed_description": "A deep learning based solver for point cloud registration (alignment) using Multiplex Dynamic Graph Attention Networks, published in RAL.",
      "domains": [
        "Robotics",
        "Computer Vision"
      ],
      "subtask_category": [
        "point_cloud_registration",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nubot-nudt/MDGAT-matcher",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "point-cloud",
        "registration",
        "graph-attention-network",
        "robotics"
      ],
      "id": 451
    },
    {
      "name": "Alignment",
      "one_line_profile": "Collaborative platform for ontology and vocabulary matching",
      "detailed_description": "A web-based platform designed to support collaborative, system-aided, and user-driven matching and validation of ontologies and vocabularies.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "ontology_matching",
        "vocabulary_alignment"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/okgreece/Alignment",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ontology-matching",
        "semantic-web",
        "alignment"
      ],
      "id": 452
    },
    {
      "name": "winter",
      "one_line_profile": "Java framework for data integration and identity resolution",
      "detailed_description": "WInte.r (Web Data Integration Framework) is a Java framework that implements methods for data pre-processing, schema matching, identity resolution, and data fusion.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_integration",
        "identity_resolution",
        "schema_matching"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/olehmberg/winter",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-integration",
        "identity-resolution",
        "schema-matching"
      ],
      "id": 453
    },
    {
      "name": "elasticsearch-record-linkage",
      "one_line_profile": "ElasticSearch plugin for record linkage scoring metrics",
      "detailed_description": "An ElasticSearch plugin that exposes advanced scoring metrics specifically useful for performing record linkage and deduplication tasks within the search engine.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "deduplication"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/openc/elasticsearch-record-linkage",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "elasticsearch",
        "record-linkage",
        "plugin"
      ],
      "id": 454
    },
    {
      "name": "heritrace",
      "one_line_profile": "Semantic editor for GLAM data with provenance tracking",
      "detailed_description": "A semantic editor designed for GLAM (Galleries, Libraries, Archives, Museums) professionals to enrich data while automatically tracking provenance and changes.",
      "domains": [
        "G2",
        "G2-02",
        "Digital Humanities"
      ],
      "subtask_category": [
        "provenance_tracking",
        "data_enrichment"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/opencitations/heritrace",
      "help_website": [],
      "license": "ISC",
      "tags": [
        "glam",
        "provenance",
        "semantic-web",
        "editor"
      ],
      "id": 455
    },
    {
      "name": "nomenklatura",
      "one_line_profile": "Tool for entity resolution and data integration in investigative graphs",
      "detailed_description": "Nomenklatura is a Python library and command-line tool for performing entity resolution, record linkage, and data integration. It is designed to merge entities from disparate sources (like FollowTheMoney data streams), handling deduplication, canonicalization, and ID mapping, which is essential for constructing high-quality knowledge graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "data_integration",
        "deduplication"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/opensanctions/nomenklatura",
      "help_website": [
        "https://github.com/opensanctions/nomenklatura"
      ],
      "license": "MIT",
      "tags": [
        "entity-resolution",
        "record-linkage",
        "knowledge-graph",
        "deduplication"
      ],
      "id": 456
    },
    {
      "name": "libpostal",
      "one_line_profile": "Fast statistical parser and normalizer for international street addresses",
      "detailed_description": "A C library for parsing and normalizing street addresses around the world using statistical NLP. It is a critical tool for entity normalization in geospatial data processing, enabling the alignment of location entities in scientific and demographic datasets.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_normalization",
        "parsing"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/openvenues/libpostal",
      "help_website": [
        "https://github.com/openvenues/libpostal"
      ],
      "license": "MIT",
      "tags": [
        "address-normalization",
        "nlp",
        "geocoding",
        "entity-alignment"
      ],
      "id": 457
    },
    {
      "name": "lieu",
      "one_line_profile": "Deduplication and geocoding engine based on libpostal",
      "detailed_description": "A Python tool that leverages libpostal to perform deduplication and batch geocoding of addresses and venues. It facilitates the resolution of location entities in large datasets, supporting the construction of geospatial knowledge bases.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "deduplication",
        "entity_resolution",
        "geocoding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/openvenues/lieu",
      "help_website": [
        "https://github.com/openvenues/lieu"
      ],
      "license": "MIT",
      "tags": [
        "deduplication",
        "geospatial",
        "entity-resolution"
      ],
      "id": 458
    },
    {
      "name": "SparkDataLineageCapture",
      "one_line_profile": "Tool to capture data lineage from Spark SQL logical plans",
      "detailed_description": "A Scala library designed to intercept and capture the logical execution plans from Apache Spark jobs. It enables the tracking of data provenance and lineage in large-scale data processing pipelines, which is essential for reproducibility and auditing in scientific data workflows.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance_tracking",
        "data_lineage"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/pauldeschacht/SparkDataLineageCapture",
      "help_website": [
        "https://github.com/pauldeschacht/SparkDataLineageCapture"
      ],
      "license": "Apache-2.0",
      "tags": [
        "spark",
        "data-lineage",
        "provenance"
      ],
      "id": 459
    },
    {
      "name": "Phovea CLUE",
      "one_line_profile": "Provenance tracking and visualization library for visual exploration",
      "detailed_description": "CLUE (Capture, Label, Understand, Explain) is a library within the Phovea ecosystem for tracking and visualizing the provenance of user interactions and data states in visual analysis tools. It supports reproducibility and storytelling in scientific data visualization.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance_tracking",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/phovea/phovea_clue",
      "help_website": [
        "https://github.com/phovea/phovea_clue"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "provenance",
        "visualization",
        "reproducibility"
      ],
      "id": 460
    },
    {
      "name": "EPInformer",
      "one_line_profile": "Tool for gene expression and gene-enhancer link prediction",
      "detailed_description": "A computational tool for predicting gene expression and identifying gene-enhancer interactions (links) using genomic data. It utilizes deep learning or statistical methods to infer regulatory relationships, contributing to the construction of gene regulatory networks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "inference"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/pinellolab/EPInformer",
      "help_website": [
        "https://github.com/pinellolab/EPInformer"
      ],
      "license": null,
      "tags": [
        "genomics",
        "gene-expression",
        "link-prediction",
        "bioinformatics"
      ],
      "id": 461
    },
    {
      "name": "STREAM",
      "one_line_profile": "Single-cell Trajectories Reconstruction, Exploration And Mapping",
      "detailed_description": "An interactive pipeline for reconstructing complex cellular differentiation trajectories from single-cell RNA-sequencing data. It models the developmental paths (provenance/lineage of cells) and visualizes them as a graph structure.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "trajectory_inference",
        "data_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/pinellolab/STREAM",
      "help_website": [
        "https://stream.pinellolab.partners.org/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "single-cell",
        "trajectory-inference",
        "bioinformatics"
      ],
      "id": 462
    },
    {
      "name": "PROV-A",
      "one_line_profile": "Web tool for creating and publishing provenance data as Linked Open Data",
      "detailed_description": "A web-based application designed to facilitate the creation of provenance information conforming to the PROV standard. It allows users to generate and publish provenance graphs as Linked Open Data (LOD), supporting scientific reproducibility and data lineage tracking.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance_generation",
        "linked_data_publishing"
      ],
      "application_level": "service",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/prov-a/prov-a.github.io",
      "help_website": [
        "https://prov-a.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "provenance",
        "linked-data",
        "semantic-web",
        "prov-o"
      ],
      "id": 463
    },
    {
      "name": "jsonmapping",
      "one_line_profile": "Library to transform flat data into nested JSON object graphs",
      "detailed_description": "A Python library used to map flat data structures (like CSV rows) into nested JSON object graphs based on schema definitions. It is widely used in data integration pipelines (e.g., OpenSanctions) to normalize and structure raw data into entity-centric formats.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_transformation",
        "entity_mapping"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pudo-attic/jsonmapping",
      "help_website": [
        "https://github.com/pudo-attic/jsonmapping"
      ],
      "license": "MIT",
      "tags": [
        "data-mapping",
        "json-schema",
        "etl"
      ],
      "id": 464
    },
    {
      "name": "DeepER",
      "one_line_profile": "End-to-End Deep Learning framework for Entity Resolution",
      "detailed_description": "A deep learning-based system for entity resolution (record linkage). It uses recurrent neural networks (RNNs) with attention mechanisms to learn vector representations of tuples and compute similarities, enabling accurate deduplication and alignment of entities in dirty datasets.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "record_linkage"
      ],
      "application_level": "solver",
      "primary_language": "Lua",
      "repo_url": "https://github.com/qcri/DeepER",
      "help_website": [
        "https://github.com/qcri/DeepER"
      ],
      "license": null,
      "tags": [
        "entity-resolution",
        "deep-learning",
        "deduplication"
      ],
      "id": 465
    },
    {
      "name": "deeper-lite",
      "one_line_profile": "Lightweight Python version of the DeepER entity resolution tool",
      "detailed_description": "A Python implementation of the DeepER entity resolution framework. It provides a more accessible and lightweight approach to performing deep learning-based entity alignment and deduplication compared to the original Lua version.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "record_linkage"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/qcri/deeper-lite",
      "help_website": [
        "https://github.com/qcri/deeper-lite"
      ],
      "license": null,
      "tags": [
        "entity-resolution",
        "python",
        "deep-learning"
      ],
      "id": 466
    },
    {
      "name": "linkpred",
      "one_line_profile": "Python library for link prediction in graphs",
      "detailed_description": "A Python package for performing link prediction on graphs. It implements various topological predictors (e.g., Adamic-Adar, Jaccard) and provides a framework for evaluating their performance, useful for inferring missing relations in scientific networks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "network_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rafguns/linkpred",
      "help_website": [
        "https://github.com/rafguns/linkpred"
      ],
      "license": "NOASSERTION",
      "tags": [
        "link-prediction",
        "graph-analysis",
        "network-science"
      ],
      "id": 467
    },
    {
      "name": "Compass",
      "one_line_profile": "Data catalog and lineage platform for data discovery and governance",
      "detailed_description": "An enterprise data catalog system that provides data discovery, metadata management, and lineage tracking. It helps users understand the provenance and relationships of data assets across an organization, supporting data governance and reproducibility.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_catalog",
        "provenance_tracking",
        "metadata_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/raystack/compass",
      "help_website": [
        "https://raystack.org/compass"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-catalog",
        "lineage",
        "governance",
        "metadata"
      ],
      "id": 468
    },
    {
      "name": "maximum-weighted-bipartite-matching",
      "one_line_profile": "Solver for maximum weighted bipartite matching in graphs",
      "detailed_description": "A C++ implementation of an algorithm to compute the maximum weighted bipartite matching of a graph. This algorithmic primitive is frequently used in scientific tasks such as taxonomy alignment, entity resolution, and biological sequence matching.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "optimization"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/rdmpage/maximum-weighted-bipartite-matching",
      "help_website": [
        "https://github.com/rdmpage/maximum-weighted-bipartite-matching"
      ],
      "license": null,
      "tags": [
        "graph-algorithms",
        "bipartite-matching",
        "optimization"
      ],
      "id": 469
    },
    {
      "name": "dupuis",
      "one_line_profile": "UI tool for record deduplication and linkage",
      "detailed_description": "A Python-based user interface tool designed to assist in the manual review and active learning phases of record deduplication and linkage. It helps users label potential duplicates to train or validate entity resolution models.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "deduplication",
        "record_linkage",
        "data_labeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/redapple/dupuis",
      "help_website": [
        "https://github.com/redapple/dupuis"
      ],
      "license": "MIT",
      "tags": [
        "deduplication",
        "record-linkage",
        "ui"
      ],
      "id": 470
    },
    {
      "name": "EA_for_KG",
      "one_line_profile": "Benchmark library for Knowledge Graph Entity Alignment",
      "detailed_description": "A comprehensive library and benchmark suite for Knowledge Graph Entity Alignment (EA). It contains implementations of state-of-the-art representation learning-based algorithms for aligning entities across different knowledge graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ruizhang-ai/EA_for_KG",
      "help_website": [
        "https://github.com/ruizhang-ai/EA_for_KG"
      ],
      "license": "NOASSERTION",
      "tags": [
        "entity-alignment",
        "knowledge-graph",
        "benchmarking",
        "representation-learning"
      ],
      "id": 471
    },
    {
      "name": "deep-graph-matching-consensus",
      "one_line_profile": "PyTorch implementation of Deep Graph Matching Consensus",
      "detailed_description": "A robust PyTorch implementation of the Deep Graph Matching Consensus algorithm. It provides a solver for graph matching problems, which involves finding correspondences between nodes in two graphs, a fundamental task in structural analysis and entity alignment.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rusty1s/deep-graph-matching-consensus",
      "help_website": [
        "https://github.com/rusty1s/deep-graph-matching-consensus"
      ],
      "license": "MIT",
      "tags": [
        "graph-matching",
        "pytorch",
        "deep-learning"
      ],
      "id": 472
    },
    {
      "name": "s3git",
      "one_line_profile": "Distributed version control tool for large datasets on cloud storage",
      "detailed_description": "A command-line tool that brings git-like versioning to large datasets stored in cloud object storage (S3). It supports deduplication and versioning of massive data repositories, enabling data lineage and management for scientific datasets that exceed typical git limits.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_versioning",
        "deduplication",
        "data_management"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/s3git/s3git",
      "help_website": [
        "https://github.com/s3git/s3git"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-versioning",
        "s3",
        "deduplication",
        "git-for-data"
      ],
      "id": 473
    },
    {
      "name": "KnowledgeGraphQA-Langgraph",
      "one_line_profile": "System for generating knowledge graphs from text and performing Q&A",
      "detailed_description": "An AI-powered tool that converts unstructured text into knowledge graphs and enables graph-based question answering. It integrates LLMs with Neo4j to automate the extraction of entities and relations, facilitating the construction of queryable knowledge bases.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_construction",
        "question_answering",
        "extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/samitugal/KnowledgeGraphQA-Langgraph",
      "help_website": [
        "https://github.com/samitugal/KnowledgeGraphQA-Langgraph"
      ],
      "license": null,
      "tags": [
        "knowledge-graph",
        "llm",
        "neo4j",
        "text-to-graph"
      ],
      "id": 474
    },
    {
      "name": "MagellanMapper",
      "one_line_profile": "Tool for 3D bioimage annotation and atlas registration",
      "detailed_description": "A graphical interface and software suite for annotating 3D biological images, performing atlas registration (alignment), and quantifying regional data. It is used in neuroscience and microscopy to map experimental data to reference atlases.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "image_registration",
        "annotation",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sanderslab/magellanmapper",
      "help_website": [
        "https://github.com/sanderslab/magellanmapper"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "bioimaging",
        "atlas-registration",
        "microscopy",
        "annotation"
      ],
      "id": 475
    },
    {
      "name": "llm-data-annotation",
      "one_line_profile": "Framework using LLMs and Active Learning for data annotation",
      "detailed_description": "A framework that leverages Large Language Models (LLMs) and Iterative Active Learning to automate and enhance data annotation. It integrates CleanLab for confident learning to ensure high-quality datasets, supporting the creation of training data for scientific models.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_annotation",
        "quality_control",
        "active_learning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/saran9991/llm-data-annotation",
      "help_website": [
        "https://github.com/saran9991/llm-data-annotation"
      ],
      "license": "MIT",
      "tags": [
        "data-annotation",
        "llm",
        "active-learning",
        "cleanlab"
      ],
      "id": 476
    },
    {
      "name": "Event Provenance Registry",
      "one_line_profile": "Service for managing and tracking event provenance",
      "detailed_description": "A service designed to manage, store, and track the provenance of events and their receivers. It provides a registry for auditing data flows and event chains, which is critical for establishing trust and lineage in distributed data processing systems.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance_tracking",
        "event_logging"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/sassoftware/event-provenance-registry",
      "help_website": [
        "https://github.com/sassoftware/event-provenance-registry"
      ],
      "license": "Apache-2.0",
      "tags": [
        "provenance",
        "event-tracking",
        "registry"
      ],
      "id": 477
    },
    {
      "name": "DVCP-TE",
      "one_line_profile": "Simulation model of the Tennessee Eastman chemical process for security research",
      "detailed_description": "A simulation implementation of the Tennessee Eastman chemical process, designed as a testbed for research in industrial control systems (ICS) security and process control. It generates data for analyzing cyber-physical attacks and defense mechanisms.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "simulation",
        "process_control_modeling"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/satejnik/DVCP-TE",
      "help_website": [
        "https://github.com/satejnik/DVCP-TE"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "simulation",
        "chemical-process",
        "ics-security",
        "tennessee-eastman"
      ],
      "id": 478
    },
    {
      "name": "JedAIToolkit",
      "one_line_profile": "High scalability toolkit for Entity Resolution and Record Linkage",
      "detailed_description": "An open source, high scalability toolkit in Java for Entity Resolution, offering state-of-the-art methods for data cleaning and integration tasks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "record_linkage"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/scify/JedAIToolkit",
      "help_website": [
        "https://github.com/scify/JedAIToolkit"
      ],
      "license": "Apache-2.0",
      "tags": [
        "entity-resolution",
        "data-integration",
        "deduplication"
      ],
      "id": 479
    },
    {
      "name": "OntoAligner",
      "one_line_profile": "Toolkit for Ontology Alignment and matching",
      "detailed_description": "A Python Toolkit for Ontology Alignment, facilitating the matching and integration of different ontological structures.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "ontology_alignment",
        "schema_matching"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sciknoworg/OntoAligner",
      "help_website": [
        "https://pypi.org/project/OntoAligner/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ontology-alignment",
        "knowledge-graph",
        "semantic-web"
      ],
      "id": 480
    },
    {
      "name": "event_entity_coref_ecb_plus",
      "one_line_profile": "Cross-document event and entity coreference resolution system",
      "detailed_description": "A system for resolving coreferences of events and entities across multiple documents, trained on the ECB+ corpus.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "coreference_resolution",
        "event_coreference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/shanybar/event_entity_coref_ecb_plus",
      "help_website": [
        "https://github.com/shanybar/event_entity_coref_ecb_plus"
      ],
      "license": null,
      "tags": [
        "coreference-resolution",
        "nlp",
        "event-extraction"
      ],
      "id": 481
    },
    {
      "name": "SpEL",
      "one_line_profile": "Structured Prediction for Entity Linking",
      "detailed_description": "A framework for Entity Linking using structured prediction methods to disambiguate and link entities to a knowledge base.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_linking",
        "disambiguation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/shavarani/SpEL",
      "help_website": [
        "https://github.com/shavarani/SpEL"
      ],
      "license": "GPL-3.0",
      "tags": [
        "entity-linking",
        "structured-prediction",
        "nlp"
      ],
      "id": 482
    },
    {
      "name": "NeuralCoMapping",
      "one_line_profile": "Multi-Robot Active Mapping via Neural Bipartite Graph Matching",
      "detailed_description": "Implementation of a neural bipartite graph matching approach for multi-robot active mapping and spatial alignment.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "robot_mapping",
        "graph_matching"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/siyandong/NeuralCoMapping",
      "help_website": [
        "https://github.com/siyandong/NeuralCoMapping"
      ],
      "license": "MIT",
      "tags": [
        "slam",
        "multi-robot",
        "graph-matching"
      ],
      "id": 483
    },
    {
      "name": "GIMS",
      "one_line_profile": "Graph-Based Image Matching System",
      "detailed_description": "A system for matching images using graph-based structures, useful for computer vision and structural alignment tasks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "image_matching",
        "graph_matching"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/songxf1024/GIMS",
      "help_website": [
        "https://github.com/songxf1024/GIMS"
      ],
      "license": "MIT",
      "tags": [
        "image-matching",
        "computer-vision",
        "graph-theory"
      ],
      "id": 484
    },
    {
      "name": "spindle-token",
      "one_line_profile": "Privacy Preserving Record Linkage (OPPRL) implementation",
      "detailed_description": "PySpark implementation of the Open Privacy Preserving Record Linkage (OPPRL) specification for secure entity resolution.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "record_linkage",
        "privacy_preserving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/spindle-health/spindle-token",
      "help_website": [
        "https://github.com/spindle-health/spindle-token"
      ],
      "license": "Apache-2.0",
      "tags": [
        "record-linkage",
        "privacy",
        "pyspark"
      ],
      "id": 485
    },
    {
      "name": "java_data_lineage",
      "one_line_profile": "SQL and stored procedure data lineage analyzer in Java",
      "detailed_description": "A tool to analyze and extract data lineage from SQL scripts and stored procedures, aiding in data provenance tracking.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_lineage",
        "provenance"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/sqlparser/java_data_lineage",
      "help_website": [
        "https://github.com/sqlparser/java_data_lineage"
      ],
      "license": null,
      "tags": [
        "data-lineage",
        "sql-parser",
        "provenance"
      ],
      "id": 486
    },
    {
      "name": "python_data_lineage",
      "one_line_profile": "Data lineage analysis tools in Python",
      "detailed_description": "Python-based tools for extracting and visualizing data lineage from SQL and other data processing scripts.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_lineage",
        "provenance"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sqlparser/python_data_lineage",
      "help_website": [
        "https://github.com/sqlparser/python_data_lineage"
      ],
      "license": null,
      "tags": [
        "data-lineage",
        "python",
        "sql"
      ],
      "id": 487
    },
    {
      "name": "MedType",
      "one_line_profile": "Medical Entity Linking with Semantic Type Prediction",
      "detailed_description": "A tool for improving medical entity linking by incorporating semantic type prediction, specifically designed for biomedical text.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_linking",
        "biomedical_nlp"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/svjan5/medtype",
      "help_website": [
        "https://github.com/svjan5/medtype"
      ],
      "license": "Apache-2.0",
      "tags": [
        "entity-linking",
        "medical-nlp",
        "semantic-typing"
      ],
      "id": 488
    },
    {
      "name": "LinChemIn",
      "one_line_profile": "Linked Chemical Information toolkit for reaction data analysis",
      "detailed_description": "A Python toolkit that leverages the connectivity of Chemical Reaction Data to provide insights and metrics on predicted synthetic routes.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "chemical_reaction_analysis",
        "synthesis_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/syngenta/linchemin",
      "help_website": [
        "https://github.com/syngenta/linchemin"
      ],
      "license": "MIT",
      "tags": [
        "cheminformatics",
        "reaction-data",
        "synthesis-planning"
      ],
      "id": 489
    },
    {
      "name": "Crosslingula-KG-Matching",
      "one_line_profile": "Cross-lingual Knowledge Graph Alignment via Graph Matching Neural Network",
      "detailed_description": "Implementation of Graph Matching Neural Networks for aligning entities across cross-lingual knowledge graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "cross_lingual_matching"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/syxu828/Crosslingula-KG-Matching",
      "help_website": [
        "https://github.com/syxu828/Crosslingula-KG-Matching"
      ],
      "license": null,
      "tags": [
        "knowledge-graph",
        "entity-alignment",
        "gnn"
      ],
      "id": 490
    },
    {
      "name": "data-lineage-parent",
      "one_line_profile": "Big data lineage analysis platform using Neo4j",
      "detailed_description": "A system to parse and generate data lineage from Hive, Sqoop, HBase, and Spark jobs, visualizing dependencies in Neo4j.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_lineage",
        "provenance"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/thestyleofme/data-lineage-parent",
      "help_website": [
        "https://github.com/thestyleofme/data-lineage-parent"
      ],
      "license": null,
      "tags": [
        "data-lineage",
        "neo4j",
        "big-data"
      ],
      "id": 491
    },
    {
      "name": "IEAJKE",
      "one_line_profile": "Iterative Entity Alignment via Joint Knowledge Embeddings",
      "detailed_description": "A solver for entity alignment in knowledge graphs using joint knowledge embeddings and iterative training.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "knowledge_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/thunlp/IEAJKE",
      "help_website": [
        "https://github.com/thunlp/IEAJKE"
      ],
      "license": null,
      "tags": [
        "entity-alignment",
        "knowledge-graph",
        "embedding"
      ],
      "id": 492
    },
    {
      "name": "MuGNN",
      "one_line_profile": "Multi-Channel Graph Neural Network for Entity Alignment",
      "detailed_description": "A multi-channel graph neural network approach for aligning entities between different knowledge graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "gnn"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/thunlp/MuGNN",
      "help_website": [
        "https://github.com/thunlp/MuGNN"
      ],
      "license": null,
      "tags": [
        "entity-alignment",
        "gnn",
        "knowledge-graph"
      ],
      "id": 493
    },
    {
      "name": "explore-and-evaluate",
      "one_line_profile": "Entity Alignment using Attributes, Values, and Structures",
      "detailed_description": "A framework for exploring and evaluating the role of attributes, values, and structures in knowledge graph entity alignment.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/thunlp/explore-and-evaluate",
      "help_website": [
        "https://github.com/thunlp/explore-and-evaluate"
      ],
      "license": null,
      "tags": [
        "entity-alignment",
        "knowledge-graph",
        "benchmarking"
      ],
      "id": 494
    },
    {
      "name": "tokern-data-lineage",
      "one_line_profile": "Data Lineage generation and visualization from query history",
      "detailed_description": "A tool to parse SQL query history and generate column-level data lineage graphs for data governance and debugging.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_lineage",
        "provenance"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tokern/data-lineage",
      "help_website": [
        "https://tokern.io/lineage"
      ],
      "license": "MIT",
      "tags": [
        "data-lineage",
        "sql-parsing",
        "visualization"
      ],
      "id": 495
    },
    {
      "name": "trinity-ie",
      "one_line_profile": "Information extraction pipeline for coreference and linking",
      "detailed_description": "A comprehensive information extraction pipeline that includes modules for coreference resolution, named entity linking, and relationship extraction.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "information_extraction",
        "coreference_resolution",
        "entity_linking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/tomasonjo/trinity-ie",
      "help_website": [
        "https://github.com/tomasonjo/trinity-ie"
      ],
      "license": null,
      "tags": [
        "information-extraction",
        "nlp",
        "pipeline"
      ],
      "id": 496
    },
    {
      "name": "SQLServer-Data-Lineage",
      "one_line_profile": "Data Lineage for Microsoft SQL Server and Azure Synapse",
      "detailed_description": "A utility to extract and visualize data lineage specifically for SQL Server and Azure Synapse environments.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_lineage",
        "provenance"
      ],
      "application_level": "tool",
      "primary_language": "TSQL",
      "repo_url": "https://github.com/tomaztk/SQLServer-Data-Lineage",
      "help_website": [
        "https://github.com/tomaztk/SQLServer-Data-Lineage"
      ],
      "license": "MIT",
      "tags": [
        "sql-server",
        "data-lineage",
        "azure"
      ],
      "id": 497
    },
    {
      "name": "LineageExplorer",
      "one_line_profile": "SARS-CoV2 variant growth rate estimation tool",
      "detailed_description": "A tool to estimate the growth rate advantage of SARS-CoV2 variants of concern using genomic surveillance data.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "viral_lineage_analysis",
        "epidemiology"
      ],
      "application_level": "solver",
      "primary_language": "R",
      "repo_url": "https://github.com/tomwenseleers/LineageExplorer",
      "help_website": [
        "https://github.com/tomwenseleers/LineageExplorer"
      ],
      "license": null,
      "tags": [
        "genomics",
        "covid-19",
        "epidemiology"
      ],
      "id": 498
    },
    {
      "name": "stairlight",
      "one_line_profile": "Data lineage tool for SQL table dependencies",
      "detailed_description": "A data lineage tool that detects table dependencies from rendered SQL statements, supporting file-based configuration.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "data_lineage",
        "provenance"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/tosh2230/stairlight",
      "help_website": [
        "https://github.com/tosh2230/stairlight"
      ],
      "license": "MIT",
      "tags": [
        "data-lineage",
        "sql",
        "dependency-tracking"
      ],
      "id": 499
    },
    {
      "name": "DVC",
      "one_line_profile": "Open-source version control system for machine learning projects and data",
      "detailed_description": "Data Version Control (DVC) is a tool for data science and machine learning projects that replaces spreadsheets and ad-hoc scripts with a Git-like workflow. It handles data versioning, experiment tracking, and pipeline management.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "versioning",
        "workflow_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/treeverse/dvc",
      "help_website": [
        "https://dvc.org/doc"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-versioning",
        "mlops",
        "reproducibility",
        "provenance"
      ],
      "id": 500
    },
    {
      "name": "DVCLive",
      "one_line_profile": "Library for logging machine learning metrics and tracking experiments",
      "detailed_description": "DVCLive is a Python library for logging machine learning metrics, parameters, and model artifacts. It integrates with DVC to provide experiment tracking and visualization capabilities.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "experiment_tracking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/treeverse/dvclive",
      "help_website": [
        "https://dvc.org/doc/dvclive"
      ],
      "license": "Apache-2.0",
      "tags": [
        "metrics-logging",
        "experiment-tracking",
        "mlops"
      ],
      "id": 501
    },
    {
      "name": "SERF",
      "one_line_profile": "Stanford Entity-Resolution Framework",
      "detailed_description": "A generic infrastructure for Entity Resolution (ER) that provides a framework for resolving entities in data sets. It supports various ER algorithms and configurations.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "record_linkage"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/trevorprater/serf",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "entity-resolution",
        "data-cleaning",
        "record-linkage"
      ],
      "id": 502
    },
    {
      "name": "Spectral-Gromov-Wasserstein",
      "one_line_profile": "Graph matching and clustering via optimal transport",
      "detailed_description": "Implements a method for graph matching and clustering by comparing heat kernels via optimal transport, specifically using the Spectral Gromov-Wasserstein distance.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/trneedham/Spectral-Gromov-Wasserstein",
      "help_website": [],
      "license": null,
      "tags": [
        "graph-matching",
        "optimal-transport",
        "clustering"
      ],
      "id": 503
    },
    {
      "name": "prov",
      "one_line_profile": "Python library for W3C Provenance Data Model (PROV)",
      "detailed_description": "A library that provides an implementation of the W3C Provenance Data Model (PROV) in Python, allowing for the creation, manipulation, and serialization of provenance information.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "data_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/trungdong/prov",
      "help_website": [
        "https://prov.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "provenance",
        "w3c-prov",
        "metadata"
      ],
      "id": 504
    },
    {
      "name": "ComplEx",
      "one_line_profile": "Complex Embeddings for Link Prediction in Knowledge Graphs",
      "detailed_description": "Source code for experiments involving Complex Embeddings for Simple Link Prediction and Knowledge Graph Completion via Complex Tensor Factorization.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "knowledge_graph_completion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ttrouill/complex",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "knowledge-graph",
        "embedding",
        "link-prediction"
      ],
      "id": 505
    },
    {
      "name": "DyGLIP",
      "one_line_profile": "Dynamic Graph Model with Link Prediction for Object Tracking",
      "detailed_description": "Implementation of DyGLIP, a dynamic graph model that utilizes link prediction for accurate multi-camera multiple object tracking.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "object_tracking",
        "dynamic_graph"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/uark-cviu/DyGLIP",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "computer-vision",
        "graph-neural-networks",
        "tracking"
      ],
      "id": 506
    },
    {
      "name": "OpenGlue",
      "one_line_profile": "Graph Neural Net Based Pipeline for Image Matching",
      "detailed_description": "An open-source pipeline based on Graph Neural Networks for image matching, serving as a free alternative to SuperGlue for feature matching tasks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "alignment",
        "image_matching"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ucuapps/OpenGlue",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "image-matching",
        "graph-neural-networks",
        "feature-matching"
      ],
      "id": 507
    },
    {
      "name": "onefl-deduper",
      "one_line_profile": "Patient de-duplication tool for Electronic Health Records",
      "detailed_description": "A Python package designed for probabilistic record linkage and de-duplication of patient entities in Electronic Health Record (EHR) datasets.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "deduplication"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ufbmi/onefl-deduper",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ehr",
        "record-linkage",
        "healthcare"
      ],
      "id": 508
    },
    {
      "name": "Magellan (Ultralytics)",
      "one_line_profile": "Earth observation software powered by Machine Learning",
      "detailed_description": "Software for Earth observation that utilizes Machine Learning, capable of visualization in Google Maps and WebGL Earth.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "visualization",
        "earth_observation"
      ],
      "application_level": "platform",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/ultralytics/magellan",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "earth-observation",
        "satellite-imagery",
        "visualization"
      ],
      "id": 509
    },
    {
      "name": "RLTK",
      "one_line_profile": "Record Linkage ToolKit",
      "detailed_description": "A comprehensive open-source toolkit for Record Linkage (Entity Resolution) that provides components for blocking, matching, and clustering entities.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "record_linkage"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/usc-isi-i2/rltk",
      "help_website": [
        "https://rltk.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "record-linkage",
        "entity-resolution",
        "data-integration"
      ],
      "id": 510
    },
    {
      "name": "nominally",
      "one_line_profile": "Name parser for record linkage",
      "detailed_description": "A library designed to parse human names into structured components to support record linkage and entity resolution tasks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "normalization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vaneseltine/nominally",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "name-parsing",
        "record-linkage",
        "normalization"
      ],
      "id": 511
    },
    {
      "name": "SGMNet",
      "one_line_profile": "Seeded Graph Matching Network for feature matching",
      "detailed_description": "Implementation of the Seeded Graph Matching Network (SGMNet) for learning to match features, as presented in ICCV 2021.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/vdvchen/SGMNet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-matching",
        "computer-vision",
        "feature-matching"
      ],
      "id": 512
    },
    {
      "name": "MinoanER",
      "one_line_profile": "Entity Resolution framework",
      "detailed_description": "A framework for Entity Resolution (ER) designed to identify descriptions referring to the same entity within or across knowledge bases.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "data_integration"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/vefthym/MinoanER",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "entity-resolution",
        "big-data",
        "blocking"
      ],
      "id": 513
    },
    {
      "name": "OpenCorr",
      "one_line_profile": "Digital Image and Volume Correlation Library",
      "detailed_description": "An open-source C++ library for Digital Image Correlation (2D-DIC) and Digital Volume Correlation (3D-DVC) analysis.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "alignment",
        "image_correlation"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/vincentjzy/OpenCorr",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "dic",
        "dvc",
        "image-correlation"
      ],
      "id": 514
    },
    {
      "name": "EMGCN",
      "one_line_profile": "Entity Alignment with Multi-order Convolutional Networks",
      "detailed_description": "Implementation of the paper 'Entity Alignment for Knowledge Graphs with Multi-order Convolutional Networks'.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "knowledge_graph"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/vinhsuhi/EMGCN",
      "help_website": [],
      "license": null,
      "tags": [
        "entity-alignment",
        "gcn",
        "knowledge-graph"
      ],
      "id": 515
    },
    {
      "name": "entity-embed",
      "one_line_profile": "Vector-based Entity Resolution library",
      "detailed_description": "A PyTorch library for transforming entities into vectors to support scalable Record Linkage and Entity Resolution using Approximate Nearest Neighbors.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "embedding"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/vintasoftware/entity-embed",
      "help_website": [
        "https://github.com/vintasoftware/entity-embed"
      ],
      "license": "MIT",
      "tags": [
        "entity-resolution",
        "pytorch",
        "embeddings"
      ],
      "id": 516
    },
    {
      "name": "trrack",
      "one_line_profile": "Provenance tracking library for visualizations",
      "detailed_description": "A library for tracking history and provenance in web-based visualizations, enabling undo/redo and state management.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/visdesignlab/trrack",
      "help_website": [
        "https://trrack.js.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "provenance",
        "visualization",
        "history-tracking"
      ],
      "id": 517
    },
    {
      "name": "SphereGlue",
      "one_line_profile": "Feature matching for spherical images",
      "detailed_description": "A Graph Neural Network based feature matching tool specifically designed for high-resolution spherical images.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "alignment",
        "feature_matching"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/vishalsharbidar/SphereGlue",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "spherical-images",
        "feature-matching",
        "gnn"
      ],
      "id": 518
    },
    {
      "name": "PipelineIE",
      "one_line_profile": "Information Extraction pipeline with Entity Resolution",
      "detailed_description": "A pipeline for information extraction from text that includes modules for coreference resolution and entity resolution, supporting custom models.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "information_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/vj1494/PipelineIE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "information-extraction",
        "nlp",
        "entity-resolution"
      ],
      "id": 519
    },
    {
      "name": "graph-representation-learning",
      "one_line_profile": "Autoencoders for Link Prediction",
      "detailed_description": "Implementation of autoencoders for link prediction and semi-supervised node classification in graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "node_classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/vuptran/graph-representation-learning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "link-prediction",
        "autoencoder",
        "graph-learning"
      ],
      "id": 520
    },
    {
      "name": "bayesian-record-linkage",
      "one_line_profile": "Bayesian models for record linkage",
      "detailed_description": "Implementation of Bayesian approaches to graphical record linkage and de-duplication, based on the SMERED model.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "record_linkage"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wammar/bayesian-record-linkage",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "bayesian",
        "record-linkage",
        "deduplication"
      ],
      "id": 521
    },
    {
      "name": "lgl-feature-matching",
      "one_line_profile": "Lifelong Graph Learning for Feature Matching",
      "detailed_description": "Implementation of Lifelong Graph Learning methods applied to the task of feature matching.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "alignment",
        "feature_matching"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wang-chen/lgl-feature-matching",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "graph-learning",
        "feature-matching",
        "lifelong-learning"
      ],
      "id": 522
    },
    {
      "name": "MMGraphRAG",
      "one_line_profile": "Multi-modal knowledge graph framework",
      "detailed_description": "A multi-modal knowledge graph-based framework designed to enhance complex reasoning tasks like document question-answering by integrating text and image data.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "knowledge_fusion",
        "reasoning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/wanxueyao/MMGraphRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "knowledge-graph",
        "rag"
      ],
      "id": 523
    },
    {
      "name": "TraceFL",
      "one_line_profile": "Provenance tracking for Federated Learning",
      "detailed_description": "A mechanism for Federated Learning that achieves interpretability by tracking neuron provenance to identify clients responsible for global model predictions.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "federated_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/warisgill/TraceFL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "provenance",
        "federated-learning",
        "interpretability"
      ],
      "id": 524
    },
    {
      "name": "PyDI",
      "one_line_profile": "End-to-end data integration framework",
      "detailed_description": "A framework providing methods for end-to-end data integration, covering schema matching, data translation, entity matching, and data fusion.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "schema_matching",
        "data_fusion"
      ],
      "application_level": "framework",
      "primary_language": "HTML",
      "repo_url": "https://github.com/wbsg-uni-mannheim/PyDI",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-integration",
        "entity-matching",
        "schema-matching"
      ],
      "id": 525
    },
    {
      "name": "DESAlign",
      "one_line_profile": "Multi-Modal Entity Alignment tool",
      "detailed_description": "Implementation of Dirichlet Energy Driven Robust Multi-Modal Entity Alignment for semantic consistency.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "knowledge_graph"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wyy-code/DESAlign",
      "help_website": [],
      "license": null,
      "tags": [
        "entity-alignment",
        "multimodal",
        "knowledge-graph"
      ],
      "id": 526
    },
    {
      "name": "ClusterEA",
      "one_line_profile": "Scalable Entity Alignment tool",
      "detailed_description": "Source code for ClusterEA, a method for scalable entity alignment using stochastic training and normalized mini-batch similarities.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "knowledge_graph"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/xz-liu/ClusterEA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "entity-alignment",
        "scalability",
        "clustering"
      ],
      "id": 527
    },
    {
      "name": "BioGraphFusion",
      "one_line_profile": "Graph Knowledge Embedding for Biological Reasoning",
      "detailed_description": "Implementation of BioGraphFusion, a graph knowledge embedding method for biological completion and reasoning.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "knowledge_graph_completion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/y-tarl/BioGraphFusion",
      "help_website": [],
      "license": null,
      "tags": [
        "bioinformatics",
        "knowledge-graph",
        "reasoning"
      ],
      "id": 528
    },
    {
      "name": "DLGM",
      "one_line_profile": "Deep Learning of Graph Matching",
      "detailed_description": "Implementation of deep learning models for graph matching tasks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yannadani/dlgm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-matching",
        "deep-learning",
        "computer-vision"
      ],
      "id": 529
    },
    {
      "name": "VF2",
      "one_line_profile": "VF2 Graph Isomorphism Algorithm",
      "detailed_description": "Implementation of the VF2 algorithm for subgraph isomorphism and matching large graphs.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "graph_matching",
        "isomorphism"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yaolili/VF2",
      "help_website": [],
      "license": null,
      "tags": [
        "graph-matching",
        "isomorphism",
        "algorithm"
      ],
      "id": 530
    },
    {
      "name": "Link-Prediction-on-Social-Networks",
      "one_line_profile": "Link prediction algorithms for social networks",
      "detailed_description": "A collection of algorithms for link prediction in social networks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "link_prediction",
        "network_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yebiro/Link-Prediction-on-Social-Networks",
      "help_website": [],
      "license": null,
      "tags": [
        "link-prediction",
        "social-network",
        "graph-mining"
      ],
      "id": 531
    },
    {
      "name": "SuperGlue-pytorch",
      "one_line_profile": "SuperGlue Feature Matching Network",
      "detailed_description": "PyTorch implementation of the SuperGlue network for learning feature matching with graph neural networks.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "alignment",
        "feature_matching"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yingxin-jia/SuperGlue-pytorch",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "feature-matching",
        "superglue",
        "computer-vision"
      ],
      "id": 532
    },
    {
      "name": "COTSA",
      "one_line_profile": "Co-Training for Entity Alignment",
      "detailed_description": "Implementation of COTSAE, a method for co-training structure and attribute embeddings for entity alignment.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_alignment",
        "knowledge_graph"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ykpku/COTSA",
      "help_website": [],
      "license": null,
      "tags": [
        "entity-alignment",
        "co-training",
        "knowledge-graph"
      ],
      "id": 533
    },
    {
      "name": "zentity",
      "one_line_profile": "Entity resolution plugin for Elasticsearch to handle duplicate detection",
      "detailed_description": "A plugin for Elasticsearch that enables real-time entity resolution. It allows users to define resolution models in JSON to find and link duplicate entities across indices, supporting the alignment and fusion of knowledge graph data.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "data_fusion"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/zentity-io/zentity",
      "help_website": [
        "https://zentity.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "entity-resolution",
        "elasticsearch",
        "deduplication",
        "knowledge-graph"
      ],
      "id": 534
    },
    {
      "name": "ZnTrack",
      "one_line_profile": "Parameter tracking and provenance tool for DVC pipelines",
      "detailed_description": "A Python interface for DVC (Data Version Control) that simplifies the creation, execution, and benchmarking of scientific workflows. It focuses on tracking parameters, metrics, and provenance of data, facilitating reproducible research and experiment management.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "provenance",
        "workflow_management",
        "experiment_tracking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zincware/ZnTrack",
      "help_website": [
        "https://zntrack.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dvc",
        "provenance",
        "workflow",
        "reproducibility"
      ],
      "id": 535
    },
    {
      "name": "Zingg",
      "one_line_profile": "Scalable machine learning platform for entity resolution and data mastering",
      "detailed_description": "An enterprise-grade tool for identity resolution and entity linking. It uses machine learning to deduplicate and link records across large datasets, supporting the construction of unified views for knowledge graphs and master data management.",
      "domains": [
        "G2",
        "G2-02"
      ],
      "subtask_category": [
        "entity_resolution",
        "identity_resolution",
        "deduplication"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/zinggAI/zingg",
      "help_website": [
        "https://docs.zingg.ai"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "entity-resolution",
        "machine-learning",
        "spark",
        "data-quality"
      ],
      "id": 536
    },
    {
      "name": "GraphRAG Agent",
      "one_line_profile": "Integrated agent for knowledge graph construction and RAG reasoning using Neo4j and LLMs",
      "detailed_description": "A comprehensive RAG (Retrieval-Augmented Generation) agent that integrates GraphRAG, LightRAG, and Neo4j-llm-graph-builder. It facilitates knowledge graph construction, search, and reasoning, incorporating DeepSearch technology for private domain RAG inference and providing an evaluation framework.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "reasoning",
        "rag"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/1517005260/graph-rag-agent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-rag",
        "neo4j",
        "knowledge-graph",
        "llm"
      ],
      "id": 537
    },
    {
      "name": "Knowledge Extraction",
      "one_line_profile": "Pipeline for extracting knowledge from natural language text into a graph database",
      "detailed_description": "A Java-based tool designed to process natural language text and extract structured knowledge to populate a graph database. It serves as a bridge between unstructured text data and structured graph storage.",
      "domains": [
        "G2",
        "G2-01",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "graph_construction"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/5agado/knowledge-extraction",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "graph-database",
        "knowledge-extraction"
      ],
      "id": 538
    },
    {
      "name": "LSQ",
      "one_line_profile": "Framework for RDFizing and benchmarking Linked SPARQL Queries logs",
      "detailed_description": "Linked SPARQL Queries (LSQ) is a framework designed to RDFize triple store logs and perform extraction, analysis, and benchmarking of SPARQL queries. It aids in creating datasets of Linked SPARQL queries for research and optimization of graph stores.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "query_analysis",
        "benchmarking",
        "rdf_processing"
      ],
      "application_level": "framework",
      "primary_language": "Java",
      "repo_url": "https://github.com/AKSW/LSQ",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sparql",
        "rdf",
        "benchmarking",
        "linked-data"
      ],
      "id": 539
    },
    {
      "name": "ABLkit",
      "one_line_profile": "Toolkit for Abductive Learning integrating machine learning and logical reasoning",
      "detailed_description": "An efficient Python toolkit for Abductive Learning (ABL), a neuro-symbolic paradigm that unifies machine learning with logical reasoning. It enables the development of systems that can learn from data while adhering to logical constraints, suitable for scientific reasoning tasks.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "neuro_symbolic_reasoning",
        "abductive_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AbductiveLearning/ABLkit",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "neuro-symbolic",
        "reasoning",
        "machine-learning",
        "logic"
      ],
      "id": 540
    },
    {
      "name": "AmpliGraph",
      "one_line_profile": "Library for representation learning on knowledge graphs",
      "detailed_description": "A Python library dedicated to representation learning on knowledge graphs. It provides implementations of various graph embedding models to predict links and discover new knowledge within graphs.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_embedding",
        "link_prediction",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Accenture/AmpliGraph",
      "help_website": [
        "https://docs.ampligraph.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "embedding",
        "machine-learning"
      ],
      "id": 541
    },
    {
      "name": "AtomGraph Core-PHP",
      "one_line_profile": "Generic Jena-compatible PHP Linked Data management library",
      "detailed_description": "A PHP library for managing Linked Data, compatible with Apache Jena. It provides functionality for handling RDF data and interacting with SPARQL endpoints within PHP applications.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "linked_data_management",
        "rdf_processing"
      ],
      "application_level": "library",
      "primary_language": "PHP",
      "repo_url": "https://github.com/AtomGraph/Core-PHP",
      "help_website": [],
      "license": null,
      "tags": [
        "linked-data",
        "rdf",
        "php",
        "jena"
      ],
      "id": 542
    },
    {
      "name": "sparql-engine",
      "one_line_profile": "Framework for building SPARQL query engines in Javascript/Typescript",
      "detailed_description": "A modular framework designed to facilitate the construction of SPARQL query engines using Javascript or Typescript. It allows developers to implement custom query processing logic for RDF data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "query_engine",
        "sparql_processing"
      ],
      "application_level": "framework",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/Callidon/sparql-engine",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sparql",
        "rdf",
        "query-engine"
      ],
      "id": 543
    },
    {
      "name": "PA4RDF",
      "one_line_profile": "Annotation-based mapping framework between RDF triples and Java POJOs",
      "detailed_description": "PA4RDF provides functionality on top of an RDF store to map RDF triples to Plain Old Java Objects (POJOs) using annotations and dynamic proxies, simplifying the interaction between Java applications and graph storage.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "object_rdf_mapping",
        "data_access"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/Claudenw/PA4RDF",
      "help_website": [],
      "license": null,
      "tags": [
        "rdf",
        "orm",
        "java",
        "annotation"
      ],
      "id": 544
    },
    {
      "name": "RezoJDM16K",
      "one_line_profile": "French Knowledge Graph Dataset for semantic relation prediction",
      "detailed_description": "A French Knowledge Graph Dataset (RezoJDM16K) containing 53 semantic relations derived from RezoJDM. It is designed for training and evaluating graph embedding models and semantic link prediction tasks.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "dataset",
        "link_prediction"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ContentSide/French_Knowledge_Graph",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "dataset",
        "french",
        "link-prediction"
      ],
      "id": 545
    },
    {
      "name": "entity2rec",
      "one_line_profile": "Item recommendation tool using property-specific knowledge graph embeddings",
      "detailed_description": "A tool that generates item recommendations by leveraging property-specific knowledge graph embeddings. It applies graph representation learning techniques to improve recommendation systems.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "recommendation",
        "graph_embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/D2KLab/entity2rec",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "recsys",
        "knowledge-graph",
        "embedding"
      ],
      "id": 546
    },
    {
      "name": "entity2vec",
      "one_line_profile": "Tool for generating property-specific entity embeddings from knowledge graphs",
      "detailed_description": "A library that generates property-specific entity embeddings from knowledge graphs using node2vec. It allows for capturing specific relational properties in the embedding space.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_embedding",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/D2KLab/entity2vec",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "node2vec",
        "knowledge-graph",
        "embedding"
      ],
      "id": 547
    },
    {
      "name": "Explorer",
      "one_line_profile": "Exploratory search engine for Linked Data",
      "detailed_description": "An exploratory search engine designed for Linked Data, enabling users to navigate and visualize connections within knowledge graphs. It has been used in projects like MeMAD, SILKNOW, and Odeuropa.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "visualization",
        "exploratory_search",
        "linked_data"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/D2KLab/explorer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "linked-data",
        "search-engine",
        "visualization"
      ],
      "id": 548
    },
    {
      "name": "scylla-rdf",
      "one_line_profile": "RDF store implementation based on ScyllaDB and Eclipse RDF4J",
      "detailed_description": "An RDF store backend that leverages ScyllaDB for high-performance storage and Eclipse RDF4J for the RDF handling interface. It provides a scalable solution for storing and querying graph data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "rdf_store"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/DataFabricRus/scylla-rdf",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rdf",
        "scylladb",
        "graph-database"
      ],
      "id": 549
    },
    {
      "name": "ULTRA",
      "one_line_profile": "Foundation model for knowledge graph reasoning",
      "detailed_description": "A foundation model designed for reasoning on knowledge graphs. ULTRA aims to generalize across different graphs and tasks, providing a robust capability for inferring missing links and reasoning over structured data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "foundation_model",
        "link_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DeepGraphLearning/ULTRA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "reasoning",
        "foundation-model"
      ],
      "id": 550
    },
    {
      "name": "SymbolicAI",
      "one_line_profile": "Compositional neuro-symbolic framework for building logic-enhanced LLM applications",
      "detailed_description": "A neuro-symbolic framework that treats Large Language Models (LLMs) as semantic parsers and reasoning engines, allowing users to build compositional neuro-symbolic solvers. It integrates logic programming concepts with probabilistic generative models to enable complex reasoning tasks.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "neuro_symbolic_inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ExtensityAI/symbolicai",
      "help_website": [
        "https://github.com/ExtensityAI/symbolicai"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "neuro-symbolic",
        "reasoning",
        "llm-agent",
        "logic-programming"
      ],
      "id": 551
    },
    {
      "name": "FalkorDB",
      "one_line_profile": "High-performance low-latency Graph Database powered by GraphBLAS",
      "detailed_description": "A high-performance graph database that utilizes sparse adjacency matrix graph representation via GraphBLAS. It is designed to support low-latency graph operations and serves as a backend for Knowledge Graphs, supporting applications like GraphRAG.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "graph_querying"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/FalkorDB/FalkorDB",
      "help_website": [
        "https://docs.falkordb.com/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "graph-database",
        "knowledge-graph",
        "graphblas",
        "redis-module"
      ],
      "id": 552
    },
    {
      "name": "Openllet",
      "one_line_profile": "Open-source OWL 2 DL reasoner for Java",
      "detailed_description": "An open-source OWL 2 DL reasoner for Java, built on top of the Pellet reasoner. It provides standard reasoning services for OWL ontologies, which are widely used in bioinformatics and scientific knowledge management.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "ontology_inference"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/Galigator/openllet",
      "help_website": [
        "https://github.com/Galigator/openllet"
      ],
      "license": "NOASSERTION",
      "tags": [
        "owl",
        "reasoner",
        "semantic-web",
        "ontology"
      ],
      "id": 553
    },
    {
      "name": "LinkedGeoData",
      "one_line_profile": "Tools for converting OpenStreetMap data to RDF/Linked Data",
      "detailed_description": "A project that uses the OpenStreetMap data and makes it available as an RDF knowledge base according to the Linked Data principles. It includes tools for data extraction and conversion, enabling geospatial semantic queries.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "data_processing",
        "knowledge_graph_construction"
      ],
      "application_level": "dataset",
      "primary_language": "Java",
      "repo_url": "https://github.com/GeoKnow/LinkedGeoData",
      "help_website": [
        "http://linkedgeodata.org"
      ],
      "license": "GPL-3.0",
      "tags": [
        "geospatial",
        "rdf",
        "openstreetmap",
        "linked-data"
      ],
      "id": 554
    },
    {
      "name": "GraphLite",
      "one_line_profile": "Embeddable lightweight graph database with GQL support",
      "detailed_description": "An embeddable graph database written in Rust that supports ISO Graph Query Language (GQL). It is designed for lightweight applications requiring graph storage and querying capabilities.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "graph_querying"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/GraphLite-AI/GraphLite",
      "help_website": [
        "https://github.com/GraphLite-AI/GraphLite"
      ],
      "license": "Apache-2.0",
      "tags": [
        "graph-database",
        "rust",
        "gql",
        "embedded-database"
      ],
      "id": 555
    },
    {
      "name": "KGEmb",
      "one_line_profile": "Library for Hyperbolic Knowledge Graph Embeddings",
      "detailed_description": "A PyTorch library for learning hyperbolic embeddings of Knowledge Graphs. Hyperbolic geometry is particularly effective for representing hierarchical data structures often found in scientific taxonomies and biological ontologies.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_embedding",
        "link_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HazyResearch/KGEmb",
      "help_website": [
        "https://github.com/HazyResearch/KGEmb"
      ],
      "license": null,
      "tags": [
        "knowledge-graph",
        "hyperbolic-embeddings",
        "representation-learning",
        "pytorch"
      ],
      "id": 556
    },
    {
      "name": "Expressive Reasoning Graph Store",
      "one_line_profile": "OWL reasoner and RDF triple store on Property Graph",
      "detailed_description": "A system that combines an OWL reasoner with an RDF triple store architecture, built on top of a Property Graph model. It enables expressive reasoning capabilities over graph data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "graph_storage"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/IBM/expressive-reasoning-graph-store",
      "help_website": [
        "https://github.com/IBM/expressive-reasoning-graph-store"
      ],
      "license": "Apache-2.0",
      "tags": [
        "owl",
        "reasoner",
        "rdf",
        "property-graph"
      ],
      "id": 557
    },
    {
      "name": "Neuro-Symbolic AI Toolkit",
      "one_line_profile": "Toolkit for developing Neuro-Symbolic AI applications",
      "detailed_description": "A comprehensive toolkit designed to facilitate the development of Neuro-Symbolic AI systems, which combine neural networks with symbolic reasoning. This approach is increasingly used in scientific discovery to integrate data-driven learning with domain knowledge.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "neuro_symbolic_inference"
      ],
      "application_level": "library",
      "primary_language": null,
      "repo_url": "https://github.com/IBM/neuro-symbolic-ai",
      "help_website": [
        "https://github.com/IBM/neuro-symbolic-ai"
      ],
      "license": "MIT",
      "tags": [
        "neuro-symbolic",
        "ai-toolkit",
        "reasoning"
      ],
      "id": 558
    },
    {
      "name": "Otter-Knowledge",
      "one_line_profile": "Knowledge-enhanced representation learning for drug discovery",
      "detailed_description": "A tool that enriches protein sequence and SMILES drug databases with a large Knowledge Graph fused from different sources. It is specifically designed to improve drug target binding affinity prediction benchmarks.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "drug_discovery",
        "graph_representation_learning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/IBM/otter-knowledge",
      "help_website": [
        "https://github.com/IBM/otter-knowledge"
      ],
      "license": "MIT",
      "tags": [
        "drug-discovery",
        "knowledge-graph",
        "binding-affinity",
        "bioinformatics"
      ],
      "id": 559
    },
    {
      "name": "TorchLogic",
      "one_line_profile": "PyTorch framework for Neuro-Symbolic AI and Neural Reasoning Networks",
      "detailed_description": "A PyTorch-based framework for developing Neuro-Symbolic AI systems. It implements Neural Reasoning Networks, allowing for the integration of logical reasoning constraints into deep learning models.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "neuro_symbolic_inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IBM/torchlogic",
      "help_website": [
        "https://github.com/IBM/torchlogic"
      ],
      "license": "Apache-2.0",
      "tags": [
        "pytorch",
        "neuro-symbolic",
        "logic",
        "reasoning"
      ],
      "id": 560
    },
    {
      "name": "Whelk",
      "one_line_profile": "High-performance OWL EL reasoner in Scala",
      "detailed_description": "An implementation of an OWL EL reasoner written in Scala. It is designed to classify ontologies in the OWL EL profile, which is common in large biomedical ontologies like SNOMED CT and GO.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "ontology_classification"
      ],
      "application_level": "solver",
      "primary_language": "Scala",
      "repo_url": "https://github.com/INCATools/whelk",
      "help_website": [
        "https://github.com/INCATools/whelk"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "owl-el",
        "reasoner",
        "ontology",
        "scala"
      ],
      "id": 561
    },
    {
      "name": "Whelk-rs",
      "one_line_profile": "High-performance OWL EL reasoner in Rust",
      "detailed_description": "A Rust port of the Whelk OWL EL reasoner. It provides efficient classification for OWL EL ontologies, leveraging Rust's performance and safety features.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "ontology_classification"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/INCATools/whelk-rs",
      "help_website": [
        "https://github.com/INCATools/whelk-rs"
      ],
      "license": "MIT",
      "tags": [
        "owl-el",
        "reasoner",
        "ontology",
        "rust"
      ],
      "id": 562
    },
    {
      "name": "NormalHermiteSplines.jl",
      "one_line_profile": "Multivariate Normal Hermite-Birkhoff Interpolating Splines",
      "detailed_description": "A Julia library for computing multivariate Normal Hermite-Birkhoff interpolating splines. This is a mathematical tool used for data interpolation and approximation in scientific computing.",
      "domains": [
        "Scientific Computing"
      ],
      "subtask_category": [
        "interpolation",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/IgorKohan/NormalHermiteSplines.jl",
      "help_website": [
        "https://github.com/IgorKohan/NormalHermiteSplines.jl"
      ],
      "license": "MIT",
      "tags": [
        "splines",
        "interpolation",
        "julia",
        "numerical-analysis"
      ],
      "id": 563
    },
    {
      "name": "Metatheory.jl",
      "one_line_profile": "Symbolic computation and equational reasoning library for Julia",
      "detailed_description": "A library for general-purpose metaprogramming, symbolic computation, and algebraic equational reasoning in Julia. It implements E-Graphs and equality saturation, which are powerful techniques for symbolic mathematics and optimization in scientific computing.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "symbolic_reasoning",
        "equation_simplification"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaSymbolics/Metatheory.jl",
      "help_website": [
        "https://juliasymbolics.github.io/Metatheory.jl/"
      ],
      "license": "MIT",
      "tags": [
        "symbolic-computation",
        "e-graphs",
        "reasoning",
        "julia"
      ],
      "id": 564
    },
    {
      "name": "DHGE",
      "one_line_profile": "Dual-view Hyper-Relational Knowledge Graph Embedding model for link prediction",
      "detailed_description": "An implementation of the DHGE model which utilizes dual-view hyper-relational embeddings to improve link prediction and entity typing tasks within knowledge graphs.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "link_prediction",
        "entity_typing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LHRLAB/DHGE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph-embedding",
        "link-prediction",
        "hyper-relational"
      ],
      "id": 565
    },
    {
      "name": "ViziQuer",
      "one_line_profile": "Visual query tool for searching structured semantic data",
      "detailed_description": "A tool designed to facilitate the creation of SPARQL queries through a visual interface, enabling users to search and explore structured semantic data (RDF/Knowledge Graphs) without writing raw code.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "querying",
        "visualization"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/LUMII-Syslab/viziquer",
      "help_website": [
        "https://viziquer.lumii.lv/"
      ],
      "license": "MIT",
      "tags": [
        "sparql",
        "visual-query",
        "semantic-web"
      ],
      "id": 566
    },
    {
      "name": "StarGraph",
      "one_line_profile": "Graph database designed to query large Knowledge Graphs",
      "detailed_description": "A graph database system optimized for querying large-scale knowledge graphs, supporting AI applications and data analysis over complex domains.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "querying"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/Lambda-3/Stargraph",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-database",
        "knowledge-graph",
        "query-engine"
      ],
      "id": 567
    },
    {
      "name": "TransE-Knowledge-Graph-Embedding",
      "one_line_profile": "TensorFlow implementation of TransE and extended models for Knowledge Representation Learning",
      "detailed_description": "A library implementing the TransE algorithm and its extensions for learning vector representations of entities and relations in knowledge graphs, facilitating link prediction and knowledge completion.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_representation_learning",
        "link_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lapis-Hong/TransE-Knowledge-Graph-Embedding",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "transe",
        "tensorflow",
        "kge"
      ],
      "id": 568
    },
    {
      "name": "RE-GCN",
      "one_line_profile": "Temporal Knowledge Graph Reasoning based on Evolutional Representation Learning",
      "detailed_description": "A model implementation for reasoning on temporal knowledge graphs, using recurrent graph convolutional networks to capture structural and temporal evolution for link prediction.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "temporal_reasoning",
        "link_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lee-zix/RE-GCN",
      "help_website": [],
      "license": null,
      "tags": [
        "temporal-knowledge-graph",
        "gcn",
        "reasoning"
      ],
      "id": 569
    },
    {
      "name": "GCN4KGC",
      "one_line_profile": "Graph Convolutional Networks for Knowledge Graph Completion",
      "detailed_description": "Implementation of Graph Convolutional Networks (GCN) specifically optimized for the task of Knowledge Graph Completion, addressing issues in standard GCN applications for KGs.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_completion",
        "link_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MIRALab-USTC/GCN4KGC",
      "help_website": [],
      "license": null,
      "tags": [
        "gcn",
        "knowledge-graph-completion",
        "deep-learning"
      ],
      "id": 570
    },
    {
      "name": "KGE-DURA",
      "one_line_profile": "Duality-Induced Regularizer for Tensor Factorization Based KG Completion",
      "detailed_description": "Implementation of the DURA regularizer for tensor factorization models, improving the performance and efficiency of knowledge graph completion tasks.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_completion",
        "regularization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MIRALab-USTC/KGE-DURA",
      "help_website": [],
      "license": null,
      "tags": [
        "tensor-factorization",
        "regularization",
        "kge"
      ],
      "id": 571
    },
    {
      "name": "SALIENT",
      "one_line_profile": "System for accelerating GNN training and inference",
      "detailed_description": "A high-performance system designed to accelerate the training and inference of Graph Neural Networks (GNNs) using fast sampling and pipelining techniques.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "gnn_training",
        "inference_acceleration"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/MITIBMxGraph/SALIENT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gnn",
        "acceleration",
        "graph-sampling"
      ],
      "id": 572
    },
    {
      "name": "Clinical Knowledge Graph (CKG)",
      "one_line_profile": "Platform for biomedical knowledge discovery and graph database integration",
      "detailed_description": "An open-source platform that integrates experimental data with diverse biomedical databases into a graph database, automating knowledge discovery and analysis for clinical proteomics and related fields.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_discovery",
        "data_integration",
        "biomedical_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/MannLabs/CKG",
      "help_website": [
        "https://ckg.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "clinical-data",
        "proteomics",
        "knowledge-graph"
      ],
      "id": 573
    },
    {
      "name": "go-light-rag",
      "one_line_profile": "LightRAG implementation combining vector and graph databases",
      "detailed_description": "A library implementing the LightRAG architecture, which integrates vector databases with graph database relationships to enhance knowledge retrieval and reasoning capabilities.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "retrieval_augmented_generation",
        "knowledge_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/MegaGrindStone/go-light-rag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "graph-database",
        "vector-database"
      ],
      "id": 574
    },
    {
      "name": "hermiter",
      "one_line_profile": "Efficient sequential estimation of PDF and CDF",
      "detailed_description": "An R package for efficient sequential and batch estimation of univariate and bivariate probability density functions, cumulative distribution functions, and quantiles using Hermite series estimators.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "statistical_estimation",
        "density_estimation"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/MikeJaredS/hermiter",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "statistics",
        "density-estimation",
        "r-package"
      ],
      "id": 575
    },
    {
      "name": "MillenniumDB",
      "one_line_profile": "Property Graph and RDF engine",
      "detailed_description": "A graph database engine that supports both Property Graph and RDF data models, designed for efficient storage and querying of graph data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "query_engine"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/MillenniumDB/MillenniumDB",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "graph-database",
        "rdf",
        "property-graph"
      ],
      "id": 576
    },
    {
      "name": "Neo4j-KGBuilder",
      "one_line_profile": "Knowledge Graph construction and visualization system based on Neo4j",
      "detailed_description": "A comprehensive system for building, managing, and visualizing knowledge graphs using Neo4j, Spring Boot, and Vue.js, facilitating the entire lifecycle of KG construction.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "kg_construction",
        "visualization"
      ],
      "application_level": "platform",
      "primary_language": "Vue",
      "repo_url": "https://github.com/MiracleTanC/Neo4j-KGBuilder",
      "help_website": [],
      "license": null,
      "tags": [
        "neo4j",
        "visualization",
        "kg-construction"
      ],
      "id": 577
    },
    {
      "name": "Nucleoid",
      "one_line_profile": "Neuro-Symbolic AI with Pythonic Logic Language",
      "detailed_description": "A neuro-symbolic AI platform that enables reasoning and logic processing using a Pythonic syntax, integrating symbolic logic with neural capabilities.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "neuro_symbolic_reasoning",
        "logic_programming"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/NucleoidAI/Nucleoid",
      "help_website": [
        "https://nucleoid.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "neuro-symbolic",
        "reasoning",
        "logic"
      ],
      "id": 578
    },
    {
      "name": "COSMO",
      "one_line_profile": "Multimodal Knowledge Graph framework for camera trap species classification",
      "detailed_description": "A framework that treats camera trap species classification as a link prediction problem on multimodal knowledge graphs, integrating contextual information for ecological monitoring.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "species_classification",
        "multimodal_link_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OSU-NLP-Group/COSMO",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ecology",
        "multimodal-kg",
        "classification"
      ],
      "id": 579
    },
    {
      "name": "KG-R3",
      "one_line_profile": "Retrieve-and-Read Framework for Knowledge Graph Link Prediction",
      "detailed_description": "A framework for knowledge graph link prediction that utilizes a retrieve-and-read mechanism to enhance reasoning capabilities over incomplete graphs.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "link_prediction",
        "reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OSU-NLP-Group/KG-R3",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "retrieve-and-read",
        "link-prediction",
        "kg"
      ],
      "id": 580
    },
    {
      "name": "CLEVR graph",
      "one_line_profile": "Dataset for graph-based reasoning",
      "detailed_description": "A dataset designed to benchmark and develop graph-based reasoning models, providing structured data for evaluating logical inference capabilities.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning_benchmark",
        "dataset"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Octavian-ai/clevr-graph",
      "help_website": [],
      "license": "Unlicense",
      "tags": [
        "dataset",
        "reasoning",
        "benchmark"
      ],
      "id": 581
    },
    {
      "name": "OpenBG-IMG",
      "one_line_profile": "Baselines for Multimodal Product Knowledge Graph Link Prediction",
      "detailed_description": "A collection of baseline models and tools for the task of link prediction on multimodal product knowledge graphs, developed for the CCKS 2022 challenge.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "multimodal_link_prediction",
        "benchmark"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenBGBenchmark/OpenBG-IMG",
      "help_website": [],
      "license": null,
      "tags": [
        "multimodal",
        "product-graph",
        "link-prediction"
      ],
      "id": 582
    },
    {
      "name": "TopoNet",
      "one_line_profile": "Graph-based Topology Reasoning for Driving Scenes",
      "detailed_description": "A graph-based reasoning framework for inferring the topology of driving scenes, essential for autonomous driving perception and planning.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "topology_reasoning",
        "scene_understanding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenDriveLab/TopoNet",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "autonomous-driving",
        "topology-reasoning",
        "graph-neural-network"
      ],
      "id": 583
    },
    {
      "name": "KAG",
      "one_line_profile": "Logical form-guided reasoning and retrieval framework",
      "detailed_description": "A framework combining OpenSPG engine and LLMs for logical reasoning and factual Q&A on professional domain knowledge bases, enhancing RAG with logical forms.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "logical_reasoning",
        "retrieval_augmented_generation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenSPG/KAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "logical-reasoning",
        "knowledge-graph"
      ],
      "id": 584
    },
    {
      "name": "MoSE4MKGC",
      "one_line_profile": "Modality Split and Ensemble for Multimodal Knowledge Graph Completion",
      "detailed_description": "Implementation of the MoSE method for multimodal knowledge graph completion, which uses modality splitting and ensembling to improve prediction performance.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "multimodal_completion",
        "link_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OreOZhao/MoSE4MKGC",
      "help_website": [],
      "license": null,
      "tags": [
        "multimodal",
        "ensemble",
        "kgc"
      ],
      "id": 585
    },
    {
      "name": "ControlledVocabularyManager",
      "one_line_profile": "Manager for RDF controlled vocabularies using Blazegraph",
      "detailed_description": "A Rails-based application for managing and serving controlled vocabularies in RDF format, utilizing Blazegraph as the backend, facilitating data normalization and standardization.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "vocabulary_management",
        "data_normalization"
      ],
      "application_level": "service",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/OregonDigital/ControlledVocabularyManager",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "rdf",
        "controlled-vocabulary",
        "blazegraph"
      ],
      "id": 586
    },
    {
      "name": "Graph-CoT",
      "one_line_profile": "Graph Chain-of-Thought for augmenting LLMs with graph reasoning",
      "detailed_description": "A framework that augments Large Language Models (LLMs) by enabling them to perform chain-of-thought reasoning over graphs, improving their ability to handle complex structural knowledge.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_reasoning",
        "llm_augmentation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/PeterGriffinJin/Graph-CoT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "chain-of-thought",
        "llm",
        "graph-reasoning"
      ],
      "id": 587
    },
    {
      "name": "Quetzal",
      "one_line_profile": "SPARQL to SQL translation engine",
      "detailed_description": "An engine that translates SPARQL queries into SQL, allowing the use of relational databases (like PostgreSQL, DB2) and Spark as backends for RDF graph querying.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "query_translation",
        "rdf_storage"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/Quetzal-RDF/quetzal",
      "help_website": [],
      "license": "EPL-2.0",
      "tags": [
        "sparql",
        "sql",
        "rdf"
      ],
      "id": 588
    },
    {
      "name": "OWL-RL",
      "one_line_profile": "OWL2 RL Profile implementation on RDFLib",
      "detailed_description": "A Python implementation of the OWL 2 RL reasoning profile, capable of expanding an RDF graph with inferences defined by the OWL RL standard.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/RDFLib/OWL-RL",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "owl",
        "reasoning",
        "rdflib"
      ],
      "id": 589
    },
    {
      "name": "NP-FKGC",
      "one_line_profile": "Normalizing Flow-based Neural Process for Few-Shot KG Completion",
      "detailed_description": "Implementation of a few-shot knowledge graph completion model utilizing normalizing flow-based neural processes to handle data scarcity.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "few_shot_learning",
        "knowledge_graph_completion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RManLuo/NP-FKGC",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "few-shot",
        "neural-process",
        "kgc"
      ],
      "id": 590
    },
    {
      "name": "Graph-constrained Reasoning",
      "one_line_profile": "LLM-based reasoning framework constrained by knowledge graphs",
      "detailed_description": "Official implementation of the ICML 2025 paper 'Graph-constrained Reasoning'. It provides a framework for performing faithful reasoning on knowledge graphs using Large Language Models (LLMs) by constraining the generation process with graph structures.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RManLuo/graph-constrained-reasoning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "llm",
        "reasoning",
        "icml-2025"
      ],
      "id": 591
    },
    {
      "name": "Reasoning on Graphs (RoG)",
      "one_line_profile": "Framework for faithful and interpretable LLM reasoning on graphs",
      "detailed_description": "Implementation of the ICLR 2024 paper 'Reasoning on Graphs'. It synergizes Large Language Models (LLMs) with Knowledge Graphs (KGs) to enable faithful and interpretable reasoning, generating reasoning paths grounded in the graph.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "inference",
        "interpretability"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RManLuo/reasoning-on-graphs",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "llm",
        "reasoning",
        "iclr-2024"
      ],
      "id": 592
    },
    {
      "name": "PloverDB",
      "one_line_profile": "In-memory database service for biomedical knowledge graphs",
      "detailed_description": "An in-memory database service designed to host and serve biomedical knowledge graphs via TRAPI (Translator Reasoner API) compliant APIs, facilitating rapid querying and reasoning over biomedical data.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "graph_database",
        "data_serving",
        "biomedical_informatics"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/RTXteam/PloverDB",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "biomedical-knowledge-graph",
        "trapi",
        "database",
        "api"
      ],
      "id": 593
    },
    {
      "name": "SANSA-Stack",
      "one_line_profile": "Big Data RDF processing and analytics stack",
      "detailed_description": "A scalable big data processing stack for RDF data, built on top of Apache Spark and Apache Jena. It enables querying, inference, and analytics on large-scale semantic datasets.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "rdf_processing",
        "analytics",
        "inference"
      ],
      "application_level": "platform",
      "primary_language": "Scala",
      "repo_url": "https://github.com/SANSA-Stack/SANSA-Stack",
      "help_website": [
        "http://sansa-stack.github.io/SANSA-Stack/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rdf",
        "spark",
        "big-data",
        "semantic-web"
      ],
      "id": 594
    },
    {
      "name": "DeTrusty",
      "one_line_profile": "Federated query engine over RDF sources",
      "detailed_description": "A federated SPARQL query engine capable of executing queries over heterogeneous RDF sources, enabling data integration and retrieval across distributed scientific knowledge bases.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "federated_query",
        "sparql_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SDM-TIB/DeTrusty",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "sparql",
        "federated-query",
        "rdf",
        "semantic-web"
      ],
      "id": 595
    },
    {
      "name": "Ontario",
      "one_line_profile": "Federated SPARQL query processing engine for semantic data lakes",
      "detailed_description": "A federated query processing engine designed for semantic data lakes, allowing efficient SPARQL query execution over diverse data sources.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "federated_query",
        "sparql_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/SDM-TIB/Ontario",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "sparql",
        "data-lake",
        "federated-query"
      ],
      "id": 596
    },
    {
      "name": "BioKEEN",
      "one_line_profile": "Library for learning and evaluating biological knowledge graph embeddings",
      "detailed_description": "A computational library specifically designed for learning and evaluating embeddings on biological knowledge graphs, facilitating bioinformatics research and link prediction.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "embedding_learning",
        "link_prediction",
        "bioinformatics"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/SmartDataAnalytics/BioKEEN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "biological-knowledge-graph",
        "embeddings",
        "machine-learning"
      ],
      "id": 597
    },
    {
      "name": "Kolibrie",
      "one_line_profile": "SPARQL database and RDF stream processing engine",
      "detailed_description": "A system combining a SPARQL database with an RDF Stream Processing (RSP) engine, enabling real-time querying and reasoning over streaming semantic data.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "stream_processing",
        "sparql_querying"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/StreamIntelligenceLab/Kolibrie",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rdf-stream",
        "sparql",
        "database"
      ],
      "id": 598
    },
    {
      "name": "pykg2vec",
      "one_line_profile": "Python library for knowledge graph embedding and representation learning",
      "detailed_description": "A comprehensive Python library for knowledge graph embedding (KGE) and representation learning, implementing various state-of-the-art algorithms for link prediction and triple classification.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "embedding_learning",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Sujit-O/pykg2vec",
      "help_website": [
        "https://pykg2vec.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "knowledge-graph-embedding",
        "machine-learning",
        "python"
      ],
      "id": 599
    },
    {
      "name": "DacKGR",
      "one_line_profile": "Dynamic anticipation and completion for multi-hop reasoning",
      "detailed_description": "Implementation of a multi-hop reasoning model over sparse knowledge graphs that uses dynamic anticipation and completion mechanisms to improve reasoning performance.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "multi_hop_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/THU-KEG/DacKGR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "reasoning",
        "multi-hop"
      ],
      "id": 600
    },
    {
      "name": "MetaKGR",
      "one_line_profile": "Meta-learning framework for multi-hop reasoning on few-shot relations",
      "detailed_description": "A meta-learning based framework for performing multi-hop reasoning over knowledge graphs, specifically targeting few-shot relations where data is scarce.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "meta_learning",
        "few_shot_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/THU-KEG/MetaKGR",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "meta-learning",
        "reasoning"
      ],
      "id": 601
    },
    {
      "name": "PKGC",
      "one_line_profile": "Evaluation framework for pre-trained models in knowledge graph completion",
      "detailed_description": "A framework and evaluation study investigating the impact of pre-trained language models on knowledge graph completion tasks.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_completion",
        "evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/THU-KEG/PKGC",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph-completion",
        "pre-trained-models",
        "evaluation"
      ],
      "id": 602
    },
    {
      "name": "Knowledge Engine SPARQL Endpoint",
      "one_line_profile": "SPARQL endpoint for the TNO Knowledge Engine",
      "detailed_description": "A component that provides a SPARQL endpoint interface for the TNO Knowledge Engine, allowing standard SPARQL queries to be executed against the knowledge base.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "sparql_querying",
        "data_access"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/TNO/knowledge-engine-SPARQL-endpoint",
      "help_website": [],
      "license": null,
      "tags": [
        "sparql",
        "knowledge-engine",
        "endpoint"
      ],
      "id": 603
    },
    {
      "name": "KRACL",
      "one_line_profile": "Contrastive learning with graph context modeling for sparse KG completion",
      "detailed_description": "A model for sparse knowledge graph completion that utilizes contrastive learning and graph context modeling to improve performance on sparse data.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_completion",
        "contrastive_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TamSiuhin/KRACL",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "contrastive-learning",
        "completion"
      ],
      "id": 604
    },
    {
      "name": "AbutionGraph",
      "one_line_profile": "Time-series knowledge graph database for real-time analysis",
      "detailed_description": "A knowledge graph database optimized for time-series data, enabling real-time data analysis and management of temporal knowledge graphs.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "graph_database",
        "time_series_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/ThutmoseAI/AbutionGraph",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "graph-database",
        "time-series",
        "real-time"
      ],
      "id": 605
    },
    {
      "name": "ConvE",
      "one_line_profile": "Convolutional 2D knowledge graph embeddings model",
      "detailed_description": "Implementation of ConvE, a link prediction model that uses 2D convolution over embeddings to capture interactions between entities and relations in knowledge graphs.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "embedding_learning",
        "link_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TimDettmers/ConvE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph-embedding",
        "convolutional-neural-networks",
        "link-prediction"
      ],
      "id": 606
    },
    {
      "name": "TopQuadrant SHACL API",
      "one_line_profile": "Java API for SHACL (Shapes Constraint Language)",
      "detailed_description": "A Java API based on Apache Jena for SHACL, the W3C standard language for validating RDF graphs against a set of conditions (shapes).",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "data_validation",
        "rdf_processing"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/TopQuadrant/shacl",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "shacl",
        "rdf",
        "validation",
        "java"
      ],
      "id": 607
    },
    {
      "name": "Awesome-Text2GQL",
      "one_line_profile": "Fine-tuning dataset auto-generation for Graph Query Languages",
      "detailed_description": "A toolset for automatically generating fine-tuning datasets to train models for Text-to-GQL (Graph Query Language) tasks, facilitating natural language interfaces for graph databases.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "dataset_generation",
        "text_to_gql"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/TuGraph-family/Awesome-Text2GQL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "graph-query-language",
        "dataset-generation",
        "fine-tuning"
      ],
      "id": 608
    },
    {
      "name": "MedReason",
      "one_line_profile": "Eliciting medical reasoning steps in LLMs via knowledge graphs",
      "detailed_description": "A framework for improving medical reasoning in Large Language Models by using Knowledge Graphs to elicit and guide factual reasoning steps.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "medical_informatics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/UCSC-VLAA/MedReason",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-reasoning",
        "knowledge-graph",
        "llm"
      ],
      "id": 609
    },
    {
      "name": "KICGPT",
      "one_line_profile": "LLM with knowledge in context for KG completion",
      "detailed_description": "A framework that enhances Large Language Models with knowledge context to perform knowledge graph completion tasks effectively.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_completion",
        "context_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/WEIYanbin1999/KICGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "llm",
        "completion"
      ],
      "id": 610
    },
    {
      "name": "Cyber Doctor (Cyber Huatuo)",
      "one_line_profile": "Medical agent based on multimodal LLM and knowledge graph",
      "detailed_description": "An intelligent medical agent system that integrates multimodal Large Language Models with medical knowledge graphs and databases to provide disease diagnosis, analysis, and Q&A capabilities.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "medical_reasoning",
        "diagnosis",
        "agent"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Warma10032/cyber-doctor",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "medical-agent",
        "knowledge-graph",
        "llm"
      ],
      "id": 611
    },
    {
      "name": "ALANS",
      "one_line_profile": "Algebraic representation learning for abstract reasoning",
      "detailed_description": "A model for learning algebraic representations to enable systematic generalization in abstract reasoning tasks, contributing to neuro-symbolic AI research.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/WellyZhang/ALANS",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "abstract-reasoning",
        "algebraic-representation",
        "neuro-symbolic"
      ],
      "id": 612
    },
    {
      "name": "ReasonGraph",
      "one_line_profile": "Visualization tool for reasoning paths",
      "detailed_description": "A visualization tool designed to display and analyze reasoning paths, aiding in the interpretability of reasoning systems.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "visualization",
        "reasoning_analysis"
      ],
      "application_level": "tool",
      "primary_language": "HTML",
      "repo_url": "https://github.com/ZongqianLi/ReasonGraph",
      "help_website": [],
      "license": null,
      "tags": [
        "visualization",
        "reasoning",
        "interpretability"
      ],
      "id": 613
    },
    {
      "name": "INSTANS",
      "one_line_profile": "Incremental engine for standing SPARQL queries",
      "detailed_description": "An incremental engine designed for executing standing SPARQL queries, suitable for RDF stream processing and continuous query evaluation.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "sparql_processing",
        "stream_processing"
      ],
      "application_level": "solver",
      "primary_language": "Common Lisp",
      "repo_url": "https://github.com/aaltodsg/instans",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sparql",
        "incremental-reasoning",
        "rdf-stream"
      ],
      "id": 614
    },
    {
      "name": "SpectralEmbeddings",
      "one_line_profile": "Node embeddings from KGs using GCN kernels",
      "detailed_description": "A Python library for generating node embeddings from knowledge graphs using Graph Convolutional Network (GCN) kernels and Graph Autoencoders.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "embedding_learning",
        "graph_neural_networks"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/abhilash1910/SpectralEmbeddings",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "graph-embedding",
        "gcn",
        "autoencoder"
      ],
      "id": 615
    },
    {
      "name": "Sparqloscope",
      "one_line_profile": "Benchmark for SPARQL engine performance evaluation",
      "detailed_description": "A generic benchmark suite designed for the comprehensive and concise performance evaluation of SPARQL engines.",
      "domains": [
        "Sci Knowledge/KG",
        "G2-03"
      ],
      "subtask_category": [
        "benchmarking",
        "sparql_evaluation"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/ad-freiburg/sparqloscope",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sparql",
        "benchmark",
        "performance"
      ],
      "id": 616
    },
    {
      "name": "RRAM_COMPILER",
      "one_line_profile": "Compiler for Resistive Random Access Memory (RRAM) array configuration",
      "detailed_description": "A specialized compiler designed for the research context of RRAM technology, facilitating the configuration and testing of resistive memory arrays.",
      "domains": [
        "Hardware",
        "Physics"
      ],
      "subtask_category": [
        "simulation",
        "device_modeling"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/akdimitri/RRAM_COMPILER",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "rram",
        "compiler",
        "memory-devices"
      ],
      "id": 617
    },
    {
      "name": "MORe",
      "one_line_profile": "Modular OWL 2 reasoner for ontology classification",
      "detailed_description": "A modular reasoner for OWL 2 ontologies that combines a fully-fledged reasoner with a profile-specific reasoner to optimize classification performance.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "ontology_classification"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/anaphylactic/MORe",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "owl2",
        "reasoner",
        "ontology"
      ],
      "id": 618
    },
    {
      "name": "ANAPSID",
      "one_line_profile": "Adaptive query processing engine for SPARQL endpoints",
      "detailed_description": "An adaptive query engine for SPARQL endpoints that adapts query execution schedules to data availability and runtime conditions of remote sources.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "query_processing",
        "sparql_federation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/anapsid/anapsid",
      "help_website": [],
      "license": null,
      "tags": [
        "sparql",
        "query-engine",
        "linked-data"
      ],
      "id": 619
    },
    {
      "name": "Sequoia",
      "one_line_profile": "Consequence-based OWL 2 DL Reasoner",
      "detailed_description": "A consequence-based reasoner for the OWL 2 DL ontology language, supporting multithreaded reasoning for improved performance.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "ontology_inference"
      ],
      "application_level": "solver",
      "primary_language": "Scala",
      "repo_url": "https://github.com/andrewdbate/Sequoia",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "owl2-dl",
        "reasoner",
        "scala"
      ],
      "id": 620
    },
    {
      "name": "OpenRDF Sesame",
      "one_line_profile": "Framework for processing RDF data (Mirror)",
      "detailed_description": "An open-source Java framework for storage, querying, and inference of RDF data, serving as the predecessor to Eclipse RDF4J.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "rdf_storage",
        "query_processing"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/ansell/openrdf-sesame",
      "help_website": [],
      "license": null,
      "tags": [
        "rdf",
        "semantic-web",
        "framework"
      ],
      "id": 621
    },
    {
      "name": "G6VP",
      "one_line_profile": "Online visual analysis tool for graph data",
      "detailed_description": "A visual analysis platform and low-code tool for building graph applications, enabling exploration and visualization of complex relational data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "visualization",
        "graph_analysis"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/antvis/G6VP",
      "help_website": [
        "https://g6vp.antv.vision/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "graph-visualization",
        "visual-analysis",
        "low-code"
      ],
      "id": 622
    },
    {
      "name": "Apache Jena",
      "one_line_profile": "Java framework for building Semantic Web and Linked Data applications",
      "detailed_description": "A comprehensive framework for building semantic web applications, providing RDF API, SPARQL query engine (ARQ), and inference subsystems.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "rdf_processing",
        "reasoning",
        "sparql_query"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/apache/jena",
      "help_website": [
        "https://jena.apache.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "semantic-web",
        "rdf",
        "sparql"
      ],
      "id": 623
    },
    {
      "name": "KGT5",
      "one_line_profile": "Sequence-to-Sequence Knowledge Graph Completion and QA",
      "detailed_description": "A model for knowledge graph completion and question answering that treats these tasks as sequence-to-sequence generation problems using a T5 architecture.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "link_prediction",
        "question_answering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/apoorvumang/kgt5",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph-completion",
        "seq2seq",
        "transformer"
      ],
      "id": 624
    },
    {
      "name": "ArangoDB",
      "one_line_profile": "Native multi-model database for graphs, documents, and key-values",
      "detailed_description": "A scalable, multi-model database system that supports graph, document, and key-value data models with a unified query language (AQL).",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "data_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/arangodb/arangodb",
      "help_website": [
        "https://www.arangodb.com/docs/stable/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "graph-database",
        "multi-model",
        "nosql"
      ],
      "id": 625
    },
    {
      "name": "DGL-KE",
      "one_line_profile": "High-performance library for learning knowledge graph embeddings",
      "detailed_description": "A scalable and easy-to-use package for training knowledge graph embedding models on large-scale datasets, built on top of the Deep Graph Library (DGL).",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "embedding_learning",
        "link_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/awslabs/dgl-ke",
      "help_website": [
        "https://dglke.dgl.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph-embeddings",
        "dgl",
        "distributed-training"
      ],
      "id": 626
    },
    {
      "name": "BiVE",
      "one_line_profile": "Bi-Level Knowledge Graph Embeddings for Reasoning",
      "detailed_description": "Implementation of BiVE (Bi-Level Knowledge Graph Embeddings) for reasoning tasks beyond simple link prediction, as presented at AAAI 2023.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "reasoning",
        "embedding_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bdi-lab/BiVE",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "knowledge-graph",
        "reasoning",
        "representation-learning"
      ],
      "id": 627
    },
    {
      "name": "InGram",
      "one_line_profile": "Inductive Knowledge Graph Embedding via Relation Graphs",
      "detailed_description": "Implementation of InGram, a method for inductive knowledge graph embedding that leverages relation graphs to handle unseen entities.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "inductive_learning",
        "embedding_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bdi-lab/InGram",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "inductive-learning",
        "knowledge-graph",
        "icml"
      ],
      "id": 628
    },
    {
      "name": "blazegraph-python",
      "one_line_profile": "Python client library for Blazegraph Database",
      "detailed_description": "A Python client library designed to interact with the Blazegraph high-performance graph database, facilitating data manipulation and query execution.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "database_interface",
        "data_access"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/blazegraph/blazegraph-python",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "blazegraph",
        "python-client",
        "graph-database"
      ],
      "id": 629
    },
    {
      "name": "Blazegraph Database",
      "one_line_profile": "High-performance graph database supporting RDF and Tinkerpop",
      "detailed_description": "A scalable, high-performance graph database with support for Blueprints and RDF/SPARQL APIs, widely used for large-scale knowledge graphs.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "sparql_query",
        "rdf_processing"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/blazegraph/database",
      "help_website": [
        "https://blazegraph.com/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "graph-database",
        "rdf",
        "sparql"
      ],
      "id": 630
    },
    {
      "name": "Blazegraph Tinkerpop3",
      "one_line_profile": "TinkerPop 3 implementation for Blazegraph",
      "detailed_description": "The implementation of the Apache TinkerPop 3 graph computing framework interfaces for the Blazegraph database.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_computing",
        "database_interface"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/blazegraph/tinkerpop3",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "tinkerpop",
        "gremlin",
        "blazegraph"
      ],
      "id": 631
    },
    {
      "name": "MTL-KGC",
      "one_line_profile": "Multi-Task Learning for Knowledge Graph Completion",
      "detailed_description": "Code for the COLING20 paper 'Multi-Task Learning for Knowledge Graph Completion with Pre-trained Language Models', integrating PLMs with KG tasks.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "link_prediction",
        "multi_task_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bosung/MTL-KGC",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "bert",
        "multi-task-learning"
      ],
      "id": 632
    },
    {
      "name": "TA_TransE",
      "one_line_profile": "Temporal Knowledge Graph Completion using Sequence Encoders",
      "detailed_description": "Implementation of temporal knowledge graph completion methods, specifically focusing on learning sequence encoders as described in Duran et al.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "temporal_kg_completion",
        "link_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bsantraigi/TA_TransE",
      "help_website": [],
      "license": null,
      "tags": [
        "temporal-knowledge-graph",
        "transe",
        "sequence-modeling"
      ],
      "id": 633
    },
    {
      "name": "ConMask",
      "one_line_profile": "Open-world Knowledge Graph Completion model",
      "detailed_description": "Implementation of the ConMask model for open-world knowledge graph completion, capable of handling unseen entities by leveraging text descriptions.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "open_world_kgc",
        "link_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bxshi/ConMask",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "open-world",
        "embedding"
      ],
      "id": 634
    },
    {
      "name": "ProjE",
      "one_line_profile": "Embedding Projection for Knowledge Graph Completion",
      "detailed_description": "Implementation of ProjE, a neural network model for knowledge graph completion that learns joint embeddings of entities and relations.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "link_prediction",
        "embedding_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bxshi/ProjE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "embedding",
        "neural-network"
      ],
      "id": 635
    },
    {
      "name": "KBGAN",
      "one_line_profile": "Adversarial Learning for Knowledge Graph Embeddings",
      "detailed_description": "Implementation of KBGAN, an adversarial learning framework for improving knowledge graph embeddings by generating high-quality negative samples.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "embedding_learning",
        "adversarial_training"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cai-lw/KBGAN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gan",
        "knowledge-graph",
        "embedding"
      ],
      "id": 636
    },
    {
      "name": "Knowledge Graph Language",
      "one_line_profile": "Query language for exploring knowledge graphs",
      "detailed_description": "A domain-specific query language designed to facilitate the exploration and querying of knowledge graphs in a more intuitive manner.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "query_language",
        "graph_exploration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/capjamesg/knowledge-graph-language",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dsl",
        "query-language",
        "knowledge-graph"
      ],
      "id": 637
    },
    {
      "name": "Virtue",
      "one_line_profile": "Python and SKILL Framework for Cadence Virtuoso",
      "detailed_description": "A framework to automate and interact with Cadence Virtuoso (EDA tool) using Python and SKILL, facilitating circuit design and simulation workflows.",
      "domains": [
        "Physics",
        "Electronics"
      ],
      "subtask_category": [
        "circuit_design",
        "eda_automation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cascode-labs/virtue",
      "help_website": [
        "https://virtue.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "eda",
        "cadence-virtuoso",
        "circuit-design"
      ],
      "id": 638
    },
    {
      "name": "causalgraph",
      "one_line_profile": "Python package for modeling and visualizing causal graphs in knowledge graphs",
      "detailed_description": "A Python package designed for modeling, persisting, and visualizing causal graphs that are embedded within knowledge graphs, facilitating causal inference and analysis in complex data structures.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "causal_modeling",
        "graph_visualization",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/causalgraph/causalgraph",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "causal-inference",
        "knowledge-graph",
        "visualization"
      ],
      "id": 639
    },
    {
      "name": "go-graphkb",
      "one_line_profile": "Graph-oriented Knowledge Base engine written in Go",
      "detailed_description": "A standalone graph database engine and knowledge base implementation written in Go, designed for storing and querying graph-structured data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "data_query"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/clems4ever/go-graphkb",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-base",
        "graph-database",
        "go"
      ],
      "id": 640
    },
    {
      "name": "CogniPy",
      "one_line_profile": "In-memory Graph Database with Natural Language Interface and Pandas integration",
      "detailed_description": "An in-memory graph database and knowledge graph tool that features a natural language interface and seamless compatibility with Pandas DataFrames, enabling data scientists to manipulate graph data using familiar Python tools.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "data_analysis",
        "natural_language_query"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/cognitum-octopus/cognipy",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "graph-database",
        "pandas",
        "nlp",
        "knowledge-graph"
      ],
      "id": 641
    },
    {
      "name": "VirtuosoToolboxMatlab",
      "one_line_profile": "MATLAB toolbox for interfacing with Cadence Virtuoso IC Design System",
      "detailed_description": "A MATLAB toolbox that provides an interface to the Cadence Virtuoso IC Design System, allowing engineers to control design parameters and process simulation data within the MATLAB scientific computing environment.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "simulation_control",
        "data_interface",
        "eda_workflow"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/curtisma/VirtuosoToolboxMatlab",
      "help_website": [],
      "license": null,
      "tags": [
        "matlab",
        "cadence-virtuoso",
        "eda",
        "ic-design"
      ],
      "id": 642
    },
    {
      "name": "D2RQ",
      "one_line_profile": "Platform for treating non-RDF relational databases as virtual RDF graphs",
      "detailed_description": "A database-to-RDF mapping engine that allows accessing relational databases as virtual, read-only RDF graphs. It offers SPARQL access and RDF dumps without replicating the database into an RDF store.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "data_mapping",
        "rdb2rdf",
        "sparql_endpoint"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/d2rq/d2rq",
      "help_website": [
        "http://d2rq.org/"
      ],
      "license": null,
      "tags": [
        "rdf",
        "sparql",
        "mapping",
        "database"
      ],
      "id": 643
    },
    {
      "name": "IGUANA",
      "one_line_profile": "Benchmark execution framework for RDF triple stores",
      "detailed_description": "A generic benchmark execution framework designed for RDF triple stores and quad stores, allowing researchers to evaluate and compare the performance of different graph database systems.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/dice-group/IGUANA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmarking",
        "rdf",
        "triplestore",
        "evaluation"
      ],
      "id": 644
    },
    {
      "name": "ActiveLink",
      "one_line_profile": "Deep active learning framework for link prediction in knowledge graphs",
      "detailed_description": "A framework utilizing deep active learning strategies to enhance link prediction tasks within knowledge graphs, aiming to reduce labeling costs while maintaining performance.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "link_prediction",
        "active_learning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/eXascaleInfolab/ActiveLink",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "link-prediction",
        "active-learning"
      ],
      "id": 645
    },
    {
      "name": "Eclipse RDF4J",
      "one_line_profile": "Scalable RDF framework for Java",
      "detailed_description": "A comprehensive framework for processing and handling RDF data in Java, providing functionality for parsing, storing, inferencing, and querying semantic data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "storage",
        "querying",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/eclipse-rdf4j/rdf4j",
      "help_website": [
        "https://rdf4j.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "rdf",
        "sparql",
        "semantic-web",
        "java"
      ],
      "id": 646
    },
    {
      "name": "neo4jd3",
      "one_line_profile": "Neo4j graph visualization using D3.js",
      "detailed_description": "A JavaScript library for visualizing graph data stored in Neo4j databases using the D3.js library, enabling interactive exploration of knowledge graph structures.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/eisman/neo4jd3",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "neo4j",
        "d3",
        "graph-database"
      ],
      "id": 647
    },
    {
      "name": "Bulbs",
      "one_line_profile": "Python persistence framework for graph databases",
      "detailed_description": "A Python object-graph mapper (OGM) and persistence framework that supports multiple graph databases including Neo4j, OrientDB, and Titan, facilitating graph data management.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "storage",
        "querying"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/espeed/bulbs",
      "help_website": [
        "http://bulbflow.com/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "graph-database",
        "orm",
        "neo4j",
        "persistence"
      ],
      "id": 648
    },
    {
      "name": "libfactplusplus",
      "one_line_profile": "Efficient Description Logic reasoner compatible with OWL DL",
      "detailed_description": "A C++ library implementation of FaCT++, a highly optimized Description Logic reasoner supporting OWL DL and OWL 2 standards, used for ontology consistency checking and inference.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "inference"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ethz-asl/libfactplusplus",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "reasoner",
        "owl",
        "description-logic",
        "ontology"
      ],
      "id": 649
    },
    {
      "name": "embeddedCypher",
      "one_line_profile": "Portable in-memory graph database implementing openCypher",
      "detailed_description": "A lightweight, portable, in-memory graph database management system written in C++ that implements the openCypher query language, suitable for embedded graph processing.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "storage",
        "querying"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/expertcompsci/embeddedCypher",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "graph-database",
        "opencypher",
        "embedded",
        "c++"
      ],
      "id": 650
    },
    {
      "name": "eye-js",
      "one_line_profile": "WebAssembly distribution of the EYE reasoner",
      "detailed_description": "A JavaScript/WebAssembly distribution of the EYE (Euler Yet another proof Engine) semantic reasoner, enabling logic-based reasoning directly in web environments.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "inference"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/eyereasoner/eye-js",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "reasoner",
        "semantic-web",
        "webassembly",
        "logic"
      ],
      "id": 651
    },
    {
      "name": "SSL-Relation-Prediction",
      "one_line_profile": "Self-supervised learning for Knowledge Graph Embeddings",
      "detailed_description": "An implementation of simple yet state-of-the-art Knowledge Graph Embedding methods using self-supervised learning techniques for relation prediction tasks.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "link_prediction",
        "embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/ssl-relation-prediction",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "knowledge-graph",
        "embedding",
        "self-supervised-learning",
        "relation-prediction"
      ],
      "id": 652
    },
    {
      "name": "SemTK",
      "one_line_profile": "SPARQL query generation and data ingestion toolkit",
      "detailed_description": "A toolkit designed to facilitate the generation of SPARQL queries and the ingestion of data into triple stores (like Virtuoso) via a drag-and-drop interface and API.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "querying",
        "data_ingestion"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/ge-semtk/semtk",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "sparql",
        "semantic-web",
        "data-ingestion",
        "virtuoso"
      ],
      "id": 653
    },
    {
      "name": "Noctua Reasoner",
      "one_line_profile": "Client-side reasoner for the Noctua curation platform",
      "detailed_description": "A client-side reasoning engine developed for the Noctua platform by the Gene Ontology Consortium, enabling real-time consistency checking and inference for biological ontologies.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "inference"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/geneontology/noctua-reasoner",
      "help_website": [],
      "license": null,
      "tags": [
        "gene-ontology",
        "reasoner",
        "bioinformatics",
        "noctua"
      ],
      "id": 654
    },
    {
      "name": "InteractiveGraph",
      "one_line_profile": "Web-based interactive graph visualization framework",
      "detailed_description": "A framework for interactive visualization and analysis of large graph data, supporting data sources like GSON files and Neo4j, enabling visual exploration of complex networks.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "visualization",
        "analysis"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/grapheco/InteractiveGraph",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "visualization",
        "graph-analysis",
        "neo4j",
        "interactive"
      ],
      "id": 655
    },
    {
      "name": "PyGraphistry",
      "one_line_profile": "GPU-accelerated graph visualization and analysis library",
      "detailed_description": "A Python library that interfaces with Graphistry's GPU-accelerated engine to load, shape, embed, and explore large-scale graphs for visual analysis.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "visualization",
        "analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/graphistry/pygraphistry",
      "help_website": [
        "https://github.com/graphistry/pygraphistry"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "visualization",
        "gpu",
        "graph-analysis",
        "python"
      ],
      "id": 656
    },
    {
      "name": "Reasonable",
      "one_line_profile": "OWL 2 Reasoner built on DataFrog",
      "detailed_description": "A high-performance OWL 2 RL reasoner implemented in Rust, utilizing the DataFrog Datalog engine for efficient semantic inference.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "inference"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/gtfierro/reasonable",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "reasoner",
        "owl",
        "rust",
        "semantic-web"
      ],
      "id": 657
    },
    {
      "name": "INDRA",
      "one_line_profile": "Automated model assembly system for causal graphs",
      "detailed_description": "Integrated Network and Dynamical Reasoning Assembler (INDRA) is a system that extracts knowledge from literature and databases to assemble causal graphs and dynamical models for systems biology.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "modeling",
        "extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/gyorilab/indra",
      "help_website": [
        "https://indra.readthedocs.io/"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "systems-biology",
        "causal-inference",
        "nlp",
        "knowledge-assembly"
      ],
      "id": 658
    },
    {
      "name": "BlazegraphBasedTPFServer",
      "one_line_profile": "Triple Pattern Fragment server backend using Blazegraph",
      "detailed_description": "A server implementation of the Triple Pattern Fragments (TPF) interface that uses the Blazegraph graph database as its backend, enabling low-cost querying of RDF datasets.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_querying",
        "rdf_server"
      ],
      "application_level": "service",
      "primary_language": "Java",
      "repo_url": "https://github.com/hartig/BlazegraphBasedTPFServer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "linked-data",
        "tpf",
        "blazegraph",
        "rdf"
      ],
      "id": 659
    },
    {
      "name": "Hash",
      "one_line_profile": "Open-source, multi-tenant knowledge graph platform",
      "detailed_description": "A self-building knowledge graph platform designed to be open-source and multi-tenant, providing infrastructure for structuring and querying connected data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "knowledge_management"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/hashintel/hash",
      "help_website": [
        "https://hash.ai"
      ],
      "license": "NOASSERTION",
      "tags": [
        "knowledge-graph",
        "database",
        "rust"
      ],
      "id": 660
    },
    {
      "name": "RAGQnASystem",
      "one_line_profile": "Medical QA system using Knowledge Graphs and RAG",
      "detailed_description": "A medical question-answering system that integrates Retrieval-Augmented Generation (RAG) with a Neo4j-based Knowledge Graph (DiseaseKG) and Large Language Models to provide accurate medical information.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "question_answering",
        "medical_informatics"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/honeyandme/RAGQnASystem",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "neo4j",
        "medical-kg",
        "llm"
      ],
      "id": 661
    },
    {
      "name": "HyperGraphDB",
      "one_line_profile": "General purpose distributed graph database",
      "detailed_description": "An extensible, portable, distributed, and embeddable graph database designed specifically for artificial intelligence and semantic web projects, supporting generalized hypergraphs.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "graph_database"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/hypergraphdb/hypergraphdb",
      "help_website": [
        "http://www.hypergraphdb.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "graph-database",
        "java",
        "semantic-web"
      ],
      "id": 662
    },
    {
      "name": "pyKE",
      "one_line_profile": "Library for Knowledge Graph Embedding models",
      "detailed_description": "A collection of implementations of Knowledge Embedding Models (such as TransE, etc.), originally forked from OpenKE, providing a toolkit for training and evaluating embeddings.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ifis-tu-bs/pyKE",
      "help_website": [],
      "license": null,
      "tags": [
        "kge",
        "embedding",
        "machine-learning"
      ],
      "id": 663
    },
    {
      "name": "jena-jruby",
      "one_line_profile": "JRuby wrapper for Apache Jena",
      "detailed_description": "A wrapper library that provides access to the Apache Jena Semantic Web framework within JRuby programs, enabling RDF processing and reasoning.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "rdf_processing",
        "reasoning"
      ],
      "application_level": "library",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/ijdickinson/jena-jruby",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "jena",
        "ruby",
        "rdf",
        "semantic-web"
      ],
      "id": 664
    },
    {
      "name": "cl-grph",
      "one_line_profile": "In-memory graph structure with Datalog query",
      "detailed_description": "A Common Lisp library providing an in-memory immutable graph structure and a Datalog query language for graph traversal and reasoning.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_querying",
        "reasoning"
      ],
      "application_level": "library",
      "primary_language": "Common Lisp",
      "repo_url": "https://github.com/inconvergent/cl-grph",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "common-lisp",
        "datalog",
        "graph-algorithms"
      ],
      "id": 665
    },
    {
      "name": "Visual-Knowledge-Graph-System",
      "one_line_profile": "Visual knowledge graph system with Neo4j",
      "detailed_description": "A system for visualizing knowledge graphs using G6 for the frontend and Neo4j as the database backend, facilitating exploration of graph data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "visualization",
        "graph_exploration"
      ],
      "application_level": "workflow",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/island99/Visual-Knowledge-Graph-System",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "visualization",
        "neo4j",
        "g6"
      ],
      "id": 666
    },
    {
      "name": "CogKGE",
      "one_line_profile": "Knowledge Graph Embedding Toolkit",
      "detailed_description": "A toolkit and benchmark for Knowledge Graph Embedding (KGE) that supports representing multi-source and heterogeneous knowledge, designed for research and application development.",
      "domains": [
        "G2",
        "G2-01"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jinzhuoran/CogKGE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kge",
        "toolkit",
        "pytorch"
      ],
      "id": 667
    },
    {
      "name": "data2neo",
      "one_line_profile": "Relational data to Neo4j converter",
      "detailed_description": "A library that simplifies the conversion of data from relational formats (SQL) to a graph knowledge database (Neo4j), facilitating KG construction.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "data_conversion",
        "kg_construction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jkminder/data2neo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "neo4j",
        "etl",
        "sql"
      ],
      "id": 668
    },
    {
      "name": "sesametools",
      "one_line_profile": "Utilities for OpenRDF Sesame (RDF4J)",
      "detailed_description": "A collection of utilities and tools for working with the OpenRDF Sesame framework (now Eclipse RDF4J), aiding in RDF data management and processing.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "rdf_processing",
        "utilities"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/joshsh/sesametools",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rdf4j",
        "sesame",
        "semantic-web"
      ],
      "id": 669
    },
    {
      "name": "python-virtuoso",
      "one_line_profile": "Python wrapper for Virtuoso triplestore",
      "detailed_description": "A Python wrapper for the Virtuoso triplestore, allowing users to interact with the database and execute SPARQL queries from Python applications.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_querying",
        "database_interface"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/juanique/python-virtuoso",
      "help_website": [],
      "license": null,
      "tags": [
        "virtuoso",
        "sparql",
        "python"
      ],
      "id": 670
    },
    {
      "name": "cl-jena",
      "one_line_profile": "Common Lisp wrapper for Apache Jena",
      "detailed_description": "A Common Lisp wrapper around functionality of the Apache Jena framework, enabling RDF graph manipulation and reasoning within Lisp environments.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "rdf_processing",
        "reasoning"
      ],
      "application_level": "library",
      "primary_language": "Common Lisp",
      "repo_url": "https://github.com/justin2004/cl-jena",
      "help_website": [],
      "license": null,
      "tags": [
        "common-lisp",
        "jena",
        "rdf"
      ],
      "id": 671
    },
    {
      "name": "kineo",
      "one_line_profile": "Persistent RDF quadstore and SPARQL engine",
      "detailed_description": "A persistent RDF quadstore and SPARQL query engine implemented in Swift, designed for storing and querying semantic web data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "sparql_engine"
      ],
      "application_level": "solver",
      "primary_language": "Swift",
      "repo_url": "https://github.com/kasei/kineo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rdf",
        "sparql",
        "quadstore",
        "swift"
      ],
      "id": 672
    },
    {
      "name": "Konclude",
      "one_line_profile": "High-performance parallel reasoner for OWL 2 DL ontologies",
      "detailed_description": "Konclude is a high-performance reasoner for the Description Logic SROIQV(D), which corresponds to OWL 2 DL. It employs a tableau-based algorithm and is designed for parallel processing to handle large and complex ontologies efficiently.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "ontology_inference",
        "consistency_checking"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/konclude/Konclude",
      "help_website": [
        "https://www.konclude.com/"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "reasoner",
        "owl2",
        "description-logic",
        "semantic-web"
      ],
      "id": 673
    },
    {
      "name": "Kùzu",
      "one_line_profile": "Embedded property graph database management system",
      "detailed_description": "Kùzu is an in-process property graph database management system (GDBMS) built for query speed and scalability. It implements the Cypher query language and is optimized for graph analytics and vector search.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "graph_query",
        "vector_search"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/kuzudb/kuzu",
      "help_website": [
        "https://kuzudb.com/"
      ],
      "license": "MIT",
      "tags": [
        "graph-database",
        "cypher",
        "embedded-database",
        "vector-search"
      ],
      "id": 674
    },
    {
      "name": "Pixy",
      "one_line_profile": "Declarative graph query language on TinkerPop",
      "detailed_description": "Pixy is a declarative, vendor-independent graph query language built on the TinkerPop software stack. It allows users to query graph databases using a logic-based syntax.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_query",
        "query_language"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/lambdazen/pixy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "graph-query-language",
        "tinkerpop",
        "declarative"
      ],
      "id": 675
    },
    {
      "name": "LiteGraph",
      "one_line_profile": "Lightweight graph database with vector and relational support",
      "detailed_description": "LiteGraph is a lightweight graph database designed for AI and knowledge persistence. It supports relational data, vector embeddings, and integrates with the Model Context Protocol (MCP).",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "graph_query",
        "vector_storage"
      ],
      "application_level": "platform",
      "primary_language": "C#",
      "repo_url": "https://github.com/litegraphdb/litegraph",
      "help_website": [],
      "license": null,
      "tags": [
        "graph-database",
        "vector-database",
        "knowledge-graph"
      ],
      "id": 676
    },
    {
      "name": "RAGAT",
      "one_line_profile": "Relation Aware Graph Attention Network for KG Completion",
      "detailed_description": "RAGAT is a graph neural network model for knowledge graph completion. It introduces a relation-aware graph attention mechanism to better capture the interactions between entities and relations.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "link_prediction",
        "knowledge_graph_completion",
        "graph_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liuxiyang641/RAGAT",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph-completion",
        "graph-attention-network",
        "link-prediction"
      ],
      "id": 677
    },
    {
      "name": "ELK Reasoner",
      "one_line_profile": "High-performance reasoner for OWL 2 EL ontologies",
      "detailed_description": "ELK is a reasoner for the OWL 2 EL profile, designed for high performance on large ontologies such as SNOMED CT. It supports classification and consistency checking.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "ontology_classification",
        "consistency_checking"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/liveontologies/elk-reasoner",
      "help_website": [
        "http://elk.semanticweb.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "reasoner",
        "owl-el",
        "ontology",
        "snomed-ct"
      ],
      "id": 678
    },
    {
      "name": "EmbedKGQA",
      "one_line_profile": "Multi-hop Question Answering over Knowledge Graphs using Embeddings",
      "detailed_description": "EmbedKGQA is a method for multi-hop question answering over knowledge graphs. It leverages knowledge base embeddings to handle data sparsity and improve reasoning capabilities.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "question_answering",
        "graph_reasoning",
        "knowledge_graph_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/malllabiisc/EmbedKGQA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kgqa",
        "knowledge-graph-embeddings",
        "multi-hop-qa"
      ],
      "id": 679
    },
    {
      "name": "HyTE",
      "one_line_profile": "Hyperplane-based Temporally aware Knowledge Graph Embedding",
      "detailed_description": "HyTE is a knowledge graph embedding model that explicitly incorporates temporal information by projecting entities and relations onto temporal hyperplanes.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "temporal_reasoning",
        "link_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/malllabiisc/HyTE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "temporal-knowledge-graph",
        "embedding",
        "link-prediction"
      ],
      "id": 680
    },
    {
      "name": "InteractE",
      "one_line_profile": "Convolution-based Knowledge Graph Embeddings with Feature Interactions",
      "detailed_description": "InteractE is a knowledge graph embedding model that improves upon convolution-based methods by increasing feature interactions, enhancing performance on link prediction tasks.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "link_prediction",
        "graph_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/malllabiisc/InteractE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph-embedding",
        "convolutional-neural-networks",
        "link-prediction"
      ],
      "id": 681
    },
    {
      "name": "BERT-KG-Document-Classification",
      "one_line_profile": "Document classification using BERT enriched with KG embeddings",
      "detailed_description": "This tool implements a method to enrich BERT models with knowledge graph embeddings for improved document classification, integrating structured knowledge into text analysis.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "document_classification",
        "knowledge_integration",
        "text_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/malteos/pytorch-bert-document-classification",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bert",
        "knowledge-graph",
        "document-classification",
        "pytorch"
      ],
      "id": 682
    },
    {
      "name": "knowledge-graph-embeddings",
      "one_line_profile": "Library of embedding-based methods for Knowledge Base Completion",
      "detailed_description": "A Python library providing implementations of various embedding-based methods (such as TransE, TransH, etc.) for knowledge base completion and link prediction tasks.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "link_prediction",
        "knowledge_base_completion"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mana-ysh/knowledge-graph-embeddings",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kge",
        "link-prediction",
        "transe",
        "transh"
      ],
      "id": 683
    },
    {
      "name": "DRAGON",
      "one_line_profile": "Deep Bidirectional Language-Knowledge Graph Pretraining",
      "detailed_description": "DRAGON is a pre-trained model that jointly learns from text and knowledge graphs using a bidirectional approach. It is designed to improve performance on tasks requiring both language understanding and structured knowledge reasoning.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_reasoning",
        "language_model_pretraining",
        "knowledge_integration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/michiyasunaga/dragon",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "pretraining",
        "language-model",
        "reasoning"
      ],
      "id": 684
    },
    {
      "name": "HittER",
      "one_line_profile": "Hierarchical Transformers for Knowledge Graph Embeddings",
      "detailed_description": "HittER is a model for knowledge graph embeddings that uses hierarchical transformers to capture structural information and improve link prediction performance.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "link_prediction",
        "graph_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/HittER",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "transformer",
        "knowledge-graph-embedding",
        "hierarchical-learning"
      ],
      "id": 685
    },
    {
      "name": "openCypherTranspiler",
      "one_line_profile": "Transpiler from openCypher to SQL",
      "detailed_description": "This tool transpiles openCypher graph queries into SQL, allowing users to execute graph queries on relational database management systems (RDBMS) like SQL Server.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "query_translation",
        "graph_query",
        "interoperability"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/microsoft/openCypherTranspiler",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "opencypher",
        "sql",
        "transpiler",
        "graph-query"
      ],
      "id": 686
    },
    {
      "name": "cubic-hermite",
      "one_line_profile": "Cubic Hermite spline interpolation library",
      "detailed_description": "A lightweight JavaScript library for performing cubic Hermite spline interpolation, useful for scientific data visualization and numerical analysis.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "interpolation",
        "numerical_analysis",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/mikolalysenko/cubic-hermite",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "interpolation",
        "spline",
        "math",
        "numerical-methods"
      ],
      "id": 687
    },
    {
      "name": "Graph-LLM",
      "one_line_profile": "Boosting Graph Reasoning Ability of Large Language Models",
      "detailed_description": "Graph-LLM is a framework designed to enhance the graph reasoning capabilities of Large Language Models (LLMs), enabling them to better process and reason over structured graph data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_reasoning",
        "llm_integration",
        "knowledge_graph"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mistyreed63849/Graph-LLM",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "graph-reasoning",
        "knowledge-graph",
        "ai4s"
      ],
      "id": 688
    },
    {
      "name": "Holographic Embeddings (HolE)",
      "one_line_profile": "Holographic Embeddings of Knowledge Graphs",
      "detailed_description": "This repository contains the implementation of Holographic Embeddings (HolE), a method for learning compositional vector space representations of entire knowledge graphs, used for link prediction and other inference tasks.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "link_prediction",
        "graph_representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mnick/holographic-embeddings",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph-embedding",
        "hole",
        "link-prediction"
      ],
      "id": 689
    },
    {
      "name": "scikit-kge",
      "one_line_profile": "Python library for computing knowledge graph embeddings with a scikit-learn compatible API",
      "detailed_description": "A library to compute knowledge graph embeddings, providing a unified interface for various embedding models (Rescal, HolE, TransE, etc.) to support link prediction and entity classification in scientific knowledge graphs.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "link_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mnick/scikit-kge",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kge",
        "embedding",
        "machine-learning"
      ],
      "id": 690
    },
    {
      "name": "Morph-KGC",
      "one_line_profile": "Engine for constructing RDF knowledge graphs from heterogeneous data sources using RML",
      "detailed_description": "A tool that generates RDF knowledge graphs from various data sources (relational databases, CSV, JSON, etc.) using RML (RDF Mapping Language) mappings, essential for integrating heterogeneous scientific data into a unified graph structure.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "kg_construction",
        "data_integration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/morph-kgc/morph-kgc",
      "help_website": [
        "https://morph-kgc.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rdf",
        "knowledge-graph-construction",
        "rml"
      ],
      "id": 691
    },
    {
      "name": "Neo4j Graph Algorithms",
      "one_line_profile": "Library of efficient graph algorithms for Neo4j",
      "detailed_description": "A library providing parallel versions of common graph algorithms (Centrality, Community Detection, Path Finding, Similarity) for Neo4j, enabling network analysis on scientific data stored in graph databases.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_analysis",
        "network_science"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/neo4j-contrib/neo4j-graph-algorithms",
      "help_website": [
        "https://neo4j.com/docs/graph-algorithms/current/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "graph-algorithms",
        "network-analysis",
        "centrality"
      ],
      "id": 692
    },
    {
      "name": "Neo4j Spatial",
      "one_line_profile": "Spatial utilities and indexing for Neo4j",
      "detailed_description": "A library enabling geospatial operations within Neo4j, allowing for the storage, indexing, and querying of spatial data, which is critical for geographic information systems (GIS) and spatial analysis in scientific research.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "spatial_analysis",
        "geospatial_query"
      ],
      "application_level": "library",
      "primary_language": "Scheme",
      "repo_url": "https://github.com/neo4j-contrib/spatial",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "gis",
        "spatial-index",
        "geospatial"
      ],
      "id": 693
    },
    {
      "name": "LLM Graph Builder",
      "one_line_profile": "Tool for constructing knowledge graphs from unstructured data using LLMs",
      "detailed_description": "A workflow tool that leverages Large Language Models to extract entities and relationships from unstructured text (PDFs, docs, etc.) and construct a knowledge graph in Neo4j, automating the scientific knowledge extraction process.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "kg_construction",
        "information_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/neo4j-labs/llm-graph-builder",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "knowledge-extraction",
        "unstructured-data"
      ],
      "id": 694
    },
    {
      "name": "neosemantics",
      "one_line_profile": "RDF and Linked Data import/export toolkit for Neo4j",
      "detailed_description": "A plugin for Neo4j that enables the use of RDF and Linked Data, supporting ontology management, SHACL validation, and inference, which are essential for semantic interoperability in scientific knowledge graphs.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "ontology_management",
        "rdf_processing"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/neo4j-labs/neosemantics",
      "help_website": [
        "https://neo4j.com/labs/neosemantics/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rdf",
        "semantic-web",
        "ontology"
      ],
      "id": 695
    },
    {
      "name": "Neo4j Graph Data Science",
      "one_line_profile": "Enterprise-grade library for graph analytics and machine learning",
      "detailed_description": "A comprehensive library for running graph algorithms (community detection, centrality, embeddings) and machine learning pipelines directly within the Neo4j database, widely used for scientific network analysis and predictive modeling.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_analytics",
        "machine_learning"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/neo4j/graph-data-science",
      "help_website": [
        "https://neo4j.com/docs/graph-data-science/current/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "graph-ml",
        "network-science",
        "algorithms"
      ],
      "id": 696
    },
    {
      "name": "Neo4j",
      "one_line_profile": "Native graph database platform for connected data",
      "detailed_description": "The core graph database platform that provides storage, query (Cypher), and reasoning capabilities for highly connected scientific data, serving as the foundational infrastructure for many scientific knowledge graphs.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "graph_query"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/neo4j/neo4j",
      "help_website": [
        "https://neo4j.com/docs/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "graph-database",
        "nosql",
        "cypher"
      ],
      "id": 697
    },
    {
      "name": "Neo4j GraphRAG Python",
      "one_line_profile": "GraphRAG implementation for Python using Neo4j",
      "detailed_description": "A library enabling Retrieval-Augmented Generation (RAG) using knowledge graphs, allowing for more accurate and context-aware scientific question answering and reasoning by combining LLMs with structured graph data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_rag",
        "question_answering"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/neo4j/neo4j-graphrag-python",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "llm",
        "knowledge-graph"
      ],
      "id": 698
    },
    {
      "name": "muKG",
      "one_line_profile": "Library for multi-source knowledge graph embeddings",
      "detailed_description": "A Python library designed for multi-source knowledge graph embeddings, supporting tasks like entity alignment and multi-view learning, facilitating the integration and reasoning over distributed scientific knowledge bases.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "multi_source_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nju-websoft/muKG",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "kge",
        "multi-source",
        "embedding"
      ],
      "id": 699
    },
    {
      "name": "Helio",
      "one_line_profile": "Framework for publishing heterogeneous data as RDF Linked Data services",
      "detailed_description": "Helio is a framework that facilitates the publication of RDF data as a Linked Data service by translating data from heterogeneous sources. It supports automatic injection into triple stores, versioning, and SPARQL endpoint generation.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "data_integration",
        "rdf_generation"
      ],
      "application_level": "framework",
      "primary_language": "HTML",
      "repo_url": "https://github.com/oeg-upm/helio",
      "help_website": [],
      "license": null,
      "tags": [
        "rdf",
        "linked-data",
        "data-integration"
      ],
      "id": 700
    },
    {
      "name": "Ontoweaver",
      "one_line_profile": "Library for integrating tabular data into Semantic Knowledge Graphs",
      "detailed_description": "Ontoweaver provides an easy way to integrate heterogeneous iterable data (like tables) into Semantic Knowledge Graph databases, specifically designed with oncology data in mind.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "data_integration",
        "knowledge_graph_construction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/oncodash/ontoweaver",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "data-integration",
        "oncology"
      ],
      "id": 701
    },
    {
      "name": "Ontop",
      "one_line_profile": "Virtual Knowledge Graph platform for querying relational databases as RDF",
      "detailed_description": "Ontop is a platform that exposes relational databases as Virtual RDF Knowledge Graphs, allowing users to query them using SPARQL without materializing the data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "virtual_knowledge_graph",
        "sparql_querying"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/ontop/ontop",
      "help_website": [
        "https://ontop-vkg.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "sparql",
        "virtual-knowledge-graph",
        "rdb2rdf"
      ],
      "id": 702
    },
    {
      "name": "Unified Rule Engine (URE)",
      "one_line_profile": "Graph rewriting and reasoning engine for the OpenCog AtomSpace",
      "detailed_description": "The Unified Rule Engine (URE) is a graph rewriting system used as the reasoning engine for OpenCog, operating on the AtomSpace hypergraph knowledge store.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "graph_rewriting"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/opencog/ure",
      "help_website": [
        "https://wiki.opencog.org/w/Unified_Rule_Engine"
      ],
      "license": "NOASSERTION",
      "tags": [
        "reasoning",
        "opencog",
        "graph-rewriting"
      ],
      "id": 703
    },
    {
      "name": "Morpheus",
      "one_line_profile": "Cypher query language implementation on Apache Spark",
      "detailed_description": "Morpheus (formerly Cypher for Apache Spark) brings the Cypher property graph query language to the distributed processing platform Apache Spark, enabling large-scale graph processing.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_querying",
        "distributed_processing"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/opencypher/morpheus",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "cypher",
        "spark",
        "graph-processing"
      ],
      "id": 704
    },
    {
      "name": "Virtuoso RDFizer Mapper Scripts",
      "one_line_profile": "Scripts for mapping non-RDF data sources to RDF",
      "detailed_description": "A collection of XSLT stylesheets and scripts for mapping various non-RDF data sources to RDF, used in Virtuoso RDFizer Cartridges and GRDDL processors.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "data_conversion",
        "rdf_mapping"
      ],
      "application_level": "library",
      "primary_language": "Shell",
      "repo_url": "https://github.com/openlink/Virtuoso-RDFIzer-Mapper-Scripts",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "xslt",
        "rdf-mapping",
        "virtuoso"
      ],
      "id": 705
    },
    {
      "name": "Virtuoso OpenSource",
      "one_line_profile": "High-performance Multi-Model RDBMS and RDF Triple Store",
      "detailed_description": "Virtuoso is a scalable Multi-Model RDBMS, Data Integration Middleware, Linked Data Deployment, and HTTP Application Server Platform, widely used as an RDF Triple Store.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_database",
        "triple_store"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/openlink/virtuoso-opensource",
      "help_website": [
        "http://virtuoso.openlinksw.com/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "triple-store",
        "rdf",
        "sparql"
      ],
      "id": 706
    },
    {
      "name": "OpenNARS",
      "one_line_profile": "General-purpose reasoning system implementing Non-Axiomatic Logic",
      "detailed_description": "OpenNARS is an open-source implementation of the NARS (Non-Axiomatic Reasoning System) theory, designed for general intelligence and reasoning under uncertainty.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "agi"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/opennars/opennars",
      "help_website": [
        "http://opennars.org/"
      ],
      "license": "MIT",
      "tags": [
        "reasoning",
        "nars",
        "logic"
      ],
      "id": 707
    },
    {
      "name": "Open Semantic Entity Search API",
      "one_line_profile": "API for named entity extraction and linking using knowledge graphs",
      "detailed_description": "A REST API for named entity extraction, linking, disambiguation, and reconciliation against linked data knowledge graphs like SKOS thesauri or RDF ontologies.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "entity_linking",
        "entity_extraction"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/opensemanticsearch/open-semantic-entity-search-api",
      "help_website": [
        "https://www.opensemanticsearch.org/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "ner",
        "entity-linking",
        "semantic-search"
      ],
      "id": 708
    },
    {
      "name": "NornicDB",
      "one_line_profile": "High-performance graph database for AI agents",
      "detailed_description": "NornicDB is a graph database compatible with Neo4j's Bolt protocol and Cypher, featuring GPU-accelerated embedding search and intelligent features for AI agents.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_database",
        "vector_search"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/orneryd/NornicDB",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "graph-database",
        "cypher",
        "ai-agents"
      ],
      "id": 709
    },
    {
      "name": "ONT-API",
      "one_line_profile": "Unified API for OWL ontologies over Apache Jena",
      "detailed_description": "ONT-API provides a comprehensive Java API for working with OWL ontologies, built on top of Apache Jena, facilitating ontology manipulation and reasoning integration.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "ontology_management",
        "reasoning_interface"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/owlcs/ont-api",
      "help_website": [],
      "license": null,
      "tags": [
        "owl",
        "jena",
        "ontology"
      ],
      "id": 710
    },
    {
      "name": "Owlery",
      "one_line_profile": "REST web service wrapper for OWL reasoners",
      "detailed_description": "Owlery provides a set of REST web services that allow querying of an OWL reasoner containing a configured set of ontologies, developed by the Phenoscape project.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "ontology_querying"
      ],
      "application_level": "service",
      "primary_language": "Scala",
      "repo_url": "https://github.com/phenoscape/owlery",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "owl",
        "reasoner",
        "rest-api"
      ],
      "id": 711
    },
    {
      "name": "gStore",
      "one_line_profile": "Graph-based RDF triple store",
      "detailed_description": "gStore is a graph-based RDF triple store system that supports SPARQL queries and is designed for managing large-scale knowledge graphs.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_database",
        "triple_store"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/pkumod/gStore",
      "help_website": [
        "http://www.gstore.cn/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "rdf",
        "sparql",
        "graph-database"
      ],
      "id": 712
    },
    {
      "name": "SPARQL-DL API",
      "one_line_profile": "Query engine API for SPARQL-DL",
      "detailed_description": "A query engine API for SPARQL-DL, enabling Description Logic queries over OWL ontologies, maintained by the Protégé project.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "query_engine"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/protegeproject/sparql-dl-api",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "sparql-dl",
        "owl",
        "reasoning"
      ],
      "id": 713
    },
    {
      "name": "SWRLAPI Drools Engine",
      "one_line_profile": "Drools-based SWRL rule engine and OWL 2 RL reasoner",
      "detailed_description": "An implementation of a SWRLAPI-based OWL 2 RL reasoner and SWRL rule engine using the Drools rule engine, maintained by the Protégé project.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "rule_engine"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/protegeproject/swrlapi-drools-engine",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "swrl",
        "drools",
        "reasoning"
      ],
      "id": 714
    },
    {
      "name": "PyKEEN",
      "one_line_profile": "Library for learning and evaluating knowledge graph embeddings",
      "detailed_description": "PyKEEN (Python KnowlEdge EmbeddiNgs) is a Python library for training and evaluating knowledge graph embedding models, supporting a wide range of models and datasets.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "link_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pykeen/pykeen",
      "help_website": [
        "https://pykeen.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "kge",
        "embedding",
        "machine-learning"
      ],
      "id": 715
    },
    {
      "name": "Parliament",
      "one_line_profile": "High-performance triple store for RDF, OWL, and SPARQL",
      "detailed_description": "Parliament is a high-performance, standards-compliant triple store for RDF, OWL, and SPARQL, developed by Raytheon BBN.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "triple_store",
        "graph_database"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/raytheonbbn/parliament",
      "help_website": [
        "http://parliament.semwebcentral.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "triple-store",
        "rdf",
        "sparql"
      ],
      "id": 716
    },
    {
      "name": "Comunica Browser",
      "one_line_profile": "Browser-compatible build of the Comunica SPARQL query engine",
      "detailed_description": "Comunica Browser provides scripts and builds to run the Comunica query engine in web browsers, enabling client-side SPARQL querying of Linked Data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "query_engine",
        "sparql"
      ],
      "application_level": "library",
      "primary_language": null,
      "repo_url": "https://github.com/rdfjs/comunica-browser",
      "help_website": [
        "https://comunica.dev/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "sparql",
        "comunica",
        "browser"
      ],
      "id": 717
    },
    {
      "name": "Ostrich",
      "one_line_profile": "Versioned RDF triple store supporting changesets",
      "detailed_description": "Ostrich is a versioned RDF triple store that supports offset-enabled queries for changesets, allowing for efficient management and querying of evolving knowledge graphs.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "triple_store",
        "versioning"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/rdfostrich/ostrich",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rdf",
        "versioning",
        "triple-store"
      ],
      "id": 718
    },
    {
      "name": "virtuoso (R package)",
      "one_line_profile": "R interface for interacting with Virtuoso Open Source graph databases",
      "detailed_description": "A client library for the R programming language that enables scientists to query and manage data in Virtuoso graph databases, facilitating the integration of semantic web data into R-based scientific workflows.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "data_access",
        "querying"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/ropensci/virtuoso",
      "help_website": [
        "https://docs.ropensci.org/virtuoso/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "r",
        "virtuoso",
        "sparql",
        "graph-database",
        "linked-data"
      ],
      "id": 719
    },
    {
      "name": "Sage",
      "one_line_profile": "Preemptive SPARQL query engine for public Linked Data providers",
      "detailed_description": "A SPARQL query engine designed to execute queries over public Linked Data interfaces with support for preemption, allowing for stable and responsive querying of distributed scientific knowledge graphs.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "querying",
        "data_retrieval"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/sage-org/sage-engine",
      "help_website": [
        "http://sage.univ-nantes.fr/"
      ],
      "license": "MIT",
      "tags": [
        "sparql",
        "linked-data",
        "query-engine",
        "semantic-web"
      ],
      "id": 720
    },
    {
      "name": "ELepHant",
      "one_line_profile": "A specialized reasoner for OWL 2 EL ontologies",
      "detailed_description": "A reasoning engine specifically designed for the OWL 2 EL profile, enabling efficient inference and consistency checking for large-scale biomedical and scientific ontologies.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "inference"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/sertkaya/elephant-reasoner",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "owl",
        "reasoner",
        "ontology",
        "logic"
      ],
      "id": 721
    },
    {
      "name": "unKR",
      "one_line_profile": "Library for reasoning over uncertain knowledge graphs",
      "detailed_description": "A Python library dedicated to representation learning and reasoning on uncertain knowledge graphs, supporting various models for handling probabilistic or confidence-weighted scientific data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/seucoin/unKR",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "uncertainty",
        "reasoning",
        "embedding"
      ],
      "id": 722
    },
    {
      "name": "SimPhoNy OSP",
      "one_line_profile": "Ontology-based interoperability framework for scientific simulations",
      "detailed_description": "A framework that uses knowledge graphs as a common language to achieve interoperability between simulation engines, databases, and data repositories, facilitating complex multi-physics scientific workflows.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "integration",
        "simulation_interface"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/simphony/simphony-osp",
      "help_website": [
        "https://simphony-osp.readthedocs.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "simulation",
        "interoperability",
        "ontology",
        "knowledge-graph"
      ],
      "id": 723
    },
    {
      "name": "SociaLite",
      "one_line_profile": "Query language and engine for large-scale graph analysis",
      "detailed_description": "A Datalog-based query language and distributed execution engine designed for efficient analysis and data mining of large-scale graphs, applicable to scientific network analysis.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_analysis",
        "querying"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/socialite-lang/socialite",
      "help_website": [
        "http://socialite-lang.github.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "datalog",
        "graph-analysis",
        "distributed-systems",
        "query-language"
      ],
      "id": 724
    },
    {
      "name": "SPARQL-Generate",
      "one_line_profile": "Extension of SPARQL to generate RDF from non-RDF documents",
      "detailed_description": "An implementation of the SPARQL-Generate query language that allows for the generation of RDF streams from various document formats (JSON, XML, CSV, etc.) and streams, facilitating data ingestion into scientific knowledge graphs.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "data_transformation",
        "normalization"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/sparql-generate/sparql-generate",
      "help_website": [
        "https://w3id.org/sparql-generate/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "sparql",
        "rdf",
        "data-transformation",
        "semantic-web"
      ],
      "id": 725
    },
    {
      "name": "Pellet",
      "one_line_profile": "Open source OWL 2 DL reasoner for Java",
      "detailed_description": "A comprehensive OWL 2 DL reasoner written in Java, widely used for consistency checking, classification, and query answering in scientific ontologies and knowledge graphs.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "inference"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/stardog-union/pellet",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "owl",
        "reasoner",
        "semantic-web",
        "java"
      ],
      "id": 726
    },
    {
      "name": "Spfy",
      "one_line_profile": "Integrated graph database for real-time prediction of E. coli phenotypes",
      "detailed_description": "Spfy is an integrated graph database designed for the real-time prediction of Escherichia coli phenotypes and downstream comparative analyses. It leverages graph structures to store and query genomic data for biological research.",
      "domains": [
        "G2",
        "G2-03",
        "Biology",
        "Genomics"
      ],
      "subtask_category": [
        "phenotype_prediction",
        "comparative_analysis",
        "graph_database"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/superphy/spfy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "graph-database",
        "bioinformatics",
        "e-coli",
        "genomics"
      ],
      "id": 727
    },
    {
      "name": "RedisGraph",
      "one_line_profile": "Graph database module for Redis using Cypher query language",
      "detailed_description": "RedisGraph is a graph database module for Redis that implements the Cypher query language. It uses sparse adjacency matrices to represent graphs, enabling efficient storage and querying of connected data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "graph_query"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/swilly22/redis-graph",
      "help_website": [
        "https://oss.redis.com/redisgraph/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "graph-database",
        "redis",
        "cypher",
        "matrix-operations"
      ],
      "id": 728
    },
    {
      "name": "qEndpoint",
      "one_line_profile": "Scalable RDF triple store with full-text and GeoSPARQL support",
      "detailed_description": "qEndpoint is a highly scalable RDF triple store designed to handle large knowledge graphs. It supports standard SPARQL queries along with full-text search and GeoSPARQL for spatial data.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "rdf_storage",
        "sparql_query",
        "geospatial_query"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/the-qa-company/qEndpoint",
      "help_website": [],
      "license": null,
      "tags": [
        "rdf",
        "triple-store",
        "sparql",
        "geosparql"
      ],
      "id": 729
    },
    {
      "name": "thi.ng/trio",
      "one_line_profile": "Datatype agnostic triple store and query engine",
      "detailed_description": "Trio is a datatype-agnostic triple store and query engine API. It provides a flexible way to store and query graph-structured data without being tied to specific RDF data types.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "triple_store",
        "graph_query"
      ],
      "application_level": "library",
      "primary_language": "Shell",
      "repo_url": "https://github.com/thi-ng/trio",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "triple-store",
        "graph-database",
        "query-engine"
      ],
      "id": 730
    },
    {
      "name": "KB2E",
      "one_line_profile": "Library for Knowledge Graph Embeddings (TransE, TransH, TransR, PTransE)",
      "detailed_description": "KB2E is a comprehensive library for Knowledge Graph Embeddings (KGE), providing implementations of foundational models such as TransE, TransH, TransR, and PTransE for representation learning on graphs.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/thunlp/KB2E",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kge",
        "transe",
        "transh",
        "embedding"
      ],
      "id": 731
    },
    {
      "name": "OpenKE",
      "one_line_profile": "Open-source package for Knowledge Embedding",
      "detailed_description": "OpenKE is an open-source framework for knowledge embedding, supporting various models for training and evaluating embeddings of knowledge graphs. It is widely used for link prediction and triple classification tasks.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "link_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/thunlp/OpenKE",
      "help_website": [
        "http://openke.thunlp.org/"
      ],
      "license": null,
      "tags": [
        "knowledge-embedding",
        "pytorch",
        "knowledge-graph"
      ],
      "id": 732
    },
    {
      "name": "pyfactxx",
      "one_line_profile": "Python bindings for FaCT++ description logic reasoner",
      "detailed_description": "pyfactxx provides Python bindings for the FaCT++ description logic reasoner, enabling Python-based applications to perform logical reasoning and inference on ontologies.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "reasoning",
        "ontology_inference"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/tilde-lab/pyfactxx",
      "help_website": [],
      "license": null,
      "tags": [
        "reasoner",
        "description-logic",
        "fact++",
        "ontology"
      ],
      "id": 733
    },
    {
      "name": "cognee",
      "one_line_profile": "Graph-based memory and reasoning framework for AI agents",
      "detailed_description": "Cognee is a framework that provides deterministic memory and reasoning capabilities for AI agents using graph structures. It enables the creation of knowledge graphs from data to support reliable retrieval and inference.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_memory",
        "reasoning",
        "knowledge_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/topoteretes/cognee",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-memory",
        "knowledge-graph",
        "llm-agent",
        "reasoning"
      ],
      "id": 734
    },
    {
      "name": "TorchKGE",
      "one_line_profile": "Knowledge Graph embedding library in Python and PyTorch",
      "detailed_description": "TorchKGE is a Python library for knowledge graph embedding based on PyTorch. It provides efficient implementations of various KGE models and utilities for training and evaluation.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/torchkge-team/torchkge",
      "help_website": [
        "https://torchkge.readthedocs.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "pytorch",
        "kge",
        "embedding",
        "knowledge-graph"
      ],
      "id": 735
    },
    {
      "name": "TrustGraph",
      "one_line_profile": "Graph-based tool to eliminate AI hallucinations via knowledge structures",
      "detailed_description": "TrustGraph is a tool designed to construct and utilize knowledge graphs to ground AI agents, aiming to eliminate hallucinations by providing structured, verifiable evidence chains.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_construction",
        "evidence_reasoning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/trustgraph-ai/trustgraph",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination-reduction",
        "knowledge-graph",
        "ai-safety"
      ],
      "id": 736
    },
    {
      "name": "LibKGE",
      "one_line_profile": "Library for reproducible research in knowledge graph embeddings",
      "detailed_description": "LibKGE is a PyTorch-based library for training, evaluating, and hyperparameter optimizing knowledge graph embeddings. It emphasizes reproducibility and provides a flexible configuration system.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "hyperparameter_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/uma-pi1/kge",
      "help_website": [
        "https://github.com/uma-pi1/kge"
      ],
      "license": "MIT",
      "tags": [
        "kge",
        "reproducibility",
        "pytorch",
        "embedding"
      ],
      "id": 737
    },
    {
      "name": "SkillBridge",
      "one_line_profile": "Python to Cadence Virtuoso Skill interface for EDA automation",
      "detailed_description": "SkillBridge provides a seamless interface between Python and the Cadence Virtuoso Skill language, enabling the automation of electronic design automation (EDA) tasks and scientific modeling in circuit design.",
      "domains": [
        "Physics",
        "Engineering"
      ],
      "subtask_category": [
        "eda_automation",
        "circuit_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/unihd-cag/skillbridge",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "eda",
        "cadence-virtuoso",
        "automation",
        "circuit-design"
      ],
      "id": 738
    },
    {
      "name": "CadenceSKILL-Python",
      "one_line_profile": "IPC interface between Python and Cadence Virtuoso",
      "detailed_description": "This tool facilitates Inter-Process Communication (IPC) between Python and Cadence Virtuoso, allowing researchers and engineers to control EDA workflows and simulations from Python.",
      "domains": [
        "Physics",
        "Engineering"
      ],
      "subtask_category": [
        "eda_automation",
        "simulation_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/unnir/CadenceSKILL-Python",
      "help_website": [],
      "license": null,
      "tags": [
        "eda",
        "cadence",
        "ipc",
        "python-interface"
      ],
      "id": 739
    },
    {
      "name": "UStore",
      "one_line_profile": "Multi-modal database with NetworkX and Pandas interfaces",
      "detailed_description": "UStore is a high-performance multi-modal database that supports graph data structures. It provides interfaces for NetworkX and Pandas, making it suitable for scientific data analysis and graph processing.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "data_analysis"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/unum-cloud/UStore",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "database",
        "graph",
        "networkx",
        "multi-modal"
      ],
      "id": 740
    },
    {
      "name": "NebulaGraph",
      "one_line_profile": "Distributed, scalable open-source graph database",
      "detailed_description": "NebulaGraph is a distributed, scalable, and fast open-source graph database designed to handle super-large-scale graphs with billions of vertices and trillions of edges, suitable for scientific knowledge graph storage.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_storage",
        "graph_query"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/vesoft-inc/nebula",
      "help_website": [
        "https://docs.nebula-graph.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "graph-database",
        "distributed-system",
        "knowledge-graph"
      ],
      "id": 741
    },
    {
      "name": "Nebula Algorithm",
      "one_line_profile": "Graph algorithms on NebulaGraph using Spark GraphX",
      "detailed_description": "Nebula Algorithm is a Spark application based on GraphX that enables running state-of-the-art graph algorithms (e.g., PageRank, Louvain, Connected Components) on data stored in NebulaGraph.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_algorithm",
        "graph_analysis"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/vesoft-inc/nebula-algorithm",
      "help_website": [],
      "license": null,
      "tags": [
        "graph-algorithms",
        "spark",
        "graphx",
        "nebula-graph"
      ],
      "id": 742
    },
    {
      "name": "triplestore",
      "one_line_profile": "RDF triple management and query library for Go",
      "detailed_description": "A lightweight library to manage, query, and store RDF triples in Go, supporting the semantic web standard for knowledge graph data structures.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "rdf_storage",
        "querying"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/wallix/triplestore",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rdf",
        "triplestore",
        "semantic-web",
        "knowledge-graph"
      ],
      "id": 743
    },
    {
      "name": "NebulaGraph-NX",
      "one_line_profile": "NetworkX API adapter for NebulaGraph database",
      "detailed_description": "A library that allows users to manipulate and analyze graphs stored in NebulaGraph using the standard NetworkX API, facilitating scientific graph analysis.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_analysis",
        "data_manipulation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wey-gu/NebulaGraph-NX",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "networkx",
        "graph-analysis",
        "nebulagraph"
      ],
      "id": 744
    },
    {
      "name": "jupyter_nebulagraph",
      "one_line_profile": "Jupyter notebook extension for NebulaGraph queries and visualization",
      "detailed_description": "A tool enabling interactive execution of nGQL queries and graph visualization directly within Jupyter notebooks, supporting scientific data analysis workflows.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "visualization",
        "query",
        "interactive_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wey-gu/jupyter_nebulagraph",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "jupyter",
        "visualization",
        "nebulagraph",
        "interactive"
      ],
      "id": 745
    },
    {
      "name": "nebula-dgl",
      "one_line_profile": "Integration package for NebulaGraph and Deep Graph Library (DGL)",
      "detailed_description": "A library facilitating the use of graph data stored in NebulaGraph for training Graph Neural Networks (GNNs) using DGL, bridging storage and scientific modeling.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_neural_network",
        "data_loading",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wey-gu/nebula-dgl",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dgl",
        "gnn",
        "nebulagraph",
        "deep-learning"
      ],
      "id": 746
    },
    {
      "name": "nebulagraph-ai",
      "one_line_profile": "High-level API for graph algorithms and analytics on NebulaGraph",
      "detailed_description": "A Python library providing a high-level interface to execute graph algorithms and analytics on NebulaGraph, simplifying scientific graph computations.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_analytics",
        "algorithm_execution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wey-gu/nebulagraph-ai",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "graph-algorithms",
        "analytics",
        "nebulagraph"
      ],
      "id": 747
    },
    {
      "name": "Wikidata Query Blazegraph",
      "one_line_profile": "Blazegraph-based RDF graph database service used by Wikidata",
      "detailed_description": "The customized Blazegraph RDF database/triplestore used to power the Wikidata Query Service, enabling large-scale semantic knowledge graph querying.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "graph_database",
        "sparql_query"
      ],
      "application_level": "service",
      "primary_language": "Java",
      "repo_url": "https://github.com/wikimedia/wikidata-query-blazegraph",
      "help_website": [
        "https://query.wikidata.org/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "blazegraph",
        "sparql",
        "wikidata",
        "rdf"
      ],
      "id": 748
    },
    {
      "name": "Yuxi-Know",
      "one_line_profile": "Knowledge Graph Agent platform integrating LightRAG and Neo4j",
      "detailed_description": "A platform for building intelligent agents using Knowledge Graphs and RAG (Retrieval-Augmented Generation), integrating tools like Neo4j and LangChain for knowledge management.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "rag",
        "agent_construction",
        "knowledge_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/xerrors/Yuxi-Know",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "knowledge-graph",
        "agent",
        "neo4j"
      ],
      "id": 749
    },
    {
      "name": "NL2GQL",
      "one_line_profile": "Tool for converting natural language to Graph Query Language (GQL)",
      "detailed_description": "A utility leveraging LLMs to translate natural language questions into Graph Query Language (GQL) for NebulaGraph or Neo4j, facilitating knowledge graph querying.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "query_generation",
        "natural_language_interface"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhiqix/NL2GQL",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "text-to-sql",
        "gql",
        "nebulagraph"
      ],
      "id": 750
    },
    {
      "name": "MKGL",
      "one_line_profile": "Knowledge graph completion model based on a three-word language mastery approach",
      "detailed_description": "A solver for knowledge graph completion that implements a 'Mastery of a Three-Word Language' framework. It focuses on learning representations for entities and relations to predict missing links in knowledge graphs.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_completion",
        "link_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjukg/MKGL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "link-prediction",
        "representation-learning"
      ],
      "id": 751
    },
    {
      "name": "NATIVE",
      "one_line_profile": "Multi-modal knowledge graph completion model for unconstrained environments",
      "detailed_description": "An implementation of the NativE model for multi-modal knowledge graph completion (MKGC). It is designed to handle MKGC tasks 'in the wild', integrating visual and textual modalities to enhance link prediction accuracy.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_completion",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjukg/NATIVE",
      "help_website": [],
      "license": null,
      "tags": [
        "multimodal-knowledge-graph",
        "link-prediction",
        "sigir-2024"
      ],
      "id": 752
    },
    {
      "name": "RMPI",
      "one_line_profile": "Relational message passing solver for fully inductive knowledge graph completion",
      "detailed_description": "A graph neural network-based tool implementing Relational Message Passing for Inductive (RMPI) knowledge graph completion. It is specifically designed to handle inductive settings where the model must generalize to unseen entities during inference.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "inductive_reasoning",
        "knowledge_graph_completion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjukg/RMPI",
      "help_website": [],
      "license": null,
      "tags": [
        "inductive-learning",
        "graph-neural-networks",
        "icde-2023"
      ],
      "id": 753
    },
    {
      "name": "UniHR",
      "one_line_profile": "Hierarchical representation learning framework for unified knowledge graph link prediction",
      "detailed_description": "A solver implementing Hierarchical Representation Learning (UniHR) for knowledge graph link prediction. It aims to unify different aspects of KG representation to improve prediction performance.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "link_prediction",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjukg/UniHR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hierarchical-learning",
        "knowledge-graph",
        "aaai"
      ],
      "id": 754
    },
    {
      "name": "MKG_Analogy",
      "one_line_profile": "Multimodal analogical reasoning framework over knowledge graphs",
      "detailed_description": "A tool for performing analogical reasoning on multimodal knowledge graphs. It leverages multimodal data (images, text) associated with entities to solve analogy tasks within the graph structure.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "analogical_reasoning",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/MKG_Analogy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "analogical-reasoning",
        "multimodal-kg",
        "iclr-2023"
      ],
      "id": 755
    },
    {
      "name": "MKGformer",
      "one_line_profile": "Hybrid Transformer model for multimodal knowledge graph completion",
      "detailed_description": "A deep learning solver utilizing a hybrid Transformer architecture with multi-level fusion. It is designed for multimodal knowledge graph completion, effectively combining visual and textual information to predict missing relations.",
      "domains": [
        "G2",
        "G2-03"
      ],
      "subtask_category": [
        "knowledge_graph_completion",
        "multimodal_fusion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/MKGformer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "transformer",
        "multimodal-kg",
        "sigir-2022"
      ],
      "id": 756
    },
    {
      "name": "GRAPE",
      "one_line_profile": "High-performance graph representation learning library for biological and general graphs",
      "detailed_description": "A Rust/Python library optimized for graph representation learning, specifically designed to handle large-scale graphs efficiently. It is developed by a bioinformatics lab and is suitable for predictions and evaluations on biological networks (e.g., PPI) and other scientific graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_representation_learning",
        "link_prediction",
        "node_classification"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/AnacletoLAB/grape",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-neural-networks",
        "bioinformatics",
        "rust",
        "python",
        "embedding"
      ],
      "id": 757
    },
    {
      "name": "OpenHGNN",
      "one_line_profile": "Toolkit for Heterogeneous Graph Neural Networks based on DGL",
      "detailed_description": "An open-source toolkit built on DGL specifically for Heterogeneous Graph Neural Networks (HGNNs). It provides a unified interface for running various HGNN models, which are essential for modeling complex scientific entities (e.g., drugs, proteins, diseases) and their diverse relationships.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_neural_network",
        "heterogeneous_graph",
        "node_classification",
        "link_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BUPT-GAMMA/OpenHGNN",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hgnn",
        "dgl",
        "heterogeneous-graph",
        "toolkit"
      ],
      "id": 758
    },
    {
      "name": "tf_geometric",
      "one_line_profile": "Graph Neural Network library for TensorFlow",
      "detailed_description": "An efficient and user-friendly Graph Neural Network (GNN) library designed for TensorFlow 1.x and 2.x. It provides essential building blocks for graph deep learning, enabling the development of models for scientific graph data (e.g., molecular graphs).",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_neural_network",
        "deep_learning",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CrawlScript/tf_geometric",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "tensorflow",
        "gnn",
        "graph-neural-networks",
        "library"
      ],
      "id": 759
    },
    {
      "name": "STSGCN",
      "one_line_profile": "Spatial-Temporal Synchronous Graph Convolutional Networks for forecasting",
      "detailed_description": "A framework for spatial-temporal network data forecasting, specifically designed to capture localized spatial-temporal correlations in traffic and other network data.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "time_series_forecasting",
        "spatial_temporal_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Davidham3/STSGCN",
      "help_website": [],
      "license": null,
      "tags": [
        "stgcn",
        "traffic-forecasting",
        "spatial-temporal"
      ],
      "id": 760
    },
    {
      "name": "GraphVite",
      "one_line_profile": "High-performance graph embedding system",
      "detailed_description": "A general and high-performance graph embedding system that supports large-scale knowledge graph embedding and node embedding, optimized for speed and scalability on CPUs and GPUs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_embedding",
        "knowledge_graph_embedding"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/DeepGraphLearning/graphvite",
      "help_website": [
        "https://graphvite.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "graph-embedding",
        "high-performance",
        "kge"
      ],
      "id": 761
    },
    {
      "name": "PDE Dataset Generator",
      "one_line_profile": "Tool for generating PDE ground truth datasets",
      "detailed_description": "A utility tool for generating Partial Differential Equations (PDEs) ground truth datasets using solvers like ARCSim, FEniCS, and SU2, facilitating machine learning for physics simulations.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "data_generation",
        "simulation"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/DiffEqML/pde-dataset-generator",
      "help_website": [],
      "license": null,
      "tags": [
        "pde",
        "dataset-generation",
        "physics-simulation"
      ],
      "id": 762
    },
    {
      "name": "GraphGallery",
      "one_line_profile": "Benchmarking framework for Graph Neural Networks",
      "detailed_description": "A gallery and benchmarking framework for Graph Neural Networks (GNNs), providing unified interfaces for implementing and evaluating various GNN models on standard datasets.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "model_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/EdisonLeeeee/GraphGallery",
      "help_website": [
        "https://graphgallery.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "gnn",
        "benchmark",
        "framework"
      ],
      "id": 763
    },
    {
      "name": "GreatX",
      "one_line_profile": "Graph reliability toolbox based on PyTorch Geometric",
      "detailed_description": "A toolbox focused on graph reliability, including robustness, defense, and uncertainty estimation for Graph Neural Networks, built upon PyTorch Geometric.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "robustness_analysis",
        "defense_mechanism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EdisonLeeeee/GreatX",
      "help_website": [
        "https://greatx.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "graph-reliability",
        "adversarial-defense",
        "gnn"
      ],
      "id": 764
    },
    {
      "name": "STGCN-PyTorch",
      "one_line_profile": "PyTorch implementation of Spatio-Temporal Graph Convolutional Networks",
      "detailed_description": "A PyTorch implementation of the Spatio-Temporal Graph Convolutional Network (STGCN) for solving time-series prediction problems on graphs, such as traffic forecasting.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "time_series_forecasting",
        "spatial_temporal_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FelixOpolka/STGCN-PyTorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "stgcn",
        "pytorch",
        "traffic-forecasting"
      ],
      "id": 765
    },
    {
      "name": "Think-on-Graph (ToG)",
      "one_line_profile": "Deep and responsible reasoning of LLM on Knowledge Graph",
      "detailed_description": "A framework that enables Large Language Models (LLMs) to perform deep reasoning on Knowledge Graphs by iteratively exploring and reasoning over graph structures.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_graph_reasoning",
        "llm_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GasolSun36/ToG",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "knowledge-graph",
        "reasoning"
      ],
      "id": 766
    },
    {
      "name": "GraphSAINT",
      "one_line_profile": "Graph sampling based inductive learning method",
      "detailed_description": "A graph sampling-based inductive learning method that enables fast and accurate minibatch training for deep Graph Neural Networks on large graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "model_training",
        "graph_sampling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/GraphSAINT/GraphSAINT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gnn-training",
        "graph-sampling",
        "scalability"
      ],
      "id": 767
    },
    {
      "name": "Neural Fingerprint",
      "one_line_profile": "Convolutional networks for molecular graphs",
      "detailed_description": "A library for creating differentiable fingerprints for molecules using graph convolutional neural networks, enabling prediction of molecular properties.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "molecular_property_prediction",
        "fingerprint_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HIPS/neural-fingerprint",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cheminformatics",
        "molecular-graph",
        "fingerprint"
      ],
      "id": 768
    },
    {
      "name": "3DInfomax",
      "one_line_profile": "Self-supervised learning on molecules using 3D geometry",
      "detailed_description": "A framework for pre-training Graph Neural Networks on molecular graphs by maximizing mutual information between 2D and 3D representations, improving molecular property prediction.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "molecular_representation_learning",
        "pretraining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HannesStark/3DInfomax",
      "help_website": [],
      "license": null,
      "tags": [
        "molecular-geometry",
        "self-supervised-learning",
        "gnn"
      ],
      "id": 769
    },
    {
      "name": "HGCN",
      "one_line_profile": "Hyperbolic Graph Convolutional Networks library",
      "detailed_description": "A PyTorch implementation of Hyperbolic Graph Convolutional Networks (HGCN), designed to learn embeddings for scale-free or hierarchical graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_embedding",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HazyResearch/hgcn",
      "help_website": [],
      "license": null,
      "tags": [
        "hyperbolic-geometry",
        "gnn",
        "graph-embedding"
      ],
      "id": 770
    },
    {
      "name": "BrainGB",
      "one_line_profile": "Benchmark for Geometric Deep Learning in Brain Network Analysis",
      "detailed_description": "A benchmark and toolbox for applying Graph Neural Networks (GNNs) to brain network analysis, facilitating the study of brain connectivity and disease prediction.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "brain_network_analysis",
        "medical_imaging_analysis"
      ],
      "application_level": "platform",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/HennyJie/BrainGB",
      "help_website": [
        "https://braingb.us"
      ],
      "license": "MIT",
      "tags": [
        "brain-network",
        "neuroscience",
        "geometric-deep-learning"
      ],
      "id": 771
    },
    {
      "name": "EvolveGCN",
      "one_line_profile": "Evolving Graph Convolutional Networks for dynamic graph representation learning",
      "detailed_description": "An implementation of EvolveGCN, a method that adapts the graph convolutional network (GCN) model along the temporal dimension to capture the dynamics of evolving graphs. It is useful for modeling dynamic systems in scientific networks.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "dynamic_graph_embedding",
        "temporal_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/IBM/EvolveGCN",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dynamic-graphs",
        "gnn",
        "temporal-networks"
      ],
      "id": 772
    },
    {
      "name": "LNN",
      "one_line_profile": "Neuro-symbolic framework for weighted real-value logic",
      "detailed_description": "Logical Neural Networks (LNN) is a framework that combines neural networks with symbolic logic, allowing for sound and complete weighted real-value logic reasoning. It is applicable to knowledge graph reasoning and scientific inference.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "neuro_symbolic_reasoning",
        "logic_inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IBM/LNN",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "neuro-symbolic",
        "logic",
        "reasoning"
      ],
      "id": 773
    },
    {
      "name": "torchlogic",
      "one_line_profile": "PyTorch framework for Neuro-Symbolic AI and Neural Reasoning Networks",
      "detailed_description": "A framework built on PyTorch for developing Neuro-Symbolic AI systems, specifically implementing Neural Reasoning Networks. It facilitates the integration of logical reasoning into deep learning models.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "neuro_symbolic_reasoning",
        "model_development"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IBM/torchlogic",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pytorch",
        "neuro-symbolic",
        "reasoning"
      ],
      "id": 774
    },
    {
      "name": "KagNet",
      "one_line_profile": "Knowledge-Aware Graph Networks for commonsense reasoning",
      "detailed_description": "An implementation of KagNet, a model that performs commonsense reasoning by grounding questions and answers in a knowledge graph and modeling the relational paths using GNNs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "commonsense_reasoning",
        "knowledge_graph_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/INK-USC/KagNet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "reasoning",
        "knowledge-graph",
        "gnn"
      ],
      "id": 775
    },
    {
      "name": "RE-Net",
      "one_line_profile": "Recurrent Event Network for temporal knowledge graph reasoning",
      "detailed_description": "A model for autoregressive structure inference over temporal knowledge graphs, capable of predicting future events based on historical graph structures.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "temporal_reasoning",
        "structure_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/INK-USC/RE-Net",
      "help_website": [],
      "license": null,
      "tags": [
        "temporal-kg",
        "event-prediction",
        "gnn"
      ],
      "id": 776
    },
    {
      "name": "KGEmbedding-OTE",
      "one_line_profile": "Orthogonal Relation Transforms for Knowledge Graph Embedding",
      "detailed_description": "An implementation of the OTE (Orthogonal Relation Transforms) method for knowledge graph embedding, which models relations as orthogonal transforms to better capture symmetry, antisymmetry, and inversion patterns.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "link_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JD-AI-Research-Silicon-Valley/KGEmbedding-OTE",
      "help_website": [],
      "license": null,
      "tags": [
        "kge",
        "embedding",
        "relation-modeling"
      ],
      "id": 777
    },
    {
      "name": "PPT",
      "one_line_profile": "Prompt-based Pre-trained Language Model for Temporal KG Completion",
      "detailed_description": "A framework utilizing pre-trained language models with prompts to perform completion tasks on temporal knowledge graphs, enhancing reasoning capabilities over time-evolving data.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "temporal_kg_completion",
        "prompt_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JaySaligia/PPT",
      "help_website": [],
      "license": null,
      "tags": [
        "temporal-kg",
        "plm",
        "prompting"
      ],
      "id": 778
    },
    {
      "name": "HAN",
      "one_line_profile": "Heterogeneous Graph Neural Network",
      "detailed_description": "Implementation of the Heterogeneous Graph Attention Network (HAN), designed to handle heterogeneous graphs with multiple types of nodes and edges, widely used in analyzing complex scientific networks.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "heterogeneous_graph_learning",
        "node_classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Jhy1993/HAN",
      "help_website": [],
      "license": null,
      "tags": [
        "heterogeneous-graph",
        "attention",
        "gnn"
      ],
      "id": 779
    },
    {
      "name": "Representation-Learning-on-Heterogeneous-Graph",
      "one_line_profile": "Collection of representation learning methods for heterogeneous graphs",
      "detailed_description": "A repository containing implementations and benchmarks for various representation learning methods on heterogeneous graphs, serving as a resource for comparative analysis in graph research.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_representation_learning",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": null,
      "repo_url": "https://github.com/Jhy1993/Representation-Learning-on-Heterogeneous-Graph",
      "help_website": [],
      "license": null,
      "tags": [
        "heterogeneous-graph",
        "embedding",
        "benchmark"
      ],
      "id": 780
    },
    {
      "name": "TeMP",
      "one_line_profile": "Temporal Message Passing Network for Temporal KG Completion",
      "detailed_description": "A temporal message passing network designed for completing missing links in temporal knowledge graphs by effectively aggregating structural and temporal information.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "temporal_kg_completion",
        "link_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JiapengWu/TeMP",
      "help_website": [],
      "license": null,
      "tags": [
        "temporal-kg",
        "message-passing",
        "gnn"
      ],
      "id": 781
    },
    {
      "name": "FAAN",
      "one_line_profile": "Adaptive Attentional Network for Few-Shot KG Completion",
      "detailed_description": "Code for the Adaptive Attentional Network, a method for few-shot knowledge graph completion that adapts to new relations with limited examples.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "few_shot_learning",
        "kg_completion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JiaweiSheng/FAAN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "few-shot",
        "knowledge-graph",
        "attention"
      ],
      "id": 782
    },
    {
      "name": "P-GNN",
      "one_line_profile": "Position-aware Graph Neural Networks",
      "detailed_description": "Implementation of Position-aware Graph Neural Networks (P-GNNs), which capture the position of nodes with respect to anchor sets, useful for tasks requiring structural position awareness in graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_representation_learning",
        "position_aware_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JiaxuanYou/P-GNN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gnn",
        "position-aware",
        "embedding"
      ],
      "id": 783
    },
    {
      "name": "JOIE",
      "one_line_profile": "Jointly Embedding Instances and Ontological Concepts",
      "detailed_description": "Code for the JOIE model, which learns universal representations of knowledge bases by jointly embedding instances and ontological concepts, facilitating hierarchy-aware knowledge reasoning.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_representation_learning",
        "ontology_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JunhengH/joie-kdd19",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kge",
        "ontology",
        "embedding"
      ],
      "id": 784
    },
    {
      "name": "pytorch-direct_dgl",
      "one_line_profile": "GPU-Oriented Data Communication Architecture for Large GNN Training",
      "detailed_description": "A system optimization tool for training large-scale Graph Convolutional Networks (GCNs) using a GPU-oriented data communication architecture, enabling efficient processing of massive scientific graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "gnn_training_optimization",
        "large_scale_graph_learning"
      ],
      "application_level": "library",
      "primary_language": null,
      "repo_url": "https://github.com/K-Wu/pytorch-direct_dgl",
      "help_website": [],
      "license": null,
      "tags": [
        "gnn",
        "hpc",
        "gpu-optimization"
      ],
      "id": 785
    },
    {
      "name": "AIToolbox",
      "one_line_profile": "AI modules toolbox written in Swift",
      "detailed_description": "A comprehensive toolbox of AI algorithms implemented in Swift, including graphs, neural networks, SVMs, and genetic algorithms, suitable for scientific data analysis and modeling on Swift-supported platforms.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "data_analysis",
        "machine_learning"
      ],
      "application_level": "library",
      "primary_language": "Swift",
      "repo_url": "https://github.com/KevinCoble/AIToolbox",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "swift",
        "machine-learning",
        "graph-algorithms"
      ],
      "id": 786
    },
    {
      "name": "Neural-Temporal-Walks",
      "one_line_profile": "Motif-Aware Representation Learning on Continuous-Time Dynamic Graphs",
      "detailed_description": "Implementation of Neural Temporal Walks, a method for learning representations on continuous-time dynamic graphs by leveraging temporal motifs, useful for analyzing dynamic scientific networks.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "dynamic_graph_learning",
        "temporal_motif_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/KimMeen/Neural-Temporal-Walks",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dynamic-graphs",
        "temporal-walks",
        "representation-learning"
      ],
      "id": 787
    },
    {
      "name": "tensorlogic",
      "one_line_profile": "Unified programming language for AI combining neural and symbolic reasoning",
      "detailed_description": "A Python implementation of Tensor Logic, a framework that unifies neural and symbolic reasoning through tensor equations, enabling the development of neuro-symbolic AI models.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "neuro_symbolic_reasoning",
        "tensor_logic"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Kocoro-lab/tensorlogic",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "neuro-symbolic",
        "logic",
        "tensor"
      ],
      "id": 788
    },
    {
      "name": "PeSTo",
      "one_line_profile": "Geometric deep learning for protein binding interface prediction",
      "detailed_description": "A geometric deep learning method designed to predict protein binding interfaces directly from protein structures, aiding in the understanding of protein interactions.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "protein_structure_analysis",
        "binding_site_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/LBM-EPFL/PeSTo",
      "help_website": [
        "https://pesto.epfl.ch/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "protein-binding",
        "geometric-deep-learning",
        "structural-biology"
      ],
      "id": 789
    },
    {
      "name": "DRL-GNN-Routing",
      "one_line_profile": "Residual edge-graph attention neural network for routing problems",
      "detailed_description": "A Deep Reinforcement Learning and Graph Neural Network based solver for routing problems (e.g., TSP, VRP), applying scientific optimization techniques to combinatorial problems.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "combinatorial_optimization",
        "routing_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lei-Kun/DRL-and-graph-neural-network-for-routing-problems",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "drl",
        "gnn",
        "optimization"
      ],
      "id": 790
    },
    {
      "name": "AGCRN",
      "one_line_profile": "Adaptive Graph Convolutional Recurrent Network",
      "detailed_description": "Implementation of AGCRN, a model that captures node-specific patterns and infers inter-dependencies in multivariate time-series data through adaptive graph convolution, applicable to scientific structure inference and forecasting.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "spatio_temporal_modeling",
        "structure_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LeiBAI/AGCRN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "time-series",
        "gnn",
        "adaptive-graph"
      ],
      "id": 791
    },
    {
      "name": "MTAD-GAT",
      "one_line_profile": "Graph Attention Networks for multivariate time-series anomaly detection",
      "detailed_description": "A PyTorch implementation of MTAD-GAT, a model that uses graph attention networks to capture feature and temporal correlations for detecting anomalies in multivariate time-series data, applicable to industrial sensor data analysis.",
      "domains": [
        "G2-04",
        "Scientific_Data_Analysis"
      ],
      "subtask_category": [
        "anomaly_detection",
        "time_series_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ML4ITS/mtad-gat-pytorch",
      "help_website": [
        "https://arxiv.org/abs/2009.02040"
      ],
      "license": "MIT",
      "tags": [
        "anomaly-detection",
        "time-series",
        "gat"
      ],
      "id": 792
    },
    {
      "name": "CommonsenseERL",
      "one_line_profile": "Event representation learning enhanced with external commonsense knowledge",
      "detailed_description": "Code for learning event representations by integrating external commonsense knowledge graphs. It improves event prediction and reasoning tasks by leveraging structured knowledge.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "event_representation",
        "commonsense_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MagiaSN/CommonsenseERL_EMNLP_2019",
      "help_website": [],
      "license": null,
      "tags": [
        "event-reasoning",
        "commonsense-knowledge",
        "representation-learning"
      ],
      "id": 793
    },
    {
      "name": "R-GCN (RelationPrediction)",
      "one_line_profile": "Relational Graph Convolutional Networks for link prediction",
      "detailed_description": "Implementation of Relational Graph Convolutional Networks (R-GCNs), a fundamental GNN architecture specifically designed for handling multi-relational data in knowledge graphs for tasks like link prediction and entity classification.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "link_prediction",
        "relational_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MichSchli/RelationPrediction",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "r-gcn",
        "link-prediction",
        "gnn"
      ],
      "id": 794
    },
    {
      "name": "Relation_Extraction_KBE",
      "one_line_profile": "C++ implementation of Knowledge Base Embedding models",
      "detailed_description": "A C++ codebase for knowledge base embedding and relation extraction. It provides efficient implementations of embedding algorithms for processing large-scale knowledge graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/Mrlyk423/Relation_Extraction",
      "help_website": [],
      "license": null,
      "tags": [
        "kge",
        "cpp",
        "relation-extraction"
      ],
      "id": 795
    },
    {
      "name": "KGen",
      "one_line_profile": "Fortran kernel generator for extracting and optimizing scientific code",
      "detailed_description": "A tool developed by NCAR to extract kernels from large Fortran applications (common in climate and weather modeling) into standalone, compilable units for optimization, testing, and verification.",
      "domains": [
        "Scientific_Computing",
        "HPC"
      ],
      "subtask_category": [
        "code_generation",
        "performance_optimization"
      ],
      "application_level": "tool",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/NCAR/KGen",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "fortran",
        "hpc",
        "climate-modeling"
      ],
      "id": 796
    },
    {
      "name": "BGRL_Pytorch",
      "one_line_profile": "Bootstrapped Graph Latents for self-supervised graph representation learning",
      "detailed_description": "PyTorch implementation of BGRL (Bootstrapped Graph Latents), a self-supervised learning method for graphs that learns representations without requiring negative samples, suitable for large-scale graph analysis.",
      "domains": [
        "G2-04"
      ],
      "subtask_category": [
        "graph_representation_learning",
        "self_supervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Namkyeong/BGRL_Pytorch",
      "help_website": [],
      "license": null,
      "tags": [
        "self-supervised",
        "graph-learning",
        "contrastive-learning"
      ],
      "id": 797
    },
    {
      "name": "GLBench",
      "one_line_profile": "Comprehensive benchmark for evaluating Large Language Models on graph tasks",
      "detailed_description": "A benchmark suite designed to evaluate the capabilities of Large Language Models (LLMs) in solving various graph-related tasks, facilitating the assessment of LLM-Graph integration strategies.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "llm_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/NineAbyss/GLBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "llm",
        "graph-reasoning"
      ],
      "id": 798
    },
    {
      "name": "CLEVR-Graph",
      "one_line_profile": "Dataset and generator for graph-based reasoning tasks",
      "detailed_description": "A dataset and generation tool for graph-based reasoning, derived from the CLEVR dataset. It provides structured graph representations of scenes to test the reasoning capabilities of graph neural networks.",
      "domains": [
        "G2-04"
      ],
      "subtask_category": [
        "dataset_generation",
        "graph_reasoning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Octavian-ai/clevr-graph",
      "help_website": [],
      "license": "Unlicense",
      "tags": [
        "dataset",
        "reasoning",
        "synthetic-data"
      ],
      "id": 799
    },
    {
      "name": "OpenSPG-KAG",
      "one_line_profile": "Logical form-guided reasoning and retrieval framework for knowledge bases",
      "detailed_description": "A framework combining OpenSPG engine and LLMs to build logical reasoning and factual Q&A solutions. It addresses limitations of vector similarity by using logical forms to guide retrieval and reasoning on professional domain knowledge bases.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "logical_reasoning",
        "knowledge_retrieval",
        "rag"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenSPG/KAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "logical-reasoning",
        "llm-agent"
      ],
      "id": 800
    },
    {
      "name": "MoSE",
      "one_line_profile": "Modality split and ensemble for multimodal knowledge graph completion",
      "detailed_description": "Implementation of the MoSE framework for multimodal knowledge graph completion. It uses modality splitting and ensemble techniques to better integrate visual and textual information for link prediction.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_graph_completion",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OreOZhao/MoSE4MKGC",
      "help_website": [],
      "license": null,
      "tags": [
        "multimodal",
        "ensemble-learning",
        "kge"
      ],
      "id": 801
    },
    {
      "name": "GAT",
      "one_line_profile": "Original implementation of Graph Attention Networks",
      "detailed_description": "The reference implementation of Graph Attention Networks (GAT), a pioneering GNN architecture that uses attention mechanisms to weigh the importance of neighboring nodes, widely used in scientific graph modeling.",
      "domains": [
        "G2-04"
      ],
      "subtask_category": [
        "graph_modeling",
        "node_classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PetarV-/GAT",
      "help_website": [
        "https://arxiv.org/abs/1710.10903"
      ],
      "license": "MIT",
      "tags": [
        "gnn",
        "attention-mechanism",
        "deep-learning"
      ],
      "id": 802
    },
    {
      "name": "OPTransE",
      "one_line_profile": "Ordered relation paths for knowledge graph completion",
      "detailed_description": "Implementation of OPTransE, a knowledge graph embedding model that incorporates ordered relation paths to capture long-distance dependencies and composite relations for improved link prediction.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_graph_completion",
        "path_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/Peter7Yao/OPTransE",
      "help_website": [],
      "license": null,
      "tags": [
        "kge",
        "path-encoding",
        "cpp"
      ],
      "id": 803
    },
    {
      "name": "Edgeformers",
      "one_line_profile": "Graph-empowered transformers for textual-edge networks",
      "detailed_description": "A framework that adapts Transformer architectures to handle textual-edge networks, integrating graph structural information with textual semantics for representation learning on edges.",
      "domains": [
        "G2-04",
        "NLP"
      ],
      "subtask_category": [
        "representation_learning",
        "text_graph_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PeterGriffinJin/Edgeformers",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "transformer",
        "graph-learning",
        "text-mining"
      ],
      "id": 804
    },
    {
      "name": "ProcrustEs-KGE",
      "one_line_profile": "Closed-form orthogonal Procrustes analysis for efficient KGE",
      "detailed_description": "Implementation of a highly efficient knowledge graph embedding method using closed-form Orthogonal Procrustes Analysis. It offers significant speedups in training compared to gradient-based methods.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Pzoom522/ProcrustEs-KGE",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "kge",
        "efficiency",
        "procrustes-analysis"
      ],
      "id": 805
    },
    {
      "name": "Two-timescale-DGL-DDPG",
      "one_line_profile": "DRL-based resource allocation for MEC systems",
      "detailed_description": "A Deep Reinforcement Learning (DDPG) approach for joint service caching, communication, and computing resource allocation in Mobile Edge Computing (MEC) systems, utilizing graph-based state representation.",
      "domains": [
        "G2-04",
        "Telecommunications"
      ],
      "subtask_category": [
        "resource_allocation",
        "optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Qqianliu/Two-timescale-DGL-DDPG",
      "help_website": [],
      "license": null,
      "tags": [
        "drl",
        "mec",
        "resource-optimization"
      ],
      "id": 806
    },
    {
      "name": "KeAP",
      "one_line_profile": "Knowledge-enhanced protein representation learning",
      "detailed_description": "A framework for protein representation learning that integrates knowledge from primary structure reasoning. It enhances protein embeddings by leveraging biological knowledge graphs and sequence information.",
      "domains": [
        "G2",
        "G2-04",
        "Bioinformatics"
      ],
      "subtask_category": [
        "protein_representation",
        "bio_knowledge_graph"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RL4M/KeAP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-folding",
        "representation-learning",
        "bio-kg"
      ],
      "id": 807
    },
    {
      "name": "Graph-Constrained-Reasoning",
      "one_line_profile": "Faithful reasoning on knowledge graphs with LLMs",
      "detailed_description": "A framework for constraining Large Language Model reasoning using knowledge graphs to ensure faithfulness and reduce hallucinations. It forces the LLM to follow valid paths in the KG during inference.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_reasoning",
        "llm_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RManLuo/graph-constrained-reasoning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "hallucination-reduction",
        "graph-reasoning"
      ],
      "id": 808
    },
    {
      "name": "Reasoning-on-Graphs (RoG)",
      "one_line_profile": "Faithful and interpretable LLM reasoning on graphs",
      "detailed_description": "Implementation of the Reasoning on Graphs (RoG) framework, which synergizes LLMs and KGs for faithful and interpretable reasoning. It generates reasoning paths on KGs to answer questions.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_reasoning",
        "interpretable_ai"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RManLuo/reasoning-on-graphs",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "interpretability",
        "qa"
      ],
      "id": 809
    },
    {
      "name": "GNN-Explainer",
      "one_line_profile": "Model-agnostic explainer for Graph Neural Networks",
      "detailed_description": "A tool for explaining the predictions of any Graph Neural Network. It identifies a compact subgraph and a small subset of node features that play a crucial role in the GNN's prediction.",
      "domains": [
        "G2-04"
      ],
      "subtask_category": [
        "model_interpretability",
        "explainable_ai"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RexYing/gnn-model-explainer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "xai",
        "gnn",
        "interpretability"
      ],
      "id": 810
    },
    {
      "name": "GHE-LPC",
      "one_line_profile": "Distantly supervised relation extraction with hierarchy embeddings",
      "detailed_description": "Code for relation extraction using Global Hierarchy Embeddings and Local Probability Constraints. It improves distantly supervised relation extraction by incorporating hierarchical information of relations.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "relation_extraction",
        "distant_supervision"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/RidongHan/GHE-LPC",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "relation-extraction",
        "hierarchy",
        "nlp"
      ],
      "id": 811
    },
    {
      "name": "DGN",
      "one_line_profile": "Directional Graph Networks implementation",
      "detailed_description": "Implementation of Directional Graph Networks (DGN), which incorporate directional vector fields into GNNs to better model physical or geometric graphs where directionality is critical.",
      "domains": [
        "G2-04",
        "Physics_Informed_ML"
      ],
      "subtask_category": [
        "graph_modeling",
        "geometric_deep_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Saro00/DGN",
      "help_website": [],
      "license": null,
      "tags": [
        "directional-graphs",
        "physics-aware",
        "gnn"
      ],
      "id": 812
    },
    {
      "name": "PyG-Signed-Directed",
      "one_line_profile": "Signed and directed graph neural network extension for PyTorch Geometric",
      "detailed_description": "An extension library for PyTorch Geometric specifically designed for signed and directed networks. It provides data loaders, models, and utilities for analyzing graphs with positive/negative links and directionality.",
      "domains": [
        "G2-04"
      ],
      "subtask_category": [
        "graph_analysis",
        "signed_networks"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SherylHYX/pytorch_geometric_signed_directed",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pyg",
        "signed-graphs",
        "directed-graphs"
      ],
      "id": 813
    },
    {
      "name": "Jumping-Knowledge-Networks",
      "one_line_profile": "Representation learning on graphs with Jumping Knowledge Networks",
      "detailed_description": "Implementation of Jumping Knowledge (JK) Networks, a GNN architecture that adaptively aggregates information from different neighborhood ranges for each node, improving representation learning on graphs with varying structures.",
      "domains": [
        "G2-04"
      ],
      "subtask_category": [
        "graph_representation_learning",
        "node_classification"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ShinKyuY/Representation_Learning_on_Graphs_with_Jumping_Knowledge_Networks",
      "help_website": [],
      "license": null,
      "tags": [
        "gnn",
        "representation-learning",
        "jk-net"
      ],
      "id": 814
    },
    {
      "name": "CogDL",
      "one_line_profile": "A comprehensive library for graph deep learning",
      "detailed_description": "CogDL is a graph deep learning toolkit that allows researchers and developers to easily train and evaluate GNN models. It covers tasks like node classification, link prediction, and graph classification.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_deep_learning",
        "embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/THUDM/CogDL",
      "help_website": [
        "http://cogdl.ai/"
      ],
      "license": "MIT",
      "tags": [
        "gnn",
        "graph-neural-networks",
        "deep-learning",
        "embedding"
      ],
      "id": 815
    },
    {
      "name": "tsl",
      "one_line_profile": "A PyTorch library for processing spatiotemporal data",
      "detailed_description": "tsl (Torch Spatiotemporal) is a library designed to accelerate research in spatiotemporal data processing, with a focus on Graph Neural Networks for tasks like traffic forecasting and weather prediction.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "spatiotemporal_modeling",
        "graph_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TorchSpatiotemporal/tsl",
      "help_website": [
        "https://torch-spatiotemporal.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "spatiotemporal",
        "pytorch",
        "gnn",
        "time-series"
      ],
      "id": 816
    },
    {
      "name": "graphein",
      "one_line_profile": "Protein graph library for converting protein structures into graphs",
      "detailed_description": "Graphein is a Python library that provides functionality for constructing graph representations of biomolecules (like proteins) from PDB files, facilitating the use of GNNs in structural biology.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_construction",
        "protein_structure_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/a-r-j/graphein",
      "help_website": [
        "https://graphein.ai"
      ],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "protein-structure",
        "graph-construction",
        "molecular-graphs"
      ],
      "id": 817
    },
    {
      "name": "pyHGT",
      "one_line_profile": "Heterogeneous Graph Transformer implementation based on PyTorch Geometric",
      "detailed_description": "A PyTorch implementation of the Heterogeneous Graph Transformer (HGT) model, designed to handle heterogeneous information networks (HINs) for tasks like node classification and link prediction in scientific knowledge graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_embedding",
        "node_classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/acbull/pyHGT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gnn",
        "heterogeneous-graph",
        "transformer"
      ],
      "id": 818
    },
    {
      "name": "kgeo",
      "one_line_profile": "Analytic Kerr raytracing library for black hole physics",
      "detailed_description": "A simple Python library for analytic raytracing in the Kerr metric, used for calculating geodesics and visualizing light paths around rotating black holes in astrophysics simulations.",
      "domains": [
        "Physics",
        "Astrophysics"
      ],
      "subtask_category": [
        "simulation",
        "raytracing"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/achael/kgeo",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "physics",
        "black-hole",
        "general-relativity"
      ],
      "id": 819
    },
    {
      "name": "Graph-Learn",
      "one_line_profile": "Industrial-scale Graph Neural Network framework",
      "detailed_description": "An industrial graph neural network framework designed for large-scale graph training and inference, supporting distributed processing and integration with TensorFlow and PyTorch for complex network analysis.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_learning",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/alibaba/graph-learn",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gnn",
        "distributed-systems",
        "deep-learning"
      ],
      "id": 820
    },
    {
      "name": "libgrape-lite",
      "one_line_profile": "Parallel graph processing library based on GRAPE",
      "detailed_description": "A C++ library for parallel graph processing, implementing the GRAPE model to handle large-scale graph analytics and algorithms efficiently.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_processing",
        "analytics"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/alibaba/libgrape-lite",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "parallel-computing",
        "graph-processing",
        "c++"
      ],
      "id": 821
    },
    {
      "name": "kged",
      "one_line_profile": "Tool for Knowledge Graph Error Detection",
      "detailed_description": "A Python tool designed to detect errors and inconsistencies within knowledge graphs, serving as a quality control utility for KG maintenance.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "quality_control",
        "error_detection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aolimelo/kged",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "quality-control",
        "cleaning"
      ],
      "id": 822
    },
    {
      "name": "DySAT",
      "one_line_profile": "Dynamic Graph Representation Learning with Self-Attention",
      "detailed_description": "Implementation of DySAT (Dynamic Self-Attention Network), a model for learning node representations on dynamic graphs where structure and features evolve over time.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "dynamic_graph_embedding",
        "link_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aravindsankar28/DySAT",
      "help_website": [],
      "license": null,
      "tags": [
        "dynamic-graph",
        "self-attention",
        "representation-learning"
      ],
      "id": 823
    },
    {
      "name": "DGL-LifeSci",
      "one_line_profile": "GNN library for chemistry and biology",
      "detailed_description": "A Python package based on DGL specifically designed for applying graph neural networks to tasks in chemistry and biology, such as molecular property prediction and drug discovery.",
      "domains": [
        "G2",
        "G2-04",
        "Chemistry",
        "Biology"
      ],
      "subtask_category": [
        "molecular_modeling",
        "property_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/awslabs/dgl-lifesci",
      "help_website": [
        "https://lifesci.dgl.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "cheminformatics",
        "bioinformatics",
        "gnn"
      ],
      "id": 824
    },
    {
      "name": "RGAT",
      "one_line_profile": "Relational Graph Attention Networks implementation",
      "detailed_description": "TensorFlow implementation of Relational Graph Attention Networks (RGAT), used for reasoning over knowledge graphs by incorporating relation-specific attention mechanisms.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_embedding",
        "reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/babylonhealth/rgat",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gnn",
        "attention",
        "tensorflow"
      ],
      "id": 825
    },
    {
      "name": "APPNP",
      "one_line_profile": "Predict then Propagate GNN implementation",
      "detailed_description": "A PyTorch implementation of the APPNP (Approximate Personalized Propagation of Neural Predictions) model, combining GNNs with personalized PageRank for node classification.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "node_classification",
        "graph_propagation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/benedekrozemberczki/APPNP",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "gnn",
        "pagerank",
        "pytorch"
      ],
      "id": 826
    },
    {
      "name": "CapsGNN",
      "one_line_profile": "Capsule Graph Neural Network implementation",
      "detailed_description": "A PyTorch implementation of Capsule Graph Neural Networks (CapsGNN), applying capsule network concepts to graph structured data for classification tasks.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_classification",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/benedekrozemberczki/CapsGNN",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "capsule-networks",
        "gnn",
        "pytorch"
      ],
      "id": 827
    },
    {
      "name": "ClusterGCN",
      "one_line_profile": "Efficient GCN training algorithm implementation",
      "detailed_description": "A PyTorch implementation of Cluster-GCN, an algorithm designed for efficient training of deep and large graph convolutional networks via graph clustering.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_training",
        "node_classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/benedekrozemberczki/ClusterGCN",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "scalable-gnn",
        "clustering",
        "pytorch"
      ],
      "id": 828
    },
    {
      "name": "GraphWaveletNeuralNetwork",
      "one_line_profile": "Graph Wavelet Neural Network implementation",
      "detailed_description": "A PyTorch implementation of Graph Wavelet Neural Networks (GWNN), utilizing graph wavelets for efficient spectral graph convolution.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "spectral_gnn",
        "node_classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/benedekrozemberczki/GraphWaveletNeuralNetwork",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "wavelets",
        "gnn",
        "spectral-methods"
      ],
      "id": 829
    },
    {
      "name": "MixHop-and-N-GCN",
      "one_line_profile": "MixHop GNN architecture implementation",
      "detailed_description": "Implementation of MixHop, a graph convolutional architecture that mixes powers of the adjacency matrix to capture higher-order neighborhood information.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_convolution",
        "node_classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/benedekrozemberczki/MixHop-and-N-GCN",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "gnn",
        "higher-order",
        "pytorch"
      ],
      "id": 830
    },
    {
      "name": "SimGNN",
      "one_line_profile": "Fast Graph Similarity Computation with GNNs",
      "detailed_description": "A PyTorch implementation of SimGNN, a neural network approach for efficient graph similarity computation and matching.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_similarity",
        "graph_matching"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/benedekrozemberczki/SimGNN",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "graph-similarity",
        "gnn",
        "matching"
      ],
      "id": 831
    },
    {
      "name": "PyTorch Geometric Temporal",
      "one_line_profile": "Spatiotemporal Signal Processing with GNNs",
      "detailed_description": "A temporal extension library for PyTorch Geometric, providing methods for spatiotemporal signal processing and dynamic graph representation learning.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "spatiotemporal_analysis",
        "dynamic_graph_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/benedekrozemberczki/pytorch_geometric_temporal",
      "help_website": [
        "https://pytorch-geometric-temporal.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "temporal-gnn",
        "spatiotemporal",
        "pytorch"
      ],
      "id": 832
    },
    {
      "name": "Emgraph",
      "one_line_profile": "Library for Knowledge Graph Representation Learning",
      "detailed_description": "A Python library for knowledge graph embedding and representation learning, offering implementations of standard KGE models.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_embedding",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bi-graph/Emgraph",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "kge",
        "embedding",
        "python"
      ],
      "id": 833
    },
    {
      "name": "pytorch-graphsage",
      "one_line_profile": "PyTorch implementation of GraphSAGE",
      "detailed_description": "A PyTorch implementation of the GraphSAGE algorithm for inductive representation learning on large graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "inductive_learning",
        "graph_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bkj/pytorch-graphsage",
      "help_website": [],
      "license": null,
      "tags": [
        "graphsage",
        "inductive",
        "pytorch"
      ],
      "id": 834
    },
    {
      "name": "graph_attention_pool",
      "one_line_profile": "Graph Attention Pooling implementation",
      "detailed_description": "Implementation of attention-based pooling mechanisms for Graph Neural Networks, enabling hierarchical representation learning.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_pooling",
        "attention"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/bknyaz/graph_attention_pool",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "pooling",
        "attention",
        "gnn"
      ],
      "id": 835
    },
    {
      "name": "graph-cnn.pytorch",
      "one_line_profile": "Graph CNN implementation in PyTorch",
      "detailed_description": "A PyTorch implementation of Graph Convolutional Neural Networks, providing a baseline solver for graph classification tasks.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_classification",
        "convolution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bmsookim/graph-cnn.pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gcn",
        "pytorch",
        "classification"
      ],
      "id": 836
    },
    {
      "name": "city2graph",
      "one_line_profile": "Tool to transform geospatial relations into graph representations for GNNs",
      "detailed_description": "A Python tool designed to transform geospatial road network data into graph representations suitable for spatial network analysis and Graph Neural Networks (GNNs).",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "data_processing",
        "graph_construction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/c2g-dev/city2graph",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "geospatial",
        "gnn",
        "graph-construction"
      ],
      "id": 837
    },
    {
      "name": "EasyDGL",
      "one_line_profile": "Library for Continuous-time Dynamic Graph Learning",
      "detailed_description": "A toolkit designed to encode, train, and interpret continuous-time dynamic graph learning models, providing a simplified interface for dynamic GNNs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "model_training",
        "dynamic_graph_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cchao0116/EasyDGL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dynamic-graph",
        "gnn",
        "continuous-time"
      ],
      "id": 838
    },
    {
      "name": "Geometric GNN Dojo",
      "one_line_profile": "Unified framework for exploring Geometric GNN designs",
      "detailed_description": "A unified implementation and benchmarking framework (Dojo) to explore the design space of Geometric Graph Neural Networks, facilitating reproducible research.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "model_design"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/chaitjo/geometric-gnn-dojo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "geometric-gnn",
        "benchmark",
        "design-space"
      ],
      "id": 839
    },
    {
      "name": "gRNAde",
      "one_line_profile": "Generative AI framework for 3D RNA inverse design",
      "detailed_description": "A generative AI framework (gRNAde) for the inverse design of 3D RNA structures and functions, utilizing geometric deep learning.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "structure_prediction",
        "inverse_design"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/chaitjo/geometric-rna-design",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rna-design",
        "geometric-dl",
        "generative-ai"
      ],
      "id": 840
    },
    {
      "name": "graph-convnet-tsp",
      "one_line_profile": "GCN-based solver for the Travelling Salesman Problem",
      "detailed_description": "An efficient Graph Convolutional Network implementation designed to solve the Travelling Salesman Problem (TSP), serving as a neural combinatorial optimization tool.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "optimization",
        "solver"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chaitjo/graph-convnet-tsp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tsp",
        "combinatorial-optimization",
        "gcn"
      ],
      "id": 841
    },
    {
      "name": "GCNII",
      "one_line_profile": "Implementation of Simple and Deep Graph Convolutional Networks",
      "detailed_description": "A widely used PyTorch implementation of the GCNII model, enabling deep graph convolutional networks with initial residual and identity mapping.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "model_training",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chennnM/GCNII",
      "help_website": [],
      "license": null,
      "tags": [
        "gcn",
        "deep-learning",
        "graph-neural-networks"
      ],
      "id": 842
    },
    {
      "name": "ggnn.pytorch",
      "one_line_profile": "PyTorch implementation of Gated Graph Sequence Neural Networks",
      "detailed_description": "A reusable PyTorch implementation of Gated Graph Sequence Neural Networks (GGNN), often used as a component in larger graph learning systems.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "model_component",
        "sequence_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chingyaoc/ggnn.pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ggnn",
        "pytorch",
        "graph-sequence"
      ],
      "id": 843
    },
    {
      "name": "FCGF",
      "one_line_profile": "Fully Convolutional Geometric Features for 3D registration",
      "detailed_description": "A library for extracting fast and accurate 3D geometric features using fully convolutional networks, used for 3D registration and correspondence tasks.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "feature_extraction",
        "3d_registration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chrischoy/FCGF",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "3d-vision",
        "geometric-features",
        "registration"
      ],
      "id": 844
    },
    {
      "name": "HetGNN",
      "one_line_profile": "Heterogeneous Graph Neural Network implementation",
      "detailed_description": "A standard implementation of HetGNN (Heterogeneous Graph Neural Network), widely used as a baseline and tool for heterogeneous graph representation learning.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "embedding",
        "heterogeneous_graph"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chuxuzhang/KDD2019_HetGNN",
      "help_website": [],
      "license": null,
      "tags": [
        "heterogeneous-graph",
        "gnn",
        "embedding"
      ],
      "id": 845
    },
    {
      "name": "GNN-RAG",
      "one_line_profile": "Graph Neural Retrieval for LLM Reasoning",
      "detailed_description": "A framework combining Graph Neural Networks (GNN) with Retrieval-Augmented Generation (RAG) to enhance Large Language Model reasoning over knowledge graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "reasoning",
        "retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cmavro/GNN-RAG",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "gnn",
        "llm",
        "knowledge-graph"
      ],
      "id": 846
    },
    {
      "name": "MAGNN",
      "one_line_profile": "Metapath Aggregated Graph Neural Network",
      "detailed_description": "Implementation of MAGNN, a model for heterogeneous graph embedding that aggregates information via metapaths, serving as a key tool for heterogeneous graph analysis.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "embedding",
        "heterogeneous_graph"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cynricfu/MAGNN",
      "help_website": [],
      "license": null,
      "tags": [
        "metapath",
        "heterogeneous-graph",
        "gnn"
      ],
      "id": 847
    },
    {
      "name": "GDN",
      "one_line_profile": "GNN-based Anomaly Detection in Multivariate Time Series",
      "detailed_description": "A tool for detecting anomalies in multivariate time series data using Graph Neural Networks, applicable to sensor networks and physical system monitoring.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "anomaly_detection",
        "time_series_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/d-ailin/GDN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "anomaly-detection",
        "time-series",
        "gnn"
      ],
      "id": 848
    },
    {
      "name": "Graph-Transformer",
      "one_line_profile": "Universal Graph Transformer Self-Attention Networks",
      "detailed_description": "A comprehensive implementation of Graph Transformer networks, providing a versatile tool for applying self-attention mechanisms to graph data.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "model_training",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/daiquocnguyen/Graph-Transformer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "graph-transformer",
        "self-attention",
        "gnn"
      ],
      "id": 849
    },
    {
      "name": "keras-gat",
      "one_line_profile": "Keras implementation of Graph Attention Networks",
      "detailed_description": "A reusable Keras implementation of Graph Attention Networks (GAT), facilitating the integration of attention mechanisms into graph-based workflows.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "model_component",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/danielegrattarola/keras-gat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gat",
        "keras",
        "graph-attention"
      ],
      "id": 850
    },
    {
      "name": "Spektral",
      "one_line_profile": "Graph Neural Networks library for Keras and Tensorflow 2",
      "detailed_description": "A comprehensive Python library for Graph Neural Networks, built on Keras and TensorFlow 2, offering a wide range of layers and utilities for graph deep learning.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "model_development",
        "graph_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/danielegrattarola/spektral",
      "help_website": [
        "https://graphneural.network/"
      ],
      "license": "MIT",
      "tags": [
        "gnn",
        "keras",
        "tensorflow",
        "library"
      ],
      "id": 851
    },
    {
      "name": "DGLL",
      "one_line_profile": "Distributed Graph Learning Library for scalable GNN training",
      "detailed_description": "A distributed graph learning library designed to handle large-scale graph data and train Graph Neural Networks (GNNs) efficiently across multiple computing nodes.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "model_training",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dke-lab/dgll",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "distributed-learning",
        "gnn",
        "graph-learning"
      ],
      "id": 852
    },
    {
      "name": "GNNLens2",
      "one_line_profile": "Interactive visualization tool for Graph Neural Networks",
      "detailed_description": "A visualization tool designed to help researchers and developers understand and debug Graph Neural Networks (GNNs) by visualizing graph structures, node embeddings, and model predictions.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "visualization",
        "model_debugging"
      ],
      "application_level": "tool",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/dmlc/GNNLens2",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "gnn",
        "explainable-ai"
      ],
      "id": 853
    },
    {
      "name": "DGL",
      "one_line_profile": "Deep Graph Library for deep learning on graphs",
      "detailed_description": "A Python package built to ease deep learning on graphs, on top of existing DL frameworks like PyTorch, TensorFlow, and MXNet. It provides efficient primitives for message passing and graph operations.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "model_training",
        "inference",
        "graph_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dmlc/dgl",
      "help_website": [
        "https://www.dgl.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "gnn",
        "deep-learning",
        "graph-neural-networks"
      ],
      "id": 854
    },
    {
      "name": "gvp-pytorch",
      "one_line_profile": "Geometric Vector Perceptrons for biomolecular structure learning",
      "detailed_description": "A library implementing Geometric Vector Perceptrons (GVP), a rotation-equivariant Graph Neural Network architecture specifically designed for learning from 3D biomolecular structures (protein engineering/design).",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "structure_prediction",
        "molecular_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/drorlab/gvp-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-structure",
        "geometric-deep-learning",
        "biomolecules"
      ],
      "id": 855
    },
    {
      "name": "DGLD",
      "one_line_profile": "Deep Graph Outlier Detection Library",
      "detailed_description": "A comprehensive library for deep graph outlier detection, providing unified interfaces for various anomaly detection algorithms on graphs, built upon DGL.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "anomaly_detection",
        "graph_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/eaglelab-zju/DGLD",
      "help_website": [
        "https://dgld.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "outlier-detection",
        "graph-mining",
        "anomaly-detection"
      ],
      "id": 856
    },
    {
      "name": "DRKG",
      "one_line_profile": "Drug Repurposing Knowledge Graph and analysis tools",
      "detailed_description": "A comprehensive biological knowledge graph relating genes, compounds, diseases, and other biological entities, accompanied by tools and pre-trained models for drug repurposing analysis.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "drug_discovery",
        "link_prediction",
        "data_mining"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/gnn4dr/DRKG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "drug-repurposing",
        "knowledge-graph",
        "bioinformatics"
      ],
      "id": 857
    },
    {
      "name": "jraph",
      "one_line_profile": "Graph Neural Network library in JAX",
      "detailed_description": "A lightweight, functional library for building Graph Neural Networks (GNNs) in JAX, providing data structures and utilities for graph operations and model definitions.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "model_training",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google-deepmind/jraph",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jax",
        "gnn",
        "deep-learning"
      ],
      "id": 858
    },
    {
      "name": "Graph4NLP",
      "one_line_profile": "Library for Graph Neural Networks in NLP",
      "detailed_description": "A library designed to facilitate the use of Graph Neural Networks (GNNs) for Natural Language Processing (NLP) tasks, supporting graph construction, representation learning, and prediction workflows.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "text_mining",
        "graph_construction",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/graph4ai/graph4nlp",
      "help_website": [
        "https://graph4ai.github.io/graph4nlp/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "gnn",
        "graph-learning"
      ],
      "id": 859
    },
    {
      "name": "distributed-kge-poplar",
      "one_line_profile": "Distributed Knowledge Graph Embedding system for IPUs",
      "detailed_description": "A system for training and evaluating knowledge graph embedding models, optimized for distributed execution on Graphcore IPUs (Intelligence Processing Units).",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "model_training",
        "embedding_generation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/graphcore/distributed-kge-poplar",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kge",
        "ipu",
        "distributed-training"
      ],
      "id": 860
    },
    {
      "name": "benchmarking-gnns",
      "one_line_profile": "Benchmarking infrastructure for Graph Neural Networks across various tasks",
      "detailed_description": "A library designed to facilitate the benchmarking of Graph Neural Networks (GNNs) by providing standard datasets, data loading pipelines, and evaluation metrics. It aims to ensure fair and reproducible comparisons between different GNN architectures.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/graphdeeplearning/benchmarking-gnns",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gnn",
        "benchmarking",
        "graph-neural-networks"
      ],
      "id": 861
    },
    {
      "name": "Gunrock",
      "one_line_profile": "High-performance programmable GPU graph analytics library",
      "detailed_description": "A CUDA library for graph-processing designed specifically for the GPU. It uses a high-level, bulk-synchronous, data-centric abstraction focused on operations on vertex or edge frontiers, enabling efficient implementation of graph algorithms.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_analytics",
        "graph_processing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/gunrock/gunrock",
      "help_website": [
        "https://gunrock.github.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "cuda",
        "gpu",
        "graph-analytics",
        "hpc"
      ],
      "id": 862
    },
    {
      "name": "bijou",
      "one_line_profile": "Training and tuning framework for PyTorch GNN models",
      "detailed_description": "A fastai-like framework designed to simplify the training, tuning, and probing of PyTorch models, specifically compatible with graph neural network libraries like pytorch_geometric and DGL.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "model_training",
        "hyperparameter_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hitlic/bijou",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pytorch",
        "gnn",
        "training-framework",
        "dgl"
      ],
      "id": 863
    },
    {
      "name": "MatDGL",
      "one_line_profile": "Deep learning library for crystal modeling and materials science",
      "detailed_description": "A neural network package built to allow researchers to train custom models for crystal modeling tasks, aiming to accelerate research and applications in material science.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "crystal_modeling",
        "property_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huzongxiang/MatDGL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "materials-science",
        "crystal-structure",
        "deep-learning"
      ],
      "id": 864
    },
    {
      "name": "CogDL-TensorFlow",
      "one_line_profile": "TensorFlow implementation of the CogDL graph representation learning toolkit",
      "detailed_description": "The TensorFlow version of CogDL, a toolkit for deep learning on graphs. It provides implementations of various graph neural network algorithms and embedding methods.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_representation_learning",
        "embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/imsheridan/CogDL-TensorFlow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tensorflow",
        "cogdl",
        "graph-embedding"
      ],
      "id": 865
    },
    {
      "name": "dl-benchmark",
      "one_line_profile": "Benchmark suite for deep learning inference engines",
      "detailed_description": "A tool for benchmarking deep learning inference performance across various frameworks (OpenVINO, TensorFlow, PyTorch, etc.), useful for optimizing scientific model deployment.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "inference_benchmarking",
        "performance_optimization"
      ],
      "application_level": "utility",
      "primary_language": "HTML",
      "repo_url": "https://github.com/itlab-vision/dl-benchmark",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "inference",
        "deep-learning"
      ],
      "id": 866
    },
    {
      "name": "scGNN",
      "one_line_profile": "Graph neural network tool for single-cell RNA-seq analysis",
      "detailed_description": "scGNN (single cell graph neural networks) is a tool for single cell clustering and imputation using graph neural networks, providing a hypothesis-free deep learning framework for scRNA-seq data.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "imputation",
        "clustering",
        "single_cell_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/juexinwang/scGNN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "single-cell",
        "scrna-seq",
        "gnn",
        "bioinformatics"
      ],
      "id": 867
    },
    {
      "name": "En-transformer",
      "one_line_profile": "Implementation of E(n)-Equivariant Transformer for 3D graph data",
      "detailed_description": "A PyTorch implementation of the E(n)-Transformer, which extends E(n)-Equivariant Graph Neural Networks with attention mechanisms. This tool is essential for modeling 3D scientific data such as molecules and proteins where rotation and translation equivariance are critical.",
      "domains": [
        "G2-04",
        "Chemistry",
        "Physics"
      ],
      "subtask_category": [
        "molecular_modeling",
        "structure_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucidrains/En-transformer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "equivariant-gnn",
        "transformer",
        "3d-structure",
        "molecules"
      ],
      "id": 868
    },
    {
      "name": "Adjacent Attention Network",
      "one_line_profile": "Transformer-based message passing layer for Graph Neural Networks",
      "detailed_description": "A PyTorch library implementing a Graph Neural Network architecture that reframes message passing as a Transformer with local attention. It serves as a building block for graph inference tasks in scientific domains.",
      "domains": [
        "G2-04"
      ],
      "subtask_category": [
        "graph_inference",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucidrains/adjacent-attention-network",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gnn",
        "attention",
        "transformer",
        "graph-learning"
      ],
      "id": 869
    },
    {
      "name": "EGNN-PyTorch",
      "one_line_profile": "PyTorch implementation of E(n)-Equivariant Graph Neural Networks",
      "detailed_description": "A widely used library implementing E(n)-Equivariant Graph Neural Networks (EGNN). It provides rotation, translation, and reflection equivariant layers, making it a standard tool for deep learning on 3D molecular structures and particle physics data.",
      "domains": [
        "G2-04",
        "Chemistry",
        "Biology",
        "Physics"
      ],
      "subtask_category": [
        "molecular_dynamics",
        "structure_prediction",
        "property_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucidrains/egnn-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "egnn",
        "equivariant-gnn",
        "molecular-dynamics",
        "3d-graph"
      ],
      "id": 870
    },
    {
      "name": "Geometric Vector Perceptron",
      "one_line_profile": "Equivariant neural network layers for large biomolecule learning",
      "detailed_description": "A PyTorch implementation of Geometric Vector Perceptron (GVP), designed for learning representations of large biomolecules like proteins. It handles 3D rotation equivariance efficiently, enabling tasks such as protein design and structure analysis.",
      "domains": [
        "G2-04",
        "Biology",
        "Chemistry"
      ],
      "subtask_category": [
        "protein_structure_learning",
        "biomolecule_representation",
        "protein_design"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucidrains/geometric-vector-perceptron",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-structure",
        "geometric-deep-learning",
        "gvp",
        "biomolecules"
      ],
      "id": 871
    },
    {
      "name": "PNA",
      "one_line_profile": "Principal Neighbourhood Aggregation layers for Graph Neural Networks",
      "detailed_description": "A library implementing Principal Neighbourhood Aggregation (PNA) for Graph Neural Networks in PyTorch, DGL, and PyTorch Geometric. PNA is a powerful aggregation strategy often used in molecular graph learning to capture structural properties better than standard aggregators.",
      "domains": [
        "G2-04",
        "Chemistry"
      ],
      "subtask_category": [
        "graph_inference",
        "molecular_property_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lukecavabarrett/pna",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gnn",
        "aggregation",
        "molecular-graphs",
        "pytorch-geometric"
      ],
      "id": 872
    },
    {
      "name": "FastGCN",
      "one_line_profile": "Fast learning algorithm for Graph Convolutional Networks via importance sampling",
      "detailed_description": "A library implementing FastGCN, an improvement over standard GCNs that uses importance sampling to reduce the computational cost of training on large graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_learning",
        "node_classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/matenure/FastGCN",
      "help_website": [],
      "license": null,
      "tags": [
        "gcn",
        "graph-sampling",
        "scalability"
      ],
      "id": 873
    },
    {
      "name": "cnn_graph",
      "one_line_profile": "Spectral Graph Convolutional Neural Networks (ChebNet)",
      "detailed_description": "Implementation of Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering (ChebNet), a foundational method for graph signal processing and learning.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_learning",
        "spectral_filtering"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mdeff/cnn_graph",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "spectral-gnn",
        "chebnet",
        "graph-signal-processing"
      ],
      "id": 874
    },
    {
      "name": "ML-GCN",
      "one_line_profile": "Multi-label image recognition using Graph Convolutional Networks",
      "detailed_description": "A PyTorch implementation of ML-GCN which captures label dependencies using GCNs to improve multi-label image classification performance.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "image_classification",
        "label_dependency_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/megvii-research/ML-GCN",
      "help_website": [],
      "license": null,
      "tags": [
        "computer-vision",
        "multi-label",
        "gcn"
      ],
      "id": 875
    },
    {
      "name": "Subgraph Sketching",
      "one_line_profile": "Scalable subgraph-based link prediction for Graph Neural Networks",
      "detailed_description": "Code for 'Graph Neural Networks for Link Prediction with Subgraph Sketching', providing efficient methods for link prediction tasks in large knowledge graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "link_prediction",
        "graph_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/melifluos/subgraph-sketching",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "link-prediction",
        "subgraph",
        "gnn"
      ],
      "id": 876
    },
    {
      "name": "StemGNN",
      "one_line_profile": "Spectral Temporal Graph Neural Network for time-series forecasting",
      "detailed_description": "A graph neural network model designed for multivariate time-series forecasting that captures both temporal and inter-series correlations in the spectral domain.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "time_series_forecasting",
        "spectral_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/StemGNN",
      "help_website": [],
      "license": null,
      "tags": [
        "time-series",
        "forecasting",
        "spectral-gnn"
      ],
      "id": 877
    },
    {
      "name": "GGNN Samples",
      "one_line_profile": "Reference implementation for Gated Graph Neural Networks",
      "detailed_description": "Sample code and reference implementation for Gated Graph Neural Networks (GGNN), widely used for tasks involving graph-structured data and sequence learning on graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_learning",
        "sequence_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/gated-graph-neural-network-samples",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ggnn",
        "gated-gnn",
        "reference-implementation"
      ],
      "id": 878
    },
    {
      "name": "ptgnn",
      "one_line_profile": "PyTorch Graph Neural Network Library",
      "detailed_description": "A library for building and training Graph Neural Networks in PyTorch, focusing on applications in program analysis and other structured data tasks.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_learning",
        "model_building"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/ptgnn",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "gnn-library",
        "program-analysis"
      ],
      "id": 879
    },
    {
      "name": "tf-gnn-samples",
      "one_line_profile": "TensorFlow implementations of various Graph Neural Networks",
      "detailed_description": "A collection of Graph Neural Network implementations in TensorFlow, serving as a resource for researchers and practitioners to apply GNNs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_learning",
        "model_implementation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/tf-gnn-samples",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tensorflow",
        "gnn",
        "samples"
      ],
      "id": 880
    },
    {
      "name": "tf2-gnn",
      "one_line_profile": "TensorFlow 2 library for Graph Neural Networks",
      "detailed_description": "A library implementing Graph Neural Networks using TensorFlow 2, providing reusable components for building GNN models.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_learning",
        "model_building"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/tf2-gnn",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tensorflow2",
        "gnn-library",
        "deep-learning"
      ],
      "id": 881
    },
    {
      "name": "OhmNet",
      "one_line_profile": "Representation learning in multi-layer tissue-specific graphs",
      "detailed_description": "An algorithm for learning node representations in multi-layer graphs, specifically designed for modeling tissue-specific protein interaction networks.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "network_biology",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mims-harvard/ohmnet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "protein-interaction",
        "multi-layer-graph"
      ],
      "id": 882
    },
    {
      "name": "GraphLLM",
      "one_line_profile": "Boosting graph reasoning ability of Large Language Models",
      "detailed_description": "A framework to enhance the reasoning capabilities of Large Language Models on graph-structured data, bridging the gap between LLMs and GNNs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_reasoning",
        "llm_integration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mistyreed63849/Graph-LLM",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "graph-reasoning",
        "gnn"
      ],
      "id": 883
    },
    {
      "name": "JKNet-dgl",
      "one_line_profile": "DGL implementation of Jumping Knowledge Networks",
      "detailed_description": "An implementation of Jumping Knowledge Networks (JK-Nets) using the Deep Graph Library (DGL), allowing GNNs to adaptively leverage different neighborhood ranges.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_learning",
        "architecture_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mori97/JKNet-dgl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dgl",
        "jknet",
        "gnn"
      ],
      "id": 884
    },
    {
      "name": "Robust Matching Network",
      "one_line_profile": "Geometric transformation estimation for remote sensing imagery",
      "detailed_description": "A robust matching network designed to estimate geometric transformations in remote sensing imagery, useful for image registration and analysis in earth sciences.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "remote_sensing",
        "image_registration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mrk1992/robust_matching_network_on_remote_sensing_imagery_pytorch",
      "help_website": [],
      "license": null,
      "tags": [
        "remote-sensing",
        "geometric-matching",
        "earth-science"
      ],
      "id": 885
    },
    {
      "name": "MTransE",
      "one_line_profile": "Multilingual Knowledge Graph Embeddings for Cross-lingual Alignment",
      "detailed_description": "A model for cross-lingual knowledge alignment that learns multilingual knowledge graph embeddings, facilitating knowledge transfer across languages.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "entity_alignment",
        "cross_lingual_kg"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/muhaochen/MTransE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kge",
        "entity-alignment",
        "multilingual"
      ],
      "id": 886
    },
    {
      "name": "gnn-powerflow",
      "one_line_profile": "GNN application for predicting AC Power Flow",
      "detailed_description": "A Graph Neural Network application developed with PyTorch Geometric to predict AC power flow calculations in electrical power systems.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "power_flow_prediction",
        "grid_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mukhlishga/gnn-powerflow",
      "help_website": [],
      "license": null,
      "tags": [
        "power-systems",
        "gnn",
        "physics-informed"
      ],
      "id": 887
    },
    {
      "name": "gnn_hierarchical_pooling",
      "one_line_profile": "Hierarchical Graph Representation Learning with Differentiable Pooling",
      "detailed_description": "Implementation of hierarchical pooling mechanisms for Graph Neural Networks, enabling the learning of hierarchical graph representations.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_learning",
        "pooling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/murphyyhuang/gnn_hierarchical_pooling",
      "help_website": [],
      "license": null,
      "tags": [
        "gnn",
        "pooling",
        "representation-learning"
      ],
      "id": 888
    },
    {
      "name": "NCATS ADME",
      "one_line_profile": "Prediction models for ADME properties",
      "detailed_description": "Source code for the ADME@NCATS application, hosting prediction models for Absorption, Distribution, Metabolism, and Excretion properties of chemical compounds.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "adme_prediction",
        "cheminformatics"
      ],
      "application_level": "platform",
      "primary_language": "HTML",
      "repo_url": "https://github.com/ncats/ncats-adme",
      "help_website": [
        "https://opendata.ncats.nih.gov/adme/home"
      ],
      "license": null,
      "tags": [
        "drug-discovery",
        "adme",
        "predictive-modeling"
      ],
      "id": 889
    },
    {
      "name": "CAKE",
      "one_line_profile": "Scalable Commonsense-Aware Framework for Multi-View KG Completion",
      "detailed_description": "A framework for knowledge graph completion that integrates commonsense knowledge and multi-view learning to improve scalability and accuracy.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_graph_completion",
        "commonsense_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ngl567/CAKE",
      "help_website": [],
      "license": null,
      "tags": [
        "kgc",
        "commonsense",
        "multi-view"
      ],
      "id": 890
    },
    {
      "name": "GANA-FewShotKGC",
      "one_line_profile": "Gated and Attentive Neighbor Aggregator for Few-Shot KG Completion",
      "detailed_description": "A model for few-shot knowledge graph completion that uses a gated and attentive neighbor aggregator to learn from limited data.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "few_shot_learning",
        "knowledge_graph_completion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ngl567/GANA-FewShotKGC",
      "help_website": [],
      "license": null,
      "tags": [
        "few-shot",
        "kgc",
        "attention"
      ],
      "id": 891
    },
    {
      "name": "LCGE",
      "one_line_profile": "Logic and Commonsense-Guided Temporal Knowledge Graph Completion",
      "detailed_description": "A method for temporal knowledge graph completion that incorporates logic rules and commonsense knowledge to guide the learning process.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "temporal_kgc",
        "logic_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ngl567/LCGE",
      "help_website": [],
      "license": null,
      "tags": [
        "temporal-kg",
        "logic",
        "commonsense"
      ],
      "id": 892
    },
    {
      "name": "RPJE",
      "one_line_profile": "Rule-Guided Compositional Representation Learning on Knowledge Graphs",
      "detailed_description": "A representation learning approach for knowledge graphs that uses rules to guide the composition of embeddings, enhancing interpretability and performance.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "rule_learning"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ngl567/RPJE",
      "help_website": [],
      "license": null,
      "tags": [
        "kge",
        "rule-guided",
        "compositional"
      ],
      "id": 893
    },
    {
      "name": "DIFT",
      "one_line_profile": "Finetuning Generative LLMs for Knowledge Graph Completion",
      "detailed_description": "A method for finetuning generative Large Language Models with discrimination instructions to perform knowledge graph completion tasks.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_graph_completion",
        "llm_finetuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nju-websoft/DIFT",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "llm",
        "kgc",
        "generative-ai"
      ],
      "id": 894
    },
    {
      "name": "FedLU",
      "one_line_profile": "Heterogeneous Federated Knowledge Graph Embedding Learning and Unlearning",
      "detailed_description": "A federated learning framework for knowledge graph embeddings that supports both learning and unlearning in heterogeneous environments.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "federated_learning",
        "knowledge_graph_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nju-websoft/FedLU",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "federated-learning",
        "kge",
        "privacy"
      ],
      "id": 895
    },
    {
      "name": "GraphCMR",
      "one_line_profile": "Convolutional Mesh Regression for Human Shape Reconstruction",
      "detailed_description": "A method for reconstructing 3D human shapes from single images using a Graph Convolutional Network attached to a mesh structure.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "3d_reconstruction",
        "mesh_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nkolot/GraphCMR",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "computer-vision",
        "3d-mesh",
        "gcn"
      ],
      "id": 896
    },
    {
      "name": "kgextension",
      "one_line_profile": "Knowledge Graph Extension for Python",
      "detailed_description": "A Python library that extends standard data analysis workflows with knowledge graph capabilities, making it easier to integrate KG features into ML pipelines.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_graph_integration",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/om-hb/kgextension",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "python",
        "knowledge-graph",
        "extension"
      ],
      "id": 897
    },
    {
      "name": "Visualkeras",
      "one_line_profile": "Visualization library for Keras neural network architectures",
      "detailed_description": "A Python package that generates layered or graph-style visualizations of Keras/TensorFlow neural network architectures, aiding researchers in model inspection and documentation.",
      "domains": [
        "G2-04"
      ],
      "subtask_category": [
        "visualization",
        "model_inspection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/paulgavrikov/visualkeras",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "keras",
        "neural-networks"
      ],
      "id": 898
    },
    {
      "name": "PyTorch Geometric (PyG)",
      "one_line_profile": "Graph Neural Network library for PyTorch",
      "detailed_description": "A library built upon PyTorch to easily write and train Graph Neural Networks (GNNs) for a wide range of applications related to structured data, including geometric deep learning.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_learning",
        "geometric_deep_learning",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pyg-team/pytorch_geometric",
      "help_website": [
        "https://pytorch-geometric.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "gnn",
        "graph-neural-networks",
        "geometric-deep-learning"
      ],
      "id": 899
    },
    {
      "name": "GraFOG",
      "one_line_profile": "Graph Data Augmentation Library for PyTorch Geometric",
      "detailed_description": "A library designed to perform data augmentation on graph datasets, compatible with PyTorch Geometric, to enhance the robustness and performance of GNN models.",
      "domains": [
        "G2-04"
      ],
      "subtask_category": [
        "data_augmentation",
        "graph_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rish-16/grafog",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-augmentation",
        "gnn",
        "pytorch-geometric"
      ],
      "id": 900
    },
    {
      "name": "GNN-FakeNews",
      "one_line_profile": "Benchmarking framework for GNN-based fake news detection",
      "detailed_description": "A collection of Graph Neural Network models and datasets specifically designed for the task of fake news detection, serving as a benchmark framework for social network analysis research.",
      "domains": [
        "G2-04"
      ],
      "subtask_category": [
        "fake_news_detection",
        "graph_classification",
        "benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/safe-graph/GNN-FakeNews",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fake-news",
        "gnn",
        "social-network-analysis"
      ],
      "id": 901
    },
    {
      "name": "GTrick",
      "one_line_profile": "Library of tricks for Graph Neural Networks",
      "detailed_description": "A library that implements various 'tricks' and optimization techniques for Graph Neural Networks to improve model performance and training stability.",
      "domains": [
        "G2-04"
      ],
      "subtask_category": [
        "graph_learning",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/sangyx/gtrick",
      "help_website": [
        "https://gtrick.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "gnn",
        "optimization",
        "tricks"
      ],
      "id": 902
    },
    {
      "name": "GNN Benchmark",
      "one_line_profile": "Framework for evaluating Graph Neural Network models",
      "detailed_description": "A framework designed to evaluate and compare different Graph Neural Network models on semi-supervised node classification tasks, ensuring fair and consistent benchmarking.",
      "domains": [
        "G2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "node_classification"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/shchur/gnn-benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gnn",
        "benchmark",
        "evaluation"
      ],
      "id": 903
    },
    {
      "name": "XNM-Net",
      "one_line_profile": "Explainable and explicit visual reasoning model over scene graphs",
      "detailed_description": "A PyTorch implementation of the XNM-Net model for visual reasoning tasks. It utilizes scene graphs to perform explainable and explicit reasoning, bridging computer vision and knowledge graph domains.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "visual_reasoning",
        "scene_graph_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/shijx12/XNM-Net",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visual-reasoning",
        "scene-graph",
        "pytorch",
        "explainable-ai"
      ],
      "id": 904
    },
    {
      "name": "gae-dgl",
      "one_line_profile": "DGL implementation of Graph Autoencoder (GAE)",
      "detailed_description": "A reimplementation of the Graph Autoencoder (GAE) and Variational Graph Autoencoder (VGAE) models using the Deep Graph Library (DGL). It serves as a tool for unsupervised learning on graph data.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_embedding",
        "link_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/shionhonda/gae-dgl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-autoencoder",
        "dgl",
        "unsupervised-learning",
        "graph-neural-networks"
      ],
      "id": 905
    },
    {
      "name": "ad_examples",
      "one_line_profile": "Comprehensive collection of anomaly detection methods and algorithms",
      "detailed_description": "A library providing implementations of various anomaly detection methods, including point-based, graph-based, and time-series approaches. It includes active learning, Bayesian rule-mining, and adversarial attacks with Graph Convolutional Networks.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "anomaly_detection",
        "graph_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shubhomoydas/ad_examples",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "anomaly-detection",
        "graph-convolutional-networks",
        "time-series",
        "active-learning"
      ],
      "id": 906
    },
    {
      "name": "SGMN",
      "one_line_profile": "Graph-structured referring expressions reasoning model",
      "detailed_description": "Implementation of the SGMN model for reasoning over graph-structured referring expressions in the wild. It applies graph neural networks to solve visual grounding and reasoning tasks.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "visual_reasoning",
        "graph_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sibeiyang/sgmn",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visual-grounding",
        "graph-neural-networks",
        "reasoning",
        "cvpr"
      ],
      "id": 907
    },
    {
      "name": "GraphGym",
      "one_line_profile": "Platform for designing and evaluating Graph Neural Networks",
      "detailed_description": "A comprehensive platform developed by Stanford for designing, implementing, and evaluating Graph Neural Networks (GNNs). It simplifies the process of creating GNN pipelines and benchmarking performance.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "gnn_design",
        "model_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/snap-stanford/GraphGym",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "gnn",
        "deep-learning",
        "benchmark",
        "pytorch"
      ],
      "id": 908
    },
    {
      "name": "GreaseLM",
      "one_line_profile": "Graph reasoning enhanced language models for QA",
      "detailed_description": "A model that integrates graph reasoning with language models to improve performance on question answering tasks. It fuses representations from pre-trained LMs and GNNs over knowledge graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "question_answering",
        "graph_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/snap-stanford/GreaseLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "language-models",
        "knowledge-graph",
        "reasoning",
        "qa"
      ],
      "id": 909
    },
    {
      "name": "KGReasoning",
      "one_line_profile": "Framework for multi-hop logical reasoning in knowledge graphs",
      "detailed_description": "A library and framework for performing multi-hop logical reasoning over knowledge graphs. It supports complex query answering tasks using graph embeddings and neural reasoning methods.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "logical_reasoning",
        "query_answering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/snap-stanford/KGReasoning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "logical-reasoning",
        "multi-hop",
        "embedding"
      ],
      "id": 910
    },
    {
      "name": "pretrain-gnns",
      "one_line_profile": "Strategies and tools for pre-training Graph Neural Networks",
      "detailed_description": "A repository providing strategies and implementations for pre-training Graph Neural Networks (GNNs) to improve transfer learning on graph tasks. It includes methods for self-supervised learning on graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "gnn_pretraining",
        "transfer_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/snap-stanford/pretrain-gnns",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pre-training",
        "gnn",
        "self-supervised-learning",
        "transfer-learning"
      ],
      "id": 911
    },
    {
      "name": "RelBench",
      "one_line_profile": "Relational Deep Learning Benchmark",
      "detailed_description": "A benchmark suite for relational deep learning, providing datasets and evaluation tools for machine learning tasks on relational databases and knowledge graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "benchmarking",
        "relational_learning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/snap-stanford/relbench",
      "help_website": [
        "https://relbench.stanford.edu"
      ],
      "license": "MIT",
      "tags": [
        "benchmark",
        "relational-learning",
        "gnn",
        "database"
      ],
      "id": 912
    },
    {
      "name": "ATISE",
      "one_line_profile": "Temporal Knowledge Graph completion with Gaussian embedding",
      "detailed_description": "Implementation of ATISE and TeRo models for temporal knowledge graph completion. It uses time-series Gaussian embeddings and temporal rotation to model evolving knowledge graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "temporal_kg_completion",
        "link_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/soledad921/ATISE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "temporal-knowledge-graph",
        "embedding",
        "link-prediction",
        "gaussian-embedding"
      ],
      "id": 913
    },
    {
      "name": "TeLM",
      "one_line_profile": "Linear Temporal Regularizer and Multivector Embeddings for TKG",
      "detailed_description": "Implementation of the TeLM model for Temporal Knowledge Graph Completion. It utilizes a linear temporal regularizer and multivector embeddings to perform link prediction in temporal settings.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "temporal_kg_completion",
        "link_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/soledad921/TeLM",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "temporal-knowledge-graph",
        "embedding",
        "complex-space",
        "link-prediction"
      ],
      "id": 914
    },
    {
      "name": "cnn-lstm-link-prediction",
      "one_line_profile": "Path-based link prediction model using CNN and LSTM",
      "detailed_description": "A Keras implementation of a path-based link prediction model for knowledge graph completion, combining CNN and LSTM to process graph paths.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "link_prediction",
        "knowledge_graph_completion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/spacewalk01/cnn-lstm-for-link-prediction",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "link-prediction",
        "keras",
        "cnn",
        "lstm"
      ],
      "id": 915
    },
    {
      "name": "Knowledge Graph of Thoughts",
      "one_line_profile": "Framework for AI assistants using Knowledge Graph of Thoughts",
      "detailed_description": "Implementation of the 'Knowledge Graph of Thoughts' (KoT) approach, which structures the reasoning process of AI assistants as a knowledge graph to improve performance and affordability.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "reasoning",
        "graph_construction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/spcl/knowledge-graph-of-thoughts",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "knowledge-graph",
        "llm",
        "reasoning",
        "ai-assistant"
      ],
      "id": 916
    },
    {
      "name": "InfoGraph",
      "one_line_profile": "Unsupervised graph-level representation learning via mutual information",
      "detailed_description": "Implementation of InfoGraph, a method for unsupervised and semi-supervised graph-level representation learning that maximizes mutual information between graph-level and substructure-level representations.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_representation_learning",
        "unsupervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sunfanyunn/InfoGraph",
      "help_website": [],
      "license": null,
      "tags": [
        "graph-neural-networks",
        "representation-learning",
        "mutual-information",
        "unsupervised"
      ],
      "id": 917
    },
    {
      "name": "graph-based-nn",
      "one_line_profile": "Collection of Graph Convolutional Network implementations",
      "detailed_description": "A repository containing implementations of Graph Convolutional Networks (GCNs). Given its high star count, it serves as a reference library for GNN models.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_convolution",
        "node_classification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sungyongs/graph-based-nn",
      "help_website": [],
      "license": null,
      "tags": [
        "gcn",
        "graph-neural-networks",
        "deep-learning"
      ],
      "id": 918
    },
    {
      "name": "RKGE",
      "one_line_profile": "Recurrent Knowledge Graph Embedding framework",
      "detailed_description": "Implementation of the Recurrent Knowledge Graph Embedding (RKGE) framework, designed for recommendation systems leveraging knowledge graph paths.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "recommendation",
        "knowledge_graph_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sunzhuntu/Recurrent-Knowledge-Graph-Embedding",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "recommendation-system",
        "rnn",
        "embedding"
      ],
      "id": 919
    },
    {
      "name": "GATGNN",
      "one_line_profile": "GNN with global attention for materials property prediction",
      "detailed_description": "A PyTorch implementation of Graph Convolutional Neural Networks with Global Attention (GATGNN), specifically designed for predicting properties of materials.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "property_prediction",
        "materials_science"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/superlouis/GATGNN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "materials-science",
        "gnn",
        "attention-mechanism",
        "property-prediction"
      ],
      "id": 920
    },
    {
      "name": "kg-reeval",
      "one_line_profile": "Evaluation framework for Knowledge Graph Completion methods",
      "detailed_description": "Codebase for the re-evaluation of Knowledge Graph Completion methods, providing a standardized environment to benchmark and assess the performance of various KGE models.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/svjan5/kg-reeval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph-completion",
        "evaluation",
        "benchmark",
        "kge"
      ],
      "id": 921
    },
    {
      "name": "Kingdon",
      "one_line_profile": "Symbolically optimized Geometric Algebra library",
      "detailed_description": "A Geometric Algebra library for Python that supports symbolic optimization and is compatible with PyTorch, NumPy, and SymPy. It is useful for physics simulations and geometric deep learning.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "geometric_algebra",
        "physics_simulation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tBuLi/kingdon",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "geometric-algebra",
        "pytorch",
        "symbolic-computation",
        "physics"
      ],
      "id": 922
    },
    {
      "name": "pytorch_HAN",
      "one_line_profile": "PyTorch implementation of Heterogeneous Graph Attention Network",
      "detailed_description": "An implementation of the Heterogeneous Graph Attention Network (HAN) using PyTorch. It allows for attention-based learning on heterogeneous graphs containing different types of nodes and edges.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "heterogeneous_graph_learning",
        "node_classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/taishan1994/pytorch_HAN",
      "help_website": [],
      "license": null,
      "tags": [
        "han",
        "heterogeneous-graph",
        "attention-network",
        "pytorch"
      ],
      "id": 923
    },
    {
      "name": "GCMC",
      "one_line_profile": "Graph Convolutional Matrix Completion implementation",
      "detailed_description": "Re-implementation of the Graph Convolutional Matrix Completion (GCMC) model using PyTorch and PyTorch Geometric. It is used for recommendation and link prediction tasks.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "matrix_completion",
        "recommendation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tanimutomo/gcmc",
      "help_website": [],
      "license": null,
      "tags": [
        "matrix-completion",
        "gcn",
        "pytorch-geometric",
        "recommender-system"
      ],
      "id": 924
    },
    {
      "name": "lightning-geometric",
      "one_line_profile": "Integration library for PyTorch Geometric and PyTorch Lightning",
      "detailed_description": "A library designed to integrate PyTorch Geometric with PyTorch Lightning, facilitating the training and scaling of Graph Neural Networks.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "gnn_training",
        "model_scaling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tchaton/lightning-geometric",
      "help_website": [],
      "license": null,
      "tags": [
        "pytorch-lightning",
        "pytorch-geometric",
        "gnn",
        "integration"
      ],
      "id": 925
    },
    {
      "name": "how_attentive_are_gats",
      "one_line_profile": "Analysis tools for Graph Attention Networks",
      "detailed_description": "Code and tools for analyzing the attention mechanisms in Graph Attention Networks (GATs), as presented in the ICLR 2022 paper. It helps in understanding the interpretability of GATs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "model_analysis",
        "interpretability"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tech-srl/how_attentive_are_gats",
      "help_website": [],
      "license": null,
      "tags": [
        "graph-attention-networks",
        "interpretability",
        "analysis",
        "gnn"
      ],
      "id": 926
    },
    {
      "name": "EAGRNet",
      "one_line_profile": "Edge-aware Graph Representation Learning for Face Parsing",
      "detailed_description": "Implementation of EAGRNet, a model for face parsing that utilizes edge-aware graph representation learning and reasoning.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "face_parsing",
        "graph_representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tegusi/EAGRNet",
      "help_website": [],
      "license": null,
      "tags": [
        "face-parsing",
        "graph-learning",
        "computer-vision",
        "edge-aware"
      ],
      "id": 927
    },
    {
      "name": "TensorFlow GNN",
      "one_line_profile": "Library to build Graph Neural Networks on TensorFlow",
      "detailed_description": "A comprehensive library for building and training Graph Neural Networks (GNNs) within the TensorFlow ecosystem. It provides primitives for handling graph data and implementing GNN layers.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "gnn_modeling",
        "graph_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tensorflow/gnn",
      "help_website": [
        "https://github.com/tensorflow/gnn"
      ],
      "license": "Apache-2.0",
      "tags": [
        "tensorflow",
        "gnn",
        "graph-neural-networks",
        "deep-learning"
      ],
      "id": 928
    },
    {
      "name": "torch-geometric-pool",
      "one_line_profile": "Pooling layers library for PyTorch Geometric",
      "detailed_description": "A specialized library providing various pooling layers and operations for Graph Neural Networks, designed to work with PyTorch Geometric.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_pooling",
        "gnn_components"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tgp-team/torch-geometric-pool",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pooling",
        "pytorch-geometric",
        "gnn",
        "graph-classification"
      ],
      "id": 929
    },
    {
      "name": "JointGT",
      "one_line_profile": "Graph-Text Joint Representation Learning model",
      "detailed_description": "Implementation of JointGT, a model for learning joint representations of graphs and text, specifically for text generation tasks from knowledge graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "text_generation",
        "graph_text_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-coai/JointGT",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph",
        "text-generation",
        "representation-learning",
        "nlp"
      ],
      "id": 930
    },
    {
      "name": "SentiLARE",
      "one_line_profile": "Sentiment-Aware Language Representation Learning",
      "detailed_description": "A library for sentiment-aware language representation learning that incorporates linguistic knowledge (including Part-of-Speech and sentiment polarity) into pre-trained models.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "sentiment_analysis",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-coai/SentiLARE",
      "help_website": [],
      "license": null,
      "tags": [
        "sentiment-analysis",
        "language-representation",
        "linguistic-knowledge",
        "nlp"
      ],
      "id": 931
    },
    {
      "name": "CKRL",
      "one_line_profile": "Knowledge Representation Learning with Confidence",
      "detailed_description": "Implementation of a knowledge representation learning method that incorporates confidence information into knowledge graph embeddings to handle noisy data.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_representation_learning",
        "noise_handling"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/thunlp/CKRL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "embedding",
        "confidence-learning",
        "krl"
      ],
      "id": 932
    },
    {
      "name": "DKRL",
      "one_line_profile": "Representation learning of knowledge graphs with entity descriptions",
      "detailed_description": "An implementation of the DKRL model (Description-embodied Knowledge Representation Learning) which utilizes entity descriptions for better knowledge graph embeddings, particularly for zero-shot scenarios.",
      "domains": [
        "G2",
        "G2-04",
        "NLP"
      ],
      "subtask_category": [
        "knowledge_embedding",
        "entity_representation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/thunlp/DKRL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kge",
        "entity-description",
        "representation-learning"
      ],
      "id": 933
    },
    {
      "name": "Fast-TransX",
      "one_line_profile": "Efficient implementation of TransE and extended KGE models",
      "detailed_description": "A highly efficient C++ implementation of translation-based knowledge graph embedding models (TransE, TransH, TransR, TransD) designed for speed and scalability.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_embedding",
        "link_prediction"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/thunlp/Fast-TransX",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "transe",
        "kge",
        "high-performance"
      ],
      "id": 934
    },
    {
      "name": "GEAR",
      "one_line_profile": "Graph-based Evidence Aggregating and Reasoning for fact verification",
      "detailed_description": "A tool implementing a graph-based evidence aggregating and reasoning framework for fact verification, enabling multi-hop reasoning over evidence graphs.",
      "domains": [
        "G2",
        "G2-04",
        "NLP"
      ],
      "subtask_category": [
        "fact_verification",
        "reasoning",
        "evidence_aggregation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/thunlp/GEAR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fact-checking",
        "graph-reasoning",
        "bert"
      ],
      "id": 935
    },
    {
      "name": "IKRL",
      "one_line_profile": "Image-embodied Knowledge Representation Learning",
      "detailed_description": "An implementation of the IKRL model which incorporates visual information (images) into knowledge graph representations to improve entity embeddings.",
      "domains": [
        "G2",
        "G2-04",
        "Multimodal"
      ],
      "subtask_category": [
        "knowledge_embedding",
        "multimodal_learning"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/thunlp/IKRL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kge",
        "multimodal",
        "image-embedding"
      ],
      "id": 936
    },
    {
      "name": "KR-EAR",
      "one_line_profile": "Knowledge Representation Learning with Entities, Attributes and Relations",
      "detailed_description": "A tool for learning knowledge representations by jointly modeling entities, relations, and attributes, distinguishing between relational and attribute triples.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_embedding",
        "attribute_modeling"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/thunlp/KR-EAR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kge",
        "attributes",
        "joint-modeling"
      ],
      "id": 937
    },
    {
      "name": "KernelGAT",
      "one_line_profile": "Fine-grained Fact Verification with Kernel Graph Attention Network",
      "detailed_description": "A graph attention network based tool for fine-grained fact verification, utilizing kernel-based attention mechanisms to aggregate evidence.",
      "domains": [
        "G2",
        "G2-04",
        "NLP"
      ],
      "subtask_category": [
        "fact_verification",
        "graph_attention",
        "inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/thunlp/KernelGAT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gat",
        "fact-checking",
        "kernel-methods"
      ],
      "id": 938
    },
    {
      "name": "TKRL",
      "one_line_profile": "Representation Learning of Knowledge Graphs with Hierarchical Types",
      "detailed_description": "A tool for knowledge graph embedding that incorporates hierarchical entity type information to improve representation quality.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_embedding",
        "type_encoding"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/thunlp/TKRL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kge",
        "hierarchical-types",
        "representation-learning"
      ],
      "id": 939
    },
    {
      "name": "TensorFlow-TransX",
      "one_line_profile": "TensorFlow implementation of TransE and extended KGE models",
      "detailed_description": "A TensorFlow-based library for training and evaluating translation-based knowledge graph embedding models.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_embedding",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/thunlp/TensorFlow-TransX",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tensorflow",
        "kge",
        "transe"
      ],
      "id": 940
    },
    {
      "name": "DeepPBS",
      "one_line_profile": "Geometric deep learning of protein–DNA binding specificity",
      "detailed_description": "A geometric deep learning tool for predicting protein-DNA binding specificity from structural data, utilizing graph neural networks.",
      "domains": [
        "G2",
        "G2-04",
        "Biology"
      ],
      "subtask_category": [
        "binding_prediction",
        "structure_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/timkartar/DeepPBS",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "protein-dna",
        "geometric-deep-learning",
        "bioinformatics"
      ],
      "id": 941
    },
    {
      "name": "GCN",
      "one_line_profile": "Implementation of Graph Convolutional Networks in TensorFlow",
      "detailed_description": "The original reference implementation of Graph Convolutional Networks (GCN) for semi-supervised classification on graph-structured data.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "node_classification",
        "graph_embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tkipf/gcn",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gcn",
        "graph-neural-networks",
        "tensorflow"
      ],
      "id": 942
    },
    {
      "name": "keras-gcn",
      "one_line_profile": "Keras implementation of Graph Convolutional Networks",
      "detailed_description": "A Keras-based library for implementing Graph Convolutional Networks, facilitating easy integration into Keras workflows.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "node_classification",
        "graph_embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tkipf/keras-gcn",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "keras",
        "gcn",
        "deep-learning"
      ],
      "id": 943
    },
    {
      "name": "pygcn",
      "one_line_profile": "Graph Convolutional Networks in PyTorch",
      "detailed_description": "A PyTorch implementation of Graph Convolutional Networks, widely used as a baseline and building block for GNN research.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "node_classification",
        "graph_embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tkipf/pygcn",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "gcn",
        "graph-neural-networks"
      ],
      "id": 944
    },
    {
      "name": "relational-gcn",
      "one_line_profile": "Relational Graph Convolutional Networks (R-GCN)",
      "detailed_description": "Implementation of Relational Graph Convolutional Networks, designed specifically for modeling relational data and knowledge graphs.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "link_prediction",
        "entity_classification",
        "relational_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tkipf/relational-gcn",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rgcn",
        "knowledge-graph",
        "link-prediction"
      ],
      "id": 945
    },
    {
      "name": "CompGCN-DGL",
      "one_line_profile": "Implementation of CompGCN in Pytorch and DGL",
      "detailed_description": "A DGL-based implementation of Composition-based Multi-Relational Graph Convolutional Networks (CompGCN) for knowledge graph embedding.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "knowledge_embedding",
        "link_prediction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/toooooodo/CompGCN-DGL",
      "help_website": [],
      "license": null,
      "tags": [
        "compgcn",
        "dgl",
        "kge"
      ],
      "id": 946
    },
    {
      "name": "AnalyzeKGE",
      "one_line_profile": "Analyzing knowledge graph embedding methods",
      "detailed_description": "A toolkit for analyzing and comparing various knowledge graph embedding methods including TransE, DistMult, and others.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "model_analysis",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tranhungnghiep/AnalyzeKGE",
      "help_website": [],
      "license": null,
      "tags": [
        "kge",
        "analysis",
        "benchmarking"
      ],
      "id": 947
    },
    {
      "name": "MEIM-KGE",
      "one_line_profile": "Multi-partition Embedding Interaction for KGE",
      "detailed_description": "Implementation of the MEIM model and other KGE baselines (RotatE, ComplEx, etc.) for efficient and expressive link prediction.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "link_prediction",
        "knowledge_embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tranhungnghiep/MEIM-KGE",
      "help_website": [],
      "license": null,
      "tags": [
        "kge",
        "link-prediction",
        "interaction-models"
      ],
      "id": 948
    },
    {
      "name": "CoDEx",
      "one_line_profile": "Knowledge graph Completion Datasets Extracted from Wikidata and Wikipedia",
      "detailed_description": "A set of high-quality knowledge graph completion datasets extracted from Wikidata and Wikipedia, serving as benchmarks for KGE models.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "dataset",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/tsafavi/codex",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dataset",
        "wikidata",
        "kg-completion"
      ],
      "id": 949
    },
    {
      "name": "Traffic-Benchmark",
      "one_line_profile": "Benchmark and Solution for Traffic Prediction with Graph Neural Networks",
      "detailed_description": "A benchmark suite and solution implementation for traffic prediction using Dynamic Graph Convolutional Recurrent Networks, applicable to urban science and complex systems modeling.",
      "domains": [
        "G2",
        "G2-04",
        "Urban Science"
      ],
      "subtask_category": [
        "traffic_prediction",
        "dynamics_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tsinghua-fib-lab/Traffic-Benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "traffic-prediction",
        "gnn",
        "urban-computing"
      ],
      "id": 950
    },
    {
      "name": "complex",
      "one_line_profile": "Complex Embeddings for Simple Link Prediction",
      "detailed_description": "Source code for Complex Embeddings (ComplEx), a state-of-the-art model for knowledge graph completion using complex-valued embeddings.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "link_prediction",
        "knowledge_embedding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ttrouill/complex",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "complex",
        "kge",
        "tensor-factorization"
      ],
      "id": 951
    },
    {
      "name": "cgcnn",
      "one_line_profile": "Crystal graph convolutional neural networks for predicting material properties",
      "detailed_description": "A machine learning tool that uses graph convolutional neural networks to predict material properties directly from the crystal structure.",
      "domains": [
        "G2",
        "G2-04",
        "Materials Science"
      ],
      "subtask_category": [
        "property_prediction",
        "structure_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/txie-93/cgcnn",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "materials-science",
        "crystal-structure",
        "gnn"
      ],
      "id": 952
    },
    {
      "name": "GraphTrans",
      "one_line_profile": "Graph Neural Networks with Global Attention",
      "detailed_description": "Implementation of Graph Transformer, a GNN variant that captures long-range context using global attention mechanisms.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_learning",
        "attention_mechanism"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ucbrise/graphtrans",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "graph-transformer",
        "attention",
        "gnn"
      ],
      "id": 953
    },
    {
      "name": "low-rank-logic",
      "one_line_profile": "Injecting Logical Background Knowledge into Embeddings",
      "detailed_description": "A tool for relation extraction that combines matrix factorization with logical background knowledge to improve embedding quality.",
      "domains": [
        "G2",
        "G2-04",
        "NLP"
      ],
      "subtask_category": [
        "relation_extraction",
        "logic_injection"
      ],
      "application_level": "solver",
      "primary_language": "Scala",
      "repo_url": "https://github.com/uclnlp/low-rank-logic",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "logic",
        "relation-extraction",
        "embeddings"
      ],
      "id": 954
    },
    {
      "name": "UrbanKGent",
      "one_line_profile": "Urban knowledge graph construction agent",
      "detailed_description": "An agent-based tool for constructing urban knowledge graphs, facilitating the modeling of complex urban systems.",
      "domains": [
        "G2",
        "G2-04",
        "Urban Science"
      ],
      "subtask_category": [
        "kg_construction",
        "urban_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/usail-hkust/UrbanKGent",
      "help_website": [],
      "license": null,
      "tags": [
        "urban-computing",
        "knowledge-graph",
        "agent"
      ],
      "id": 955
    },
    {
      "name": "Keras-DGL",
      "one_line_profile": "Keras Deep Learning on Graphs",
      "detailed_description": "A library providing Keras layers for deep learning on graphs, enabling easy implementation of GNNs within the Keras framework.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_learning",
        "model_building"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/vermaMachineLearning/keras-deep-graph-learning",
      "help_website": [
        "http://vermaMachineLearning.github.io/keras-deep-graph-learning"
      ],
      "license": "MIT",
      "tags": [
        "keras",
        "gnn",
        "deep-learning"
      ],
      "id": 956
    },
    {
      "name": "torchlensmaker",
      "one_line_profile": "Differentiable geometric optics in PyTorch",
      "detailed_description": "A tool for designing optical systems using differentiable geometric optics and optimization in PyTorch.",
      "domains": [
        "Physics",
        "Optics"
      ],
      "subtask_category": [
        "optical_design",
        "simulation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/victorpoughon/torchlensmaker",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "optics",
        "differentiable-programming",
        "physics"
      ],
      "id": 957
    },
    {
      "name": "GNN-LSPE",
      "one_line_profile": "Graph Neural Networks with Learnable Structural and Positional Representations",
      "detailed_description": "Implementation of GNNs that explicitly learn structural and positional encodings to improve graph representation power.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "graph_learning",
        "positional_encoding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/vijaydwivedi75/gnn-lspe",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gnn",
        "positional-encoding",
        "graph-transformer"
      ],
      "id": 958
    },
    {
      "name": "datasets_knowledge_embedding",
      "one_line_profile": "Datasets for Knowledge Graph Completion with textual information",
      "detailed_description": "A collection of datasets for knowledge graph completion tasks, enriched with textual descriptions for entities.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "dataset",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/villmow/datasets_knowledge_embedding",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dataset",
        "kge",
        "text-enhanced"
      ],
      "id": 959
    },
    {
      "name": "JMAC",
      "one_line_profile": "Joint Multilingual Knowledge Graph Completion and Alignment",
      "detailed_description": "A tool for jointly performing knowledge graph completion and alignment across multiple languages.",
      "domains": [
        "G2",
        "G2-04",
        "NLP"
      ],
      "subtask_category": [
        "kg_alignment",
        "kg_completion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/vinhsuhi/JMAC",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multilingual",
        "kg-alignment",
        "completion"
      ],
      "id": 960
    },
    {
      "name": "Graphiler",
      "one_line_profile": "Compiler stack for optimizing Graph Neural Network execution",
      "detailed_description": "A compiler stack built on top of DGL and TorchScript that compiles GNNs defined using user-defined functions (UDFs) into efficient execution plans, accelerating inference and training for graph-based scientific models.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "inference",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/xiezhq-hermann/graphiler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gnn",
        "compiler",
        "optimization",
        "dgl"
      ],
      "id": 961
    },
    {
      "name": "NeuralKG",
      "one_line_profile": "Open-source library for knowledge graph representation learning",
      "detailed_description": "A comprehensive Python library for knowledge graph representation learning (KGRL) that implements various methods including conventional KGEs, GNN-based models, and Transformer-based models. It provides a unified framework for training, evaluation, and hyperparameter tuning on standard datasets, supporting scientific knowledge discovery tasks.",
      "domains": [
        "G2",
        "G2-04"
      ],
      "subtask_category": [
        "representation_learning",
        "link_prediction",
        "knowledge_graph_embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjukg/NeuralKG",
      "help_website": [
        "https://zjukg.github.io/NeuralKG/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "representation-learning",
        "gnn",
        "kge",
        "pytorch"
      ],
      "id": 962
    },
    {
      "name": "PapersChat",
      "one_line_profile": "Agentic AI tool for querying and analyzing scientific papers from ArXiv and PubMed",
      "detailed_description": "An agentic AI application designed to assist researchers in literature review and information extraction. It allows users to chat with their local papers and automatically retrieves and incorporates information from scientific databases like ArXiv and PubMed, facilitating evidence-based research.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "literature_review",
        "information_extraction"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/AstraBert/PapersChat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "arxiv",
        "pubmed",
        "literature-review",
        "scientific-papers"
      ],
      "id": 963
    },
    {
      "name": "Pyhaystack",
      "one_line_profile": "Python library to connect to Project Haystack for building science data",
      "detailed_description": "A module that allows Python programs to connect to a Haystack server (Project Haystack), facilitating the retrieval and management of semantic data from building automation systems (Niagara, Skyspark, etc.) for energy and operational research.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "data_acquisition",
        "semantic_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChristianTremblay/pyhaystack",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "project-haystack",
        "building-automation",
        "iot",
        "semantic-data"
      ],
      "id": 964
    },
    {
      "name": "Rankify",
      "one_line_profile": "Comprehensive benchmarking toolkit for retrieval and RAG",
      "detailed_description": "A Python toolkit integrating multiple pre-retrieved benchmark datasets, retrieval techniques, and re-ranking models to evaluate and optimize Retrieval-Augmented Generation (RAG) pipelines for scientific and general information retrieval tasks.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "benchmarking",
        "retrieval",
        "ranking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DataScienceUIBK/Rankify",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "benchmarking",
        "information-retrieval",
        "re-ranking"
      ],
      "id": 965
    },
    {
      "name": "XRAG",
      "one_line_profile": "Benchmarking framework for RAG component modules",
      "detailed_description": "A framework dedicated to examining and benchmarking the core component modules of Advanced Retrieval-Augmented Generation systems, enabling researchers to evaluate the performance of different RAG strategies.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "benchmarking",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DocAILab/XRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "benchmarking",
        "evaluation",
        "nlp"
      ],
      "id": 966
    },
    {
      "name": "GraphRAG SDK",
      "one_line_profile": "SDK for building GraphRAG applications with FalkorDB",
      "detailed_description": "A software development kit designed to facilitate the creation of Graph Retrieval-Augmented Generation (GraphRAG) applications, leveraging knowledge graphs to enhance LLM reasoning and evidence retrieval.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "rag_implementation",
        "kg_construction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/FalkorDB/GraphRAG-SDK",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graphrag",
        "knowledge-graph",
        "sdk",
        "llm"
      ],
      "id": 967
    },
    {
      "name": "paper-qa",
      "one_line_profile": "High-accuracy RAG agent for answering questions from scientific documents with citations",
      "detailed_description": "A library that uses Retrieval Augmented Generation (RAG) to answer questions from scientific literature (PDFs/text) with verifiable citations. It manages document parsing, embedding, and answer generation with evidence grounding.",
      "domains": [
        "G2",
        "G2-05",
        "Scientific Literature"
      ],
      "subtask_category": [
        "literature_mining",
        "question_answering",
        "citation_verification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Future-House/paper-qa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "scientific-qa",
        "citation-support"
      ],
      "id": 968
    },
    {
      "name": "FacTool",
      "one_line_profile": "Framework for detecting factual errors in generative AI outputs",
      "detailed_description": "A tool designed to detect factuality in texts generated by Large Language Models. It supports various domains including knowledge-based QA and scientific code generation, helping to verify the reliability of AI-generated content.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "fact_checking",
        "hallucination_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/GAIR-NLP/factool",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "factuality-detection",
        "llm-evaluation",
        "hallucination"
      ],
      "id": 969
    },
    {
      "name": "FEAT",
      "one_line_profile": "Factcheck Explorer Analysis Tool for visualizing fact-checking data",
      "detailed_description": "A tool designed to facilitate the exploration, analysis, and visualization of fact-checking data, aiding researchers in understanding misinformation trends and evidence chains.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "data_analysis",
        "visualization",
        "fact_checking"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/GONZOsint/FEAT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fact-checking",
        "visualization",
        "osint"
      ],
      "id": 970
    },
    {
      "name": "Simba",
      "one_line_profile": "Portable Knowledge Management System for RAG integration",
      "detailed_description": "A knowledge management system designed to integrate with Retrieval-Augmented Generation (RAG) systems. It handles parsing, chunking, and indexing of documents to support evidence-based retrieval tasks.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "knowledge_management",
        "rag_infrastructure",
        "document_processing"
      ],
      "application_level": "system",
      "primary_language": "Python",
      "repo_url": "https://github.com/GitHamza0206/simba",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kms",
        "rag",
        "vector-database"
      ],
      "id": 971
    },
    {
      "name": "GraphRAG-Benchmark",
      "one_line_profile": "Benchmark suite for evaluating GraphRAG models",
      "detailed_description": "A comprehensive benchmark and dataset toolkit for evaluating Graph-based Retrieval-Augmented Generation models, providing metrics and evaluation pipelines for knowledge-intensive tasks.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "benchmarking",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/GraphRAG-Bench/GraphRAG-Benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "graphrag",
        "evaluation"
      ],
      "id": 972
    },
    {
      "name": "LightRAG",
      "one_line_profile": "Simple and fast Retrieval-Augmented Generation framework",
      "detailed_description": "A lightweight and efficient framework for building Retrieval-Augmented Generation systems. It optimizes the retrieval and generation pipeline for speed and simplicity, suitable for building scientific knowledge assistants.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "retrieval",
        "generation",
        "rag_pipeline"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUDS/LightRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "llm",
        "retrieval"
      ],
      "id": 973
    },
    {
      "name": "AutoSchemaKG",
      "one_line_profile": "Framework for automatic knowledge graph construction and schema generation",
      "detailed_description": "A tool for automatically constructing knowledge graphs that combines schema generation via conceptualization. It helps in structuring unstructured scientific data into organized knowledge graphs.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "kg_construction",
        "schema_generation",
        "conceptualization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUST-KnowComp/AutoSchemaKG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "schema-induction",
        "ie"
      ],
      "id": 974
    },
    {
      "name": "CRUD-RAG",
      "one_line_profile": "Benchmark for evaluating RAG systems on CRUD capabilities",
      "detailed_description": "A comprehensive benchmark suite for evaluating Retrieval-Augmented Generation systems, specifically focusing on Create, Read, Update, and Delete operations in knowledge retrieval contexts.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "benchmarking",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IAAR-Shanghai/CRUD_RAG",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "rag",
        "evaluation"
      ],
      "id": 975
    },
    {
      "name": "Prophecies",
      "one_line_profile": "Self-hosted data validation platform for fact checking",
      "detailed_description": "A platform designed for labor-intensive fact-checking and data validation. It allows users to verify claims against evidence, managing the workflow of investigative journalism and scientific verification.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "fact_checking",
        "data_validation",
        "workflow_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ICIJ/prophecies",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "fact-checking",
        "validation",
        "journalism"
      ],
      "id": 976
    },
    {
      "name": "Medical-Graph-RAG",
      "one_line_profile": "Graph RAG System for Evidence-based Medical Information Retrieval",
      "detailed_description": "A specialized RAG system that utilizes knowledge graphs to enhance medical information retrieval. It focuses on providing evidence-based answers for medical queries by grounding generation in structured medical knowledge.",
      "domains": [
        "G2",
        "G2-05",
        "Medical"
      ],
      "subtask_category": [
        "medical_qa",
        "information_retrieval",
        "evidence_grounding"
      ],
      "application_level": "system",
      "primary_language": "Python",
      "repo_url": "https://github.com/ImprintLab/Medical-Graph-RAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-ai",
        "graph-rag",
        "healthcare"
      ],
      "id": 977
    },
    {
      "name": "RAG-FiT",
      "one_line_profile": "Framework for fine-tuning LLMs for RAG tasks",
      "detailed_description": "A framework designed to enhance Large Language Models for Retrieval-Augmented Generation tasks through fine-tuning. It provides tools to optimize LLMs for better context utilization and answer generation.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "model_finetuning",
        "rag_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IntelLabs/RAG-FiT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fine-tuning",
        "rag",
        "llm-optimization"
      ],
      "id": 978
    },
    {
      "name": "MeDuSA",
      "one_line_profile": "Fine-resolution cellular deconvolution method for bulk RNA-seq",
      "detailed_description": "A bioinformatics tool that leverages scRNA-seq data as a reference to estimate cell-state abundance in bulk RNA-seq data with high resolution.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "cellular_deconvolution",
        "rna-seq_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/JianYang-Lab/MeDuSA",
      "help_website": [],
      "license": null,
      "tags": [
        "bioinformatics",
        "deconvolution",
        "scrna-seq"
      ],
      "id": 979
    },
    {
      "name": "Entity-Linking",
      "one_line_profile": "Named Entity Recognition and Linking tool for mapping text entities to knowledge bases",
      "detailed_description": "A Python implementation for Entity Linking, which identifies named entities in text and maps them to unique entities in a specific knowledge base. It includes modules for Named Entity Recognition (NER) and disambiguation.",
      "domains": [
        "G2",
        "Sci Knowledge/KG"
      ],
      "subtask_category": [
        "entity_linking",
        "named_entity_recognition",
        "disambiguation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Junshuai-Song/Entity-Linking",
      "help_website": [],
      "license": null,
      "tags": [
        "entity-linking",
        "ner",
        "knowledge-graph",
        "nlp"
      ],
      "id": 980
    },
    {
      "name": "RasterSmith",
      "one_line_profile": "Preprocessing tool for NASA Earth observing satellite data products",
      "detailed_description": "A package to preprocess different NASA Earth observing satellite data products into common resolution, spatial reference, and format for easy analysis and processing across sensors.",
      "domains": [
        "Earth Science",
        "Remote Sensing"
      ],
      "subtask_category": [
        "data_preprocessing",
        "normalization",
        "satellite_imaging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KMarkert/rastersmith",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "remote-sensing",
        "nasa",
        "satellite-data",
        "preprocessing"
      ],
      "id": 981
    },
    {
      "name": "LettuceDetect",
      "one_line_profile": "Hallucination detection framework for RAG applications",
      "detailed_description": "A framework designed to detect hallucinations in Retrieval-Augmented Generation (RAG) applications, enhancing the reliability and trustworthiness of generated content.",
      "domains": [
        "G2-05",
        "Sci Knowledge/KG"
      ],
      "subtask_category": [
        "hallucination_detection",
        "quality_control",
        "rag_evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/KRLabsOrg/LettuceDetect",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "hallucination-detection",
        "llm",
        "trustworthiness"
      ],
      "id": 982
    },
    {
      "name": "xmc.dspy",
      "one_line_profile": "In-Context Learning library for eXtreme Multi-Label Classification (XMC)",
      "detailed_description": "A tool leveraging DSPy for In-Context Learning to perform eXtreme Multi-Label Classification (XMC) using only a handful of examples.",
      "domains": [
        "Machine Learning",
        "NLP"
      ],
      "subtask_category": [
        "classification",
        "in_context_learning",
        "extreme_multi_label_classification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KarelDO/xmc.dspy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dspy",
        "xmc",
        "classification",
        "few-shot-learning"
      ],
      "id": 983
    },
    {
      "name": "VAP",
      "one_line_profile": "Visual noise generation for mitigating object hallucinations in LVMs",
      "detailed_description": "Implementation of 'Poison as Cure', using visual noise to mitigate object hallucinations in Large Vision-Language Models (LVMs).",
      "domains": [
        "Computer Vision",
        "G2-05"
      ],
      "subtask_category": [
        "hallucination_mitigation",
        "visual_generation",
        "model_robustness"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/KejiaZhang-Robust/VAP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "lvm",
        "visual-noise",
        "robustness"
      ],
      "id": 984
    },
    {
      "name": "LeanRAG",
      "one_line_profile": "Knowledge-Graph-Based Generation with Semantic Aggregation",
      "detailed_description": "A framework for Knowledge-Graph-Based Generation that utilizes semantic aggregation and hierarchical retrieval to enhance RAG performance.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "rag",
        "knowledge_graph_retrieval",
        "semantic_aggregation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/KnowledgeXLab/LeanRAG",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "knowledge-graph",
        "retrieval",
        "generation"
      ],
      "id": 985
    },
    {
      "name": "RAKG",
      "one_line_profile": "Document-level Retrieval Augmented Knowledge Graph Construction",
      "detailed_description": "A tool for constructing Knowledge Graphs using document-level retrieval augmentation, facilitating better structured knowledge extraction from texts.",
      "domains": [
        "G2",
        "Sci Knowledge/KG"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "retrieval_augmented_generation",
        "information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/KnowledgeXLab/RAKG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "construction",
        "rag",
        "nlp"
      ],
      "id": 986
    },
    {
      "name": "Graph-R1",
      "one_line_profile": "Agentic GraphRAG Framework via End-to-end Reinforcement Learning",
      "detailed_description": "A framework implementing Agentic GraphRAG using end-to-end reinforcement learning to optimize retrieval and generation processes over graph structures.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "graph_rag",
        "reinforcement_learning",
        "agentic_framework"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/LHRLAB/Graph-R1",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-rag",
        "reinforcement-learning",
        "agents",
        "knowledge-graph"
      ],
      "id": 987
    },
    {
      "name": "HyperGraphRAG",
      "one_line_profile": "Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation",
      "detailed_description": "Official implementation of HyperGraphRAG, utilizing hypergraph-structured knowledge representations to enhance retrieval-augmented generation capabilities.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "graph_rag",
        "hypergraph_learning",
        "knowledge_representation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LHRLAB/HyperGraphRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hypergraph",
        "rag",
        "knowledge-graph",
        "neurips-2025"
      ],
      "id": 988
    },
    {
      "name": "Platform War Public",
      "one_line_profile": "Multi-agent debate simulation framework using GraphRAG",
      "detailed_description": "A chatbot/GraphRAG framework that creates multi-llm-agents from social platform user comments to simulate debates on specific topics, useful for social science simulation and analysis.",
      "domains": [
        "G2",
        "Social Science Simulation"
      ],
      "subtask_category": [
        "agent_simulation",
        "graph_rag",
        "debate_modeling"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/LYiHub/platform-war-public",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "graph-rag",
        "simulation",
        "debate"
      ],
      "id": 989
    },
    {
      "name": "AGLA",
      "one_line_profile": "Mitigating Object Hallucinations in Large Vision-Language Models",
      "detailed_description": "Implementation of Assembly of Global and Local Attention (AGLA) to mitigate object hallucinations in Large Vision-Language Models (LVLMs).",
      "domains": [
        "Computer Vision",
        "G2-05"
      ],
      "subtask_category": [
        "hallucination_mitigation",
        "attention_mechanism",
        "model_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lackel/AGLA",
      "help_website": [],
      "license": null,
      "tags": [
        "hallucination",
        "lvlm",
        "attention",
        "cvpr-2025"
      ],
      "id": 990
    },
    {
      "name": "MiniCheck",
      "one_line_profile": "Efficient Fact-Checking tool for LLMs on Grounding Documents",
      "detailed_description": "A tool for efficient fact-checking of Large Language Models (LLMs) against grounding documents, ensuring the accuracy and reliability of generated text.",
      "domains": [
        "G2-05",
        "NLP"
      ],
      "subtask_category": [
        "fact_checking",
        "grounding",
        "verification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Liyan06/MiniCheck",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fact-checking",
        "grounding",
        "llm",
        "emnlp-2024"
      ],
      "id": 991
    },
    {
      "name": "spacyfishing",
      "one_line_profile": "spaCy wrapper for Entity-Fishing named entity disambiguation",
      "detailed_description": "A spaCy wrapper component for Entity-Fishing, enabling named entity disambiguation and linking to Wikidata within spaCy pipelines.",
      "domains": [
        "G2",
        "Sci Knowledge/KG"
      ],
      "subtask_category": [
        "entity_linking",
        "disambiguation",
        "knowledge_base_mapping"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lucaterre/spacyfishing",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "spacy",
        "entity-linking",
        "wikidata",
        "nlp"
      ],
      "id": 992
    },
    {
      "name": "context-cite",
      "one_line_profile": "Attribution tool for citing LLM generated statements to in-context information",
      "detailed_description": "A tool to attribute or cite statements generated by Large Language Models (LLMs) back to the source information provided in the context, enhancing interpretability and grounding.",
      "domains": [
        "G2-05",
        "NLP"
      ],
      "subtask_category": [
        "citation_generation",
        "attribution",
        "grounding"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/MadryLab/context-cite",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "citation",
        "attribution",
        "llm",
        "interpretability"
      ],
      "id": 993
    },
    {
      "name": "AutoRAG",
      "one_line_profile": "AutoML-style framework for RAG evaluation and optimization",
      "detailed_description": "An open-source framework for Retrieval-Augmented Generation (RAG) evaluation and optimization, automating the process of finding the best RAG pipeline configurations.",
      "domains": [
        "G2-05",
        "AutoML"
      ],
      "subtask_category": [
        "rag_optimization",
        "evaluation",
        "pipeline_search"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "automl",
        "optimization",
        "evaluation"
      ],
      "id": 994
    },
    {
      "name": "SciQAG",
      "one_line_profile": "Framework for generating science question-answer pairs from literature",
      "detailed_description": "A framework for automatically generating high-quality science question-answer pairs from a large corpus of scientific literature using large language models, useful for dataset creation and training.",
      "domains": [
        "Scientific Data Generation",
        "NLP"
      ],
      "subtask_category": [
        "data_generation",
        "qa_generation",
        "scientific_literature_mining"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/MasterAI-EAM/SciQAG",
      "help_website": [],
      "license": null,
      "tags": [
        "qa-generation",
        "scientific-literature",
        "llm",
        "dataset-creation"
      ],
      "id": 995
    },
    {
      "name": "HSA-DPO",
      "one_line_profile": "Hallucination detection and mitigation in LVLMs via fine-grained AI feedback",
      "detailed_description": "Implementation of HSA-DPO, a method for detecting and mitigating hallucinations in Large Vision-Language Models (LVLMs) using fine-grained AI feedback.",
      "domains": [
        "Computer Vision",
        "G2-05"
      ],
      "subtask_category": [
        "hallucination_mitigation",
        "dpo",
        "feedback_learning"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/Mr-Loevan/HSA-DPO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "lvlm",
        "dpo",
        "aaai-2025"
      ],
      "id": 996
    },
    {
      "name": "context-aware-rag",
      "one_line_profile": "Library for Knowledge Graph ingestion and retrieval in RAG",
      "detailed_description": "A Context-Aware RAG library designed for Knowledge Graph ingestion and retrieval functions, facilitating the integration of structured knowledge into RAG pipelines.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "knowledge_graph_ingestion",
        "retrieval",
        "rag"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/context-aware-rag",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "knowledge-graph",
        "nvidia",
        "retrieval"
      ],
      "id": 997
    },
    {
      "name": "GraphragTest",
      "one_line_profile": "Utility to enable GraphRAG with non-OpenAI models (Ollama, etc.)",
      "detailed_description": "A solution/wrapper that allows the use of the GraphRAG framework with local and other non-GPT large models (like Ollama, Qwen, etc.), facilitating broader access to GraphRAG capabilities.",
      "domains": [
        "G2-05",
        "Sci Knowledge/KG"
      ],
      "subtask_category": [
        "model_adaptation",
        "graph_rag",
        "inference_support"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NanGePlus/GraphragTest",
      "help_website": [],
      "license": null,
      "tags": [
        "graphrag",
        "ollama",
        "local-llm",
        "adaptation"
      ],
      "id": 998
    },
    {
      "name": "Controllable-RAG-Agent",
      "one_line_profile": "Advanced RAG solution for complex QA using graph-based algorithms",
      "detailed_description": "An advanced Retrieval-Augmented Generation (RAG) solution designed for complex question answering, utilizing sophisticated graph-based algorithms to handle intricate queries.",
      "domains": [
        "G2-05",
        "Sci Knowledge/KG"
      ],
      "subtask_category": [
        "complex_qa",
        "graph_rag",
        "agentic_rag"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/NirDiamant/Controllable-RAG-Agent",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "graph-algorithm",
        "agent",
        "qa"
      ],
      "id": 999
    },
    {
      "name": "HippoRAG",
      "one_line_profile": "Neurobiologically inspired RAG framework for long-term knowledge integration",
      "detailed_description": "A novel Retrieval-Augmented Generation (RAG) framework inspired by human long-term memory (hippocampal indexing theory). It enables Large Language Models (LLMs) to continuously integrate knowledge across external documents using Knowledge Graphs and Personalized PageRank, specifically addressing the challenge of multi-hop reasoning and knowledge integration in scientific and general domains.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "knowledge_integration",
        "rag",
        "graph_reasoning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/OSU-NLP-Group/HippoRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "knowledge-graph",
        "llm",
        "pagerank",
        "memory-augmented"
      ],
      "id": 1000
    },
    {
      "name": "RagView",
      "one_line_profile": "Unified evaluation platform for RAG methods on custom datasets",
      "detailed_description": "A unified evaluation platform designed to benchmark different Retrieval-Augmented Generation (RAG) methods on user-specific data. It addresses the limitation that SOTA results are often dataset-dependent, providing a tool for researchers to evaluate and select the best RAG strategies for their specific scientific or domain knowledge bases.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking",
        "rag"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/RagView/RagView",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "evaluation",
        "benchmark",
        "retrieval"
      ],
      "id": 1001
    },
    {
      "name": "Falcon 2.0",
      "one_line_profile": "Joint entity and relation linking tool over Wikidata",
      "detailed_description": "A rule-based tool for joint entity and relation linking over Wikidata. It performs fundamental tasks for Knowledge Graph construction and grounding by mapping textual mentions to Wikidata entities and relations, essential for scientific knowledge extraction and normalization.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "entity_linking",
        "relation_linking",
        "knowledge_graph_construction"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/SDM-TIB/falcon2.0",
      "help_website": [
        "https://labs.tib.eu/falcon/"
      ],
      "license": "MIT",
      "tags": [
        "entity-linking",
        "relation-linking",
        "wikidata",
        "nlp",
        "knowledge-graph"
      ],
      "id": 1002
    },
    {
      "name": "R2R",
      "one_line_profile": "Production-ready agentic RAG system for scientific knowledge retrieval",
      "detailed_description": "A comprehensive, production-ready Retrieval-Augmented Generation (RAG) system developed by SciPhi-AI. It provides a RESTful API for agentic retrieval, designed to make Large Language Models (LLMs) accessible and grounded for scientific applications. It supports complex ingestion, retrieval, and generation pipelines suitable for scientific knowledge bases.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "rag",
        "knowledge_retrieval",
        "pipeline_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/SciPhi-AI/R2R",
      "help_website": [
        "https://r2r-docs.sciphi.ai/"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "agentic-ai",
        "retrieval",
        "llm",
        "scientific-knowledge"
      ],
      "id": 1003
    },
    {
      "name": "EmoLLM",
      "one_line_profile": "Comprehensive LLM framework for mental health counseling and analysis",
      "detailed_description": "A specialized Large Language Model framework for mental health, supporting pre-training, post-training, evaluation, and RAG. It serves as a scientific modeling tool for psychology and mental health research, enabling the development of AI agents for counseling and patient analysis.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "scientific_modeling",
        "inference"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/SmartFlowAI/EmoLLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mental-health",
        "llm",
        "psychology",
        "rag"
      ],
      "id": 1004
    },
    {
      "name": "LongCite",
      "one_line_profile": "Tool enabling LLMs to generate fine-grained citations for evidence-based QA",
      "detailed_description": "A framework designed to enhance Large Language Models with the ability to generate precise, sentence-level citations in long-context question answering. This directly supports the 'Evidence Chain' requirement in scientific RAG systems by ensuring generated claims are grounded in source texts.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "alignment",
        "inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/THUDM/LongCite",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "citation-generation",
        "evidence-chain",
        "rag",
        "long-context"
      ],
      "id": 1005
    },
    {
      "name": "Equi7Grid",
      "one_line_profile": "Spatial reference system library for high-resolution global raster data",
      "detailed_description": "A Python implementation of the Equi7Grid spatial reference system, optimized for handling global high-resolution raster data in Earth observation and remote sensing. It facilitates scientific data processing by providing a consistent grid system for geospatial analysis.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "scientific_data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TUW-GEO/Equi7Grid",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "geospatial",
        "remote-sensing",
        "grid-system",
        "earth-science"
      ],
      "id": 1006
    },
    {
      "name": "bbw",
      "one_line_profile": "Library for linking CSV data to Wikibase instances",
      "detailed_description": "A Python library designed for entity linking, typing, and relation extraction by matching CSV data to Wikibase instances (like Wikidata). It supports the construction and normalization of scientific knowledge graphs by aligning tabular data with established knowledge bases.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "scientific_data_processing",
        "alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/UB-Mannheim/bbw",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "entity-linking",
        "wikibase",
        "knowledge-graph",
        "data-alignment"
      ],
      "id": 1007
    },
    {
      "name": "spacyopentapioca",
      "one_line_profile": "SpaCy wrapper for OpenTapioca entity linking on Wikidata",
      "detailed_description": "A pipeline component for spaCy that integrates OpenTapioca for named entity linking against Wikidata. This tool facilitates the normalization of entities in scientific text processing by linking mentions to unique identifiers in a large-scale knowledge graph.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "scientific_data_processing",
        "alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/UB-Mannheim/spacyopentapioca",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "entity-linking",
        "spacy",
        "wikidata",
        "nlp"
      ],
      "id": 1008
    },
    {
      "name": "Cyber Huatuo (cyber-doctor)",
      "one_line_profile": "Medical agent framework based on LLM and Knowledge Graph",
      "detailed_description": "A multimodal agent framework ('Cyber Huatuo') that integrates Large Language Models with medical knowledge graphs and databases. It functions as a scientific inference tool for medical diagnosis, case analysis, and professional QA, facilitating the deployment of AI in healthcare research and application.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "scientific_inference",
        "scientific_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Warma10032/cyber-doctor",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "medical-ai",
        "knowledge-graph",
        "diagnosis",
        "agent"
      ],
      "id": 1009
    },
    {
      "name": "G-Retriever",
      "one_line_profile": "Graph-based Retrieval-Augmented Generation solver for textual graph understanding",
      "detailed_description": "An implementation of the G-Retriever method for Retrieval-Augmented Generation on textual graphs. It serves as a solver for questioning and answering over graph-structured data, enabling scientific inference on complex relational datasets (e.g., knowledge graphs).",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "scientific_inference",
        "alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/XiaoxinHe/G-Retriever",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-rag",
        "knowledge-graph",
        "qa",
        "graph-neural-networks"
      ],
      "id": 1010
    },
    {
      "name": "singleCellHaystack",
      "one_line_profile": "Method for finding differentially active genes in single-cell transcriptome data",
      "detailed_description": "A package that uses Kullback-Leibler divergence to find genes with non-random spatial distributions in single-cell transcriptomics data, enabling the discovery of biologically significant markers without relying on clustering.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "differential_expression",
        "feature_selection"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/alexisvdb/singleCellHaystack",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "single-cell",
        "transcriptomics",
        "gene-expression",
        "bioinformatics"
      ],
      "id": 1011
    },
    {
      "name": "nel",
      "one_line_profile": "Entity linking framework for connecting text mentions to knowledge base entities",
      "detailed_description": "A framework for Named Entity Linking (NEL) that facilitates the grounding of textual entities into knowledge graphs, essential for constructing evidence chains.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "entity_linking",
        "normalization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/andychisholm/nel",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "entity-linking",
        "nlp",
        "knowledge-graph"
      ],
      "id": 1012
    },
    {
      "name": "ApeRAG",
      "one_line_profile": "Production-ready GraphRAG system with multi-modal indexing",
      "detailed_description": "A scalable Graph Retrieval-Augmented Generation (GraphRAG) system designed for production environments, supporting multi-modal indexing and agentic workflows for knowledge retrieval.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "retrieval",
        "evidence_alignment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/apecloud/ApeRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "graph-rag",
        "knowledge-retrieval"
      ],
      "id": 1013
    },
    {
      "name": "math-llm",
      "one_line_profile": "Framework for grounding LLM mathematical reasoning with proof assistants",
      "detailed_description": "A tool that interfaces Large Language Models with formal proof assistants to verify and ground mathematical reasoning, ensuring logical consistency in scientific inference.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "reasoning_verification",
        "formal_proof"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/atroyn/math-llm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "math",
        "formal-verification",
        "llm-grounding"
      ],
      "id": 1014
    },
    {
      "name": "graphrag-rs",
      "one_line_profile": "High-performance Rust implementation of GraphRAG",
      "detailed_description": "A Rust-based implementation of Graph Retrieval-Augmented Generation that builds knowledge graphs from documents for efficient natural language querying and entity extraction.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "retrieval",
        "knowledge_graph_construction"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/automataIA/graphrag-rs",
      "help_website": [],
      "license": null,
      "tags": [
        "rust",
        "graph-rag",
        "performance"
      ],
      "id": 1015
    },
    {
      "name": "graphrag-toolkit",
      "one_line_profile": "Toolkit for building graph-enhanced GenAI applications",
      "detailed_description": "A Python toolkit designed to facilitate the construction and deployment of GraphRAG applications, integrating knowledge graphs with generative AI for enhanced evidence retrieval.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "retrieval",
        "knowledge_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/awslabs/graphrag-toolkit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "graph-rag",
        "aws",
        "genai"
      ],
      "id": 1016
    },
    {
      "name": "geomodelgrids",
      "one_line_profile": "Library for geographic referenced grid-based earth models",
      "detailed_description": "A C++ library for handling geographic referenced grid-based models composed of blocks with different grid resolutions, used in geological and geophysical modeling.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "modeling",
        "spatial_analysis"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/baagaard-usgs/geomodelgrids",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "geology",
        "grid-modeling",
        "usgs"
      ],
      "id": 1017
    },
    {
      "name": "BEIR",
      "one_line_profile": "Heterogeneous benchmark for information retrieval evaluation",
      "detailed_description": "A comprehensive benchmark suite for evaluating information retrieval models across diverse datasets, essential for validating RAG and evidence retrieval systems.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/beir-cellar/beir",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "information-retrieval",
        "benchmark",
        "evaluation"
      ],
      "id": 1018
    },
    {
      "name": "cragg",
      "one_line_profile": "Statistical test for weak IV instruments in R",
      "detailed_description": "An R package implementing the Cragg-Donald test for weak instruments in instrumental variable regression, a specific statistical analysis tool.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "statistical_analysis",
        "hypothesis_testing"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/beniaminogreen/cragg",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "statistics",
        "econometrics",
        "r-package"
      ],
      "id": 1019
    },
    {
      "name": "TypeTruth",
      "one_line_profile": "Library for detecting AI-generated text",
      "detailed_description": "A tool to detect whether text is written by a human or AI, serving as a quality control mechanism for scientific content and evidence verification.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "quality_control",
        "content_verification"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/bhaskatripathi/TypeTruth",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ai-detection",
        "fact-checking",
        "nlp"
      ],
      "id": 1020
    },
    {
      "name": "VeritasGraph",
      "one_line_profile": "Enterprise-grade Graph RAG for verifiable attribution",
      "detailed_description": "A Graph RAG system focused on secure, on-premise AI with verifiable attribution, ensuring evidence chains are traceable and grounded.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "retrieval",
        "attribution"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/bibinprathap/VeritasGraph",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-rag",
        "attribution",
        "enterprise"
      ],
      "id": 1021
    },
    {
      "name": "BABILong",
      "one_line_profile": "Benchmark for long-context LLM evaluation",
      "detailed_description": "A benchmark designed to evaluate Large Language Models' ability to retrieve information from long contexts (needle-in-a-haystack), critical for assessing RAG capabilities.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/booydar/babilong",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "long-context",
        "benchmark"
      ],
      "id": 1022
    },
    {
      "name": "DATSR",
      "one_line_profile": "Reference-based Image Super-Resolution with Deformable Attention Transformer",
      "detailed_description": "An implementation of reference-based image super-resolution using deformable attention transformers, applicable for enhancing scientific imaging data.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "image_processing",
        "super_resolution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/caojiezhang/DATSR",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "computer-vision",
        "super-resolution",
        "transformer"
      ],
      "id": 1023
    },
    {
      "name": "LogicRAG",
      "one_line_profile": "Logic-enhanced Retrieval-Augmented Generation",
      "detailed_description": "A RAG framework that incorporates logical reasoning capabilities to improve the accuracy and reliability of generated answers, suitable for complex scientific query answering.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "retrieval",
        "reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chensyCN/LogicRAG",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "logic",
        "reasoning"
      ],
      "id": 1024
    },
    {
      "name": "dspy-neo4j-knowledge-graph",
      "one_line_profile": "Automated knowledge graph construction using DSPy and Neo4j",
      "detailed_description": "A tool that leverages DSPy and Neo4j to automate the construction of knowledge graphs from text, facilitating the creation of structured evidence bases.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/chrisammon3000/dspy-neo4j-knowledge-graph",
      "help_website": [],
      "license": null,
      "tags": [
        "neo4j",
        "dspy",
        "knowledge-graph"
      ],
      "id": 1025
    },
    {
      "name": "fast-graphrag",
      "one_line_profile": "Efficient and adaptive GraphRAG framework",
      "detailed_description": "A high-performance GraphRAG system that intelligently adapts to data and queries, optimizing the retrieval and generation process for knowledge-intensive tasks.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "retrieval",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/circlemind-ai/fast-graphrag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-rag",
        "efficiency",
        "retrieval"
      ],
      "id": 1026
    },
    {
      "name": "clef2018-factchecking",
      "one_line_profile": "Evaluation resources for automated fact checking",
      "detailed_description": "A collection of data, format checkers, and scoring scripts for the CLEF2018 Fact Checking Lab, used for benchmarking fact-checking and evidence verification systems.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "evaluation",
        "fact_checking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/clef2018-factchecking/clef2018-factchecking",
      "help_website": [],
      "license": null,
      "tags": [
        "fact-checking",
        "benchmark",
        "clef"
      ],
      "id": 1027
    },
    {
      "name": "TagMe",
      "one_line_profile": "Entity Linking system implementation",
      "detailed_description": "An implementation of the TagMe entity linking system, designed to identify meaningful substrings (spots) in an unstructured text and link them to pertinent Wikipedia pages.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "entity_linking",
        "entity_normalization"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/code1271968258/tagme",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "entity-linking",
        "wikipedia",
        "text-annotation"
      ],
      "id": 1028
    },
    {
      "name": "PBOH Entity Linking",
      "one_line_profile": "Probabilistic Bag-Of-Hyperlinks Model for Entity Linking",
      "detailed_description": "Source code for the Probabilistic Bag-Of-Hyperlinks (PBOH) model, a method for entity linking that leverages hyperlink information to disambiguate entities in text.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "entity_linking",
        "disambiguation"
      ],
      "application_level": "solver",
      "primary_language": "Scala",
      "repo_url": "https://github.com/dalab/pboh-entity-linking",
      "help_website": [
        "http://dl.acm.org/citation.cfm?id=2882988"
      ],
      "license": null,
      "tags": [
        "entity-linking",
        "probabilistic-model",
        "hyperlinks"
      ],
      "id": 1029
    },
    {
      "name": "Databricks Auto Data Linkage",
      "one_line_profile": "Automated entity resolution solution for data linkage",
      "detailed_description": "A solution accelerator for automated entity resolution and data linkage, providing tools for intra- and inter-data linking and de-duplication within a lakehouse environment.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "entity_resolution",
        "data_linkage",
        "deduplication"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/databricks-industry-solutions/auto-data-linkage",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "entity-resolution",
        "record-linkage",
        "databricks"
      ],
      "id": 1030
    },
    {
      "name": "DBpedia Lookup",
      "one_line_profile": "Entity retrieval service for DBpedia",
      "detailed_description": "A generic entity retrieval service for linked data, specifically designed to replicate the DBpedia Lookup service, allowing for searching and resolving DBpedia URIs from keywords.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "entity_retrieval",
        "lookup_service"
      ],
      "application_level": "service",
      "primary_language": "Java",
      "repo_url": "https://github.com/dbpedia/dbpedia-lookup",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dbpedia",
        "entity-retrieval",
        "linked-data",
        "semantic-web"
      ],
      "id": 1031
    },
    {
      "name": "Haystack",
      "one_line_profile": "Orchestration framework for RAG and semantic search",
      "detailed_description": "An open-source NLP framework for building search systems that work intelligently with large collections of documents. It provides the core components for Retrieval-Augmented Generation (RAG), Question Answering, and Semantic Search pipelines.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "retrieval_augmented_generation",
        "semantic_search",
        "question_answering"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepset-ai/haystack",
      "help_website": [
        "https://haystack.deepset.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "nlp",
        "semantic-search",
        "information-retrieval"
      ],
      "id": 1032
    },
    {
      "name": "Dexter",
      "one_line_profile": "Framework for entity linking algorithms",
      "detailed_description": "A framework that implements popular entity linking algorithms and provides tools to develop, evaluate, and benchmark new entity linking techniques.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "entity_linking",
        "benchmarking",
        "annotation"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/dexter/dexter",
      "help_website": [
        "http://dexter.isti.cnr.it/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "entity-linking",
        "framework",
        "evaluation"
      ],
      "id": 1033
    },
    {
      "name": "BLP",
      "one_line_profile": "Inductive Entity Representations from Text via Link Prediction",
      "detailed_description": "Implementation of a method for learning inductive entity representations from text by optimizing a link prediction objective, enabling entity linking and knowledge graph completion tasks.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "link_prediction",
        "entity_representation",
        "knowledge_graph_completion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dfdazac/blp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "link-prediction",
        "entity-representation",
        "knowledge-graph"
      ],
      "id": 1034
    },
    {
      "name": "MultiVerS",
      "one_line_profile": "Model and checkpoints for scientific claim verification against evidence",
      "detailed_description": "A system designed to predict the veracity of scientific claims by retrieving and reasoning over relevant evidence from scientific literature. It supports fact-checking and evidence-based verification tasks.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "claim_verification",
        "fact_checking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dwadden/multivers",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scientific-fact-checking",
        "claim-verification",
        "nlp"
      ],
      "id": 1035
    },
    {
      "name": "spaCy-entity-linker",
      "one_line_profile": "Pipeline for linking text entities to Wikidata knowledge graph",
      "detailed_description": "A spaCy pipeline extension that performs entity linking to Wikidata. It resolves named entities in text to their corresponding unique identifiers in the knowledge graph, facilitating entity normalization and grounding.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "entity_linking",
        "entity_normalization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/egerber/spaCy-entity-linker",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "entity-linking",
        "wikidata",
        "spacy-extension"
      ],
      "id": 1036
    },
    {
      "name": "CRAG",
      "one_line_profile": "De novo characterization of cell-free DNA fragmentation hotspots",
      "detailed_description": "A bioinformatics tool for analyzing cell-free DNA (cfDNA) fragmentation patterns. It identifies fragmentation hotspots which are crucial for understanding chromatin structure and gene regulation in liquid biopsy data.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "genomics_analysis",
        "fragmentation_analysis"
      ],
      "application_level": "solver",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/epifluidlab/CRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cfdna",
        "bioinformatics",
        "genomics"
      ],
      "id": 1037
    },
    {
      "name": "cragr",
      "one_line_profile": "R package for CRAG (Cell-free DNA fragmentation analysis)",
      "detailed_description": "The R implementation/package for the CRAG algorithm, facilitating the analysis of cell-free DNA fragmentation hotspots within the R statistical environment.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "genomics_analysis",
        "fragmentation_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/epifluidlab/cragr",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "r-package",
        "cfdna",
        "bioinformatics"
      ],
      "id": 1038
    },
    {
      "name": "CooRnet",
      "one_line_profile": "Detection of coordinated link sharing behavior on social media",
      "detailed_description": "An R package for computational social science that detects coordinated link sharing behavior (CLSB) on social media platforms. It outputs networks of entities performing such behavior, useful for analyzing information diffusion and manipulation.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "network_analysis",
        "social_science_inference"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/fabiogiglietto/CooRnet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "social-network-analysis",
        "computational-social-science",
        "r-package"
      ],
      "id": 1039
    },
    {
      "name": "BLINK",
      "one_line_profile": "State-of-the-art entity linking library using bi-encoders and cross-encoders",
      "detailed_description": "A scalable entity linking python library that uses a two-stage approach (bi-encoder for retrieval, cross-encoder for re-ranking) to link entities in text to a knowledge base (Wikipedia). Essential for entity normalization in scientific KGs.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "entity_linking",
        "entity_normalization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/BLINK",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "entity-linking",
        "nlp",
        "knowledge-graph"
      ],
      "id": 1040
    },
    {
      "name": "RAG Arena",
      "one_line_profile": "Evaluation platform for Retrieval-Augmented Generation (RAG) systems",
      "detailed_description": "An open-source platform for evaluating RAG pipelines through user feedback and comparative analysis. It serves as a tool for quality control and benchmarking of scientific information retrieval and generation systems.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "quality_control"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/firecrawl/rag-arena",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag-evaluation",
        "benchmarking",
        "human-eval"
      ],
      "id": 1041
    },
    {
      "name": "RAGEval",
      "one_line_profile": "Evaluation toolkit for Retrieval-Augmented Generation (RAG) methods",
      "detailed_description": "A library providing metrics and tools to evaluate the performance of RAG systems. It helps in assessing retrieval accuracy, generation quality, and faithfulness, which are critical for scientific evidence chains.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gomate-community/rageval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag-evaluation",
        "metrics",
        "nlp"
      ],
      "id": 1042
    },
    {
      "name": "LangExtract",
      "one_line_profile": "Library for extracting structured information with source grounding using LLMs",
      "detailed_description": "A tool for information extraction that emphasizes precise source grounding. It converts unstructured text into structured data while maintaining links to the original evidence, supporting the creation of verifiable knowledge bases.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "information_extraction",
        "evidence_grounding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google/langextract",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "information-extraction",
        "grounding",
        "llm"
      ],
      "id": 1043
    },
    {
      "name": "nano-graphrag",
      "one_line_profile": "A lightweight and hackable implementation of GraphRAG for retrieval-augmented generation",
      "detailed_description": "A simplified, easy-to-understand implementation of GraphRAG (Graph Retrieval-Augmented Generation) designed for experimentation and customization in knowledge graph-enhanced LLM workflows.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "rag",
        "knowledge_graph_construction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gusye1234/nano-graphrag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graphrag",
        "rag",
        "knowledge-graph",
        "llm"
      ],
      "id": 1044
    },
    {
      "name": "TRACE",
      "one_line_profile": "Temporal Grounding Video LLM via Casual Event Modeling",
      "detailed_description": "Implementation of the TRACE model for temporal grounding in videos, capable of localizing events in video content using Large Language Models.",
      "domains": [
        "Computer Vision",
        "Multimodal AI"
      ],
      "subtask_category": [
        "video_temporal_grounding",
        "event_localization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gyxxyg/TRACE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "video-grounding",
        "llm",
        "temporal-localization"
      ],
      "id": 1045
    },
    {
      "name": "VTG-LLM",
      "one_line_profile": "Video LLM integrating timestamp knowledge for enhanced temporal grounding",
      "detailed_description": "A Video Large Language Model framework that integrates timestamp knowledge to improve performance in video temporal grounding tasks.",
      "domains": [
        "Computer Vision",
        "Multimodal AI"
      ],
      "subtask_category": [
        "video_temporal_grounding",
        "video_understanding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gyxxyg/VTG-LLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "video-llm",
        "temporal-grounding",
        "timestamps"
      ],
      "id": 1046
    },
    {
      "name": "ERVSR",
      "one_line_profile": "Efficient Reference-based Video Super-Resolution model",
      "detailed_description": "Implementation of the ERVSR model for enhancing video resolution using reference frames, applicable in video processing and enhancement tasks.",
      "domains": [
        "Computer Vision",
        "Image Processing"
      ],
      "subtask_category": [
        "super_resolution",
        "video_enhancement"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/haewonc/ERVSR",
      "help_website": [],
      "license": null,
      "tags": [
        "video-super-resolution",
        "image-processing"
      ],
      "id": 1047
    },
    {
      "name": "dspy-redteam",
      "one_line_profile": "Framework for red-teaming Language Models using DSPy",
      "detailed_description": "A tool for evaluating and red-teaming Large Language Models to identify vulnerabilities and robustness issues, leveraging the DSPy framework.",
      "domains": [
        "NLP",
        "AI Safety"
      ],
      "subtask_category": [
        "model_evaluation",
        "red_teaming"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/haizelabs/dspy-redteam",
      "help_website": [],
      "license": null,
      "tags": [
        "dspy",
        "red-teaming",
        "llm-evaluation"
      ],
      "id": 1048
    },
    {
      "name": "EntityLinkingRetrieval-ELR",
      "one_line_profile": "Entity linking integration for enhanced entity retrieval",
      "detailed_description": "A library/framework for exploiting entity linking within search queries to improve entity retrieval performance, relevant for knowledge graph and information retrieval tasks.",
      "domains": [
        "G2",
        "Information Retrieval"
      ],
      "subtask_category": [
        "entity_linking",
        "entity_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hasibi/EntityLinkingRetrieval-ELR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "entity-linking",
        "information-retrieval",
        "search"
      ],
      "id": 1049
    },
    {
      "name": "TAGME-Reproducibility",
      "one_line_profile": "Reproducible implementation of the TAGME entity linking system",
      "detailed_description": "Provides code to reproduce and use the TAGME entity linking system, a tool for annotating text with hyperlinks to Wikipedia pages.",
      "domains": [
        "G2",
        "NLP"
      ],
      "subtask_category": [
        "entity_linking",
        "text_annotation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hasibi/TAGME-Reproducibility",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tagme",
        "entity-linking",
        "wikipedia"
      ],
      "id": 1050
    },
    {
      "name": "ComfyUI_LLM_Party",
      "one_line_profile": "ComfyUI nodes for LLM Agents and RAG workflows",
      "detailed_description": "A comprehensive set of nodes for ComfyUI that integrates various LLMs, Agents, and RAG capabilities (including GraphRAG), enabling the construction of complex AI research and processing workflows.",
      "domains": [
        "G2-05",
        "AI Workflow"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "rag",
        "agent_framework"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/heshengtao/comfyui_LLM_party",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "comfyui",
        "llm-agent",
        "rag",
        "graphrag"
      ],
      "id": 1051
    },
    {
      "name": "HiRAG",
      "one_line_profile": "Retrieval-Augmented Generation with Hierarchical Knowledge",
      "detailed_description": "Implementation of HiRAG, a method for RAG that leverages hierarchical knowledge structures to improve generation quality.",
      "domains": [
        "G2-05",
        "NLP"
      ],
      "subtask_category": [
        "rag",
        "knowledge_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hhy-huang/HiRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "hierarchical-knowledge",
        "llm"
      ],
      "id": 1052
    },
    {
      "name": "Activation_Decoding",
      "one_line_profile": "Hallucination mitigation via inner representation analysis",
      "detailed_description": "Implementation of 'In-Context Sharpness as Alerts', a method to detect and mitigate hallucinations in LLMs by analyzing inner activation representations.",
      "domains": [
        "NLP",
        "AI Safety"
      ],
      "subtask_category": [
        "hallucination_mitigation",
        "model_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hkust-nlp/Activation_Decoding",
      "help_website": [],
      "license": null,
      "tags": [
        "hallucination",
        "llm",
        "activation-analysis"
      ],
      "id": 1053
    },
    {
      "name": "LRAGE",
      "one_line_profile": "Evaluation framework for Legal RAG pipelines",
      "detailed_description": "A specialized framework for evaluating Retrieval-Augmented Generation (RAG) pipelines within the legal domain, providing metrics and tools for assessment.",
      "domains": [
        "Legal Tech",
        "NLP"
      ],
      "subtask_category": [
        "rag_evaluation",
        "benchmarking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/hoorangyee/LRAGE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "legal-domain"
      ],
      "id": 1054
    },
    {
      "name": "ComfyUI-IF_AI_tools",
      "one_line_profile": "ComfyUI nodes for local LLM integration via Ollama",
      "detailed_description": "A set of custom nodes for ComfyUI enabling the integration of local Large Language Models (via Ollama) into image generation and AI workflows.",
      "domains": [
        "AI Workflow",
        "Generative AI"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "prompt_generation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/if-ai/ComfyUI-IF_AI_tools",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "comfyui",
        "ollama",
        "llm",
        "local-ai"
      ],
      "id": 1055
    },
    {
      "name": "ViDoRe Benchmark",
      "one_line_profile": "Benchmark for Vision Document Retrieval",
      "detailed_description": "Evaluation code and benchmark suite for Vision Document Retrieval (ViDoRe), supporting the assessment of models like ColPali.",
      "domains": [
        "Computer Vision",
        "Information Retrieval"
      ],
      "subtask_category": [
        "benchmarking",
        "document_retrieval"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/illuin-tech/vidore-benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "vision-retrieval",
        "document-retrieval"
      ],
      "id": 1056
    },
    {
      "name": "RAGFlow",
      "one_line_profile": "Open-source RAG engine with agent capabilities",
      "detailed_description": "A comprehensive Retrieval-Augmented Generation (RAG) engine that combines RAG with agentic capabilities to build context-aware LLM applications.",
      "domains": [
        "G2-05",
        "NLP"
      ],
      "subtask_category": [
        "rag",
        "agent_framework"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/infiniflow/ragflow",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "llm",
        "agent",
        "engine"
      ],
      "id": 1057
    },
    {
      "name": "REL",
      "one_line_profile": "Radboud Entity Linker",
      "detailed_description": "A modular and efficient entity linking library (Radboud Entity Linker) capable of linking text mentions to knowledge base entities.",
      "domains": [
        "G2",
        "NLP"
      ],
      "subtask_category": [
        "entity_linking",
        "disambiguation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/informagi/REL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "entity-linking",
        "nlp",
        "knowledge-graph"
      ],
      "id": 1058
    },
    {
      "name": "IPEX-LLM",
      "one_line_profile": "LLM acceleration library for Intel XPU",
      "detailed_description": "A library for accelerating local LLM inference and fine-tuning on Intel hardware (CPUs, GPUs, NPUs), integrating with popular frameworks like LangChain and LlamaIndex.",
      "domains": [
        "High Performance Computing",
        "AI Infrastructure"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/intel/ipex-llm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "acceleration",
        "intel",
        "llm",
        "inference"
      ],
      "id": 1059
    },
    {
      "name": "OntologyRAG",
      "one_line_profile": "Biomedical code mapping using RAG and Ontologies",
      "detailed_description": "A tool leveraging Retrieval-Augmented Generation and Ontology Knowledge Graphs to improve biomedical code mapping and normalization.",
      "domains": [
        "Biomedical Informatics",
        "G2"
      ],
      "subtask_category": [
        "entity_normalization",
        "rag",
        "biomedical_coding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/iqvianlp/ontologyRAG",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "biomedical",
        "ontology",
        "rag",
        "normalization"
      ],
      "id": 1060
    },
    {
      "name": "Bitcoin-Transaction-Network-Extraction",
      "one_line_profile": "Tool to extract Bitcoin transaction networks from binary data",
      "detailed_description": "Processes raw Bitcoin binary data into flat file formats suitable for network analysis and scientific research on transaction graphs.",
      "domains": [
        "Network Science",
        "Data Processing"
      ],
      "subtask_category": [
        "data_extraction",
        "network_construction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ivanbrugere/Bitcoin-Transaction-Network-Extraction",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "bitcoin",
        "network-analysis",
        "data-extraction"
      ],
      "id": 1061
    },
    {
      "name": "RagRank",
      "one_line_profile": "Evaluation toolkit for RAG applications",
      "detailed_description": "A toolkit for assessing the accuracy, context understanding, and quality of Retrieval-Augmented Generation (RAG) systems.",
      "domains": [
        "G2-05",
        "NLP"
      ],
      "subtask_category": [
        "rag_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/izam-mohammed/ragrank",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "rag",
        "metrics"
      ],
      "id": 1062
    },
    {
      "name": "ScientificDiscourseTagging",
      "one_line_profile": "Scientific discourse tagging for evidence extraction",
      "detailed_description": "Implementation of a sequence tagging model designed to identify discourse roles in scientific text, aiding in evidence extraction and literature analysis.",
      "domains": [
        "G2",
        "NLP"
      ],
      "subtask_category": [
        "evidence_extraction",
        "discourse_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jacklxc/ScientificDiscourseTagging",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "scientific-nlp",
        "evidence-extraction",
        "tagging"
      ],
      "id": 1063
    },
    {
      "name": "fact-checker",
      "one_line_profile": "LLM output fact-checking using self-ask",
      "detailed_description": "A tool/implementation for verifying the factual accuracy of Large Language Model outputs using the self-ask prompting technique.",
      "domains": [
        "G2-05",
        "NLP"
      ],
      "subtask_category": [
        "fact_checking",
        "hallucination_mitigation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/jagilley/fact-checker",
      "help_website": [],
      "license": null,
      "tags": [
        "fact-checking",
        "llm",
        "verification"
      ],
      "id": 1064
    },
    {
      "name": "audio_dspy",
      "one_line_profile": "Python package for audio signal processing",
      "detailed_description": "A library providing various digital signal processing tools and filters specifically for audio analysis and synthesis.",
      "domains": [
        "Signal Processing",
        "Acoustics"
      ],
      "subtask_category": [
        "signal_processing",
        "audio_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jatinchowdhury18/audio_dspy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dsp",
        "audio",
        "signal-processing"
      ],
      "id": 1065
    },
    {
      "name": "GraphRAG-Bench",
      "one_line_profile": "Benchmark for Graph Retrieval-Augmented Generation",
      "detailed_description": "A benchmarking suite designed to evaluate the reasoning capabilities of GraphRAG systems in domain-specific contexts.",
      "domains": [
        "G2-05",
        "NLP"
      ],
      "subtask_category": [
        "benchmarking",
        "rag_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/jeremycp3/GraphRAG-Bench",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "graphrag",
        "evaluation"
      ],
      "id": 1066
    },
    {
      "name": "llm-eval",
      "one_line_profile": "Evaluation platform for Large Language Models and RAG systems",
      "detailed_description": "A platform for evaluating Large Language Models (LLMs) supporting multiple benchmarks, custom datasets, and performance testing. It specifically includes support for evaluating Retrieval-Augmented Generation (RAG) systems based on custom datasets.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "rag_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/justplus/llm-eval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-evaluation",
        "rag",
        "benchmark"
      ],
      "id": 1067
    },
    {
      "name": "autoarena",
      "one_line_profile": "Automated head-to-head evaluation library for LLMs and RAG systems",
      "detailed_description": "A library designed to rank Large Language Models (LLMs), RAG systems, and prompts using automated head-to-head evaluation mechanisms, facilitating comparative analysis of model performance.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/kolenaIO/autoarena",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "llm",
        "rag",
        "ranking"
      ],
      "id": 1068
    },
    {
      "name": "DSRs",
      "one_line_profile": "High-performance Rust implementation of the DSPy framework",
      "detailed_description": "A performance-centered rewrite of the DSPy framework in Rust, designed to optimize the programming and orchestration of language models for scientific and general AI tasks.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "model_orchestration",
        "prompt_engineering"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/krypticmouse/DSRs",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dspy",
        "rust",
        "llm-framework"
      ],
      "id": 1069
    },
    {
      "name": "langchain-graphrag",
      "one_line_profile": "LangChain implementation of GraphRAG for query-focused summarization",
      "detailed_description": "An implementation of the GraphRAG approach (From Local to Global) compatible with LangChain, enabling graph-based retrieval-augmented generation for tasks like query-focused summarization.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "retrieval",
        "summarization",
        "graph_rag"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ksachdeva/langchain-graphrag",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "graphrag",
        "langchain",
        "rag"
      ],
      "id": 1070
    },
    {
      "name": "global-canopy-height-model",
      "one_line_profile": "High-resolution global canopy height estimation model",
      "detailed_description": "A model developed to estimate canopy top height anywhere on Earth at high resolution using Sentinel-2 imagery, trained with sparse GEDI LIDAR data as reference. Useful for ecological and environmental research.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "environmental_modeling",
        "remote_sensing_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/langnico/global-canopy-height-model",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "remote-sensing",
        "canopy-height",
        "sentinel-2",
        "gedi"
      ],
      "id": 1071
    },
    {
      "name": "langstruct",
      "one_line_profile": "Library for extracting structured data using LLMs",
      "detailed_description": "A tool designed to extract structured data from unstructured content using Large Language Models, facilitating data processing and knowledge base construction tasks.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "information_extraction",
        "data_structuring"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/langstruct-ai/langstruct",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "information-extraction",
        "llm",
        "structured-data"
      ],
      "id": 1072
    },
    {
      "name": "Citation-Graph-Python",
      "one_line_profile": "Tool for generating citation graphs from reference data",
      "detailed_description": "A Python tool for automatically generating citation graphs from references, aiding in bibliometric analysis and visualization of scientific literature connections.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "scientometrics",
        "visualization"
      ],
      "application_level": "solver",
      "primary_language": "TeX",
      "repo_url": "https://github.com/lanstonchu/Citation-Graph-Python",
      "help_website": [],
      "license": null,
      "tags": [
        "citation-graph",
        "bibliometrics",
        "visualization"
      ],
      "id": 1073
    },
    {
      "name": "paperqa-zotero",
      "one_line_profile": "LLM-based question answering tool for Zotero libraries",
      "detailed_description": "A tool that integrates Large Language Models with Zotero to enable question answering based on the content of PDF documents in a user's reference library, supporting literature review and evidence retrieval.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "literature_review",
        "question_answering"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/lejacobroy/paperqa-zotero",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "zotero",
        "paperqa",
        "literature-review"
      ],
      "id": 1074
    },
    {
      "name": "mulrel-nel",
      "one_line_profile": "Named Entity Linking system with latent relations",
      "detailed_description": "An implementation of a Named Entity Linking (NEL) model that utilizes latent relations to improve entity disambiguation, a key task in knowledge graph construction and text normalization.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "entity_linking",
        "normalization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lephong/mulrel-nel",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "entity-linking",
        "nel",
        "nlp"
      ],
      "id": 1075
    },
    {
      "name": "StrainScan",
      "one_line_profile": "High-resolution strain-level microbiome composition analysis tool",
      "detailed_description": "A bioinformatics tool for high-resolution strain-level microbiome composition analysis based on reference genomes and k-mers, enabling precise identification of microbial strains.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "microbiome_analysis",
        "genomics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liaoherui/StrainScan",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "microbiome",
        "strain-analysis",
        "bioinformatics"
      ],
      "id": 1076
    },
    {
      "name": "litegraph",
      "one_line_profile": "Lightweight graph database for AI knowledge persistence",
      "detailed_description": "A lightweight graph database supporting relational, vector, and MCP features, designed to power knowledge persistence and retrieval for artificial intelligence applications.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "data_storage",
        "knowledge_graph_management"
      ],
      "application_level": "dataset",
      "primary_language": "C#",
      "repo_url": "https://github.com/litegraphdb/litegraph",
      "help_website": [],
      "license": null,
      "tags": [
        "graph-database",
        "vector-database",
        "knowledge-graph"
      ],
      "id": 1077
    },
    {
      "name": "fid-med-eval",
      "one_line_profile": "Feature extraction and evaluation metrics for generative medical imaging",
      "detailed_description": "A Python library implementing Feature Extraction for Generative Medical Imaging Evaluation, specifically designed to provide evidence against evolving trends in medical image synthesis assessment. It offers metrics like FID tailored for medical datasets.",
      "domains": [
        "Medical Imaging",
        "G2-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "image_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mckellwoodland/fid-med-eval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-imaging",
        "evaluation-metric",
        "generative-models"
      ],
      "id": 1078
    },
    {
      "name": "RadFact",
      "one_line_profile": "Metric suite for evaluating radiology report generation and grounding",
      "detailed_description": "A metric suite leveraging the logical inference capabilities of LLMs to evaluate radiology report generation, focusing on factual correctness and grounding in medical evidence.",
      "domains": [
        "Radiology",
        "G2-05"
      ],
      "subtask_category": [
        "fact_checking",
        "report_generation_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/RadFact",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "radiology",
        "factuality",
        "evaluation-metric"
      ],
      "id": 1079
    },
    {
      "name": "phenomics-assistant",
      "one_line_profile": "LLM RAG agent for the Monarch Knowledge Graph",
      "detailed_description": "A retrieval-augmented generation (RAG) agent specifically designed to interact with the Monarch Knowledge Graph, enabling researchers to query and retrieve phenomic and genomic evidence.",
      "domains": [
        "Phenomics",
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "phenotype_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/monarch-initiative/phenomics-assistant",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "monarch-initiative",
        "phenomics",
        "rag"
      ],
      "id": 1080
    },
    {
      "name": "Pubmed-PaperQA",
      "one_line_profile": "Tools for searching, downloading, and QA on PubMed papers",
      "detailed_description": "A toolkit for building question-answering language models based on scientific literature from PubMed. It includes functionality for searching and downloading papers, facilitating evidence-based QA.",
      "domains": [
        "Biomedicine",
        "G2-05"
      ],
      "subtask_category": [
        "literature_mining",
        "question_answering"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/nachovy/Pubmed-PaperQA",
      "help_website": [],
      "license": null,
      "tags": [
        "pubmed",
        "paper-qa",
        "literature-search"
      ],
      "id": 1081
    },
    {
      "name": "Vocalocator",
      "one_line_profile": "Deep neural networks for sound source localization and vocalization attribution",
      "detailed_description": "A scientific analysis tool developed by NeuroStats Lab for localizing sound sources and attributing vocalizations, specifically designed for neuroscience and bioacoustics research.",
      "domains": [
        "Neuroscience",
        "Bioacoustics"
      ],
      "subtask_category": [
        "sound_localization",
        "vocalization_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/neurostatslab/vocalocator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "neuroscience",
        "audio-analysis",
        "localization"
      ],
      "id": 1082
    },
    {
      "name": "Xapian Haystack",
      "one_line_profile": "Xapian backend integration for the Haystack NLP framework",
      "detailed_description": "A library extension that provides a Xapian backend for Haystack, enabling efficient information retrieval and document storage for RAG and QA pipelines in scientific knowledge management.",
      "domains": [
        "Sci Knowledge/KG",
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "information_retrieval",
        "document_indexing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/notanumber/xapian-haystack",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "haystack",
        "xapian",
        "retrieval",
        "backend"
      ],
      "id": 1083
    },
    {
      "name": "GraphRAG Visualizer",
      "one_line_profile": "Visualization tool for Microsoft GraphRAG artifacts",
      "detailed_description": "A web-based tool designed to visualize and explore the artifacts generated by Microsoft's GraphRAG, aiding researchers in understanding the structure and content of the generated knowledge graphs.",
      "domains": [
        "Sci Knowledge/KG",
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "scientific_visualization",
        "graph_exploration"
      ],
      "application_level": "application",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/noworneverev/graphrag-visualizer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "graph-rag",
        "knowledge-graph"
      ],
      "id": 1084
    },
    {
      "name": "WFGY",
      "one_line_profile": "Semantic Reasoning Engine for LLMs to mitigate RAG hallucinations",
      "detailed_description": "A semantic reasoning engine designed to fix RAG and OCR drift, collapse, and ghost matches via symbolic overlays and logic patches, aiming to improve the reliability of scientific information retrieval.",
      "domains": [
        "Sci Knowledge/KG",
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "hallucination_mitigation",
        "semantic_reasoning",
        "rag_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/onestardao/WFGY",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "hallucination",
        "semantic-reasoning",
        "llm"
      ],
      "id": 1085
    },
    {
      "name": "OpeNER Coreference Base",
      "one_line_profile": "Coreference resolution tool for English language",
      "detailed_description": "A component of the OpeNER project providing coreference resolution capabilities, essential for entity normalization and evidence linking in scientific text processing.",
      "domains": [
        "Sci Knowledge/KG",
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "coreference_resolution",
        "entity_normalization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/opener-project/coreference-base",
      "help_website": [
        "http://www.opener-project.eu/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "nlp",
        "coreference",
        "opener"
      ],
      "id": 1086
    },
    {
      "name": "Open Movement",
      "one_line_profile": "Firmware and software for Open Movement sensor devices",
      "detailed_description": "Open source firmware and software for Open Movement miniature sensors, used for scientific data generation in movement analysis and health research.",
      "domains": [
        "Health/Movement Science"
      ],
      "subtask_category": [
        "data_generation",
        "sensor_data_acquisition"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/openmovementproject/openmovement",
      "help_website": [
        "https://openmovement.co.uk/"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "sensors",
        "firmware",
        "movement-analysis"
      ],
      "id": 1087
    },
    {
      "name": "Open Semantic ETL",
      "one_line_profile": "ETL tools for document processing and semantic analysis",
      "detailed_description": "A Python-based ETL toolkit for file crawling, text extraction, OCR, and content analysis (NER), designed to ingest data into Solr/Elasticsearch or graph databases for semantic search applications.",
      "domains": [
        "Sci Knowledge/KG",
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "etl",
        "data_ingestion",
        "document_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/opensemanticsearch/open-semantic-etl",
      "help_website": [
        "https://opensemanticsearch.org/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "etl",
        "ocr",
        "text-extraction",
        "semantic-search"
      ],
      "id": 1088
    },
    {
      "name": "Open Semantic Visual Graph Explorer",
      "one_line_profile": "Visual explorer for linked data graphs",
      "detailed_description": "A web-based visualization tool for exploring direct and indirect connections between named entities in a knowledge graph, supporting discovery and analysis of semantic relationships.",
      "domains": [
        "Sci Knowledge/KG",
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "scientific_visualization",
        "graph_exploration"
      ],
      "application_level": "application",
      "primary_language": "HTML",
      "repo_url": "https://github.com/opensemanticsearch/open-semantic-visual-graph-explorer",
      "help_website": [
        "https://opensemanticsearch.org/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "visualization",
        "knowledge-graph",
        "linked-data"
      ],
      "id": 1089
    },
    {
      "name": "OpenTapioca",
      "one_line_profile": "Real-time entity linking system for Wikidata",
      "detailed_description": "A lightweight entity linking system that works with Wikidata, capable of adapting to real-time edits, used for normalizing entities in text to Wikidata identifiers.",
      "domains": [
        "Sci Knowledge/KG",
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "entity_linking",
        "entity_normalization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/opentapioca/opentapioca",
      "help_website": [
        "https://opentapioca.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "entity-linking",
        "wikidata",
        "nlp"
      ],
      "id": 1090
    },
    {
      "name": "Hoaxy Backend",
      "one_line_profile": "Backend for Hoaxy misinformation visualization tool",
      "detailed_description": "The backend component for Hoaxy, a scientific tool developed by Indiana University to visualize the spread of claims and fact-checking in social networks.",
      "domains": [
        "Sci Knowledge/KG",
        "Social Science"
      ],
      "subtask_category": [
        "misinformation_analysis",
        "network_analysis",
        "fact_checking"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/osome-iu/hoaxy-backend",
      "help_website": [
        "https://hoaxy.osome.iu.edu/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "misinformation",
        "visualization",
        "backend",
        "fact-checking"
      ],
      "id": 1091
    },
    {
      "name": "ALCE",
      "one_line_profile": "Benchmark and toolkit for evaluating LLM citation generation and evidence grounding",
      "detailed_description": "A framework for enabling and evaluating Large Language Models in generating text with correct citations, addressing the hallucination and evidence alignment problem in scientific text generation.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "citation_evaluation",
        "hallucination_mitigation",
        "evidence_alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/princeton-nlp/ALCE",
      "help_website": [
        "https://arxiv.org/abs/2305.14627"
      ],
      "license": "MIT",
      "tags": [
        "citation",
        "hallucination",
        "rag-evaluation",
        "nlp"
      ],
      "id": 1092
    },
    {
      "name": "rag-citation",
      "one_line_profile": "Library for adding citation and reference tracking to RAG pipelines",
      "detailed_description": "A lightweight tool designed to enhance Retrieval-Augmented Generation (RAG) by automatically generating and managing citations for AI-generated content, ensuring evidence alignment.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "citation_generation",
        "evidence_alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rahulanand1103/rag-citation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "citation",
        "evidence-chain"
      ],
      "id": 1093
    },
    {
      "name": "Llama-Researcher",
      "one_line_profile": "Autonomous research agent for comprehensive online literature review",
      "detailed_description": "A research assistant tool built on LlamaIndex that performs autonomous online research, synthesizing information from multiple sources to generate comprehensive reports, useful for scientific literature review.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "literature_review",
        "information_retrieval",
        "report_generation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/rsrohan99/Llama-Researcher",
      "help_website": [],
      "license": null,
      "tags": [
        "agent",
        "literature-review",
        "llamaindex",
        "research-automation"
      ],
      "id": 1094
    },
    {
      "name": "OpenCE",
      "one_line_profile": "Toolkit for implementing and evaluating LLM context engineering strategies",
      "detailed_description": "OpenCE (Open Context Engineering) is a community toolkit designed to implement, evaluate, and combine various LLM context strategies such as RAG (Retrieval-Augmented Generation), ACE, and context compression. It aids in optimizing the evidence chain for scientific QA and reasoning.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "context_engineering",
        "rag_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sci-m-wang/OpenCE",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "context-engineering",
        "llm",
        "evidence-chain"
      ],
      "id": 1095
    },
    {
      "name": "semanticizer",
      "one_line_profile": "Entity linking tool for mapping text mentions to knowledge base entities",
      "detailed_description": "Semanticizer is a Python tool for entity linking, designed to identify and link entities in text to a knowledge base. It supports the entity normalization process essential for constructing scientific knowledge graphs.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "entity_linking",
        "entity_normalization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/semanticize/semanticizer",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "entity-linking",
        "nlp",
        "knowledge-graph"
      ],
      "id": 1096
    },
    {
      "name": "STaRK",
      "one_line_profile": "Benchmark suite for LLM retrieval on textual and relational knowledge bases",
      "detailed_description": "STaRK is a benchmarking framework designed to evaluate Large Language Model (LLM) retrieval capabilities across textual and relational knowledge bases. It provides datasets and evaluation scripts to measure the effectiveness of RAG systems in handling structured and unstructured knowledge.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "retrieval_benchmarking",
        "kb_retrieval"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/snap-stanford/stark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "retrieval",
        "knowledge-base",
        "rag"
      ],
      "id": 1097
    },
    {
      "name": "ARES",
      "one_line_profile": "Automated evaluation framework for RAG systems",
      "detailed_description": "ARES (Automated RAG Evaluation System) is a tool for evaluating Retrieval-Augmented Generation systems. It uses synthetic data and LLM-based judges to assess context relevance, answer faithfulness, and answer relevance, helping to optimize RAG pipelines for scientific knowledge.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanford-futuredata/ARES",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "llm",
        "automated-testing"
      ],
      "id": 1098
    },
    {
      "name": "STORM",
      "one_line_profile": "LLM-powered knowledge curation and report generation system",
      "detailed_description": "STORM is a knowledge curation system that orchestrates LLMs to research topics, retrieve information from the web or knowledge bases, and generate comprehensive reports with citations. It automates the evidence gathering and synthesis process for scientific literature review.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "knowledge_curation",
        "report_generation",
        "citation_alignment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanford-oval/storm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-curation",
        "rag",
        "report-generation",
        "citation"
      ],
      "id": 1099
    },
    {
      "name": "DSPy",
      "one_line_profile": "Framework for programming and optimizing language model pipelines",
      "detailed_description": "DSPy is a framework for algorithmically optimizing LM prompts and weights. It allows researchers to build complex RAG and information extraction pipelines by programming logical flows rather than manual prompt engineering, essential for robust scientific knowledge extraction.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "pipeline_optimization",
        "prompt_programming"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanfordnlp/dspy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "framework",
        "prompt-engineering",
        "rag"
      ],
      "id": 1100
    },
    {
      "name": "RAG Genie",
      "one_line_profile": "Prototype tool for evaluating RAG embeddings and chunking strategies",
      "detailed_description": "RAG Genie is a tool designed to test and evaluate different embedding models and chunk splitting strategies within a RAG pipeline. It helps researchers optimize retrieval performance for specific document sets.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "embedding_testing"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/stephanj/rag-genie",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "embeddings",
        "chunking"
      ],
      "id": 1101
    },
    {
      "name": "LLM Structured Output Benchmarks",
      "one_line_profile": "Benchmark suite for LLM structured output frameworks",
      "detailed_description": "This repository provides benchmarks for various LLM structured output frameworks (like Instructor, Outlines, etc.) on tasks such as Named Entity Recognition (NER) and classification. It aids in selecting the best tools for extracting structured scientific data from text.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "structured_output_benchmarking",
        "tool_selection"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/stephenleo/llm-structured-output-benchmarks",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "structured-output",
        "ner",
        "llm"
      ],
      "id": 1102
    },
    {
      "name": "RAGLite",
      "one_line_profile": "Lightweight toolkit for RAG with DuckDB and PostgreSQL",
      "detailed_description": "RAGLite is a Python toolkit that simplifies the implementation of Retrieval-Augmented Generation systems using DuckDB or PostgreSQL. It provides a lightweight infrastructure for building local scientific knowledge retrieval systems.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "rag_implementation",
        "data_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/superlinear-ai/raglite",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "rag",
        "duckdb",
        "postgresql",
        "retrieval"
      ],
      "id": 1103
    },
    {
      "name": "AutoCitation",
      "one_line_profile": "LLM agent for finding and verifying citations",
      "detailed_description": "AutoCitation is an LLM-based agent designed to find real citations for content. It assists in the evidence chain process by verifying claims and retrieving authentic academic references.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "citation_verification",
        "citation_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sypsyp97/AutoCitation",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "citation",
        "agent",
        "rag",
        "verification"
      ],
      "id": 1104
    },
    {
      "name": "Trinity-IE",
      "one_line_profile": "Information extraction pipeline for coreference resolution, entity linking, and relationship extraction",
      "detailed_description": "A comprehensive information extraction pipeline designed to process text and extract structured knowledge. It integrates coreference resolution, named entity linking, and relationship extraction into a unified workflow, facilitating the construction of knowledge graphs from unstructured text.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "information_extraction",
        "entity_linking",
        "relation_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/tomasonjo/trinity-ie",
      "help_website": [
        "https://github.com/tomasonjo/trinity-ie"
      ],
      "license": null,
      "tags": [
        "information-extraction",
        "entity-linking",
        "knowledge-graph",
        "nlp-pipeline"
      ],
      "id": 1105
    },
    {
      "name": "Cognee",
      "one_line_profile": "Deterministic graph generation and memory management library for AI agents",
      "detailed_description": "A library that implements deterministic graph generation (GraphRAG) and memory management for AI systems. It structures unstructured data into knowledge graphs to provide grounded context and reduce hallucinations in retrieval-augmented generation tasks.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "graph_construction",
        "rag",
        "memory_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/topoteretes/cognee",
      "help_website": [
        "https://docs.cognee.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "graph-rag",
        "knowledge-graph",
        "memory",
        "agent-memory"
      ],
      "id": 1106
    },
    {
      "name": "ROGRAG",
      "one_line_profile": "Robustly Optimized GraphRAG Framework for enhanced retrieval-augmented generation",
      "detailed_description": "A framework designed to optimize GraphRAG (Graph Retrieval-Augmented Generation) workflows. It provides tools for constructing and querying knowledge graphs to improve the robustness and accuracy of LLM responses in scientific and general domains.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "rag",
        "graph_construction",
        "retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tpoisonooo/ROGRAG",
      "help_website": [
        "https://github.com/tpoisonooo/ROGRAG"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "graph-rag",
        "retrieval-augmented-generation",
        "knowledge-graph",
        "optimization"
      ],
      "id": 1107
    },
    {
      "name": "NameMatch",
      "one_line_profile": "Probabilistic entity linkage tool for record matching",
      "detailed_description": "A Python tool for probabilistically linking records of individual entities within and across datasets. It is essential for entity normalization and cleaning in scientific data pipelines.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "entity_resolution",
        "record_linkage",
        "data_cleaning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/urban-labs/namematch",
      "help_website": [
        "https://github.com/urban-labs/namematch"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "entity-linking",
        "record-linkage",
        "probabilistic-matching",
        "data-cleaning"
      ],
      "id": 1108
    },
    {
      "name": "LearningByReading",
      "one_line_profile": "Pipeline of NLP and Entity Linking tools for knowledge extraction",
      "detailed_description": "A pipeline of Natural Language Processing and Entity Linking tools implemented in C. It is designed for 'Learning by Reading' tasks, extracting entities and knowledge from text for scientific or general knowledge base construction.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "entity_linking",
        "nlp_pipeline",
        "knowledge_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "C",
      "repo_url": "https://github.com/valeriobasile/learningbyreading",
      "help_website": [
        "https://github.com/valeriobasile/learningbyreading"
      ],
      "license": "GPL-2.0",
      "tags": [
        "entity-linking",
        "nlp",
        "c",
        "pipeline"
      ],
      "id": 1109
    },
    {
      "name": "Open-RAG-Eval",
      "one_line_profile": "RAG evaluation tool without requiring golden answers",
      "detailed_description": "A tool for evaluating Retrieval-Augmented Generation (RAG) systems without the need for ground truth 'golden answers'. It uses LLM-based metrics to assess the quality of retrieved context and generated responses, essential for validating evidence chains.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "evaluation",
        "quality_control",
        "rag_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vectara/open-rag-eval",
      "help_website": [
        "https://github.com/vectara/open-rag-eval"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag-evaluation",
        "metrics",
        "quality-control",
        "llm-eval"
      ],
      "id": 1110
    },
    {
      "name": "Ragas",
      "one_line_profile": "Framework for evaluating Retrieval Augmented Generation (RAG) pipelines",
      "detailed_description": "A comprehensive framework for evaluating RAG pipelines. It provides metrics for faithfulness, answer relevance, and context retrieval quality, enabling quantitative assessment of evidence chains and generation quality in scientific AI applications.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "evaluation",
        "metrics",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vibrantlabsai/ragas",
      "help_website": [
        "https://docs.ragas.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag-evaluation",
        "metrics",
        "faithfulness",
        "hallucination-detection"
      ],
      "id": 1111
    },
    {
      "name": "Time-R1",
      "one_line_profile": "R1-like Video-LLM for temporal grounding in videos",
      "detailed_description": "A video large language model designed for temporal grounding, enabling the alignment of textual queries with specific video segments, relevant for multimodal evidence grounding.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "grounding",
        "multimodal_alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/www-Ye/Time-R1",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "video-llm",
        "temporal-grounding",
        "multimodal"
      ],
      "id": 1112
    },
    {
      "name": "wikientities",
      "one_line_profile": "Tool for linking entities in CommonCrawl to Wikipedia concepts",
      "detailed_description": "A Java-based tool designed to perform entity linking on large-scale datasets like CommonCrawl, mapping text mentions to Wikipedia concepts for knowledge graph construction.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "entity_linking",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/xiaoganghan/wikientities",
      "help_website": [],
      "license": null,
      "tags": [
        "entity-linking",
        "wikipedia",
        "commoncrawl"
      ],
      "id": 1113
    },
    {
      "name": "CCA-LLaVA",
      "one_line_profile": "Mitigating object hallucination in LVLMs via Concentric Causal Attention",
      "detailed_description": "A method and implementation for reducing object hallucinations in Large Vision-Language Models using Concentric Causal Attention, enhancing the trustworthiness of multimodal generation.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "hallucination_mitigation",
        "model_alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/xing0047/cca-llava",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "lvlm",
        "attention-mechanism"
      ],
      "id": 1114
    },
    {
      "name": "FEL",
      "one_line_profile": "Fast Entity Linker Toolkit for linking entities to Knowledge Bases",
      "detailed_description": "A toolkit for training and deploying models to link entities in documents and queries to a Knowledge Base (specifically Wikipedia), facilitating entity normalization.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "entity_linking",
        "knowledge_graph"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/yahoo/FEL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "entity-linking",
        "wikipedia",
        "nlp"
      ],
      "id": 1115
    },
    {
      "name": "ConVis",
      "one_line_profile": "Contrastive Decoding with Hallucination Visualization for MLLMs",
      "detailed_description": "A tool implementing contrastive decoding strategies and visualization techniques to mitigate and analyze hallucinations in Multimodal Large Language Models.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "hallucination_mitigation",
        "visualization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yejipark-m/ConVis",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "mllm",
        "decoding"
      ],
      "id": 1116
    },
    {
      "name": "HawkEye",
      "one_line_profile": "Training Video-Text LLMs for Grounding Text in Videos",
      "detailed_description": "An implementation for training Video-Text Large Language Models specifically to ground textual descriptions in video content, supporting multimodal evidence alignment.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "grounding",
        "multimodal_alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yellow-binary-tree/HawkEye",
      "help_website": [],
      "license": null,
      "tags": [
        "video-grounding",
        "llm",
        "multimodal"
      ],
      "id": 1117
    },
    {
      "name": "Eider",
      "one_line_profile": "Document-level Relation Extraction with Efficient Evidence Extraction",
      "detailed_description": "A tool for document-level relation extraction that emphasizes efficient evidence extraction and inference-stage fusion, aiding in knowledge graph construction from text.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "relation_extraction",
        "evidence_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yiqingxyq/Eider",
      "help_website": [],
      "license": null,
      "tags": [
        "relation-extraction",
        "nlp",
        "evidence-mining"
      ],
      "id": 1118
    },
    {
      "name": "SRTK",
      "one_line_profile": "Subgraph Retrieval Toolkit for large-scale knowledge graphs",
      "detailed_description": "A toolkit designed to retrieve semantically relevant subgraphs from large-scale knowledge graphs, supporting RAG and knowledge-enhanced inference.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "subgraph_retrieval",
        "knowledge_graph"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yuancu/subgraph-retrieval-toolkit",
      "help_website": [
        "https://srtk.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "retrieval",
        "subgraph"
      ],
      "id": 1119
    },
    {
      "name": "less-is-more",
      "one_line_profile": "Mitigating Multimodal Hallucination via EOS Decision",
      "detailed_description": "An implementation of a decoding strategy to mitigate multimodal hallucination in Large Vision-Language Models by focusing on End-of-Sentence (EOS) decisions.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "hallucination_mitigation",
        "inference_control"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yuezih/less-is-more",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "lvlm",
        "decoding"
      ],
      "id": 1120
    },
    {
      "name": "Factcheck-GPT",
      "one_line_profile": "Tool for fact-checking LLM outputs with annotation and evaluation",
      "detailed_description": "A framework for fact-checking the outputs of generative Large Language Models, providing tools for both annotation and automated evaluation of factual accuracy.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "fact_checking",
        "evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yuxiaw/Factcheck-GPT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fact-checking",
        "llm",
        "hallucination"
      ],
      "id": 1121
    },
    {
      "name": "ESCNet",
      "one_line_profile": "Entity-enhanced and Stance Checking Network for Multi-modal Fact-Checking",
      "detailed_description": "A network implementation for multi-modal fact-checking that leverages entity information and stance detection to verify claims against evidence.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "fact_checking",
        "stance_detection"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/zfr00/ESCNet",
      "help_website": [],
      "license": null,
      "tags": [
        "fact-checking",
        "multimodal",
        "entity-enhanced"
      ],
      "id": 1122
    },
    {
      "name": "DeGF",
      "one_line_profile": "Self-Correcting Decoding with Generative Feedback for Hallucination Mitigation",
      "detailed_description": "A decoding framework that uses generative feedback to self-correct and mitigate hallucinations in Large Vision-Language Models.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "hallucination_mitigation",
        "decoding_strategy"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhangce01/DeGF",
      "help_website": [],
      "license": null,
      "tags": [
        "hallucination",
        "lvlm",
        "self-correction"
      ],
      "id": 1123
    },
    {
      "name": "SIFT",
      "one_line_profile": "Grounding LLM Reasoning in Contexts via Stickers",
      "detailed_description": "A tool for grounding Large Language Model reasoning in specific contexts, enhancing the reliability and evidence-alignment of model outputs.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "grounding",
        "reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhijie-group/SIFT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "grounding",
        "llm",
        "reasoning"
      ],
      "id": 1124
    },
    {
      "name": "OPA-DPO",
      "one_line_profile": "Mitigating Hallucinations in LVLMs via On-Policy DPO",
      "detailed_description": "A Direct Preference Optimization (DPO) based approach to mitigate hallucinations in Large Vision-Language Models by utilizing on-policy data.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "hallucination_mitigation",
        "model_alignment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhyang2226/OPA-DPO",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dpo",
        "hallucination",
        "lvlm"
      ],
      "id": 1125
    },
    {
      "name": "ONLY",
      "one_line_profile": "One-Layer Intervention for Hallucination Mitigation in LVLMs",
      "detailed_description": "A lightweight intervention method that targets a single layer to effectively mitigate hallucinations in Large Vision-Language Models.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "hallucination_mitigation",
        "model_intervention"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zifuwan/ONLY",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "lvlm",
        "intervention"
      ],
      "id": 1126
    },
    {
      "name": "Self_Reflection_Medical",
      "one_line_profile": "Mitigating LLM Hallucination via Self Reflection in Medical Domain",
      "detailed_description": "A framework for mitigating hallucinations in Large Language Models specifically within the medical domain using self-reflection mechanisms.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "hallucination_mitigation",
        "medical_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ziweiji/Self_Reflection_Medical",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-llm",
        "hallucination",
        "self-reflection"
      ],
      "id": 1127
    },
    {
      "name": "REVERIE",
      "one_line_profile": "Reflective Instruction Tuning for Mitigating Hallucinations in LVLMs",
      "detailed_description": "An instruction tuning approach that incorporates reflection to reduce hallucinations in Large Vision-Language Models.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "hallucination_mitigation",
        "instruction_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjr2000/REVERIE",
      "help_website": [],
      "license": null,
      "tags": [
        "hallucination",
        "lvlm",
        "tuning"
      ],
      "id": 1128
    },
    {
      "name": "Deco",
      "one_line_profile": "Dynamic Correction Decoding for Hallucination Mitigation",
      "detailed_description": "A dynamic decoding strategy designed to correct and mitigate hallucinations in Multimodal Large Language Models during the generation process.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "hallucination_mitigation",
        "decoding_strategy"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/Deco",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "mllm",
        "decoding"
      ],
      "id": 1129
    },
    {
      "name": "RAP",
      "one_line_profile": "Schema-aware Reference as Prompt for KG Construction",
      "detailed_description": "A framework that uses schema-aware references as prompts to improve data efficiency in Knowledge Graph construction tasks.",
      "domains": [
        "G2",
        "G2-05"
      ],
      "subtask_category": [
        "kg_construction",
        "prompt_engineering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/RAP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "construction",
        "prompting"
      ],
      "id": 1130
    },
    {
      "name": "GraphRAG-Agent",
      "one_line_profile": "Integrated framework for Knowledge Graph construction and RAG with custom evaluation",
      "detailed_description": "A comprehensive agent-based framework that integrates GraphRAG, LightRAG, and Neo4j for knowledge graph construction and search. It includes DeepSearch for private RAG reasoning and features a custom evaluation framework specifically designed for GraphRAG systems.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "rag_evaluation",
        "reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/1517005260/graph-rag-agent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-rag",
        "knowledge-graph",
        "neo4j",
        "evaluation-framework"
      ],
      "id": 1131
    },
    {
      "name": "LLM-KG-Bench",
      "one_line_profile": "Automated benchmarking framework for LLMs on Knowledge Graph tasks",
      "detailed_description": "A framework and task collection designed for the automated benchmarking of Large Language Models (LLMs) across various Knowledge Graph (KG) related tasks, facilitating standardized evaluation of LLM capabilities in structured knowledge domains.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "benchmarking",
        "model_evaluation",
        "knowledge_graph_tasks"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AKSW/LLM-KG-Bench",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "llm",
        "knowledge-graph",
        "benchmarking",
        "evaluation"
      ],
      "id": 1132
    },
    {
      "name": "tacrev",
      "one_line_profile": "Evaluation framework for TACRED relation extraction task",
      "detailed_description": "A toolkit providing a thorough evaluation of the TACRED Relation Extraction task, including revised datasets and evaluation scripts to address issues in the original benchmark.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "relation_extraction",
        "evaluation",
        "benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/DFKI-NLP/tacrev",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "relation-extraction",
        "tacred",
        "evaluation",
        "nlp"
      ],
      "id": 1133
    },
    {
      "name": "ChatGPT-IE-Eval",
      "one_line_profile": "Evaluation framework for ChatGPT on Information Extraction tasks",
      "detailed_description": "A framework for evaluating the performance of ChatGPT on various Information Extraction (IE) tasks, including Named Entity Recognition (NER), Relation Extraction (RE), Event Extraction (EE), and Aspect-based Sentiment Analysis (ABSA).",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "information_extraction",
        "model_evaluation",
        "ner",
        "relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FreedomIntelligence/Evaluation-of-ChatGPT-on-Information-Extraction",
      "help_website": [],
      "license": null,
      "tags": [
        "chatgpt",
        "information-extraction",
        "evaluation",
        "ner",
        "re"
      ],
      "id": 1134
    },
    {
      "name": "Digital Twin Benchmark Generator",
      "one_line_profile": "Knowledge graph benchmark dataset generator for digital twins",
      "detailed_description": "A tool for generating knowledge graph benchmark datasets specifically tailored for digital twin use cases, facilitating the evaluation of semantic technologies in industrial digital twin scenarios.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "data_generation",
        "benchmarking",
        "digital_twin"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/IBM/digital-twin-benchmark-model",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "digital-twin",
        "knowledge-graph",
        "data-generator",
        "benchmark"
      ],
      "id": 1135
    },
    {
      "name": "OpenPSG",
      "one_line_profile": "Benchmark framework for Panoptic Scene Graph Generation",
      "detailed_description": "A comprehensive benchmarking codebase for Panoptic Scene Graph Generation (PSG), providing tools for training and evaluating models that generate scene graphs with panoptic segmentation information.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "scene_graph_generation",
        "benchmarking",
        "computer_vision"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Jingkang50/OpenPSG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scene-graph",
        "panoptic-segmentation",
        "benchmark",
        "computer-vision"
      ],
      "id": 1136
    },
    {
      "name": "PAS-OGB",
      "one_line_profile": "Pooling Architecture Search for Graph Classification",
      "detailed_description": "An implementation of Pooling Architecture Search (PAS) for graph classification tasks, specifically designed for Open Graph Benchmark (OGB) datasets.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "graph_classification",
        "architecture_search",
        "automl"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LARS-research/PAS-OGB",
      "help_website": [],
      "license": null,
      "tags": [
        "graph-neural-networks",
        "architecture-search",
        "ogb",
        "classification"
      ],
      "id": 1137
    },
    {
      "name": "OpenPVSG",
      "one_line_profile": "Benchmark for Panoptic Video Scene Graph Generation",
      "detailed_description": "A benchmarking framework for Panoptic Video Scene Graph Generation (PVSG), facilitating the development and evaluation of models that understand dynamic scene graphs in videos.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "video_scene_graph",
        "benchmarking",
        "computer_vision"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/LilyDaytoy/OpenPVSG",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "video-scene-graph",
        "benchmark",
        "panoptic-segmentation"
      ],
      "id": 1138
    },
    {
      "name": "MORE",
      "one_line_profile": "Multimodal Object-Entity Relation Extraction Benchmark",
      "detailed_description": "A benchmark evaluation framework and dataset for Multimodal Object-Entity Relation Extraction, designed to assess models on extracting relations between visual objects and textual entities.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "relation_extraction",
        "multimodal_learning",
        "benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NJUNLP/MORE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multimodal",
        "relation-extraction",
        "benchmark",
        "nlp"
      ],
      "id": 1139
    },
    {
      "name": "DyKGChat",
      "one_line_profile": "Benchmark for dialogue generation on dynamic knowledge graphs",
      "detailed_description": "A model and benchmarking code for dialogue generation grounded on dynamic knowledge graphs, addressing the challenge of incorporating evolving knowledge into conversational agents.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "dialogue_generation",
        "dynamic_knowledge_graph",
        "benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Pascalson/DyKGChat",
      "help_website": [],
      "license": null,
      "tags": [
        "dialogue-system",
        "dynamic-graph",
        "knowledge-grounding"
      ],
      "id": 1140
    },
    {
      "name": "CONVEX",
      "one_line_profile": "Unsupervised conversational QA over knowledge graphs",
      "detailed_description": "An unsupervised method and framework for conversational question answering over knowledge graphs, enabling QA systems to operate without large-scale annotated training data.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "question_answering",
        "knowledge_graph",
        "unsupervised_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PhilippChr/CONVEX",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "qa",
        "knowledge-graph",
        "conversational-ai"
      ],
      "id": 1141
    },
    {
      "name": "YouGraph",
      "one_line_profile": "Graph learning library for OGB benchmarks",
      "detailed_description": "A collection of graph learning codes and models designed for the Open Graph Benchmark (OGB), facilitating the development and testing of GNNs on standard datasets.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "graph_learning",
        "benchmarking",
        "gnn"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PierreHao/YouGraph",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ogb",
        "graph-neural-networks",
        "machine-learning"
      ],
      "id": 1142
    },
    {
      "name": "OpenGDA",
      "one_line_profile": "Graph Domain Adaptation Benchmark",
      "detailed_description": "A benchmark for Graph Domain Adaptation (GDA) focusing on cross-network learning tasks, providing datasets and evaluation protocols for adapting graph models across different domains.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "domain_adaptation",
        "graph_learning",
        "benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Skyorca/OpenGDA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "domain-adaptation",
        "graph-neural-networks",
        "benchmark"
      ],
      "id": 1143
    },
    {
      "name": "Deep_GCN_Benchmarking",
      "one_line_profile": "Benchmark for training deeper Graph Neural Networks",
      "detailed_description": "A comprehensive benchmark study and codebase for training deeper Graph Neural Networks (GNNs), providing 'bag of tricks' and evaluation protocols to improve GNN performance on various tasks.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "graph_neural_networks",
        "benchmarking",
        "model_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/VITA-Group/Deep_GCN_Benchmarking",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gnn",
        "deep-learning",
        "benchmark",
        "optimization"
      ],
      "id": 1144
    },
    {
      "name": "GraphGPT",
      "one_line_profile": "Generative pre-trained graph transformer for graph structure modeling",
      "detailed_description": "A generative pre-trained graph model based on the Eulerian Transformer architecture, designed to handle graph generation and representation learning tasks, applicable to molecular and protein graph modeling.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "graph_generation",
        "representation_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/alibaba/graph-gpt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-transformer",
        "generative-model",
        "graph-learning"
      ],
      "id": 1145
    },
    {
      "name": "Graph Classification Benchmarks",
      "one_line_profile": "Benchmarking framework for Graph Neural Networks using PyTorch Lightning",
      "detailed_description": "A benchmarking suite for evaluating Graph Neural Networks (GNNs) on standard datasets like Open Graph Benchmarks (OGB) and superpixel image classification tasks, leveraging PyTorch Lightning for reproducible training loops.",
      "domains": [
        "G2-06"
      ],
      "subtask_category": [
        "benchmarking",
        "graph_classification"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ashleve/graph_classification",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gnn",
        "benchmarking",
        "pytorch-lightning"
      ],
      "id": 1146
    },
    {
      "name": "PheKnowLator",
      "one_line_profile": "Ecosystem for constructing heterogeneous biomedical knowledge graphs",
      "detailed_description": "A Python library and workflow for constructing large-scale, heterogeneous biomedical knowledge graphs from diverse data sources, supporting alternative semantic models and benchmarking.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "kg_construction",
        "data_integration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/callahantiff/PheKnowLator",
      "help_website": [
        "https://pheknowlator.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "biomedical-kg",
        "ontology",
        "semantic-web"
      ],
      "id": 1147
    },
    {
      "name": "Interpret LM Knowledge",
      "one_line_profile": "Benchmark for extracting knowledge graphs from language models",
      "detailed_description": "A diagnostic benchmark tool for extracting and evaluating knowledge graphs from pre-trained language models to interpret their internal knowledge representation.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "kg_extraction",
        "model_interpretability"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/epfml/interpret-lm-knowledge",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "language-models",
        "knowledge-extraction",
        "interpretability"
      ],
      "id": 1148
    },
    {
      "name": "SEAL_OGB",
      "one_line_profile": "SEAL implementation for link prediction on OGB datasets",
      "detailed_description": "An implementation of the SEAL (Subgraphs, Embeddings, Attributes, and Link prediction) framework specifically optimized for link prediction tasks on Open Graph Benchmark (OGB) datasets.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "link_prediction",
        "graph_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/SEAL_OGB",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ogb",
        "link-prediction",
        "gnn"
      ],
      "id": 1149
    },
    {
      "name": "Distributed KGE Poplar",
      "one_line_profile": "Distributed knowledge graph embedding system for Graphcore IPUs",
      "detailed_description": "An end-user training and evaluation system for standard knowledge graph embedding models, optimized for distributed execution on Graphcore IPU hardware using the Poplar SDK.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "knowledge_graph_embedding",
        "model_training"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/graphcore/distributed-kge-poplar",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ipu",
        "hpc",
        "kge"
      ],
      "id": 1150
    },
    {
      "name": "OGB-LSC PCQM4Mv2 Solver",
      "one_line_profile": "Graphcore implementation for OGB Large Scale Challenge PCQM4Mv2",
      "detailed_description": "Implementations and tools for the OGB Large Scale Challenge (OGB-LSC) PCQM4Mv2 dataset, focusing on graph machine learning tasks for quantum chemistry on Graphcore hardware.",
      "domains": [
        "G2-06"
      ],
      "subtask_category": [
        "graph_regression",
        "quantum_chemistry"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/graphcore/ogb-lsc-pcqm4mv2",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ogb-lsc",
        "graph-neural-networks",
        "quantum-chemistry"
      ],
      "id": 1151
    },
    {
      "name": "KGEval",
      "one_line_profile": "Fine-grained evaluation framework for Knowledge Graph Embedding models",
      "detailed_description": "A framework designed to evaluate Knowledge Graph Embedding (KGE) models in a fine-grained manner, allowing for detailed performance analysis beyond standard metrics.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/nec-research/KGEval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "knowledge-graph",
        "embedding",
        "evaluation",
        "benchmarking"
      ],
      "id": 1152
    },
    {
      "name": "GTFS-Madrid-Bench",
      "one_line_profile": "Benchmark for Knowledge Graph construction engines using transport data",
      "detailed_description": "A benchmark suite designed to evaluate the performance and scalability of Knowledge Graph construction engines (like RML mappers) using GTFS (General Transit Feed Specification) data.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "kg_construction",
        "benchmarking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/oeg-upm/gtfs-bench",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph-construction",
        "benchmark",
        "gtfs",
        "rml"
      ],
      "id": 1153
    },
    {
      "name": "Open Knowledge Graph Embeddings",
      "one_line_profile": "Library for training and benchmarking open knowledge graph embeddings",
      "detailed_description": "A library designed for training embeddings on Open Knowledge Graphs (where schema is not fixed) and benchmarking open link prediction tasks.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "embedding_learning",
        "link_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/samuelbroscheit/open_knowledge_graph_embeddings",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "open-ie",
        "knowledge-graph",
        "embedding",
        "benchmark"
      ],
      "id": 1154
    },
    {
      "name": "Open Graph Benchmark (OGB)",
      "one_line_profile": "Benchmark datasets and evaluators for graph machine learning",
      "detailed_description": "A collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs, including specific tasks for molecular property prediction and biological networks.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "benchmarking",
        "molecular_property_prediction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/snap-stanford/ogb",
      "help_website": [
        "https://ogb.stanford.edu"
      ],
      "license": "MIT",
      "tags": [
        "graph-neural-networks",
        "benchmark",
        "molecular-graphs",
        "bioinformatics"
      ],
      "id": 1155
    },
    {
      "name": "KG-Gen",
      "one_line_profile": "Tool for generating knowledge graphs from text",
      "detailed_description": "A tool leveraging sequence-to-sequence models to generate knowledge graphs directly from input text, facilitating knowledge extraction from scientific literature.",
      "domains": [
        "G2"
      ],
      "subtask_category": [
        "kg_construction",
        "information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/stair-lab/kg-gen",
      "help_website": [],
      "license": null,
      "tags": [
        "knowledge-graph-generation",
        "nlp",
        "text-to-graph"
      ],
      "id": 1156
    },
    {
      "name": "KG20C",
      "one_line_profile": "A scholarly knowledge graph benchmark dataset for link prediction and node classification",
      "detailed_description": "KG20C is a large-scale scholarly knowledge graph dataset constructed from high-quality papers, designed to serve as a benchmark for evaluating knowledge graph embedding and graph neural network models in the context of scientific literature.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "benchmarking",
        "dataset_construction"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/tranhungnghiep/KG20C",
      "help_website": [],
      "license": null,
      "tags": [
        "scholarly-knowledge-graph",
        "benchmark",
        "dataset"
      ],
      "id": 1157
    },
    {
      "name": "BioKGBench",
      "one_line_profile": "A benchmark for evaluating AI agents on biomedical knowledge graphs",
      "detailed_description": "BioKGBench is a knowledge graph checking benchmark designed to evaluate the performance of AI agents in the biomedical domain. It focuses on assessing the ability of agents to perform reasoning and fact-checking tasks within biomedical knowledge graphs.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "benchmarking",
        "biomedical_reasoning",
        "evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/westlake-autolab/BioKGBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "biomedical",
        "knowledge-graph",
        "benchmark"
      ],
      "id": 1158
    },
    {
      "name": "GraphEval",
      "one_line_profile": "Framework for evaluating LLM factuality using knowledge graphs",
      "detailed_description": "GraphEval is a tool designed to evaluate the factuality of Large Language Models (LLMs) by leveraging large-scale knowledge graphs. It provides a pipeline to check the consistency of LLM-generated content against structured knowledge bases.",
      "domains": [
        "G2",
        "G2-06"
      ],
      "subtask_category": [
        "evaluation",
        "factuality_checking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/xz-liu/GraphEval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "knowledge-graph",
        "evaluation"
      ],
      "id": 1159
    }
  ]
}