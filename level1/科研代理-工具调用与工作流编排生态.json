{
  "leaf_cluster_name": "科研代理-工具调用与工作流编排生态",
  "domain": "AI Toolchain",
  "typical_objects": "tools/workflows",
  "task_chain": "规划→调用→追踪→回放→评测→治理",
  "tool_form": "agent框架 + tracing + registry",
  "total_tools": 1246,
  "tools": [
    {
      "name": "PapersChat",
      "one_line_profile": "Agentic AI application for retrieving and chatting with scientific papers from ArXiv and PubMed",
      "detailed_description": "PapersChat is an AI agent application designed to assist researchers in literature review and information retrieval. It integrates with scientific databases like ArXiv and PubMed, allowing users to query, summarize, and extract information from research papers through a conversational interface.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "literature_review",
        "information_retrieval"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/AstraBert/PapersChat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arxiv",
        "pubmed",
        "literature-review",
        "agent"
      ],
      "id": 1
    },
    {
      "name": "Robin",
      "one_line_profile": "Multi-agent system for automating scientific discovery and experiments",
      "detailed_description": "Robin is a multi-agent system developed by Future House designed to automate the scientific discovery process. It utilizes Large Language Models (LLMs) to plan, execute, and analyze scientific experiments, specifically targeting research in biology and chemistry. It can perform literature reviews, formulate hypotheses, and orchestrate lab automation tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "scientific_discovery",
        "experiment_automation",
        "literature_review"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Future-House/robin",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent",
        "scientific-discovery",
        "lab-automation",
        "llm"
      ],
      "id": 2
    },
    {
      "name": "Adala",
      "one_line_profile": "Autonomous data labeling agent framework",
      "detailed_description": "Adala is an agent framework designed for autonomous data processing, specifically focusing on data labeling tasks. It allows researchers to create agents that can learn from feedback and improve their labeling quality, essential for creating high-quality datasets for scientific machine learning.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "data_labeling",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HumanSignal/Adala",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-labeling",
        "autonomous-agents",
        "dataset-creation"
      ],
      "id": 3
    },
    {
      "name": "PII Masker",
      "one_line_profile": "AI-powered PII detection and masking tool",
      "detailed_description": "PII Masker utilizes advanced AI models (DeBERTa-v3) to automatically detect and mask Personally Identifiable Information (PII) in datasets. This is critical for processing sensitive scientific data, such as medical records or social science survey data, ensuring privacy compliance.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "data_privacy",
        "data_cleaning"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/HydroXai/pii-masker",
      "help_website": [],
      "license": null,
      "tags": [
        "pii-masking",
        "data-privacy",
        "deberta"
      ],
      "id": 4
    },
    {
      "name": "Hephaestus",
      "one_line_profile": "Semi-structured agentic framework for self-building workflows",
      "detailed_description": "Hephaestus is an agentic framework where workflows are dynamically constructed by agents based on task discovery rather than predefined paths. This adaptive orchestration is valuable for complex, non-linear scientific problem solving where the solution path is not known a priori.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "agent_planning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Ido-Levi/Hephaestus",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "agent-framework",
        "dynamic-workflow",
        "orchestration"
      ],
      "id": 5
    },
    {
      "name": "CommonGround",
      "one_line_profile": "Platform for building and collaborating with AI agent teams",
      "detailed_description": "CommonGround is an application designed to facilitate the construction, observation, and collaboration of multi-agent teams. It provides a shared environment for agents to interact, which is useful for simulating multi-agent systems or coordinating complex research tasks involving multiple specialized agents.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multi_agent_collaboration",
        "agent_observation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Intelligent-Internet/CommonGround",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "multi-agent",
        "collaboration",
        "agent-platform"
      ],
      "id": 6
    },
    {
      "name": "MindSearch",
      "one_line_profile": "LLM-based multi-agent framework for deep web search",
      "detailed_description": "MindSearch is a multi-agent framework designed to mimic human search behavior for complex information retrieval tasks. It is particularly effective for scientific literature review and information gathering, capable of synthesizing answers from multiple web sources similar to Perplexity.ai but as an open framework.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "information_retrieval",
        "literature_review"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/InternLM/MindSearch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "web-search",
        "multi-agent",
        "information-retrieval"
      ],
      "id": 7
    },
    {
      "name": "AGiXT",
      "one_line_profile": "Dynamic AI agent automation and orchestration platform",
      "detailed_description": "AGiXT is a comprehensive platform for managing and orchestrating AI agents. It supports instruction management, complex task execution, and adaptive memory across various AI providers. In scientific contexts, it serves as a robust infrastructure for building autonomous research assistants and lab automation agents.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "workflow_automation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Josh-XT/AGiXT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-platform",
        "automation",
        "orchestration"
      ],
      "id": 8
    },
    {
      "name": "Agent Service Toolkit",
      "one_line_profile": "Toolkit for building and deploying AI agent services",
      "detailed_description": "This toolkit provides a complete stack (LangGraph, FastAPI, Streamlit) for developing and deploying AI agent services. It facilitates the creation of robust, service-oriented research agents that can be integrated into larger scientific workflows or accessible via APIs.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_deployment",
        "service_creation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/JoshuaC215/agent-service-toolkit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "langgraph",
        "agent-service",
        "deployment"
      ],
      "id": 9
    },
    {
      "name": "JudgeVal",
      "one_line_profile": "Agent evaluation and post-training framework",
      "detailed_description": "JudgeVal is a framework designed for the post-building layer of agents, focusing on evaluation and monitoring. It provides tools for Reinforcement Learning (RL) and Supervised Fine-Tuning (SFT) based on agent performance, which is crucial for optimizing scientific agents to ensure accuracy and reliability.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "model_evaluation",
        "agent_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/JudgmentLabs/judgeval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "rlhf",
        "agent-monitoring"
      ],
      "id": 10
    },
    {
      "name": "Klavis",
      "one_line_profile": "Platform for reliable tool integration with AI agents (MCP)",
      "detailed_description": "Klavis is a platform that facilitates the integration of tools with AI agents, likely leveraging the Model Context Protocol (MCP). It ensures reliable tool usage at scale, which is essential for scientific agents that need to interact with diverse databases, simulation software, and analysis scripts.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "tool_integration",
        "agent_infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Klavis-AI/klavis",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mcp",
        "tool-use",
        "agent-integration"
      ],
      "id": 11
    },
    {
      "name": "KwaiAgents",
      "one_line_profile": "Generalized information-seeking agent system",
      "detailed_description": "KwaiAgents is a system designed for information seeking using Large Language Models. It supports the creation of agents capable of retrieving, processing, and synthesizing information, which is directly applicable to scientific literature mining and data gathering tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "information_retrieval",
        "agent_system"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KwaiKEG/KwaiAgents",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "information-seeking",
        "llm-agent",
        "search"
      ],
      "id": 12
    },
    {
      "name": "CrewAI-GUI-Qt",
      "one_line_profile": "Node-based GUI for CrewAI workflow creation",
      "detailed_description": "This tool provides a visual, node-based interface for designing and managing CrewAI agents and workflows. It simplifies the orchestration of complex multi-agent systems, making it easier for researchers to design agentic workflows without deep coding.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_design",
        "visual_programming"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/LangGraph-GUI/CrewAI-GUI-Qt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gui",
        "crewai",
        "workflow-editor"
      ],
      "id": 13
    },
    {
      "name": "LazyLLM",
      "one_line_profile": "Low-code framework for building multi-agent LLM applications",
      "detailed_description": "LazyLLM is a framework designed to simplify the construction of multi-agent LLM applications. It provides abstractions that allow researchers to quickly prototype and deploy agent-based solutions for tasks like data analysis or automated reasoning without extensive boilerplate code.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_development",
        "rapid_prototyping"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/LazyAGI/LazyLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "low-code",
        "llm-framework"
      ],
      "id": 14
    },
    {
      "name": "AutoAgents",
      "one_line_profile": "Framework for automatic agent role generation and collaboration",
      "detailed_description": "AutoAgents is a framework that automatically generates different agent roles to form a collaborative entity for complex tasks. Based on IJCAI 2024 research, it is useful for scientific problem solving where the optimal team structure of agents is not known in advance.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multi_agent_collaboration",
        "role_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Link-AGI/AutoAgents",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multi-agent",
        "collaboration",
        "adaptive-agents"
      ],
      "id": 15
    },
    {
      "name": "MARM Systems",
      "one_line_profile": "Universal MCP server for agent memory and coordination",
      "detailed_description": "MARM Systems implements a Universal MCP (Model Context Protocol) Server that enables cross-platform AI memory and multi-agent coordination. It provides the infrastructure for agents to maintain persistent context and reason in a structured manner, which is vital for long-running scientific research assistants.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_memory",
        "infrastructure"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lyellr88/MARM-Systems",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "memory",
        "agent-coordination"
      ],
      "id": 16
    },
    {
      "name": "Open Assistant API",
      "one_line_profile": "Self-hosted agent orchestration and creation framework",
      "detailed_description": "The Open Assistant API is an open-source framework for orchestrating and creating agents/GPTs. It supports extensions for RAG, function calling, and tools, making it a viable backend for deploying custom scientific research assistants within a secure, self-hosted environment.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "api_service"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MLT-OSS/open-assistant-api",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "orchestration",
        "self-hosted",
        "rag"
      ],
      "id": 17
    },
    {
      "name": "SurfSense",
      "one_line_profile": "Open source research assistant and knowledge connector",
      "detailed_description": "SurfSense is an open-source alternative to tools like NotebookLM and Perplexity. It connects to various data sources (search engines, GitHub, Notion) to aggregate and synthesize information, serving as a powerful assistant for scientific literature review and knowledge management.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "knowledge_management",
        "literature_review"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/MODSetter/SurfSense",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "research-assistant",
        "knowledge-base",
        "search"
      ],
      "id": 18
    },
    {
      "name": "d2s-cli",
      "one_line_profile": "CLI for orchestrating data integration into RDF Knowledge Graphs",
      "detailed_description": "d2s-cli is a command-line tool developed by the Institute of Data Science at Maastricht University. It orchestrates the integration of heterogeneous data sources into a common RDF Knowledge Graph using RML mappings, facilitating semantic data interoperability in scientific projects.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "data_integration",
        "knowledge_graph_construction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MaastrichtU-IDS/d2s-cli",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rdf",
        "knowledge-graph",
        "data-integration"
      ],
      "id": 19
    },
    {
      "name": "LangChain-GPT-Researcher",
      "one_line_profile": "LangChain tool wrapper for GPT-Researcher",
      "detailed_description": "This repository provides a LangChain tool wrapper for GPT-Researcher, allowing the autonomous research agent to be easily integrated into broader LangChain-based workflows and agents. It enables automated online research and report generation within custom agent pipelines.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "literature_review",
        "automated_research"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Makesh-Srinivasan/LangChain-GPT-Researcher",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "langchain",
        "research-agent",
        "wrapper"
      ],
      "id": 20
    },
    {
      "name": "P_MAS_TG",
      "one_line_profile": "Planner for multi-agent systems with temporal logic goals",
      "detailed_description": "A C-based implementation of a planner for multi-agent systems that handles temporal goals, suitable for robotics and control theory research.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "path_planning",
        "motion_planning"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/MengGuo/P_MAS_TG",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "multi-agent",
        "planning",
        "robotics",
        "temporal-logic"
      ],
      "id": 21
    },
    {
      "name": "RVO_Py_MAS",
      "one_line_profile": "Python implementation of Reciprocal Velocity Obstacle for multi-agent systems",
      "detailed_description": "A Python implementation of the Reciprocal Velocity Obstacle (RVO) algorithm, used for collision avoidance and path planning in multi-agent simulations.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "simulation",
        "collision_avoidance"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MengGuo/RVO_Py_MAS",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "rvo",
        "multi-agent",
        "simulation",
        "robotics"
      ],
      "id": 22
    },
    {
      "name": "MiroThinker",
      "one_line_profile": "Agentic models designed for deep research and complex reasoning",
      "detailed_description": "A series of open-source agentic models and systems trained specifically for deep research tasks and complex tool usage, enabling automated literature review and information synthesis.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "literature_review",
        "scientific_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MiroMindAI/MiroThinker",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "deep-research",
        "agentic-models",
        "reasoning"
      ],
      "id": 23
    },
    {
      "name": "PowerGridworld",
      "one_line_profile": "Multi-agent Gym environments for power systems simulation",
      "detailed_description": "A framework for creating power-systems-focused, multi-agent Reinforcement Learning (RL) environments, enabling simulation and control research in energy grids.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "simulation",
        "power_systems_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NREL/PowerGridworld",
      "help_website": [
        "https://arxiv.org/abs/2111.05969"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "power-systems",
        "reinforcement-learning",
        "simulation",
        "gym-environment"
      ],
      "id": 24
    },
    {
      "name": "TensorRT-LLM",
      "one_line_profile": "High-performance inference optimizer for Large Language Models",
      "detailed_description": "A library for defining and optimizing Large Language Models (LLMs) for efficient inference on NVIDIA GPUs, essential for high-throughput scientific text processing and agent execution.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "inference_optimization",
        "model_deployment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/TensorRT-LLM",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "inference",
        "optimization",
        "llm",
        "gpu"
      ],
      "id": 25
    },
    {
      "name": "LLM-Planner",
      "one_line_profile": "Few-shot grounded planning for embodied agents",
      "detailed_description": "A system for embodied agents that uses Large Language Models to generate grounded plans for physical tasks, applicable in robotics and physical simulation research.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "task_planning",
        "embodied_ai"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/OSU-NLP-Group/LLM-Planner",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "planning",
        "robotics",
        "llm",
        "embodied-agents"
      ],
      "id": 26
    },
    {
      "name": "Open-Probe",
      "one_line_profile": "Agent-based deep research search system",
      "detailed_description": "An advanced agent-based search system that performs deep web searches to answer complex questions, suitable for scientific literature review and information gathering.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "literature_review",
        "information_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Open-Probe/Open-Probe",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "deep-research",
        "search-agent",
        "langgraph"
      ],
      "id": 27
    },
    {
      "name": "AgentVerse",
      "one_line_profile": "Framework for multi-agent simulation and task solving",
      "detailed_description": "A framework designed to facilitate the deployment of multiple LLM-based agents for various applications, including social simulation and complex task solving in research contexts.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "simulation",
        "multi_agent_coordination"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/OpenBMB/AgentVerse",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "simulation",
        "llm",
        "framework"
      ],
      "id": 28
    },
    {
      "name": "IoA",
      "one_line_profile": "Internet of Agents framework for collaborative AI",
      "detailed_description": "An open-source framework enabling diverse, distributed agents to team up and tackle complex tasks through internet-like connectivity, facilitating large-scale agent research.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "distributed_computing",
        "agent_coordination"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenBMB/IoA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-agents",
        "collaboration",
        "framework"
      ],
      "id": 29
    },
    {
      "name": "WorkflowLLM",
      "one_line_profile": "Platform for LLM workflow orchestration",
      "detailed_description": "An open platform for enhancing the capability of LLMs in workflow orchestration, enabling the design of complex procedural tasks for scientific agents.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "process_automation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenBMB/WorkflowLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "workflow",
        "orchestration",
        "llm"
      ],
      "id": 30
    },
    {
      "name": "XAgent",
      "one_line_profile": "Autonomous LLM Agent for complex task solving",
      "detailed_description": "An autonomous LLM agent designed for solving complex tasks, capable of self-planning and tool usage, applicable to automated scientific problem solving.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "autonomous_problem_solving",
        "task_planning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenBMB/XAgent",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "autonomous-agent",
        "complex-tasks",
        "llm"
      ],
      "id": 31
    },
    {
      "name": "Ask-Anything",
      "one_line_profile": "Video understanding and analysis tool using LLMs",
      "detailed_description": "A multimodal tool combining ChatGPT with video understanding models to perform complex analysis and question answering on video data.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "video_analysis",
        "multimodal_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/Ask-Anything",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "video-understanding",
        "multimodal",
        "chatgpt"
      ],
      "id": 32
    },
    {
      "name": "OpenRLHF",
      "one_line_profile": "High-performance RLHF framework for model alignment",
      "detailed_description": "A scalable and high-performance framework for Reinforcement Learning from Human Feedback (RLHF), used for aligning and training large models, including those for scientific domains.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "model_training",
        "alignment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenRLHF/OpenRLHF",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "reinforcement-learning",
        "model-alignment"
      ],
      "id": 33
    },
    {
      "name": "local-rag-llamaindex",
      "one_line_profile": "Local RAG tool for research paper navigation",
      "detailed_description": "A local Retrieval-Augmented Generation (RAG) tool built with LlamaIndex, specifically designed to assist researchers in quickly navigating and querying research papers.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "literature_review",
        "document_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Otman404/local-rag-llamaindex",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "research-assistant",
        "llamaindex"
      ],
      "id": 34
    },
    {
      "name": "ControlFlow",
      "one_line_profile": "Python framework for building task-centric AI agents with defined workflows",
      "detailed_description": "ControlFlow is a Python framework designed to create AI agents with structured, task-centric workflows. It allows developers to define tasks, assign them to specialized agents, and orchestrate their execution, providing a higher level of control over agent behavior compared to purely autonomous loops. It integrates with Prefect for workflow orchestration.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "agent_management"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/PrefectHQ/ControlFlow",
      "help_website": [
        "https://controlflow.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "agent-framework",
        "workflow",
        "orchestration",
        "python"
      ],
      "id": 35
    },
    {
      "name": "Nexus",
      "one_line_profile": "Python framework for orchestrating AI agents and managing LLM-driven tasks",
      "detailed_description": "Nexus is a Python framework designed to simplify the orchestration of AI agents. It provides abstractions for managing complex tasks driven by Large Language Models (LLMs), enabling developers to build multi-agent systems that can collaborate to solve problems.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "task_management"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/PrimisAI/nexus",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-orchestration",
        "llm",
        "python"
      ],
      "id": 36
    },
    {
      "name": "go-agent",
      "one_line_profile": "Production-ready Agent framework for Go with graph-aware memory",
      "detailed_description": "go-agent is an agent framework built for the Go programming language. It features graph-aware memory, native support for UTCP (Universal Tool Call Protocol) tools, and capabilities for multi-agent orchestration, designed for production environments.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_framework",
        "multi_agent_orchestration"
      ],
      "application_level": "framework",
      "primary_language": "Go",
      "repo_url": "https://github.com/Protocol-Lattice/go-agent",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "go",
        "agent-framework",
        "graph-memory"
      ],
      "id": 37
    },
    {
      "name": "PySpur",
      "one_line_profile": "Visual playground and workflow builder for agentic AI systems",
      "detailed_description": "PySpur is a visual tool and framework for building, iterating, and managing agentic workflows. It provides a graph-based interface to design agent interactions and workflows, aiming to accelerate the development cycle of AI agents.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_design",
        "visual_programming"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/PySpur-Dev/pyspur",
      "help_website": [
        "https://pyspur.dev"
      ],
      "license": "Apache-2.0",
      "tags": [
        "visual-editor",
        "agent-workflow",
        "low-code"
      ],
      "id": 38
    },
    {
      "name": "Ragna",
      "one_line_profile": "Orchestration framework for Retrieval-Augmented Generation (RAG)",
      "detailed_description": "Ragna is a Python-based orchestration framework specifically designed for Retrieval-Augmented Generation (RAG). It provides a flexible architecture to swap out components (LLMs, vector databases) and manage the RAG pipeline, suitable for scientific and enterprise knowledge retrieval tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "rag_orchestration",
        "knowledge_retrieval"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Quansight/ragna",
      "help_website": [
        "https://ragna.chat"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "rag",
        "orchestration",
        "python"
      ],
      "id": 39
    },
    {
      "name": "Qwen-Agent",
      "one_line_profile": "Agent framework built upon Qwen LLMs with tool use and RAG capabilities",
      "detailed_description": "Qwen-Agent is a framework for developing AI agents, optimized for the Qwen series of Large Language Models. It supports advanced features like function calling, code interpretation, Retrieval-Augmented Generation (RAG), and Chrome extension integration for browser-based tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_framework",
        "tool_use"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/QwenLM/Qwen-Agent",
      "help_website": [
        "https://qwenlm.github.io/Qwen-Agent/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "qwen",
        "agent-framework",
        "rag",
        "function-calling"
      ],
      "id": 40
    },
    {
      "name": "Relevance AI",
      "one_line_profile": "Platform for building and deploying multi-agent systems",
      "detailed_description": "Relevance AI is a platform and SDK for building, deploying, and managing multi-agent systems. It provides tools for chaining agents, handling vector storage, and orchestrating complex workflows for the AI workforce.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multi_agent_system",
        "agent_deployment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/RelevanceAI/relevanceai",
      "help_website": [
        "https://docs.relevanceai.com"
      ],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "platform",
        "sdk"
      ],
      "id": 41
    },
    {
      "name": "Agent-Wiz",
      "one_line_profile": "CLI tool for threat modeling and visualizing AI agents",
      "detailed_description": "Agent-Wiz is a command-line interface tool designed to assist in the development of AI agents by providing threat modeling and visualization capabilities. It supports popular frameworks like LangGraph, AutoGen, and CrewAI, helping developers understand and secure agent interactions.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_visualization",
        "security_analysis"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/Repello-AI/Agent-Wiz",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "threat-modeling",
        "agent-security"
      ],
      "id": 42
    },
    {
      "name": "Collaborative Gym",
      "one_line_profile": "Framework for building and evaluating collaborative human-agent teams",
      "detailed_description": "Collaborative Gym is a framework and toolkit designed to facilitate the creation and evaluation of agents that collaborate with humans. It provides environments and metrics for assessing the performance of human-AI teams in collaborative tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_evaluation",
        "human_ai_collaboration"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/SALT-NLP/collaborative-gym",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "collaboration",
        "evaluation",
        "human-ai"
      ],
      "id": 43
    },
    {
      "name": "AgentLaboratory",
      "one_line_profile": "End-to-end autonomous research workflow for scientific discovery",
      "detailed_description": "Agent Laboratory is an autonomous research workflow system designed to assist researchers. It acts as an AI co-scientist, capable of planning, executing, and managing research tasks, effectively implementing an end-to-end pipeline for scientific inquiry.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "autonomous_research",
        "scientific_workflow"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/SamuelSchmidgall/AgentLaboratory",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "autonomous-science",
        "research-agent",
        "workflow"
      ],
      "id": 44
    },
    {
      "name": "GPT-Agent (CAMEL)",
      "one_line_profile": "Role-playing multi-agent framework for autonomous task solving",
      "detailed_description": "GPT-Agent (implementing the CAMEL framework) is a multi-agent system that utilizes role-playing to facilitate collaboration between AI agents. It enables agents to simulate user-assistant interactions to solve complex tasks autonomously.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multi_agent_collaboration",
        "role_playing"
      ],
      "application_level": "framework",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/SamurAIGPT/GPT-Agent",
      "help_website": [
        "https://www.camel-ai.org/"
      ],
      "license": "MIT",
      "tags": [
        "camel",
        "multi-agent",
        "role-playing"
      ],
      "id": 45
    },
    {
      "name": "Scrapecraft",
      "one_line_profile": "Visual workflow builder for AI-powered web scraping agents",
      "detailed_description": "Scrapecraft is a visual editor and workflow builder for ScrapeGraphAI. It allows users to create, test, and deploy web scraping agents using natural language and a visual interface, facilitating data acquisition for research and analysis.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "data_acquisition",
        "visual_workflow"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/ScrapeGraphAI/scrapecraft",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scraping",
        "visual-editor",
        "agent-workflow"
      ],
      "id": 46
    },
    {
      "name": "AutoGPT",
      "one_line_profile": "Autonomous AI agent framework for goal-oriented task execution",
      "detailed_description": "AutoGPT is an open-source experimental application that demonstrates the capabilities of the GPT-4 language model. It chains together LLM 'thoughts' to autonomously achieve whatever goal is set, serving as a foundational framework for autonomous agent research and development.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "autonomous_agent",
        "task_execution"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Significant-Gravitas/AutoGPT",
      "help_website": [
        "https://agpt.co"
      ],
      "license": "NOASSERTION",
      "tags": [
        "autonomous-agent",
        "gpt-4",
        "automation"
      ],
      "id": 47
    },
    {
      "name": "AutoGPT-Code-Ability",
      "one_line_profile": "Coding capability module for AutoGPT agents",
      "detailed_description": "AutoGPT-Code-Ability is a specialized module for the AutoGPT framework that empowers agents to write, analyze, and execute code. This capability is essential for agents performing data analysis, simulation, or software-driven research tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "code_generation",
        "tool_use"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Significant-Gravitas/AutoGPT-Code-Ability",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "coding-agent",
        "autogpt-plugin"
      ],
      "id": 48
    },
    {
      "name": "DeepResearchAgent",
      "one_line_profile": "Hierarchical multi-agent system for deep research and task solving",
      "detailed_description": "DeepResearchAgent is a hierarchical multi-agent framework designed for complex task solving, particularly deep research. It employs a top-level planner to coordinate specialized sub-agents, enabling automated decomposition and execution of intricate research workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "research_automation",
        "hierarchical_planning"
      ],
      "application_level": "framework",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/SkyworkAI/DeepResearchAgent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "research-agent",
        "multi-agent",
        "planning"
      ],
      "id": 49
    },
    {
      "name": "SmythOS Runtime Environment (SRE)",
      "one_line_profile": "Cloud-native runtime for deploying and managing agentic AI",
      "detailed_description": "The SmythOS Runtime Environment (SRE) is a runtime system for executing and managing intelligent agents. It supports deployment across local, cloud, and edge environments, providing a secure and modular foundation for agentic AI applications.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_runtime",
        "deployment"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/SmythOS/sre",
      "help_website": [
        "https://smythos.com"
      ],
      "license": "MIT",
      "tags": [
        "agent-runtime",
        "cloud-native",
        "edge-ai"
      ],
      "id": 50
    },
    {
      "name": "Solace Agent Mesh",
      "one_line_profile": "Event-driven framework for orchestrating multi-agent systems",
      "detailed_description": "Solace Agent Mesh is a framework that uses an event-driven architecture to build and orchestrate multi-agent AI systems. It facilitates the integration of agents with real-time data streams and systems, enabling complex, asynchronous workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "event_driven_orchestration",
        "multi_agent_system"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/SolaceLabs/solace-agent-mesh",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "event-driven",
        "agent-mesh",
        "orchestration"
      ],
      "id": 51
    },
    {
      "name": "LLMCompiler",
      "one_line_profile": "LLM Compiler for optimizing parallel function calling",
      "detailed_description": "LLMCompiler is a framework designed to optimize the execution of LLM function calls. It acts as a compiler that plans and executes function calls in parallel where possible, significantly speeding up complex agentic tasks that require multiple tool interactions.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "function_calling",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SqueezeAILab/LLMCompiler",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "compiler",
        "parallel-execution",
        "function-calling"
      ],
      "id": 52
    },
    {
      "name": "AppWorld",
      "one_line_profile": "Environment and benchmark for interactive coding agents",
      "detailed_description": "AppWorld is a controllable environment and benchmarking suite designed to evaluate interactive coding agents and function calling capabilities. It simulates a world of apps and people, providing a rigorous testbed for agentic systems.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_benchmarking",
        "environment_simulation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/StonyBrookNLP/appworld",
      "help_website": [
        "https://appworld.github.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "agent-environment",
        "function-calling"
      ],
      "id": 53
    },
    {
      "name": "Tribe",
      "one_line_profile": "Low-code tool for building and coordinating multi-agent teams",
      "detailed_description": "Tribe is a low-code platform and framework designed to rapidly build, deploy, and coordinate teams of AI agents. It simplifies the creation of multi-agent systems, making agent orchestration accessible for various tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multi_agent_coordination",
        "low_code_development"
      ],
      "application_level": "framework",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/StreetLamb/tribe",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "low-code",
        "multi-agent",
        "coordination"
      ],
      "id": 54
    },
    {
      "name": "AdalFlow",
      "one_line_profile": "Library for building and auto-optimizing LLM applications",
      "detailed_description": "AdalFlow is a Python library designed to build and automatically optimize Large Language Model (LLM) applications. It focuses on the optimization pipeline for agentic workflows, helping to tune prompts and flows for better performance.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "pipeline_optimization",
        "llm_workflow"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SylphAI-Inc/AdalFlow",
      "help_website": [
        "https://adalflow.sylphai.com"
      ],
      "license": "MIT",
      "tags": [
        "optimization",
        "llm-pipeline",
        "auto-tuning"
      ],
      "id": 55
    },
    {
      "name": "verl-tool",
      "one_line_profile": "Extension of VERL framework supporting diverse tool use for RLHF",
      "detailed_description": "verl-tool is a version of the VERL (Volatile Experience Replay Learning) framework extended to support diverse tool usage. It is designed for research in Reinforcement Learning from Human Feedback (RLHF) where agents need to interact with external tools.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "rlhf",
        "tool_use_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/TIGER-AI-Lab/verl-tool",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rlhf",
        "tool-use",
        "reinforcement-learning"
      ],
      "id": 56
    },
    {
      "name": "TaskingAI",
      "one_line_profile": "Open source platform for AI-native application development and agent management",
      "detailed_description": "TaskingAI is a platform designed for developing and managing AI-native applications. It provides a unified interface for managing models, assistants (agents), tools, and retrievals, simplifying the backend infrastructure for agentic systems.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_management",
        "backend_infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/TaskingAI/TaskingAI",
      "help_website": [
        "https://tasking.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "baas",
        "agent-platform",
        "ai-native"
      ],
      "id": 57
    },
    {
      "name": "WeKnora",
      "one_line_profile": "LLM-powered framework for deep document understanding and RAG",
      "detailed_description": "WeKnora is a framework leveraging LLMs for deep document understanding and semantic retrieval using the RAG (Retrieval-Augmented Generation) paradigm. It is suitable for processing scientific literature and extracting context-aware information.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "rag",
        "document_understanding"
      ],
      "application_level": "framework",
      "primary_language": "Go",
      "repo_url": "https://github.com/Tencent/WeKnora",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "document-analysis",
        "semantic-retrieval"
      ],
      "id": 58
    },
    {
      "name": "youtu-agent",
      "one_line_profile": "Simple and powerful agent framework supporting open-source models",
      "detailed_description": "youtu-agent is a lightweight yet capable agent framework developed by Tencent Cloud. It is designed to work effectively with open-source models, providing essential abstractions for building agentic applications.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_framework",
        "model_integration"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/TencentCloudADP/youtu-agent",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "agent-framework",
        "open-source-models"
      ],
      "id": 59
    },
    {
      "name": "AppAgent",
      "one_line_profile": "Multimodal agent framework for operating smartphone apps",
      "detailed_description": "AppAgent is a multimodal agent framework that enables LLMs to operate smartphone applications like human users. It uses visual perception and action simulation to interact with GUI elements, useful for automating data collection or testing in mobile environments.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multimodal_agent",
        "gui_automation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/TencentQQGYLab/AppAgent",
      "help_website": [
        "https://appagent-official.github.io"
      ],
      "license": "MIT",
      "tags": [
        "multimodal",
        "mobile-agent",
        "automation"
      ],
      "id": 60
    },
    {
      "name": "ActionWeaver",
      "one_line_profile": "Library to simplify function calling and tool management for LLMs",
      "detailed_description": "ActionWeaver is a Python library designed to streamline the process of function calling with Large Language Models. It provides decorators and utilities to easily expose Python functions as tools to LLMs, facilitating the development of agentic capabilities.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "tool_calling",
        "function_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TengHu/ActionWeaver",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "function-calling",
        "tool-management",
        "llm-utils"
      ],
      "id": 61
    },
    {
      "name": "PocketFlow",
      "one_line_profile": "Minimalist LLM framework for building agents",
      "detailed_description": "PocketFlow is a lightweight, minimalist framework for building LLM agents. It emphasizes simplicity and the concept of 'Agents building Agents', providing a core set of primitives for constructing agentic workflows with minimal code.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_framework",
        "minimalist_design"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/The-Pocket/PocketFlow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "minimalist",
        "agent-framework",
        "python"
      ],
      "id": 62
    },
    {
      "name": "COVINS",
      "one_line_profile": "Framework for collaborative visual-inertial SLAM and multi-agent 3D mapping",
      "detailed_description": "A generic framework for collaborative Visual-Inertial SLAM (Simultaneous Localization and Mapping) that enables multi-agent 3D mapping and state estimation, applicable in robotics and autonomous systems research.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "slam",
        "3d_mapping",
        "state_estimation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/VIS4ROB-lab/covins",
      "help_website": [],
      "license": null,
      "tags": [
        "slam",
        "robotics",
        "multi-agent",
        "visual-inertial"
      ],
      "id": 63
    },
    {
      "name": "MMedAgent",
      "one_line_profile": "Multi-modal agent framework for learning to use medical tools",
      "detailed_description": "A research framework and agent system designed to handle medical tasks by learning to utilize various medical tools and processing multi-modal medical data.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "medical_diagnosis",
        "tool_learning",
        "multi_modal_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Wangyixinxin/MMedAgent",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-agent",
        "multi-modal",
        "healthcare",
        "tool-use"
      ],
      "id": 64
    },
    {
      "name": "MAC-Ego3D",
      "one_line_profile": "Multi-agent Gaussian consensus for collaborative ego-motion and 3D reconstruction",
      "detailed_description": "A system for real-time collaborative ego-motion estimation and photorealistic 3D reconstruction using multi-agent Gaussian consensus, applicable in computer vision and spatial modeling.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "3d_reconstruction",
        "ego_motion_estimation",
        "gaussian_splatting"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/Xiaohao-Xu/MAC-Ego3D",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "3d-reconstruction",
        "computer-vision",
        "multi-agent",
        "gaussian-splatting"
      ],
      "id": 65
    },
    {
      "name": "Robust-and-cooperative-formation-control",
      "one_line_profile": "Simulation for robust and cooperative formation control of nonlinear multi-agent systems",
      "detailed_description": "A MATLAB-based simulation toolkit for researching and validating robust cooperative formation control algorithms in nonlinear multi-agent systems, relevant to control theory and robotics.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "formation_control",
        "simulation",
        "multi_agent_control"
      ],
      "application_level": "solver",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/YangFei9606/Robust-and-cooperative-formation-control-of-nonlinear-multi-agent-systems",
      "help_website": [],
      "license": null,
      "tags": [
        "control-theory",
        "multi-agent-systems",
        "formation-control",
        "matlab"
      ],
      "id": 66
    },
    {
      "name": "ego-planner-swarm",
      "one_line_profile": "Efficient single/multi-agent trajectory planner for multicopters",
      "detailed_description": "A trajectory planning framework for multicopter swarms, enabling efficient navigation and obstacle avoidance in complex environments, used in robotics and autonomous systems.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "trajectory_planning",
        "navigation",
        "swarm_robotics"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ZJU-FAST-Lab/ego-planner-swarm",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "trajectory-planning",
        "robotics",
        "swarm",
        "multicopter"
      ],
      "id": 67
    },
    {
      "name": "DeepLake",
      "one_line_profile": "Database for AI optimized for deep learning and LLM applications",
      "detailed_description": "A data lake for deep learning that stores vectors, images, texts, and videos. It enables streaming data to PyTorch/TensorFlow and serves as a vector store/memory for LLM agents, facilitating efficient data management for AI research.",
      "domains": [
        "AI5",
        "AI4-01"
      ],
      "subtask_category": [
        "data_storage",
        "vector_database",
        "agent_memory"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/activeloopai/deeplake",
      "help_website": [
        "https://docs.activeloop.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "database",
        "vector-store",
        "deep-learning",
        "agent-memory"
      ],
      "id": 68
    },
    {
      "name": "Agent Zero",
      "one_line_profile": "Personal AI agent framework for autonomous task execution",
      "detailed_description": "An AI framework designed to create autonomous agents capable of using the computer, writing code, and executing terminal commands. It serves as a foundation for building research assistants that can automate computational tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_framework",
        "task_automation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/agent0ai/agent-zero",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "agent",
        "automation",
        "llm"
      ],
      "id": 69
    },
    {
      "name": "Jido",
      "one_line_profile": "Autonomous agent framework for Elixir",
      "detailed_description": "A framework for building distributed, autonomous agents in Elixir. It provides primitives for dynamic workflows and agent behaviors, suitable for building scalable multi-agent systems in distributed computing environments.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_framework",
        "distributed_computing"
      ],
      "application_level": "framework",
      "primary_language": "Elixir",
      "repo_url": "https://github.com/agentjido/jido",
      "help_website": [
        "https://hexdocs.pm/jido"
      ],
      "license": "Apache-2.0",
      "tags": [
        "elixir",
        "agent",
        "distributed-systems"
      ],
      "id": 70
    },
    {
      "name": "agentUniverse",
      "one_line_profile": "Industrial-grade multi-agent framework for LLM applications",
      "detailed_description": "A multi-agent framework that provides standard components for building collaborative agent patterns. It focuses on orchestration, knowledge integration, and tool management, suitable for complex domain-specific problem solving.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "multi_agent_system"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/agentuniverse-ai/agentUniverse",
      "help_website": [
        "https://agentuniverse.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "llm",
        "orchestration"
      ],
      "id": 71
    },
    {
      "name": "Waggle Dance",
      "one_line_profile": "Concurrent agent orchestration tool",
      "detailed_description": "A tool for automating knowledge work by orchestrating multiple AI agents. It focuses on breaking down tasks and managing the execution flow between different agentic capabilities.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_automation",
        "agent_orchestration"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/agi-merge/waggle-dance",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent",
        "automation",
        "workflow"
      ],
      "id": 72
    },
    {
      "name": "Agno",
      "one_line_profile": "Unified framework for building multi-modal AI agents",
      "detailed_description": "A comprehensive stack (formerly Phidata) for building multi-agent systems with memory, knowledge, and tools. It supports creating agents that can perform research, analyze data, and interact with various APIs.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_framework",
        "multi_agent_system"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/agno-agi/agno",
      "help_website": [
        "https://docs.agno.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "llm",
        "memory"
      ],
      "id": 73
    },
    {
      "name": "ACI",
      "one_line_profile": "Open source tool-calling platform and MCP server",
      "detailed_description": "A platform that provides a unified interface for AI agents to call external tools via the Model Context Protocol (MCP). It acts as a bridge between LLMs and executable functions/APIs, essential for agentic workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "tool_calling",
        "interoperability"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/aipotheosis-labs/aci",
      "help_website": [
        "https://aci.dev/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mcp",
        "tool-use",
        "agent-infrastructure"
      ],
      "id": 74
    },
    {
      "name": "Gate22",
      "one_line_profile": "Governance and control plane for AI agents",
      "detailed_description": "A gateway and control plane for managing Model Context Protocol (MCP) connections. It allows teams to govern, audit, and control which tools and data sources AI agents can access.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "governance",
        "security",
        "agent_management"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/aipotheosis-labs/gate22",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mcp",
        "governance",
        "security"
      ],
      "id": 75
    },
    {
      "name": "AIWaves Agents",
      "one_line_profile": "Framework for data-centric self-evolving agents",
      "detailed_description": "An open-source framework designed for building autonomous language agents that can evolve and adapt. It emphasizes data-centric approaches to agent behavior and long-term memory management.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_framework",
        "adaptive_learning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/aiwaves-cn/agents",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "autonomous-agents",
        "self-evolving",
        "llm"
      ],
      "id": 76
    },
    {
      "name": "Spring AI Alibaba",
      "one_line_profile": "Java framework for building AI agents and applications",
      "detailed_description": "An implementation of the Spring AI framework tailored for Alibaba Cloud's AI services. It provides Java developers with abstractions for building agents, RAG systems, and integrating with LLMs.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_framework",
        "application_development"
      ],
      "application_level": "framework",
      "primary_language": "Java",
      "repo_url": "https://github.com/alibaba/spring-ai-alibaba",
      "help_website": [
        "https://github.com/alibaba/spring-ai-alibaba/wiki"
      ],
      "license": "Apache-2.0",
      "tags": [
        "java",
        "spring",
        "agent"
      ],
      "id": 77
    },
    {
      "name": "Sanic-Web",
      "one_line_profile": "One-stop large model application development platform",
      "detailed_description": "A lightweight platform for building LLM applications, supporting RAG, Text2SQL, and data visualization. It integrates LangChain/LangGraph and supports local model deployment, suitable for data analysis workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "data_analysis",
        "visualization",
        "rag_platform"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/apconw/sanic-web",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "text2sql",
        "data-analysis"
      ],
      "id": 78
    },
    {
      "name": "Apify MCP Server",
      "one_line_profile": "MCP server for web data extraction agents",
      "detailed_description": "An implementation of the Model Context Protocol (MCP) that exposes Apify's scraping and crawling capabilities to AI agents. It enables agents to autonomously gather data from the web for research and analysis.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "data_acquisition",
        "web_scraping",
        "tool_integration"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/apify/apify-mcp-server",
      "help_website": [
        "https://docs.apify.com/"
      ],
      "license": "MIT",
      "tags": [
        "mcp",
        "scraping",
        "agent-tool"
      ],
      "id": 79
    },
    {
      "name": "RESTai",
      "one_line_profile": "AI-as-a-Service platform for RAG and agents",
      "detailed_description": "An open-source platform built on LlamaIndex and LangChain that provides REST APIs for managing embeddings, RAG, and AI agents. It simplifies the deployment of agentic workflows and knowledge retrieval systems.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "rag_service",
        "agent_deployment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/apocas/restai",
      "help_website": [
        "https://github.com/apocas/restai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "api",
        "agent-platform"
      ],
      "id": 80
    },
    {
      "name": "EdgeChains",
      "one_line_profile": "Declarative GenAI library for distributed chains",
      "detailed_description": "A full-stack GenAI library that manages prompts and chains declaratively using Jsonnet. It is designed for building distributed, edge-compatible AI applications and workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "prompt_management"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/arakoodev/EdgeChains",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "genai",
        "jsonnet",
        "edge-computing"
      ],
      "id": 81
    },
    {
      "name": "DocsGPT",
      "one_line_profile": "Open-source documentation assistant and agent platform",
      "detailed_description": "A platform for creating AI agents that can search, retrieve, and answer questions from documentation. It includes an agent builder and supports deep research capabilities, making it useful for knowledge management in research.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "documentation_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/arc53/DocsGPT",
      "help_website": [
        "https://docsgpt.arc53.com/"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "documentation",
        "agent"
      ],
      "id": 82
    },
    {
      "name": "Argilla",
      "one_line_profile": "Collaboration tool for AI dataset curation and RLHF",
      "detailed_description": "A platform for data labeling, validation, and curation, specifically designed for NLP and LLM workflows (RLHF, RAG evaluation). It helps researchers build high-quality datasets to train and align AI agents.",
      "domains": [
        "AI5",
        "AI4-01"
      ],
      "subtask_category": [
        "data_curation",
        "rlhf",
        "dataset_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/argilla-io/argilla",
      "help_website": [
        "https://docs.argilla.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "dataset",
        "rlhf",
        "labeling"
      ],
      "id": 83
    },
    {
      "name": "GPT Researcher",
      "one_line_profile": "Autonomous agent for deep online research",
      "detailed_description": "An autonomous agent designed to conduct comprehensive online research on a given topic. It scrapes, filters, and aggregates information from multiple sources to generate detailed research reports with citations.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "literature_review",
        "data_aggregation",
        "research_automation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/assafelovic/gpt-researcher",
      "help_website": [
        "https://docs.gptr.dev/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "research-agent",
        "web-scraping",
        "automation"
      ],
      "id": 84
    },
    {
      "name": "AutoGluon Assistant",
      "one_line_profile": "LLM-powered multi-agent system for automating end-to-end multimodal machine learning tasks",
      "detailed_description": "An agentic framework built on top of AutoGluon that leverages Large Language Models (LLMs) to automate the process of machine learning, including data preprocessing, model selection, and training, specifically for multimodal datasets.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "automl",
        "model_selection",
        "code_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/autogluon/autogluon-assistant",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "automl",
        "multi-agent",
        "llm",
        "machine-learning"
      ],
      "id": 85
    },
    {
      "name": "Mahler",
      "one_line_profile": "Automated task composer and HTN-based planner for autonomous system agents",
      "detailed_description": "A library for Hierarchical Task Network (HTN) planning, designed to compose tasks and plan behaviors for autonomous systems, which is relevant for robotics and control systems research.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "task_planning",
        "htn_planning",
        "autonomous_control"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/balena-io-modules/mahler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "htn-planner",
        "autonomous-agents",
        "robotics"
      ],
      "id": 86
    },
    {
      "name": "BARK Planner MCTS",
      "one_line_profile": "Behavior planners based on Monte Carlo Tree Search for the BARK simulator",
      "detailed_description": "A module for the BARK autonomous driving simulator that implements single- and multi-agent behavior planning using Monte Carlo Tree Search (MCTS), facilitating research in autonomous vehicle decision making.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "motion_planning",
        "behavior_planning",
        "simulation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/bark-simulator/planner-mcts",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcts",
        "autonomous-driving",
        "planning"
      ],
      "id": 87
    },
    {
      "name": "BARK Planner Rules MCTS",
      "one_line_profile": "Behavior planner fusing runtime verification with MCTS for BARK",
      "detailed_description": "An extension of the BARK MCTS planner that integrates runtime verification of traffic rules, enabling research into safe and rule-compliant autonomous driving behaviors.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "motion_planning",
        "verification",
        "simulation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/bark-simulator/planner-rules-mcts",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcts",
        "formal-verification",
        "autonomous-driving"
      ],
      "id": 88
    },
    {
      "name": "VeritasGraph",
      "one_line_profile": "Enterprise-grade Graph RAG framework for verifiable attribution",
      "detailed_description": "A framework for building Graph Retrieval-Augmented Generation (Graph RAG) systems, focusing on secure and verifiable attribution, which is critical for scientific knowledge discovery and literature review.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "rag",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bibinprathap/VeritasGraph",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-rag",
        "knowledge-graph",
        "attribution"
      ],
      "id": 89
    },
    {
      "name": "DeerFlow",
      "one_line_profile": "Deep research framework combining LLMs with web tools for information synthesis",
      "detailed_description": "A community-driven framework for 'Deep Research', enabling agents to autonomously perform web search, crawling, and execution to gather and synthesize information, highly relevant for scientific literature review and data gathering.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "literature_review",
        "information_gathering",
        "deep_research"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bytedance/deer-flow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "deep-research",
        "agent",
        "literature-review"
      ],
      "id": 90
    },
    {
      "name": "PaSa",
      "one_line_profile": "Autonomous paper search agent powered by LLMs",
      "detailed_description": "An advanced paper search agent that autonomously makes decisions to invoke search tools, read papers, and select relevant references to answer complex scholarly queries.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "literature_search",
        "paper_reading",
        "reference_selection"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/bytedance/pasa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "scholarly-search",
        "literature-review",
        "autonomous-agent"
      ],
      "id": 91
    },
    {
      "name": "CAMEL",
      "one_line_profile": "Communicative Agents for \"Mind\" Exploration of Large Scale Society",
      "detailed_description": "A multi-agent framework designed to study the scaling laws of agents and facilitate autonomous cooperation among communicative agents, widely used in AI research for simulation and task automation.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multi_agent_simulation",
        "role_playing",
        "agent_collaboration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/camel-ai/camel",
      "help_website": [
        "https://www.camel-ai.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "simulation",
        "ai-research"
      ],
      "id": 92
    },
    {
      "name": "OWL",
      "one_line_profile": "Optimized Workforce Learning for general multi-agent assistance",
      "detailed_description": "A framework focusing on multi-agent collaboration for real-world task automation, serving as a research tool for exploring agent dynamics and workforce learning.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "task_automation",
        "multi_agent_collaboration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/camel-ai/owl",
      "help_website": [],
      "license": null,
      "tags": [
        "multi-agent",
        "automation",
        "workforce-learning"
      ],
      "id": 93
    },
    {
      "name": "Casibase",
      "one_line_profile": "Open-source AI knowledge base and agent management platform",
      "detailed_description": "An enterprise-level AI knowledge base and Model Context Protocol (MCP) management platform that supports RAG and agent-to-agent interactions, suitable for managing scientific knowledge and documents.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "knowledge_base_management",
        "rag",
        "context_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/casibase/casibase",
      "help_website": [
        "https://casibase.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-base",
        "rag",
        "mcp"
      ],
      "id": 94
    },
    {
      "name": "Langchain-Chatchat",
      "one_line_profile": "Local knowledge-based LLM RAG and Agent application",
      "detailed_description": "A RAG and Agent application based on Langchain that enables users to build knowledge bases from local files (papers, reports), facilitating secure scientific literature review and knowledge management.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "knowledge_base_qa",
        "rag",
        "document_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/chatchat-space/Langchain-Chatchat",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "knowledge-base",
        "local-llm"
      ],
      "id": 95
    },
    {
      "name": "FROG",
      "one_line_profile": "Fabricating and Running Orchestration Graphs for learning activities",
      "detailed_description": "A tool for designing and running orchestration graphs, primarily used in learning sciences research to manage complex collaborative learning activities and workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "graph_orchestration",
        "learning_activity_management"
      ],
      "application_level": "workflow",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/chili-epfl/FROG",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "orchestration-graphs",
        "learning-sciences",
        "workflow"
      ],
      "id": 96
    },
    {
      "name": "Orchestration Graphs",
      "one_line_profile": "Workflow engine for orchestration graphs",
      "detailed_description": "The underlying workflow engine for the FROG platform, capable of executing complex orchestration graphs for research in collaborative systems.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_engine",
        "graph_execution"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/chili-epfl/orchestration-graphs",
      "help_website": [],
      "license": null,
      "tags": [
        "workflow-engine",
        "orchestration"
      ],
      "id": 97
    },
    {
      "name": "ALFRED-GPT2",
      "one_line_profile": "Visual semantic planner for the ALFRED virtual agent challenge",
      "detailed_description": "A visual semantic planning model using GPT-2 for the ALFRED benchmark, enabling research into embodied agents that follow natural language instructions in simulated environments.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "visual_semantic_planning",
        "embodied_agent_control"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cognitiveailab/alfred-gpt2",
      "help_website": [],
      "license": null,
      "tags": [
        "embodied-ai",
        "planning",
        "alfred-benchmark"
      ],
      "id": 98
    },
    {
      "name": "CoPerception",
      "one_line_profile": "SDK for multi-agent collaborative perception and sensor fusion",
      "detailed_description": "A framework designed for multi-agent collaborative perception research, enabling agents to share sensor data (like LiDAR or cameras) to improve perception accuracy in distributed systems such as autonomous vehicles or robotics.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "sensor_fusion",
        "collaborative_perception",
        "multi_agent_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/coperception/coperception",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "perception",
        "robotics",
        "sensor-fusion"
      ],
      "id": 99
    },
    {
      "name": "Autonomous Learning Library",
      "one_line_profile": "PyTorch library for building deep reinforcement learning agents",
      "detailed_description": "A library for deep reinforcement learning (DRL) that provides building blocks for creating autonomous agents. It is used in research for control tasks, optimization, and simulation environments common in scientific modeling.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "agent_control",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cpnota/autonomous-learning-library",
      "help_website": [
        "https://autonomous-learning-library.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "reinforcement-learning",
        "pytorch",
        "autonomous-agents"
      ],
      "id": 100
    },
    {
      "name": "CrewAI",
      "one_line_profile": "Framework for orchestrating role-playing autonomous AI agents",
      "detailed_description": "A leading framework for orchestrating role-playing, autonomous AI agents. It enables the creation of collaborative agent teams that can perform complex workflows, widely used in scientific literature review, data analysis pipelines, and automated research tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "multi_agent_collaboration",
        "automated_reasoning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/crewAIInc/crewAI",
      "help_website": [
        "https://docs.crewai.com"
      ],
      "license": "MIT",
      "tags": [
        "agent-orchestration",
        "multi-agent",
        "llm-agents",
        "workflow-automation"
      ],
      "id": 101
    },
    {
      "name": "CrewAI Tools",
      "one_line_profile": "Collection of tools for CrewAI agents",
      "detailed_description": "A set of pre-built tools designed to extend the capabilities of CrewAI agents, enabling them to perform specific actions such as web searching, file manipulation, and data extraction, which are essential for constructing scientific research agents.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "tool_use",
        "data_retrieval",
        "agent_capability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/crewAIInc/crewAI-tools",
      "help_website": [
        "https://docs.crewai.com/tools"
      ],
      "license": "MIT",
      "tags": [
        "agent-tools",
        "crewai",
        "integration"
      ],
      "id": 102
    },
    {
      "name": "DeepRL Network",
      "one_line_profile": "Multi-agent deep reinforcement learning for networked system control",
      "detailed_description": "A research codebase implementing multi-agent deep reinforcement learning algorithms specifically for the control of networked systems, applicable in engineering and complex systems research.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "network_control",
        "multi_agent_rl",
        "system_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cts198859/deeprl_network",
      "help_website": [],
      "license": null,
      "tags": [
        "deep-reinforcement-learning",
        "multi-agent",
        "network-control"
      ],
      "id": 103
    },
    {
      "name": "AutoDidact",
      "one_line_profile": "Autonomously train research-agent LLMs on custom data",
      "detailed_description": "A tool designed to autonomously train research-agent LLMs using reinforcement learning and self-verification. It is specifically aimed at creating agents capable of conducting research on custom datasets.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_training",
        "research_automation",
        "knowledge_acquisition"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/dCaples/AutoDidact",
      "help_website": [],
      "license": null,
      "tags": [
        "research-agent",
        "llm-training",
        "reinforcement-learning"
      ],
      "id": 104
    },
    {
      "name": "Data Commons Agent Toolkit",
      "one_line_profile": "Tools for agents to interact with Data Commons Knowledge Graph",
      "detailed_description": "A toolkit enabling AI agents to query and interact with the Data Commons Knowledge Graph, facilitating the retrieval and analysis of vast amounts of public scientific, demographic, and economic data.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "data_retrieval",
        "knowledge_graph_query",
        "scientific_data_access"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/datacommonsorg/agent-toolkit",
      "help_website": [
        "https://docs.datacommons.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-commons",
        "knowledge-graph",
        "mcp",
        "agent-tools"
      ],
      "id": 105
    },
    {
      "name": "ACE Framework",
      "one_line_profile": "Autonomous Cognitive Entities framework for local agents",
      "detailed_description": "A conceptual and practical framework for building Autonomous Cognitive Entities (ACE). It provides a layered architecture for creating autonomous agents with cognitive capabilities, used in AI alignment and agentic research.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "cognitive_architecture",
        "autonomous_agents",
        "agent_design"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/daveshap/ACE_Framework",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cognitive-architecture",
        "autonomous-agents",
        "ai-alignment"
      ],
      "id": 106
    },
    {
      "name": "OpenAI Agent Swarm (HAAS)",
      "one_line_profile": "Hierarchical Autonomous Agent Swarm framework",
      "detailed_description": "A framework for creating Hierarchical Autonomous Agent Swarms (HAAS). It enables the orchestration of multiple agents in a hierarchical structure to solve complex tasks, applicable to distributed problem solving in research.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "swarm_intelligence",
        "multi_agent_orchestration",
        "hierarchical_planning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/daveshap/OpenAI_Agent_Swarm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "swarm-intelligence",
        "multi-agent",
        "hierarchical-agents"
      ],
      "id": 107
    },
    {
      "name": "Haystack",
      "one_line_profile": "Orchestration framework for LLM agents and RAG pipelines",
      "detailed_description": "A comprehensive orchestration framework for building LLM applications, including agents and RAG pipelines. It is widely used in scientific text mining, literature review automation, and knowledge retrieval systems.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "rag",
        "information_retrieval"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepset-ai/haystack",
      "help_website": [
        "https://haystack.deepset.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "rag",
        "agent-orchestration",
        "pipeline"
      ],
      "id": 108
    },
    {
      "name": "ROS2-BDI",
      "one_line_profile": "BDI Multi-Agent System framework for ROS2",
      "detailed_description": "A Multi-Agent System (MAS) framework built on top of ROS2 (Robot Operating System) that implements the Belief-Desire-Intention (BDI) architecture. It uses PDDL planning for autonomous robotic agents, suitable for robotics research and complex task planning.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "robotics_planning",
        "multi_agent_system",
        "bdi_architecture"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/devis12/ROS2-BDI",
      "help_website": [
        "https://github.com/devis12/ROS2-BDI/wiki"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ros2",
        "multi-agent",
        "bdi",
        "robotics"
      ],
      "id": 109
    },
    {
      "name": "OpenMAS",
      "one_line_profile": "Multi-agent simulator for decentralized intelligent systems in MATLAB",
      "detailed_description": "An open-source multi-agent simulator based in MATLAB for simulating decentralized intelligent systems with arbitrary behaviors and dynamics. It is used for research in control theory, swarm robotics, and complex systems.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multi_agent_simulation",
        "system_dynamics",
        "decentralized_control"
      ],
      "application_level": "solver",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/douthwja01/OpenMAS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "matlab",
        "multi-agent-simulation",
        "control-theory"
      ],
      "id": 110
    },
    {
      "name": "Dynamiq",
      "one_line_profile": "Orchestration framework for agentic AI and LLM applications",
      "detailed_description": "Dynamiq is a framework designed to orchestrate agentic AI workflows, enabling the creation of complex RAG and LLM-based applications suitable for scientific data retrieval and processing pipelines.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "rag_pipeline"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/dynamiq-ai/dynamiq",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "orchestration",
        "agent-framework",
        "llm",
        "rag"
      ],
      "id": 111
    },
    {
      "name": "E2B",
      "one_line_profile": "Secure sandboxed cloud environments for AI agents",
      "detailed_description": "E2B provides secure, sandboxed code execution environments (Code Interpreters) for AI agents, essential for enabling agents to perform data analysis, code generation, and computational tasks in scientific workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "code_execution_environment",
        "agent_infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "MDX",
      "repo_url": "https://github.com/e2b-dev/E2B",
      "help_website": [
        "https://e2b.dev/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "sandbox",
        "code-interpreter",
        "agent-infrastructure"
      ],
      "id": 112
    },
    {
      "name": "Fiddler",
      "one_line_profile": "Fast inference system for Mixture-of-Experts (MoE) models with CPU-GPU orchestration",
      "detailed_description": "Fiddler is an inference system designed to efficiently run large Mixture-of-Experts (MoE) models by orchestrating CPU and GPU resources, serving as critical infrastructure for deploying large-scale scientific AI models.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "model_inference",
        "resource_orchestration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/efeslab/fiddler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "moe",
        "cpu-gpu-orchestration"
      ],
      "id": 113
    },
    {
      "name": "DB-GPT",
      "one_line_profile": "AI-native data application development framework with agents and AWEL",
      "detailed_description": "DB-GPT is a framework for building AI-native data applications, featuring the Agentic Workflow Expression Language (AWEL) and multi-agent capabilities, specifically designed for data analysis, Text-to-SQL, and knowledge base interaction.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "data_analysis",
        "text_to_sql",
        "rag"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/eosphoros-ai/DB-GPT",
      "help_website": [
        "https://docs.dbgpt.site"
      ],
      "license": "MIT",
      "tags": [
        "data-analysis",
        "agent-framework",
        "awel",
        "rag"
      ],
      "id": 114
    },
    {
      "name": "aiFlows",
      "one_line_profile": "Framework for building collaborative multi-agent systems",
      "detailed_description": "aiFlows is a framework developed by EPFL for constructing collaborative AI systems where agents (Flows) communicate and coordinate to solve complex tasks, suitable for research in multi-agent interaction.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multi_agent_coordination",
        "agent_simulation"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/epfl-dlab/aiflows",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multi-agent",
        "collaboration",
        "research-framework"
      ],
      "id": 115
    },
    {
      "name": "Evoplex",
      "one_line_profile": "Platform for agent-based modeling and multi-agent systems on networks",
      "detailed_description": "Evoplex is a fast and extensible platform for developing and analyzing agent-based models (ABM) and multi-agent systems on networks, widely used in complexity science, sociology, and epidemiology.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_based_modeling",
        "network_simulation"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/evoplex/evoplex",
      "help_website": [
        "https://evoplex.org"
      ],
      "license": null,
      "tags": [
        "abm",
        "simulation",
        "complex-systems"
      ],
      "id": 116
    },
    {
      "name": "Flyte",
      "one_line_profile": "Workflow orchestration platform for data and ML processes",
      "detailed_description": "Flyte is a scalable workflow orchestration platform that unifies data, ML, and analytics stacks, widely used in bioinformatics and scientific computing for reproducible data pipelines.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "pipeline_orchestration",
        "workflow_management"
      ],
      "application_level": "workflow",
      "primary_language": "Go",
      "repo_url": "https://github.com/flyteorg/flyte",
      "help_website": [
        "https://flyte.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow",
        "orchestration",
        "mlops",
        "reproducibility"
      ],
      "id": 117
    },
    {
      "name": "GenWorlds",
      "one_line_profile": "Framework for event-based autonomous multi-agent systems",
      "detailed_description": "GenWorlds is a framework for building complex, interactive environments and coordinating autonomous agents to achieve common goals, applicable in multi-agent simulation and social science modeling.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multi_agent_simulation",
        "agent_coordination"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/genlayerlabs/genworlds",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multi-agent",
        "simulation",
        "autonomous-agents"
      ],
      "id": 118
    },
    {
      "name": "MedAgents",
      "one_line_profile": "Multi-agent framework for zero-shot medical reasoning and diagnosis",
      "detailed_description": "A specialized multi-agent framework that leverages Large Language Models (LLMs) as collaborators to perform complex medical reasoning tasks. It orchestrates interactions between agents with distinct roles to improve diagnostic accuracy and medical knowledge retrieval, specifically designed for the biomedical domain.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "medical_reasoning",
        "diagnosis_support",
        "scientific_inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gersteinlab/MedAgents",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-ai",
        "multi-agent",
        "reasoning",
        "llm-agent"
      ],
      "id": 119
    },
    {
      "name": "SMARTS",
      "one_line_profile": "Scalable Multi-Agent RL Training School for Autonomous Driving",
      "detailed_description": "A simulation platform and benchmark for multi-agent reinforcement learning (MARL) research, specifically focused on autonomous driving scenarios. It provides a physics-based environment to simulate complex traffic interactions, enabling the development and evaluation of agent planning and control algorithms.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "simulation",
        "reinforcement_learning",
        "agent_training"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/huawei-noah/SMARTS",
      "help_website": [
        "https://smarts.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "simulation",
        "reinforcement-learning",
        "autonomous-driving",
        "multi-agent"
      ],
      "id": 120
    },
    {
      "name": "MeeseeksAI",
      "one_line_profile": "Graph-based orchestration framework for AI agents using Mermaid syntax",
      "detailed_description": "A Python framework designed to orchestrate AI agents by defining workflows and dependencies through Mermaid graphs, enabling structured multi-agent execution.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/interstellarninja/MeeseeksAI",
      "help_website": [],
      "license": null,
      "tags": [
        "agent-orchestration",
        "mermaid-graph",
        "workflow"
      ],
      "id": 121
    },
    {
      "name": "function-calling-eval",
      "one_line_profile": "Evaluation framework for LLM function calling capabilities",
      "detailed_description": "A framework specifically designed to evaluate the accuracy and reliability of function calls made by Large Language Models (LLMs), aiding in the development of robust agentic systems.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "model_evaluation",
        "function_calling_test"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/interstellarninja/function-calling-eval",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-evaluation",
        "function-calling",
        "testing"
      ],
      "id": 122
    },
    {
      "name": "llm-consortium",
      "one_line_profile": "Parallel reasoning orchestration for multiple LLMs",
      "detailed_description": "A framework that orchestrates multiple LLMs to perform parallel reasoning, iterative refinement, and consensus building, enhancing the reliability of complex inference tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multi_agent_reasoning",
        "consensus_building"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/irthomasthomas/llm-consortium",
      "help_website": [],
      "license": null,
      "tags": [
        "multi-agent",
        "reasoning",
        "consensus"
      ],
      "id": 123
    },
    {
      "name": "ISEK",
      "one_line_profile": "Decentralized network for agent-to-agent collaboration",
      "detailed_description": "A decentralized agent network framework designed to build collaborative, LLM-powered agent-to-agent (A2A) systems, facilitating distributed problem solving.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "distributed_agents",
        "agent_collaboration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/isekOS/ISEK",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "decentralized-agents",
        "multi-agent-system",
        "collaboration"
      ],
      "id": 124
    },
    {
      "name": "acte",
      "one_line_profile": "Framework for building GUI-like tools for agents",
      "detailed_description": "A framework to construct complex, GUI-like tool interfaces for AI agents, enhancing the function calling capabilities of LLMs by structuring tool interactions.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "tool_creation",
        "agent_interface"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/j66n/acte",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-tools",
        "function-calling",
        "framework"
      ],
      "id": 125
    },
    {
      "name": "llm-auto-forge",
      "one_line_profile": "Dynamic tool creation and retrieval for LangChain agents",
      "detailed_description": "A LangChain-based utility that allows agents to dynamically create, store, retrieve, and utilize tools to solve problems, enabling adaptive agent capabilities.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "tool_management",
        "dynamic_tooling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jbpayton/llm-auto-forge",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "langchain",
        "tool-generation",
        "agent-memory"
      ],
      "id": 126
    },
    {
      "name": "AutoGroq",
      "one_line_profile": "Dynamic agent team generation for AutoGen",
      "detailed_description": "A tool that dynamically generates and configures tailored teams of AI agents based on project requirements, designed to streamline the setup of multi-agent systems using AutoGen.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "team_generation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/jgravelle/AutoGroq",
      "help_website": [],
      "license": null,
      "tags": [
        "autogen",
        "multi-agent",
        "groq"
      ],
      "id": 127
    },
    {
      "name": "tree-of-thought-puzzle-solver",
      "one_line_profile": "Tree of Thoughts (ToT) reasoning framework implementation",
      "detailed_description": "An implementation of the Tree of Thoughts (ToT) framework, enabling Large Language Models to perform complex reasoning tasks through tree-based search and evaluation strategies.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "reasoning_framework",
        "search_algorithm"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jieyilong/tree-of-thought-puzzle-solver",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tree-of-thoughts",
        "reasoning",
        "llm"
      ],
      "id": 128
    },
    {
      "name": "agentchain",
      "one_line_profile": "Orchestration framework for chaining LLMs and tools",
      "detailed_description": "A framework by Jina AI to chain together Large Language Models for reasoning and orchestrate multiple models to accomplish complex tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "chain_reasoning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jina-ai/agentchain",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "orchestration",
        "llm-chain",
        "jina"
      ],
      "id": 129
    },
    {
      "name": "MAS-TTS",
      "one_line_profile": "Test-time scaling framework for multi-agent collaborative reasoning",
      "detailed_description": "Implementation of a multi-agent collaborative reasoning framework that utilizes test-time scaling to improve performance on complex reasoning tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "collaborative_reasoning",
        "multi_agent_system"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jincan333/MAS-TTS",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "reasoning",
        "test-time-scaling"
      ],
      "id": 130
    },
    {
      "name": "DialOp",
      "one_line_profile": "Decision-oriented dialogue environments for agent evaluation",
      "detailed_description": "A set of decision-oriented dialogue environments designed to evaluate collaborative language agents, serving as a benchmark for agent decision-making capabilities.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_evaluation",
        "benchmark_environment"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/jlin816/dialop",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "benchmark",
        "dialogue-agents",
        "evaluation"
      ],
      "id": 131
    },
    {
      "name": "Paper2Agent",
      "one_line_profile": "System to transform research papers into interactive AI agents",
      "detailed_description": "A multi-agent AI system that automatically processes research papers and converts them into interactive agents, facilitating literature review and scientific knowledge extraction.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "literature_processing",
        "knowledge_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/jmiao24/Paper2Agent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "literature-review",
        "paper-analysis",
        "multi-agent"
      ],
      "id": 132
    },
    {
      "name": "UB-ANC-Planner",
      "one_line_profile": "Multi-agent energy efficient coverage path planner",
      "detailed_description": "A C-based path planning tool for multi-agent systems, specifically optimizing for energy-efficient coverage, suitable for robotic agents.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "path_planning",
        "robotics_control"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/jmodares/UB-ANC-Planner",
      "help_website": [],
      "license": null,
      "tags": [
        "path-planning",
        "multi-agent",
        "robotics"
      ],
      "id": 133
    },
    {
      "name": "mcp-client-for-ollama",
      "one_line_profile": "TUI client for interacting with MCP servers via Ollama",
      "detailed_description": "A terminal user interface client that enables developers to interact with Model Context Protocol (MCP) servers using Ollama, facilitating local LLM agent development and testing.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_development",
        "model_interaction"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/jonigl/mcp-client-for-ollama",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "ollama",
        "agent-tooling"
      ],
      "id": 134
    },
    {
      "name": "julep",
      "one_line_profile": "Platform for building and deploying stateful AI agents",
      "detailed_description": "A platform designed to build, deploy, and manage serverless AI workflows and stateful agents at scale, providing backend infrastructure for agentic applications.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_deployment",
        "workflow_management"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/julep-ai/julep",
      "help_website": [],
      "license": null,
      "tags": [
        "serverless-agents",
        "workflow-engine",
        "state-management"
      ],
      "id": 135
    },
    {
      "name": "KaibanJS",
      "one_line_profile": "JavaScript framework for multi-agent systems",
      "detailed_description": "A JavaScript-native framework for building and managing multi-agent systems, utilizing a Kanban-inspired approach for task management and agent coordination.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "task_management"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/kaiban-ai/KaibanJS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "javascript",
        "multi-agent",
        "kanban"
      ],
      "id": 136
    },
    {
      "name": "ai-assisted-task-executor",
      "one_line_profile": "Task-driven autonomous agent system",
      "detailed_description": "An AI-powered solution leveraging LLMs, vector search, and LangChain to efficiently generate, prioritize, and execute tasks within an autonomous agent system.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "task_execution",
        "autonomous_agents"
      ],
      "application_level": "workflow",
      "primary_language": null,
      "repo_url": "https://github.com/kalaspuff/ai-assisted-task-executor",
      "help_website": [],
      "license": "CC0-1.0",
      "tags": [
        "autonomous-agents",
        "task-management",
        "langchain"
      ],
      "id": 137
    },
    {
      "name": "autogen_FEA",
      "one_line_profile": "Conversational agents for Finite Element Analysis (FEA)",
      "detailed_description": "A specialized agent system using Microsoft AutoGen and GPT-4o to automate engineering simulations (Finite Element Analysis) with minimal human input.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "engineering_simulation",
        "finite_element_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/karthik-codex/autogen_FEA",
      "help_website": [],
      "license": null,
      "tags": [
        "fea",
        "engineering",
        "autogen"
      ],
      "id": 138
    },
    {
      "name": "archgw",
      "one_line_profile": "Infrastructure gateway for agent routing and orchestration",
      "detailed_description": "A models-native proxy and data plane designed to handle plumbing work for AI agents, including routing, orchestration, guardrails, and unified access to LLMs.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_infrastructure",
        "model_routing"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/katanemo/archgw",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent-gateway",
        "orchestration",
        "infrastructure"
      ],
      "id": 139
    },
    {
      "name": "simplemind",
      "one_line_profile": "Lightweight Python API client for AI providers",
      "detailed_description": "A Python API client designed as a simpler alternative to complex frameworks like LangChain, facilitating direct interaction with AI providers for building agentic workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "model_interface",
        "agent_development"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kennethreitz/simplemind",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-client",
        "agent-framework",
        "python"
      ],
      "id": 140
    },
    {
      "name": "Memary",
      "one_line_profile": "Long-term memory layer for autonomous agents using knowledge graphs",
      "detailed_description": "Memary is an open-source memory layer designed for autonomous agents, enabling them to store, retrieve, and utilize information over long periods. It uses knowledge graphs to structure memory, making it valuable for scientific agents that need to retain context across complex experiments or literature reviews.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "memory_management",
        "knowledge_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/kingjulio8238/Memary",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "memory",
        "agent-memory",
        "knowledge-graph",
        "rag"
      ],
      "id": 141
    },
    {
      "name": "ma-gym",
      "one_line_profile": "Collection of multi-agent environments for Reinforcement Learning research",
      "detailed_description": "ma-gym provides a collection of multi-agent environments based on the OpenAI Gym interface. It serves as a benchmark and testing ground for developing and evaluating multi-agent reinforcement learning (MARL) algorithms, a key area in AI research.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "simulation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/koulanurag/ma-gym",
      "help_website": [
        "https://github.com/koulanurag/ma-gym/wiki"
      ],
      "license": "Apache-2.0",
      "tags": [
        "reinforcement-learning",
        "multi-agent",
        "openai-gym",
        "simulation"
      ],
      "id": 142
    },
    {
      "name": "IX",
      "one_line_profile": "Autonomous agent platform for workflow automation",
      "detailed_description": "IX is an autonomous agent platform designed to automate complex workflows using LLMs (like GPT-4). It provides a framework for defining, executing, and monitoring agent-based tasks, suitable for orchestrating research workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "agent_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/kreneskyp/ix",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-platform",
        "workflow-automation",
        "gpt-4",
        "autonomous-agents"
      ],
      "id": 143
    },
    {
      "name": "PALI3",
      "one_line_profile": "Implementation of the PALI-3 Vision Language Model",
      "detailed_description": "An implementation of the PALI-3 Vision Language Model (VLM). VLMs are essential tools in scientific image analysis, enabling automated interpretation of visual data in fields like biology and materials science.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "image_analysis",
        "visual_reasoning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kyegomez/PALI3",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vlm",
        "computer-vision",
        "multimodal",
        "deep-learning"
      ],
      "id": 144
    },
    {
      "name": "Swarms",
      "one_line_profile": "Enterprise-grade multi-agent orchestration framework",
      "detailed_description": "Swarms is a modular framework for orchestrating multi-agent systems. It allows researchers and developers to build, deploy, and manage swarms of autonomous agents that can collaborate on complex tasks, including scientific data processing and analysis.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "multi_agent_system"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kyegomez/swarms",
      "help_website": [
        "https://swarms.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "orchestration",
        "swarm-intelligence",
        "llm"
      ],
      "id": 145
    },
    {
      "name": "Team of AI Agents",
      "one_line_profile": "Framework for effective AI agent team collaboration",
      "detailed_description": "An open-source framework designed to facilitate collaboration among teams of AI agents. It aims to structure agent interactions to be as effective as human teams, applicable to coordinating complex scientific problem-solving tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_collaboration",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/l3vels/team-of-ai-agents",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "multi-agent",
        "collaboration",
        "agent-framework"
      ],
      "id": 146
    },
    {
      "name": "FastGPT",
      "one_line_profile": "Knowledge-based platform for visual AI workflow orchestration and RAG",
      "detailed_description": "FastGPT is a comprehensive platform for building knowledge-based QA systems and orchestrating AI workflows visually. It supports RAG (Retrieval-Augmented Generation) and data processing, making it highly suitable for managing scientific knowledge bases and automating research inquiries.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "knowledge_management",
        "rag"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/labring/FastGPT",
      "help_website": [
        "https://fastgpt.in"
      ],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "workflow-orchestration",
        "knowledge-base",
        "llm-ops"
      ],
      "id": 147
    },
    {
      "name": "DeepAgents",
      "one_line_profile": "Advanced agent harness with planning and subagent spawning capabilities",
      "detailed_description": "DeepAgents is an agent framework built on LangChain and LangGraph that equips agents with advanced capabilities such as planning tools, filesystem backends, and the ability to spawn subagents. This hierarchical structure is well-suited for complex, multi-step scientific tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_planning",
        "hierarchical_agents"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/langchain-ai/deepagents",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "langgraph",
        "planning",
        "subagents",
        "autonomous-agents"
      ],
      "id": 148
    },
    {
      "name": "LangChain",
      "one_line_profile": "Comprehensive framework for building context-aware reasoning applications",
      "detailed_description": "LangChain is the foundational framework for developing applications powered by language models. It provides the essential infrastructure for creating scientific agents, including tool calling, memory management, and chain-of-thought reasoning capabilities.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "framework",
        "tool_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/langchain-ai/langchain",
      "help_website": [
        "https://python.langchain.com"
      ],
      "license": "MIT",
      "tags": [
        "llm-framework",
        "agents",
        "rag",
        "tool-use"
      ],
      "id": 149
    },
    {
      "name": "LangChain MCP Adapters",
      "one_line_profile": "Adapters for integrating Model Context Protocol tools with LangChain",
      "detailed_description": "This library provides adapters to connect LangChain with the Model Context Protocol (MCP), enabling LangChain agents to utilize a standardized ecosystem of tools and resources, facilitating interoperability in scientific toolchains.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "interoperability",
        "tool_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/langchain-ai/langchain-mcp-adapters",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "langchain",
        "adapter",
        "interoperability"
      ],
      "id": 150
    },
    {
      "name": "LangChain.js",
      "one_line_profile": "JavaScript/TypeScript framework for building context-aware reasoning applications",
      "detailed_description": "The JavaScript/TypeScript implementation of the LangChain framework, enabling the development of AI agents and workflows in web-based scientific applications and environments.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "framework",
        "tool_integration"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/langchain-ai/langchainjs",
      "help_website": [
        "https://js.langchain.com"
      ],
      "license": "MIT",
      "tags": [
        "javascript",
        "llm-framework",
        "agents"
      ],
      "id": 151
    },
    {
      "name": "LangGraph",
      "one_line_profile": "Library for building stateful, multi-actor applications with LLMs",
      "detailed_description": "LangGraph is a library for building resilient, stateful language agents as graphs. It enables the creation of complex, cyclic workflows and multi-agent systems, which are essential for modeling iterative scientific processes and simulations.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "graph_orchestration",
        "state_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/langchain-ai/langgraph",
      "help_website": [
        "https://langchain-ai.github.io/langgraph/"
      ],
      "license": "MIT",
      "tags": [
        "graph-orchestration",
        "stateful-agents",
        "cyclic-workflows"
      ],
      "id": 152
    },
    {
      "name": "LangGraph BigTool",
      "one_line_profile": "Extension for LangGraph agents to handle large numbers of tools",
      "detailed_description": "A specialized extension for LangGraph that enables agents to efficiently manage and select from a large number of tools. This is particularly useful in scientific domains where agents may need access to vast libraries of analysis functions or databases.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "tool_management",
        "scalability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/langchain-ai/langgraph-bigtool",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "langgraph",
        "tool-selection",
        "scalability"
      ],
      "id": 153
    },
    {
      "name": "LangGraph Swarm",
      "one_line_profile": "Implementation of swarm architectures using LangGraph",
      "detailed_description": "This library implements swarm-based multi-agent architectures within the LangGraph framework, facilitating the creation of decentralized, collaborative agent systems for complex problem solving.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "swarm_intelligence",
        "multi_agent_system"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/langchain-ai/langgraph-swarm-py",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "swarm",
        "multi-agent",
        "langgraph"
      ],
      "id": 154
    },
    {
      "name": "LangGraph.js",
      "one_line_profile": "JavaScript framework for building stateful language agents as graphs",
      "detailed_description": "The JavaScript/TypeScript implementation of LangGraph, allowing developers to build stateful, graph-based agent workflows in JS environments.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "graph_orchestration",
        "state_management"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/langchain-ai/langgraphjs",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "javascript",
        "graph-orchestration",
        "agents"
      ],
      "id": 155
    },
    {
      "name": "LangChain4j",
      "one_line_profile": "Java library for integrating LLMs into Java applications",
      "detailed_description": "LangChain4j is a Java library that simplifies the integration of LLMs into Java applications. It supports RAG, tool calling, and agent development, providing a robust foundation for building scientific tools in the Java ecosystem.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "framework",
        "tool_integration"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/langchain4j/langchain4j",
      "help_website": [
        "https://docs.langchain4j.dev/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "java",
        "llm-framework",
        "agents",
        "rag"
      ],
      "id": 156
    },
    {
      "name": "Langflow",
      "one_line_profile": "Visual tool for building and deploying AI-powered agents and workflows",
      "detailed_description": "Langflow is a low-code/no-code platform that allows users to design, build, and deploy AI agents and workflows using a visual interface. It simplifies the creation of complex agentic systems for researchers without deep programming expertise.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "visual_programming"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/langflow-ai/langflow",
      "help_website": [
        "https://docs.langflow.org"
      ],
      "license": "MIT",
      "tags": [
        "low-code",
        "visual-interface",
        "agent-builder",
        "workflow"
      ],
      "id": 157
    },
    {
      "name": "Dify",
      "one_line_profile": "Production-ready platform for agentic workflow development",
      "detailed_description": "Dify is an open-source platform for developing LLM applications and agentic workflows. It provides a comprehensive suite of tools for RAG, prompt engineering, and workflow orchestration, suitable for deploying scientific AI assistants and knowledge systems.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "application_development"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/langgenius/dify",
      "help_website": [
        "https://dify.ai"
      ],
      "license": "NOASSERTION",
      "tags": [
        "llm-ops",
        "agent-platform",
        "rag",
        "workflow"
      ],
      "id": 158
    },
    {
      "name": "LangGraph4j",
      "one_line_profile": "Java library for developing AI Agentic Architectures",
      "detailed_description": "LangGraph4j brings the graph-based agent orchestration capabilities of LangGraph to the Java ecosystem, enabling the construction of complex, stateful agent workflows in Java applications.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "graph_orchestration",
        "agent_architecture"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/langgraph4j/langgraph4j",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "java",
        "langgraph",
        "agents"
      ],
      "id": 159
    },
    {
      "name": "MCP Agent",
      "one_line_profile": "Framework for building agents using Model Context Protocol",
      "detailed_description": "A framework designed to build effective agents using the Model Context Protocol (MCP) and simple workflow patterns. It facilitates the creation of agents that can standardize context and tool usage, enhancing interoperability in research workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "framework",
        "interoperability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lastmile-ai/mcp-agent",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mcp",
        "agent-framework",
        "interoperability"
      ],
      "id": 160
    },
    {
      "name": "LoTa-Bench",
      "one_line_profile": "Benchmark for Language-oriented Task Planners for Embodied Agents",
      "detailed_description": "LoTa-Bench (LLMTaskPlanning) is a benchmark suite for evaluating language-oriented task planners in embodied agents. It serves as a tool for AI research, specifically in measuring the planning capabilities of agents in simulated environments.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "benchmarking",
        "task_planning"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/lbaa2022/LLMTaskPlanning",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "benchmark",
        "task-planning",
        "embodied-ai",
        "llm"
      ],
      "id": 161
    },
    {
      "name": "JS Agent",
      "one_line_profile": "Library for building AI Agents with JavaScript and TypeScript",
      "detailed_description": "A library for constructing AI agents using JavaScript and TypeScript. It provides the necessary abstractions for building agentic workflows in web environments, supporting the development of scientific web tools.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "framework",
        "agent_development"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/lgrammel/js-agent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "javascript",
        "typescript",
        "agents"
      ],
      "id": 162
    },
    {
      "name": "Claude Data Analysis Agent",
      "one_line_profile": "Data analysis AI agent built with Claude Code",
      "detailed_description": "An AI agent implementation specifically designed for data analysis tasks using Claude. It automates the process of analyzing datasets, making it a direct tool for scientific data interpretation and statistical analysis.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "data_analysis",
        "statistical_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/liangdabiao/claude-data-analysis",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "data-analysis",
        "claude",
        "agent",
        "automation"
      ],
      "id": 163
    },
    {
      "name": "PromptWizard",
      "one_line_profile": "Task-Aware Agent-driven Prompt Optimization Framework",
      "detailed_description": "A framework designed to optimize prompts for Large Language Models (LLMs) using an agent-driven approach. It iteratively refines prompts based on task performance, making it a valuable tool for enhancing the reliability of LLMs in scientific workflows and complex reasoning tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "prompt_optimization",
        "workflow_orchestration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/PromptWizard",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-engineering",
        "agent",
        "optimization",
        "llm"
      ],
      "id": 164
    },
    {
      "name": "TaskWeaver",
      "one_line_profile": "Code-first agent framework for data analytics tasks",
      "detailed_description": "A code-first agent framework that seamlessly plans and executes data analytics tasks. It interprets user requests, generates code (typically Python), and executes it to perform data analysis, making it highly suitable for scientific data processing and statistical analysis workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "data_analysis",
        "code_generation",
        "workflow_planning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/TaskWeaver",
      "help_website": [
        "https://microsoft.github.io/TaskWeaver/"
      ],
      "license": "MIT",
      "tags": [
        "agent",
        "data-analytics",
        "code-generation",
        "planning"
      ],
      "id": 165
    },
    {
      "name": "Microsoft Agent Framework",
      "one_line_profile": "Framework for building and orchestrating AI agents",
      "detailed_description": "A comprehensive framework for building, orchestrating, and deploying AI agents and multi-agent workflows. It provides the foundational infrastructure for creating complex agentic systems that can be applied to scientific simulation, data analysis, and automated research pipelines.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "workflow_management"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/agent-framework",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent",
        "orchestration",
        "multi-agent",
        "framework"
      ],
      "id": 166
    },
    {
      "name": "AutoGen",
      "one_line_profile": "A programming framework for agentic AI",
      "detailed_description": "A framework that enables the development of LLM applications using multiple agents that can converse with each other to solve tasks. It is widely used in the scientific community for building autonomous research assistants, coding agents, and simulation environments.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multi_agent_simulation",
        "code_generation",
        "workflow_automation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/autogen",
      "help_website": [
        "https://microsoft.github.io/autogen/"
      ],
      "license": "CC-BY-4.0",
      "tags": [
        "multi-agent",
        "llm",
        "orchestration",
        "automation"
      ],
      "id": 167
    },
    {
      "name": "POML",
      "one_line_profile": "Prompt Orchestration Markup Language",
      "detailed_description": "A markup language and toolset designed for defining and orchestrating complex prompt workflows and agent interactions. It facilitates the structured design of agentic systems, which is essential for reproducible scientific AI workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_definition",
        "prompt_orchestration"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/microsoft/poml",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dsl",
        "orchestration",
        "prompt-engineering"
      ],
      "id": 168
    },
    {
      "name": "Semantic Workbench",
      "one_line_profile": "Tool to prototype intelligent assistants and multi-agent systems",
      "detailed_description": "A workbench environment for prototyping, testing, and refining intelligent agents and multi-agent systems. It supports the development lifecycle of research agents by providing a visual and interactive interface for agent behavior analysis.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_prototyping",
        "system_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/semanticworkbench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "workbench",
        "prototyping",
        "agent-development"
      ],
      "id": 169
    },
    {
      "name": "MADER",
      "one_line_profile": "Trajectory planner for multi-agent systems in dynamic environments",
      "detailed_description": "MADER (Multi-Agent Dynamic Environment Planner) is a decentralized trajectory planner designed for multi-agent systems, specifically drones, to navigate dynamic environments while avoiding collisions. It is developed by the MIT Aerospace Controls Lab.",
      "domains": [
        "AI5",
        "Robotics"
      ],
      "subtask_category": [
        "trajectory_planning",
        "collision_avoidance",
        "multi_agent_coordination"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/mit-acl/mader",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "robotics",
        "path-planning",
        "multi-agent",
        "uav"
      ],
      "id": 170
    },
    {
      "name": "MLflow",
      "one_line_profile": "Open source platform for the machine learning lifecycle",
      "detailed_description": "MLflow is a platform to streamline machine learning development, including tracking experiments, packaging code into reproducible runs, and sharing and deploying models. It is fundamental infrastructure for scientific ML workflows.",
      "domains": [
        "AI5",
        "MLOps"
      ],
      "subtask_category": [
        "experiment_tracking",
        "model_management",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/mlflow/mlflow",
      "help_website": [
        "https://mlflow.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "experiment-tracking",
        "model-registry"
      ],
      "id": 171
    },
    {
      "name": "MS-Agent",
      "one_line_profile": "Lightweight framework for building autonomous agents",
      "detailed_description": "MS-Agent is a framework from ModelScope designed to empower agents with autonomous exploration capabilities in complex task scenarios. It supports tool calling and multi-agent orchestration for various applications including scientific tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "tool_calling",
        "autonomous_exploration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/modelscope/ms-agent",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent-framework",
        "modelscope",
        "autonomous-agents"
      ],
      "id": 172
    },
    {
      "name": "AIlice",
      "one_line_profile": "Fully autonomous general-purpose AI agent",
      "detailed_description": "AIlice is a lightweight, fully autonomous AI agent designed to create a standalone, self-evolving agent system. It can be configured for scientific workflows involving complex reasoning and tool usage.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "autonomous_agent",
        "task_planning",
        "tool_execution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/myshell-ai/AIlice",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "autonomous-agent",
        "llm",
        "workflow-automation"
      ],
      "id": 173
    },
    {
      "name": "LLM Graph Builder",
      "one_line_profile": "Tool to construct knowledge graphs from unstructured data using LLMs",
      "detailed_description": "A tool by Neo4j Labs that leverages Large Language Models to extract structured data from unstructured text and build knowledge graphs. This is critical for scientific knowledge management and literature mining.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "information_extraction",
        "unstructured_data_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/neo4j-labs/llm-graph-builder",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "neo4j",
        "llm",
        "data-extraction"
      ],
      "id": 174
    },
    {
      "name": "txtai",
      "one_line_profile": "All-in-one embeddings database and AI workflow framework",
      "detailed_description": "txtai is an all-in-one embeddings database for semantic search, LLM orchestration, and language model workflows. It is widely used in scientific applications for RAG (Retrieval Augmented Generation) and data analysis pipelines.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "semantic_search",
        "workflow_orchestration",
        "rag"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/neuml/txtai",
      "help_website": [
        "https://neuml.github.io/txtai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "embeddings",
        "semantic-search",
        "rag",
        "workflow"
      ],
      "id": 175
    },
    {
      "name": "NexusRaven",
      "one_line_profile": "LLM specialized for function calling and tool usage",
      "detailed_description": "NexusRaven is a Large Language Model specifically fine-tuned for function calling, enabling agents to reliably interact with external tools and APIs. The repository contains code for evaluation and reproduction.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "function_calling",
        "tool_usage",
        "model_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nexusflowai/NexusRaven",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "function-calling",
        "agent-tooling"
      ],
      "id": 176
    },
    {
      "name": "Pautobot",
      "one_line_profile": "Private task assistant for document analysis",
      "detailed_description": "Pautobot is a private, local AI assistant developed by NRL-AI (likely Naval Research Lab context) for asking questions about documents and automating tasks without data leaving the local environment.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "document_qa",
        "local_inference",
        "privacy_preserving_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nrl-ai/pautobot",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "document-analysis",
        "privacy"
      ],
      "id": 177
    },
    {
      "name": "LLaMAR",
      "one_line_profile": "LM-based long-horizon planner for multi-agent robotics",
      "detailed_description": "LLaMAR is a framework leveraging Language Models for long-horizon planning in multi-agent robotics systems, enabling high-level instruction following and coordination.",
      "domains": [
        "AI5",
        "Robotics"
      ],
      "subtask_category": [
        "robotic_planning",
        "multi_agent_coordination",
        "long_horizon_planning"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/nsidn98/LLaMAR",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "robotics",
        "planning",
        "multi-agent",
        "llm"
      ],
      "id": 178
    },
    {
      "name": "BabyAGI-ASI",
      "one_line_profile": "Autonomous and Self-Improving (ASI) agent implementation",
      "detailed_description": "A variant of the BabyAGI framework focused on creating an autonomous and self-improving agent. It serves as a foundational implementation for task-driven autonomous agents.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "autonomous_agent",
        "task_execution",
        "self_improvement"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/oliveirabruno01/babyagi-asi",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "babyagi",
        "autonomous-agent",
        "asi"
      ],
      "id": 179
    },
    {
      "name": "OmAgent",
      "one_line_profile": "Framework for building multimodal language agents",
      "detailed_description": "OmAgent is a framework designed for building multimodal language agents, facilitating fast prototyping and production deployment of agents that can process text, images, and other modalities.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multimodal_agent_orchestration",
        "multimodal_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/om-ai-lab/OmAgent",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "agent-framework",
        "omagent"
      ],
      "id": 180
    },
    {
      "name": "OmniCoreAgent",
      "one_line_profile": "Framework for building autonomous AI agents",
      "detailed_description": "OmniCoreAgent is a Python framework for building autonomous AI agents capable of reasoning, executing complex tasks, managing memory, and coordinating workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_framework",
        "workflow_coordination",
        "memory_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/omnirexflora-labs/omnicoreagent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-framework",
        "autonomous-agents"
      ],
      "id": 181
    },
    {
      "name": "Multi-Agent Emergence Environments",
      "one_line_profile": "Environments for multi-agent reinforcement learning research",
      "detailed_description": "Code for generating environments used in the paper 'Emergent Tool Use From Multi-Agent Autocurricula'. It provides a simulation platform for studying multi-agent interaction and emergent behavior.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multi_agent_simulation",
        "reinforcement_learning_environment",
        "emergent_behavior_study"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/openai/multi-agent-emergence-environments",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "marl",
        "simulation",
        "openai",
        "research-code"
      ],
      "id": 182
    },
    {
      "name": "Swarm",
      "one_line_profile": "Ergonomic and lightweight multi-agent orchestration framework",
      "detailed_description": "Swarm is an educational framework by OpenAI exploring ergonomic and lightweight patterns for multi-agent orchestration. It provides primitives for building scalable and controllable agent systems.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multi_agent_orchestration",
        "agent_coordination"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/openai/swarm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-orchestration",
        "multi-agent",
        "openai"
      ],
      "id": 183
    },
    {
      "name": "MinerU",
      "one_line_profile": "High-quality document extraction tool for scientific literature and complex PDFs",
      "detailed_description": "MinerU is a data processing tool designed to transform complex documents, such as scientific papers (PDFs), into LLM-ready formats like Markdown and JSON. It handles multi-modal content including formulas, tables, and charts, making it an essential component for agentic workflows involving literature review and knowledge extraction.",
      "domains": [
        "AI5",
        "AI5-01",
        "AI4-01"
      ],
      "subtask_category": [
        "data_extraction",
        "document_parsing",
        "literature_review"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/opendatalab/MinerU",
      "help_website": [
        "https://github.com/opendatalab/MinerU"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "pdf-parsing",
        "ocr",
        "scientific-literature",
        "llm-data-prep"
      ],
      "id": 184
    },
    {
      "name": "osBrain",
      "one_line_profile": "General-purpose multi-agent system framework for simulations",
      "detailed_description": "osBrain is a multi-agent system module written in Python that provides a flexible infrastructure for creating and orchestrating agents. It uses ZeroMQ for efficient communication, making it suitable for building distributed scientific simulations and complex agent-based models.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_simulation",
        "multi_agent_coordination"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/opensistemas-hub/osbrain",
      "help_website": [
        "https://osbrain.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent-system",
        "simulation",
        "distributed-computing"
      ],
      "id": 185
    },
    {
      "name": "BlockAGI",
      "one_line_profile": "Self-hosted research agent platform for autonomous tasks",
      "detailed_description": "BlockAGI is a hackable, self-hosted research agent platform inspired by AutoGPT. It provides a web interface and orchestration capabilities for autonomous agents to perform complex research tasks, including information retrieval and synthesis.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "research_automation",
        "autonomous_agent"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/orgexyz/BlockAGI",
      "help_website": [
        "https://github.com/orgexyz/BlockAGI"
      ],
      "license": "Apache-2.0",
      "tags": [
        "research-agent",
        "autonomous-systems",
        "llm-agent"
      ],
      "id": 186
    },
    {
      "name": "orra",
      "one_line_profile": "Dynamic planning engine for AI agent workflows",
      "detailed_description": "Orra is a plan engine designed for the dynamic planning and reliable execution of AI agent workflows. It serves as a core component for orchestrating complex sequences of actions in agentic systems, ensuring robustness in execution.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_planning",
        "task_orchestration"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/orra-dev/orra",
      "help_website": [
        "https://github.com/orra-dev/orra"
      ],
      "license": "MPL-2.0",
      "tags": [
        "planning-engine",
        "workflow-orchestration",
        "agent-control"
      ],
      "id": 187
    },
    {
      "name": "swarm",
      "one_line_profile": "Ruby-based framework for multi-agent system orchestration",
      "detailed_description": "Swarm is a Ruby framework for building general-purpose AI agent systems. It provides tools for single-process orchestration, persistent memory, and node workflows, enabling the creation of agents for research automation and data processing tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "workflow_automation"
      ],
      "application_level": "library",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/parruda/swarm",
      "help_website": [
        "https://github.com/parruda/swarm"
      ],
      "license": "MIT",
      "tags": [
        "ruby",
        "multi-agent",
        "orchestration"
      ],
      "id": 188
    },
    {
      "name": "MuSHR",
      "one_line_profile": "Multi-agent system platform for robotics research",
      "detailed_description": "MuSHR (Multi-agent System for non-Holonomic Racing) is a research platform designed for testing multi-agent coordination and planning algorithms in robotics. It provides a standardized stack for developing and evaluating autonomous agents in dynamic environments.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "robotics_simulation",
        "multi_agent_control"
      ],
      "application_level": "platform",
      "primary_language": "CMake",
      "repo_url": "https://github.com/prl-mushr/mushr",
      "help_website": [
        "https://mushr.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "robotics",
        "multi-agent",
        "autonomous-racing"
      ],
      "id": 189
    },
    {
      "name": "PydanticAI",
      "one_line_profile": "Production-grade framework for building Generative AI agents",
      "detailed_description": "PydanticAI is a Python framework for building GenAI agents using Pydantic for data validation and structuring. It provides a robust foundation for creating type-safe, reliable agentic workflows suitable for complex scientific data processing and orchestration.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_framework",
        "workflow_orchestration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pydantic/pydantic-ai",
      "help_website": [
        "https://ai.pydantic.dev/"
      ],
      "license": "MIT",
      "tags": [
        "agent-framework",
        "pydantic",
        "llm-orchestration"
      ],
      "id": 190
    },
    {
      "name": "dlsc_gc_planner",
      "one_line_profile": "Decentralized multi-agent trajectory planner with goal convergence",
      "detailed_description": "A C++ implementation of a decentralized multi-agent trajectory planner that guarantees goal convergence. It is a solver for path planning problems in multi-agent systems, applicable to robotics and swarm intelligence research.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "trajectory_planning",
        "multi_agent_coordination"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/qwerty35/dlsc_gc_planner",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "path-planning",
        "multi-agent",
        "robotics"
      ],
      "id": 191
    },
    {
      "name": "lsc_dr_planner",
      "one_line_profile": "Deadlock-free multi-agent trajectory planner using linear safe corridor",
      "detailed_description": "An online multi-agent trajectory planner that utilizes linear safe corridors (LSC) to ensure deadlock-free navigation. This tool is designed for coordinating multiple agents in shared environments, solving collision avoidance and path optimization problems.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "trajectory_planning",
        "collision_avoidance"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/qwerty35/lsc_dr_planner",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "path-planning",
        "multi-agent",
        "collision-avoidance"
      ],
      "id": 192
    },
    {
      "name": "lsc_planner",
      "one_line_profile": "Online multi-agent trajectory planner using linear safe corridor",
      "detailed_description": "A C++ library implementing the Linear Safe Corridor (LSC) method for online multi-agent trajectory planning. It serves as a core algorithm for safe and efficient movement coordination in multi-agent research.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "trajectory_planning",
        "multi_agent_coordination"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/qwerty35/lsc_planner",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "path-planning",
        "multi-agent",
        "robotics"
      ],
      "id": 193
    },
    {
      "name": "RagaAI Catalyst",
      "one_line_profile": "Observability and evaluation framework for agentic AI systems",
      "detailed_description": "RagaAI Catalyst is a Python SDK and platform for the observability, monitoring, and evaluation of AI agents. It provides tools for tracing agent execution, debugging multi-agent systems, and analyzing performance, which is critical for developing reliable scientific agents.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_evaluation",
        "observability",
        "debugging"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/raga-ai-hub/RagaAI-Catalyst",
      "help_website": [
        "https://docs.raga.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "observability",
        "agent-evaluation",
        "monitoring"
      ],
      "id": 194
    },
    {
      "name": "AgentGPT",
      "one_line_profile": "Platform for configuring and deploying autonomous AI agents",
      "detailed_description": "AgentGPT is a platform that allows users to assemble, configure, and deploy autonomous AI agents directly in the browser. It enables the creation of agents capable of executing complex, multi-step research goals through recursive planning and execution.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_deployment",
        "autonomous_planning"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/reworkd/AgentGPT",
      "help_website": [
        "https://agentgpt.reworkd.ai/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "autonomous-agents",
        "web-agent",
        "planning"
      ],
      "id": 195
    },
    {
      "name": "Rhesis",
      "one_line_profile": "Testing platform and SDK for LLM and agentic applications",
      "detailed_description": "Rhesis is an open-source testing platform designed for LLM and agentic applications. It allows developers to define behavioral constraints and automatically generates test scenarios to verify agent performance and reliability before deployment.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_testing",
        "reliability_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/rhesis-ai/rhesis",
      "help_website": [
        "https://rhesis.ai/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "testing",
        "agent-evaluation",
        "quality-assurance"
      ],
      "id": 196
    },
    {
      "name": "Agent-MCP",
      "one_line_profile": "Multi-agent system framework using Model Context Protocol",
      "detailed_description": "Agent-MCP is a framework for creating coordinated multi-agent systems leveraging the Model Context Protocol (MCP). It facilitates efficient collaboration between specialized agents, enabling modular and scalable agentic workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multi_agent_coordination",
        "protocol_implementation"
      ],
      "application_level": "framework",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/rinadelph/Agent-MCP",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "mcp",
        "multi-agent",
        "interoperability"
      ],
      "id": 197
    },
    {
      "name": "local-llm-function-calling",
      "one_line_profile": "Function calling utility for local LLMs",
      "detailed_description": "A Python utility that enables local Large Language Models (LLMs) to perform function calling. It generates function arguments and selects appropriate functions based on specifications, serving as a critical middleware for building agentic tools with local models.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "tool_calling",
        "function_execution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rizerphe/local-llm-function-calling",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "function-calling",
        "local-llm",
        "agent-tooling"
      ],
      "id": 198
    },
    {
      "name": "Diff-Epo Planner",
      "one_line_profile": "Differentiable game-theoretic optimization for multi-agent prediction and control",
      "detailed_description": "A framework integrating differentiable game-theoretic optimization with neural networks for multi-agent trajectory prediction and control, specifically designed for robotics and autonomous systems.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "trajectory_prediction",
        "control_optimization",
        "multi_agent_simulation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/rst-tu-dortmund/diff_epo_planner",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "robotics",
        "control-theory",
        "game-theory",
        "optimization"
      ],
      "id": 199
    },
    {
      "name": "DeepAnalyze",
      "one_line_profile": "Agentic LLM framework for autonomous data science and analysis",
      "detailed_description": "An autonomous data science agent capable of analyzing large datasets, performing statistical inference, and generating professional analysis reports automatically.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "data_analysis",
        "automated_reporting",
        "statistical_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ruc-datalab/DeepAnalyze",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-science",
        "autonomous-agent",
        "data-analysis"
      ],
      "id": 200
    },
    {
      "name": "LlamaIndexTS",
      "one_line_profile": "TypeScript data framework for building LLM-based agents and RAG systems",
      "detailed_description": "The TypeScript implementation of LlamaIndex, providing data structures and interfaces to connect LLMs with external data sources for building agentic workflows and RAG applications.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_framework",
        "rag_pipeline",
        "data_indexing"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/run-llama/LlamaIndexTS",
      "help_website": [
        "https://ts.llamaindex.ai/"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "llm-framework",
        "typescript",
        "agent"
      ],
      "id": 201
    },
    {
      "name": "LlamaHub",
      "one_line_profile": "Community library of data loaders and agent tools for LlamaIndex",
      "detailed_description": "A repository of data loaders, agent tools, and packs that extend LlamaIndex, enabling connection to various scientific and general data sources for LLM applications.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "data_loading",
        "tool_integration"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/run-llama/llama-hub",
      "help_website": [
        "https://llamahub.ai/"
      ],
      "license": "MIT",
      "tags": [
        "data-loaders",
        "integrations",
        "llamaindex"
      ],
      "id": 202
    },
    {
      "name": "LlamaIndex",
      "one_line_profile": "Data framework for building LLM-powered agents and RAG applications",
      "detailed_description": "A comprehensive framework for connecting LLMs to private data, enabling the creation of query engines, chat engines, and autonomous agents capable of reasoning over complex data structures.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_framework",
        "rag_pipeline",
        "data_indexing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/run-llama/llama_index",
      "help_website": [
        "https://docs.llamaindex.ai/"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "agent",
        "llm",
        "data-framework"
      ],
      "id": 203
    },
    {
      "name": "Claude Flow",
      "one_line_profile": "Agent orchestration platform specialized for Claude models",
      "detailed_description": "An orchestration framework for deploying multi-agent swarms and autonomous workflows, featuring RAG integration and support for the Model Context Protocol (MCP).",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "multi_agent_system"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/ruvnet/claude-flow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "claude",
        "agent-swarm",
        "orchestration"
      ],
      "id": 204
    },
    {
      "name": "Q-Star Agent",
      "one_line_profile": "Reinforcement learning-based framework for intelligent agents",
      "detailed_description": "A framework leveraging Q-learning variants (Q-Star) within Microsoft AutoGen to enable dynamic decision-making and adaptive behavior in AI agents.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "agent_training",
        "decision_making"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ruvnet/q-star",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "reinforcement-learning",
        "q-learning",
        "autogen"
      ],
      "id": 205
    },
    {
      "name": "ToolEmu",
      "one_line_profile": "Emulation framework for identifying risks in LM agents with tool use",
      "detailed_description": "A framework designed to emulate and evaluate the behavior of language model agents using tools, specifically focused on identifying safety risks and failure modes in agentic workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_evaluation",
        "risk_assessment",
        "simulation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ryoungj/ToolEmu",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "safety",
        "llm-agent"
      ],
      "id": 206
    },
    {
      "name": "Agents Manager",
      "one_line_profile": "Lightweight Python package for multi-agent orchestration",
      "detailed_description": "A library for defining and managing agents with custom instructions, tools, and containers, facilitating the orchestration of modular and collaborative AI systems.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "multi_agent_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sandeshnaroju/agents_manager",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "orchestration",
        "multi-agent",
        "python"
      ],
      "id": 207
    },
    {
      "name": "Orca",
      "one_line_profile": "LLM Orchestrator built in Rust",
      "detailed_description": "A high-performance orchestration library for Large Language Models, written in Rust, designed to manage complex LLM workflows and agent interactions.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/santiagomed/orca",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rust",
        "orchestrator",
        "llm"
      ],
      "id": 208
    },
    {
      "name": "ROMA",
      "one_line_profile": "Recursive-Open-Meta-Agent framework for multi-agent systems",
      "detailed_description": "A meta-agent framework designed to build high-performance multi-agent systems through recursive and open architectural patterns.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multi_agent_system",
        "agent_architecture"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/sentient-agi/ROMA",
      "help_website": [],
      "license": null,
      "tags": [
        "meta-agent",
        "multi-agent",
        "framework"
      ],
      "id": 209
    },
    {
      "name": "NPI",
      "one_line_profile": "Action library for AI Agents",
      "detailed_description": "A library providing a set of executable actions and tools for AI agents, enabling them to interact with external environments and APIs.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "tool_use",
        "agent_actions"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sheet0/npi",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent-tools",
        "actions",
        "api-integration"
      ],
      "id": 210
    },
    {
      "name": "Agentica",
      "one_line_profile": "Framework for building intelligent multimodal AI agents",
      "detailed_description": "A framework designed to facilitate the construction of reflective and collaborative multimodal AI agents, supporting complex interaction patterns.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_framework",
        "multimodal_agents"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/shibing624/agentica",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "agent",
        "collaboration"
      ],
      "id": 211
    },
    {
      "name": "CoAgents",
      "one_line_profile": "Cooperative and interactive agents framework for tool learning",
      "detailed_description": "Implementation of the 'Learning to Use Tools via Cooperative and Interactive Agents' paper, providing a framework for agents to learn tool usage through cooperation.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_cooperation",
        "tool_learning",
        "multi_agent_system"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shizhl/CoAgents",
      "help_website": [],
      "license": null,
      "tags": [
        "research",
        "tool-use",
        "cooperative-agents"
      ],
      "id": 212
    },
    {
      "name": "CodeInterpreter API",
      "one_line_profile": "Open source implementation of ChatGPT Code Interpreter",
      "detailed_description": "A library that provides a sandboxed Python execution environment for LLMs, enabling agents to perform data analysis, visualization, and complex calculations.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "code_execution",
        "data_analysis",
        "sandbox"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shroominic/codeinterpreter-api",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "code-interpreter",
        "sandbox",
        "data-analysis"
      ],
      "id": 213
    },
    {
      "name": "OpenAlpha_Evolve",
      "one_line_profile": "Evolutionary algorithm framework for autonomous coding agents",
      "detailed_description": "An open-source framework inspired by AlphaEvolve, designed for evolving algorithms and autonomous coding agents using evolutionary strategies.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "evolutionary_algorithm",
        "automl",
        "algorithm_discovery"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shyamsaktawat/OpenAlpha_Evolve",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evolutionary-algorithms",
        "automl",
        "alpha-evolve"
      ],
      "id": 214
    },
    {
      "name": "Multi-Agent-Medical-Assistant",
      "one_line_profile": "GenAI-powered multi-agent system for medical diagnostics and healthcare research",
      "detailed_description": "A multi-agent chatbot system designed for healthcare professionals and researchers to assist with medical diagnostics and healthcare research tasks using Generative AI.",
      "domains": [
        "AI5",
        "AI5-01",
        "Medicine"
      ],
      "subtask_category": [
        "medical_diagnostics",
        "healthcare_research"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/souvikmajumder26/Multi-Agent-Medical-Assistant",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-agent",
        "healthcare",
        "diagnostics",
        "multi-agent"
      ],
      "id": 215
    },
    {
      "name": "DATAGEN",
      "one_line_profile": "AI-driven multi-agent research assistant for hypothesis generation and data analysis",
      "detailed_description": "A multi-agent system designed to act as a research assistant, automating key scientific tasks such as hypothesis generation, data analysis, and report writing.",
      "domains": [
        "AI5",
        "AI5-01",
        "Data Science"
      ],
      "subtask_category": [
        "hypothesis_generation",
        "data_analysis",
        "scientific_writing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/starpig1129/DATAGEN",
      "help_website": [
        "https://datagen.digital/"
      ],
      "license": "MIT",
      "tags": [
        "research-assistant",
        "hypothesis-generation",
        "data-analysis",
        "multi-agent"
      ],
      "id": 216
    },
    {
      "name": "open-data-scientist",
      "one_line_profile": "AI agent for automating complex data analysis tasks",
      "detailed_description": "An Open AI data scientist agent that automates complex data analysis tasks using the ReAct framework. It can execute Python code, handle datasets, and generate analytical reports, serving as an autonomous tool for scientific data analysis.",
      "domains": [
        "AI5",
        "AI5-01",
        "Data Science"
      ],
      "subtask_category": [
        "data_analysis",
        "scientific_reporting",
        "code_execution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/togethercomputer/open-data-scientist",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-scientist",
        "agent",
        "data-analysis",
        "react-framework"
      ],
      "id": 217
    },
    {
      "name": "DocETL",
      "one_line_profile": "Agentic system for optimizing LLM-powered complex data processing pipelines",
      "detailed_description": "A system that uses LLM agents to optimize data processing and ETL (Extract, Transform, Load) workflows, specifically designed for complex, unstructured data tasks often found in research.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "data_processing",
        "workflow_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ucbepic/docetl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "etl",
        "llm-agents",
        "data-processing"
      ],
      "id": 218
    },
    {
      "name": "LOMAP",
      "one_line_profile": "LTL Optimal Multi-Agent Planner",
      "detailed_description": "A solver for Linear Temporal Logic (LTL) optimal multi-agent planning, enabling the synthesis of agent behaviors that satisfy complex temporal specifications.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "planning",
        "agent_coordination"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wasserfeder/lomap",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "multi-agent-planning",
        "ltl",
        "solver"
      ],
      "id": 219
    },
    {
      "name": "WebArena",
      "one_line_profile": "Realistic web environment for benchmarking autonomous agents",
      "detailed_description": "A standalone, self-hostable web environment for building and evaluating autonomous agents, providing a realistic benchmark for agentic tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "benchmarking",
        "simulation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/web-arena-x/webarena",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "autonomous-agents",
        "simulation"
      ],
      "id": 220
    },
    {
      "name": "ComfyBench",
      "one_line_profile": "Benchmark for LLM-based agents in ComfyUI workflows",
      "detailed_description": "A framework and benchmark for evaluating the performance of LLM-based agents in designing and executing collaborative AI systems within ComfyUI.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "benchmarking",
        "workflow_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/xxyQwQ/ComfyBench",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "comfyui",
        "llm-agents"
      ],
      "id": 221
    },
    {
      "name": "BabyAGI-2o",
      "one_line_profile": "Self-building autonomous agent framework for task planning and execution",
      "detailed_description": "A simplified and modernized version of the BabyAGI autonomous agent, designed to self-build and execute tasks. It serves as a general-purpose agent framework that can be adapted for scientific workflow automation, experiment planning, and autonomous data gathering.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "task_planning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yoheinakajima/babyagi-2o",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "autonomous-agent",
        "task-planning",
        "agent-framework"
      ],
      "id": 222
    },
    {
      "name": "BabyAGI (Original)",
      "one_line_profile": "The classic autonomous task management agent implementation",
      "detailed_description": "The original implementation of the BabyAGI task management system, updated to support modern LLM interfaces. It provides a foundational framework for creating autonomous agents that can plan, prioritize, and execute tasks, applicable to scientific research automation.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "task_planning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yoheinakajima/babyagi_og",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "autonomous-agent",
        "task-management",
        "llm-agent"
      ],
      "id": 223
    },
    {
      "name": "Swarm.js",
      "one_line_profile": "Node.js implementation of the OpenAI Swarm multi-agent orchestration framework",
      "detailed_description": "A lightweight SDK for orchestrating multi-agent systems using OpenAI's Swarm patterns. It enables the creation of scalable agent workflows, which can be applied to coordinate distributed scientific computing tasks or multi-step analysis pipelines.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "multi_agent_orchestration",
        "workflow_automation"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/youseai/openai-swarm-node",
      "help_website": [],
      "license": null,
      "tags": [
        "multi-agent",
        "swarm",
        "orchestration"
      ],
      "id": 224
    },
    {
      "name": "AutoGPT.js",
      "one_line_profile": "Browser-based implementation of the AutoGPT autonomous agent",
      "detailed_description": "A TypeScript implementation of AutoGPT designed to run in the browser. It brings autonomous agent capabilities to web environments, allowing for the creation of agents that can perform web-based research and task execution relevant to scientific data gathering.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "autonomous_agent",
        "web_automation"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/zabirauf/AutoGPT.js",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "autogpt",
        "browser-agent",
        "autonomous-task"
      ],
      "id": 225
    },
    {
      "name": "ZenML",
      "one_line_profile": "Extensible MLOps framework for creating portable production-ready machine learning pipelines",
      "detailed_description": "An MLOps framework that orchestrates machine learning pipelines and agents. It is widely used in scientific AI to ensure reproducibility, manage experiments, and deploy models for tasks ranging from drug discovery to physics simulations.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "pipeline_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/zenml-io/zenml",
      "help_website": [
        "https://zenml.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "pipeline",
        "reproducibility",
        "workflow"
      ],
      "id": 226
    },
    {
      "name": "RAGElo",
      "one_line_profile": "Evaluation toolkit for ranking RAG-based LLM agents using Elo rating",
      "detailed_description": "A tool for evaluating and selecting the best Retrieval-Augmented Generation (RAG) agents. In scientific contexts, it helps researchers benchmark agents designed for literature review or knowledge extraction to ensure accuracy and performance.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "model_evaluation",
        "agent_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zetaalphavector/RAGElo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "rag",
        "elo-ranking",
        "agent-benchmarking"
      ],
      "id": 227
    },
    {
      "name": "Paper Summarizer",
      "one_line_profile": "Intelligent agent for automated academic paper subscription, translation, and summarization",
      "detailed_description": "An agent designed to automate the literature review process by monitoring email subscriptions for academic papers, translating content, and generating summaries. This directly supports the scientific task of knowledge acquisition and literature tracking.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "literature_review",
        "summarization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhangleino1/paper-summarizer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "literature-review",
        "academic-paper",
        "summarization"
      ],
      "id": 228
    },
    {
      "name": "ChatWiki",
      "one_line_profile": "AI knowledge base workflow agent platform for RAG applications",
      "detailed_description": "A platform for building AI agents integrated with knowledge bases (RAG). It allows researchers to construct domain-specific knowledge assistants that can query and synthesize information from scientific documents and databases.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "knowledge_management",
        "rag_workflow"
      ],
      "application_level": "platform",
      "primary_language": "Vue",
      "repo_url": "https://github.com/zhimaAi/chatwiki",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "knowledge-base",
        "rag",
        "agent-platform"
      ],
      "id": 229
    },
    {
      "name": "OpenChatBI",
      "one_line_profile": "Intelligent chat-based BI agent for natural language data analysis and SQL generation",
      "detailed_description": "An intelligent agent tool that converts natural language queries into SQL for data analysis and visualization. It supports scientific data analysis by enabling researchers to interactively query experimental databases using natural language.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "data_analysis",
        "sql_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhongyu09/openchatbi",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-analysis",
        "text-to-sql",
        "bi-agent"
      ],
      "id": 230
    },
    {
      "name": "GPTCache",
      "one_line_profile": "Semantic cache library for optimizing LLM inference in agent workflows",
      "detailed_description": "A semantic caching layer for Large Language Models (LLMs). It is a critical infrastructure tool for scientific AI agents, reducing latency and cost when processing repetitive queries in literature mining or data analysis workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "inference_optimization",
        "workflow_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zilliztech/GPTCache",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-cache",
        "optimization",
        "inference"
      ],
      "id": 231
    },
    {
      "name": "OneKE",
      "one_line_profile": "Schema-guided LLM agent system for knowledge extraction",
      "detailed_description": "A Dockerized system using LLM agents for schema-guided knowledge extraction. It is specifically designed to extract structured scientific knowledge (entities, relations, events) from unstructured text, facilitating knowledge graph construction.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "information_extraction"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/zjunlp/OneKE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-extraction",
        "ie",
        "schema-guided"
      ],
      "id": 232
    },
    {
      "name": "Instructor (Python)",
      "one_line_profile": "Library for structured data extraction and validation from LLMs using Pydantic",
      "detailed_description": "A Python library that simplifies the process of extracting structured data from Large Language Models (LLMs) by leveraging Pydantic for schema validation. It is essential for scientific agents requiring precise data extraction from literature or structured tool inputs.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "structured_extraction",
        "schema_validation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/567-labs/instructor",
      "help_website": [
        "https://python.useinstructor.com/"
      ],
      "license": "MIT",
      "tags": [
        "llm",
        "structured-output",
        "pydantic",
        "function-calling"
      ],
      "id": 233
    },
    {
      "name": "Instructor (Go)",
      "one_line_profile": "Go client for structured LLM outputs and data extraction",
      "detailed_description": "The Go implementation of the Instructor library, enabling structured data extraction and validation from LLMs within Go-based scientific workflows and agent backends.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "structured_extraction",
        "schema_validation"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/567-labs/instructor-go",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "go",
        "llm",
        "structured-data"
      ],
      "id": 234
    },
    {
      "name": "Instructor (TypeScript)",
      "one_line_profile": "TypeScript library for structured LLM extraction using Zod",
      "detailed_description": "The TypeScript/JavaScript version of Instructor, utilizing Zod for schema definition to ensure type-safe structured outputs from LLMs, suitable for web-based scientific interfaces and agents.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "structured_extraction",
        "schema_validation"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/567-labs/instructor-js",
      "help_website": [
        "https://js.useinstructor.com/"
      ],
      "license": "MIT",
      "tags": [
        "typescript",
        "llm",
        "zod",
        "structured-output"
      ],
      "id": 235
    },
    {
      "name": "Instructor (Ruby)",
      "one_line_profile": "Ruby library for structured outputs from LLMs",
      "detailed_description": "The Ruby implementation of the Instructor pattern, facilitating structured data handling from LLMs for Ruby-based research tools and scripts.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "structured_extraction",
        "schema_validation"
      ],
      "application_level": "library",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/567-labs/instructor-rb",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ruby",
        "llm",
        "structured-output"
      ],
      "id": 236
    },
    {
      "name": "Instructor (Rust)",
      "one_line_profile": "Rust crate for structured LLM outputs",
      "detailed_description": "The Rust implementation of Instructor, providing high-performance, type-safe structured extraction from LLMs, suitable for computationally intensive scientific agent backends.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "structured_extraction",
        "schema_validation"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/567-labs/instructor-rs",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rust",
        "llm",
        "structured-output"
      ],
      "id": 237
    },
    {
      "name": "tuui",
      "one_line_profile": "Desktop client for Model Context Protocol (MCP) orchestration",
      "detailed_description": "A desktop client designed to accelerate AI adoption through the Model Context Protocol (MCP), enabling cross-vendor LLM API orchestration and tool integration, which is critical for multi-model scientific workflows.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "tool_orchestration",
        "api_integration"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/AI-QL/tuui",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mcp",
        "llm-orchestration",
        "tool-integration"
      ],
      "id": 238
    },
    {
      "name": "tiny_fnc_engine",
      "one_line_profile": "Minimal engine for executing LLM-generated function calls",
      "detailed_description": "A lightweight Python library that provides a flexible engine for parsing and executing function calls extracted from LLMs, serving as a building block for custom scientific agents.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "function_calling",
        "tool_execution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AtakanTekparmak/tiny_fnc_engine",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "function-calling",
        "llm",
        "agent-utils"
      ],
      "id": 239
    },
    {
      "name": "open-ptc-agent",
      "one_line_profile": "Agent implementation for programmatic tool calling via MCP",
      "detailed_description": "An open-source implementation of an AI agent focused on code execution and programmatic tool calling using the Model Context Protocol (MCP), suitable for automating computational scientific tasks.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "code_execution",
        "tool_use"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Chen-zexi/open-ptc-agent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "agent",
        "code-execution"
      ],
      "id": 240
    },
    {
      "name": "Composio Function Calling Benchmark",
      "one_line_profile": "Benchmark suite for LLM function calling capabilities",
      "detailed_description": "A benchmarking tool designed to evaluate and test the function calling performance of various Large Language Models, aiding researchers in selecting appropriate models for agentic workflows.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmark"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ComposioHQ/Composio-Function-Calling-Benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "function-calling",
        "llm-eval"
      ],
      "id": 241
    },
    {
      "name": "Composio",
      "one_line_profile": "Integration platform for AI agents to interface with external tools",
      "detailed_description": "A comprehensive platform and library that equips AI agents and LLMs with extensive integrations via function calling, serving as a critical infrastructure for building agents that interact with external software and APIs.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "tool_integration",
        "workflow_automation"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/ComposioHQ/composio",
      "help_website": [
        "https://docs.composio.dev/"
      ],
      "license": "MIT",
      "tags": [
        "agent-integration",
        "function-calling",
        "tool-registry"
      ],
      "id": 242
    },
    {
      "name": "HuggingFists",
      "one_line_profile": "Low-code data flow tool for LLM pipelines",
      "detailed_description": "A low-code data flow tool that facilitates the construction of processing pipelines using LLMs and HuggingFace models, enabling researchers to build complex data processing workflows without extensive coding.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "data_flow"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Datayoo/HuggingFists",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "low-code",
        "llm-workflow",
        "pipeline"
      ],
      "id": 243
    },
    {
      "name": "Chat2Anything",
      "one_line_profile": "LLM-based knowledge base QA system",
      "detailed_description": "An LLM-based tool designed to chat with documents and databases, providing a management system for enterprise or research knowledge bases, facilitating literature review and data querying.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "document_qa"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DemoGit4LIANG/Chat2Anything",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "knowledge-base",
        "qa-system"
      ],
      "id": 244
    },
    {
      "name": "GPT_ALL",
      "one_line_profile": "Framework for multi-step asynchronous function calling",
      "detailed_description": "A project combining LLMs with multi-step asynchronous function calling, NLP, and TTS, providing a framework for building complex, interactive AI agents.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "asynchronous_function_calling",
        "agent_orchestration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Eloquent-Algorithmics/GPT_ALL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "function-calling",
        "async",
        "agent-framework"
      ],
      "id": 245
    },
    {
      "name": "AnyTool",
      "one_line_profile": "Universal tool-use layer for AI agents",
      "detailed_description": "A framework implementing a universal tool-use layer for AI agents, designed to enhance the capability of LLMs to interact with a wide variety of tools effectively, supporting complex agentic workflows.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "tool_use_optimization",
        "agent_capability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUDS/AnyTool",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent",
        "tool-use",
        "llm"
      ],
      "id": 246
    },
    {
      "name": "AutoAgent",
      "one_line_profile": "Fully-automated zero-code LLM agent framework",
      "detailed_description": "A framework for generating and managing LLM-based agents without coding, automating the process of agent creation and workflow orchestration, suitable for rapid prototyping of scientific assistants.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "agent_orchestration",
        "automated_workflow"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUDS/AutoAgent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-framework",
        "no-code",
        "automation"
      ],
      "id": 247
    },
    {
      "name": "MCP Context Forge",
      "one_line_profile": "Gateway and registry for Model Context Protocol (MCP) tools and resources",
      "detailed_description": "A centralized management point for tools, resources, and prompts accessible by MCP-compatible LLM applications. It converts REST API endpoints to MCP, composes virtual MCP servers, and handles protocol conversions, serving as a critical infrastructure component for AI agent toolchains.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "tool_registry",
        "protocol_conversion"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/IBM/mcp-context-forge",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mcp",
        "agent-tools",
        "gateway"
      ],
      "id": 248
    },
    {
      "name": "Patito",
      "one_line_profile": "Data modeling and validation layer for Polars dataframes",
      "detailed_description": "A library built on top of Polars and Pydantic that provides a structured data modeling layer. It allows for the definition of schemas and validation of dataframes, which is essential for ensuring data quality and consistency in scientific data processing pipelines.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "data_modeling",
        "schema_validation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/JakobGM/patito",
      "help_website": [
        "https://patito.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "polars",
        "pydantic",
        "data-validation"
      ],
      "id": 249
    },
    {
      "name": "UniversalLLMFunctionCaller",
      "one_line_profile": "Planner for enabling function calling on chat-based LLMs via Semantic Kernel",
      "detailed_description": "A planner integration for Semantic Kernel that enables function calling capabilities on various chat-based Large Language Models (LLMs) such as Mistral, Bard, and Claude. It acts as an adapter to standardize tool invocation across different models.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "function_calling",
        "agent_planning"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/Jenscaasen/UniversalLLMFunctionCaller",
      "help_website": [],
      "license": null,
      "tags": [
        "semantic-kernel",
        "function-calling",
        "llm-agent"
      ],
      "id": 250
    },
    {
      "name": "Composio MCP Server",
      "one_line_profile": "Model Context Protocol server for Composio tool integration",
      "detailed_description": "An MCP server implementation that connects LLMs to the Composio platform, enabling agents to access and utilize a wide range of external tools and integrations. It facilitates the orchestration of complex workflows by providing a standardized interface for tool execution.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "tool_integration",
        "mcp_server"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/MCP-Mirror/ComposioHQ_composio-mcp-server",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mcp",
        "composio",
        "tool-integration"
      ],
      "id": 251
    },
    {
      "name": "LangChain GPT Researcher",
      "one_line_profile": "LangChain tool wrapper for the GPT Researcher autonomous agent",
      "detailed_description": "Integrates GPT Researcher as a tool within the LangChain ecosystem, allowing agents to perform autonomous online research, scrape web content, and synthesize information for scientific literature review and data gathering tasks.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "literature_review",
        "web_research"
      ],
      "application_level": "tool",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Makesh-Srinivasan/LangChain-GPT-Researcher",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "langchain",
        "research-agent",
        "automated-research"
      ],
      "id": 252
    },
    {
      "name": "ToolAgents",
      "one_line_profile": "Lightweight framework for creating function-calling agents",
      "detailed_description": "A flexible framework designed to facilitate the creation of agents capable of function calling with various language models and APIs. It abstracts the complexity of tool definition and invocation, streamlining the development of agentic workflows.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "function_calling",
        "agent_framework"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Maximilian-Winter/ToolAgents",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "function-calling",
        "agent-tools",
        "llm"
      ],
      "id": 253
    },
    {
      "name": "MiniMax MCP",
      "one_line_profile": "Official Model Context Protocol server for MiniMax AI models",
      "detailed_description": "Provides an MCP interface to interact with MiniMax's suite of AI models, including Text-to-Speech, image generation, and video generation. This server enables scientific agents to leverage multimodal generation capabilities within a standardized protocol.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "model_serving",
        "mcp_server"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/MiniMax-AI/MiniMax-MCP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "minimax",
        "multimodal"
      ],
      "id": 254
    },
    {
      "name": "ToolRegistry",
      "one_line_profile": "Protocol-agnostic tool management library for function-calling LLMs",
      "detailed_description": "A library designed to manage tool definitions and registrations for Large Language Models with function calling capabilities. It provides a unified interface to register tools and generate the necessary schemas for different LLM providers.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "tool_registration",
        "schema_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Oaklight/ToolRegistry",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "function-calling",
        "tool-management",
        "llm"
      ],
      "id": 255
    },
    {
      "name": "ToolBridge",
      "one_line_profile": "Universal function calling adapter for LLMs",
      "detailed_description": "Enables tool and function calling capabilities for LLMs that do not natively support them, or standardizes the interface across OpenAI and Ollama API formats. It acts as a bridge to add agentic capabilities to a wider range of models.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "function_calling",
        "adapter"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/Oct4Pie/toolbridge",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "function-calling",
        "llm-adapter",
        "ollama"
      ],
      "id": 256
    },
    {
      "name": "OpenAPI Generator CLI",
      "one_line_profile": "CLI tool for generating API clients and servers from OpenAPI specifications",
      "detailed_description": "The command-line interface for OpenAPI Generator, which allows for the automatic generation of API client libraries, server stubs, and documentation from OpenAPI (Swagger) schemas. In the context of AI agents, it is a fundamental tool for creating the interfaces that allow agents to interact with scientific services and data repositories.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "api_generation",
        "schema_adaptation"
      ],
      "application_level": "tool",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/OpenAPITools/openapi-generator-cli",
      "help_website": [
        "https://openapi-generator.tech"
      ],
      "license": "Apache-2.0",
      "tags": [
        "openapi",
        "code-generation",
        "api-client"
      ],
      "id": 257
    },
    {
      "name": "Dive",
      "one_line_profile": "Desktop MCP host application for LLM function calling",
      "detailed_description": "An open-source desktop application that serves as a host for the Model Context Protocol (MCP). It integrates with LLMs to provide a runtime environment for function calling and tool execution, enabling users to run agentic workflows locally.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "mcp_host",
        "tool_execution"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/OpenAgentPlatform/Dive",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "desktop-agent",
        "function-calling"
      ],
      "id": 258
    },
    {
      "name": "DeepDoc",
      "one_line_profile": "Deep research tool for local knowledge base analysis",
      "detailed_description": "A tool designed for deep research tasks using local knowledge bases. It likely employs RAG (Retrieval-Augmented Generation) techniques to analyze documents and synthesize information, aiding in scientific literature review and data analysis.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "document_analysis",
        "rag"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/Oqura-ai/deepdoc",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "research-tool",
        "rag",
        "knowledge-base"
      ],
      "id": 259
    },
    {
      "name": "LangChain Prefect",
      "one_line_profile": "Integration tools for using LangChain within Prefect workflows",
      "detailed_description": "A library that provides integration between LangChain (agent framework) and Prefect (workflow orchestration). It enables the building of robust, observable, and resilient AI agent workflows for scientific tasks.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "agent_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PrefectHQ/langchain-prefect",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prefect",
        "langchain",
        "workflow"
      ],
      "id": 260
    },
    {
      "name": "MCP Framework",
      "one_line_profile": "TypeScript framework for building Model Context Protocol servers",
      "detailed_description": "A framework designed to simplify the development of MCP servers in TypeScript. It provides the necessary abstractions and utilities to create tools and resources that comply with the Model Context Protocol, facilitating the expansion of the AI agent tool ecosystem.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "mcp_development",
        "server_framework"
      ],
      "application_level": "framework",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/QuantGeekDev/mcp-framework",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "typescript",
        "framework"
      ],
      "id": 261
    },
    {
      "name": "CoexistAI",
      "one_line_profile": "Modular research assistant framework for automating workflows with LLMs and tool calls",
      "detailed_description": "A developer-friendly framework designed to build, search, summarize, and automate research workflows. It integrates LLMs with web search and mapping tools through simple MCP tool calls, enabling the automation of complex information gathering and synthesis tasks in scientific research.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "workflow_automation",
        "literature_review"
      ],
      "application_level": "framework",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/SPThole/CoexistAI",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "research-assistant",
        "workflow-automation",
        "llm-agent"
      ],
      "id": 262
    },
    {
      "name": "Tanuki.py",
      "one_line_profile": "Library for building LLM-powered functions with type safety",
      "detailed_description": "A library that allows developers to build type-safe functions powered by LLMs. It simplifies the creation of neuro-symbolic applications by patching Python functions with LLM logic, enabling easy integration of alignment and function calling capabilities into software workflows.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "function_construction",
        "prompt_engineering"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Tanuki/tanuki.py",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-functions",
        "type-safety",
        "neuro-symbolic"
      ],
      "id": 263
    },
    {
      "name": "ToolBrain",
      "one_line_profile": "Framework for agentic tool use training with reinforcement learning",
      "detailed_description": "A framework focused on training AI agents to use tools effectively using reinforcement learning techniques. It addresses the challenge of teaching agents to select and execute the correct tools in multi-step reasoning processes.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "agent_training",
        "tool_learning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/ToolBrain/ToolBrain",
      "help_website": [],
      "license": null,
      "tags": [
        "reinforcement-learning",
        "tool-use",
        "agent-training"
      ],
      "id": 264
    },
    {
      "name": "Tiger",
      "one_line_profile": "Middleware library for enhancing AI agents with code execution and tool integration",
      "detailed_description": "A library that acts as a bridge for AI agents (like LangChain, Autogen, CrewAI), providing them with capabilities such as code execution and advanced tool integration. It aims to enhance the 'brain' of the agent by facilitating complex interactions with the environment.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "agent_enhancement",
        "code_execution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Upsonic/Tiger",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-middleware",
        "code-execution",
        "tool-integration"
      ],
      "id": 265
    },
    {
      "name": "MCP Gateway & Registry",
      "one_line_profile": "Centralized registry and gateway for managing Model Context Protocol (MCP) tools",
      "detailed_description": "An enterprise-ready gateway and registry designed to centralize AI development tools. It supports the Model Context Protocol (MCP), enabling secure authentication, dynamic tool discovery, and unified access for autonomous AI agents and coding assistants.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "tool_registry",
        "tool_discovery"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/agentic-community/mcp-gateway-registry",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mcp",
        "tool-registry",
        "gateway"
      ],
      "id": 266
    },
    {
      "name": "LangChain Visualizer",
      "one_line_profile": "Visualization tool for debugging and analyzing LangChain agent workflows",
      "detailed_description": "A tool designed to visualize and debug the execution flows of LangChain agents. It helps researchers and developers understand how agents are making decisions, calling tools, and processing data, which is critical for optimizing agentic workflows.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "visualization",
        "debugging"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/amosjyng/langchain-visualizer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "langchain",
        "debugging"
      ],
      "id": 267
    },
    {
      "name": "Airflow AI SDK",
      "one_line_profile": "SDK for integrating LLMs and AI Agents into Apache Airflow workflows",
      "detailed_description": "A software development kit that enables the orchestration of AI agents and Large Language Model operations within Apache Airflow pipelines, facilitating complex scientific workflow automation.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "agent_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/astronomer/airflow-ai-sdk",
      "help_website": [
        "https://github.com/astronomer/airflow-ai-sdk"
      ],
      "license": "Apache-2.0",
      "tags": [
        "airflow",
        "llm",
        "agents",
        "workflow"
      ],
      "id": 268
    },
    {
      "name": "mcp-server-mysql",
      "one_line_profile": "Model Context Protocol server for MySQL database access",
      "detailed_description": "An implementation of the Model Context Protocol (MCP) that exposes MySQL databases to AI agents, enabling read-only schema inspection and query execution for scientific data retrieval.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "database_interface",
        "data_retrieval"
      ],
      "application_level": "service",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/benborla/mcp-server-mysql",
      "help_website": [
        "https://github.com/benborla/mcp-server-mysql"
      ],
      "license": "MIT",
      "tags": [
        "mcp",
        "mysql",
        "database",
        "llm-tool"
      ],
      "id": 269
    },
    {
      "name": "arxiv-mcp-server",
      "one_line_profile": "MCP server for searching and analyzing arXiv papers",
      "detailed_description": "A Model Context Protocol server designed to allow AI agents to search, retrieve, and analyze scientific papers from the arXiv repository, supporting automated literature review workflows.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "literature_search",
        "data_retrieval"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/blazickjp/arxiv-mcp-server",
      "help_website": [
        "https://github.com/blazickjp/arxiv-mcp-server"
      ],
      "license": "Apache-2.0",
      "tags": [
        "arxiv",
        "mcp",
        "literature-review",
        "research-automation"
      ],
      "id": 270
    },
    {
      "name": "brightdata-mcp",
      "one_line_profile": "MCP server for public web data collection",
      "detailed_description": "A Model Context Protocol server that provides AI agents with capabilities for web scraping and public data collection, useful for gathering scientific datasets from web sources.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "data_collection",
        "web_scraping"
      ],
      "application_level": "service",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/brightdata/brightdata-mcp",
      "help_website": [
        "https://github.com/brightdata/brightdata-mcp"
      ],
      "license": "MIT",
      "tags": [
        "mcp",
        "web-scraping",
        "data-collection"
      ],
      "id": 271
    },
    {
      "name": "tool2schema",
      "one_line_profile": "Converter for Python functions to LLM tool schemas",
      "detailed_description": "A utility library that automatically converts Python function signatures and docstrings into JSON schemas compatible with LLM function calling, facilitating the integration of scientific analysis code into AI agent workflows.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "schema_generation",
        "function_calling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cadifyai/tool2schema",
      "help_website": [
        "https://github.com/cadifyai/tool2schema"
      ],
      "license": "Apache-2.0",
      "tags": [
        "json-schema",
        "function-calling",
        "llm-tools"
      ],
      "id": 272
    },
    {
      "name": "mcpr",
      "one_line_profile": "Model Context Protocol (MCP) implementation in Rust",
      "detailed_description": "A Rust implementation of the Model Context Protocol, providing the infrastructure to build high-performance, memory-safe MCP servers and clients for scientific computing environments.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "protocol_implementation",
        "infrastructure"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/conikeec/mcpr",
      "help_website": [
        "https://github.com/conikeec/mcpr"
      ],
      "license": "MIT",
      "tags": [
        "rust",
        "mcp",
        "protocol"
      ],
      "id": 273
    },
    {
      "name": "DeepMCPAgent",
      "one_line_profile": "LangChain agents powered by MCP tools",
      "detailed_description": "A framework for creating model-agnostic AI agents that utilize Model Context Protocol (MCP) tools over HTTP/SSE, enabling the integration of diverse scientific tools into LangChain/LangGraph workflows.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "agent_framework",
        "tool_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cryxnet/DeepMCPAgent",
      "help_website": [
        "https://github.com/cryxnet/DeepMCPAgent"
      ],
      "license": "Apache-2.0",
      "tags": [
        "langchain",
        "mcp",
        "agent",
        "workflow"
      ],
      "id": 274
    },
    {
      "name": "talksheet",
      "one_line_profile": "CLI tool for querying data files with LLMs",
      "detailed_description": "A command-line interface tool that uses GPT models to answer questions about data contained in spreadsheets (CSV/Excel), facilitating quick exploratory data analysis.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "data_analysis",
        "qa_system"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/danthelion/talksheet",
      "help_website": [
        "https://github.com/danthelion/talksheet"
      ],
      "license": null,
      "tags": [
        "data-analysis",
        "cli",
        "llm",
        "csv"
      ],
      "id": 275
    },
    {
      "name": "ChatMCP",
      "one_line_profile": "AI chat client for Model Context Protocol",
      "detailed_description": "A desktop client that implements the Model Context Protocol (MCP), allowing researchers to interact with and utilize various MCP-compliant scientific tools and agents through a chat interface.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "tool_interface",
        "client_application"
      ],
      "application_level": "platform",
      "primary_language": "Dart",
      "repo_url": "https://github.com/daodao97/chatmcp",
      "help_website": [
        "https://github.com/daodao97/chatmcp"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mcp-client",
        "chat-interface",
        "tool-usage"
      ],
      "id": 276
    },
    {
      "name": "mysql_mcp_server",
      "one_line_profile": "Secure MySQL MCP server for LLMs",
      "detailed_description": "A Model Context Protocol server that provides secure, read-only access to MySQL databases, enabling LLMs to inspect schemas and execute queries for scientific data analysis.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "database_interface",
        "data_access"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/designcomputer/mysql_mcp_server",
      "help_website": [
        "https://github.com/designcomputer/mysql_mcp_server"
      ],
      "license": "MIT",
      "tags": [
        "mysql",
        "mcp",
        "database",
        "security"
      ],
      "id": 277
    },
    {
      "name": "openapi-schema-ref-parser",
      "one_line_profile": "OpenAPI Schema parser for LLM integration",
      "detailed_description": "A utility to parse, resolve, and dereference OpenAPI Schema $ref pointers, specifically designed to prepare API definitions for consumption by Large Language Models in agentic workflows.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "schema_parsing",
        "api_integration"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/devflowinc/openapi-schema-ref-parser",
      "help_website": [
        "https://github.com/devflowinc/openapi-schema-ref-parser"
      ],
      "license": "MIT",
      "tags": [
        "openapi",
        "json-schema",
        "llm"
      ],
      "id": 278
    },
    {
      "name": "ai-fns",
      "one_line_profile": "Typesafe OpenAI Function calling utility",
      "detailed_description": "A lightweight library to facilitate type-safe OpenAI function calling, simplifying the development of AI agents that need to invoke external scientific tools or functions.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "function_calling",
        "tool_integration"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/dillionverma/ai-fns",
      "help_website": [
        "https://github.com/dillionverma/ai-fns"
      ],
      "license": "MIT",
      "tags": [
        "openai",
        "function-calling",
        "typescript"
      ],
      "id": 279
    },
    {
      "name": "DocArray",
      "one_line_profile": "Data structure for multimodal data",
      "detailed_description": "A library for representing, sending, storing, and searching multimodal data (text, image, audio, video, 3D mesh), serving as a fundamental data structure for AI applications and scientific data processing.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "data_representation",
        "multimodal_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/docarray/docarray",
      "help_website": [
        "https://docarray.jina.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "data-structure",
        "neural-search"
      ],
      "id": 280
    },
    {
      "name": "EmbedElite Semantic Kernel Plugin",
      "one_line_profile": "Semantic Kernel plugin for EmbedElite",
      "detailed_description": "A plugin for Microsoft Semantic Kernel that enables AI agents to interact with EmbedElite services, facilitating knowledge retrieval and integration into agent workflows.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "plugin_integration",
        "knowledge_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/embedelite/embedelite-sk-plugin",
      "help_website": [
        "https://github.com/embedelite/embedelite-sk-plugin"
      ],
      "license": null,
      "tags": [
        "semantic-kernel",
        "plugin",
        "agent"
      ],
      "id": 281
    },
    {
      "name": "Empower Functions",
      "one_line_profile": "Function calling models and tools for real-world use cases",
      "detailed_description": "A collection of models and tools optimized for GPT-4 level function calling, designed to enable AI agents to reliably interact with external tools and APIs in complex scenarios.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "function_calling",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/empower-ai/empower-functions",
      "help_website": [
        "https://github.com/empower-ai/empower-functions"
      ],
      "license": null,
      "tags": [
        "function-calling",
        "llm",
        "tool-use"
      ],
      "id": 282
    },
    {
      "name": "mcp-playwright",
      "one_line_profile": "Playwright MCP Server for browser automation",
      "detailed_description": "A Model Context Protocol server that wraps Playwright, allowing AI agents to automate web browsers for tasks such as data collection, testing, and interaction with web-based scientific tools.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "browser_automation",
        "data_collection"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/executeautomation/mcp-playwright",
      "help_website": [
        "https://github.com/executeautomation/mcp-playwright"
      ],
      "license": "MIT",
      "tags": [
        "playwright",
        "mcp",
        "browser-automation"
      ],
      "id": 283
    },
    {
      "name": "mcptools",
      "one_line_profile": "CLI for interacting with MCP servers",
      "detailed_description": "A command-line interface tool for testing, debugging, and interacting with Model Context Protocol (MCP) servers, supporting both stdio and HTTP transports to facilitate tool development.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "tool_development",
        "debugging"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/f/mcptools",
      "help_website": [
        "https://github.com/f/mcptools"
      ],
      "license": "MIT",
      "tags": [
        "mcp",
        "cli",
        "debugging"
      ],
      "id": 284
    },
    {
      "name": "Fiddler Auditor",
      "one_line_profile": "Tool to evaluate robustness and correctness of language models",
      "detailed_description": "A Python library designed to evaluate Large Language Models (LLMs) by assessing their robustness to prompt perturbations and correctness of outputs, essential for ensuring reliability in AI-driven scientific workflows.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "model_evaluation",
        "robustness_testing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fiddler-labs/fiddler-auditor",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm-evaluation",
        "robustness",
        "ai-safety"
      ],
      "id": 285
    },
    {
      "name": "Firesearch",
      "one_line_profile": "AI-powered deep research tool for complex query resolution",
      "detailed_description": "A deep research tool that leverages Firecrawl and LangGraph to break down complex queries, validate answers, and provide cited comprehensive results, functioning as an automated research assistant.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "research_automation",
        "information_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/firecrawl/firesearch",
      "help_website": [],
      "license": null,
      "tags": [
        "research-agent",
        "information-retrieval",
        "langgraph"
      ],
      "id": 286
    },
    {
      "name": "Toolify",
      "one_line_profile": "Function calling capabilities enabler for LLMs",
      "detailed_description": "A library designed to empower Large Language Models with function calling capabilities, facilitating the integration of external tools into AI agents.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "function_calling",
        "tool_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/funnycups/Toolify",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "llm",
        "function-calling",
        "agent-tools"
      ],
      "id": 287
    },
    {
      "name": "Microchain",
      "one_line_profile": "Minimalist framework for function calling-based LLM agents",
      "detailed_description": "A lightweight Python framework for building Large Language Model agents that rely on function calling, providing a simple abstraction for tool usage and agent orchestration.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "agent_framework",
        "function_calling"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/galatolofederico/microchain",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-agent",
        "function-calling",
        "minimalist"
      ],
      "id": 288
    },
    {
      "name": "Haiku RAG",
      "one_line_profile": "Agentic RAG framework powered by LanceDB and Pydantic AI",
      "detailed_description": "An opinionated agentic Retrieval-Augmented Generation (RAG) tool that integrates LanceDB, Pydantic AI, and Docling to build advanced research agents capable of handling complex document queries.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "rag_agent",
        "information_retrieval"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/ggozad/haiku.rag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "agent",
        "lancedb"
      ],
      "id": 289
    },
    {
      "name": "Gorilla CLI",
      "one_line_profile": "LLM-powered command line interface tool",
      "detailed_description": "A tool that leverages Large Language Models to generate and execute command-line commands, acting as an intelligent agent for system interaction and automation.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "command_generation",
        "tool_use"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gorilla-llm/gorilla-cli",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "cli",
        "llm",
        "automation"
      ],
      "id": 290
    },
    {
      "name": "MCP Adapt",
      "one_line_profile": "Adapter to unlock MCP servers tools in agentic frameworks",
      "detailed_description": "A Python library that acts as an adapter to make Model Context Protocol (MCP) servers and their tools accessible within various agentic frameworks, expanding the toolset available to AI agents.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "protocol_adaptation",
        "tool_integration"
      ],
      "application_level": "adapter",
      "primary_language": "Python",
      "repo_url": "https://github.com/grll/mcpadapt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "agent-adapter",
        "interoperability"
      ],
      "id": 291
    },
    {
      "name": "Chrome MCP Server",
      "one_line_profile": "Model Context Protocol server for browser automation",
      "detailed_description": "A Chrome extension-based Model Context Protocol (MCP) server that exposes browser functionality to AI assistants, enabling agents to perform browser automation, content analysis, and semantic search.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "browser_automation",
        "tool_server"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/hangwin/mcp-chrome",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "browser-automation",
        "chrome-extension"
      ],
      "id": 292
    },
    {
      "name": "Excel MCP Server",
      "one_line_profile": "Model Context Protocol server for Excel file manipulation",
      "detailed_description": "A Model Context Protocol (MCP) server designed to allow AI agents to interact with and manipulate Excel files, facilitating data processing and analysis workflows.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "data_manipulation",
        "tool_server"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/haris-musa/excel-mcp-server",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "excel",
        "data-processing"
      ],
      "id": 293
    },
    {
      "name": "AgentSilex",
      "one_line_profile": "Transparent and minimal agent framework",
      "detailed_description": "A minimal and hackable Python framework for building AI agents, focusing on transparency and control without complex abstractions, suitable for research and custom agent development.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "agent_framework",
        "orchestration"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/howl-anderson/agentsilex",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent-framework",
        "minimalist",
        "python"
      ],
      "id": 294
    },
    {
      "name": "LangChainGo MCP Adapter",
      "one_line_profile": "Adapter bridging LangChain Go tools with MCP servers",
      "detailed_description": "A Go adapter that enables the integration of LangChain Go tools with Model Context Protocol (MCP) servers, facilitating interoperability in the AI agent ecosystem.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "protocol_adaptation",
        "tool_integration"
      ],
      "application_level": "adapter",
      "primary_language": "Go",
      "repo_url": "https://github.com/i2y/langchaingo-mcp-adapter",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "langchain",
        "go",
        "adapter"
      ],
      "id": 295
    },
    {
      "name": "Ruby Nano Bots",
      "one_line_profile": "Ruby implementation of small, AI-powered bots with tool calling",
      "detailed_description": "A Ruby library for creating small, shareable AI-powered bots that support multiple LLM providers and tool calling (functions), enabling agentic workflows in Ruby environments.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "agent_framework",
        "function_calling"
      ],
      "application_level": "library",
      "primary_language": "Lua",
      "repo_url": "https://github.com/icebaker/ruby-nano-bots",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ruby",
        "agent",
        "bot",
        "function-calling"
      ],
      "id": 296
    },
    {
      "name": "Swama",
      "one_line_profile": "CLI tool for interacting with Swagger/OpenAPI definitions",
      "detailed_description": "A command-line interface tool for interacting with Swagger and OpenAPI definitions, useful for managing and testing API schemas used in AI tool calling and registry contexts.",
      "domains": [
        "AI5-02"
      ],
      "subtask_category": [
        "api_interaction",
        "schema_handling"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/idsulik/swama",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "openapi",
        "swagger",
        "cli",
        "schema"
      ],
      "id": 297
    },
    {
      "name": "Instructor Evals",
      "one_line_profile": "Evaluation tool for extraction and reasoning capabilities",
      "detailed_description": "A Python library for evaluating the quality and capabilities of extractions and reasoning performed by instructor clients, supporting the validation of structured outputs from LLMs.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "extraction_evaluation",
        "model_validation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/instructor-ai/evals",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation",
        "structured-output",
        "llm"
      ],
      "id": 298
    },
    {
      "name": "openapi2jsonschema",
      "one_line_profile": "Converter from OpenAPI definitions to JSON schemas",
      "detailed_description": "A tool to convert OpenAPI definitions into JSON schemas, facilitating the use of API specifications in contexts requiring JSON schema validation, such as LLM function calling definitions.",
      "domains": [
        "AI5-02"
      ],
      "subtask_category": [
        "schema_conversion",
        "interoperability"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/instrumenta/openapi2jsonschema",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "openapi",
        "json-schema",
        "conversion"
      ],
      "id": 299
    },
    {
      "name": "Function Calling Eval",
      "one_line_profile": "Framework for evaluating function calls made by LLMs",
      "detailed_description": "A framework designed to evaluate the accuracy and correctness of function calls generated by Large Language Models, essential for benchmarking and improving agentic tool use.",
      "domains": [
        "AI5-02"
      ],
      "subtask_category": [
        "function_calling_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/interstellarninja/function-calling-eval",
      "help_website": [],
      "license": null,
      "tags": [
        "evaluation",
        "function-calling",
        "llm"
      ],
      "id": 300
    },
    {
      "name": "Native Tool Call Adapter",
      "one_line_profile": "Adapter for translating tool calls into native API formats",
      "detailed_description": "A Python library that helps agents work more efficiently by translating tool calls from specific formats (like cline/Roo-Code) into native tool calls required by APIs, enhancing interoperability.",
      "domains": [
        "AI5-02"
      ],
      "subtask_category": [
        "tool_adaptation",
        "interoperability"
      ],
      "application_level": "adapter",
      "primary_language": "Python",
      "repo_url": "https://github.com/irreg/native_tool_call_adapter",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tool-calling",
        "adapter",
        "api"
      ],
      "id": 301
    },
    {
      "name": "Acte",
      "one_line_profile": "Framework to build GUI-like Agent Tools",
      "detailed_description": "A Python framework designed to build GUI-like Agent Tools, providing an enhancement to standard LLM function calling by structuring tool interactions more effectively.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "tool_ui_framework",
        "function_calling_enhancement"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/j66n/acte",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-tools",
        "gui",
        "framework"
      ],
      "id": 302
    },
    {
      "name": "Magentic",
      "one_line_profile": "Seamless integration of LLMs as Python functions",
      "detailed_description": "A Python library that allows developers to seamlessly integrate Large Language Models as Python functions, simplifying the process of function calling and structured output generation.",
      "domains": [
        "AI5-02"
      ],
      "subtask_category": [
        "function_calling",
        "structured_output"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jackmpcollins/magentic",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "python",
        "function-calling",
        "decorators"
      ],
      "id": 303
    },
    {
      "name": "LLM Auto Forge",
      "one_line_profile": "Tool for dynamic creation and retrieval of agent tools",
      "detailed_description": "A LangChain-based tool that enables agents to dynamically create, use, store, and retrieve tools to solve problems, enhancing the adaptability of AI agents.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "tool_generation",
        "tool_management"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/jbpayton/llm-auto-forge",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "langchain",
        "agent-tools",
        "dynamic-tools"
      ],
      "id": 304
    },
    {
      "name": "instructor-clj",
      "one_line_profile": "Clojure library for structured output extraction from LLMs",
      "detailed_description": "A Clojure implementation of the Instructor pattern, enabling reliable extraction of structured data (JSON/Schema) from Large Language Models. This is essential for converting unstructured scientific text into structured datasets for analysis.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "structured_output",
        "schema_adaptation"
      ],
      "application_level": "library",
      "primary_language": "Clojure",
      "repo_url": "https://github.com/kapilreddy/instructor-clj",
      "help_website": [],
      "license": null,
      "tags": [
        "clojure",
        "llm",
        "structured-data",
        "json-schema"
      ],
      "id": 305
    },
    {
      "name": "ChatGPT CLI",
      "one_line_profile": "CLI tool for LLM interaction with Model Context Protocol (MCP) support",
      "detailed_description": "A command-line interface for interacting with various LLM providers (OpenAPI, Azure, etc.) that supports the Model Context Protocol (MCP). This allows researchers to inject live data and context into LLM sessions, facilitating agentic workflows and tool usage.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "tool_calling",
        "mcp_client"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/kardolus/chatgpt-cli",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cli",
        "mcp",
        "llm-client",
        "context-injection"
      ],
      "id": 306
    },
    {
      "name": "SemanticKernel.Assistants",
      "one_line_profile": "Assistant extensions for Microsoft Semantic Kernel",
      "detailed_description": "A library extending Microsoft Semantic Kernel to support hierarchical assistants and multi-assistant conversations. It enables the orchestration of complex agentic workflows where different agents (tools) collaborate on tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/kbeaugrand/SemanticKernel.Assistants",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-kernel",
        "agents",
        "orchestration",
        "dotnet"
      ],
      "id": 307
    },
    {
      "name": "datamodel-code-generator",
      "one_line_profile": "Generator for Pydantic models from JSON Schema and OpenAPI",
      "detailed_description": "A utility that generates Pydantic models and dataclasses from JSON Schema, OpenAPI, and YAML data sources. In the context of AI Agents, this is a critical infrastructure tool for defining tool interfaces and validating structured outputs from LLMs.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "schema_adaptation",
        "code_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/koxudaxi/datamodel-code-generator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pydantic",
        "json-schema",
        "openapi",
        "data-modeling"
      ],
      "id": 308
    },
    {
      "name": "Deepagents",
      "one_line_profile": "Agent harness for complex tasks built on LangChain/LangGraph",
      "detailed_description": "An agent framework equipped with planning tools, filesystem backends, and sub-agent spawning capabilities. It is designed to handle complex, multi-step agentic tasks, suitable for orchestrating scientific research workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "planning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/langchain-ai/deepagents",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agents",
        "langgraph",
        "planning",
        "orchestration"
      ],
      "id": 309
    },
    {
      "name": "langchain-mcp-adapters",
      "one_line_profile": "LangChain adapters for Model Context Protocol (MCP)",
      "detailed_description": "Provides adapters to integrate Model Context Protocol (MCP) tools into LangChain applications. This enables LangChain-based scientific agents to communicate with external data sources and tools using the standardized MCP interface.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "tool_calling",
        "protocol_adaptation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/langchain-ai/langchain-mcp-adapters",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "langchain",
        "adapter",
        "interoperability"
      ],
      "id": 310
    },
    {
      "name": "langchainjs-mcp-adapters",
      "one_line_profile": "TypeScript adapters for Model Context Protocol (MCP) in LangChain.js",
      "detailed_description": "The TypeScript/JavaScript equivalent of the MCP adapters for LangChain, enabling web-based or Node.js-based scientific agents to utilize MCP-compliant tools and data sources.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "tool_calling",
        "protocol_adaptation"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/langchain-ai/langchainjs-mcp-adapters",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "langchain-js",
        "typescript",
        "adapter"
      ],
      "id": 311
    },
    {
      "name": "mcp-agent",
      "one_line_profile": "Framework for building agents using Model Context Protocol",
      "detailed_description": "A Python library designed to build effective agents specifically leveraging the Model Context Protocol (MCP) and simple workflow patterns. It streamlines the creation of agents that can discover and utilize standardized tools.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "agent_orchestration",
        "mcp_implementation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lastmile-ai/mcp-agent",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mcp",
        "agents",
        "workflow",
        "protocol"
      ],
      "id": 312
    },
    {
      "name": "Code-Interpreter-Api",
      "one_line_profile": "Open source implementation of ChatGPT Code Interpreter",
      "detailed_description": "A Python library that provides a sandbox for LLMs to execute Python code, generate charts, and analyze data. This mimics the OpenAI Code Interpreter functionality, allowing local or custom agents to perform rigorous data analysis and visualization tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "code_execution",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/leezhuuuuu/Code-Interpreter-Api",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "code-interpreter",
        "sandbox",
        "data-analysis",
        "visualization"
      ],
      "id": 313
    },
    {
      "name": "ollama-instructor",
      "one_line_profile": "Structured output validation for Ollama models",
      "detailed_description": "A Python library for the instruction and reliable validation of structured outputs (JSON) from LLMs running via Ollama. It uses Pydantic for schema definition, enabling deterministic data extraction workflows with local models.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "structured_output",
        "schema_validation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lennartpollvogt/ollama-instructor",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ollama",
        "pydantic",
        "structured-output",
        "local-llm"
      ],
      "id": 314
    },
    {
      "name": "tool-ahead-of-time",
      "one_line_profile": "Shim to add tool calling capabilities to LLMs",
      "detailed_description": "A Python package that adds tool calling capabilities to LLM classes (like LangChain's ChatOpenAI) that might not natively support them or are waiting for framework updates. It facilitates the immediate use of new models in agentic tool-use workflows.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "tool_calling",
        "compatibility_layer"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/leockl/tool-ahead-of-time",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tool-calling",
        "langchain",
        "llm-adapter"
      ],
      "id": 315
    },
    {
      "name": "toolhub",
      "one_line_profile": "Collection of tools for LLM function calling",
      "detailed_description": "A library providing a collection of pre-built tools designed for LLM function calling. It serves as a registry of ready-to-use functions that agents can invoke to perform specific tasks.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "tool_registry",
        "function_calling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/levrofin/toolhub",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tools",
        "function-calling",
        "registry"
      ],
      "id": 316
    },
    {
      "name": "mcp-go",
      "one_line_profile": "Go implementation of the Model Context Protocol (MCP)",
      "detailed_description": "A Go library implementing the Model Context Protocol (MCP), enabling the creation of high-performance MCP servers and clients. This is core infrastructure for integrating external tools and data sources into the AI research agent ecosystem.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "mcp_implementation",
        "protocol_infrastructure"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/mark3labs/mcp-go",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "go",
        "mcp",
        "protocol",
        "interoperability"
      ],
      "id": 317
    },
    {
      "name": "mcphost",
      "one_line_profile": "CLI host for Model Context Protocol (MCP) tools",
      "detailed_description": "A CLI application that acts as a host for Large Language Models to interact with external tools via the Model Context Protocol. It provides a runtime environment for testing and deploying MCP-compliant tools.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "mcp_hosting",
        "tool_execution"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/mark3labs/mcphost",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cli",
        "mcp",
        "host",
        "runtime"
      ],
      "id": 318
    },
    {
      "name": "Retrieval-Framework",
      "one_line_profile": "Tool for converting scientific PDFs into plain text for RAG and agents",
      "detailed_description": "A specialized tool designed to process scientific PDFs and convert them into plain text, facilitating the creation of RAG systems or agents specifically for academic knowledge and literature review.",
      "domains": [
        "AI5",
        "AI5-02"
      ],
      "subtask_category": [
        "data_processing",
        "literature_review"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/tensorsense/Retrieval-Framework",
      "help_website": [],
      "license": null,
      "tags": [
        "pdf-parsing",
        "scientific-literature",
        "rag",
        "academic-knowledge"
      ],
      "id": 319
    },
    {
      "name": "Maestro",
      "one_line_profile": "Declarative multi-agent workflow orchestration framework for quantum computing research",
      "detailed_description": "Maestro is an agent orchestration framework designed to manage complex, multi-agent workflows in a declarative manner. It is specifically positioned within the AI4Quantum ecosystem to facilitate the coordination of AI agents for quantum computing tasks, enabling the synthesis and execution of research workflows.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "agent_coordination",
        "quantum_workflow"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/AI4quantum/maestro",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantum-computing",
        "multi-agent",
        "workflow-orchestration",
        "agentic-workflow"
      ],
      "id": 320
    },
    {
      "name": "FlowAgent",
      "one_line_profile": "Multi-agent framework for automating bioinformatics workflows",
      "detailed_description": "FlowAgent is an advanced multi-agent framework specifically designed to automate complex bioinformatics workflows. It leverages agentic capabilities to manage and execute tasks within biological data analysis pipelines.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "workflow_automation",
        "bioinformatics_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/EnteloBio/flowagent",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bioinformatics",
        "multi-agent",
        "workflow-automation",
        "pipeline"
      ],
      "id": 321
    },
    {
      "name": "HaVen",
      "one_line_profile": "Hallucination-mitigated LLM for Verilog code generation",
      "detailed_description": "A specialized Large Language Model framework designed to generate Verilog code for hardware description, incorporating hallucination mitigation techniques to align with HDL engineering standards.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "code_generation",
        "hardware_design"
      ],
      "application_level": "solver",
      "primary_language": "Verilog",
      "repo_url": "https://github.com/Intelligent-Computing-Research-Group/HaVen",
      "help_website": [],
      "license": null,
      "tags": [
        "verilog",
        "llm",
        "eda",
        "hardware-design"
      ],
      "id": 322
    },
    {
      "name": "AutoBA",
      "one_line_profile": "AI Agent for Fully Automated Multi-omic Analyses",
      "detailed_description": "An autonomous AI agent framework designed to execute fully automated multi-omic analysis pipelines, streamlining bioinformatics workflows and data interpretation.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "multiomics_analysis",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/JoshuaChou2018/AutoBA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "multi-omics",
        "ai-agent",
        "automation"
      ],
      "id": 323
    },
    {
      "name": "BRAD",
      "one_line_profile": "LLM powered agent for bioinformatics",
      "detailed_description": "A Large Language Model powered agent specifically tailored for bioinformatics tasks, capable of interacting with databases, running tools, and assisting in literature mining.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "bioinformatics_assistant",
        "literature_mining"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Jpickard1/BRAD",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "llm-agent",
        "rag"
      ],
      "id": 324
    },
    {
      "name": "Gmsh.jl",
      "one_line_profile": "Julia wrapper for Gmsh mesh generator",
      "detailed_description": "A Julia interface to the Gmsh three-dimensional finite element mesh generator, enabling parametric model construction and automatic mesh generation within scientific FEM pipelines.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "mesh_generation",
        "finite_element_method"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaFEM/Gmsh.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fem",
        "mesh-generation",
        "julia",
        "scientific-computing"
      ],
      "id": 325
    },
    {
      "name": "Triangulate.jl",
      "one_line_profile": "Julia Wrapper for the Triangle Mesh Generator",
      "detailed_description": "A Julia wrapper for the Triangle library, providing robust 2D mesh generation and Delaunay triangulation capabilities for scientific computing and simulation.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "mesh_generation",
        "triangulation"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaGeometry/Triangulate.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "delaunay",
        "mesh",
        "julia",
        "geometry"
      ],
      "id": 326
    },
    {
      "name": "wrap",
      "one_line_profile": "MPI wrapper generator for PMPI tool libraries",
      "detailed_description": "A code generation tool from LLNL that creates MPI wrappers, facilitating the development of PMPI-based profiling, tracing, and debugging tools for High Performance Computing (HPC) applications.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "hpc_profiling",
        "code_generation"
      ],
      "application_level": "generator",
      "primary_language": "Python",
      "repo_url": "https://github.com/LLNL/wrap",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "mpi",
        "hpc",
        "profiling",
        "code-generation"
      ],
      "id": 327
    },
    {
      "name": "GenoMAS",
      "one_line_profile": "Multi-agent framework for scientific analysis workflows",
      "detailed_description": "A minimalist multi-agent framework designed for the robust automation of scientific analysis workflows, with specific applications in gene expression analysis and bioinformatics.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "workflow_automation",
        "gene_expression_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Liu-Hy/GenoMAS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multi-agent",
        "bioinformatics",
        "workflow",
        "automation"
      ],
      "id": 328
    },
    {
      "name": "SpikeAgent",
      "one_line_profile": "Multimodal LLM-based AI agent for spike sorting",
      "detailed_description": "An AI agent leveraging multimodal Large Language Models to automate and standardize the spike sorting pipeline, a critical task in neuroscience for analyzing neuronal activity.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "spike_sorting",
        "neuroscience_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LiuLab-Bioelectronics-Harvard/SpikeAgent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "neuroscience",
        "spike-sorting",
        "llm-agent",
        "automation"
      ],
      "id": 329
    },
    {
      "name": "artificial-data-generator",
      "one_line_profile": "Pipelines for generating anonymous artificial NHS health data",
      "detailed_description": "A toolset from NHS Digital for generating large volumes of synthetic, anonymous data that statistically mimics real National Health Service (NHS) data, enabling research and system testing without compromising patient privacy.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "synthetic_data_generation",
        "health_informatics"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/NHSDigital/artificial-data-generator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "synthetic-data",
        "healthcare",
        "nhs",
        "data-generation"
      ],
      "id": 330
    },
    {
      "name": "ToolOrchestra",
      "one_line_profile": "RL training framework for orchestrating tools and agentic workflows",
      "detailed_description": "An end-to-end Reinforcement Learning framework from NVIDIA Research designed to train agents for orchestrating complex tool usage and workflows, applicable to scientific agent development.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "agent_orchestration",
        "reinforcement_learning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVlabs/ToolOrchestra",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reinforcement-learning",
        "agent-orchestration",
        "tool-use",
        "nvidia-research"
      ],
      "id": 331
    },
    {
      "name": "Project-Eucalyptus",
      "one_line_profile": "Pipelines for satellite-based methane detection",
      "detailed_description": "Open-source pipelines for detecting methane plumes using satellite imagery (Sentinel-2, Landsat, EMIT), including segmentation models, synthetic plume generators, and benchmarking tools for earth science research.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "remote_sensing",
        "methane_detection"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Orbio-Earth/Project-Eucalyptus",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "remote-sensing",
        "methane",
        "satellite-imagery",
        "earth-science"
      ],
      "id": 332
    },
    {
      "name": "mikropml-snakemake-workflow",
      "one_line_profile": "Snakemake template for mikropml machine learning pipelines",
      "detailed_description": "A Snakemake workflow template designed for building reproducible and scalable machine learning pipelines using the mikropml package, specifically tailored for microbiology and predictive modeling tasks.",
      "domains": [
        "AI5-03"
      ],
      "subtask_category": [
        "workflow_management",
        "machine_learning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/SchlossLab/mikropml-snakemake-workflow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "snakemake",
        "machine-learning",
        "microbiology",
        "reproducibility"
      ],
      "id": 333
    },
    {
      "name": "conv3d-video-toolkit",
      "one_line_profile": "3D ConvNet pipeline for video-based behavior classification",
      "detailed_description": "A modular toolkit for video-based behavior classification using 3D Convolutional Networks, providing pipelines for data preparation, training, and inference, suitable for scientific behavioral analysis.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "behavior_analysis",
        "video_classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ShanJiangEmugen/conv3d-video-toolkit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "computer-vision",
        "behavior-analysis",
        "3d-cnn",
        "video-processing"
      ],
      "id": 334
    },
    {
      "name": "XFEM_Fracture2D",
      "one_line_profile": "MATLAB program for 2D fracture mechanics simulation using Extended Finite Element Method",
      "detailed_description": "A Matlab solver for fracture problems involving arbitrary multiple crack propagations in a 2D linear-elastic solid. It uses XFEM to discretise the solid continuum and implements crack growth criteria like maximum tension and minimum total energy.",
      "domains": [
        "AI5",
        "Mechanics"
      ],
      "subtask_category": [
        "simulation",
        "fracture_mechanics",
        "finite_element_analysis"
      ],
      "application_level": "solver",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/ShelvanLee/XFEM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "xfem",
        "fracture-mechanics",
        "matlab",
        "simulation"
      ],
      "id": 335
    },
    {
      "name": "ilus",
      "one_line_profile": "Pipeline generator for WGS/WES variant calling using GATK and Sentieon",
      "detailed_description": "A lightweight variant calling pipeline generator designed for whole-genome sequencing (WGS) and whole exome sequencing (WES) data analysis. It automates the generation of analysis scripts based on GATK and Sentieon best practices.",
      "domains": [
        "AI5",
        "AI5-03",
        "Genomics"
      ],
      "subtask_category": [
        "variant_calling",
        "pipeline_generation",
        "workflow_synthesis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ShujiaHuang/ilus",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "gatk",
        "sentieon",
        "wgs",
        "wes",
        "pipeline-generator"
      ],
      "id": 336
    },
    {
      "name": "metapipe",
      "one_line_profile": "Pipeline generator and runtime system for genomics workflows",
      "detailed_description": "A tool developed by TorkamaniLab for generating and executing genomics analysis pipelines. It facilitates the creation of job scripts and manages the runtime execution of bioinformatics tasks.",
      "domains": [
        "AI5",
        "AI5-03",
        "Genomics"
      ],
      "subtask_category": [
        "workflow_management",
        "pipeline_generation",
        "genomics"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/TorkamaniLab/metapipe",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pipeline",
        "genomics",
        "workflow-manager"
      ],
      "id": 337
    },
    {
      "name": "ASReview Makita",
      "one_line_profile": "Workflow generator for simulation studies in systematic reviews",
      "detailed_description": "Makita (MAKe IT Automatic) is a workflow generator for the ASReview LAB ecosystem. It automates the creation of scripts and folder structures required for running large-scale simulation studies on scientific literature, aiding in systematic reviews and meta-analyses.",
      "domains": [
        "AI5",
        "AI5-03",
        "Scientometrics"
      ],
      "subtask_category": [
        "systematic_review",
        "simulation_workflow",
        "literature_screening"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/asreview/asreview-makita",
      "help_website": [
        "https://asreview.nl/"
      ],
      "license": "MIT",
      "tags": [
        "systematic-review",
        "simulation",
        "workflow-generator",
        "asreview"
      ],
      "id": 338
    },
    {
      "name": "BIA (BioInformatics Agent)",
      "one_line_profile": "LLM-based agent for automating bioinformatics workflows and data analysis",
      "detailed_description": "BIA (BioInformatics Agent) leverages Large Language Models to reshape bioinformatics workflows. It acts as an intelligent assistant to automate data processing, analysis tasks, and tool invocation within the bioinformatics domain.",
      "domains": [
        "AI5",
        "Bioinformatics"
      ],
      "subtask_category": [
        "bioinformatics_workflow",
        "data_analysis",
        "agent_orchestration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/biagent-dev/bia",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bioinformatics",
        "llm-agent",
        "workflow-automation"
      ],
      "id": 339
    },
    {
      "name": "BioChatter",
      "one_line_profile": "Backend library for conversational AI and knowledge graph interaction in biomedicine",
      "detailed_description": "BioChatter is a backend library designed to facilitate conversational AI applications in biomedicine. It orchestrates interactions between Large Language Models (LLMs) and biomedical knowledge graphs/databases, enabling efficient querying and data retrieval for scientific research.",
      "domains": [
        "AI5",
        "Biomedicine"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "biomedical_analysis",
        "agent_backend"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/biocypher/biochatter",
      "help_website": [
        "https://biochatter.org/"
      ],
      "license": "MIT",
      "tags": [
        "biomedicine",
        "conversational-ai",
        "knowledge-graph",
        "llm"
      ],
      "id": 340
    },
    {
      "name": "BioCypher",
      "one_line_profile": "A unifying framework for biomedical research knowledge graphs",
      "detailed_description": "BioCypher is a framework designed to democratize the creation and use of Knowledge Graphs (KGs) in biomedical research. It provides a modular system to harmonize diverse biomedical datasets, facilitating the construction of knowledge graphs that can be used for AI-driven analysis and reasoning.",
      "domains": [
        "AI5",
        "AI4"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "data_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/biocypher/biocypher",
      "help_website": [
        "https://biocypher.org"
      ],
      "license": "MIT",
      "tags": [
        "biomedical",
        "knowledge-graph",
        "ontology",
        "data-harmonization"
      ],
      "id": 341
    },
    {
      "name": "Geniac",
      "one_line_profile": "Automatic Configuration Generator and Installer for Nextflow pipelines",
      "detailed_description": "Geniac is a set of utilities designed to implement best practices for the development and deployment of bioinformatics analysis pipelines using Nextflow. It automates the generation of configuration files and installation processes, streamlining the setup of reproducible scientific workflows.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "workflow_configuration",
        "pipeline_deployment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bioinfo-pf-curie/geniac",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "nextflow",
        "bioinformatics",
        "pipeline-management",
        "workflow-automation"
      ],
      "id": 342
    },
    {
      "name": "cwltool",
      "one_line_profile": "Common Workflow Language reference implementation",
      "detailed_description": "cwltool is the reference implementation of the Common Workflow Language (CWL) standard. It serves as a portable and reproducible executor for scientific workflows defined in CWL, allowing researchers to run complex data analysis pipelines across various computing environments.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "workflow_execution",
        "pipeline_orchestration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/common-workflow-language/cwltool",
      "help_website": [
        "https://cwl.discourse.group/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "cwl",
        "workflow-engine",
        "reproducibility",
        "bioinformatics"
      ],
      "id": 343
    },
    {
      "name": "MeshPy",
      "one_line_profile": "Python interface for 2D/3D simplicial mesh generation (Triangle, TetGen, Gmsh)",
      "detailed_description": "MeshPy provides a Pythonic wrapper around high-quality mesh generation software including Triangle (2D), TetGen (3D), and Gmsh. It is essential for scientific computing tasks such as Finite Element Analysis (FEA) and Computational Fluid Dynamics (CFD), allowing for the programmatic generation and manipulation of complex geometric discretizations.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "mesh_generation",
        "discretization",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/inducer/meshpy",
      "help_website": [
        "https://documen.tician.de/meshpy/"
      ],
      "license": "MIT",
      "tags": [
        "mesh-generation",
        "fem",
        "cfd",
        "geometry",
        "python-wrapper"
      ],
      "id": 344
    },
    {
      "name": "Struo",
      "one_line_profile": "A pipeline for building custom metagenomic profiling databases (GTDB/NCBI)",
      "detailed_description": "Struo is a tool designed to construct custom databases for metagenomic profilers like Kraken2, Bracken, and Humann3. It automates the retrieval and processing of genome data from NCBI and GTDB, facilitating the creation of reference databases for microbiome analysis.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "database_generation",
        "metagenomics",
        "bioinformatics_pipeline"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/leylabmpi/Struo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "metagenomics",
        "database-construction",
        "microbiome",
        "bioinformatics"
      ],
      "id": 345
    },
    {
      "name": "ProtGraph",
      "one_line_profile": "A graph generator for protein structures from PDB files",
      "detailed_description": "ProtGraph is a bioinformatics tool that converts protein structures (PDB format) into graph representations. These graphs capture the structural and spatial relationships of amino acids, enabling the application of Graph Neural Networks (GNNs) for protein property prediction and modeling.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "structure_modeling",
        "graph_generation",
        "protein_structure_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mpc-bioinformatics/ProtGraph",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "protein-structure",
        "graph-neural-networks",
        "bioinformatics",
        "pdb"
      ],
      "id": 346
    },
    {
      "name": "AIA-Academic-Illustrator",
      "one_line_profile": "AI agent for generating academic diagrams from paper abstracts",
      "detailed_description": "An AI agent that automates the creation of standard academic diagrams (e.g., for CVPR/NeurIPS) by implementing a 'Logic (Architect) -> Vision (Renderer)' workflow to transform paper abstracts into high-fidelity scientific illustrations.",
      "domains": [
        "AI5",
        "Scientific Publishing"
      ],
      "subtask_category": [
        "scientific_visualization",
        "illustration_generation"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/qwwzdyj/AIA-Academic-Illustrator-",
      "help_website": [],
      "license": null,
      "tags": [
        "ai-agent",
        "scientific-visualization",
        "academic-paper"
      ],
      "id": 347
    },
    {
      "name": "SatGen",
      "one_line_profile": "Semi-analytical satellite galaxy and dark matter halo generator",
      "detailed_description": "A semi-analytical generator for simulating satellite galaxies and dark matter halos, used in astrophysical modeling and cosmological simulations to study galaxy formation and evolution.",
      "domains": [
        "Astrophysics",
        "Cosmology"
      ],
      "subtask_category": [
        "simulation",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shergreen/SatGen",
      "help_website": [],
      "license": null,
      "tags": [
        "astrophysics",
        "galaxy-formation",
        "simulation",
        "dark-matter"
      ],
      "id": 348
    },
    {
      "name": "SimStudio",
      "one_line_profile": "Open-source platform to build and deploy AI agent workflows visually",
      "detailed_description": "SimStudio is a drag-and-drop platform for building, testing, and deploying AI agent workflows. It allows users to orchestrate LLMs and tools into complex agents without extensive coding, serving as a workflow synthesis and execution environment for AI agents.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "workflow_synthesis",
        "agent_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/simstudioai/sim",
      "help_website": [
        "https://docs.simstudio.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ai-agent",
        "workflow-automation",
        "visual-programming",
        "llm-orchestration"
      ],
      "id": 349
    },
    {
      "name": "Snakemake",
      "one_line_profile": "Scalable bioinformatics workflow management system",
      "detailed_description": "Snakemake is a workflow management system that aims to reduce the complexity of creating workflows by providing a fast and comfortable execution environment, together with a clean and modern specification language in Python style. It is widely used for reproducible and scalable data analyses in science.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "workflow_management",
        "pipeline_execution"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake/snakemake",
      "help_website": [
        "https://snakemake.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "workflow-engine",
        "bioinformatics",
        "reproducibility",
        "pipeline"
      ],
      "id": 350
    },
    {
      "name": "Agent SOP",
      "one_line_profile": "Natural language workflow framework for AI agents",
      "detailed_description": "Agent SOP (Standard Operating Procedure) provides a framework for defining natural language workflows that enable AI agents to perform complex, multi-step tasks with consistency and reliability. It structures agent reasoning and execution patterns.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "agent_orchestration",
        "workflow_definition"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/strands-agents/agent-sop",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-agent",
        "sop",
        "workflow",
        "prompt-engineering"
      ],
      "id": 351
    },
    {
      "name": "HOHQMesh.jl",
      "one_line_profile": "Julia wrapper for the HOHQMesh high-order mesh generator",
      "detailed_description": "HOHQMesh.jl provides a Julia interface to the HOHQMesh mesh generator, enabling the creation of curved quadrilateral and hexahedral meshes for high-order numerical simulations in physics and engineering.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "mesh_generation",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/trixi-framework/HOHQMesh.jl",
      "help_website": [
        "https://trixi-framework.github.io/HOHQMesh.jl/stable/"
      ],
      "license": "MIT",
      "tags": [
        "mesh-generation",
        "numerical-simulation",
        "julia",
        "cfd"
      ],
      "id": 352
    },
    {
      "name": "Waldiez",
      "one_line_profile": "Visual orchestration tool for multi-agent collaboration",
      "detailed_description": "Waldiez is a flow-based editor and orchestration tool for AutoGen (AG2) agents. It allows users to visually design, configure, and execute multi-agent workflows, facilitating the creation of complex agentic systems for various tasks.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "agent_orchestration",
        "workflow_design"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/waldiez/waldiez",
      "help_website": [
        "https://waldiez.github.io/waldiez/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "autogen",
        "multi-agent",
        "visual-editor",
        "orchestration"
      ],
      "id": 353
    },
    {
      "name": "GraphRAG Agent",
      "one_line_profile": "Integrated framework for Knowledge Graph construction and RAG with custom evaluation",
      "detailed_description": "A comprehensive RAG solution that integrates GraphRAG, LightRAG, and Neo4j-llm-graph-builder for knowledge graph construction and search. It includes DeepSearch integration for reasoning and a custom evaluation framework specifically designed for GraphRAG systems.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "knowledge_graph_construction",
        "workflow_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/1517005260/graph-rag-agent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "graph-rag",
        "evaluation",
        "neo4j"
      ],
      "id": 354
    },
    {
      "name": "Tuui",
      "one_line_profile": "Desktop MCP client for cross-vendor LLM API orchestration",
      "detailed_description": "A desktop client implementing the Model Context Protocol (MCP) designed to facilitate tool unitary utility integration. It accelerates AI adoption by enabling cross-vendor LLM API orchestration, serving as a platform for managing and utilizing AI agents and tools.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "agent_orchestration",
        "api_management"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/AI-QL/tuui",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mcp",
        "llm-orchestration",
        "agent-client"
      ],
      "id": 355
    },
    {
      "name": "Aigne Framework",
      "one_line_profile": "Typescript-first AI Agent framework for composable LLM applications",
      "detailed_description": "A functional and composable AI Agent framework designed for building real-world LLM applications. It prioritizes TypeScript support and provides structures for creating and managing intelligent agents.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "agent_framework",
        "workflow_orchestration"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/AIGNE-io/aigne-framework",
      "help_website": [],
      "license": null,
      "tags": [
        "agent-framework",
        "typescript",
        "llm-apps"
      ],
      "id": 356
    },
    {
      "name": "VideoGen-Eval",
      "one_line_profile": "Agent-based system for evaluating video generation models",
      "detailed_description": "An agent-based system designed to evaluate video generation models. It provides a framework for assessing the quality and performance of AI-generated videos, serving as a specialized evaluation tool in the generative AI domain.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "video_generation_assessment"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/AILab-CVC/VideoGen-Eval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation",
        "video-generation",
        "agent-based"
      ],
      "id": 357
    },
    {
      "name": "MCP-Bench",
      "one_line_profile": "Benchmark for tool-using LLM agents via MCP servers",
      "detailed_description": "A benchmarking tool designed to evaluate tool-using LLM agents on complex real-world tasks. It utilizes MCP (Model Context Protocol) servers to standardize the interaction and assessment of agent performance.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_benchmarking",
        "performance_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Accenture/mcp-bench",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "mcp",
        "agent-evaluation"
      ],
      "id": 358
    },
    {
      "name": "AutoQuant",
      "one_line_profile": "Automation framework for ML, forecasting, and model evaluation",
      "detailed_description": "A comprehensive automation framework in R for machine learning and forecasting. It includes modules for model evaluation, interpretation, and automated workflow management, suitable for quantitative analysis and data science tasks.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "automl",
        "model_evaluation",
        "forecasting"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/AdrianAntico/AutoQuant",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "automl",
        "forecasting",
        "model-interpretation",
        "r"
      ],
      "id": 359
    },
    {
      "name": "AgentField",
      "one_line_profile": "Kubernetes-like orchestration platform for AI Agents",
      "detailed_description": "An infrastructure tool that enables building and running AI agents like microservices. It provides scalability, observability, and identity management, acting as a container orchestration layer specifically for AI agents.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "agent_orchestration",
        "infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/Agent-Field/agentfield",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "agent-orchestration",
        "microservices"
      ],
      "id": 360
    },
    {
      "name": "AgentOps",
      "one_line_profile": "Observability and evaluation SDK for AI agents",
      "detailed_description": "A Python SDK for monitoring, benchmarking, and tracking costs of AI agents. It integrates with major agent frameworks (CrewAI, LangChain, etc.) to provide comprehensive observability, session replays, and performance metrics for agent development.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_observability",
        "tracing",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AgentOps-AI/agentops",
      "help_website": [
        "https://agentops.ai"
      ],
      "license": "MIT",
      "tags": [
        "observability",
        "monitoring",
        "llm-cost",
        "agent-evaluation"
      ],
      "id": 361
    },
    {
      "name": "TokenCost",
      "one_line_profile": "Token price estimation utility for LLMs",
      "detailed_description": "A utility library for estimating token costs across 400+ Large Language Models. It serves as a support tool for LLMOps and agent cost management/tracking.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "cost_estimation",
        "resource_tracking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AgentOps-AI/tokencost",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "token-counting",
        "cost-estimation",
        "llmops"
      ],
      "id": 362
    },
    {
      "name": "Agenta",
      "one_line_profile": "Open-source LLMOps platform for prompt management and evaluation",
      "detailed_description": "An LLMOps platform that provides tools for prompt engineering, management, LLM evaluation, and observability. It allows developers to iterate on prompts and evaluate model performance in a unified interface.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "prompt_management",
        "llm_evaluation",
        "observability"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Agenta-AI/agenta",
      "help_website": [
        "https://agenta.ai"
      ],
      "license": null,
      "tags": [
        "llmops",
        "prompt-engineering",
        "evaluation"
      ],
      "id": 363
    },
    {
      "name": "AgenticGoKit",
      "one_line_profile": "Agentic AI framework in Go with observability",
      "detailed_description": "An open-source framework in Go for building and orchestrating intelligent agents. It supports multi-agent workflows, MCP tool discovery, and includes production-grade observability features.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_framework",
        "observability",
        "workflow_orchestration"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/AgenticGoKit/AgenticGoKit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "go",
        "agent-framework",
        "observability"
      ],
      "id": 364
    },
    {
      "name": "OmniSearch",
      "one_line_profile": "Benchmark for Multimodal RAG with adaptive planning agents",
      "detailed_description": "A repository for benchmarking Multimodal Retrieval Augmented Generation (RAG) systems. It features a Dynamic VQA dataset and a self-adaptive planning agent to evaluate retrieval and generation capabilities across modalities.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "rag_benchmarking",
        "multimodal_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Alibaba-NLP/OmniSearch",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "multimodal-rag",
        "vqa"
      ],
      "id": 365
    },
    {
      "name": "OpenInference",
      "one_line_profile": "OpenTelemetry instrumentation standard for AI observability",
      "detailed_description": "Provides OpenTelemetry instrumentation for AI observability, defining a standard for tracing and monitoring LLM and agentic applications. It enables consistent data collection across various AI frameworks.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tracing",
        "observability",
        "instrumentation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Arize-ai/openinference",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "opentelemetry",
        "observability",
        "tracing",
        "standard"
      ],
      "id": 366
    },
    {
      "name": "DeepResearch Bench",
      "one_line_profile": "Benchmark for evaluating Deep Research Agents",
      "detailed_description": "A comprehensive benchmark specifically designed for assessing the performance of Deep Research Agents. It provides datasets and evaluation metrics to measure the capabilities of agents in conducting deep, multi-step research tasks.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_benchmarking",
        "research_capability_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Ayanami0730/deep_research_bench",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "deep-research",
        "agent-evaluation"
      ],
      "id": 367
    },
    {
      "name": "ArtKit",
      "one_line_profile": "Automated prompt-based testing and evaluation for Gen AI",
      "detailed_description": "A toolkit for automated prompt-based testing and evaluation of Generative AI applications. It facilitates the creation of test suites and evaluation pipelines to ensure the quality and reliability of Gen AI outputs.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "prompt_testing",
        "model_evaluation",
        "quality_assurance"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/BCG-X-Official/artkit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "testing",
        "evaluation",
        "gen-ai",
        "prompt-engineering"
      ],
      "id": 368
    },
    {
      "name": "Ko-LM-Evaluation-Harness",
      "one_line_profile": "Evaluation harness for Korean language models",
      "detailed_description": "A specialized fork of the lm-evaluation-harness tailored for evaluating Korean Large Language Models. It includes datasets and metrics specific to the Korean language context.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "linguistic_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Beomi/ko-lm-evaluation-harness",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation",
        "korean-llm",
        "benchmark"
      ],
      "id": 369
    },
    {
      "name": "RAG Logger",
      "one_line_profile": "Lightweight logging tool for RAG applications",
      "detailed_description": "An open-source logging tool specifically designed for Retrieval-Augmented Generation (RAG) applications. It serves as a lightweight alternative to complex observability platforms, focusing on capturing RAG-specific events and data flows.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "logging",
        "tracing",
        "rag_observability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Brandon-c-tech/RAG-logger",
      "help_website": [],
      "license": null,
      "tags": [
        "logging",
        "rag",
        "observability"
      ],
      "id": 370
    },
    {
      "name": "DAComp",
      "one_line_profile": "Benchmark for Data Agents across the data intelligence lifecycle",
      "detailed_description": "A benchmarking suite for evaluating Data Agents across the full data intelligence lifecycle. It assesses the capabilities of agents in handling data processing, analysis, and management tasks.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_benchmarking",
        "data_agent_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/ByteDance-Seed/DAComp",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "data-agents",
        "evaluation"
      ],
      "id": 371
    },
    {
      "name": "RAGEval",
      "one_line_profile": "Automated evaluation system for RAG applications",
      "detailed_description": "A one-stop solution for the automated evaluation of RAG systems. It provides tools and metrics to assess the performance of retrieval and generation components in RAG pipelines.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "automated_testing"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/BytePioneer-AI/RAGEval",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "evaluation",
        "automation"
      ],
      "id": 372
    },
    {
      "name": "Rankify",
      "one_line_profile": "Comprehensive Python toolkit for Retrieval, Re-Ranking, and RAG",
      "detailed_description": "A toolkit integrating pre-retrieved benchmark datasets and supporting multiple retrieval techniques, reranking models, and RAG methods for scientific information retrieval and processing.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "retrieval",
        "reranking",
        "rag"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DataScienceUIBK/Rankify",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "retrieval",
        "reranking"
      ],
      "id": 373
    },
    {
      "name": "XRAG",
      "one_line_profile": "Benchmark for evaluating foundational component modules in RAG",
      "detailed_description": "A benchmarking framework designed to examine the core components of Advanced Retrieval-Augmented Generation systems, facilitating evaluation of retrieval and generation modules.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmarking",
        "evaluation",
        "rag"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DocAILab/XRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "benchmark",
        "evaluation"
      ],
      "id": 374
    },
    {
      "name": "LM Evaluation Harness",
      "one_line_profile": "Framework for few-shot evaluation of language models",
      "detailed_description": "A framework for few-shot evaluation of language models, widely used for benchmarking LLM performance across various tasks including scientific reasoning.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EleutherAI/lm-evaluation-harness",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "evaluation",
        "benchmark"
      ],
      "id": 375
    },
    {
      "name": "JamAIBase",
      "one_line_profile": "Collaborative spreadsheet interface for building and evaluating AI pipelines",
      "detailed_description": "A tool that combines spreadsheet UI with LLM pipeline building capabilities, allowing users to experiment with prompts, chain cells, and evaluate LLM responses in real-time.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "evaluation",
        "prompt_engineering"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/EmbeddedLLM/JamAIBase",
      "help_website": [
        "https://jamaibase.com"
      ],
      "license": "Apache-2.0",
      "tags": [
        "spreadsheet",
        "llm-ops",
        "evaluation"
      ],
      "id": 376
    },
    {
      "name": "EmbodiedBench",
      "one_line_profile": "Benchmark to evaluate Multimodal LLMs as embodied agents",
      "detailed_description": "A comprehensive benchmark designed to evaluate Multimodal Large Language Models (MLLMs) in the context of embodied agents, testing their ability to interact with environments.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmarking",
        "evaluation",
        "embodied_ai"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/EmbodiedBench/EmbodiedBench",
      "help_website": [],
      "license": null,
      "tags": [
        "embodied-ai",
        "benchmark",
        "mllm"
      ],
      "id": 377
    },
    {
      "name": "spacecutter",
      "one_line_profile": "Ordinal regression models implementation in PyTorch",
      "detailed_description": "A library for implementing ordinal regression models in PyTorch, useful for scientific data analysis where outcome variables are ordered categories.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "regression",
        "statistical_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EthanRosenthal/spacecutter",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ordinal-regression",
        "pytorch",
        "statistics"
      ],
      "id": 378
    },
    {
      "name": "QueryWeaver",
      "one_line_profile": "Text-to-SQL tool using graph-powered schema understanding",
      "detailed_description": "An open-source Text2SQL tool that transforms natural language into SQL, facilitating data retrieval from scientific databases via agentic interfaces.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "text_to_sql",
        "query_generation",
        "data_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/FalkorDB/QueryWeaver",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "text2sql",
        "graph-database",
        "nlp"
      ],
      "id": 379
    },
    {
      "name": "FixedEffectModels.jl",
      "one_line_profile": "Fast estimation of linear models with fixed effects and IV in Julia",
      "detailed_description": "A Julia package for fast estimation of linear models with high-dimensional categorical variables and instrumental variables, widely used in econometrics and statistical analysis.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "regression",
        "statistical_modeling"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/FixedEffects/FixedEffectModels.jl",
      "help_website": [],
      "license": null,
      "tags": [
        "julia",
        "econometrics",
        "statistics"
      ],
      "id": 380
    },
    {
      "name": "LLMZoo",
      "one_line_profile": "Data, models, and evaluation benchmarks for large language models",
      "detailed_description": "A project providing data, models, and evaluation benchmarks for LLMs, supporting the development and assessment of language models.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking",
        "model_hosting"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/FreedomIntelligence/LLMZoo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "benchmark",
        "dataset"
      ],
      "id": 381
    },
    {
      "name": "Giskard",
      "one_line_profile": "Open-source testing and evaluation library for LLM agents and AI models",
      "detailed_description": "A comprehensive testing and evaluation library for AI models, including LLMs, focusing on quality, security, and performance assessment.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "testing",
        "hallucination_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Giskard-AI/giskard-oss",
      "help_website": [
        "https://docs.giskard.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ai-testing",
        "evaluation",
        "llm-ops"
      ],
      "id": 382
    },
    {
      "name": "Giskard Vision",
      "one_line_profile": "Evaluation and testing library for Computer Vision AI systems",
      "detailed_description": "An extension of the Giskard framework specifically designed for evaluating and testing computer vision models.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "computer_vision",
        "testing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Giskard-AI/giskard-vision",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "computer-vision",
        "evaluation",
        "testing"
      ],
      "id": 383
    },
    {
      "name": "Giskard Prompt Injections",
      "one_line_profile": "Collection of prompt injection payloads for security testing of LLMs",
      "detailed_description": "A dataset/resource containing prompt injection payloads used for red-teaming and security evaluation of Large Language Models.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "security_testing",
        "evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Giskard-AI/prompt-injections",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "security",
        "prompt-injection",
        "red-teaming"
      ],
      "id": 384
    },
    {
      "name": "GraphRAG-Benchmark",
      "one_line_profile": "Benchmark and dataset for evaluating GraphRAG models",
      "detailed_description": "A comprehensive benchmark and dataset specifically designed for evaluating Retrieval-Augmented Generation models that utilize graph structures.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmarking",
        "evaluation",
        "graph_rag"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/GraphRAG-Bench/GraphRAG-Benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-rag",
        "benchmark",
        "evaluation"
      ],
      "id": 385
    },
    {
      "name": "LightRAG",
      "one_line_profile": "Simple and fast Retrieval-Augmented Generation framework",
      "detailed_description": "A framework for implementing Retrieval-Augmented Generation (RAG) systems, optimizing for simplicity and speed in information retrieval tasks.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "rag",
        "retrieval",
        "generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUDS/LightRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "retrieval",
        "llm"
      ],
      "id": 386
    },
    {
      "name": "GLM.jl",
      "one_line_profile": "Generalized linear models library for Julia",
      "detailed_description": "A Julia package for fitting generalized linear models (GLM), including linear, logistic, and Poisson regression, which are fundamental for scientific statistical analysis.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "statistical_analysis",
        "regression",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaStats/GLM.jl",
      "help_website": [
        "https://juliastats.org/GLM.jl/stable/"
      ],
      "license": "MIT",
      "tags": [
        "statistics",
        "regression",
        "julia",
        "glm"
      ],
      "id": 387
    },
    {
      "name": "Weave.jl",
      "one_line_profile": "Scientific report generator and literate programming tool for Julia",
      "detailed_description": "A scientific report generator for Julia that enables literate programming, allowing researchers to weave code and documentation into reproducible scientific reports (HTML, PDF, LaTeX).",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "scientific_visualization",
        "reproducible_research",
        "report_generation"
      ],
      "application_level": "tool",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JunoLab/Weave.jl",
      "help_website": [
        "http://weavejl.mpastell.com/stable/"
      ],
      "license": "MIT",
      "tags": [
        "literate-programming",
        "reproducibility",
        "julia",
        "reporting"
      ],
      "id": 388
    },
    {
      "name": "trame",
      "one_line_profile": "Python framework for building interactive scientific visualization applications",
      "detailed_description": "A framework by Kitware that enables the creation of interactive web-based applications for scientific visualization and data analysis, leveraging VTK and ParaView backends.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "scientific_visualization",
        "visual_analytics",
        "dashboarding"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Kitware/trame",
      "help_website": [
        "https://kitware.github.io/trame/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "vtk",
        "paraview",
        "web-app"
      ],
      "id": 389
    },
    {
      "name": "DeepTab",
      "one_line_profile": "Deep learning library for tabular data regression and classification",
      "detailed_description": "A Python package providing a suite of deep learning models (e.g., FT-Transformer, TabTransformer) specifically for tabular data analysis, enabling regression and classification tasks common in scientific experiments.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tabular_regression",
        "classification",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenTabular/DeepTab",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tabular-data",
        "deep-learning",
        "regression",
        "classification"
      ],
      "id": 390
    },
    {
      "name": "GitTaskBench",
      "one_line_profile": "Repo-level benchmark for evaluating coding agents on real-world Git tasks",
      "detailed_description": "A benchmark designed to evaluate the capabilities of Large Language Model (LLM) based agents in performing real-world software development tasks within a Git repository context. It assesses repo understanding, environment setup, and bug fixing.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_evaluation",
        "benchmark"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/QuantaAlpha/GitTaskBench",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "agents",
        "coding-agents",
        "llm-evaluation"
      ],
      "id": 391
    },
    {
      "name": "LLMBox",
      "one_line_profile": "Comprehensive library for LLM training and evaluation",
      "detailed_description": "A unified library for implementing, training, and evaluating Large Language Models (LLMs). It provides a pipeline for standardizing the training and comprehensive evaluation of models, supporting various datasets and metrics.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/RUCAIBox/LLMBox",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "evaluation",
        "training-pipeline",
        "benchmark"
      ],
      "id": 392
    },
    {
      "name": "RagView",
      "one_line_profile": "Unified evaluation platform for benchmarking RAG methods",
      "detailed_description": "A platform designed to evaluate and benchmark different Retrieval-Augmented Generation (RAG) methods on custom datasets, facilitating the comparison of SOTA results in specific data contexts.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "benchmark"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/RagView/RagView",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "evaluation",
        "benchmark",
        "retrieval"
      ],
      "id": 393
    },
    {
      "name": "Whistleblower",
      "one_line_profile": "Offensive security tool for testing AI application prompt leakage",
      "detailed_description": "A security tool designed for AI engineers and researchers to test system prompt leakage and discover capabilities of LLM-based applications exposed via API, serving as a red-teaming utility.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "security_evaluation",
        "red_teaming"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Repello-AI/whistleblower",
      "help_website": [],
      "license": null,
      "tags": [
        "security",
        "llm",
        "red-teaming",
        "prompt-injection"
      ],
      "id": 394
    },
    {
      "name": "RAG-evaluation-harnesses",
      "one_line_profile": "Evaluation suite for Retrieval-Augmented Generation (RAG)",
      "detailed_description": "A comprehensive evaluation harness specifically designed for assessing the performance of Retrieval-Augmented Generation (RAG) systems.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "benchmark"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/RulinShao/RAG-evaluation-harnesses",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "harness"
      ],
      "id": 395
    },
    {
      "name": "Agentic Web",
      "one_line_profile": "Framework for weaving the web with AI Agents",
      "detailed_description": "A research framework aimed at enabling AI agents to interact with and navigate the web, likely supporting the development and evaluation of web-based agents.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_framework",
        "web_agents"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/SafeRL-Lab/agentic-web",
      "help_website": [],
      "license": null,
      "tags": [
        "agents",
        "web-navigation",
        "framework"
      ],
      "id": 396
    },
    {
      "name": "MCP-Universe",
      "one_line_profile": "Framework for developing and benchmarking AI agents",
      "detailed_description": "A comprehensive framework from Salesforce AI Research designed for the development, testing, and benchmarking of AI agents, facilitating reproducible agent research.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_benchmarking",
        "agent_development"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/SalesforceAIResearch/MCP-Universe",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agents",
        "benchmark",
        "multi-agent"
      ],
      "id": 397
    },
    {
      "name": "DomainMind",
      "one_line_profile": "RAG integration for local LLMs in specialized domains",
      "detailed_description": "A tool to enhance local Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) for answering domain-specific questions, specifically targeting fields like scientific research.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "rag",
        "domain_adaptation"
      ],
      "application_level": "application",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/SalmanFarizN/DomainMind",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "local-llm",
        "scientific-research",
        "knowledge-base"
      ],
      "id": 398
    },
    {
      "name": "AgentClinic",
      "one_line_profile": "Agent benchmark for medical diagnosis",
      "detailed_description": "A benchmark environment designed to evaluate the performance of AI agents in the context of medical diagnosis tasks, simulating clinical scenarios.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_evaluation",
        "medical_diagnosis"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/SamuelSchmidgall/AgentClinic",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical",
        "benchmark",
        "agents",
        "healthcare"
      ],
      "id": 399
    },
    {
      "name": "Langtrace",
      "one_line_profile": "Open Telemetry based observability tool for LLM applications",
      "detailed_description": "An open-source observability tool providing real-time tracing, evaluations, and metrics for LLM applications, supporting popular frameworks and vector databases.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tracing",
        "observability",
        "evaluation"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/Scale3-Labs/langtrace",
      "help_website": [
        "https://docs.langtrace.ai"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "observability",
        "tracing",
        "llm",
        "opentelemetry"
      ],
      "id": 400
    },
    {
      "name": "Langtrace Python SDK",
      "one_line_profile": "Python SDK for Langtrace observability platform",
      "detailed_description": "The Python Software Development Kit (SDK) for integrating Langtrace observability and tracing capabilities into Python-based LLM applications.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tracing",
        "observability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Scale3-Labs/langtrace-python-sdk",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sdk",
        "python",
        "tracing",
        "llm"
      ],
      "id": 401
    },
    {
      "name": "giskardpy",
      "one_line_profile": "Python library for constraint-based robot motion control",
      "detailed_description": "The core Python library of the Giskard framework, facilitating constraint- and optimization-based motion control for robotics.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "robotics_control",
        "motion_planning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SemRoCo/giskardpy",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "robotics",
        "motion-control",
        "optimization"
      ],
      "id": 402
    },
    {
      "name": "AgentLab",
      "one_line_profile": "Framework for developing and benchmarking web agents",
      "detailed_description": "An open-source framework for developing, testing, and benchmarking web agents across diverse tasks, emphasizing scalability and reproducibility in agent research.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_benchmarking",
        "agent_development"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/ServiceNow/AgentLab",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "agents",
        "benchmark",
        "web-agents"
      ],
      "id": 403
    },
    {
      "name": "SynthGenAI",
      "one_line_profile": "Package for generating synthetic datasets using LLMs",
      "detailed_description": "A Python package designed to facilitate the generation of synthetic datasets using Large Language Models (LLMs), useful for data augmentation in scientific and AI research.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "synthetic_data_generation",
        "data_augmentation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Shekswess/synthgenai",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "synthetic-data",
        "llm",
        "dataset-generation"
      ],
      "id": 404
    },
    {
      "name": "Gorilla",
      "one_line_profile": "Training and evaluating LLMs for function calls",
      "detailed_description": "A project focused on training and evaluating Large Language Models (LLMs) specifically for their ability to perform function calls (tool use), critical for agentic workflows.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "tool_use"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ShishirPatil/gorilla",
      "help_website": [
        "https://gorilla.cs.berkeley.edu/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "function-calling",
        "tool-use",
        "evaluation"
      ],
      "id": 405
    },
    {
      "name": "Auto-GPT-Benchmarks",
      "one_line_profile": "Benchmark for evaluating agent performance",
      "detailed_description": "A repository dedicated to benchmarking the performance of AI agents, providing a standardized way to assess agent capabilities regardless of their underlying architecture.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_benchmarking",
        "performance_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Significant-Gravitas/Auto-GPT-Benchmarks",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "agents",
        "auto-gpt"
      ],
      "id": 406
    },
    {
      "name": "Skywork",
      "one_line_profile": "Skywork model series with training and evaluation resources",
      "detailed_description": "Open-source release of the Skywork series models, including training data, evaluation datasets, and evaluation methods, supporting multilingual and code tasks.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "model_release"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/SkyworkAI/Skywork",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "evaluation",
        "pretrained-models"
      ],
      "id": 407
    },
    {
      "name": "EmoLLM",
      "one_line_profile": "Mental health LLM framework with evaluation and RAG",
      "detailed_description": "A comprehensive framework for Mental Health Large Language Models, including pre-training, post-training, datasets, evaluation, and RAG capabilities.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "domain_specific_llm",
        "mental_health_analysis"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/SmartFlowAI/EmoLLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mental-health",
        "llm",
        "evaluation",
        "rag"
      ],
      "id": 408
    },
    {
      "name": "stargazer",
      "one_line_profile": "Python implementation of R stargazer for regression tables",
      "detailed_description": "A Python library that generates LaTeX, HTML, and ASCII tables for statistical regression models, porting the functionality of the popular R 'stargazer' package.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "statistical_reporting",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/StatsReporting/stargazer",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "statistics",
        "regression",
        "reporting",
        "latex"
      ],
      "id": 409
    },
    {
      "name": "AgentBench",
      "one_line_profile": "Comprehensive benchmark to evaluate LLMs as Agents",
      "detailed_description": "A comprehensive benchmark suite designed to evaluate Large Language Models (LLMs) acting as agents across various environments and tasks.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_benchmarking",
        "llm_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/THUDM/AgentBench",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "agents",
        "llm"
      ],
      "id": 410
    },
    {
      "name": "AI-Infra-Guard",
      "one_line_profile": "AI Red Teaming platform",
      "detailed_description": "A comprehensive, intelligent AI Red Teaming platform developed to evaluate and secure AI infrastructure and models.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "security_evaluation",
        "red_teaming"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Tencent/AI-Infra-Guard",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "red-teaming",
        "ai-security",
        "evaluation"
      ],
      "id": 411
    },
    {
      "name": "AICGSecEval",
      "one_line_profile": "AI-generated code security evaluation benchmark",
      "detailed_description": "A repository-level benchmark for evaluating the security of code generated by AI models, developed by Tencent.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "security_evaluation",
        "code_generation_benchmark"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/Tencent/AICGSecEval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "security",
        "benchmark",
        "code-generation"
      ],
      "id": 412
    },
    {
      "name": "TheAgentCompany",
      "one_line_profile": "Agent benchmark with simulated software company tasks",
      "detailed_description": "A benchmark environment that simulates a software company to evaluate AI agents on a variety of realistic tasks.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_benchmarking",
        "task_simulation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/TheAgentCompany/TheAgentCompany",
      "help_website": [
        "https://the-agent-company.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "benchmark",
        "agents",
        "simulation"
      ],
      "id": 413
    },
    {
      "name": "Tonic Validate",
      "one_line_profile": "Metrics library for evaluating Retrieval Augmented Generation (RAG) applications",
      "detailed_description": "A Python library providing metrics and tools to evaluate the quality of responses from RAG applications, essential for verifying the accuracy of scientific AI assistants.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "rag_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TonicAI/tonic_validate",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "metrics",
        "llm"
      ],
      "id": 414
    },
    {
      "name": "VoltAgent",
      "one_line_profile": "AI Agent Framework with built-in LLM Observability",
      "detailed_description": "A TypeScript framework for building AI agents that includes built-in observability features, facilitating the tracing and debugging of agentic workflows.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tracing",
        "observability",
        "agent_framework"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/VoltAgent/voltagent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent",
        "observability",
        "tracing",
        "llm"
      ],
      "id": 415
    },
    {
      "name": "DeepPHY",
      "one_line_profile": "Benchmarking Agentic VLMs on Physical Reasoning",
      "detailed_description": "A benchmark and evaluation harness for testing the physical reasoning capabilities of Vision-Language Models (VLMs), critical for scientific agents interacting with the physical world.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmarking",
        "physical_reasoning",
        "evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/XinrunXu/DeepPHY",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vlm",
        "physical-reasoning",
        "benchmark",
        "agent"
      ],
      "id": 416
    },
    {
      "name": "PromptWorks",
      "one_line_profile": "Prompt management and testing tool",
      "detailed_description": "A platform for managing, testing, and optimizing prompts for LLMs, supporting the evaluation phase of AI agent development.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "prompt_engineering",
        "testing",
        "evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Vue",
      "repo_url": "https://github.com/YellowSeaa/PromptWorks",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prompt-engineering",
        "testing",
        "llm"
      ],
      "id": 417
    },
    {
      "name": "math-evaluation-harness",
      "one_line_profile": "Toolkit for benchmarking LLMs on mathematical reasoning tasks",
      "detailed_description": "A simple toolkit designed to evaluate and benchmark Large Language Models on various mathematical reasoning datasets, essential for verifying scientific reasoning capabilities.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmarking",
        "mathematical_reasoning",
        "evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ZubinGou/math-evaluation-harness",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "math",
        "reasoning",
        "benchmark",
        "llm"
      ],
      "id": 418
    },
    {
      "name": "AgentScope Studio",
      "one_line_profile": "Visualization toolkit for AgentScope multi-agent platform",
      "detailed_description": "A development-oriented visualization tool for the AgentScope framework, enabling developers to trace, visualize, and debug multi-agent workflows.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "visualization",
        "debugging",
        "agent_workflow"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/agentscope-ai/agentscope-studio",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "multi-agent",
        "debugging"
      ],
      "id": 419
    },
    {
      "name": "BeyondLLM",
      "one_line_profile": "Framework to build, evaluate and observe LLM apps",
      "detailed_description": "A framework that simplifies the development of LLM applications with integrated capabilities for evaluation and observability (tracing), supporting reliable AI agent deployment.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "observability",
        "workflow_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/aiplanethub/beyondllm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "evaluation",
        "observability",
        "rag"
      ],
      "id": 420
    },
    {
      "name": "AutoRAG-Eval",
      "one_line_profile": "Automated Evaluation of Retrieval-Augmented Language Models",
      "detailed_description": "A tool for the automated evaluation of RAG systems, generating task-specific exams to measure performance, developed by Amazon Science.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "rag_benchmarking",
        "exam_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/amazon-science/auto-rag-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "benchmarking",
        "llm"
      ],
      "id": 421
    },
    {
      "name": "langfuse-mcp",
      "one_line_profile": "MCP server for Langfuse enabling AI agent tracing and observability",
      "detailed_description": "A Model Context Protocol (MCP) server implementation that connects AI agents to Langfuse, allowing for the querying of trace data to enhance debugging and observability within agentic workflows.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tracing",
        "observability",
        "debugging"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/avivsinai/langfuse-mcp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "langfuse",
        "observability",
        "tracing",
        "agent-debugging"
      ],
      "id": 422
    },
    {
      "name": "linearmodels",
      "one_line_profile": "Extended linear models for econometrics and statistics in Python",
      "detailed_description": "A Python library that extends statsmodels with additional linear models, specifically focusing on instrumental variable (IV) models, panel data models, and other advanced statistical estimation methods used in econometrics and scientific data analysis.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "statistical_analysis",
        "regression",
        "estimation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bashtage/linearmodels",
      "help_website": [
        "https://bashtage.github.io/linearmodels/"
      ],
      "license": "NCSA",
      "tags": [
        "econometrics",
        "statistics",
        "regression",
        "panel-data",
        "instrumental-variables"
      ],
      "id": 423
    },
    {
      "name": "BEIR",
      "one_line_profile": "Heterogeneous benchmark for zero-shot information retrieval evaluation",
      "detailed_description": "A heterogeneous benchmark for Information Retrieval (IR) that enables the evaluation of retrieval models across diverse datasets and tasks. It serves as a standard evaluation harness for assessing the generalization capabilities of neural retrieval models.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "information_retrieval",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/beir-cellar/beir",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "information-retrieval",
        "benchmark",
        "evaluation",
        "zero-shot"
      ],
      "id": 424
    },
    {
      "name": "BigCode Evaluation Harness",
      "one_line_profile": "Framework for evaluating code generation language models",
      "detailed_description": "A comprehensive framework designed for the evaluation of autoregressive code generation language models. It supports multiple programming languages and tasks, enabling rigorous assessment of LLMs used for coding, which is a critical utility in scientific computing.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "code_generation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bigcode-project/bigcode-evaluation-harness",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "llm",
        "code-generation",
        "benchmark"
      ],
      "id": 425
    },
    {
      "name": "BigCodeBench",
      "one_line_profile": "Benchmark for code generation towards AGI capabilities",
      "detailed_description": "A benchmark dataset and evaluation suite designed to assess the capabilities of code generation models on complex, practical programming tasks. It serves as a standard for evaluating the reasoning and coding proficiency of AI agents.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking",
        "code_generation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/bigcode-project/bigcodebench",
      "help_website": [
        "https://bigcodebench.github.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "code-generation",
        "evaluation",
        "llm"
      ],
      "id": 426
    },
    {
      "name": "Carla-ppo",
      "one_line_profile": "Reinforcement learning agent wrapper for CARLA simulator",
      "detailed_description": "A customized PPO-based agent framework for the CARLA autonomous driving simulator. It wraps CARLA in a Gym-like environment, facilitating reinforcement learning experiments and simulation control for autonomous systems research.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "simulation",
        "reinforcement_learning",
        "agent_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bitsauce/Carla-ppo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "carla",
        "reinforcement-learning",
        "simulation",
        "autonomous-driving",
        "ppo"
      ],
      "id": 427
    },
    {
      "name": "AutoAI",
      "one_line_profile": "Automated AI framework for regression and classification",
      "detailed_description": "A Python-based AutoML framework designed to automate the process of model search, hyper-parameter tuning, and code generation for regression and classification tasks on numerical data, facilitating scientific data analysis.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "automl",
        "regression",
        "classification",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/blobcity/autoai",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "automl",
        "regression",
        "classification",
        "data-science"
      ],
      "id": 428
    },
    {
      "name": "CRAB",
      "one_line_profile": "Cross-environment agent benchmark for multimodal language models",
      "detailed_description": "A benchmark framework for evaluating Multimodal Language Model (MLM) agents across diverse environments. It provides a standardized way to assess agent performance in complex, cross-domain tasks, supporting the development of robust scientific agents.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking",
        "agent_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/camel-ai/crab",
      "help_website": [
        "https://crab.camel-ai.org/"
      ],
      "license": null,
      "tags": [
        "benchmark",
        "agent",
        "multimodal",
        "evaluation"
      ],
      "id": 429
    },
    {
      "name": "Yet Another Applied LLM Benchmark",
      "one_line_profile": "Benchmark for evaluating LLMs on applied reasoning tasks",
      "detailed_description": "A benchmark suite designed to evaluate Large Language Models on a set of practical, applied questions and problems, serving as a dataset for assessing model reasoning and problem-solving capabilities.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking",
        "reasoning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/carlini/yet-another-applied-llm-benchmark",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "benchmark",
        "llm",
        "evaluation",
        "reasoning"
      ],
      "id": 430
    },
    {
      "name": "Opik",
      "one_line_profile": "Platform for debugging, evaluating, and monitoring LLM applications",
      "detailed_description": "An open-source platform designed to trace, evaluate, and monitor LLM applications, RAG systems, and agentic workflows. It provides tools for automated evaluation and observability, essential for building reliable scientific AI agents.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tracing",
        "model_evaluation",
        "observability",
        "monitoring"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/comet-ml/opik",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-ops",
        "evaluation",
        "tracing",
        "observability",
        "rag"
      ],
      "id": 431
    },
    {
      "name": "DeepEval",
      "one_line_profile": "Evaluation framework for LLMs and RAG pipelines",
      "detailed_description": "A comprehensive evaluation framework for Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems. It provides metrics and test suites to assess model performance, hallucination, and alignment, supporting the validation of scientific AI applications.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "testing",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/confident-ai/deepeval",
      "help_website": [
        "https://docs.confident-ai.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "llm",
        "rag",
        "testing",
        "metrics"
      ],
      "id": 432
    },
    {
      "name": "Coze Loop",
      "one_line_profile": "AI agent optimization and lifecycle management platform",
      "detailed_description": "A platform for the optimization and lifecycle management of AI agents. It offers capabilities for debugging, evaluation, and monitoring, enabling the iterative improvement of agents used in complex workflows.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_optimization",
        "debugging",
        "monitoring",
        "evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/coze-dev/coze-loop",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent-optimization",
        "debugging",
        "evaluation",
        "monitoring"
      ],
      "id": 433
    },
    {
      "name": "Coze Studio",
      "one_line_profile": "Visual development environment for AI agents",
      "detailed_description": "An all-in-one visual development platform for creating, debugging, and deploying AI agents. It simplifies the orchestration of tools and workflows, facilitating the construction of agent-based solutions.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "agent_development",
        "debugging"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/coze-dev/coze-studio",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent-development",
        "visual-programming",
        "ide",
        "workflow"
      ],
      "id": 434
    },
    {
      "name": "UQLM",
      "one_line_profile": "Uncertainty quantification for language model hallucination detection",
      "detailed_description": "A Python package for Uncertainty Quantification (UQ) in Language Models, specifically designed to detect hallucinations. It provides statistical methods to estimate confidence and reliability in model outputs, a critical aspect for scientific AI.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "uncertainty_quantification",
        "hallucination_detection",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cvs-health/uqlm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "uncertainty-quantification",
        "hallucination-detection",
        "llm",
        "reliability"
      ],
      "id": 435
    },
    {
      "name": "AgentWatch",
      "one_line_profile": "Observability framework for AI agent interactions",
      "detailed_description": "An AI observability framework that provides insights into agent interactions. It enables monitoring, analysis, and optimization of AI-driven applications, supporting the tracing and evaluation of agent behaviors.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "monitoring",
        "tracing",
        "agent_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cyberark/agentwatch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "observability",
        "agent",
        "monitoring",
        "tracing"
      ],
      "id": 436
    },
    {
      "name": "finalfit",
      "one_line_profile": "R package for creating elegant regression results tables and plots",
      "detailed_description": "A library designed to streamline the process of generating final results tables and plots for regression models in R, commonly used in medical and epidemiological research for reporting.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "regression_analysis",
        "scientific_visualization"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/ewenharrison/finalfit",
      "help_website": [
        "https://finalfit.org/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "r",
        "regression",
        "statistics",
        "visualization"
      ],
      "id": 437
    },
    {
      "name": "BenchMARL",
      "one_line_profile": "Benchmarking library for Multi-Agent Reinforcement Learning (MARL)",
      "detailed_description": "A PyTorch-based library for benchmarking Multi-Agent Reinforcement Learning (MARL) algorithms, enabling systematic comparison of algorithms, tasks, and models with a focus on reproducibility.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmarking",
        "reinforcement_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/BenchMARL",
      "help_website": [
        "https://facebookresearch.github.io/BenchMARL/"
      ],
      "license": "MIT",
      "tags": [
        "marl",
        "reinforcement-learning",
        "benchmark",
        "pytorch"
      ],
      "id": 438
    },
    {
      "name": "MLGym",
      "one_line_profile": "Framework and benchmark for advancing AI research agents",
      "detailed_description": "A framework designed to facilitate the development and benchmarking of AI agents, providing environments and tools to evaluate agent performance in research settings.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmarking",
        "agent_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/MLGym",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ai-agents",
        "benchmark",
        "gym"
      ],
      "id": 439
    },
    {
      "name": "Meta Agents Research Environments",
      "one_line_profile": "Platform for evaluating AI agents in dynamic, realistic scenarios",
      "detailed_description": "A comprehensive platform for evaluating AI agents in evolving environments where agents must adapt strategies based on new information, mirroring real-world challenges.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_evaluation",
        "simulation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/meta-agents-research-environments",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ai-agents",
        "evaluation",
        "simulation"
      ],
      "id": 440
    },
    {
      "name": "SWEET-RL",
      "one_line_profile": "Benchmark for training multi-turn LLM agents on collaborative reasoning",
      "detailed_description": "A benchmark and research codebase for evaluating Large Language Model (LLM) agents on collaborative reasoning tasks, focusing on multi-turn interactions.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmarking",
        "agent_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/sweet_rl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm-agents",
        "benchmark",
        "reasoning"
      ],
      "id": 441
    },
    {
      "name": "rag-arena",
      "one_line_profile": "Open-source RAG evaluation tool using user feedback",
      "detailed_description": "A tool for evaluating Retrieval-Augmented Generation (RAG) systems by leveraging user feedback to compare and benchmark different RAG implementations.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "benchmarking"
      ],
      "application_level": "application",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/firecrawl/rag-arena",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "arena"
      ],
      "id": 442
    },
    {
      "name": "DHARMa",
      "one_line_profile": "Residual diagnostics for hierarchical (multi-level) regression models",
      "detailed_description": "An R package providing simulation-based residual diagnostics for hierarchical regression models, useful for validating statistical models in ecology and other sciences.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_diagnostics",
        "regression_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/florianhartig/DHARMa",
      "help_website": [
        "https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html"
      ],
      "license": null,
      "tags": [
        "r",
        "statistics",
        "regression",
        "diagnostics"
      ],
      "id": 443
    },
    {
      "name": "traceAI",
      "one_line_profile": "Open Source AI Tracing Framework built on OpenTelemetry",
      "detailed_description": "A framework for tracing AI applications and frameworks, built on OpenTelemetry to provide observability into AI agent execution and performance.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tracing",
        "observability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/future-agi/traceAI",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "opentelemetry",
        "tracing",
        "ai-observability"
      ],
      "id": 444
    },
    {
      "name": "langsmith-evaluation-helper",
      "one_line_profile": "Configuration-based evaluation helper for LangSmith",
      "detailed_description": "A helper library that simplifies running evaluations on LangSmith by allowing users to define evaluation configurations in files.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_evaluation",
        "workflow_automation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gaudiy/langsmith-evaluation-helper",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "langsmith",
        "evaluation",
        "llm-ops"
      ],
      "id": 445
    },
    {
      "name": "langfuse-go (git-hulk)",
      "one_line_profile": "Go SDK for Langfuse AI observability platform",
      "detailed_description": "A Go client library for Langfuse, enabling Go-based AI applications to integrate with the Langfuse observability and evaluation platform.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tracing",
        "observability"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/git-hulk/langfuse-go",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "langfuse",
        "go",
        "observability"
      ],
      "id": 446
    },
    {
      "name": "mcp-dap-server",
      "one_line_profile": "MCP server for AI Agents to debug live programs via DAP",
      "detailed_description": "A Model Context Protocol (MCP) server that bridges AI agents with Debug Adapter Protocol (DAP) servers, allowing agents to debug code execution dynamically.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "debugging",
        "tool_calling"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/go-delve/mcp-dap-server",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "dap",
        "debugging",
        "ai-agent"
      ],
      "id": 447
    },
    {
      "name": "golf",
      "one_line_profile": "Production-Ready MCP Server Framework for AI agents",
      "detailed_description": "A framework for building, deploying, and scaling Model Context Protocol (MCP) servers, providing infrastructure for secure AI agent tool usage and observability.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tool_calling",
        "agent_infrastructure"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/golf-mcp/golf",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mcp",
        "ai-agent",
        "infrastructure"
      ],
      "id": 448
    },
    {
      "name": "rageval",
      "one_line_profile": "Evaluation tools for Retrieval-augmented Generation (RAG) methods",
      "detailed_description": "A toolkit designed to evaluate Retrieval-Augmented Generation (RAG) pipelines, providing metrics and methods to assess retrieval and generation quality.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gomate-community/rageval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "metrics"
      ],
      "id": 449
    },
    {
      "name": "AndroidWorld",
      "one_line_profile": "Environment and benchmark for autonomous Android agents",
      "detailed_description": "A research environment and benchmark for evaluating autonomous agents that interact with the Android operating system, enabling reproducible agent research.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmarking",
        "agent_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/google-research/android_world",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "android",
        "agent-benchmark",
        "autonomous-agents"
      ],
      "id": 450
    },
    {
      "name": "Agent Development Kit (Go)",
      "one_line_profile": "Go toolkit for building and evaluating AI agents",
      "detailed_description": "An open-source toolkit for building, evaluating, and deploying sophisticated AI agents in Go, offering flexibility and control over agent workflows.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_development",
        "evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Go",
      "repo_url": "https://github.com/google/adk-go",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-agent",
        "go",
        "framework"
      ],
      "id": 451
    },
    {
      "name": "Agent Development Kit (Java)",
      "one_line_profile": "Java toolkit for building and evaluating AI agents",
      "detailed_description": "An open-source toolkit for building, evaluating, and deploying sophisticated AI agents in Java.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_development",
        "evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Java",
      "repo_url": "https://github.com/google/adk-java",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-agent",
        "java",
        "framework"
      ],
      "id": 452
    },
    {
      "name": "Agent Development Kit (Python)",
      "one_line_profile": "Python toolkit for building and evaluating AI agents",
      "detailed_description": "An open-source toolkit for building, evaluating, and deploying sophisticated AI agents in Python.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_development",
        "evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/google/adk-python",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-agent",
        "python",
        "framework"
      ],
      "id": 453
    },
    {
      "name": "Agent Development Kit Web",
      "one_line_profile": "Developer UI for Agent Development Kit",
      "detailed_description": "A web-based user interface integrated with the Agent Development Kit (ADK) to facilitate agent development, debugging, and evaluation.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "debugging",
        "visualization"
      ],
      "application_level": "application",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/google/adk-web",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-agent",
        "ui",
        "debugging"
      ],
      "id": 454
    },
    {
      "name": "GPstuff",
      "one_line_profile": "Gaussian process models for Bayesian analysis",
      "detailed_description": "A toolbox for Gaussian process models, providing tools for Bayesian analysis and inference, widely used in machine learning and statistics.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "bayesian_analysis",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/gpstuff-dev/gpstuff",
      "help_website": [
        "http://research.cs.aalto.fi/pml/software/gpstuff/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "gaussian-processes",
        "bayesian",
        "matlab",
        "statistics"
      ],
      "id": 455
    },
    {
      "name": "rms",
      "one_line_profile": "Regression Modeling Strategies",
      "detailed_description": "An R package by Frank Harrell for regression modeling, testing, estimation, validation, graphics, prediction, and typesetting of results.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "regression_analysis",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/harrelfe/rms",
      "help_website": [
        "https://hbiostat.org/R/rms/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "r",
        "regression",
        "statistics",
        "modeling"
      ],
      "id": 456
    },
    {
      "name": "prompttools",
      "one_line_profile": "Tools for prompt testing and experimentation with LLMs and vector DBs",
      "detailed_description": "A suite of open-source tools for testing, experimenting with, and evaluating prompts across various LLMs and vector databases.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "prompt_evaluation",
        "experimentation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hegelai/prompttools",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "prompt-engineering",
        "testing",
        "vector-db"
      ],
      "id": 457
    },
    {
      "name": "langfuse-go (henomis)",
      "one_line_profile": "Langfuse Go SDK",
      "detailed_description": "Another Go SDK implementation for the Langfuse AI observability platform, facilitating tracing and evaluation integration.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tracing",
        "observability"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/henomis/langfuse-go",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "langfuse",
        "go",
        "sdk"
      ],
      "id": 458
    },
    {
      "name": "Toolathlon",
      "one_line_profile": "Benchmark for Language Agents on diverse tasks",
      "detailed_description": "The Tool Decathlon: A benchmark designed to evaluate language agents on diverse, realistic, and long-horizon task execution capabilities.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmarking",
        "agent_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/hkust-nlp/Toolathlon",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmark",
        "language-agents",
        "tool-use"
      ],
      "id": 459
    },
    {
      "name": "LRAGE",
      "one_line_profile": "Framework for evaluating RAG pipelines in the legal domain",
      "detailed_description": "A specialized framework for evaluating Retrieval-Augmented Generation (RAG) pipelines, with specific adaptations for legal domain requirements.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "domain_specific_eval"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/hoorangyee/LRAGE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "legal-ai",
        "evaluation"
      ],
      "id": 460
    },
    {
      "name": "AI-model-comparison",
      "one_line_profile": "Web tool for side-by-side AI model response comparison",
      "detailed_description": "A web-based tool that allows users to compare responses from different Large Language Models (LLMs) side-by-side to evaluate performance and quality.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "comparison"
      ],
      "application_level": "application",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/hubhubgogo/AI-model-comparison",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "evaluation",
        "comparison-tool"
      ],
      "id": 461
    },
    {
      "name": "lighteval",
      "one_line_profile": "Toolkit for evaluating LLMs across multiple backends",
      "detailed_description": "A comprehensive toolkit by Hugging Face for evaluating Large Language Models (LLMs) across various backends, supporting a wide range of metrics and tasks.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "llm_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/lighteval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "huggingface",
        "evaluation",
        "llm"
      ],
      "id": 462
    },
    {
      "name": "dify-eval",
      "one_line_profile": "Automated evaluation service based on Dify and Langfuse",
      "detailed_description": "An automated evaluation service that integrates Dify and Langfuse to provide continuous assessment of AI agent performance.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_evaluation",
        "automation"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/hustyichi/dify-eval",
      "help_website": [],
      "license": null,
      "tags": [
        "dify",
        "langfuse",
        "evaluation"
      ],
      "id": 463
    },
    {
      "name": "ChainForge",
      "one_line_profile": "Visual programming environment for prompt engineering and evaluation",
      "detailed_description": "An open-source visual programming environment designed for battle-testing prompts to Large Language Models (LLMs). It allows users to conduct audit and evaluation of prompt robustness and model responses.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "prompt_engineering",
        "evaluation",
        "testing"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/ianarawjo/ChainForge",
      "help_website": [
        "https://chainforge.ai"
      ],
      "license": "MIT",
      "tags": [
        "prompt-engineering",
        "llm-evaluation",
        "visual-programming"
      ],
      "id": 464
    },
    {
      "name": "ViDoRe Benchmark",
      "one_line_profile": "Benchmark for Vision Document Retrieval evaluation",
      "detailed_description": "The Vision Document Retrieval (ViDoRe) Benchmark provides evaluation code and datasets for assessing the performance of vision-based document retrieval systems, specifically related to the ColPali paper.",
      "domains": [
        "AI5",
        "AI5-04",
        "Computer Vision"
      ],
      "subtask_category": [
        "benchmark",
        "retrieval_evaluation",
        "rag_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/illuin-tech/vidore-benchmark",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "document-retrieval",
        "rag"
      ],
      "id": 465
    },
    {
      "name": "Steer",
      "one_line_profile": "Active reliability layer for AI agents",
      "detailed_description": "A framework designed to act as a reliability layer for AI agents, providing capabilities to catch failures, teach fixes, and automate reliability in agentic workflows.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_reliability",
        "error_handling",
        "workflow_automation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/imtt-dev/steer",
      "help_website": [],
      "license": null,
      "tags": [
        "ai-agents",
        "reliability",
        "observability"
      ],
      "id": 466
    },
    {
      "name": "Inference Gateway",
      "one_line_profile": "Unified gateway for multiple LLM providers",
      "detailed_description": "An open-source, cloud-native gateway that unifies access to multiple LLM providers (OpenAI, Anthropic, Ollama, etc.), facilitating model management and inference orchestration for AI applications.",
      "domains": [
        "AI5",
        "Infrastructure"
      ],
      "subtask_category": [
        "inference_serving",
        "model_gateway"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/inference-gateway/inference-gateway",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-gateway",
        "inference",
        "api-management"
      ],
      "id": 467
    },
    {
      "name": "Probatus",
      "one_line_profile": "SHAP-based validation toolkit for machine learning models",
      "detailed_description": "A Python library for the validation of binary classifiers, multi-class classifiers, and regression models using SHAP (SHapley Additive exPlanations) values to analyze feature importance and model behavior.",
      "domains": [
        "Data Science",
        "AI5-04"
      ],
      "subtask_category": [
        "model_validation",
        "feature_selection",
        "explainability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ing-bank/probatus",
      "help_website": [
        "https://ing-bank.github.io/probatus/"
      ],
      "license": "MIT",
      "tags": [
        "shap",
        "model-validation",
        "machine-learning"
      ],
      "id": 468
    },
    {
      "name": "Prompt Forge",
      "one_line_profile": "Workbench for prompt engineering and evaluation",
      "detailed_description": "An AI prompt engineering workbench that allows users to craft, test, and systematically evaluate prompts with analysis tools, aiding in the optimization of LLM interactions.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "prompt_engineering",
        "evaluation",
        "testing"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/insaaniManav/prompt-forge",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "prompt-engineering",
        "llm",
        "workbench"
      ],
      "id": 469
    },
    {
      "name": "Invariant Explorer",
      "one_line_profile": "Tool for testing and inspecting AI Agent traces",
      "detailed_description": "A tool designed for testing, inspecting, and analyzing traces generated by AI agents, helping researchers and developers debug and understand agent behavior.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tracing",
        "debugging",
        "agent_analysis"
      ],
      "application_level": "tool",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/invariantlabs-ai/explorer",
      "help_website": [
        "https://invariantlabs.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ai-agents",
        "tracing",
        "debugging"
      ],
      "id": 470
    },
    {
      "name": "Invariant Gateway",
      "one_line_profile": "LLM proxy for observing AI agent behavior",
      "detailed_description": "An LLM proxy service that enables observation and debugging of AI agent activities by intercepting and logging interactions with language models.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "tracing",
        "proxy"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/invariantlabs-ai/invariant-gateway",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-proxy",
        "observability",
        "ai-agents"
      ],
      "id": 471
    },
    {
      "name": "GemInsights",
      "one_line_profile": "Dataframe analysis tool using Gemini AI",
      "detailed_description": "A tool that leverages Gemini AI to analyze dataframes, offering insights and replacing traditional manual data analysis methods with AI-driven interpretation.",
      "domains": [
        "Data Science",
        "AI5"
      ],
      "subtask_category": [
        "data_analysis",
        "automated_insights"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/izam-mohammed/GemInsights",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dataframe",
        "gemini-ai",
        "data-analysis"
      ],
      "id": 472
    },
    {
      "name": "RagRank",
      "one_line_profile": "Toolkit for evaluating RAG and LLM applications",
      "detailed_description": "A free LLM evaluation toolkit designed to assess the accuracy, context understanding, and tone of LLM applications, specifically focusing on RAG (Retrieval-Augmented Generation) systems.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "rag_assessment",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/izam-mohammed/ragrank",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "llm"
      ],
      "id": 473
    },
    {
      "name": "GraphRAG-Bench",
      "one_line_profile": "Benchmark for evaluating Graph Retrieval-Augmented Generation",
      "detailed_description": "A benchmark suite designed to evaluate Graph Retrieval-Augmented Generation (GraphRAG) systems, focusing on challenging domain-specific reasoning tasks.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmark",
        "rag_evaluation",
        "graph_reasoning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/jeremycp3/GraphRAG-Bench",
      "help_website": [],
      "license": null,
      "tags": [
        "graph-rag",
        "benchmark",
        "evaluation"
      ],
      "id": 474
    },
    {
      "name": "Ragas (Bioinformatics)",
      "one_line_profile": "R tools for single-cell subclustering analysis",
      "detailed_description": "A set of R tools for the analysis and visualization of single-cell subclustering data, aiding in bioinformatics research.",
      "domains": [
        "Bioinformatics",
        "Life Science"
      ],
      "subtask_category": [
        "single_cell_analysis",
        "clustering",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/jig4003/Ragas",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "single-cell",
        "bioinformatics",
        "r"
      ],
      "id": 475
    },
    {
      "name": "Promptspot",
      "one_line_profile": "Tool for testing and managing prompts",
      "detailed_description": "A tool designed to simplify prompt testing, allowing users to organize and evaluate prompts for LLM applications.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "prompt_testing",
        "evaluation"
      ],
      "application_level": "tool",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/jordanful/Promptspot",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prompt-testing",
        "llm"
      ],
      "id": 476
    },
    {
      "name": "HaELM",
      "one_line_profile": "Automatic MLLM hallucination detection framework",
      "detailed_description": "A framework for automatically detecting hallucinations in Multimodal Large Language Models (MLLMs), providing a method to assess model reliability.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "evaluation",
        "mllm"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/junyangwang0410/HaELM",
      "help_website": [],
      "license": null,
      "tags": [
        "hallucination-detection",
        "mllm",
        "evaluation"
      ],
      "id": 477
    },
    {
      "name": "llm-eval",
      "one_line_profile": "Platform for Large Language Model evaluation",
      "detailed_description": "An evaluation platform for Large Language Models supporting multiple benchmarks, custom datasets, and performance testing, including RAG evaluation capabilities.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "benchmark",
        "rag_assessment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/justplus/llm-eval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-evaluation",
        "benchmark",
        "rag"
      ],
      "id": 478
    },
    {
      "name": "AutoArena",
      "one_line_profile": "Automated head-to-head evaluation for LLMs and RAG",
      "detailed_description": "A tool for ranking LLMs, RAG systems, and prompts using automated head-to-head evaluation methodologies.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "ranking",
        "model_comparison"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/kolenaIO/autoarena",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-ranking",
        "evaluation",
        "rag"
      ],
      "id": 479
    },
    {
      "name": "BetterPrompt",
      "one_line_profile": "Test suite for LLM prompts",
      "detailed_description": "A test suite designed for validating and testing LLM prompts to ensure consistent and expected outputs.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "prompt_testing",
        "validation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/krrishdholakia/betterprompt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-testing",
        "llm"
      ],
      "id": 480
    },
    {
      "name": "Claude Code Telemetry",
      "one_line_profile": "Telemetry bridge for Claude Code to Langfuse",
      "detailed_description": "A lightweight bridge tool that captures telemetry data from Claude Code and forwards it to Langfuse for visualization and analysis of AI coding agent behavior.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "telemetry",
        "tracing",
        "observability"
      ],
      "application_level": "tool",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/lainra/claude-code-telemetry",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "telemetry",
        "claude",
        "langfuse"
      ],
      "id": 481
    },
    {
      "name": "LangSmith Java SDK",
      "one_line_profile": "Java client library for the LangSmith LLM observability and evaluation platform",
      "detailed_description": "The official Java SDK for interacting with LangSmith, enabling developers to trace, evaluate, and debug LLM-powered applications and agents within Java environments.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tracing",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Kotlin",
      "repo_url": "https://github.com/langchain-ai/langsmith-java",
      "help_website": [
        "https://docs.smith.langchain.com/"
      ],
      "license": "MIT",
      "tags": [
        "java",
        "sdk",
        "llm-ops",
        "observability"
      ],
      "id": 482
    },
    {
      "name": "LangSmith SDK",
      "one_line_profile": "Python client library for LangSmith observability and evaluation",
      "detailed_description": "The official Python SDK for LangSmith, providing interfaces to log traces, run evaluations, and manage datasets for LLM application development and regression testing.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tracing",
        "evaluation",
        "dataset_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/langchain-ai/langsmith-sdk",
      "help_website": [
        "https://docs.smith.langchain.com/"
      ],
      "license": "MIT",
      "tags": [
        "python",
        "sdk",
        "llm-evaluation",
        "tracing"
      ],
      "id": 483
    },
    {
      "name": "Langfuse",
      "one_line_profile": "Open source LLM engineering platform for observability, metrics, and evaluation",
      "detailed_description": "A comprehensive platform for tracing, evaluating, and managing LLM applications. It provides tools for prompt management, dataset curation, and detailed analytics to improve agent performance and reliability.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "evaluation",
        "prompt_management"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/langfuse/langfuse",
      "help_website": [
        "https://langfuse.com/docs"
      ],
      "license": "MIT",
      "tags": [
        "llm-ops",
        "tracing",
        "evaluation",
        "analytics"
      ],
      "id": 484
    },
    {
      "name": "Langfuse Java SDK",
      "one_line_profile": "Java client for Langfuse API",
      "detailed_description": "The Java SDK for integrating Langfuse observability and evaluation capabilities into Java-based LLM applications.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "tracing"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/langfuse/langfuse-java",
      "help_website": [
        "https://langfuse.com/docs/sdk/java"
      ],
      "license": "MIT",
      "tags": [
        "java",
        "sdk",
        "observability"
      ],
      "id": 485
    },
    {
      "name": "Langfuse JS/TS SDK",
      "one_line_profile": "JavaScript/TypeScript SDK for Langfuse",
      "detailed_description": "The official JavaScript/TypeScript SDK for instrumenting LLM applications with Langfuse tracing and evaluation features.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "tracing"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/langfuse/langfuse-js",
      "help_website": [
        "https://langfuse.com/docs/sdk/typescript"
      ],
      "license": "MIT",
      "tags": [
        "typescript",
        "sdk",
        "observability"
      ],
      "id": 486
    },
    {
      "name": "Langfuse Python SDK",
      "one_line_profile": "Python SDK for Langfuse observability",
      "detailed_description": "The Python SDK for Langfuse, offering decorators and low-level clients to instrument LLM calls, manage prompts, and run evaluations.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "tracing",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/langfuse/langfuse-python",
      "help_website": [
        "https://langfuse.com/docs/sdk/python"
      ],
      "license": "MIT",
      "tags": [
        "python",
        "sdk",
        "observability"
      ],
      "id": 487
    },
    {
      "name": "Langfuse MCP Server",
      "one_line_profile": "Model Context Protocol server for Langfuse",
      "detailed_description": "An MCP server implementation that allows AI agents to directly access and manage Langfuse prompts and context, facilitating agentic workflows and self-management.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "prompt_management",
        "agent_integration"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/langfuse/mcp-server-langfuse",
      "help_website": [
        "https://langfuse.com/"
      ],
      "license": "MIT",
      "tags": [
        "mcp",
        "agent-tool",
        "prompt-engineering"
      ],
      "id": 488
    },
    {
      "name": "LangSmith4j SDK",
      "one_line_profile": "Java client for LangSmith API",
      "detailed_description": "A Java library providing access to the LangSmith API for tracing and evaluating LLM applications, serving as an alternative or experimental SDK for the Java ecosystem.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tracing",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/langgraph4j/langsmith4j-sdk",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "java",
        "sdk",
        "langsmith"
      ],
      "id": 489
    },
    {
      "name": "LangWatch",
      "one_line_profile": "LLM Ops platform for traces, analytics, and evaluations",
      "detailed_description": "An open-source platform for monitoring and evaluating LLM applications. It features tools for tracing execution, analyzing costs and latency, and running evaluations to ensure model quality.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "evaluation",
        "analytics"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/langwatch/langwatch",
      "help_website": [
        "https://docs.langwatch.ai/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "llm-ops",
        "tracing",
        "evaluation"
      ],
      "id": 490
    },
    {
      "name": "Latitude LLM",
      "one_line_profile": "Prompt engineering and evaluation platform",
      "detailed_description": "An open-source platform designed to build, evaluate, and refine prompts using AI. It provides a collaborative environment for managing prompt versions and running evaluations against datasets.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "prompt_engineering",
        "evaluation"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/latitude-dev/latitude-llm",
      "help_website": [
        "https://docs.latitude.so/"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "prompt-engineering",
        "evaluation",
        "collaboration"
      ],
      "id": 491
    },
    {
      "name": "Les Audits Affaires Eval Harness",
      "one_line_profile": "Evaluation harness for French legal LLMs",
      "detailed_description": "A lightweight Python CLI tool for benchmarking French Language Models specifically on business law tasks, evaluating metrics like actionability, delay estimation, and risk assessment.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/legml-ai/les-audits-affaires-eval-harness",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "legal-tech",
        "evaluation",
        "llm-benchmark"
      ],
      "id": 492
    },
    {
      "name": "Codex Subagents MCP",
      "one_line_profile": "MCP server for orchestrating coding sub-agents",
      "detailed_description": "A tool that extends the Codex CLI with sub-agents (reviewer, debugger, security) via the Model Context Protocol, enabling isolated execution contexts for regression testing and code verification.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_orchestration",
        "regression_testing"
      ],
      "application_level": "service",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/leonardsellem/codex-subagents-mcp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "coding-agent",
        "debugging"
      ],
      "id": 493
    },
    {
      "name": "LLMKit",
      "one_line_profile": "Prompt management and evaluation toolkit",
      "detailed_description": "A toolkit and inference server for prompt management, versioning, testing, and evaluation. It offers an OpenAI-compatible API to streamline the development and assessment of LLM applications.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "prompt_management",
        "evaluation",
        "inference"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/llmkit-ai/llmkit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rust",
        "prompt-engineering",
        "evaluation"
      ],
      "id": 494
    },
    {
      "name": "RouteLLM",
      "one_line_profile": "Framework for serving and evaluating LLM routers",
      "detailed_description": "A framework designed to evaluate and serve LLM routers, enabling researchers to optimize the trade-off between cost and quality by dynamically selecting models based on query complexity.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_routing",
        "evaluation",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lm-sys/RouteLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-routing",
        "cost-optimization",
        "evaluation"
      ],
      "id": 495
    },
    {
      "name": "Logikon",
      "one_line_profile": "Tool for analyzing and scoring LLM reasoning traces",
      "detailed_description": "A Python tool for analyzing the reasoning capabilities of Large Language Models by scoring their execution traces, helping to evaluate logical consistency and inference quality.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "reasoning_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/logikon-ai/logikon",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "reasoning",
        "evaluation",
        "trace-analysis"
      ],
      "id": 496
    },
    {
      "name": "Agent Studio",
      "one_line_profile": "Environments and benchmarks for virtual agents",
      "detailed_description": "A comprehensive platform providing environments, tools, and benchmarks for evaluating general virtual agents. It supports the development and assessment of agents across various tasks and modalities.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmarking",
        "agent_evaluation",
        "environment_simulation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ltzheng/agent-studio",
      "help_website": [
        "https://arxiv.org/abs/2403.17918"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "agent-benchmark",
        "virtual-environment",
        "evaluation"
      ],
      "id": 497
    },
    {
      "name": "FlowLens MCP Server",
      "one_line_profile": "MCP server for debugging and regression testing of coding agents",
      "detailed_description": "An open-source Model Context Protocol server that provides coding agents with browser context, enabling in-depth debugging and regression testing of web-based tasks and agent behaviors.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "debugging",
        "regression_testing",
        "agent_tool"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/magentic/flowlens-mcp-server",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mcp",
        "debugging",
        "regression-testing"
      ],
      "id": 498
    },
    {
      "name": "AgC (Open Agentic Compute)",
      "one_line_profile": "Platform for deploying and orchestrating AI agents",
      "detailed_description": "An open-core platform designed as a compute substrate for deploying, running, and orchestrating AI agents at scale, providing necessary infrastructure for agentic workflows.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_orchestration",
        "deployment"
      ],
      "application_level": "platform",
      "primary_language": "Kotlin",
      "repo_url": "https://github.com/masaic-ai-platform/AgC",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent-orchestration",
        "compute-platform"
      ],
      "id": 499
    },
    {
      "name": "Mastra",
      "one_line_profile": "TypeScript AI agent framework with observability",
      "detailed_description": "A TypeScript framework for building AI agents, featuring built-in support for RAG, observability, and workflow orchestration, compatible with multiple LLM providers.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_framework",
        "observability",
        "rag"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/mastra-ai/mastra",
      "help_website": [
        "https://mastra.ai/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "typescript",
        "agent-framework",
        "observability"
      ],
      "id": 500
    },
    {
      "name": "Evalite",
      "one_line_profile": "Lightweight evaluation library for LLM apps in TypeScript",
      "detailed_description": "A TypeScript library for evaluating LLM-powered applications, providing tools to define metrics and run assessments on model outputs.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/mattpocock/evalite",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "typescript",
        "evaluation",
        "llm"
      ],
      "id": 501
    },
    {
      "name": "CoNLI",
      "one_line_profile": "Framework for ungrounded hallucination detection and reduction in LLMs",
      "detailed_description": "CoNLI is a plug-and-play framework designed to detect and reduce ungrounded hallucinations in Large Language Models, enhancing the reliability of AI agents in scientific text generation.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/CoNLI_hallucination",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "llm-evaluation",
        "nlp"
      ],
      "id": 502
    },
    {
      "name": "HaDes",
      "one_line_profile": "Token-level reference-free hallucination detection for LLMs",
      "detailed_description": "HaDes provides a method for detecting hallucinations in generated text at the token level without requiring reference texts, useful for validating scientific content generated by AI.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/HaDes",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination-detection",
        "llm",
        "verification"
      ],
      "id": 503
    },
    {
      "name": "SmartPlay",
      "one_line_profile": "Benchmark suite for evaluating LLM agent capabilities via games",
      "detailed_description": "SmartPlay is a benchmark designed to test various capabilities of Large Language Models as agents, such as planning and reasoning, which are foundational for scientific agent development.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/SmartPlay",
      "help_website": [],
      "license": "CC-BY-4.0",
      "tags": [
        "benchmark",
        "llm-agents",
        "reasoning"
      ],
      "id": 504
    },
    {
      "name": "Windows Agent Arena",
      "one_line_profile": "Scalable platform for benchmarking multi-modal AI agents on OS environments",
      "detailed_description": "Windows Agent Arena (WAA) provides a scalable environment for testing and benchmarking multi-modal AI agents, enabling reproducible evaluation of agent performance in realistic OS interactions.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmarking",
        "agent_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/WindowsAgentArena",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "multi-modal-agents",
        "evaluation"
      ],
      "id": 505
    },
    {
      "name": "micronaire",
      "one_line_profile": "RAG evaluation pipeline for Semantic Kernel applications",
      "detailed_description": "Micronaire is a tool designed to evaluate Retrieval-Augmented Generation (RAG) pipelines built with Semantic Kernel, assessing the quality and relevance of retrieved information and generated responses.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "pipeline_optimization"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/microsoft/micronaire",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "semantic-kernel"
      ],
      "id": 506
    },
    {
      "name": "Promptflow",
      "one_line_profile": "Development tool for building, testing, and evaluating LLM applications",
      "detailed_description": "Promptflow is a suite of development tools designed to streamline the development cycle of LLM-based applications, from prototyping and testing to evaluation and deployment.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "prompt_engineering",
        "evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/promptflow",
      "help_website": [
        "https://microsoft.github.io/promptflow/"
      ],
      "license": "MIT",
      "tags": [
        "llmops",
        "workflow",
        "evaluation"
      ],
      "id": 507
    },
    {
      "name": "PromptPex",
      "one_line_profile": "Test generation tool for LLM prompts",
      "detailed_description": "PromptPex focuses on generating test cases for prompts, aiding in the systematic evaluation and refinement of prompts used in AI applications.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "prompt_testing",
        "test_generation"
      ],
      "application_level": "library",
      "primary_language": "TeX",
      "repo_url": "https://github.com/microsoft/promptpex",
      "help_website": [],
      "license": "CC-BY-4.0",
      "tags": [
        "prompt-engineering",
        "testing",
        "llm"
      ],
      "id": 508
    },
    {
      "name": "Prompty",
      "one_line_profile": "Asset class and format for managing and evaluating LLM prompts",
      "detailed_description": "Prompty provides a standardized format and tooling to create, manage, debug, and evaluate LLM prompts, enhancing observability and portability in AI development.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "prompt_management",
        "observability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/prompty",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-engineering",
        "observability",
        "developer-tools"
      ],
      "id": 509
    },
    {
      "name": "RAG Experiment Accelerator",
      "one_line_profile": "Tool for conducting and evaluating RAG experiments",
      "detailed_description": "The RAG Experiment Accelerator facilitates the process of running experiments and evaluations on Retrieval-Augmented Generation patterns, helping optimize search and retrieval strategies.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "rag_optimization",
        "experimentation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/rag-experiment-accelerator",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "experimentation",
        "azure-search"
      ],
      "id": 510
    },
    {
      "name": "RAGTune",
      "one_line_profile": "Tool for tuning and evaluating RAG pipelines",
      "detailed_description": "RAGTune provides capabilities for the tuning and evaluation of Retrieval-Augmented Generation pipelines, aiming to automate the optimization of retrieval strategies.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "rag_tuning",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/misbahsy/RAGTune",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "optimization",
        "tuning"
      ],
      "id": 511
    },
    {
      "name": "TorchCP",
      "one_line_profile": "Conformal prediction toolbox for PyTorch deep learning models",
      "detailed_description": "TorchCP is a Python toolbox for conformal prediction, providing statistical guarantees of uncertainty for deep learning models, which is critical for scientific reliability.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "uncertainty_quantification",
        "statistical_inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ml-stat-Sustech/TorchCP",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "conformal-prediction",
        "uncertainty",
        "pytorch"
      ],
      "id": 512
    },
    {
      "name": "EvalScope",
      "one_line_profile": "Framework for large model evaluation and benchmarking",
      "detailed_description": "EvalScope is a customizable framework for evaluating and benchmarking large language models and multi-modal models, supporting efficient performance assessment.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/modelscope/evalscope",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "evaluation",
        "benchmark",
        "llm"
      ],
      "id": 513
    },
    {
      "name": "MyScale Telemetry",
      "one_line_profile": "Observability library for LLM applications",
      "detailed_description": "MyScale Telemetry provides open-source observability solutions for LLM applications, enabling tracing and monitoring of AI agent interactions.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "tracing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/myscale/myscale-telemetry",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "observability",
        "llm",
        "tracing"
      ],
      "id": 514
    },
    {
      "name": "Hallucination Probes",
      "one_line_profile": "Real-time detection of hallucinated entities in long-form generation",
      "detailed_description": "This tool provides probes for detecting hallucinated entities in real-time during long-form text generation, aiding in the verification of AI-generated content.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "verification"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/obalcells/hallucination_probes",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "nlp",
        "detection"
      ],
      "id": 515
    },
    {
      "name": "LLM Proteomics Hallucination",
      "one_line_profile": "Evaluation framework for hallucination risks in proteomics LLMs",
      "detailed_description": "A systematic evaluation framework designed to detect and benchmark hallucination risks in Large Language Models specifically applied to clinical proteomics and mass spectrometry interpretation.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "domain_specific_evaluation",
        "hallucination_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/olaflaitinen/llm-proteomics-hallucination",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "proteomics",
        "hallucination",
        "bioinformatics"
      ],
      "id": 516
    },
    {
      "name": "VLMEvalKit",
      "one_line_profile": "Evaluation toolkit for large multi-modality models",
      "detailed_description": "VLMEvalKit is an open-source toolkit for evaluating large multi-modality models (LMMs), supporting a wide range of models and benchmarks to assess performance across various tasks.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/open-compass/VLMEvalKit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vlm",
        "evaluation",
        "benchmark"
      ],
      "id": 517
    },
    {
      "name": "OpenCompass",
      "one_line_profile": "Comprehensive LLM evaluation platform",
      "detailed_description": "OpenCompass is a platform for evaluating Large Language Models across a wide range of datasets and capabilities, providing a standardized way to benchmark model performance.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/open-compass/opencompass",
      "help_website": [
        "https://opencompass.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "benchmark",
        "nlp"
      ],
      "id": 518
    },
    {
      "name": "OpenAI Evals",
      "one_line_profile": "Framework for evaluating LLMs and LLM systems",
      "detailed_description": "Evals is a framework for evaluating Large Language Models and systems, providing a registry of benchmarks and tools to measure performance on various tasks.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/openai/evals",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "evaluation",
        "llm",
        "benchmark"
      ],
      "id": 519
    },
    {
      "name": "MLE-bench",
      "one_line_profile": "Benchmark for AI agents in machine learning engineering",
      "detailed_description": "MLE-bench is a benchmark designed to measure how well AI agents perform at machine learning engineering tasks, evaluating their ability to act as autonomous researchers/engineers.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/openai/mle-bench",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "benchmark",
        "ai-agents",
        "ml-engineering"
      ],
      "id": 520
    },
    {
      "name": "OHR-Bench",
      "one_line_profile": "Benchmark for evaluating OCR impact on RAG systems",
      "detailed_description": "OHR-Bench evaluates the cascading impact of Optical Character Recognition (OCR) quality on Retrieval-Augmented Generation (RAG) systems, critical for processing scientific literature.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "ocr_benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/opendatalab/OHR-Bench",
      "help_website": [],
      "license": null,
      "tags": [
        "ocr",
        "rag",
        "benchmark"
      ],
      "id": 521
    },
    {
      "name": "OpenLIT",
      "one_line_profile": "OpenTelemetry-native observability platform for AI engineering",
      "detailed_description": "OpenLIT is an observability platform for AI engineering that provides monitoring, guardrails, and evaluations for LLM applications, integrating with OpenTelemetry.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "monitoring",
        "evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/openlit/openlit",
      "help_website": [
        "https://docs.openlit.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "observability",
        "opentelemetry",
        "llmops"
      ],
      "id": 522
    },
    {
      "name": "Oumi",
      "one_line_profile": "Platform for fine-tuning, evaluating, and deploying open-source LLMs",
      "detailed_description": "Oumi is an open-source platform designed to simplify the lifecycle of Large Language Models (LLMs). It provides tools for fine-tuning, evaluating, and deploying models like Llama, Mistral, and others. It supports various training recipes and evaluation benchmarks, facilitating research into model performance and adaptation.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "fine_tuning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/oumi-ai/oumi",
      "help_website": [
        "https://oumi.ai/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "fine-tuning",
        "evaluation",
        "inference"
      ],
      "id": 523
    },
    {
      "name": "Voice Devtools",
      "one_line_profile": "Debugging and development tools for realtime voice agents",
      "detailed_description": "Voice Devtools provides a suite of utilities for developers building and debugging real-time voice AI agents. It allows for the inspection of audio streams, latency analysis, and interaction tracing, which are critical for optimizing the performance of voice-based AI systems.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "debugging",
        "tracing"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/outspeed-ai/voice-devtools",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "voice-agent",
        "debugging",
        "realtime",
        "devtools"
      ],
      "id": 524
    },
    {
      "name": "SMAC",
      "one_line_profile": "The StarCraft Multi-Agent Challenge benchmark for reinforcement learning",
      "detailed_description": "SMAC (StarCraft Multi-Agent Challenge) is a benchmark environment for research in Multi-Agent Reinforcement Learning (MARL). It leverages the StarCraft II game engine to create complex scenarios requiring cooperative micromanagement, serving as a standard testbed for evaluating MARL algorithms.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmark",
        "reinforcement_learning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/oxwhirl/smac",
      "help_website": [
        "https://github.com/oxwhirl/smac"
      ],
      "license": "MIT",
      "tags": [
        "marl",
        "benchmark",
        "starcraft",
        "reinforcement-learning"
      ],
      "id": 525
    },
    {
      "name": "Pallma Guard",
      "one_line_profile": "Security and evaluation framework for AI agents",
      "detailed_description": "Pallma Guard provides lifecycle security tools for AI agents, including proactive red teaming, real-time threat detection, and automated remediation. It serves as an evaluation and hardening tool to ensure the robustness and safety of agentic systems.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "security_evaluation",
        "red_teaming"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/pallma-ai/pallma-guard",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-security",
        "red-teaming",
        "agent-evaluation"
      ],
      "id": 526
    },
    {
      "name": "MCP Server GDB",
      "one_line_profile": "Model Context Protocol server for GDB debugging",
      "detailed_description": "This tool implements a Model Context Protocol (MCP) server that exposes GDB (GNU Debugger) capabilities to AI agents. It enables LLMs to perform debugging tasks on C/C++ executables, facilitating automated code analysis and error correction in scientific computing workflows.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "debugging",
        "tool_calling"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/pansila/mcp_server_gdb",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "gdb",
        "debugging",
        "agent-tool"
      ],
      "id": 527
    },
    {
      "name": "VideoHallucer",
      "one_line_profile": "Benchmark for hallucination detection in large video-language models",
      "detailed_description": "VideoHallucer is a comprehensive benchmark designed to evaluate and detect hallucinations in Large Video-Language Models (LVLMs). It provides datasets and evaluation metrics to assess the factual consistency of model outputs against video content.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "benchmark"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/patrick-tssn/VideoHallucer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "video-llm",
        "hallucination",
        "benchmark",
        "evaluation"
      ],
      "id": 528
    },
    {
      "name": "OpenTelemetry MCP Server",
      "one_line_profile": "MCP Server enabling LLMs to query OpenTelemetry data",
      "detailed_description": "This tool provides a Model Context Protocol (MCP) server that connects LLMs to OpenTelemetry data sources. It allows AI agents to retrieve and analyze telemetry data (traces, metrics, logs), facilitating automated observability and debugging of complex systems.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "tool_calling"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/pavolloffay/opentelemetry-mcp-server",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "opentelemetry",
        "mcp",
        "llm-agent",
        "observability"
      ],
      "id": 529
    },
    {
      "name": "Dify Promptfoo",
      "one_line_profile": "Integration tool to evaluate Dify assistants using Promptfoo",
      "detailed_description": "This utility bridges Dify (an LLM app development platform) and Promptfoo (an evaluation tool), enabling developers to run automated evaluations and red-teaming tests on Dify-based AI assistants.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "integration"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/perzeuss/dify-promptfoo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dify",
        "promptfoo",
        "evaluation",
        "llm-ops"
      ],
      "id": 530
    },
    {
      "name": "Pezzo",
      "one_line_profile": "LLMOps platform for prompt management, observability, and evaluation",
      "detailed_description": "Pezzo is an open-source LLMOps platform that provides tools for prompt design, version control, and observability. It includes features for tracing LLM executions and troubleshooting issues, supporting the development and evaluation of reliable AI applications.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "llm_ops",
        "observability",
        "prompt_management"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/pezzolabs/pezzo",
      "help_website": [
        "https://docs.pezzo.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llmops",
        "observability",
        "prompt-engineering",
        "evaluation"
      ],
      "id": 531
    },
    {
      "name": "SelfCheckGPT",
      "one_line_profile": "Zero-resource black-box hallucination detection for LLMs",
      "detailed_description": "SelfCheckGPT is a tool for detecting hallucinations in Generative Large Language Models. It uses a zero-resource, black-box approach to assess the factual consistency of generated text by checking for internal consistency across multiple sampled responses.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/potsawee/selfcheckgpt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "llm",
        "evaluation",
        "consistency-check"
      ],
      "id": 532
    },
    {
      "name": "Promptimize",
      "one_line_profile": "Prompt engineering evaluation and testing toolkit",
      "detailed_description": "Promptimize is a toolkit designed for evaluating and testing prompt engineering workflows. It allows developers to systematically test prompts against various models and datasets to optimize performance and ensure reliability.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "prompt_evaluation",
        "testing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/preset-io/promptimize",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "prompt-engineering",
        "evaluation",
        "testing"
      ],
      "id": 533
    },
    {
      "name": "Prometheus Eval",
      "one_line_profile": "LLM response evaluation using Prometheus and GPT-4",
      "detailed_description": "Prometheus Eval is a library for evaluating Large Language Model responses. It leverages the Prometheus model (and others like GPT-4) to provide fine-grained feedback and scoring on generated text, aiding in the assessment of model quality.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "scoring"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/prometheus-eval/prometheus-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "prometheus",
        "feedback"
      ],
      "id": 534
    },
    {
      "name": "PS Fuzz",
      "one_line_profile": "System prompt hardening and security testing tool",
      "detailed_description": "PS Fuzz is a security tool designed to test and harden system prompts for GenAI applications. It performs fuzzing and red-teaming to identify vulnerabilities and improve the robustness of prompt defenses.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "security_testing",
        "prompt_hardening"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/prompt-security/ps-fuzz",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "security",
        "fuzzing",
        "prompt-injection",
        "red-teaming"
      ],
      "id": 535
    },
    {
      "name": "Promptfoo",
      "one_line_profile": "CLI tool for testing and evaluating LLM prompts and agents",
      "detailed_description": "Promptfoo is a CLI tool and library for testing, evaluating, and red-teaming LLM prompts, agents, and RAG pipelines. It supports comparing performance across multiple models (GPT, Claude, Llama) using declarative configuration files, making it essential for systematic AI research and development.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "red_teaming",
        "testing"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/promptfoo/promptfoo",
      "help_website": [
        "https://www.promptfoo.dev/"
      ],
      "license": "MIT",
      "tags": [
        "llm-eval",
        "red-teaming",
        "prompt-testing",
        "cli"
      ],
      "id": 536
    },
    {
      "name": "VMAS",
      "one_line_profile": "Vectorized Multi-Agent Simulator for Reinforcement Learning",
      "detailed_description": "VMAS (Vectorized Multi-Agent Simulator) is a differentiable, vectorized physics engine and simulator designed for efficient benchmarking of Multi-Agent Reinforcement Learning (MARL) algorithms. It runs on PyTorch, enabling high-throughput simulation for research.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "simulation",
        "reinforcement_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/proroklab/VectorizedMultiAgentSimulator",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "marl",
        "simulator",
        "pytorch",
        "physics-engine"
      ],
      "id": 537
    },
    {
      "name": "Raga LLM Hub",
      "one_line_profile": "Framework for LLM evaluation, guardrails, and security",
      "detailed_description": "Raga LLM Hub is a framework designed for the evaluation and security of Large Language Models. It includes tools for setting up guardrails and assessing model performance against safety and quality metrics.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "security_guardrails"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/raga-ai-hub/raga-llm-hub",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm-eval",
        "guardrails",
        "security"
      ],
      "id": 538
    },
    {
      "name": "Agent-o-rama",
      "one_line_profile": "End-to-end LLM agent platform for Java and Clojure",
      "detailed_description": "Agent-o-rama is a platform for building, tracing, testing, and monitoring LLM agents in Java and Clojure. It provides integrated storage and deployment capabilities, facilitating the development and evaluation of agentic workflows.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "agent_platform",
        "tracing",
        "testing"
      ],
      "application_level": "platform",
      "primary_language": "Clojure",
      "repo_url": "https://github.com/redplanetlabs/agent-o-rama",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-agent",
        "clojure",
        "tracing",
        "platform"
      ],
      "id": 539
    },
    {
      "name": "Continuous Eval",
      "one_line_profile": "Data-driven evaluation framework for LLM applications",
      "detailed_description": "Continuous Eval is a framework for the systematic evaluation of LLM-powered applications. It provides metrics and pipelines to assess the quality of retrieval (RAG) and generation, enabling data-driven improvements in AI systems.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "rag_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/relari-ai/continuous-eval",
      "help_website": [
        "https://docs.relari.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-eval",
        "rag",
        "metrics"
      ],
      "id": 540
    },
    {
      "name": "Regenie",
      "one_line_profile": "Whole genome regression modelling for large-scale GWAS",
      "detailed_description": "Regenie is a C++ program for whole genome regression modeling. It is designed for large-scale genome-wide association studies (GWAS), capable of handling hundreds of thousands of samples and millions of variants efficiently.",
      "domains": [
        "AI5",
        "Bioinformatics"
      ],
      "subtask_category": [
        "regression_modeling",
        "gwas"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/rgcgithub/regenie",
      "help_website": [
        "https://rgcgithub.github.io/regenie/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "gwas",
        "genetics",
        "regression",
        "bioinformatics"
      ],
      "id": 541
    },
    {
      "name": "Auto Evaluator",
      "one_line_profile": "Evaluation tool for LLM QA chains",
      "detailed_description": "Auto Evaluator is a tool designed to assess the performance of LLM-based Question Answering (QA) chains. It automates the process of generating test cases and scoring responses, helping researchers optimize RAG pipelines.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "qa_evaluation",
        "rag_testing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/rlancemartin/auto-evaluator",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-qa",
        "evaluation",
        "rag"
      ],
      "id": 542
    },
    {
      "name": "SISSO",
      "one_line_profile": "Data-driven symbolic regression method for materials science",
      "detailed_description": "A code implementing the SISSO (Sure Independence Screening and Sparsifying Operator) method, which combines symbolic regression and compressed sensing to discover accurate and interpretable physical models/descriptors from data.",
      "domains": [
        "Materials Science",
        "Physics",
        "AI4S"
      ],
      "subtask_category": [
        "symbolic_regression",
        "feature_selection",
        "scientific_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/rouyang2017/SISSO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "symbolic-regression",
        "materials-science",
        "compressed-sensing"
      ],
      "id": 543
    },
    {
      "name": "sctransform",
      "one_line_profile": "Normalization and variance stabilization for single-cell UMI data",
      "detailed_description": "An R package for modeling single-cell UMI expression data using regularized negative binomial regression. It is widely used in single-cell genomics for data normalization and variance stabilization.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "normalization",
        "variance_stabilization",
        "single_cell_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/satijalab/sctransform",
      "help_website": [
        "https://github.com/satijalab/sctransform"
      ],
      "license": "GPL-3.0",
      "tags": [
        "single-cell",
        "normalization",
        "bioinformatics"
      ],
      "id": 544
    },
    {
      "name": "multiagent_mujoco",
      "one_line_profile": "Benchmark for Continuous Multi-Agent Robotic Control",
      "detailed_description": "A benchmark environment for continuous multi-agent robotic control based on OpenAI's MuJoCo physics engine. It enables research into multi-agent reinforcement learning in physically simulated environments.",
      "domains": [
        "Robotics",
        "Physics Simulation",
        "AI5"
      ],
      "subtask_category": [
        "simulation",
        "multi_agent_control",
        "benchmark"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/schroederdewitt/multiagent_mujoco",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mujoco",
        "multi-agent",
        "robotics",
        "simulation"
      ],
      "id": 545
    },
    {
      "name": "OpenCE",
      "one_line_profile": "Toolkit for evaluating LLM context strategies",
      "detailed_description": "Open Context Engineering (OpenCE) is a community toolkit to implement, evaluate, and combine LLM context strategies such as RAG, ACE, and Compression. It supports the scientific evaluation of LLM performance in context-heavy tasks.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "context_engineering",
        "rag_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sci-m-wang/OpenCE",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-evaluation",
        "rag",
        "context-engineering"
      ],
      "id": 546
    },
    {
      "name": "frai",
      "one_line_profile": "Toolkit for responsible AI evaluation and documentation",
      "detailed_description": "An open-source toolkit for responsible AI that provides CLI and SDK tools to scan code, collect evidence, and generate model cards, risk files, and evaluations, supporting the governance of AI research.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "responsible_ai",
        "evaluation",
        "documentation"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/sebuzdugan/frai",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "responsible-ai",
        "evaluation",
        "model-cards"
      ],
      "id": 547
    },
    {
      "name": "funcchain",
      "one_line_profile": "Pythonic framework for building cognitive systems",
      "detailed_description": "A pythonic framework for building cognitive systems and AI agents. It facilitates the creation of complex workflows and agentic behaviors, serving as a foundational tool for AI research agents.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "agent_framework",
        "workflow_orchestration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shroominic/funcchain",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ai-agents",
        "pythonic",
        "cognitive-systems"
      ],
      "id": 548
    },
    {
      "name": "tau2-bench",
      "one_line_profile": "Benchmark for evaluating conversational agents",
      "detailed_description": "τ²-Bench is a benchmark for evaluating conversational agents in a dual-control environment, focusing on the agent's ability to handle complex interactions and control tasks.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "benchmark",
        "conversational_agents"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/sierra-research/tau2-bench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "benchmark",
        "conversational-agents",
        "evaluation"
      ],
      "id": 549
    },
    {
      "name": "sim",
      "one_line_profile": "Platform to build and deploy AI agent workflows",
      "detailed_description": "An open-source platform designed to build, deploy, and manage AI agent workflows. It provides the infrastructure for orchestrating complex agent interactions.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "agent_deployment",
        "platform"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/simstudioai/sim",
      "help_website": [
        "https://simstudio.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ai-agents",
        "workflow",
        "deployment"
      ],
      "id": 550
    },
    {
      "name": "SonAgent",
      "one_line_profile": "Self-repairing autonomous agent framework",
      "detailed_description": "A self-repairing autonomous agent framework that uses Large Language Models (LLM) for code generation, self-editing, and self-debugging, enabling resilient agentic workflows.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "autonomous_agent",
        "self_repair",
        "code_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/sonnhfit/SonAgent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "autonomous-agents",
        "self-repair",
        "llm"
      ],
      "id": 551
    },
    {
      "name": "spring-ai-alibaba-admin",
      "one_line_profile": "Admin console for Spring AI Alibaba agents",
      "detailed_description": "A console supporting tracing, prompt engineering, and evaluation for AI agents developed with Spring AI Alibaba. It provides observability and management capabilities for agent workflows.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tracing",
        "evaluation",
        "prompt_engineering"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/spring-ai-alibaba/spring-ai-alibaba-admin",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "observability",
        "tracing",
        "spring-ai"
      ],
      "id": 552
    },
    {
      "name": "rstanarm",
      "one_line_profile": "Bayesian applied regression modeling via Stan",
      "detailed_description": "An R package that provides an interface to Stan for Bayesian applied regression modeling. It allows users to specify models using standard R formula syntax and estimates them using Bayesian inference.",
      "domains": [
        "Statistics",
        "Data Science",
        "AI4S"
      ],
      "subtask_category": [
        "bayesian_inference",
        "regression_modeling",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/stan-dev/rstanarm",
      "help_website": [
        "https://mc-stan.org/rstanarm/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "bayesian",
        "regression",
        "stan",
        "statistics"
      ],
      "id": 553
    },
    {
      "name": "HELM",
      "one_line_profile": "Holistic Evaluation of Language Models",
      "detailed_description": "A framework for the holistic evaluation of foundation models, including LLMs and multimodal models. It provides a standardized way to assess models across a wide range of metrics and scenarios.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking",
        "metrics_calculation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanford-crfm/helm",
      "help_website": [
        "https://crfm.stanford.edu/helm/latest/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "benchmark",
        "foundation-models"
      ],
      "id": 554
    },
    {
      "name": "ARES",
      "one_line_profile": "Automated Evaluation of RAG Systems",
      "detailed_description": "A tool for the automated evaluation of Retrieval-Augmented Generation (RAG) systems. It helps researchers and developers assess the quality and accuracy of RAG pipelines.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "automated_testing",
        "metrics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanford-futuredata/ARES",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "automated-testing"
      ],
      "id": 555
    },
    {
      "name": "MedAgentBench",
      "one_line_profile": "Benchmark for Medical LLM Agents",
      "detailed_description": "A realistic virtual Electronic Health Record (EHR) environment designed to benchmark Medical LLM Agents. It evaluates the performance of agents in clinical scenarios.",
      "domains": [
        "AI5",
        "AI5-04",
        "Medicine"
      ],
      "subtask_category": [
        "benchmark",
        "medical_ai",
        "agent_evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanfordmlgroup/MedAgentBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-ai",
        "benchmark",
        "ehr"
      ],
      "id": 556
    },
    {
      "name": "Universal_Head_3DMM",
      "one_line_profile": "Complete 3D morphable model of the human head",
      "detailed_description": "A project providing a comprehensive 3D Morphable Model (3DMM) of the human head, including code and models for generating and manipulating 3D head structures, useful in computer vision and graphics research.",
      "domains": [
        "Computer Vision",
        "Graphics",
        "AI4S"
      ],
      "subtask_category": [
        "3d_modeling",
        "morphable_model",
        "face_reconstruction"
      ],
      "application_level": "solver",
      "primary_language": null,
      "repo_url": "https://github.com/steliosploumpis/Universal_Head_3DMM",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "3dmm",
        "face-model",
        "computer-vision"
      ],
      "id": 557
    },
    {
      "name": "rag-genie",
      "one_line_profile": "LLM RAG prototype for testing and evaluation",
      "detailed_description": "A prototype tool to test and evaluate embeddings and chunk splitting strategies for RAG systems using Q&A and evaluations. It aids in optimizing RAG pipelines.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "rag_evaluation",
        "embedding_testing",
        "chunking_strategy"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/stephanj/rag-genie",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "embeddings"
      ],
      "id": 558
    },
    {
      "name": "betterprompt",
      "one_line_profile": "Test suite for LLM prompts",
      "detailed_description": "A testing framework designed specifically for LLM prompts. It allows developers to create test suites to verify the behavior and output quality of prompts before deployment.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "prompt_testing",
        "evaluation",
        "quality_assurance"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/stjordanis/betterprompt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "prompt-engineering",
        "testing",
        "llm"
      ],
      "id": 559
    },
    {
      "name": "ggeffects",
      "one_line_profile": "R package for computing and visualizing estimated marginal means and effects from regression models",
      "detailed_description": "A comprehensive R package designed to compute, visualize, and interpret marginal effects, adjusted predictions, and estimated marginal means from a wide variety of regression models. It facilitates the interpretation of complex statistical models through visualization.",
      "domains": [
        "Statistics",
        "Data Visualization"
      ],
      "subtask_category": [
        "statistical_analysis",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/strengejacke/ggeffects",
      "help_website": [
        "https://strengejacke.github.io/ggeffects/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "r",
        "statistics",
        "visualization",
        "regression",
        "marginal-effects"
      ],
      "id": 560
    },
    {
      "name": "AgentTrace",
      "one_line_profile": "Lightweight observability library to trace and evaluate agentic systems",
      "detailed_description": "A lightweight observability and evaluation library designed specifically for agentic systems. It allows researchers and developers to trace agent execution flows and evaluate performance metrics, facilitating the analysis of complex AI agent behaviors.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "evaluation",
        "tracing"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/tensorstax/agenttrace",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "observability",
        "agents",
        "evaluation",
        "tracing"
      ],
      "id": 561
    },
    {
      "name": "TensorZero",
      "one_line_profile": "Unified platform for LLM observability, optimization, and evaluation",
      "detailed_description": "An industrial-grade open-source stack for Large Language Model applications that unifies gateway functionality, observability, optimization, evaluation, and experimentation. It supports scientific workflows in model performance analysis and optimization.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "evaluation",
        "optimization",
        "experimentation"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/tensorzero/tensorzero",
      "help_website": [
        "https://www.tensorzero.com/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "observability",
        "evaluation",
        "optimization",
        "gateway"
      ],
      "id": 562
    },
    {
      "name": "Safety-Prompts",
      "one_line_profile": "Chinese safety prompts dataset for evaluating LLM safety",
      "detailed_description": "A comprehensive dataset of Chinese safety prompts designed for evaluating and improving the safety of Large Language Models. It covers various risk scenarios including synthetic, adversarial, and in-the-wild prompts.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "safety_testing",
        "dataset"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/thu-coai/Safety-Prompts",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "safety",
        "evaluation",
        "prompts",
        "chinese"
      ],
      "id": 563
    },
    {
      "name": "AgentQL",
      "one_line_profile": "Query language and tooling for AI agent web data extraction",
      "detailed_description": "A suite of tools enabling AI agents to interact with the web and extract data precisely. It features a specialized query language and Playwright integrations, facilitating scientific data collection and environment interaction for agents.",
      "domains": [
        "AI5",
        "Data Acquisition"
      ],
      "subtask_category": [
        "data_extraction",
        "web_automation",
        "query_language"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tinyfish-io/agentql",
      "help_website": [
        "https://docs.agentql.com/"
      ],
      "license": "MIT",
      "tags": [
        "web-scraping",
        "agents",
        "data-extraction",
        "playwright"
      ],
      "id": 564
    },
    {
      "name": "caret",
      "one_line_profile": "Classification and Regression Training package for R",
      "detailed_description": "A comprehensive framework for building classification and regression models in R. It contains tools for data splitting, pre-processing, feature selection, model tuning using resampling, and variable importance estimation.",
      "domains": [
        "Machine Learning",
        "Statistics"
      ],
      "subtask_category": [
        "machine_learning",
        "model_training",
        "regression",
        "classification"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/topepo/caret",
      "help_website": [
        "http://topepo.github.io/caret/index.html"
      ],
      "license": "NOASSERTION",
      "tags": [
        "r",
        "machine-learning",
        "classification",
        "regression",
        "training"
      ],
      "id": 565
    },
    {
      "name": "go-openllmetry",
      "one_line_profile": "OpenTelemetry-based observability for LLM applications in Go",
      "detailed_description": "An open-source observability library for Large Language Model applications written in Go, based on OpenTelemetry standards. It enables tracing and monitoring of LLM interactions for performance analysis and evaluation.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "tracing",
        "monitoring"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/traceloop/go-openllmetry",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "observability",
        "opentelemetry",
        "llm",
        "go",
        "tracing"
      ],
      "id": 566
    },
    {
      "name": "Traceloop Hub",
      "one_line_profile": "High-scale LLM gateway with built-in observability",
      "detailed_description": "A high-performance gateway for Large Language Models written in Rust, featuring built-in OpenTelemetry-based observability. It serves as infrastructure for managing, tracing, and analyzing LLM traffic in research and production environments.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "gateway",
        "tracing"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/traceloop/hub",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "gateway",
        "observability",
        "rust",
        "opentelemetry"
      ],
      "id": 567
    },
    {
      "name": "OpenLLMetry",
      "one_line_profile": "Open-source observability for GenAI and LLM applications",
      "detailed_description": "A comprehensive observability SDK for Generative AI and Large Language Model applications, built on OpenTelemetry. It provides tracing, metrics, and evaluation capabilities to analyze model performance and behavior.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "tracing",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/traceloop/openllmetry",
      "help_website": [
        "https://www.traceloop.com/docs/openllmetry"
      ],
      "license": "Apache-2.0",
      "tags": [
        "observability",
        "opentelemetry",
        "llm",
        "genai",
        "tracing"
      ],
      "id": 568
    },
    {
      "name": "OpenLLMetry-JS",
      "one_line_profile": "OpenTelemetry-based observability for LLM applications in TypeScript",
      "detailed_description": "The TypeScript implementation of OpenLLMetry, providing open-source observability for Large Language Model applications based on OpenTelemetry standards. It facilitates tracing and performance analysis for JS/TS-based AI systems.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "tracing",
        "monitoring"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/traceloop/openllmetry-js",
      "help_website": [
        "https://www.traceloop.com/docs/openllmetry"
      ],
      "license": "Apache-2.0",
      "tags": [
        "observability",
        "opentelemetry",
        "llm",
        "typescript",
        "tracing"
      ],
      "id": 569
    },
    {
      "name": "TransformerLab",
      "one_line_profile": "Application for LLM and Diffusion model engineering and evaluation",
      "detailed_description": "An open-source application designed for advanced engineering of Large Language Models and Diffusion models. It supports workflows for interaction, training, fine-tuning, and evaluation of models on local hardware.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "model_training",
        "fine_tuning",
        "evaluation",
        "inference"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/transformerlab/transformerlab-app",
      "help_website": [
        "https://transformerlab.ai/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "llm",
        "diffusion",
        "fine-tuning",
        "evaluation",
        "training"
      ],
      "id": 570
    },
    {
      "name": "TruLens",
      "one_line_profile": "Evaluation and tracking for LLM experiments and AI agents",
      "detailed_description": "A tool for evaluating and tracking Large Language Model experiments and AI agents. It provides feedback functions to assess the quality of inputs, outputs, and intermediate steps, enabling systematic improvement of AI applications.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "experiment_tracking",
        "quality_assessment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/truera/trulens",
      "help_website": [
        "https://www.trulens.org/"
      ],
      "license": "MIT",
      "tags": [
        "llm",
        "evaluation",
        "agents",
        "tracking",
        "observability"
      ],
      "id": 571
    },
    {
      "name": "CUA (Computer-Use Agents)",
      "one_line_profile": "Infrastructure and benchmarks for evaluating Computer-Use Agents",
      "detailed_description": "An open-source infrastructure providing sandboxes, SDKs, and benchmarks to train and evaluate AI agents capable of controlling full desktop environments (macOS, Linux, Windows). It facilitates rigorous testing of agentic capabilities.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking",
        "training_environment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/trycua/cua",
      "help_website": [
        "https://docs.trycua.com/"
      ],
      "license": "MIT",
      "tags": [
        "agents",
        "evaluation",
        "benchmarking",
        "computer-use",
        "sandbox"
      ],
      "id": 572
    },
    {
      "name": "Orbit",
      "one_line_profile": "Bayesian forecasting with object-oriented design",
      "detailed_description": "A Python package for Bayesian forecasting that uses an object-oriented design and probabilistic models. It provides a flexible interface for specifying and fitting Bayesian time series models for scientific and industrial forecasting tasks.",
      "domains": [
        "Statistics",
        "Time Series Analysis"
      ],
      "subtask_category": [
        "forecasting",
        "bayesian_modeling",
        "time_series"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/uber/orbit",
      "help_website": [
        "https://orbit-ml.readthedocs.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "forecasting",
        "bayesian",
        "time-series",
        "statistics",
        "python"
      ],
      "id": 573
    },
    {
      "name": "Unify",
      "one_line_profile": "Centralized platform for AI model observability and benchmarking",
      "detailed_description": "A platform designed for AI observability, providing tools to benchmark and monitor the performance of various AI models. It acts as a central hub for comparing model metrics and optimizing selection.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "observability",
        "benchmarking",
        "model_selection"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/unifyai/unify",
      "help_website": [
        "https://unify.ai/docs/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "observability",
        "benchmarking",
        "llm",
        "ai"
      ],
      "id": 574
    },
    {
      "name": "Jailjudge",
      "one_line_profile": "Benchmark for evaluating LLM safety against malicious prompts",
      "detailed_description": "A comprehensive evaluation benchmark for assessing the safety of Large Language Models. It includes a wide range of risk scenarios with complex malicious prompts (synthetic, adversarial, multi-language) and high-quality human-annotated datasets.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "safety_benchmarking",
        "dataset"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/usail-hkust/Jailjudge",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "safety",
        "benchmark",
        "evaluation",
        "adversarial"
      ],
      "id": 575
    },
    {
      "name": "Open RAG Eval",
      "one_line_profile": "Reference-free evaluation tool for RAG systems",
      "detailed_description": "A tool for evaluating Retrieval-Augmented Generation (RAG) systems without the need for 'golden answers' (ground truth). It utilizes various metrics to assess the quality of retrieved context and generated responses.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "rag_assessment",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vectara/open-rag-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "llm",
        "metrics"
      ],
      "id": 576
    },
    {
      "name": "Ragas",
      "one_line_profile": "Evaluation framework for Retrieval Augmented Generation (RAG) pipelines",
      "detailed_description": "A framework that provides metrics and tools to evaluate the performance of RAG pipelines, focusing on retrieval and generation quality.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vibrantlabsai/ragas",
      "help_website": [
        "https://docs.ragas.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "llm",
        "metrics"
      ],
      "id": 577
    },
    {
      "name": "vllora",
      "one_line_profile": "Debugging and tracing tool for AI agents",
      "detailed_description": "A tool designed to help developers debug and trace the execution of AI agents, providing insights into their decision-making processes.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tracing",
        "debugging"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/vllora/vllora",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ai-agent",
        "debugging",
        "tracing"
      ],
      "id": 578
    },
    {
      "name": "Weave",
      "one_line_profile": "Toolkit for tracking, tracing, and evaluating AI applications",
      "detailed_description": "A toolkit by Weights & Biases for developing, debugging, and evaluating LLM-based applications, offering tracing and versioning capabilities.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "tracing",
        "evaluation",
        "versioning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/wandb/weave",
      "help_website": [
        "https://wandb.me/weave"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "tracing",
        "evaluation",
        "observability"
      ],
      "id": 579
    },
    {
      "name": "VisualWebArena",
      "one_line_profile": "Benchmark for evaluating multimodal agents on web tasks",
      "detailed_description": "A benchmark designed to evaluate the performance of multimodal agents in realistic web environments, assessing their ability to perform complex tasks.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmarking",
        "evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/web-arena-x/visualwebarena",
      "help_website": [
        "https://jykoh.com/vwa"
      ],
      "license": "MIT",
      "tags": [
        "benchmark",
        "multimodal-agents",
        "web-agents"
      ],
      "id": 580
    },
    {
      "name": "LangKit",
      "one_line_profile": "Toolkit for monitoring and extracting signals from LLM text",
      "detailed_description": "An open-source toolkit for monitoring Large Language Models, extracting signals related to text quality, relevance, and safety from prompts and responses.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "monitoring",
        "quality_control",
        "safety_check"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/whylabs/langkit",
      "help_website": [
        "https://github.com/whylabs/langkit"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-monitoring",
        "observability",
        "metrics"
      ],
      "id": 581
    },
    {
      "name": "AgentTrek",
      "one_line_profile": "Tool for synthesizing agent trajectories using web tutorials",
      "detailed_description": "A tool for synthesizing agent trajectories by guiding replay with web tutorials, useful for generating training data for agents.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "data_generation",
        "simulation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/xlang-ai/AgentTrek",
      "help_website": [],
      "license": null,
      "tags": [
        "agent-training",
        "trajectory-synthesis",
        "data-generation"
      ],
      "id": 582
    },
    {
      "name": "OSWorld",
      "one_line_profile": "Benchmark environment for multimodal agents in real computer OS",
      "detailed_description": "A benchmark for evaluating multimodal agents on open-ended tasks within real computer environments, providing a realistic OS interface.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmarking",
        "evaluation",
        "simulation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/xlang-ai/OSWorld",
      "help_website": [
        "https://os-world.github.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "multimodal-agents",
        "os-environment"
      ],
      "id": 583
    },
    {
      "name": "OSWorld-G",
      "one_line_profile": "Framework for scaling computer-use grounding via UI decomposition",
      "detailed_description": "A framework focused on improving computer-use grounding for agents through UI decomposition and synthesis, aiding in agent training and evaluation.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "data_processing",
        "grounding"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/xlang-ai/OSWorld-G",
      "help_website": [],
      "license": null,
      "tags": [
        "ui-grounding",
        "agent-training",
        "computer-use"
      ],
      "id": 584
    },
    {
      "name": "OpenCUA",
      "one_line_profile": "Foundational framework and environment for computer-use agents",
      "detailed_description": "Open foundations for building and evaluating computer-use agents, providing necessary environments and tools.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "simulation",
        "benchmarking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/xlang-ai/OpenCUA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "computer-use-agents",
        "environment",
        "foundation"
      ],
      "id": 585
    },
    {
      "name": "MultiHop-RAG",
      "one_line_profile": "Dataset and benchmark for evaluating multi-hop retrieval-augmented generation",
      "detailed_description": "A dataset and benchmark designed to evaluate Retrieval-Augmented Generation (RAG) systems on multi-hop reasoning tasks across documents.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/yixuantt/MultiHop-RAG",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "benchmark",
        "multi-hop-reasoning"
      ],
      "id": 586
    },
    {
      "name": "EasyLM",
      "one_line_profile": "Framework for pre-training, fine-tuning, and evaluating LLMs using JAX/Flax",
      "detailed_description": "A one-stop solution for Large Language Models (LLMs) that facilitates pre-training, fine-tuning, evaluating, and serving using JAX/Flax.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "training",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/young-geng/EasyLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "jax",
        "flax",
        "evaluation"
      ],
      "id": 587
    },
    {
      "name": "EasyDetect",
      "one_line_profile": "Framework for detecting hallucinations in LLMs",
      "detailed_description": "An easy-to-use framework designed to detect hallucinations in Large Language Models, aiding in the safety and reliability evaluation of AI models.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "evaluation",
        "safety_check"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/EasyDetect",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination-detection",
        "llm-eval",
        "safety"
      ],
      "id": 588
    },
    {
      "name": "FactCHD",
      "one_line_profile": "Benchmark for fact-conflicting hallucination detection",
      "detailed_description": "A benchmark specifically designed for evaluating Fact-Conflicting Hallucination Detection in LLMs.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmarking",
        "evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/FactCHD",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hallucination",
        "benchmark",
        "fact-checking"
      ],
      "id": 589
    },
    {
      "name": "WorfBench",
      "one_line_profile": "Benchmark for evaluating agentic workflow generation",
      "detailed_description": "A benchmark suite for evaluating the generation of agentic workflows, assessing the planning and execution capabilities of AI agents.",
      "domains": [
        "AI5",
        "AI5-04"
      ],
      "subtask_category": [
        "benchmarking",
        "evaluation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/WorfBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-workflow",
        "benchmark",
        "planning"
      ],
      "id": 590
    },
    {
      "name": "ViDoRAG",
      "one_line_profile": "Visual Document Retrieval-Augmented Generation agent for parsing complex scientific documents",
      "detailed_description": "A visual document retrieval-augmented generation system that employs dynamic iterative reasoning agents to process and retrieve information from visually rich documents (like scientific papers with charts and figures). It addresses the challenge of multimodal information extraction in scientific literature.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "visual_retrieval",
        "multimodal_rag"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Alibaba-NLP/ViDoRAG",
      "help_website": [],
      "license": null,
      "tags": [
        "visual-rag",
        "document-parsing",
        "scientific-literature",
        "agent"
      ],
      "id": 591
    },
    {
      "name": "RAGatouille",
      "one_line_profile": "Library for using ColBERT retrieval models in RAG pipelines",
      "detailed_description": "A library that simplifies the use and training of state-of-the-art late-interaction retrieval methods (ColBERT). It is essential for building high-precision RAG systems for scientific evidence retrieval and citation tracing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "retrieval",
        "evidence_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AnswerDotAI/RAGatouille",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "colbert",
        "retrieval",
        "rag",
        "embedding"
      ],
      "id": 592
    },
    {
      "name": "RAG_Maestro",
      "one_line_profile": "RAG pipeline for reading, summarizing, and quoting scientific papers",
      "detailed_description": "A chatbot application powered by a RAG pipeline specifically designed to read, summarize, and provide accurate quotes from relevant scientific papers, aiding in evidence-based research queries.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "summarization",
        "evidence_citation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/AymenKallala/RAG_Maestro",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "scientific-papers",
        "summarization",
        "citation"
      ],
      "id": 593
    },
    {
      "name": "KG_RAG",
      "one_line_profile": "Knowledge Graph-based Retrieval-Augmented Generation for biomedical tasks",
      "detailed_description": "A framework empowering Large Language Models with Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG), specifically optimized for knowledge-intensive scientific tasks such as biomedical discovery.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "biomedical_inference",
        "rag"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/BaranziniLab/KG_RAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "rag",
        "biomedical",
        "llm"
      ],
      "id": 594
    },
    {
      "name": "ClaimeAI",
      "one_line_profile": "AI-driven fact-checking and claim verification system",
      "detailed_description": "A system built with LangGraph that dissects text into verifiable claims and cross-references them with real-world evidence via web searches to generate accuracy reports, useful for verifying scientific claims or combating misinformation.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "fact_checking",
        "evidence_verification",
        "claim_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/BharathxD/ClaimeAI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fact-checking",
        "langgraph",
        "evidence-retrieval"
      ],
      "id": 595
    },
    {
      "name": "Verbalized Sampling",
      "one_line_profile": "Training-free prompting strategy to mitigate mode collapse in LLMs",
      "detailed_description": "A model-agnostic framework and CLI/API that implements a verbalized sampling strategy to improve the diversity and quality of LLM responses, useful for synthetic data generation and creative scientific writing.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "model_sampling",
        "synthetic_data_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CHATS-lab/verbalized-sampling",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "sampling",
        "prompt-engineering"
      ],
      "id": 596
    },
    {
      "name": "Uniflow",
      "one_line_profile": "LLM-based unstructured data extraction and cleaning tool",
      "detailed_description": "A tool for extracting, cleaning, and transforming text from unstructured data sources like PDFs, Word documents, and HTML into structured formats, facilitating faster R&D and data processing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "data_extraction",
        "text_cleaning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CambioML/uniflow-llm-based-pdf-extraction-text-cleaning-data-clustering",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf-extraction",
        "etl",
        "unstructured-data"
      ],
      "id": 597
    },
    {
      "name": "Text Extract API",
      "one_line_profile": "API for parsing and extracting structured data from documents",
      "detailed_description": "A tool leveraging modern OCRs and LLMs to extract, parse, and anonymize content from documents (PDF, Word, PPTX) into structured JSON or Markdown, suitable for scientific literature processing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "ocr",
        "document_anonymization"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/CatchTheTornado/text-extract-api",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ocr",
        "pdf-parsing",
        "data-extraction"
      ],
      "id": 598
    },
    {
      "name": "Climsight",
      "one_line_profile": "LLM-driven climate information and assessment system",
      "detailed_description": "A climate information system that combines Large Language Models with high-resolution climate model data and scientific literature to generate localized and context-aware climate assessments.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "climate_modeling",
        "literature_review",
        "scientific_assessment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/CliDyn/climsight",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "climate-change",
        "llm",
        "scientific-assessment"
      ],
      "id": 599
    },
    {
      "name": "dsRAG",
      "one_line_profile": "High-performance retrieval engine for unstructured data",
      "detailed_description": "A retrieval engine designed for unstructured data, facilitating efficient indexing and retrieval for RAG applications, applicable to scientific literature and data management.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "retrieval",
        "indexing",
        "unstructured_data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/D-Star-AI/dsRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "retrieval",
        "vector-search"
      ],
      "id": 600
    },
    {
      "name": "DawDreamer",
      "one_line_profile": "Python-based Digital Audio Workstation for audio synthesis and processing",
      "detailed_description": "A library for audio signal processing and synthesis enabling the creation of VST instruments/effects and parameter automation, supporting JAX for differentiable audio research.",
      "domains": [
        "AI4",
        "AI4-01"
      ],
      "subtask_category": [
        "signal_processing",
        "audio_synthesis",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/DBraun/DawDreamer",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "audio-processing",
        "jax",
        "synthesis"
      ],
      "id": 601
    },
    {
      "name": "Strwythura",
      "one_line_profile": "Knowledge graph construction and GraphRAG pipeline",
      "detailed_description": "A tool to construct knowledge graphs from unstructured data sources, implementing entity resolution and an enhanced GraphRAG approach for optimizing AI application outcomes in specific domains.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "rag",
        "entity_resolution"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/DerwenAI/strwythura",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "graphrag",
        "unstructured-data"
      ],
      "id": 602
    },
    {
      "name": "Dewy",
      "one_line_profile": "Knowledge extraction and semantic retrieval system",
      "detailed_description": "An opinionated knowledge extraction and semantic retrieval tool designed for Gen AI applications, streamlining the process of managing and retrieving information from documents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "retrieval",
        "document_management"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/DewyKB/dewy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-extraction",
        "retrieval",
        "rag"
      ],
      "id": 603
    },
    {
      "name": "Doctor Dok",
      "one_line_profile": "Medical document parsing and analysis framework",
      "detailed_description": "A framework for parsing health-related PDFs and images into JSON and leveraging LLMs for analysis, serving as a medical data vault and research tool for medical document processing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "medical_data_parsing",
        "clinical_analysis",
        "ocr"
      ],
      "application_level": "workflow",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/Doctor-One/doctor-dok",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-data",
        "pdf-parsing",
        "healthcare"
      ],
      "id": 604
    },
    {
      "name": "open-parse",
      "one_line_profile": "Improved file parsing and chunking library for LLMs",
      "detailed_description": "A library designed to solve the problem of parsing complex documents (like PDFs) into chunks suitable for LLMs, supporting layout analysis and table extraction, which is critical for scientific literature mining.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_processing",
        "pdf_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Filimoa/open-parse",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-parsing",
        "chunking",
        "rag",
        "ocr"
      ],
      "id": 605
    },
    {
      "name": "paper-qa",
      "one_line_profile": "RAG agent for answering questions from scientific documents with citations",
      "detailed_description": "A library that uses LLMs to answer questions from scientific papers (PDFs/text) with high accuracy, providing citations and evidence grounding, specifically designed for literature review and evidence extraction.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "evidence_extraction",
        "citation_tracing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Future-House/paper-qa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "scientific-qa",
        "citations",
        "literature-review"
      ],
      "id": 606
    },
    {
      "name": "simba",
      "one_line_profile": "Portable Knowledge Management System (KMS) for RAG integration",
      "detailed_description": "A tool designed to manage unstructured data and integrate seamlessly with Retrieval-Augmented Generation (RAG) systems, facilitating the organization and retrieval of knowledge for AI agents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_management",
        "retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/GitHamza0206/simba",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "kms",
        "vector-database",
        "knowledge-graph"
      ],
      "id": 607
    },
    {
      "name": "RAG-Anything",
      "one_line_profile": "All-in-one framework for retrieval-augmented generation",
      "detailed_description": "A comprehensive framework designed to facilitate various RAG tasks, providing a unified interface for different retrieval and generation strategies.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "retrieval",
        "generation"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUDS/RAG-Anything",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "framework",
        "llm"
      ],
      "id": 608
    },
    {
      "name": "detectron2-publaynet",
      "one_line_profile": "Trained Detectron2 models for document layout analysis on PubLayNet",
      "detailed_description": "A collection of trained Detectron2 object detection models specifically fine-tuned on the PubLayNet dataset for document layout analysis. It serves as a specialized solver for extracting structural components (text, figures, tables) from scientific documents and PDFs.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "layout_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JPLeoRX/detectron2-publaynet",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "detectron2",
        "publaynet",
        "document-layout-analysis",
        "pdf-parsing"
      ],
      "id": 609
    },
    {
      "name": "research-agents-3.0",
      "one_line_profile": "Multi-agent system for automated research using Autogen and GPTs",
      "detailed_description": "A framework leveraging Autogen and GPTs to build a swarm of AI researchers. It orchestrates multiple agents to perform comprehensive research tasks, simulating a collaborative scientific research workflow.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "agent_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/JayZeeDesign/research-agents-3.0",
      "help_website": [],
      "license": null,
      "tags": [
        "autogen",
        "research-agents",
        "multi-agent",
        "literature-review"
      ],
      "id": 610
    },
    {
      "name": "TopOpt.jl",
      "one_line_profile": "Topology optimization library for Julia",
      "detailed_description": "A Julia package for binary and continuous, single and multi-material, truss and continuum, 2D and 3D topology optimization on unstructured meshes using automatic differentiation. It is a core tool for engineering design and physics-based modeling.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "topology_optimization",
        "simulation"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaTopOpt/TopOpt.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "topology-optimization",
        "julia",
        "finite-element-analysis",
        "automatic-differentiation"
      ],
      "id": 611
    },
    {
      "name": "LettuceDetect",
      "one_line_profile": "Hallucination detection framework for RAG applications",
      "detailed_description": "A framework designed to detect hallucinations in Retrieval-Augmented Generation (RAG) applications. It provides metrics and methods to ensure the factual consistency and reliability of AI-generated scientific or technical content.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KRLabsOrg/LettuceDetect",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "hallucination-detection",
        "ai-safety",
        "evaluation"
      ],
      "id": 612
    },
    {
      "name": "owl-verbalizer",
      "one_line_profile": "Converts OWL ontologies into human-readable text",
      "detailed_description": "A tool that translates Web Ontology Language (OWL) statements into controlled natural language. This is useful in scientific knowledge management for making complex ontologies (common in biology and chemistry) accessible to researchers.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_representation",
        "ontology_verbalization"
      ],
      "application_level": "library",
      "primary_language": "Prolog",
      "repo_url": "https://github.com/Kaljurand/owl-verbalizer",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "owl",
        "ontology",
        "natural-language-generation",
        "knowledge-graph"
      ],
      "id": 613
    },
    {
      "name": "LeanRAG",
      "one_line_profile": "Knowledge-Graph-Based RAG with Semantic Aggregation",
      "detailed_description": "A framework for Retrieval-Augmented Generation that leverages Knowledge Graphs for semantic aggregation and hierarchical retrieval. It enhances the accuracy of RAG systems in complex scientific domains by structuring retrieved evidence.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag",
        "knowledge_graph"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KnowledgeXLab/LeanRAG",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "knowledge-graph",
        "retrieval",
        "semantic-aggregation"
      ],
      "id": 614
    },
    {
      "name": "RAKG",
      "one_line_profile": "Document-level Retrieval Augmented Knowledge Graph Construction",
      "detailed_description": "A tool for constructing Knowledge Graphs using document-level retrieval augmentation. It facilitates the extraction of structured knowledge from unstructured scientific text, supporting evidence chains and literature analysis.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "information_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/KnowledgeXLab/RAKG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "rag",
        "information-extraction",
        "nlp"
      ],
      "id": 615
    },
    {
      "name": "HyperGraphRAG",
      "one_line_profile": "RAG via Hypergraph-Structured Knowledge Representation",
      "detailed_description": "An advanced RAG framework that uses hypergraph structures to represent complex relationships in knowledge bases. This approach is particularly useful for scientific reasoning where multi-hop and multi-entity relationships are common.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag",
        "knowledge_representation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/LHRLAB/HyperGraphRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hypergraph",
        "rag",
        "knowledge-graph",
        "reasoning"
      ],
      "id": 616
    },
    {
      "name": "Layout-Parser",
      "one_line_profile": "Unified toolkit for deep learning based document image analysis",
      "detailed_description": "A comprehensive toolkit for document image analysis (DIA) using deep learning. It provides a unified interface for various layout detection models, essential for parsing scientific papers (PDFs) and extracting structured data for RAG systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "layout_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Layout-Parser/layout-parser",
      "help_website": [
        "https://layout-parser.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ocr",
        "document-layout-analysis",
        "pdf-parsing",
        "deep-learning"
      ],
      "id": 617
    },
    {
      "name": "local-deep-research",
      "one_line_profile": "Local AI agent for deep research and QA",
      "detailed_description": "An AI research agent capable of performing deep research by searching multiple sources (arXiv, PubMed, web) and local documents. It is designed to run locally, ensuring privacy while aggregating evidence for scientific queries.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "evidence_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LearningCircuit/local-deep-research",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "research-agent",
        "rag",
        "arxiv",
        "pubmed"
      ],
      "id": 618
    },
    {
      "name": "markpdfdown",
      "one_line_profile": "Visual-based PDF to Markdown converter using LLMs",
      "detailed_description": "A tool that converts PDF documents to Markdown format using Large Language Models with visual recognition capabilities. It is essential for preprocessing scientific literature into machine-readable formats for RAG and analysis.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "format_conversion"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/MarkPDFdown/markpdfdown",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf-to-markdown",
        "ocr",
        "document-parsing",
        "llm"
      ],
      "id": 619
    },
    {
      "name": "AutoRAG",
      "one_line_profile": "Automated framework for evaluating and optimizing RAG pipelines",
      "detailed_description": "AutoRAG is a tool designed to automatically evaluate and optimize Retrieval-Augmented Generation (RAG) pipelines. It helps researchers and developers find the optimal RAG configuration for their specific data and use cases, functioning like AutoML for RAG systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_optimization",
        "evaluation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Marker-Inc-Korea/AutoRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "automl",
        "optimization",
        "evaluation"
      ],
      "id": 620
    },
    {
      "name": "go-light-rag",
      "one_line_profile": "Go implementation of LightRAG for graph-enhanced retrieval",
      "detailed_description": "A Go library implementing the LightRAG architecture, which combines vector databases with knowledge graph relationships to improve information retrieval in RAG systems. It is suitable for building efficient, context-aware retrieval systems for scientific knowledge bases.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "retrieval",
        "knowledge_graph"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/MegaGrindStone/go-light-rag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "graph-database",
        "go",
        "retrieval"
      ],
      "id": 621
    },
    {
      "name": "arabic-nougat",
      "one_line_profile": "Fine-tuned Nougat model for parsing Arabic scientific documents",
      "detailed_description": "A specialized implementation of the Nougat (Neural Optical Understanding for Academic Documents) model, fine-tuned for processing and extracting text/formulas from Arabic PDF documents, facilitating the digitization of non-English scientific literature.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "ocr"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MohamedAliRashad/arabic-nougat",
      "help_website": [],
      "license": null,
      "tags": [
        "pdf-parsing",
        "ocr",
        "arabic",
        "scientific-literature"
      ],
      "id": 622
    },
    {
      "name": "summarization-eval",
      "one_line_profile": "Toolkit for reference-free summarization evaluation and hallucination detection",
      "detailed_description": "A Python toolkit for evaluating text summarization quality without reference summaries. It includes metrics for detecting hallucinations, which is critical for verifying the factual consistency of AI-generated scientific summaries.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "evaluation",
        "hallucination_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Muhtasham/summarization-eval",
      "help_website": [],
      "license": null,
      "tags": [
        "summarization",
        "evaluation",
        "hallucination",
        "nlp"
      ],
      "id": 623
    },
    {
      "name": "NVIDIA RAG Blueprint",
      "one_line_profile": "Reference workflow for building enterprise-grade RAG pipelines",
      "detailed_description": "A foundational blueprint by NVIDIA for constructing Retrieval-Augmented Generation (RAG) pipelines. It serves as a reference implementation for researchers and developers to build scalable systems for querying scientific knowledge bases using NVIDIA's AI stack.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "workflow_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA-AI-Blueprints/rag",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "nvidia",
        "pipeline",
        "enterprise"
      ],
      "id": 624
    },
    {
      "name": "ChatRTX",
      "one_line_profile": "Local RAG application leveraging TensorRT-LLM on Windows",
      "detailed_description": "A developer reference project enabling local Retrieval-Augmented Generation (RAG) on Windows PCs powered by NVIDIA RTX GPUs. It allows researchers to perform secure, local document analysis and querying without data leaving the device.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "local_inference",
        "document_qa"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/ChatRTX",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "local-llm",
        "tensorrt-llm",
        "privacy"
      ],
      "id": 625
    },
    {
      "name": "context-aware-rag",
      "one_line_profile": "Library for context-aware RAG with Knowledge Graph integration",
      "detailed_description": "A library designed to enhance RAG systems by ingesting and retrieving information from Knowledge Graphs. It improves the contextual accuracy of answers, which is essential for complex scientific question answering.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_graph",
        "retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/context-aware-rag",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "knowledge-graph",
        "context-aware"
      ],
      "id": 626
    },
    {
      "name": "docext",
      "one_line_profile": "Toolkit for OCR-free unstructured document extraction and benchmarking",
      "detailed_description": "An on-premises toolkit for extracting data from unstructured documents (like PDFs) without relying on traditional OCR. It includes markdown conversion and benchmarking capabilities, useful for processing scientific literature.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "data_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NanoNets/docext",
      "help_website": [
        "https://idp-leaderboard.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "pdf-parsing",
        "data-extraction",
        "benchmark"
      ],
      "id": 627
    },
    {
      "name": "NeumAI",
      "one_line_profile": "Framework for managing large-scale vector embedding pipelines",
      "detailed_description": "A framework for creating and synchronizing vector embeddings at scale. It manages the data infrastructure required for RAG systems, ensuring that scientific knowledge bases are kept up-to-date and searchable.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "embedding_management",
        "data_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/NeumTry/NeumAI",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "embeddings",
        "rag",
        "data-sync"
      ],
      "id": 628
    },
    {
      "name": "RAGDrive",
      "one_line_profile": "RAG application integrating local files and web search",
      "detailed_description": "An open-source application leveraging LlamaIndex to provide RAG capabilities across mobile and desktop platforms. It allows users to query their own documents and integrate web search, supporting literature review workflows.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_qa",
        "retrieval"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/NidumAI-Inc/ragdrive",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "llamaindex",
        "cross-platform"
      ],
      "id": 629
    },
    {
      "name": "nougat-latex-ocr",
      "one_line_profile": "Codebase for fine-tuning and evaluating Nougat image-to-LaTeX models",
      "detailed_description": "A toolkit for training, fine-tuning, and evaluating Nougat-based models, which are specialized in converting scientific document images into LaTeX/Markdown. Essential for digitizing mathematical and scientific content.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NormXU/nougat-latex-ocr",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "latex",
        "ocr",
        "nougat",
        "fine-tuning"
      ],
      "id": 630
    },
    {
      "name": "General-Documents-Layout-parser",
      "one_line_profile": "Layout analysis and parsing tool for Chinese and general documents",
      "detailed_description": "A tool for document layout analysis and parsing, capable of handling complex document structures. It supports the extraction of structured information from PDFs and images, which is a preprocessing step for scientific literature mining.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/OKC13/General-Documents-Layout-parser",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "layout-analysis",
        "ocr",
        "pdf-parsing"
      ],
      "id": 631
    },
    {
      "name": "UltraRAG",
      "one_line_profile": "Low-code framework for building complex RAG pipelines",
      "detailed_description": "A framework designed to simplify the creation of advanced Retrieval-Augmented Generation (RAG) pipelines. It supports modular components for retrieval, generation, and orchestration, facilitating the development of research agents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "workflow_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenBMB/UltraRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "low-code",
        "pipeline",
        "agent"
      ],
      "id": 632
    },
    {
      "name": "InternGPT",
      "one_line_profile": "Interactive multimodal demo platform for image editing and visual reasoning",
      "detailed_description": "An open-source demo platform (iGPT) that integrates multiple vision and language models (DragGAN, ChatGPT, SAM) for interactive image editing and visual reasoning tasks, serving as a workbench for multimodal AI research.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "image_editing",
        "visual_reasoning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/InternGPT",
      "help_website": [
        "http://igpt.opengvlab.com"
      ],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "interactive",
        "visual-reasoning",
        "demo"
      ],
      "id": 633
    },
    {
      "name": "KAG",
      "one_line_profile": "Knowledge Augmented Generation framework for logical reasoning and retrieval",
      "detailed_description": "KAG (Knowledge Augmented Generation) is a framework that combines OpenSPG engine with LLMs to perform logical form-guided reasoning and retrieval. It addresses limitations of vector-based RAG by leveraging professional domain knowledge bases for factual Q&A.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_graph",
        "reasoning",
        "retrieval"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenSPG/KAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "rag",
        "reasoning",
        "openspg"
      ],
      "id": 634
    },
    {
      "name": "OpenThaiRAG",
      "one_line_profile": "RAG framework optimized for Thai language processing",
      "detailed_description": "An open-source RAG framework specifically designed for the Thai language. It integrates vector databases and Thai-optimized LLMs to provide accurate context-aware responses, supporting regional scientific research and information retrieval.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenThaiGPT/openthairag",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "thai",
        "nlp",
        "retrieval"
      ],
      "id": 635
    },
    {
      "name": "Oxen",
      "one_line_profile": "Data version control system for machine learning datasets",
      "detailed_description": "A lightning-fast data version control system designed for structured and unstructured machine learning datasets. It enables reproducible research by managing versions of large datasets (images, text, video) used in scientific AI workflows.",
      "domains": [
        "AI5",
        "AI2"
      ],
      "subtask_category": [
        "data_management",
        "version_control"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/Oxen-AI/Oxen",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-version-control",
        "machine-learning",
        "reproducibility"
      ],
      "id": 636
    },
    {
      "name": "semantic-search",
      "one_line_profile": "Semantic search engine for scientific papers",
      "detailed_description": "A simple yet effective semantic search engine tailored for scientific papers. It allows researchers to perform meaning-based searches across literature collections, improving the discovery of relevant scientific evidence.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_search",
        "retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PathwayCommons/semantic-search",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-search",
        "scientific-literature",
        "nlp"
      ],
      "id": 637
    },
    {
      "name": "Merlin",
      "one_line_profile": "3D Vision-Language Model for Computed Tomography (CT) analysis",
      "detailed_description": "A 3D Vision-Language Model (VLM) designed for medical imaging, specifically Computed Tomography (CT). It leverages structured Electronic Health Records (EHR) and unstructured radiology reports for pretraining, enabling grounded analysis of medical scans.",
      "domains": [
        "AI5-05",
        "Medical AI"
      ],
      "subtask_category": [
        "medical_imaging",
        "vlm",
        "grounding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/StanfordMIMI/Merlin",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-imaging",
        "ct-scan",
        "vlm",
        "multimodal"
      ],
      "id": 638
    },
    {
      "name": "EmbedAnything",
      "one_line_profile": "High-performance embedding pipeline for RAG and search",
      "detailed_description": "A modular and memory-safe inference, ingestion, and indexing pipeline built in Rust. It is designed to handle embedding tasks efficiently, serving as a core infrastructure component for Retrieval-Augmented Generation (RAG) and vector search applications.",
      "domains": [
        "AI5-05"
      ],
      "subtask_category": [
        "embedding",
        "indexing",
        "inference"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/StarlightSearch/EmbedAnything",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rust",
        "embedding",
        "rag",
        "vector-search"
      ],
      "id": 639
    },
    {
      "name": "tonic_validate",
      "one_line_profile": "Evaluation metrics for Retrieval Augmented Generation (RAG) applications",
      "detailed_description": "A library providing metrics and tools to evaluate the quality of responses in RAG applications. It helps in validating the evidence chain and ensuring the accuracy of retrieved information in scientific workflows.",
      "domains": [
        "AI5-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "metrics",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TonicAI/tonic_validate",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "evaluation",
        "metrics",
        "validation"
      ],
      "id": 640
    },
    {
      "name": "PagePlus",
      "one_line_profile": "PAGE XML processing tool for document layout analysis",
      "detailed_description": "A script/tool for processing PAGE XML files, a standard format for document layout analysis. It supports validation, repair, extension, and modification of text regions, facilitating the extraction of structured data from scientific documents.",
      "domains": [
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "layout_analysis",
        "ocr_postprocessing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/UB-Mannheim/PagePlus",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "page-xml",
        "ocr",
        "layout-analysis",
        "document-processing"
      ],
      "id": 641
    },
    {
      "name": "uxarray",
      "one_line_profile": "Xarray extension for unstructured climate and weather data",
      "detailed_description": "An extension to Xarray designed for the analysis and visualization of unstructured grid data, commonly found in climate and global weather modeling. It enables efficient handling of complex scientific datasets.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "climate_analysis",
        "data_visualization",
        "unstructured_grid"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/UXARRAY/uxarray",
      "help_website": [
        "https://uxarray.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "climate-science",
        "xarray",
        "unstructured-grids",
        "geoscience"
      ],
      "id": 642
    },
    {
      "name": "Unstructured",
      "one_line_profile": "ETL pipeline for processing unstructured documents",
      "detailed_description": "A comprehensive ETL solution for transforming complex unstructured documents (PDFs, HTML, etc.) into clean, structured formats suitable for Large Language Models (LLMs). It is a critical component for RAG pipelines involving scientific literature.",
      "domains": [
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "etl",
        "pdf_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Unstructured-IO/unstructured",
      "help_website": [
        "https://unstructured.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "etl",
        "pdf-parsing",
        "rag",
        "preprocessing"
      ],
      "id": 643
    },
    {
      "name": "SimGRAG",
      "one_line_profile": "Knowledge graph driven RAG leveraging similar subgraphs",
      "detailed_description": "A retrieval-augmented generation (RAG) framework that utilizes similar subgraphs within knowledge graphs to enhance information retrieval and generation quality, specifically designed for complex reasoning tasks.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "graph_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/YZ-Cai/SimGRAG",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "knowledge-graph",
        "subgraph-retrieval"
      ],
      "id": 644
    },
    {
      "name": "TableRAG",
      "one_line_profile": "RAG pipeline optimization for tabular data",
      "detailed_description": "A specialized RAG pipeline designed to improve retrieval and generation performance when dealing with tabular data structures, addressing the challenge of extracting information from tables in scientific documents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "table_extraction",
        "structured_data_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/YuhangWuAI/tablerag",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "rag",
        "tabular-data",
        "data-extraction"
      ],
      "id": 645
    },
    {
      "name": "GEM",
      "one_line_profile": "Online globally consistent dense elevation mapping",
      "detailed_description": "A mapping tool for robotics that generates globally consistent dense elevation maps for unstructured terrain, supporting scientific data generation for autonomous navigation and environmental modeling.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "mapping",
        "spatial_modeling"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ZJU-Robotics-Lab/GEM",
      "help_website": [],
      "license": null,
      "tags": [
        "slam",
        "elevation-mapping",
        "robotics"
      ],
      "id": 646
    },
    {
      "name": "Unstract",
      "one_line_profile": "No-code platform for structuring unstructured documents via LLMs",
      "detailed_description": "A platform to launch APIs and ETL pipelines that convert unstructured documents (like PDFs) into structured data using LLMs, essential for scientific literature parsing and data extraction workflows.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "etl",
        "data_structuring"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zipstack/unstract",
      "help_website": [
        "https://unstract.com"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "etl",
        "llm",
        "document-parsing"
      ],
      "id": 647
    },
    {
      "name": "AutoSurveyGPT",
      "one_line_profile": "Automated literature survey assistant using GPT",
      "detailed_description": "An intelligent research assistant that leverages GPT models to automatically find, analyze, and rank relevant academic papers from Google Scholar, streamlining the literature review process.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "citation_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/a554b554/AutoSurveyGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "literature-survey",
        "gpt",
        "automation"
      ],
      "id": 648
    },
    {
      "name": "Deep Lake",
      "one_line_profile": "Database for AI data (vectors, images, text) optimized for LLMs",
      "detailed_description": "A database designed for AI that stores vectors, images, texts, and videos, enabling efficient querying, versioning, and streaming of data to deep learning frameworks, supporting scientific data management.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_management",
        "vector_storage"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/activeloopai/deeplake",
      "help_website": [
        "https://activeloop.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "data-lake",
        "multimodal"
      ],
      "id": 649
    },
    {
      "name": "CompleteSearch",
      "one_line_profile": "Efficient search engine for semi-structured data",
      "detailed_description": "A high-performance search engine from the University of Freiburg designed for semi-structured data, supporting advanced features like semantic search and faceted search on large datasets.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "information_retrieval",
        "semantic_search"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ad-freiburg/completesearch",
      "help_website": [],
      "license": null,
      "tags": [
        "search-engine",
        "semi-structured-data",
        "indexing"
      ],
      "id": 650
    },
    {
      "name": "VARAG",
      "one_line_profile": "Vision-Augmented Retrieval and Generation engine",
      "detailed_description": "A RAG engine that integrates vision capabilities, allowing for the retrieval and generation of information based on visual inputs, enhancing multimodal scientific data analysis.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "multimodal_retrieval",
        "image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/adithya-s-k/VARAG",
      "help_website": [],
      "license": null,
      "tags": [
        "vision-rag",
        "multimodal",
        "retrieval"
      ],
      "id": 651
    },
    {
      "name": "Marker API",
      "one_line_profile": "High-accuracy PDF to Markdown converter",
      "detailed_description": "A deployable API tool for converting PDF documents into Markdown with high accuracy, facilitating the ingestion of scientific papers into RAG pipelines and text analysis workflows.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "document_conversion"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/adithya-s-k/marker-api",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pdf-to-markdown",
        "ocr",
        "document-processing"
      ],
      "id": 652
    },
    {
      "name": "singleCellHaystack",
      "one_line_profile": "Method for finding differentially active genes in single-cell data",
      "detailed_description": "A bioinformatics tool for identifying genes with non-random spatial distributions or differential activity in single-cell transcriptome data without relying on prior clustering.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "gene_expression_analysis",
        "single_cell_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/alexisvdb/singleCellHaystack",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "bioinformatics",
        "single-cell",
        "transcriptomics"
      ],
      "id": 653
    },
    {
      "name": "CCTag",
      "one_line_profile": "Concentric Circle Tag detection library",
      "detailed_description": "A computer vision library for the detection of CCTag markers, used in photogrammetry and robotics for precise localization and calibration.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "marker_detection",
        "photogrammetry"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/alicevision/CCTag",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "computer-vision",
        "fiducial-markers",
        "calibration"
      ],
      "id": 654
    },
    {
      "name": "Science Parse",
      "one_line_profile": "Parser for converting PDF scientific papers into structured JSON",
      "detailed_description": "A tool developed by AllenAI to parse scientific papers in PDF format and extract structured information such as titles, authors, references, and sections, enabling large-scale literature analysis.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "metadata_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/allenai/science-parse",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf-parsing",
        "scientific-literature",
        "allenai"
      ],
      "id": 655
    },
    {
      "name": "Launch",
      "one_line_profile": "Agent Creation Toolkit with RAG and LLMOps integration",
      "detailed_description": "A development environment and toolkit for rapidly constructing intelligent agents, featuring integrated RAG knowledge base management and LLMOps toolchains for research agent deployment.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "agent_development",
        "workflow_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/alphapro-club/Launch",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "agent-framework",
        "rag",
        "llmops"
      ],
      "id": 656
    },
    {
      "name": "CiteEval",
      "one_line_profile": "Principle-Driven Citation Evaluation for Source Attribution",
      "detailed_description": "An evaluation framework from Amazon Science for assessing the quality and accuracy of citations and source attribution in generated text, critical for verifying evidence chains in RAG systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "citation_evaluation",
        "attribution_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/amazon-science/CiteEval",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "citation-analysis",
        "evaluation-metric",
        "rag-evaluation"
      ],
      "id": 657
    },
    {
      "name": "LlamaIndex Omakase RAG",
      "one_line_profile": "Enhanced RAG application construction framework",
      "detailed_description": "A framework built on LlamaIndex and Django to streamline the creation of scalable RAG applications, managing data ingestion and user access for research knowledge bases.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_workflow",
        "knowledge_base_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ammirsm/llamaindex-omakase-rag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "llamaindex",
        "django"
      ],
      "id": 658
    },
    {
      "name": "Mistral-Haystack",
      "one_line_profile": "Integration of Mistral models into Haystack RAG pipelines",
      "detailed_description": "A connector library that enables the use of Mistral AI models within the Haystack framework, facilitating the construction of advanced RAG pipelines for scientific text processing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "model_integration",
        "rag_pipeline"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/anakin87/mistral-haystack",
      "help_website": [],
      "license": null,
      "tags": [
        "haystack",
        "mistral",
        "rag"
      ],
      "id": 659
    },
    {
      "name": "ROSGPT",
      "one_line_profile": "Natural language control for ROS robots via ChatGPT",
      "detailed_description": "A tool bridging ChatGPT and ROS (Robot Operating System) to convert unstructured human language into actionable robotic commands, enabling LLM-driven robot control and interaction.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "robot_control",
        "natural_language_instruction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/aniskoubaa/rosgpt",
      "help_website": [],
      "license": null,
      "tags": [
        "ros",
        "robotics",
        "llm-control"
      ],
      "id": 660
    },
    {
      "name": "RAG Web Browser",
      "one_line_profile": "Apify Actor for scraping web content for RAG pipelines",
      "detailed_description": "A specialized web scraping tool designed to feed LLM applications and RAG pipelines with up-to-date text content from the web, supporting data acquisition for scientific monitoring.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "web_scraping",
        "data_acquisition"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/apify/rag-web-browser",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "scraping",
        "rag",
        "data-ingestion"
      ],
      "id": 661
    },
    {
      "name": "ADK Vertex AI RAG Engine",
      "one_line_profile": "Rapid RAG setup using Google Vertex AI",
      "detailed_description": "A tool for quickly setting up semantic search and RAG agents across documents using Google's ADK and Vertex AI, facilitating the creation of research knowledge assistants.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_setup",
        "semantic_search"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/arjunprabhulal/adk-vertex-ai-rag-engine",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vertex-ai",
        "rag",
        "google-cloud"
      ],
      "id": 662
    },
    {
      "name": "Sycamore",
      "one_line_profile": "LLM-powered search and analytics platform for unstructured data processing",
      "detailed_description": "Sycamore is a framework for building Retrieval Augmented Generation (RAG) applications that specializes in processing complex unstructured data like PDFs and HTML. It provides tools for data cleaning, partitioning, and embedding, making it suitable for scientific literature processing and knowledge extraction.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_processing",
        "pdf_parsing",
        "rag_etl"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aryn-ai/sycamore",
      "help_website": [
        "https://sycamore.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "pdf-parsing",
        "unstructured-data",
        "etl"
      ],
      "id": 663
    },
    {
      "name": "Snappy",
      "one_line_profile": "Vision-language model for region-level knowledge retrieval from documents",
      "detailed_description": "Snappy unifies vision-language late interaction with structured OCR to enable precise region-level knowledge retrieval from documents. It is particularly useful for extracting information from complex scientific document layouts.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "ocr",
        "document_retrieval",
        "layout_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/athrael-soju/Snappy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ocr",
        "vision-language",
        "document-understanding"
      ],
      "id": 664
    },
    {
      "name": "SearchTheArxiv",
      "one_line_profile": "Semantic search engine for arXiv machine learning papers",
      "detailed_description": "The codebase powering a semantic search engine specifically for ML papers on arXiv. It enables researchers to find relevant literature using natural language queries, facilitating literature discovery.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_search",
        "semantic_retrieval"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/augustwester/searchthearxiv",
      "help_website": [
        "https://www.searchthearxiv.com"
      ],
      "license": "GPL-3.0",
      "tags": [
        "arxiv",
        "semantic-search",
        "literature-mining"
      ],
      "id": 665
    },
    {
      "name": "GraphRAG-rs",
      "one_line_profile": "High-performance Rust implementation of GraphRAG for knowledge graph construction",
      "detailed_description": "A Rust implementation of GraphRAG that builds knowledge graphs from documents to enable complex reasoning and retrieval. It supports entity extraction and local LLM integration, useful for structuring scientific knowledge.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "rag",
        "entity_extraction"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/automataIA/graphrag-rs",
      "help_website": [],
      "license": null,
      "tags": [
        "graph-rag",
        "rust",
        "knowledge-graph"
      ],
      "id": 666
    },
    {
      "name": "Ragit",
      "one_line_profile": "Git-like pipeline for managing RAG knowledge bases",
      "detailed_description": "Ragit provides a version-controlled, git-like workflow for managing Retrieval-Augmented Generation (RAG) pipelines. It helps researchers manage and iterate on their knowledge bases and retrieval strategies.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_base_management",
        "rag_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Rust",
      "repo_url": "https://github.com/baehyunsol/ragit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "version-control",
        "pipeline"
      ],
      "id": 667
    },
    {
      "name": "Megatron-DeepSpeed",
      "one_line_profile": "Large-scale transformer language model training framework",
      "detailed_description": "A deep learning framework for training large-scale transformer language models (like BERT and GPT) using model parallelism. It is a fundamental tool for scientific modeling in NLP and foundation model research.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "model_training",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bigscience-workshop/Megatron-DeepSpeed",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "training",
        "deepspeed",
        "transformer"
      ],
      "id": 668
    },
    {
      "name": "Geovista",
      "one_line_profile": "Cartographic rendering and mesh analytics for earth science",
      "detailed_description": "Geovista is a library for cartographic rendering and mesh analytics, powered by PyVista. It is designed for visualizing and analyzing unstructured grids and meshes commonly found in earth science and oceanography.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "scientific_visualization",
        "geospatial_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bjlittle/geovista",
      "help_website": [
        "https://geovista.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "visualization",
        "earth-science",
        "mesh-analytics"
      ],
      "id": 669
    },
    {
      "name": "BABILong",
      "one_line_profile": "Benchmark for evaluating LLM long-context performance",
      "detailed_description": "BABILong is a benchmark designed to evaluate the performance of Large Language Models (LLMs) on long-context tasks using a needle-in-a-haystack approach. It helps in analyzing model capabilities for processing extensive scientific texts.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "model_evaluation",
        "benchmarking"
      ],
      "application_level": "dataset",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/booydar/babilong",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "llm-evaluation",
        "long-context"
      ],
      "id": 670
    },
    {
      "name": "Contextualise",
      "one_line_profile": "Knowledge management tool for organising unstructured information",
      "detailed_description": "Contextualise is a tool for organizing information-heavy projects using Topic Maps. It is suitable for structuring diverse and unstructured data resources, aiding in knowledge management and grounding for research.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_management",
        "data_organization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/brettkromkamp/contextualise",
      "help_website": [
        "https://contextualise.dev/"
      ],
      "license": "MIT",
      "tags": [
        "topic-maps",
        "knowledge-graph",
        "information-organization"
      ],
      "id": 671
    },
    {
      "name": "CDLA",
      "one_line_profile": "Chinese Document Layout Analysis Dataset",
      "detailed_description": "A large-scale dataset for Chinese document layout analysis. It serves as a critical resource for training and evaluating models that parse and structure scientific documents and other literature.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "layout_analysis",
        "dataset"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/buptlihang/CDLA",
      "help_website": [],
      "license": null,
      "tags": [
        "dataset",
        "document-layout",
        "ocr"
      ],
      "id": 672
    },
    {
      "name": "OCRFlux",
      "one_line_profile": "Multimodal toolkit for PDF-to-Markdown conversion and table parsing",
      "detailed_description": "OCRFlux is a toolkit designed to convert PDFs to Markdown, handling complex layouts, tables, and cross-page content. It is essential for preprocessing scientific papers and documents for downstream AI analysis.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "ocr",
        "table_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chatdoc-com/OCRFlux",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ocr",
        "pdf-to-markdown",
        "document-parsing"
      ],
      "id": 673
    },
    {
      "name": "Chonkie",
      "one_line_profile": "Lightweight RAG chunking library for text ingestion",
      "detailed_description": "A lightweight and efficient library designed for RAG pipelines to handle text ingestion and chunking, optimizing the preparation of data for vector retrieval systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "text_chunking",
        "data_ingestion"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chonkie-inc/chonkie",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "chunking",
        "nlp",
        "ingestion"
      ],
      "id": 674
    },
    {
      "name": "Eino",
      "one_line_profile": "CloudWeGo's framework for building LLM and AI agents",
      "detailed_description": "An application development framework in Golang designed for building Large Language Model (LLM) applications and AI agents, providing orchestration capabilities for complex AI workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_orchestration",
        "workflow_management"
      ],
      "application_level": "framework",
      "primary_language": "Go",
      "repo_url": "https://github.com/cloudwego/eino",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "agent",
        "golang",
        "orchestration"
      ],
      "id": 675
    },
    {
      "name": "CocoIndex",
      "one_line_profile": "Incremental data transformation framework for AI/RAG",
      "detailed_description": "A high-performance data transformation framework designed for AI applications, supporting incremental processing to efficiently manage data pipelines for RAG and vector databases.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_transformation",
        "pipeline_processing"
      ],
      "application_level": "framework",
      "primary_language": "Rust",
      "repo_url": "https://github.com/cocoindex-io/cocoindex",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-processing",
        "rag",
        "incremental-computation"
      ],
      "id": 676
    },
    {
      "name": "Abstracts Search",
      "one_line_profile": "Semantic search engine for academic publications",
      "detailed_description": "A semantic search engine implementation designed to index and retrieve information from a large corpus of academic abstracts (110 million publications), facilitating literature review and discovery.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_retrieval",
        "semantic_search"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/colonelwatch/abstracts-search",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "semantic-search",
        "academic-search",
        "literature-review"
      ],
      "id": 677
    },
    {
      "name": "Grobidmonkey",
      "one_line_profile": "Post-processing utility for GROBID outputs",
      "detailed_description": "A Python package designed to post-process and refine the outputs from GROBID, a machine learning library for extracting information from scholarly documents (PDFs).",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "metadata_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/com3dian/Grobidmonkey",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "grobid",
        "pdf-parsing",
        "scientific-literature"
      ],
      "id": 678
    },
    {
      "name": "Open Co-Scientist Agents",
      "one_line_profile": "Implementation of AI Co-Scientist agent architecture",
      "detailed_description": "An open-source implementation of the AI Co-Scientist concept (inspired by Google DeepMind), utilizing LangGraph and GPT Researcher to create agents capable of assisting in scientific research tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "scientific_agent",
        "research_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/conradry/open-coscientist-agents",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent",
        "langgraph",
        "scientific-discovery"
      ],
      "id": 679
    },
    {
      "name": "StageRAG",
      "one_line_profile": "Modular RAG pipeline with multi-stage retrieval",
      "detailed_description": "A blueprint and framework for building production-ready Retrieval-Augmented Generation (RAG) systems, featuring switchable pipelines for speed or precision to minimize hallucinations.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "retrieval_optimization"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/darrencxl0301/StageRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "hallucination-reduction",
        "pipeline"
      ],
      "id": 680
    },
    {
      "name": "Marker",
      "one_line_profile": "High-accuracy PDF to Markdown converter for scientific documents",
      "detailed_description": "A tool powered by deep learning to convert PDF documents (including scientific papers with equations and tables) into Markdown and JSON formats with high accuracy.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "document_conversion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/datalab-to/marker",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pdf-to-markdown",
        "ocr",
        "scientific-document"
      ],
      "id": 681
    },
    {
      "name": "Probable People",
      "one_line_profile": "Parser for unstructured western names",
      "detailed_description": "A Python library for parsing unstructured western name strings into their components, useful for bibliographic analysis and citation processing in scientific literature.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "name_parsing",
        "bibliographic_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/datamade/probablepeople",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "name-parsing",
        "citation-analysis"
      ],
      "id": 682
    },
    {
      "name": "Neural RDF Verbalizer",
      "one_line_profile": "Tool for converting RDF knowledge graphs to text",
      "detailed_description": "A multilingual tool that converts RDF triples (Knowledge Graph data) into natural language text, facilitating the integration of structured knowledge into RAG or evidence chains.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "kg_to_text",
        "verbalization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dbpedia/neural-rdf-verbalizer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rdf",
        "knowledge-graph",
        "nlg"
      ],
      "id": 683
    },
    {
      "name": "Edge SLM",
      "one_line_profile": "On-device RAG pipeline for Small Language Models",
      "detailed_description": "A native implementation of a RAG pipeline optimized for Small Language Models (SLMs) running on resource-constrained edge devices like Android smartphones.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "edge_ai"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/deepsense-ai/edge-slm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "slm",
        "edge-computing",
        "android"
      ],
      "id": 684
    },
    {
      "name": "Hayhooks",
      "one_line_profile": "Deployment tool for Haystack pipelines as REST APIs",
      "detailed_description": "A tool to easily deploy Haystack pipelines as REST APIs and MCP Tools, facilitating the integration of scientific RAG workflows into broader applications.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "pipeline_serving",
        "api_deployment"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepset-ai/hayhooks",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "haystack",
        "deployment",
        "rest-api"
      ],
      "id": 685
    },
    {
      "name": "Haystack Core Integrations",
      "one_line_profile": "Official integrations for the Haystack framework",
      "detailed_description": "A collection of additional components and document stores that extend the capabilities of the Haystack framework, enabling integration with various vector databases and models.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "integration",
        "component_extension"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepset-ai/haystack-core-integrations",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "haystack",
        "plugins",
        "integrations"
      ],
      "id": 686
    },
    {
      "name": "Haystack Experimental",
      "one_line_profile": "Experimental components for the Haystack NLP framework",
      "detailed_description": "A collection of experimental nodes, pipelines, and features for the Haystack framework, enabling advanced RAG and QA workflows for research agents before they are merged into the core library.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "rag_pipeline"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepset-ai/haystack-experimental",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "nlp",
        "experimental",
        "haystack"
      ],
      "id": 687
    },
    {
      "name": "GPT-4o Research Assistant",
      "one_line_profile": "Automated academic paper research and summarization agent",
      "detailed_description": "A research agent tool that leverages GPT-4o to search ArXiv for academic papers, download them, extract content, and generate summaries, automating the literature review process.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_search",
        "summarization",
        "paper_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/echohive42/GPT-4o-Research-assistant",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arxiv",
        "research-assistant",
        "summarization",
        "agent"
      ],
      "id": 688
    },
    {
      "name": "ScienceBeam Parser",
      "one_line_profile": "PDF to XML conversion tool for scientific publications",
      "detailed_description": "A set of tools designed to convert scientific PDF documents into structured XML formats, facilitating text mining, metadata extraction, and literature analysis workflows.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "document_conversion",
        "metadata_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/elifesciences/sciencebeam-parser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-parsing",
        "xml",
        "scientific-publishing",
        "document-conversion"
      ],
      "id": 689
    },
    {
      "name": "Sphere",
      "one_line_profile": "Web-scale retrieval library for knowledge-intensive NLP",
      "detailed_description": "A retrieval library and dataset designed for knowledge-intensive NLP tasks, enabling efficient search over massive web corpora for grounding, verification, and evidence retrieval in scientific contexts.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "retrieval",
        "grounding",
        "knowledge_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/Sphere",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "retrieval",
        "nlp",
        "knowledge-base",
        "grounding"
      ],
      "id": 690
    },
    {
      "name": "Nougat",
      "one_line_profile": "Neural Optical Understanding for Academic Documents",
      "detailed_description": "A Transformer-based model and tool for converting scientific PDF documents into Markdown, specifically designed to handle complex layouts, formulas, and tables in academic papers.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "ocr",
        "document_understanding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/nougat",
      "help_website": [
        "https://facebookresearch.github.io/nougat/"
      ],
      "license": "MIT",
      "tags": [
        "pdf-to-markdown",
        "ocr",
        "scientific-papers",
        "transformer"
      ],
      "id": 691
    },
    {
      "name": "LangExtract",
      "one_line_profile": "LLM-based structured information extraction with precise source grounding",
      "detailed_description": "A Python library designed to extract structured data from unstructured text using Large Language Models (LLMs). It features a mechanism for precise source grounding, allowing researchers to verify extracted facts against the original text, which is critical for evidence-based scientific literature mining and knowledge graph construction.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "information_extraction",
        "grounding",
        "evidence_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google/langextract",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "information-extraction",
        "grounding",
        "rag"
      ],
      "id": 692
    },
    {
      "name": "Gretel Synthetics",
      "one_line_profile": "Synthetic data generation library for privacy-preserving machine learning",
      "detailed_description": "A library for generating synthetic structured and unstructured data using recurrent neural networks and differential privacy techniques. It enables researchers to create safe, shareable versions of sensitive datasets (e.g., medical records, survey data) for training machine learning models without compromising privacy.",
      "domains": [
        "AI5",
        "Data"
      ],
      "subtask_category": [
        "data_generation",
        "synthetic_data",
        "privacy_preserving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gretelai/gretel-synthetics",
      "help_website": [
        "https://gretel.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "synthetic-data",
        "differential-privacy",
        "nlp",
        "data-generation"
      ],
      "id": 693
    },
    {
      "name": "MCPAdapt",
      "one_line_profile": "Adapter for Model Context Protocol (MCP) tools in agent frameworks",
      "detailed_description": "A library that enables AI agents built with various frameworks (like LangChain or LlamaIndex) to access and invoke tools compatible with the Model Context Protocol (MCP). This facilitates the integration of diverse external tools and data sources into scientific research agent workflows.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "tool_invocation",
        "agent_integration",
        "interoperability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/grll/mcpadapt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "agent",
        "tool-use",
        "llm"
      ],
      "id": 694
    },
    {
      "name": "WARC-GPT",
      "one_line_profile": "RAG pipeline for querying Web Archive (WARC) collections",
      "detailed_description": "An experimental retrieval-augmented generation (RAG) tool developed by Harvard Library Innovation Lab. It is designed to index and query Web Archive (WARC) files, allowing researchers to explore, retrieve, and synthesize information from historical web data with proper source attribution.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag",
        "web_archiving",
        "information_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/harvard-lil/warc-gpt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "warc",
        "web-archives",
        "rag",
        "digital-humanities"
      ],
      "id": 695
    },
    {
      "name": "PDF Document Layout Analysis",
      "one_line_profile": "Service for segmenting and classifying PDF document elements",
      "detailed_description": "A machine learning-powered service that analyzes the layout of PDF documents to identify and classify elements such as text blocks, titles, tables, and images. It provides a structured representation of PDF content, which is essential for downstream tasks like scientific literature mining, citation extraction, and knowledge base construction.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "layout_analysis",
        "document_segmentation"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/huridocs/pdf-document-layout-analysis",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf-parsing",
        "layout-analysis",
        "ocr",
        "document-processing"
      ],
      "id": 696
    },
    {
      "name": "pdf-text-extraction",
      "one_line_profile": "Automated text extraction from PDF files using layout analysis outputs",
      "detailed_description": "A tool designed to extract text from PDF files by leveraging the segmentation and classification capabilities of the pdf-document-layout-analysis service, automating the text extraction process for document processing workflows.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "text_extraction"
      ],
      "application_level": "workflow",
      "primary_language": "Makefile",
      "repo_url": "https://github.com/huridocs/pdf-text-extraction",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pdf-extraction",
        "layout-analysis",
        "document-processing"
      ],
      "id": 697
    },
    {
      "name": "vision-parse",
      "one_line_profile": "PDF to Markdown converter using Vision LLMs",
      "detailed_description": "A tool that leverages Vision Large Language Models to parse PDF documents and convert them into Markdown format, facilitating the ingestion of scientific literature and documents into RAG pipelines.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "document_ingestion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/iamarunbrahma/vision-parse",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-to-markdown",
        "vision-llm",
        "ocr"
      ],
      "id": 698
    },
    {
      "name": "SuperKnowa",
      "one_line_profile": "Enterprise RAG pipeline builder",
      "detailed_description": "A framework for building Enterprise Retrieval Augmented Generation (RAG) pipelines, allowing users to plug in components like retrievers and LLMs to tackle generative AI use cases, suitable for knowledge management and evidence retrieval.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "knowledge_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ibm-self-serve-assets/SuperKnowa",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "pipeline",
        "enterprise-ai"
      ],
      "id": 699
    },
    {
      "name": "RAGFlow",
      "one_line_profile": "Retrieval-Augmented Generation engine with agent capabilities",
      "detailed_description": "An open-source RAG engine that combines retrieval-augmented generation with agent capabilities to create a context layer for LLMs, supporting complex document parsing and evidence-based generation workflows.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_engine",
        "document_parsing",
        "agent_workflow"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/infiniflow/ragflow",
      "help_website": [
        "https://ragflow.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "agent",
        "document-processing"
      ],
      "id": 700
    },
    {
      "name": "SAC3",
      "one_line_profile": "Semantic-aware Cross-check Consistency for hallucination detection",
      "detailed_description": "A tool for reliable hallucination detection in black-box language models via Semantic-aware Cross-check Consistency, useful for grounding and verifying generated content in scientific RAG systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "grounding"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/intuit/sac3",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination-detection",
        "consistency-check",
        "llm-reliability"
      ],
      "id": 701
    },
    {
      "name": "OntologyRAG",
      "one_line_profile": "Biomedical code mapping with RAG and Ontology Knowledge Graphs",
      "detailed_description": "A Retrieval-Augmented Generation tool leveraging Ontology Knowledge Graphs and In-context-learning for biomedical code mapping, enhancing the accuracy of medical entity retrieval and normalization.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "biomedical_rag",
        "ontology_mapping"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/iqvianlp/ontologyRAG",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "biomedical",
        "ontology",
        "rag"
      ],
      "id": 702
    },
    {
      "name": "layout_analysis",
      "one_line_profile": "Chinese document layout detection using YOLOv8",
      "detailed_description": "A tool for detecting the layout of Chinese document images using YOLOv8, facilitating the structural analysis of documents for downstream tasks like OCR and RAG.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jiangnanboy/layout_analysis",
      "help_website": [],
      "license": null,
      "tags": [
        "layout-analysis",
        "yolov8",
        "document-structure"
      ],
      "id": 703
    },
    {
      "name": "layout_analysis4j",
      "one_line_profile": "Java implementation of document layout detection",
      "detailed_description": "A Java-based implementation for document layout detection using YOLOv8, providing layout analysis capabilities for Java environments in document processing pipelines.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "layout_analysis",
        "document_parsing"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/jiangnanboy/layout_analysis4j",
      "help_website": [],
      "license": null,
      "tags": [
        "java",
        "layout-analysis",
        "document-processing"
      ],
      "id": 704
    },
    {
      "name": "pdf-to-markdown",
      "one_line_profile": "Python tool to convert PDF files to Markdown",
      "detailed_description": "A Python utility to convert PDF documents into Markdown format, enabling the extraction of structured text from scientific papers for use in RAG and text mining applications.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "text_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/johnlinp/pdf-to-markdown",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "pdf-conversion",
        "markdown",
        "text-extraction"
      ],
      "id": 705
    },
    {
      "name": "local-rag",
      "one_line_profile": "Local RAG ingestion and retrieval tool",
      "detailed_description": "A tool for ingesting files for Retrieval Augmented Generation (RAG) using open-source LLMs locally, ensuring data privacy while enabling semantic search and question answering on document sets.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_ingestion",
        "local_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jonfairbanks/local-rag",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "rag",
        "local-llm",
        "privacy"
      ],
      "id": 706
    },
    {
      "name": "magicsearch",
      "one_line_profile": "Hybrid full-text and semantic search engine",
      "detailed_description": "A search engine combining full-text and semantic search capabilities, suitable for building retrieval systems in scientific knowledge bases.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "semantic_search",
        "retrieval"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/joschan21/magicsearch",
      "help_website": [],
      "license": null,
      "tags": [
        "hybrid-search",
        "semantic-search",
        "retrieval"
      ],
      "id": 707
    },
    {
      "name": "TRACE",
      "one_line_profile": "Constructing knowledge-grounded reasoning chains for RAG",
      "detailed_description": "A framework for constructing knowledge-grounded reasoning chains (TRACE) to enhance Retrieval-Augmented Generation, improving the evidence traceability and reasoning capabilities of LLMs.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "evidence_chain",
        "reasoning_grounding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jyfang6/trace",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "reasoning-chain",
        "evidence-grounding"
      ],
      "id": 708
    },
    {
      "name": "FLARE",
      "one_line_profile": "Forward-Looking Active Retrieval-augmented generation",
      "detailed_description": "An implementation of Forward-Looking Active Retrieval-augmented generation (FLARE), a method to actively retrieve information during the generation process to reduce hallucinations and improve factual accuracy.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "active_retrieval",
        "rag_method"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jzbjyb/FLARE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "active-retrieval",
        "rag",
        "generation"
      ],
      "id": 709
    },
    {
      "name": "pdf-to-markdown-js",
      "one_line_profile": "JavaScript PDF to Markdown converter",
      "detailed_description": "A JavaScript-based tool for converting PDF documents to Markdown, facilitating the extraction of text and structure from scientific papers for web-based RAG applications.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "text_extraction"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/jzillmann/pdf-to-markdown",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-conversion",
        "javascript",
        "text-extraction"
      ],
      "id": 710
    },
    {
      "name": "SearchAnything",
      "one_line_profile": "Semantic local search engine powered by AI",
      "detailed_description": "A semantic local search engine that uses AI models to index and retrieve information from local documents, serving as a personal knowledge base retrieval tool.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "semantic_search",
        "local_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/kaijiezhu11/SearchAnything",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-search",
        "local-search",
        "ai-search"
      ],
      "id": 711
    },
    {
      "name": "byte-vision",
      "one_line_profile": "Privacy-first document intelligence and RAG platform",
      "detailed_description": "A document intelligence platform that transforms static documents into an interactive, searchable knowledge base using Elasticsearch and RAG capabilities, featuring OCR processing and document parsing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_intelligence",
        "rag_platform"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/kbrisso/byte-vision",
      "help_website": [],
      "license": null,
      "tags": [
        "document-intelligence",
        "rag",
        "ocr"
      ],
      "id": 712
    },
    {
      "name": "GROBID",
      "one_line_profile": "Machine learning software for extracting information from scholarly documents",
      "detailed_description": "GROBID (GeneRation Of BIbliographic Data) is a machine learning library for extracting, parsing, and restructuring raw documents such as PDF into structured XML/TEI encoded documents with a focus on technical and scientific publications.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "information_extraction",
        "metadata_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/kermitt2/grobid",
      "help_website": [
        "https://grobid.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "pdf-parsing",
        "scholarly-articles",
        "tei-xml",
        "citation-extraction"
      ],
      "id": 713
    },
    {
      "name": "grobid-astro",
      "one_line_profile": "GROBID module for extracting astronomical entities from scholarly documents",
      "detailed_description": "A specialized module for GROBID designed to recognize and extract astronomical entities (such as celestial objects, events, and locations) from scientific literature.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "entity_extraction",
        "text_mining"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/kermitt2/grobid-astro",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "astronomy",
        "ner",
        "grobid-module"
      ],
      "id": 714
    },
    {
      "name": "grobid-ner",
      "one_line_profile": "Named-Entity Recogniser for scientific text based on GROBID",
      "detailed_description": "A module for GROBID that performs Named Entity Recognition (NER) on scientific texts, leveraging the structural analysis capabilities of the main GROBID engine.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "entity_extraction",
        "ner"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/kermitt2/grobid-ner",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ner",
        "nlp",
        "scientific-text"
      ],
      "id": 715
    },
    {
      "name": "paperqa-zotero",
      "one_line_profile": "LLM-based question answering tool for Zotero libraries",
      "detailed_description": "A tool that integrates Large Language Models with Zotero to enable question answering and information retrieval directly from a user's scientific document library.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "qa"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lejacobroy/paperqa-zotero",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "zotero",
        "rag",
        "literature-review"
      ],
      "id": 716
    },
    {
      "name": "grobid-quantities",
      "one_line_profile": "GROBID extension for identifying and normalizing physical quantities",
      "detailed_description": "A module for GROBID that extracts physical quantities (measurements, units, values) from scientific text and normalizes them for structured analysis.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "entity_extraction",
        "data_normalization"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/lfoppiano/grobid-quantities",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "physical-quantities",
        "measurement-extraction",
        "grobid-module"
      ],
      "id": 717
    },
    {
      "name": "grobid-superconductors",
      "one_line_profile": "GROBID module for superconductor material and properties extraction",
      "detailed_description": "A specialized GROBID module designed to extract superconductor materials, their classes, and associated properties (like critical temperature) from scientific papers.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "entity_extraction",
        "materials_informatics"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/lfoppiano/grobid-superconductors",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "superconductors",
        "materials-science",
        "text-mining"
      ],
      "id": 718
    },
    {
      "name": "material-parsers",
      "one_line_profile": "Parsers for material names and formula",
      "detailed_description": "A collection of tools and scripts for parsing material names and chemical formulas, initially developed for the Grobid Superconductor project.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_processing",
        "materials_informatics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lfoppiano/material-parsers",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "materials-parsing",
        "chemical-formula"
      ],
      "id": 719
    },
    {
      "name": "structure-vision",
      "one_line_profile": "Viewer for document structures extracted by GROBID",
      "detailed_description": "A visualization tool designed to inspect and verify the structured data (XML/TEI) extracted by GROBID from PDF documents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "visualization",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lfoppiano/structure-vision",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "grobid",
        "document-structure"
      ],
      "id": 720
    },
    {
      "name": "supercon2",
      "one_line_profile": "Curation interface for the SuperCon database",
      "detailed_description": "A web-based platform for curating experimental data for the SuperCon database, featuring an enhanced document viewer and tools for validating automatically extracted data.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_curation",
        "database_management"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/lfoppiano/supercon2",
      "help_website": [],
      "license": null,
      "tags": [
        "curation",
        "superconductors",
        "database"
      ],
      "id": 721
    },
    {
      "name": "Aria (ai-research-assistant)",
      "one_line_profile": "AI Research Assistant powered by LLMs",
      "detailed_description": "Aria is an AI-powered research assistant tool that helps researchers read, summarize, and extract information from scientific papers using Large Language Models.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "summarization"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/lifan0127/ai-research-assistant",
      "help_website": [
        "https://aria.ace.sh/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "research-assistant",
        "literature-review",
        "llm-agent"
      ],
      "id": 722
    },
    {
      "name": "LlamaFarm",
      "one_line_profile": "Orchestration tool to deploy AI models, agents, and RAG pipelines locally or remotely",
      "detailed_description": "A deployment and orchestration framework that simplifies the management of AI models, agents, vector databases, and RAG pipelines, facilitating the setup of local or remote AI research environments.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "deployment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/llama-farm/llamafarm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "agent-deployment",
        "pipeline-orchestration"
      ],
      "id": 723
    },
    {
      "name": "LLMWare",
      "one_line_profile": "Unified framework for building enterprise RAG pipelines with specialized small models",
      "detailed_description": "A framework designed for building retrieval-augmented generation (RAG) pipelines, emphasizing the use of small, specialized models for secure and efficient enterprise-grade knowledge retrieval and processing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "knowledge_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/llmware-ai/llmware",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "small-models",
        "enterprise-search"
      ],
      "id": 724
    },
    {
      "name": "Pix2Text-nougat-texify-GUI",
      "one_line_profile": "GUI tool for offline LaTeX OCR using Pix2Text, Nougat, and Texify models",
      "detailed_description": "A graphical interface for running offline Optical Character Recognition (OCR) specifically optimized for converting images of mathematical formulas and scientific text into LaTeX code using multiple backend models.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "ocr",
        "formula_extraction",
        "pdf_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/longchentian/Pix2Text-nougat-texify-GUI",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "latex-ocr",
        "scientific-document-parsing",
        "gui"
      ],
      "id": 725
    },
    {
      "name": "remarks",
      "one_line_profile": "Extractor for annotations and highlights from PDFs marked with reMarkable tablets",
      "detailed_description": "A tool to extract highlights, scribbles, and annotations from PDF and EPUB documents marked on reMarkable tablets, exporting them to formats like Markdown or PDF, useful for literature review and evidence gathering.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "annotation_extraction",
        "literature_review"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucasrla/remarks",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pdf-annotation",
        "remarkable",
        "knowledge-extraction"
      ],
      "id": 726
    },
    {
      "name": "FaviComp",
      "one_line_profile": "Familiarity-aware evidence compression for Retrieval Augmented Generation",
      "detailed_description": "Implementation of a method for compressing retrieved evidence in RAG systems based on familiarity, optimizing the context window and relevance for language models. Associated with EMNLP 2025 Findings.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "evidence_compression",
        "rag_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/luka-group/FaviComp",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "evidence-compression",
        "nlp"
      ],
      "id": 727
    },
    {
      "name": "MrCoD",
      "one_line_profile": "Multi-hop evidence retrieval for cross-document relation extraction",
      "detailed_description": "A tool for retrieving evidence across multiple documents to support relation extraction tasks, specifically designed to handle multi-hop reasoning scenarios in information extraction.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "evidence_retrieval",
        "relation_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/luka-group/MrCoD",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multi-hop-retrieval",
        "relation-extraction",
        "evidence-chain"
      ],
      "id": 728
    },
    {
      "name": "FRAG",
      "one_line_profile": "Context-aware generation framework from large unstructured knowledge sources",
      "detailed_description": "A flexible and efficient RAG framework designed to generate responses by leveraging large-scale unstructured knowledge sources with context awareness.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag",
        "knowledge_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lumpenspace/FRAG",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "unstructured-data",
        "generation"
      ],
      "id": 729
    },
    {
      "name": "Open WebUI Pipeline for RAGFlow",
      "one_line_profile": "Integration pipeline connecting Open WebUI with RAGFlow agents",
      "detailed_description": "A middleware tool that enables Open WebUI to utilize RAGFlow's agent capabilities, facilitating the creation of knowledge-base driven intelligent dialogue systems with a graphical interface.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "workflow_integration",
        "agent_interface"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/luyilong2015/open-webui-pipeline-for-ragflow",
      "help_website": [],
      "license": "Unlicense",
      "tags": [
        "ragflow",
        "open-webui",
        "pipeline"
      ],
      "id": 730
    },
    {
      "name": "Wenzhou-Pack-Degradation-Data",
      "one_line_profile": "Dataset for battery pack degradation analysis and prognosis",
      "detailed_description": "A dataset containing randomized battery data for transfer-driven prognosis from battery cells to packs, supporting research in energy storage and degradation modeling.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "dataset",
        "battery_prognostics"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/lvdongzhen/Wenzhou-Pack-Degradation-Data",
      "help_website": [],
      "license": null,
      "tags": [
        "battery-data",
        "degradation",
        "energy-storage"
      ],
      "id": 731
    },
    {
      "name": "Wenzhou-Randomized-Battery-Data",
      "one_line_profile": "Dataset for battery cumulative lifetime prognostics",
      "detailed_description": "A dataset bridging laboratory and real-life scenarios for battery lifetime prediction, supporting data-driven research in electrochemistry and energy systems.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "dataset",
        "battery_lifetime"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/lvdongzhen/Wenzhou-Randomized-Battery-Data",
      "help_website": [],
      "license": null,
      "tags": [
        "battery-data",
        "lifetime-prediction",
        "dataset"
      ],
      "id": 732
    },
    {
      "name": "iFEM",
      "one_line_profile": "MATLAB package for adaptive finite element methods",
      "detailed_description": "A MATLAB software package providing robust and efficient codes for adaptive finite element methods (FEM) on unstructured simplicial grids in 2D and 3D, used for numerical simulations.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "finite_element_method",
        "numerical_simulation"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/lyc102/ifem",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "fem",
        "matlab",
        "pde-solver"
      ],
      "id": 733
    },
    {
      "name": "Reference Feature Extraction",
      "one_line_profile": "Reference implementations of feature extraction algorithms in Matlab/Octave",
      "detailed_description": "A collection of reference implementations for various feature extraction algorithms, useful for signal processing and data analysis tasks.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "feature_extraction",
        "signal_processing"
      ],
      "application_level": "library",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/m-r-s/reference-feature-extraction",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "feature-extraction",
        "signal-processing",
        "matlab"
      ],
      "id": 734
    },
    {
      "name": "RagRabbit",
      "one_line_profile": "Self-hosted AI search and RAG platform for websites",
      "detailed_description": "An open-source, self-hosted solution for implementing AI-powered search and Retrieval-Augmented Generation (RAG) on websites, facilitating knowledge retrieval.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_platform",
        "semantic_search"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/madarco/ragrabbit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "search-engine",
        "self-hosted"
      ],
      "id": 735
    },
    {
      "name": "HaMI",
      "one_line_profile": "Robust hallucination detection in LLMs via adaptive token selection",
      "detailed_description": "Implementation of a method for detecting hallucinations in Large Language Models using adaptive token selection, enhancing the reliability of generative models in scientific contexts.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "quality_control"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mala-lab/HaMI",
      "help_website": [],
      "license": null,
      "tags": [
        "hallucination-detection",
        "llm-evaluation",
        "reliability"
      ],
      "id": 736
    },
    {
      "name": "Direct RAG Learning",
      "one_line_profile": "Direct Retrieval-augmented Optimization for synergizing knowledge selection and LMs",
      "detailed_description": "Code for 'Direct Retrieval-augmented Optimization', a method to jointly optimize knowledge selection and language model generation, improving RAG performance.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_optimization",
        "knowledge_selection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mangopy/direct-rag-learning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "optimization",
        "retrieval"
      ],
      "id": 737
    },
    {
      "name": "TinySearch",
      "one_line_profile": "Semantic search engine using BERT embeddings",
      "detailed_description": "A lightweight semantic search engine implementation leveraging BERT embeddings for retrieving relevant documents based on semantic similarity.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "semantic_search",
        "retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/manishpatel005/tinysearch",
      "help_website": [],
      "license": null,
      "tags": [
        "bert",
        "semantic-search",
        "embeddings"
      ],
      "id": 738
    },
    {
      "name": "OrKa",
      "one_line_profile": "Orchestrator Kit for Agentic Reasoning and transparent traceability",
      "detailed_description": "A modular AI orchestration system that transforms LLMs into composable agents capable of reasoning, fact-checking, and constructing answers with transparent traceability, useful for evidence-based scientific inquiry.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "agent_orchestration",
        "reasoning",
        "traceability"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/marcosomma/orka-reasoning",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "agent",
        "reasoning",
        "traceability"
      ],
      "id": 739
    },
    {
      "name": "RELiC",
      "one_line_profile": "Retrieving Evidence for Literary Claims",
      "detailed_description": "Codebase for retrieving evidence to support claims, specifically designed for literary analysis but applicable to general evidence retrieval tasks in RAG systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "evidence_retrieval",
        "claim_verification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/martiansideofthemoon/relic-retrieval",
      "help_website": [
        "https://relic.cs.umass.edu"
      ],
      "license": "MIT",
      "tags": [
        "retrieval",
        "evidence",
        "nlp"
      ],
      "id": 740
    },
    {
      "name": "PhysioNet ECG Segmentation Data",
      "one_line_profile": "ECG data for deep learning segmentation examples",
      "detailed_description": "A dataset of human electrocardiogram (ECG) data sourced from PhysioNet, prepared for signal processing and deep learning segmentation tasks.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "dataset",
        "ecg_segmentation"
      ],
      "application_level": "dataset",
      "primary_language": null,
      "repo_url": "https://github.com/mathworks/physionet_ECG_segmentation",
      "help_website": [],
      "license": null,
      "tags": [
        "ecg",
        "dataset",
        "signal-processing"
      ],
      "id": 741
    },
    {
      "name": "Document Knowledge Mining Solution Accelerator",
      "one_line_profile": "Accelerator for extracting summaries and entities from unstructured documents",
      "detailed_description": "A solution accelerator built on Azure OpenAI and Document Intelligence to process unstructured, multi-modal documents, extracting metadata, entities, and summaries for search and RAG applications.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_mining",
        "information_extraction",
        "rag"
      ],
      "application_level": "workflow",
      "primary_language": "C#",
      "repo_url": "https://github.com/microsoft/Document-Knowledge-Mining-Solution-Accelerator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-mining",
        "document-intelligence",
        "azure"
      ],
      "id": 742
    },
    {
      "name": "GraphRAG",
      "one_line_profile": "Modular graph-based Retrieval-Augmented Generation system",
      "detailed_description": "A system that enhances RAG by using knowledge graphs to structure and retrieve information, enabling more complex reasoning and better context understanding from unstructured data.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag",
        "knowledge_graph",
        "retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/graphrag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-rag",
        "knowledge-graph",
        "retrieval"
      ],
      "id": 743
    },
    {
      "name": "MarkItDown",
      "one_line_profile": "Tool for converting office documents and files to Markdown",
      "detailed_description": "A utility to convert various file formats (PDF, Word, Excel, etc.) into Markdown, facilitating the ingestion of scientific documents into LLMs and RAG pipelines.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_conversion",
        "data_ingestion"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/markitdown",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "markdown",
        "document-conversion",
        "pdf-parsing"
      ],
      "id": 744
    },
    {
      "name": "Micronaire",
      "one_line_profile": "RAG evaluation pipeline for Semantic Kernel",
      "detailed_description": "An evaluation pipeline designed to assess the performance and quality of RAG systems built with Semantic Kernel, ensuring reliability in retrieval and generation.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_evaluation",
        "quality_control"
      ],
      "application_level": "tool",
      "primary_language": "C#",
      "repo_url": "https://github.com/microsoft/micronaire",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "evaluation",
        "rag",
        "semantic-kernel"
      ],
      "id": 745
    },
    {
      "name": "OpenScraping C#",
      "one_line_profile": "Library to turn unstructured HTML into structured data using XPath",
      "detailed_description": "A library for extracting structured data from unstructured HTML pages using JSON configuration and XPath rules, useful for harvesting scientific data from web sources.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "web_scraping",
        "data_extraction"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/microsoft/openscraping-lib-csharp",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "scraping",
        "html-parsing",
        "data-extraction"
      ],
      "id": 746
    },
    {
      "name": "Table Transformer",
      "one_line_profile": "Deep learning model for extracting tables from unstructured documents",
      "detailed_description": "A deep learning-based tool (TATR) for detecting and extracting tabular data from PDFs and images, essential for parsing scientific papers and reports.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "table_extraction",
        "document_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/table-transformer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "table-extraction",
        "pdf-parsing",
        "deep-learning"
      ],
      "id": 747
    },
    {
      "name": "grobidclient",
      "one_line_profile": "Go client for GROBID scientific document parsing service",
      "detailed_description": "A Go client library for interacting with GROBID, a machine learning library for extracting, parsing, and restructuring raw documents such as PDF publications into structured XML/TEI.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "pdf_extraction"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/miku/grobidclient",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "grobid",
        "pdf-parsing",
        "scientific-literature"
      ],
      "id": 748
    },
    {
      "name": "map2gpt",
      "one_line_profile": "Semantic search engine for textual content from PDFs and Wikipedia",
      "detailed_description": "A search tool leveraging NLP models to provide semantic search capabilities over textual content from sources like PDF files and Wikipedia, facilitating information retrieval.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "semantic_search",
        "pdf_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/milkymap/map2gpt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-search",
        "pdf",
        "nlp"
      ],
      "id": 749
    },
    {
      "name": "llm-scraper",
      "one_line_profile": "Library to convert webpages into structured data using LLMs",
      "detailed_description": "A TypeScript library that leverages Large Language Models to scrape and parse web content into structured formats, useful for data collection in research workflows.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "web_scraping",
        "data_extraction"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/mishushakov/llm-scraper",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "scraping",
        "llm",
        "structured-data"
      ],
      "id": 750
    },
    {
      "name": "baguetter",
      "one_line_profile": "Flexible search engine library for benchmarking retrieval methods",
      "detailed_description": "A Python library for implementing, testing, and benchmarking sparse, dense, and hybrid search retrieval methods, designed for efficiency and hackability.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "information_retrieval",
        "benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mixedbread-ai/baguetter",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "search-engine",
        "retrieval",
        "benchmarking"
      ],
      "id": 751
    },
    {
      "name": "YOLOv10-Document-Layout-Analysis",
      "one_line_profile": "YOLOv10 model trained for document layout analysis",
      "detailed_description": "A repository providing YOLOv10 models trained on the DocLayNet dataset for analyzing and segmenting document layouts, essential for PDF parsing pipelines.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_layout_analysis",
        "pdf_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/moured/YOLOv10-Document-Layout-Analysis",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "yolov10",
        "document-analysis",
        "doclaynet"
      ],
      "id": 752
    },
    {
      "name": "YOLOv11-Document-Layout-Analysis",
      "one_line_profile": "YOLOv11 model trained for document layout analysis",
      "detailed_description": "A repository providing YOLOv11 models trained on the DocLayNet dataset for analyzing and segmenting document layouts, serving as an upgraded tool for PDF parsing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_layout_analysis",
        "pdf_parsing"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/moured/YOLOv11-Document-Layout-Analysis",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "yolov11",
        "document-analysis",
        "doclaynet"
      ],
      "id": 753
    },
    {
      "name": "langchain4j-aideepin-admin",
      "one_line_profile": "Java-based RAG platform with knowledge base and search",
      "detailed_description": "A Java implementation of a Retrieval-Augmented Generation (RAG) system, featuring knowledge base management and search capabilities, suitable for enterprise or research data management.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "knowledge_base"
      ],
      "application_level": "platform",
      "primary_language": "Vue",
      "repo_url": "https://github.com/moyangzhan/langchain4j-aideepin-admin",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "java",
        "knowledge-base"
      ],
      "id": 754
    },
    {
      "name": "pdf2md",
      "one_line_profile": "Tool to convert PDF documents to Markdown",
      "detailed_description": "A browser-based tool and library for converting PDF documents into Markdown format, facilitating the ingestion of scientific literature into text processing pipelines.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "format_conversion"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/mrmps/pdf2md",
      "help_website": [],
      "license": null,
      "tags": [
        "pdf-to-markdown",
        "converter",
        "pdf-parsing"
      ],
      "id": 755
    },
    {
      "name": "CitationExtractor",
      "one_line_profile": "Tool to extract canonical references from text",
      "detailed_description": "A utility for parsing text to identify and extract canonical citation references, supporting bibliometric analysis and evidence tracing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "citation_extraction",
        "reference_parsing"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/mromanello/CitationExtractor",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "citation-extraction",
        "bibliography",
        "text-mining"
      ],
      "id": 756
    },
    {
      "name": "pdf3md",
      "one_line_profile": "Web application for converting PDFs to formatted Markdown",
      "detailed_description": "A modern web application designed to convert PDF documents into clean, formatted Markdown text, useful for extracting content from scientific papers.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "format_conversion"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/murtaza-nasir/pdf3md",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "pdf",
        "markdown",
        "converter"
      ],
      "id": 757
    },
    {
      "name": "ASSESS",
      "one_line_profile": "Automatic Semantic Search Engine for Suitable Standards",
      "detailed_description": "A semantic search engine developed by NASA JPL to identify suitable standards, leveraging semantic retrieval techniques.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "semantic_search",
        "information_retrieval"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/nasa-jpl/ASSESS",
      "help_website": [],
      "license": null,
      "tags": [
        "semantic-search",
        "nasa",
        "standards"
      ],
      "id": 758
    },
    {
      "name": "llm-graph-builder",
      "one_line_profile": "Tool to construct Neo4j graphs from unstructured data using LLMs",
      "detailed_description": "A tool that utilizes Large Language Models to extract entities and relationships from unstructured text and construct knowledge graphs in Neo4j.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "unstructured_data_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/neo4j-labs/llm-graph-builder",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "neo4j",
        "llm"
      ],
      "id": 759
    },
    {
      "name": "pgrag",
      "one_line_profile": "Postgres extension for end-to-end RAG pipelines",
      "detailed_description": "A PostgreSQL extension that enables the creation of end-to-end Retrieval-Augmented Generation (RAG) pipelines directly within the database.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "vector_search"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/neondatabase/pgrag",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "postgres",
        "rag",
        "vector-search"
      ],
      "id": 760
    },
    {
      "name": "rag",
      "one_line_profile": "RAG implementation using txtai for search and LLMs",
      "detailed_description": "A repository providing Retrieval Augmented Generation (RAG) capabilities powered by txtai, allowing for the combination of search and LLMs to extract insights from data.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/neuml/rag",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "txtai",
        "search"
      ],
      "id": 761
    },
    {
      "name": "nixiesearch",
      "one_line_profile": "Hybrid search engine combining text and semantic search",
      "detailed_description": "A hybrid search engine that integrates traditional text search with semantic search capabilities, suitable for building advanced retrieval systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "information_retrieval",
        "search_engine"
      ],
      "application_level": "service",
      "primary_language": "Scala",
      "repo_url": "https://github.com/nixiesearch/nixiesearch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "search-engine",
        "hybrid-search",
        "semantic-search"
      ],
      "id": 762
    },
    {
      "name": "KG2RAG",
      "one_line_profile": "Knowledge Graph-Guided Retrieval Augmented Generation",
      "detailed_description": "Implementation of a Knowledge Graph-Guided RAG framework, enhancing retrieval augmented generation with structured knowledge from graphs.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "knowledge_graph"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nju-websoft/KG2RAG",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "rag",
        "knowledge-graph",
        "retrieval"
      ],
      "id": 763
    },
    {
      "name": "verbaflow",
      "one_line_profile": "Neural Language Model library for Go",
      "detailed_description": "A library implementing neural language models in the Go programming language, enabling NLP inference tasks within Go-based workflows.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "nlp_inference"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/nlpodyssey/verbaflow",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "nlp",
        "go",
        "language-model"
      ],
      "id": 764
    },
    {
      "name": "xapian-haystack",
      "one_line_profile": "Xapian backend for the Haystack search framework",
      "detailed_description": "A backend adapter allowing the use of the Xapian search engine within the Haystack framework, facilitating flexible information retrieval setups.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "search_backend",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/notanumber/xapian-haystack",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "haystack",
        "xapian",
        "search"
      ],
      "id": 765
    },
    {
      "name": "THRED",
      "one_line_profile": "Neural response generation model with context-aware topical attention",
      "detailed_description": "Implementation of a neural response generation model that utilizes context-aware topical attention, serving as a tool for dialogue system research and development.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "dialogue_generation",
        "nlp_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nouhadziri/THRED",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dialogue-generation",
        "nlp",
        "attention-mechanism"
      ],
      "id": 766
    },
    {
      "name": "hallucination_probes",
      "one_line_profile": "Real-time detection of hallucinated entities in long-form generation",
      "detailed_description": "A library for detecting hallucinations in Large Language Model outputs, specifically focusing on entity consistency in long-form text generation. It provides probing mechanisms to evaluate the factual reliability of AI-generated content.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "hallucination_detection",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/obalcells/hallucination_probes",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "llm",
        "reliability",
        "nlp"
      ],
      "id": 767
    },
    {
      "name": "arucogen",
      "one_line_profile": "Online generator for ArUco markers used in computer vision",
      "detailed_description": "A tool to generate ArUco markers, which are synthetic square markers composed of a wide black border and an inner binary matrix. These are essential for camera pose estimation, tracking, and calibration in robotics and computer vision research.",
      "domains": [
        "Computer Vision",
        "Robotics"
      ],
      "subtask_category": [
        "data_generation",
        "calibration"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/okalachev/arucogen",
      "help_website": [
        "http://chev.me/arucogen/"
      ],
      "license": "MIT",
      "tags": [
        "aruco",
        "computer-vision",
        "robotics",
        "markers"
      ],
      "id": 768
    },
    {
      "name": "gpt-2-output-dataset",
      "one_line_profile": "Dataset of GPT-2 outputs for detection and bias research",
      "detailed_description": "A dataset containing outputs generated by the GPT-2 model, intended for research into AI text detection, bias analysis, and linguistic properties of generated text. Essential for developing hallucination detection and content provenance tools.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "dataset",
        "bias_analysis",
        "detection_research"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/openai/gpt-2-output-dataset",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dataset",
        "gpt-2",
        "ai-safety",
        "hallucination-research"
      ],
      "id": 769
    },
    {
      "name": "DocLayout-YOLO",
      "one_line_profile": "Document layout analysis tool using YOLO",
      "detailed_description": "A specialized computer vision tool for analyzing the layout of documents (PDFs, papers). It detects and classifies document elements (text blocks, tables, figures), which is a critical preprocessing step for scientific literature mining and RAG systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "layout_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/opendatalab/DocLayout-YOLO",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "pdf-parsing",
        "ocr",
        "layout-analysis",
        "rag"
      ],
      "id": 770
    },
    {
      "name": "openmovement",
      "one_line_profile": "Open source hardware and software for movement sensing",
      "detailed_description": "A complete ecosystem (firmware, software, hardware designs) for miniature movement sensors (accelerometers). Used in clinical and behavioral research to collect and analyze physical activity data.",
      "domains": [
        "Biomedical Engineering",
        "Health Science"
      ],
      "subtask_category": [
        "data_acquisition",
        "sensor_processing"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/openmovementproject/openmovement",
      "help_website": [
        "https://openmovement.dev/"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "sensors",
        "wearables",
        "data-collection",
        "firmware"
      ],
      "id": 771
    },
    {
      "name": "open-semantic-search",
      "one_line_profile": "Integrated search engine and text analysis platform for document collections",
      "detailed_description": "An open-source research tool for searching and analyzing large document collections. It integrates ETL, OCR, Named Entity Recognition (NER), and semantic search, making it suitable for managing and exploring scientific literature archives.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "information_retrieval",
        "text_mining"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/opensemanticsearch/open-semantic-search",
      "help_website": [
        "https://www.opensemanticsearch.org/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "semantic-search",
        "etl",
        "ocr",
        "ner"
      ],
      "id": 772
    },
    {
      "name": "crrf-det",
      "one_line_profile": "PDF content and table extraction tool for climate finance data",
      "detailed_description": "A tool developed by OS-Climate for extracting structured data from PDF documents, specifically designed for climate-related financial disclosures. It features visual layout analysis and table extraction.",
      "domains": [
        "Climate Science",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_extraction",
        "data_structuring"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/os-climate/crrf-det",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "climate-data",
        "pdf-extraction",
        "ocr",
        "os-climate"
      ],
      "id": 773
    },
    {
      "name": "openalex-pdf-parser",
      "one_line_profile": "PDF parser for OpenAlex powered by GROBID",
      "detailed_description": "A utility to parse scientific PDFs using GROBID, designed to feed structured data into the OpenAlex dataset. It extracts metadata and full text from research papers.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_parsing",
        "metadata_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ourresearch/openalex-pdf-parser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "openalex",
        "grobid",
        "pdf-parsing",
        "bibliometrics"
      ],
      "id": 774
    },
    {
      "name": "aruco_ros",
      "one_line_profile": "ROS wrappers for ArUco marker detection",
      "detailed_description": "Provides ROS (Robot Operating System) integration for the ArUco augmented reality marker detector library. Essential for robotics research involving visual localization and object tracking.",
      "domains": [
        "Robotics",
        "Computer Vision"
      ],
      "subtask_category": [
        "pose_estimation",
        "tracking"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/pal-robotics/aruco_ros",
      "help_website": [
        "http://wiki.ros.org/aruco_ros"
      ],
      "license": "MIT",
      "tags": [
        "ros",
        "aruco",
        "robotics",
        "localization"
      ],
      "id": 775
    },
    {
      "name": "papercast",
      "one_line_profile": "Pipeline tool for processing and audio-converting technical papers",
      "detailed_description": "A modular pipeline tool for processing scientific documents from sources like arXiv. It uses GROBID for parsing and LangChain for processing, enabling workflows like summarizing papers or converting them to audio podcasts.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_processing",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/papercast-dev/papercast",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "arxiv",
        "grobid",
        "paper-processing",
        "accessibility"
      ],
      "id": 776
    },
    {
      "name": "Paper-to-Code",
      "one_line_profile": "Automates conversion of research paper concepts into code",
      "detailed_description": "A tool that leverages LLMs to interpret research papers and generate corresponding implementation code. It serves as a research agent to bridge the gap between theoretical publications and practical experimentation.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "code_generation",
        "literature_implementation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/pedroosodrac/Paper-to-Code",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "research-agent",
        "paper-implementation",
        "llm",
        "automation"
      ],
      "id": 777
    },
    {
      "name": "geodict",
      "one_line_profile": "Library for extracting location information from unstructured text",
      "detailed_description": "A Python library designed to identify and extract geographic location names from text. Useful for geospatial analysis in social sciences, earth sciences, and epidemiology to structure unstructured data.",
      "domains": [
        "Earth Science",
        "Social Science"
      ],
      "subtask_category": [
        "entity_extraction",
        "geocoding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/petewarden/geodict",
      "help_website": [],
      "license": null,
      "tags": [
        "geospatial",
        "nlp",
        "location-extraction"
      ],
      "id": 778
    },
    {
      "name": "Canopy",
      "one_line_profile": "Retrieval Augmented Generation (RAG) framework and context engine",
      "detailed_description": "A framework and context engine powered by Pinecone that handles the complexity of RAG pipelines, including chunking, embedding, and retrieval, enabling the construction of research agents and evidence-based AI applications.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_framework",
        "information_retrieval"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/pinecone-io/canopy",
      "help_website": [
        "https://github.com/pinecone-io/canopy"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "retrieval",
        "pinecone",
        "context-engine"
      ],
      "id": 779
    },
    {
      "name": "Korvus",
      "one_line_profile": "Search SDK unifying RAG pipeline in Postgres",
      "detailed_description": "A search SDK that unifies the entire RAG pipeline (embedding, search, generation) into a single database query within Postgres, facilitating efficient management of scientific knowledge bases.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_pipeline",
        "vector_search"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/postgresml/korvus",
      "help_website": [
        "https://postgresml.org/docs/korvus"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "postgres",
        "search-sdk",
        "vector-database"
      ],
      "id": 780
    },
    {
      "name": "YOLO-DocLayNet",
      "one_line_profile": "Document Layout Analysis models trained on DocLayNet",
      "detailed_description": "YOLO models trained on the DocLayNet dataset for performing document layout analysis, enabling the structural parsing of scientific papers and documents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_layout_analysis",
        "pdf_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ppaanngggg/yolo-doclaynet",
      "help_website": [
        "https://github.com/ppaanngggg/yolo-doclaynet"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "document-layout-analysis",
        "yolo",
        "pdf-parsing",
        "doclaynet"
      ],
      "id": 781
    },
    {
      "name": "QMiner",
      "one_line_profile": "Real-time large-scale data analytics platform",
      "detailed_description": "An analytic platform for processing real-time large-scale streams containing structured and unstructured data, suitable for scientific data mining and sensor stream analysis.",
      "domains": [
        "AI5",
        "AI4"
      ],
      "subtask_category": [
        "data_mining",
        "stream_analytics"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/qminer/qminer",
      "help_website": [
        "http://qminer.github.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "data-mining",
        "stream-processing",
        "analytics"
      ],
      "id": 782
    },
    {
      "name": "Eynollah",
      "one_line_profile": "Document Layout Analysis tool",
      "detailed_description": "A tool for document layout analysis that performs segmentation and structure recognition, useful for extracting content from scientific literature and historical documents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_layout_analysis",
        "pdf_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/qurator-spk/eynollah",
      "help_website": [
        "https://pypi.org/project/eynollah/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "document-layout-analysis",
        "ocr",
        "segmentation"
      ],
      "id": 783
    },
    {
      "name": "RAG Citation",
      "one_line_profile": "Citation generation for RAG systems",
      "detailed_description": "A library that enhances Retrieval-Augmented Generation (RAG) by automatically generating relevant citations for AI-generated content, ensuring credibility and evidence tracking in scientific agents.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "citation_generation",
        "evidence_grounding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rahulanand1103/rag-citation",
      "help_website": [
        "https://github.com/rahulanand1103/rag-citation"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "citation",
        "evidence",
        "grounding"
      ],
      "id": 784
    },
    {
      "name": "Llama-Researcher",
      "one_line_profile": "Autonomous research assistant for online literature review",
      "detailed_description": "A research assistant agent built with LlamaIndex Workflows that performs online research on a given topic, automating the process of literature discovery and summarization.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "literature_review",
        "autonomous_agent"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/rsrohan99/Llama-Researcher",
      "help_website": [
        "https://github.com/rsrohan99/Llama-Researcher"
      ],
      "license": null,
      "tags": [
        "research-agent",
        "llamaindex",
        "literature-review"
      ],
      "id": 785
    },
    {
      "name": "Markdrop",
      "one_line_profile": "PDF to Markdown converter with layout analysis for RAG pipelines",
      "detailed_description": "Markdrop is a Python package designed to convert PDF documents into Markdown format while preserving layout structures such as tables and images. It uses LLM clients to generate descriptive text for extracted visual elements, making it specifically suitable for preprocessing scientific literature for Retrieval-Augmented Generation (RAG) systems.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "document_layout_analysis",
        "data_preprocessing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shoryasethia/markdrop",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "pdf-to-markdown",
        "rag-preprocessing",
        "layout-analysis",
        "table-extraction"
      ],
      "id": 786
    },
    {
      "name": "Code Interpreter API",
      "one_line_profile": "Open source implementation of the ChatGPT Code Interpreter for agentic workflows",
      "detailed_description": "Code Interpreter API provides a sandbox environment for LLMs to execute Python code, enabling agents to perform data analysis, visualization, and complex calculations. It serves as a critical tool-calling component in scientific agent workflows where code execution is required for reasoning and data processing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "code_execution",
        "tool_calling",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shroominic/codeinterpreter-api",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "code-interpreter",
        "agent-tool",
        "sandbox",
        "python-execution"
      ],
      "id": 787
    },
    {
      "name": "STaRK",
      "one_line_profile": "Benchmark for LLM retrieval on textual and relational knowledge bases",
      "detailed_description": "STaRK is a benchmarking framework designed to evaluate the retrieval capabilities of Large Language Models (LLMs) over semi-structured knowledge bases that combine textual and relational data. It provides datasets and evaluation metrics essential for developing robust RAG systems in scientific domains where data is often hybrid.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "benchmarking",
        "retrieval_evaluation",
        "knowledge_base_retrieval"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/snap-stanford/stark",
      "help_website": [
        "https://stark-benchmark.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "benchmark",
        "retrieval",
        "knowledge-base",
        "rag-evaluation"
      ],
      "id": 788
    },
    {
      "name": "SUQL",
      "one_line_profile": "Conversational search framework over structured and unstructured data",
      "detailed_description": "SUQL (Structured and Unstructured Query Language) is a framework that extends SQL to support conversational search over hybrid data sources. It enables LLMs to query databases that contain both structured fields and unstructured text, facilitating complex evidence retrieval and grounding in scientific databases.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "retrieval",
        "query_language",
        "hybrid_search"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanford-oval/suql",
      "help_website": [
        "https://suql.stanford.edu/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "conversational-search",
        "hybrid-retrieval",
        "sql-extension",
        "rag"
      ],
      "id": 789
    },
    {
      "name": "GraphGPT",
      "one_line_profile": "Tool for extrapolating knowledge graphs from unstructured text using LLMs",
      "detailed_description": "A library that leverages GPT-3 to convert unstructured text into structured knowledge graphs, facilitating evidence chain construction and relationship extraction from scientific literature.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "knowledge_extraction",
        "graph_construction"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/varunshenoy/GraphGPT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "nlp",
        "unstructured-text"
      ],
      "id": 790
    },
    {
      "name": "Verba",
      "one_line_profile": "Retrieval Augmented Generation (RAG) chatbot platform powered by Weaviate",
      "detailed_description": "An open-source RAG application designed to ingest data (including documents) and perform semantic search and question answering, serving as a platform for literature review and knowledge retrieval.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_system",
        "semantic_search"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/weaviate/Verba",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "rag",
        "chatbot",
        "weaviate",
        "knowledge-retrieval"
      ],
      "id": 791
    },
    {
      "name": "Knowledge Table",
      "one_line_profile": "Tool for extracting structured data from unstructured documents",
      "detailed_description": "A package designed to simplify the extraction and exploration of structured data from unstructured documents (like PDFs), aiding in the creation of evidence chains and knowledge bases.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_extraction",
        "document_parsing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/whyhow-ai/knowledge-table",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "unstructured-data",
        "extraction",
        "rag"
      ],
      "id": 792
    },
    {
      "name": "E2M",
      "one_line_profile": "Universal file converter to Markdown for LLM ingestion",
      "detailed_description": "A tool that converts various file types (doc, docx, epub, html, pdf, etc.) into Markdown, specifically designed to prepare data for RAG systems and LLM processing.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "document_parsing",
        "format_conversion"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/wisupai/e2m",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "markdown",
        "converter",
        "rag-preparation",
        "pdf-parsing"
      ],
      "id": 793
    },
    {
      "name": "ThinkRAG",
      "one_line_profile": "Local RAG system for knowledge base QA",
      "detailed_description": "A Retrieval-Augmented Generation system designed to run locally, enabling researchers to build and query local knowledge bases from their documents securely.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_system",
        "knowledge_base"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wzdavid/ThinkRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "local-rag",
        "llm",
        "knowledge-base"
      ],
      "id": 794
    },
    {
      "name": "gpt_pdf_md",
      "one_line_profile": "PDF to Markdown converter using GPT-4V",
      "detailed_description": "A tool that leverages GPT-4V vision capabilities to convert PDF documents into Markdown, including image extraction, suitable for parsing complex scientific papers.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "document_conversion"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/yachty66/gpt_pdf_md",
      "help_website": [],
      "license": null,
      "tags": [
        "pdf-to-markdown",
        "gpt-4v",
        "ocr"
      ],
      "id": 795
    },
    {
      "name": "LEANN",
      "one_line_profile": "Efficient and private RAG application for personal devices",
      "detailed_description": "A RAG application optimized for storage savings and privacy, allowing researchers to run fast and accurate retrieval on their personal document collections.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "rag_system",
        "personal_knowledge_base"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yichuan-w/LEANN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "privacy",
        "local-llm"
      ],
      "id": 796
    },
    {
      "name": "llm-based-ocr",
      "one_line_profile": "High-accuracy PDF-to-Markdown OCR API using LLMs",
      "detailed_description": "An OCR tool that uses Large Language Models with vision capabilities to extract text and layout from PDFs, converting them to Markdown for downstream analysis.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "ocr_parsing",
        "document_digitization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yigitkonur/llm-based-ocr",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ocr",
        "pdf",
        "llm-vision"
      ],
      "id": 797
    },
    {
      "name": "Extractous",
      "one_line_profile": "Fast unstructured data extraction library",
      "detailed_description": "A high-performance library written in Rust for extracting text and metadata from unstructured data sources, supporting data ingestion pipelines for scientific RAG.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_extraction",
        "text_processing"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/yobix-ai/extractous",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rust",
        "extraction",
        "unstructured-data"
      ],
      "id": 798
    },
    {
      "name": "Faster-Nougat",
      "one_line_profile": "Optimized local implementation of the Nougat PDF parser",
      "detailed_description": "An efficient implementation of the Nougat model, specifically designed for parsing academic PDFs (including formulas and tables) into Markdown locally.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "pdf_parsing",
        "scientific_document_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhuzilin/faster-nougat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nougat",
        "pdf-parser",
        "academic-papers"
      ],
      "id": 799
    },
    {
      "name": "xpk",
      "one_line_profile": "Cluster orchestration tool for large-scale AI model training on TPUs/GPUs",
      "detailed_description": "xpk (Accelerated Processing Kit) is a software tool designed to help developers and researchers orchestrate large-scale deep learning training jobs on Google Kubernetes Engine (GKE), specifically optimizing for TPU and GPU accelerators. It facilitates the management of high-performance computing resources required for training scientific foundation models.",
      "domains": [
        "AI5",
        "AI5-06",
        "Scientific Computing"
      ],
      "subtask_category": [
        "model_training",
        "workflow_orchestration",
        "resource_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/AI-Hypercomputer/xpk",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "kubernetes",
        "tpu",
        "gpu",
        "orchestration"
      ],
      "id": 800
    },
    {
      "name": "Covalent",
      "one_line_profile": "Workflow orchestration tool for HPC, quantum, and ML experiments",
      "detailed_description": "Covalent is a Pythonic workflow orchestration tool designed for research scientists and engineers to manage complex experiments across heterogeneous compute environments, including high-performance computing (HPC) clusters, quantum computers, and cloud resources.",
      "domains": [
        "AI5",
        "AI5-06",
        "Quantum Computing"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "experiment_management",
        "distributed_computing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/AgnostiqHQ/covalent",
      "help_website": [
        "https://covalent.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow",
        "hpc",
        "quantum-computing",
        "machine-learning"
      ],
      "id": 801
    },
    {
      "name": "code-sandbox-mcp",
      "one_line_profile": "Secure Docker-based code execution sandbox for AI agents",
      "detailed_description": "An MCP (Model Context Protocol) server that provides a secure, isolated Docker environment for AI agents to execute code. This tool is essential for 'AI Scientist' agents to perform data analysis, simulation, and calculation tasks safely within a scientific workflow.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandbox",
        "agent_tool"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/Automata-Labs-team/code-sandbox-mcp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "sandbox",
        "docker",
        "ai-agent",
        "code-execution"
      ],
      "id": 802
    },
    {
      "name": "beanbox-vm",
      "one_line_profile": "MicroVM specifically designed for secure code execution by LLMs",
      "detailed_description": "A lightweight virtualization solution tailored for Large Language Models to execute code safely. It provides an isolated environment (sandbox) to prevent unauthorized access or damage to the host system during agentic workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandboxing"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/ErikKaum/beanbox-vm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sandbox",
        "llm-agent",
        "microvm",
        "security"
      ],
      "id": 803
    },
    {
      "name": "safe-code-execution",
      "one_line_profile": "Secure code execution utilities for AI interfaces like Open WebUI",
      "detailed_description": "A set of utilities designed to wrap and execute code generated by AI models within a secure, sandboxed environment. It is specifically integrated with platforms like Open WebUI and Ollama to enable safe agentic capabilities.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandboxing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EtiennePerot/safe-code-execution",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sandbox",
        "python",
        "security",
        "llm-tool"
      ],
      "id": 804
    },
    {
      "name": "Otter",
      "one_line_profile": "Multi-modal model based on OpenFlamingo for instruction following",
      "detailed_description": "A multi-modal Large Language Model (MLLM) designed for improved instruction-following and in-context learning capabilities. While primarily a model, it serves as a foundational tool for visual understanding tasks in scientific research agents.",
      "domains": [
        "AI4",
        "AI5"
      ],
      "subtask_category": [
        "visual_understanding",
        "multimodal_inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/EvolvingLMMs-Lab/Otter",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multimodal",
        "llm",
        "visual-question-answering",
        "deep-learning"
      ],
      "id": 805
    },
    {
      "name": "openai-o1-code-interpreter",
      "one_line_profile": "Code interpreter support utility for OpenAI o1 models",
      "detailed_description": "A tool designed to provide code interpretation capabilities specifically for the OpenAI o1 model series, enabling the model to execute code snippets for calculation or data processing tasks within a workflow.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "interpreter"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/FanaHOVA/openai-o1-code-interpreter",
      "help_website": [],
      "license": null,
      "tags": [
        "code-interpreter",
        "openai",
        "llm-tool"
      ],
      "id": 806
    },
    {
      "name": "kira",
      "one_line_profile": "Fast and scalable general-purpose sandbox code execution engine",
      "detailed_description": "A sandbox engine designed to execute untrusted code securely and efficiently. It is suitable for use in AI agent workflows where dynamic code generation and execution are required for data analysis or simulation.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandboxing"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/FlorianWoelki/kira",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sandbox",
        "execution-engine",
        "security"
      ],
      "id": 807
    },
    {
      "name": "llmesh",
      "one_line_profile": "Agentic tool mesh platform for orchestrating intelligent plugins",
      "detailed_description": "A platform designed to streamline the orchestration of AI tools and plugins. It serves as a central hub (mesh) for managing tool invocations and interactions within LLM-based agent workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "tool_invocation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/HewlettPackard/llmesh",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-orchestration",
        "tool-mesh",
        "llm-plugins"
      ],
      "id": 808
    },
    {
      "name": "mcp-bridge-api",
      "one_line_profile": "Proxy for connecting to multiple Model Context Protocol (MCP) servers",
      "detailed_description": "A bridge API that facilitates connections to various Model Context Protocol (MCP) servers. It enables LLMs to interact with external tools and contexts in a standardized way, supporting secure tool execution across environments.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "tool_invocation",
        "interoperability"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/INQUIRELAB/mcp-bridge-api",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "model-context-protocol",
        "tool-bridge"
      ],
      "id": 809
    },
    {
      "name": "IfcLCA",
      "one_line_profile": "Life Cycle Assessment tool for Built Environment using IFC",
      "detailed_description": "An open-source tool for performing Life Cycle Assessment (LCA) on built environment projects. It utilizes Industry Foundation Classes (IFC) data to calculate environmental impacts, supporting sustainable engineering and construction research.",
      "domains": [
        "AI4S",
        "Civil_Engineering"
      ],
      "subtask_category": [
        "life_cycle_assessment",
        "environmental_impact_analysis"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/IfcLCA/IfcLCA",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "lca",
        "ifc",
        "sustainability",
        "built-environment"
      ],
      "id": 810
    },
    {
      "name": "wasm_exec",
      "one_line_profile": "WASM-powered sandbox for safely running dynamic Python code",
      "detailed_description": "A sandbox implementation that uses WebAssembly (WASM) to execute Python code safely. This is particularly useful for AI agents requiring a secure, isolated environment to run generated code without risking the host system.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandboxing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Jflick58/wasm_exec",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "wasm",
        "sandbox",
        "python",
        "security"
      ],
      "id": 811
    },
    {
      "name": "k7",
      "one_line_profile": "Self-hosted infrastructure for lightweight VM sandboxes",
      "detailed_description": "A tool for deploying and managing lightweight virtual machine sandboxes. It provides a CLI, API, and Python SDK to safely execute untrusted code, making it an ideal infrastructure component for AI research agents.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandboxing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Katakate/k7",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sandbox",
        "vm",
        "infrastructure",
        "agent-execution"
      ],
      "id": 812
    },
    {
      "name": "MaestroWF",
      "one_line_profile": "Orchestration tool for computational workflows on HPC systems",
      "detailed_description": "A tool developed by LLNL to easily orchestrate general computational workflows both locally and on supercomputers, supporting complex scientific simulation pipelines.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "hpc_simulation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/LLNL/maestrowf",
      "help_website": [
        "https://maestrowf.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "hpc",
        "workflow",
        "orchestration",
        "simulation"
      ],
      "id": 813
    },
    {
      "name": "Local-Code-Interpreter",
      "one_line_profile": "Local implementation of OpenAI's Code Interpreter for data analysis",
      "detailed_description": "A local implementation of the Code Interpreter pattern, allowing execution of Python code generated by LLMs in a local environment, essential for scientific data analysis and visualization tasks.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "data_analysis"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/MrGreyfun/Local-Code-Interpreter",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "code-interpreter",
        "sandbox",
        "data-analysis"
      ],
      "id": 814
    },
    {
      "name": "OpenCodeInterpreter",
      "one_line_profile": "System for code generation and execution for data analysis",
      "detailed_description": "A suite of open-source code generation systems that integrates execution and iterative refinement, designed to bridge the gap between LLMs and sophisticated data analysis tasks.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_generation",
        "data_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenCodeInterpreter/OpenCodeInterpreter",
      "help_website": [
        "https://opencodeinterpreter.github.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "code-interpreter",
        "llm",
        "execution-sandbox"
      ],
      "id": 815
    },
    {
      "name": "ClaudeCage",
      "one_line_profile": "Sandboxed execution environment for Claude Code",
      "detailed_description": "A tool that wraps Claude Code in a container/sandbox environment, enabling safe execution of AI-generated code for analysis and development tasks.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_execution",
        "safe_code_running"
      ],
      "application_level": "tool",
      "primary_language": "Shell",
      "repo_url": "https://github.com/PACHAKUTlQ/ClaudeCage",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "sandbox",
        "claude",
        "container"
      ],
      "id": 816
    },
    {
      "name": "Arrakis",
      "one_line_profile": "Self-hosted sandboxing solution for AI agent code execution and workflow backtracking",
      "detailed_description": "Arrakis is a specialized sandboxing infrastructure designed for AI agents, enabling secure code execution, file manipulation, and workflow backtracking. It provides a REST API and Python SDK to orchestrate isolated environments (MicroVMs) for multi-step agentic tasks, essential for scientific agents performing data analysis or simulation.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandbox_environment",
        "agent_workflow"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/abshkbh/arrakis",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "sandbox",
        "ai-agent",
        "code-execution",
        "microvm"
      ],
      "id": 817
    },
    {
      "name": "Agent-Infra Sandbox",
      "one_line_profile": "All-in-One Docker-based sandbox environment for AI Agents",
      "detailed_description": "A comprehensive sandbox solution for AI agents that integrates Browser, Shell, File system, MCP (Model Context Protocol), and VSCode Server into a single Docker container. It provides a secure and interactive environment for agents to execute code, browse the web, and manage files, facilitating complex scientific agent workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_environment",
        "code_execution",
        "agent_tooling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/agent-infra/sandbox",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sandbox",
        "docker",
        "ai-agent",
        "mcp"
      ],
      "id": 818
    },
    {
      "name": "AgentScope",
      "one_line_profile": "Agent-oriented programming framework for building multi-agent LLM applications",
      "detailed_description": "AgentScope is a developer-centric framework for building multi-agent applications with Large Language Models (LLMs). It provides primitives for agent construction, message exchange, and tool usage, enabling the development of complex scientific agent systems for tasks like literature review, data analysis, and simulation orchestration.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "agent_framework",
        "workflow_orchestration",
        "multi_agent_system"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/agentscope-ai/agentscope",
      "help_website": [
        "https://agentscope.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "multi-agent",
        "llm",
        "framework",
        "agent-orchestration"
      ],
      "id": 819
    },
    {
      "name": "AgentScope Runtime",
      "one_line_profile": "Production-ready runtime environment for AgentScope agent deployment and tool sandboxing",
      "detailed_description": "The runtime component of the AgentScope framework, designed to handle the deployment and execution of agents. It includes features for tool sandboxing and distributed agent communication, ensuring secure and scalable execution of scientific agent workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "runtime_environment",
        "sandbox_execution",
        "agent_deployment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/agentscope-ai/agentscope-runtime",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "runtime",
        "agent-deployment",
        "sandbox"
      ],
      "id": 820
    },
    {
      "name": "AgentScope Runtime Java",
      "one_line_profile": "Java implementation of the AgentScope runtime for agent deployment",
      "detailed_description": "The Java-based implementation of the AgentScope runtime, enabling the deployment and execution of AgentScope agents within Java environments. It supports tool sandboxing and agent orchestration, facilitating integration with Java-based scientific infrastructure.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "runtime_environment",
        "sandbox_execution"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/agentscope-ai/agentscope-runtime-java",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "java",
        "runtime",
        "agent-scope"
      ],
      "id": 821
    },
    {
      "name": "Node Code Sandbox MCP",
      "one_line_profile": "Model Context Protocol (MCP) server for executing JavaScript in disposable Docker containers",
      "detailed_description": "A Model Context Protocol (MCP) server implementation that provides a secure, sandboxed environment for AI models to execute arbitrary JavaScript code. It uses disposable Docker containers to ensure isolation, enabling AI agents to perform data processing or calculation tasks safely.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandbox_environment",
        "mcp_server"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/alfonsograziano/node-code-sandbox-mcp",
      "help_website": [],
      "license": null,
      "tags": [
        "mcp",
        "sandbox",
        "docker",
        "code-execution"
      ],
      "id": 822
    },
    {
      "name": "Wuying Agentbay SDK",
      "one_line_profile": "SDK for Wuying Cloud Sandbox designed for AI Agents",
      "detailed_description": "The Python SDK for interacting with the Wuying Cloud Sandbox, a specialized environment built for AI agents. It allows agents to execute tasks in a secure, cloud-based sandbox, supporting workflows that require isolated execution and resource management.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_interface",
        "cloud_execution",
        "agent_tooling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aliyun/wuying-agentbay-sdk",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sdk",
        "cloud-sandbox",
        "ai-agent"
      ],
      "id": 823
    },
    {
      "name": "Semantic Router",
      "one_line_profile": "Superfast decision-making layer for LLMs and agents using semantic vector similarity",
      "detailed_description": "A library for superfast decision-making in AI agents and LLMs. It uses semantic vector similarity to route requests to the appropriate tools or handlers, enabling intelligent processing of multi-modal data and orchestration of scientific workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "tool_routing",
        "decision_making"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aurelio-labs/semantic-router",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent",
        "routing",
        "llm",
        "orchestration"
      ],
      "id": 824
    },
    {
      "name": "secimport",
      "one_line_profile": "eBPF-based sandbox for secure Python execution",
      "detailed_description": "An eBPF-based sandbox for Python that enforces precise syscall control and secures library imports. It is used to create secure execution environments for AI agents and scientific workflows running untrusted code.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_execution",
        "security_enforcement"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/avilum/secimport",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sandbox",
        "ebpf",
        "python",
        "security"
      ],
      "id": 825
    },
    {
      "name": "Autonomous Driving Data Framework (ADDF)",
      "one_line_profile": "Modular framework for processing and analyzing autonomous driving data",
      "detailed_description": "A collection of modules deployed using SeedFarmer to bootstrap environments for the processing, analysis, and visualization of autonomous driving data. It supports complex scientific/engineering data workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "data_processing",
        "workflow_orchestration",
        "data_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/awslabs/autonomous-driving-data-framework",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "autonomous-driving",
        "data-analysis",
        "workflow",
        "aws"
      ],
      "id": 826
    },
    {
      "name": "Chapyter",
      "one_line_profile": "ChatGPT Code Interpreter integration for Jupyter Notebooks",
      "detailed_description": "A Jupyter Notebook extension that integrates ChatGPT as a code interpreter, enabling natural language driven data analysis, visualization, and code generation directly within the scientific workbench.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "scientific_data_analysis",
        "scientific_visualization",
        "code_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chapyter/chapyter",
      "help_website": [
        "https://github.com/chapyter/chapyter"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyter",
        "llm-agent",
        "code-interpreter",
        "data-analysis"
      ],
      "id": 827
    },
    {
      "name": "quarto-pyodide",
      "one_line_profile": "Quarto extension for interactive Python execution via Pyodide",
      "detailed_description": "A Quarto extension that embeds Pyodide to enable interactive Python code cells within HTML documents, facilitating reproducible research, scientific data visualization, and interactive tutorials without backend servers.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "scientific_visualization",
        "reproducible_research",
        "interactive_computing"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/coatless-quarto/pyodide",
      "help_website": [
        "https://github.com/coatless-quarto/pyodide"
      ],
      "license": "MIT",
      "tags": [
        "quarto",
        "pyodide",
        "interactive-science",
        "wasm"
      ],
      "id": 828
    },
    {
      "name": "Cohere Terrarium",
      "one_line_profile": "Sandboxed execution environment for LLM-based data agents",
      "detailed_description": "A Python sandbox designed specifically for LLM data agents to execute generated code securely, enabling automated scientific data analysis and processing workflows driven by language models.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "scientific_data_analysis",
        "code_execution",
        "agent_workflow"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/cohere-ai/cohere-terrarium",
      "help_website": [
        "https://github.com/cohere-ai/cohere-terrarium"
      ],
      "license": "MIT",
      "tags": [
        "llm-agent",
        "sandbox",
        "data-analysis",
        "python-execution"
      ],
      "id": 829
    },
    {
      "name": "Sandbox Topically",
      "one_line_profile": "Topic modeling helpers using managed language models",
      "detailed_description": "A toolkit for performing topic modeling and text clustering using large language models (Cohere/GPT), facilitating qualitative data analysis and semantic structure discovery in scientific or textual datasets.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "scientific_data_analysis",
        "topic_modeling",
        "text_mining"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/cohere-ai/sandbox-topically",
      "help_website": [
        "https://github.com/cohere-ai/sandbox-topically"
      ],
      "license": "MIT",
      "tags": [
        "topic-modeling",
        "nlp",
        "clustering",
        "llm"
      ],
      "id": 830
    },
    {
      "name": "Octogen",
      "one_line_profile": "Open-source code interpreter agent framework for executing tasks",
      "detailed_description": "Octogen is a framework for building AI agents capable of interpreting and executing code to solve tasks, serving as a foundational tool for AI-driven data analysis and scientific workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_interpretation",
        "task_execution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dbpunk-labs/octogen",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "agent-framework",
        "code-interpreter",
        "llm-agent"
      ],
      "id": 831
    },
    {
      "name": "Gen AI Code Execution Agent",
      "one_line_profile": "Secure dynamic session agent for AI-generated code execution",
      "detailed_description": "A secure agent implementation designed to execute AI-generated code within isolated environments (Azure Container Apps), enabling safe data processing and analysis workflows for LLMs.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandbox_management"
      ],
      "application_level": "service",
      "primary_language": "Bicep",
      "repo_url": "https://github.com/denniszielke/gen-ai-code-execution-agent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "azure",
        "sandbox",
        "code-execution",
        "llm"
      ],
      "id": 832
    },
    {
      "name": "Agent Sandbox Skill",
      "one_line_profile": "Agent skill for managing isolated execution environments",
      "detailed_description": "A library providing skills for AI agents to manage and utilize isolated sandbox environments, facilitating secure code execution for data analysis and scientific tasks.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_management",
        "code_execution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/disler/agent-sandbox-skill",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "agent-skill",
        "sandbox",
        "python"
      ],
      "id": 833
    },
    {
      "name": "tsk",
      "one_line_profile": "Task manager and sandbox for coding agents",
      "detailed_description": "A tool designed to manage tasks and provide a sandboxed environment for coding agents, enabling secure execution of generated code for automated workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "task_management",
        "sandbox_execution"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/dtormoen/tsk",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-sandbox",
        "rust",
        "task-runner"
      ],
      "id": 834
    },
    {
      "name": "Claude Agent Server",
      "one_line_profile": "Server to run Claude Agent in a sandbox via websocket",
      "detailed_description": "A server implementation that wraps Claude Agent (Claude Code) in a secure sandbox environment, allowing remote control and execution of coding tasks via WebSocket.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "agent_hosting",
        "sandbox_execution"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/dzhng/claude-agent-server",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "claude",
        "agent-server",
        "sandbox"
      ],
      "id": 835
    },
    {
      "name": "AI Analyst",
      "one_line_profile": "AI agent for analyzing CSV files and creating charts",
      "detailed_description": "An open-source AI analyst agent powered by E2B sandboxes that automates the analysis of CSV data files and generates interactive visualizations using LLMs.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "data_analysis",
        "visualization"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/e2b-dev/ai-analyst",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-analysis",
        "agent",
        "visualization",
        "csv"
      ],
      "id": 836
    },
    {
      "name": "E2B Code Interpreter",
      "one_line_profile": "SDK for running AI-generated code in sandboxes",
      "detailed_description": "A Python and JS/TS SDK that enables AI applications to execute AI-generated code within secure E2B sandboxes, facilitating capabilities like data analysis and code interpretation.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_interpretation",
        "sandbox_integration"
      ],
      "application_level": "library",
      "primary_language": "MDX",
      "repo_url": "https://github.com/e2b-dev/code-interpreter",
      "help_website": [
        "https://e2b.dev/docs/code-interpreter/introduction"
      ],
      "license": "Apache-2.0",
      "tags": [
        "sdk",
        "code-interpreter",
        "sandbox"
      ],
      "id": 837
    },
    {
      "name": "E2B Desktop Sandbox",
      "one_line_profile": "Desktop graphical sandbox environment for LLM computer use",
      "detailed_description": "A sandboxed desktop environment designed for Large Language Models (LLMs) to perform computer use tasks securely. It provides a graphical interface and execution context for AI agents to interact with desktop applications and file systems.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_execution",
        "agent_environment"
      ],
      "application_level": "platform",
      "primary_language": "MDX",
      "repo_url": "https://github.com/e2b-dev/desktop",
      "help_website": [
        "https://e2b.dev/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "sandbox",
        "llm",
        "computer-use",
        "desktop-environment"
      ],
      "id": 838
    },
    {
      "name": "LLM Code Interpreter",
      "one_line_profile": "Advanced code interpreter for LLMs with internet and filesystem access",
      "detailed_description": "A code execution environment for LLMs (like ChatGPT) that allows running code in various languages, executing terminal processes, and accessing the filesystem and internet. It serves as a powerful tool for AI agents to perform computational tasks.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "agent_tool"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/e2b-dev/llm-code-interpreter",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "code-interpreter",
        "llm",
        "sandbox",
        "execution"
      ],
      "id": 839
    },
    {
      "name": "E2B MCP Server",
      "one_line_profile": "Model Context Protocol server for E2B sandbox integration",
      "detailed_description": "An implementation of the Model Context Protocol (MCP) that enables AI models (like Claude) to securely execute code within E2B sandboxes. It acts as a bridge between the LLM and the secure execution environment.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "tool_wrapping",
        "code_execution"
      ],
      "application_level": "service",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/e2b-dev/mcp-server",
      "help_website": [
        "https://modelcontextprotocol.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mcp",
        "sandbox",
        "claude",
        "integration"
      ],
      "id": 840
    },
    {
      "name": "Open Computer Use",
      "one_line_profile": "AI agent implementation for computer control using E2B sandboxes",
      "detailed_description": "An open-source implementation of an AI agent capable of 'computer use' (interacting with UI/desktop), powered by LLMs and running within the E2B Desktop Sandbox. It serves as a solver for automating desktop tasks via AI.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "agent_workflow",
        "computer_use"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/e2b-dev/open-computer-use",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent",
        "computer-use",
        "automation",
        "llm"
      ],
      "id": 841
    },
    {
      "name": "Rivet Plugin E2B",
      "one_line_profile": "E2B sandbox integration plugin for Rivet visual programming environment",
      "detailed_description": "A plugin for Rivet, a visual programming tool for AI agents, that provides nodes for interacting with E2B sandboxes. It enables the orchestration of code execution tasks within visual AI workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "tool_integration"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/e2b-dev/rivet-plugin-e2b",
      "help_website": [
        "https://rivet.ironcladapp.com/"
      ],
      "license": null,
      "tags": [
        "rivet",
        "plugin",
        "visual-programming",
        "sandbox"
      ],
      "id": 842
    },
    {
      "name": "Surf",
      "one_line_profile": "Natural language driven computer use AI agent",
      "detailed_description": "An AI agent powered by OpenAI models that interacts with a virtual desktop environment (E2B) through natural language instructions. It functions as a high-level solver for executing complex computer tasks via AI.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "agent_workflow",
        "computer_use"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/e2b-dev/surf",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent",
        "computer-use",
        "openai",
        "automation"
      ],
      "id": 843
    },
    {
      "name": "SymPy Beta",
      "one_line_profile": "Browser-based symbolic mathematics engine powered by SymPy",
      "detailed_description": "A Wolfram|Alpha-like answer engine that performs symbolic mathematics computations entirely in the browser using SymPy. It allows for solving mathematical problems without backend computation.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "symbolic_computation",
        "math_solver"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/eagleoflqj/sympy_beta",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "sympy",
        "math",
        "symbolic",
        "browser"
      ],
      "id": 844
    },
    {
      "name": "pooltool",
      "one_line_profile": "Physics-based billiards simulation library",
      "detailed_description": "A simulation package for billiards that emphasizes realistic physics modeling. It is used for research in event-based simulation and physics analysis of impact dynamics.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "physics_simulation",
        "dynamics_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ekiefl/pooltool",
      "help_website": [
        "https://pooltool.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "physics",
        "simulation",
        "billiards",
        "dynamics"
      ],
      "id": 845
    },
    {
      "name": "pgmpl",
      "one_line_profile": "Matplotlib-syntax wrapper for PyQtGraph visualization",
      "detailed_description": "A library that provides wrappers to allow calling PyQtGraph functions using Matplotlib syntax. It facilitates high-performance scientific visualization while maintaining a familiar API for researchers.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "scientific_visualization",
        "plotting"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/eldond/pgmpl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "matplotlib",
        "pyqtgraph",
        "plotting"
      ],
      "id": 846
    },
    {
      "name": "LetMeDoIt",
      "one_line_profile": "AI assistant for executing local computing tasks",
      "detailed_description": "An advanced AI assistant leveraging LLMs (ChatGPT, Gemini, AutoGen) to engage in conversations and execute computing tasks on local devices. It acts as an agentic solver for automating research or computational workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "agent_workflow",
        "task_automation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/eliranwong/letmedoit",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "agent",
        "automation",
        "llm",
        "cli"
      ],
      "id": 847
    },
    {
      "name": "MCP Server Code Execution",
      "one_line_profile": "MCP server for isolated Python code execution",
      "detailed_description": "A Model Context Protocol (MCP) server that executes Python code in isolated rootless containers. It provides a secure execution environment for AI agents to run scientific or general-purpose code.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "tool_wrapping"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/elusznik/mcp-server-code-execution-mode",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "mcp",
        "python",
        "sandbox",
        "execution"
      ],
      "id": 848
    },
    {
      "name": "Endor CLI",
      "one_line_profile": "CLI for managing instant sandboxed environments for AI agents",
      "detailed_description": "A command-line tool to provision and manage instant, private, sandboxed environments (like databases or servers). It is designed to support AI agents and rapid prototyping in secure environments.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_management",
        "environment_provisioning"
      ],
      "application_level": "service",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/endorhq/cli",
      "help_website": [
        "https://www.endor.ai/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "sandbox",
        "cli",
        "ai-agent",
        "infrastructure"
      ],
      "id": 849
    },
    {
      "name": "maplab",
      "one_line_profile": "Modular and multi-modal mapping framework for robotics",
      "detailed_description": "A framework for visual-inertial mapping and localization. It supports multi-session, multi-robot mapping and provides tools for map creation, processing, and evaluation in robotics research.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "mapping",
        "slam",
        "robotics_simulation"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/ethz-asl/maplab",
      "help_website": [
        "https://github.com/ethz-asl/maplab/wiki"
      ],
      "license": "Apache-2.0",
      "tags": [
        "slam",
        "robotics",
        "mapping",
        "visual-inertial"
      ],
      "id": 850
    },
    {
      "name": "Denoiser",
      "one_line_profile": "Real-time speech enhancement in the waveform domain",
      "detailed_description": "A PyTorch implementation of a causal speech enhancement model working on raw waveforms. It is capable of removing various kinds of background noise and reverb, useful for audio data processing in scientific research.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "signal_processing",
        "noise_reduction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/denoiser",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "audio",
        "speech-enhancement",
        "deep-learning",
        "pytorch"
      ],
      "id": 851
    },
    {
      "name": "Flow Matching",
      "one_line_profile": "PyTorch library for flow matching algorithms",
      "detailed_description": "A library for implementing flow matching algorithms, featuring continuous and discrete implementations. It supports research in generative modeling for text and image modalities.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "generative_modeling",
        "algorithm_implementation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/flow_matching",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "flow-matching",
        "generative-models",
        "pytorch",
        "machine-learning"
      ],
      "id": 852
    },
    {
      "name": "firectl",
      "one_line_profile": "Command-line tool to run Firecracker microVMs for secure isolation",
      "detailed_description": "Firectl is a CLI tool for Firecracker, a lightweight virtual machine monitor (VMM) that uses the Linux Kernel-based Virtual Machine (KVM) to create and manage microVMs. In the context of AI4S, it serves as a critical infrastructure component for securely sandboxing AI agent code execution.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_execution",
        "isolation_strategy"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/firecracker-microvm/firectl",
      "help_website": [
        "https://github.com/firecracker-microvm/firectl"
      ],
      "license": "Apache-2.0",
      "tags": [
        "microvm",
        "sandbox",
        "virtualization",
        "firecracker"
      ],
      "id": 853
    },
    {
      "name": "Marine",
      "one_line_profile": "Wasm runtime for multi-module applications with shared-nothing linking",
      "detailed_description": "Marine is a WebAssembly runtime that supports interface-types and a shared-nothing linking scheme. It provides a secure sandbox environment for executing multi-module Wasm applications, suitable for isolating scientific computation or agentic workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_execution",
        "wasm_runtime"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/fluencelabs/marine",
      "help_website": [
        "https://fluence.dev/docs/marine-book/introduction/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "webassembly",
        "wasm",
        "sandbox",
        "runtime"
      ],
      "id": 854
    },
    {
      "name": "Gate",
      "one_line_profile": "Platform for benign remote code execution and distributed computing",
      "detailed_description": "Gate is a system designed for remote code execution, allowing code to be moved to data or executed across clusters. It serves as an execution infrastructure that can support distributed scientific computing and agent-based workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "remote_execution",
        "distributed_computing"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/gate-computer/gate",
      "help_website": [
        "https://gate.computer/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "rce",
        "distributed-systems",
        "execution-engine"
      ],
      "id": 855
    },
    {
      "name": "gVisor",
      "one_line_profile": "Application kernel for containers providing strong isolation",
      "detailed_description": "gVisor is an application kernel, written in Go, that implements a substantial portion of the Linux system surface. It provides an isolation boundary between the application and the host kernel, making it a critical tool for securely executing untrusted scientific code or AI agent generated scripts.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_execution",
        "container_isolation"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/google/gvisor",
      "help_website": [
        "https://gvisor.dev/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "sandbox",
        "container",
        "security",
        "isolation"
      ],
      "id": 856
    },
    {
      "name": "nsjail",
      "one_line_profile": "Lightweight process isolation tool using Linux namespaces and seccomp-bpf",
      "detailed_description": "NsJail is a process isolation tool that utilizes Linux namespaces, cgroups, rlimits, and seccomp-bpf syscall filters. It is widely used to sandbox processes, making it highly relevant for securely running scientific analysis scripts generated by AI agents.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_execution",
        "process_isolation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/google/nsjail",
      "help_website": [
        "https://github.com/google/nsjail"
      ],
      "license": "Apache-2.0",
      "tags": [
        "sandbox",
        "isolation",
        "linux-namespaces",
        "security"
      ],
      "id": 857
    },
    {
      "name": "ipybox",
      "one_line_profile": "Python code sandbox designed for AI agent tool calling",
      "detailed_description": "ipybox is a Python code sandbox specifically designed to provide a secure environment for AI agents to execute code programmatically. It supports MCP (Model Context Protocol) tool calling, making it a direct component of the AI4S agent toolchain.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_interpreter",
        "sandbox_execution"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gradion-ai/ipybox",
      "help_website": [
        "https://github.com/gradion-ai/ipybox"
      ],
      "license": "Apache-2.0",
      "tags": [
        "sandbox",
        "llm-agent",
        "python",
        "code-interpreter"
      ],
      "id": 858
    },
    {
      "name": "graniet/llm",
      "one_line_profile": "CLI tool to orchestrate multiple LLM backends and workflows",
      "detailed_description": "A Rust-based library and CLI tool designed to unify and orchestrate multiple LLM backends (OpenAI, Claude, Ollama, etc.) into complex multi-step AI workflows. It serves as a workflow engine for AI agents, supporting reasoning and task execution chains.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "agent_framework"
      ],
      "application_level": "workflow",
      "primary_language": "Rust",
      "repo_url": "https://github.com/graniet/llm",
      "help_website": [
        "https://github.com/graniet/llm"
      ],
      "license": null,
      "tags": [
        "llm",
        "orchestration",
        "workflow",
        "agent"
      ],
      "id": 859
    },
    {
      "name": "aWsm",
      "one_line_profile": "WebAssembly ahead-of-time compiler and runtime",
      "detailed_description": "aWsm is a WebAssembly AOT compiler and runtime focused on generating fast, portable code. It serves as a sandboxed execution environment for Wasm modules, applicable in secure scientific computing workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_execution",
        "wasm_runtime"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/gwsystems/aWsm",
      "help_website": [
        "https://github.com/gwsystems/aWsm"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "webassembly",
        "compiler",
        "runtime",
        "sandbox"
      ],
      "id": 860
    },
    {
      "name": "sandwine",
      "one_line_profile": "Tool to run Windows applications in a sandboxed Wine environment",
      "detailed_description": "Sandwine is a command-line tool that runs Windows applications using Wine within a Bubblewrap sandbox. This allows for the secure and isolated execution of legacy scientific software (often Windows-only) on Linux clusters.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_execution",
        "compatibility_layer"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hartwork/sandwine",
      "help_website": [
        "https://github.com/hartwork/sandwine"
      ],
      "license": "GPL-3.0",
      "tags": [
        "sandbox",
        "wine",
        "bubblewrap",
        "windows-compat"
      ],
      "id": 861
    },
    {
      "name": "Code Interpreter",
      "one_line_profile": "Open-source Code Interpreter for LLMs supporting multiple models",
      "detailed_description": "An open-source implementation of a Code Interpreter that integrates with various LLMs (GPT, Gemini, Claude, LLaMa). It provides the execution environment for AI agents to write and run code for data analysis and scientific tasks.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_interpreter",
        "agent_tool"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/haseeb-heaven/code-interpreter",
      "help_website": [
        "https://github.com/haseeb-heaven/code-interpreter"
      ],
      "license": "MIT",
      "tags": [
        "llm",
        "code-interpreter",
        "agent",
        "data-analysis"
      ],
      "id": 862
    },
    {
      "name": "PRIMS",
      "one_line_profile": "MCP server for safe Python code execution by LLM agents",
      "detailed_description": "PRIMS (Python Runtime Interpreter MCP Server) is a lightweight Model Context Protocol server that enables LLM agents to execute arbitrary Python code in a secure, ephemeral sandbox. It is a specialized tool for the AI4S agent toolchain.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_interpreter",
        "sandbox_execution"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/hileamlakB/Python-Runtime-Interpreter-MCP-Server",
      "help_website": [
        "https://github.com/hileamlakB/Python-Runtime-Interpreter-MCP-Server"
      ],
      "license": "MIT",
      "tags": [
        "mcp",
        "sandbox",
        "python",
        "agent-tool"
      ],
      "id": 863
    },
    {
      "name": "EasyR1",
      "one_line_profile": "Efficient multi-modality Reinforcement Learning training framework",
      "detailed_description": "EasyR1 is a scalable Reinforcement Learning (RL) training framework based on veRL. It supports multi-modality training, making it a core tool for developing advanced AI models for scientific discovery and reasoning.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "model_training",
        "reinforcement_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hiyouga/EasyR1",
      "help_website": [
        "https://github.com/hiyouga/EasyR1"
      ],
      "license": "Apache-2.0",
      "tags": [
        "reinforcement-learning",
        "rl",
        "training-framework",
        "ai4s"
      ],
      "id": 864
    },
    {
      "name": "GoJudge",
      "one_line_profile": "Fast and secure code execution sandbox powered by nsjail",
      "detailed_description": "A high-performance code execution sandbox server based on Linux namespaces and cgroups (nsjail). It provides a secure environment for executing untrusted code, making it suitable for AI agents acting as code interpreters in scientific workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandbox_runner"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/huseynovvusal/gojudge",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sandbox",
        "nsjail",
        "code-execution",
        "security"
      ],
      "id": 865
    },
    {
      "name": "Hyperlight",
      "one_line_profile": "Lightweight Virtual Machine Manager for embedding safe code execution",
      "detailed_description": "A lightweight Virtual Machine Manager (VMM) designed to be embedded within applications. It enables the safe execution of untrusted code within micro virtual machines with very low latency, serving as a critical infrastructure for secure AI agent tool execution.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_execution",
        "isolation"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/hyperlight-dev/hyperlight",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vmm",
        "virtualization",
        "sandbox",
        "microvm"
      ],
      "id": 866
    },
    {
      "name": "CodeSherpa",
      "one_line_profile": "Code interpreter plugin for LLMs to execute analysis code",
      "detailed_description": "A code interpreter tool designed as a plugin for Large Language Models (like ChatGPT). It allows agents to write and execute code to perform calculations, data analysis, and other scientific tasks within a controlled environment.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_interpretation",
        "data_analysis"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/iamgreggarcia/codesherpa",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "code-interpreter",
        "llm-plugin",
        "agent-tool"
      ],
      "id": 867
    },
    {
      "name": "Sculptor",
      "one_line_profile": "Platform for running parallel coding agents in isolated sandboxes",
      "detailed_description": "A UI and orchestration platform for running parallel coding agents in safe, isolated sandboxes. It facilitates complex agent-based workflows where agents need to generate and execute code safely, supporting scientific simulation and analysis tasks.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "sandbox_management"
      ],
      "application_level": "platform",
      "primary_language": "Unknown",
      "repo_url": "https://github.com/imbue-ai/sculptor",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "agent-platform",
        "sandbox",
        "parallel-execution"
      ],
      "id": 868
    },
    {
      "name": "EvalGPT",
      "one_line_profile": "Code interpreter framework for automating tasks via LLMs",
      "detailed_description": "A code interpreter framework that utilizes large language models to automate the process of code-writing and execution. It provides the necessary tooling to connect LLMs with an execution environment for performing user-defined tasks, including data processing.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_interpretation",
        "task_automation"
      ],
      "application_level": "framework",
      "primary_language": "Go",
      "repo_url": "https://github.com/index-labs/evalgpt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "code-interpreter",
        "llm",
        "automation"
      ],
      "id": 869
    },
    {
      "name": "QiskitBot",
      "one_line_profile": "Sandboxed execution environment for Quantum Circuits",
      "detailed_description": "A bot interface that leverages nested containers (podman) to safely run untrusted user input for executing Quantum Circuits using Qiskit. It serves as a specialized sandbox runner for quantum computing tasks.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "quantum_simulation",
        "sandbox_execution"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/infiniteregrets/QiskitBot",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "quantum-computing",
        "qiskit",
        "sandbox",
        "podman"
      ],
      "id": 870
    },
    {
      "name": "Instill Core",
      "one_line_profile": "Full-stack AI infrastructure for data and model pipeline orchestration",
      "detailed_description": "A full-stack AI infrastructure tool designed to streamline data, model, and pipeline orchestration. It enables the construction of versatile data pipelines (VDP) for processing unstructured data (images, text) using AI models, applicable to scientific data processing workflows.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "pipeline_orchestration",
        "data_processing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/instill-ai/instill-core",
      "help_website": [
        "https://www.instill.tech/docs"
      ],
      "license": "NOASSERTION",
      "tags": [
        "pipeline-orchestration",
        "etl",
        "ai-infrastructure"
      ],
      "id": 871
    },
    {
      "name": "Pyodide Console",
      "one_line_profile": "Serverless Python environment for scientific computing via WebAssembly",
      "detailed_description": "A desktop application providing a serverless Python environment for scientific computing using WebAssembly (Pyodide). It offers a sandboxed runtime for executing Python scientific stacks (NumPy, Pandas, etc.) without local installation.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "scientific_computing",
        "sandbox_execution"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/inureyes/pyodide-console",
      "help_website": [],
      "license": null,
      "tags": [
        "pyodide",
        "webassembly",
        "scientific-computing",
        "sandbox"
      ],
      "id": 872
    },
    {
      "name": "jupylite_duckdb",
      "one_line_profile": "DuckDB-WASM integration for JupyterLite",
      "detailed_description": "Integrates DuckDB-WASM with JupyterLite and Pyodide, enabling serverless, sandboxed SQL data analysis and scientific computing directly in the browser.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "data_analysis",
        "sandbox_environment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/iqmo-org/jupylite_duckdb",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "duckdb",
        "wasm",
        "jupyterlite",
        "data-analysis"
      ],
      "id": 873
    },
    {
      "name": "Fortran Expression Evaluator",
      "one_line_profile": "Interpreter for evaluating Fortran expressions",
      "detailed_description": "An open-source Fortran expression evaluator (parser and interpreter). It allows for the dynamic evaluation of mathematical expressions using Fortran syntax, useful in scientific simulation and modeling contexts.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "expression_evaluation",
        "calculation"
      ],
      "application_level": "library",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/ivomarsoares-personal/Fortran-Expression-Evaluator",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "fortran",
        "interpreter",
        "math-expression"
      ],
      "id": 874
    },
    {
      "name": "labctl",
      "one_line_profile": "CLI for managing remote microVM playgrounds",
      "detailed_description": "A command-line tool to control iximiuz Labs, enabling the creation and management of remote microVM playgrounds. It serves as a tool for managing ephemeral, sandboxed environments for testing and execution.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_management",
        "microvm_orchestration"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/iximiuz/labctl",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "microvm",
        "sandbox",
        "cli"
      ],
      "id": 875
    },
    {
      "name": "JIProlog",
      "one_line_profile": "Cross-platform Prolog interpreter in Java",
      "detailed_description": "A pure Java 100% Prolog interpreter. It enables logic programming and reasoning tasks, which are applicable in AI and specific scientific modeling domains requiring logical inference.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "logic_programming",
        "inference"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/jiprolog/jiprolog",
      "help_website": [
        "http://www.jiprolog.com"
      ],
      "license": "NOASSERTION",
      "tags": [
        "prolog",
        "interpreter",
        "logic-programming"
      ],
      "id": 876
    },
    {
      "name": "Venice",
      "one_line_profile": "Sandboxed Lisp dialect for safe scripting",
      "detailed_description": "A Clojure-inspired Lisp dialect with Java interoperability, designed specifically as a safe, sandboxed scripting language. It provides a secure execution environment for dynamic scripts, suitable for AI agents executing generated code.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "scripting",
        "sandbox_execution"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/jlangch/venice",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lisp",
        "sandbox",
        "scripting",
        "security"
      ],
      "id": 877
    },
    {
      "name": "ONNX Script Editor",
      "one_line_profile": "Browser-based editor and visualizer for ONNX Script models",
      "detailed_description": "A web-based tool for visualizing and editing ONNX models using ONNX Script. It leverages Pyodide and Netron to run completely in the browser, enabling researchers to inspect and modify machine learning models without local setup.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "model_visualization",
        "model_editing"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/josephrocca/onnxscript-editor",
      "help_website": [
        "https://josephrocca.github.io/onnxscript-editor/"
      ],
      "license": "MIT",
      "tags": [
        "onnx",
        "visualization",
        "model-editing",
        "browser-based"
      ],
      "id": 878
    },
    {
      "name": "Replite",
      "one_line_profile": "Embeddable REPL component powered by JupyterLite",
      "detailed_description": "A lightweight, embeddable Read-Eval-Print Loop (REPL) powered by JupyterLite. It allows integrating a scientific Python computing environment directly into web applications, enabling interactive code execution for research and education.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "interactive_computing",
        "code_execution"
      ],
      "application_level": "library",
      "primary_language": "Shell",
      "repo_url": "https://github.com/jtpio/replite",
      "help_website": [
        "https://github.com/jtpio/replite"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyter",
        "repl",
        "wasm",
        "python"
      ],
      "id": 879
    },
    {
      "name": "JupyterLite",
      "one_line_profile": "Wasm-powered Jupyter running entirely in the browser",
      "detailed_description": "A JupyterLab distribution that runs entirely in the browser using WebAssembly. It provides a serverless scientific computing environment, enabling reproducible research and data analysis without backend infrastructure.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "scientific_computing_environment",
        "data_analysis"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/jupyterlite/jupyterlite",
      "help_website": [
        "https://jupyterlite.readthedocs.io/en/latest/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyter",
        "wasm",
        "scientific-computing",
        "browser-based"
      ],
      "id": 880
    },
    {
      "name": "Pyodide Kernel",
      "one_line_profile": "Python kernel for JupyterLite powered by Pyodide",
      "detailed_description": "The Python kernel for JupyterLite, built on top of Pyodide. It enables running the scientific Python stack (NumPy, Pandas, etc.) within the browser-based Jupyter environment, serving as a core component for serverless scientific workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "kernel_execution",
        "scientific_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jupyterlite/pyodide-kernel",
      "help_website": [
        "https://github.com/jupyterlite/pyodide-kernel"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyter",
        "pyodide",
        "kernel",
        "wasm"
      ],
      "id": 881
    },
    {
      "name": "pyodide-http",
      "one_line_profile": "HTTP request patching library for Pyodide environments",
      "detailed_description": "A utility library that patches standard Python HTTP libraries (like requests and urllib3) to work within the Pyodide WebAssembly environment. It is essential for enabling scientific Python code to fetch data and interact with APIs when running in browser-based sandboxes like JupyterLite.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "networking",
        "infrastructure_enabler"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/koenvo/pyodide-http",
      "help_website": [
        "https://github.com/koenvo/pyodide-http"
      ],
      "license": "MIT",
      "tags": [
        "pyodide",
        "networking",
        "wasm",
        "jupyterlite"
      ],
      "id": 882
    },
    {
      "name": "Agent Sandbox",
      "one_line_profile": "Sandbox runtime for managing AI agent workloads",
      "detailed_description": "A specialized sandbox runtime designed for managing isolated, stateful, and singleton workloads, specifically targeting AI agent runtimes. It provides the necessary infrastructure to securely execute and manage long-running AI agents in a Kubernetes environment.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "agent_execution",
        "sandbox_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubernetes-sigs/agent-sandbox",
      "help_website": [
        "https://github.com/kubernetes-sigs/agent-sandbox"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ai-agent",
        "sandbox",
        "kubernetes",
        "runtime"
      ],
      "id": 883
    },
    {
      "name": "langchain-sandbox",
      "one_line_profile": "Sandboxed execution environment for untrusted Python code in agent workflows",
      "detailed_description": "A secure sandbox environment designed for LangChain agents to execute untrusted Python code. It utilizes Pyodide and Deno to provide isolation, enabling agents to safely perform data analysis, calculation, and other dynamic tasks required in scientific research workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/langchain-ai/langchain-sandbox",
      "help_website": [],
      "license": null,
      "tags": [
        "sandbox",
        "python",
        "agent-execution",
        "security"
      ],
      "id": 884
    },
    {
      "name": "dify-sandbox",
      "one_line_profile": "Secure and lightweight code execution sandbox for AI agents",
      "detailed_description": "A specialized sandbox service designed for the Dify platform to execute code generated by AI agents. It supports multiple programming languages and provides a secure, isolated environment for running data processing and analysis scripts within scientific agent workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "data_analysis"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/langgenius/dify-sandbox",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sandbox",
        "code-execution",
        "isolation",
        "agent-infrastructure"
      ],
      "id": 885
    },
    {
      "name": "mflowgen",
      "one_line_profile": "Modular flow specification and build-system generator for ASIC/FPGA design",
      "detailed_description": "A tool for creating modular, sandboxed workflows for ASIC and FPGA design-space exploration. It allows researchers and engineers to construct complex hardware design flows using isolated nodes, facilitating reproducibility and scalability in electronic design automation (EDA) research.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "design_space_exploration",
        "simulation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/liv1n/mrflowgen",
      "help_website": [
        "https://mflowgen.readthedocs.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "eda",
        "asic",
        "fpga",
        "workflow",
        "modular-design"
      ],
      "id": 886
    },
    {
      "name": "TextWorld",
      "one_line_profile": "Sandbox learning environment for training reinforcement learning agents on text-based games",
      "detailed_description": "TextWorld is a sandbox learning environment for the training and evaluation of reinforcement learning (RL) agents on text-based games. It generates games and provides an interface for agents to interact with the environment, facilitating research in generalization and language understanding.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "environment_simulation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/TextWorld",
      "help_website": [
        "https://textworld-docs.azurewebsites.net/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "reinforcement-learning",
        "nlp",
        "sandbox",
        "simulation"
      ],
      "id": 887
    },
    {
      "name": "SEGAR",
      "one_line_profile": "Sandbox environment for generalizable agent research in reinforcement learning",
      "detailed_description": "SEGAR (Sandbox Environment for Generalizable Agent Research) is a research platform designed to test and improve the generalization capabilities of reinforcement learning agents through procedurally generated environments.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "environment_simulation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/segar",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "reinforcement-learning",
        "generalization",
        "sandbox"
      ],
      "id": 888
    },
    {
      "name": "UniLM",
      "one_line_profile": "Unified pre-training framework for large-scale self-supervised learning across tasks and modalities",
      "detailed_description": "UniLM (Unified Language Model) is a library providing large-scale self-supervised pre-training models and code for natural language processing, computer vision, and multi-modal tasks. It serves as a foundational tool for scientific text analysis and multi-modal data modeling.",
      "domains": [
        "AI5",
        "AI4"
      ],
      "subtask_category": [
        "model_training",
        "inference",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/unilm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nlp",
        "computer-vision",
        "pre-training",
        "transformer"
      ],
      "id": 889
    },
    {
      "name": "Wassette",
      "one_line_profile": "Security-oriented runtime for executing WebAssembly components via Model Context Protocol (MCP)",
      "detailed_description": "Wassette is a runtime environment designed to securely execute WebAssembly (WASM) components, integrated with the Model Context Protocol (MCP). It enables AI agents to safely invoke external tools and computations within a sandboxed environment.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_execution",
        "tool_wrapping"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/microsoft/wassette",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "webassembly",
        "sandbox",
        "agent-tools",
        "security"
      ],
      "id": 890
    },
    {
      "name": "modAL",
      "one_line_profile": "Modular active learning framework for optimizing data labeling and experimental design",
      "detailed_description": "modAL is an active learning framework for Python, designed to streamline the process of intelligent data labeling and experimental design. It allows researchers to build active learning pipelines with scikit-learn compatible estimators.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "active_learning",
        "experimental_design",
        "data_selection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/modAL-python/modAL",
      "help_website": [
        "https://modal-python.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "active-learning",
        "machine-learning",
        "optimization"
      ],
      "id": 891
    },
    {
      "name": "3D-Speaker",
      "one_line_profile": "Toolkit for single- and multi-modal speaker verification, recognition, and diarization",
      "detailed_description": "3D-Speaker is a comprehensive toolkit for speaker verification, recognition, and diarization. It supports large-scale pre-trained models and handles multi-modal data, serving as a tool for audio signal analysis and biometric research.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "audio_analysis",
        "speaker_recognition",
        "diarization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/modelscope/3D-Speaker",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "audio-processing",
        "speaker-verification",
        "biometrics"
      ],
      "id": 892
    },
    {
      "name": "ms-enclave",
      "one_line_profile": "Modular and stable agent sandbox runtime environment for secure tool execution",
      "detailed_description": "ms-enclave is a sandbox runtime environment specifically designed for AI agents. It provides a secure and isolated context for agents to execute code and invoke tools, ensuring safety and stability in automated workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_execution",
        "agent_runtime"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/modelscope/ms-enclave",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sandbox",
        "agent",
        "runtime",
        "security"
      ],
      "id": 893
    },
    {
      "name": "Brainchop",
      "one_line_profile": "In-browser 3D MRI rendering and volumetric segmentation tool",
      "detailed_description": "A client-side web-based tool for 3D MRI visualization and segmentation, allowing researchers to process neuroimaging data directly in the browser using WebGL and machine learning models.",
      "domains": [
        "Neuroscience",
        "Medical Imaging"
      ],
      "subtask_category": [
        "scientific_visualization",
        "image_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/neuroneural/brainchop",
      "help_website": [
        "https://brainchop.org"
      ],
      "license": "MIT",
      "tags": [
        "mri",
        "neuroimaging",
        "segmentation",
        "visualization"
      ],
      "id": 894
    },
    {
      "name": "Open Interpreter",
      "one_line_profile": "Local code execution agent for scientific workflows",
      "detailed_description": "A natural language interface that allows LLMs to run code (Python, JavaScript, Shell) locally, acting as an autonomous agent for scientific data analysis, simulation execution, and workflow orchestration.",
      "domains": [
        "AI5",
        "AI5-06",
        "Data Science"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "data_analysis",
        "code_generation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/openinterpreter/open-interpreter",
      "help_website": [
        "https://docs.openinterpreter.com/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "agent",
        "code-interpreter",
        "automation",
        "llm"
      ],
      "id": 895
    },
    {
      "name": "OpenTripPlanner",
      "one_line_profile": "Multi-modal transportation network analysis and routing engine",
      "detailed_description": "A software platform for multi-modal trip planning and transportation network analysis, widely used in urban planning research and geography for modeling accessibility and transit systems.",
      "domains": [
        "Urban Planning",
        "Transportation Science",
        "Geography"
      ],
      "subtask_category": [
        "scientific_modeling",
        "network_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/opentripplanner/OpenTripPlanner",
      "help_website": [
        "https://www.opentripplanner.org/"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "transportation",
        "routing",
        "urban-planning",
        "gis"
      ],
      "id": 896
    },
    {
      "name": "AeroSandbox",
      "one_line_profile": "Aircraft design optimization and aerodynamics analysis tool",
      "detailed_description": "A Python library for aircraft design optimization that leverages automatic differentiation for fast aerodynamic, propulsion, and structural analysis, enabling complex engineering simulations.",
      "domains": [
        "Aerospace Engineering",
        "Physics"
      ],
      "subtask_category": [
        "scientific_modeling",
        "optimization",
        "simulation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/peterdsharpe/AeroSandbox",
      "help_website": [
        "https://peterdsharpe.github.io/AeroSandbox/"
      ],
      "license": "MIT",
      "tags": [
        "aerodynamics",
        "optimization",
        "aircraft-design",
        "physics"
      ],
      "id": 897
    },
    {
      "name": "Polyaxon",
      "one_line_profile": "MLOps platform for reproducible machine learning experiments and workflow orchestration",
      "detailed_description": "Polyaxon is a platform for reproducing and managing the whole life cycle of machine learning projects, including workflow orchestration and sandboxed execution of experiments.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "experiment_tracking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/polyaxon/polyaxon",
      "help_website": [
        "https://polyaxon.com/docs/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "workflow-orchestration",
        "reproducibility",
        "kubernetes"
      ],
      "id": 898
    },
    {
      "name": "pctx",
      "one_line_profile": "Secure sandboxed execution layer for AI agent tool calls",
      "detailed_description": "pctx provides an execution layer for agentic tool calls, exposing custom tools and MCP servers as code that runs in secure sandboxes, facilitating safe code execution for AI agents.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_execution",
        "code_interpretation"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/portofcontext/pctx",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sandbox",
        "agent-tools",
        "security",
        "mcp"
      ],
      "id": 899
    },
    {
      "name": "sandbox-mcp",
      "one_line_profile": "MCP server for running code in isolated Docker containers",
      "detailed_description": "A Model Context Protocol (MCP) server that enables Large Language Models (LLMs) to execute arbitrary code safely within isolated Docker containers, serving as a secure sandbox runner.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_execution",
        "code_interpretation"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/pottekkat/sandbox-mcp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "sandbox",
        "docker",
        "llm-tools"
      ],
      "id": 900
    },
    {
      "name": "mcp-run-python",
      "one_line_profile": "MCP server to execute Python code in a secure sandbox environment",
      "detailed_description": "An MCP server implementation that allows AI agents to run Python code within a sandboxed environment, enabling safe code execution and data processing capabilities for LLMs.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_execution",
        "code_interpretation"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/pydantic/mcp-run-python",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "python",
        "sandbox",
        "agent-tools"
      ],
      "id": 901
    },
    {
      "name": "matplotlib-pyodide",
      "one_line_profile": "Matplotlib backend for rendering plots in Pyodide (WASM) environments",
      "detailed_description": "Provides HTML5 backends for Matplotlib, enabling scientific visualization within Pyodide-based browser sandboxes, essential for client-side scientific data analysis.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "scientific_visualization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pyodide/matplotlib-pyodide",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "visualization",
        "matplotlib",
        "wasm",
        "pyodide"
      ],
      "id": 902
    },
    {
      "name": "Pyodide",
      "one_line_profile": "Python distribution for the browser based on WebAssembly with scientific stack support",
      "detailed_description": "Pyodide is a port of CPython to WebAssembly/Emscripten, enabling the deployment of the scientific Python stack (NumPy, Pandas, Matplotlib, etc.) in browser sandboxes and Node.js.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "runtime_environment",
        "scientific_computing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/pyodide/pyodide",
      "help_website": [
        "https://pyodide.org/en/stable/"
      ],
      "license": "MPL-2.0",
      "tags": [
        "wasm",
        "python",
        "scientific-computing",
        "sandbox"
      ],
      "id": 903
    },
    {
      "name": "GPT Code UI",
      "one_line_profile": "Open source implementation of OpenAI's ChatGPT Code Interpreter",
      "detailed_description": "A web-based platform that provides a Python sandbox environment for Large Language Models (LLMs) to generate and execute code. It enables scientific workflows such as data analysis, visualization, and file processing through natural language instructions, mimicking the functionality of OpenAI's Code Interpreter.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "data_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ricklamers/gpt-code-ui",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "code-interpreter",
        "sandbox",
        "llm-agent",
        "data-analysis"
      ],
      "id": 904
    },
    {
      "name": "law",
      "one_line_profile": "Large-scale task workflow management system for High Energy Physics",
      "detailed_description": "A workflow management tool based on Luigi, designed for High Energy Physics (HEP) analyses. It handles job submission to remote infrastructure and provides environment sandboxing using Docker and Singularity, ensuring reproducible scientific computation pipelines.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "job_submission"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/riga/law",
      "help_website": [
        "https://law.readthedocs.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "workflow",
        "physics",
        "hep",
        "sandboxing",
        "luigi"
      ],
      "id": 905
    },
    {
      "name": "Smart Grasping Sandbox",
      "one_line_profile": "Simulation sandbox for robotic grasping research",
      "detailed_description": "A public simulation sandbox designed for research into robotic grasping using Shadow Robot's hardware. It provides a virtual environment (often via Jupyter Notebooks) for testing and developing grasping algorithms and control strategies.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "robotics_simulation",
        "control_policy"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/shadow-robot/smart_grasping_sandbox",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "robotics",
        "simulation",
        "grasping",
        "sandbox"
      ],
      "id": 906
    },
    {
      "name": "CodeBoxAPI",
      "one_line_profile": "Sandboxing infrastructure for LLM-based code execution",
      "detailed_description": "A scalable and secure sandboxing infrastructure designed to execute code generated by Large Language Models (LLMs). It serves as the backend execution engine for AI agents performing scientific data analysis, plotting, and calculation tasks.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox_execution",
        "code_interpreter"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/shroominic/codebox-api",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sandbox",
        "llm",
        "code-execution",
        "infrastructure"
      ],
      "id": 907
    },
    {
      "name": "CodeInterpreterAPI",
      "one_line_profile": "Open source implementation of ChatGPT Code Interpreter",
      "detailed_description": "A Python library that implements the Code Interpreter pattern for LLMs, allowing agents to execute Python code in a sandbox (using CodeBox) to perform data analysis, file manipulation, and visualization tasks relevant to scientific research.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shroominic/codeinterpreter-api",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent",
        "code-interpreter",
        "llm",
        "data-science"
      ],
      "id": 908
    },
    {
      "name": "IncognitoPilot",
      "one_line_profile": "Local AI code interpreter for sensitive data analysis",
      "detailed_description": "An AI code interpreter designed to run locally, enabling the secure analysis of sensitive scientific data using LLMs (like Llama 2 or GPT-4). It provides a sandbox environment where code is executed on the user's machine, ensuring data privacy.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "data_analysis"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/silvanmelchior/IncognitoPilot",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "local-llm",
        "code-interpreter",
        "privacy",
        "data-analysis"
      ],
      "id": 909
    },
    {
      "name": "WhyNot",
      "one_line_profile": "A Python sandbox for decision making and causal inference in dynamics",
      "detailed_description": "WhyNot is a Python sandbox designed for research in decision making within dynamic environments. It provides a set of simulators and tools to study causal inference and reinforcement learning in complex systems.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "simulation",
        "causal_inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/socialfoundations/whynot",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "causal-inference",
        "reinforcement-learning",
        "simulation",
        "sandbox"
      ],
      "id": 910
    },
    {
      "name": "Docker Code Interpreter",
      "one_line_profile": "Containerized environment for running Open-source Code Interpreters",
      "detailed_description": "A project providing one-click Docker applications for Open-source Code Interpreters, enabling secure and isolated execution of code generated by AI agents, facilitating data analysis and calculation tasks.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandbox_environment"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/soulteary/docker-code-interpreter",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "code-interpreter",
        "docker",
        "sandbox",
        "ai-agent"
      ],
      "id": 911
    },
    {
      "name": "Spring AI Agents",
      "one_line_profile": "Autonomous agent integrations for Spring AI with secure sandbox execution",
      "detailed_description": "A library providing autonomous agent capabilities for the Spring AI ecosystem, featuring secure sandbox execution environments for running agent-generated code, essential for reliable scientific workflows.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "code_execution"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/spring-ai-community/spring-ai-agents",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "spring-ai",
        "agent",
        "sandbox",
        "java"
      ],
      "id": 912
    },
    {
      "name": "QuantumSheet",
      "one_line_profile": "User-friendly mathematics worksheet and solver",
      "detailed_description": "A web-based tool for mathematical calculation and solving, providing a worksheet interface for executing mathematical operations and solving equations.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "calculation",
        "solver"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/stefnotch/quantum-sheet",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "math",
        "solver",
        "worksheet"
      ],
      "id": 913
    },
    {
      "name": "SandboxAI",
      "one_line_profile": "Isolated sandbox environment for running AI-generated code",
      "detailed_description": "A platform for executing code generated by AI agents in isolated sandboxes, ensuring safety and reproducibility for computational tasks and data analysis.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandbox_environment"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/substratusai/sandboxai",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "sandbox",
        "ai-code-execution",
        "security"
      ],
      "id": 914
    },
    {
      "name": "Super RAG",
      "one_line_profile": "RAG pipelines with integrated Code Interpreters",
      "detailed_description": "A library for building RAG pipelines that includes built-in Code Interpreter capabilities, allowing AI agents to perform data analysis and summarization tasks.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "data_analysis",
        "code_execution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/superagent-ai/super-rag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "code-interpreter",
        "data-analysis"
      ],
      "id": 915
    },
    {
      "name": "VibeKit",
      "one_line_profile": "Isolated sandbox for running coding agents",
      "detailed_description": "A toolkit for running coding agents (like Claude Code, Gemini) in clean, isolated sandboxes with data redaction and observability, facilitating secure scientific code execution.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandbox_environment"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/superagent-ai/vibekit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sandbox",
        "agent-runner",
        "code-execution"
      ],
      "id": 916
    },
    {
      "name": "OpenDataInterpreter",
      "one_line_profile": "Agent for data analytics and visualization",
      "detailed_description": "An AI agent tool designed to interpret data, perform analytics, and generate visualizations by conversing with the data, automating the data science workflow.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "data_analysis",
        "visualization"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/suvansh/OpenDataInterpreter",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "data-analysis",
        "visualization",
        "agent"
      ],
      "id": 917
    },
    {
      "name": "SymPy Live",
      "one_line_profile": "Web-based interactive shell for SymPy",
      "detailed_description": "A web-based interactive shell environment for SymPy, a Python library for symbolic mathematics, allowing users to perform symbolic computation in a browser sandbox.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "symbolic_computation",
        "calculation"
      ],
      "application_level": "platform",
      "primary_language": "CSS",
      "repo_url": "https://github.com/sympy/live",
      "help_website": [
        "https://live.sympy.org/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "sympy",
        "math",
        "symbolic-computation",
        "shell"
      ],
      "id": 918
    },
    {
      "name": "MCP Runner",
      "one_line_profile": "Sandboxed runner for Dockerized MCP Servers",
      "detailed_description": "A tool to run Model Context Protocol (MCP) servers in sandboxed Docker containers, enabling AI agents to securely invoke external tools and services.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "tool_invocation",
        "sandbox_environment"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/tangier-ai/mcp-runner",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mcp",
        "docker",
        "sandbox",
        "agent-tools"
      ],
      "id": 919
    },
    {
      "name": "sdsandbox",
      "one_line_profile": "Sandbox simulator for training self-driving cars",
      "detailed_description": "A simulation environment using Unity for training self-driving car models with Python, Keras, and Tensorflow, facilitating machine learning research in autonomous driving.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "simulation",
        "training"
      ],
      "application_level": "solver",
      "primary_language": "C#",
      "repo_url": "https://github.com/tawnkramer/sdsandbox",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "simulation",
        "autonomous-driving",
        "machine-learning",
        "unity"
      ],
      "id": 920
    },
    {
      "name": "Runno",
      "one_line_profile": "Sandboxed runtime for programming languages and WASI binaries",
      "detailed_description": "A sandboxed runtime environment that works in the browser or via MCP, allowing AI agents to execute code in various programming languages securely.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandbox_environment"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/taybenlor/runno",
      "help_website": [
        "https://runno.dev"
      ],
      "license": "MIT",
      "tags": [
        "sandbox",
        "wasi",
        "code-execution",
        "mcp"
      ],
      "id": 921
    },
    {
      "name": "Claude Code Sandbox",
      "one_line_profile": "Secure local Docker sandbox for Claude Code",
      "detailed_description": "A tool to run Claude Code agents safely in local Docker containers, providing an isolated environment for code execution and tool use without risking the host system.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandbox_environment"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/textcortex/claude-code-sandbox",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "claude",
        "docker",
        "sandbox",
        "security"
      ],
      "id": 922
    },
    {
      "name": "CodeBox AI",
      "one_line_profile": "Secure Python code execution sandbox designed for LLM agents",
      "detailed_description": "A self-hosted Python code execution service that provides a secure sandbox for Large Language Models (LLMs) to run generated code. It serves as an open-source alternative to OpenAI's Code Interpreter, enabling AI agents to perform data analysis and scientific calculation tasks safely.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandbox"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/tomconte/codebox-ai",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sandbox",
        "llm-agent",
        "code-interpreter",
        "python"
      ],
      "id": 923
    },
    {
      "name": "Tuplex",
      "one_line_profile": "High-performance parallel processing framework for Python data science pipelines",
      "detailed_description": "A big data processing framework that compiles Python data science pipelines into optimized LLVM bytecode. It allows data scientists to write standard Python code (similar to PySpark or Dask) while achieving performance comparable to compiled C++ code, specifically targeting scientific data cleaning and transformation tasks.",
      "domains": [
        "AI5",
        "AI5-06",
        "AI5-01"
      ],
      "subtask_category": [
        "data_processing",
        "pipeline_optimization"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/tuplex/tuplex",
      "help_website": [
        "https://tuplex.cs.brown.edu"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-science",
        "pipeline",
        "compiler",
        "llvm",
        "parallel-computing"
      ],
      "id": 924
    },
    {
      "name": "AI Code Sandbox",
      "one_line_profile": "Docker-based secure Python sandbox for AI code execution",
      "detailed_description": "A secure sandboxing solution designed to execute Python code generated by AI/ML models. It utilizes Docker to isolate the execution environment, making it suitable for AI agents performing data analysis, visualization, or other scientific computing tasks without risking the host system.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandbox"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/typper-io/ai-code-sandbox",
      "help_website": [],
      "license": null,
      "tags": [
        "sandbox",
        "docker",
        "llm",
        "python",
        "security"
      ],
      "id": 925
    },
    {
      "name": "Fiber",
      "one_line_profile": "Distributed computing library for large-scale AI and scientific computation",
      "detailed_description": "A Python distributed computing library developed by Uber that simplifies running large-scale AI and scientific computation workloads across computer clusters. It unifies the interface for local and distributed execution, supporting tasks like reinforcement learning, population-based training, and general scientific simulation.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "distributed_computing",
        "task_scheduling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/uber/fiber",
      "help_website": [
        "https://uber.github.io/fiber/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-systems",
        "hpc",
        "reinforcement-learning",
        "python"
      ],
      "id": 926
    },
    {
      "name": "Unity Catalog",
      "one_line_profile": "Open unified governance solution for data and AI assets",
      "detailed_description": "A unified governance catalog for data and AI, providing a centralized interface to manage tables, files, and ML models. It supports scientific data management by offering lineage, access control, and discovery capabilities for large-scale datasets used in AI for Science workflows.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "data_management",
        "data_governance"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/unitycatalog/unitycatalog",
      "help_website": [
        "https://www.unitycatalog.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-catalog",
        "governance",
        "lakehouse",
        "metadata"
      ],
      "id": 927
    },
    {
      "name": "LLM Sandbox",
      "one_line_profile": "Lightweight Python code interpreter sandbox for LLMs",
      "detailed_description": "A portable Python library that provides a sandboxed runtime environment for Large Language Models to execute code. It is designed to facilitate the development of AI agents that require safe code execution capabilities for tasks such as data analysis, mathematical calculation, and scientific simulation.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandbox"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vndee/llm-sandbox",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "code-interpreter",
        "sandbox",
        "llm",
        "python",
        "agent"
      ],
      "id": 928
    },
    {
      "name": "stlite",
      "one_line_profile": "Serverless Wasm runtime for Streamlit data science applications",
      "detailed_description": "A tool that enables running Streamlit applications entirely in the browser using WebAssembly (Pyodide), facilitating the deployment and sharing of scientific data visualization and analysis dashboards without backend infrastructure.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "scientific_visualization",
        "data_app_deployment"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/whitphx/stlite",
      "help_website": [
        "https://stlite.net"
      ],
      "license": "Apache-2.0",
      "tags": [
        "streamlit",
        "wasm",
        "data-science",
        "visualization",
        "pyodide"
      ],
      "id": 929
    },
    {
      "name": "OCP.wasm",
      "one_line_profile": "WebAssembly port of Build123d for browser-based CAD modeling",
      "detailed_description": "A tool wrapping the Build123d Python CAD library into WebAssembly, enabling parametric 3D modeling and engineering design directly in the browser.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "scientific_modeling",
        "cad",
        "engineering_design"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yeicor/OCP.wasm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cad",
        "wasm",
        "build123d",
        "modeling",
        "python"
      ],
      "id": 930
    },
    {
      "name": "mcp-code-execution-enhanced",
      "one_line_profile": "Sandboxed code execution provider for AI agents via MCP",
      "detailed_description": "A tool implementing the Model Context Protocol (MCP) for secure, sandboxed code execution, enabling AI agents to perform data analysis and scientific computation tasks safely.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "sandbox",
        "agent_tool"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/yoloshii/mcp-code-execution-enhanced",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "mcp",
        "sandbox",
        "agent",
        "code-execution"
      ],
      "id": 931
    },
    {
      "name": "code-atlas",
      "one_line_profile": "C++ implementation of Open Interpreter for efficient agentic code execution",
      "detailed_description": "A high-performance implementation of the Open Interpreter pattern, serving as a tool for AI agents to execute code for tasks such as data analysis and scientific computing.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "code_execution",
        "data_analysis",
        "agent_tool"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ystemsrx/code-atlas",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "open-interpreter",
        "agent",
        "code-execution",
        "cpp"
      ],
      "id": 932
    },
    {
      "name": "microsandbox",
      "one_line_profile": "Self-hosted sandboxes for AI agent code execution",
      "detailed_description": "A specialized sandbox environment designed for AI agents to securely execute generated code, essential for automated scientific data analysis and workflow orchestration.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox",
        "code_execution",
        "agent_infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/zerocore-ai/microsandbox",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sandbox",
        "ai-agent",
        "code-execution",
        "rust"
      ],
      "id": 933
    },
    {
      "name": "codeinterpreter-codebox",
      "one_line_profile": "Cloud sandbox service for Python code interpreters",
      "detailed_description": "A tool providing isolated Python environments (sandboxes) specifically for 'Code Interpreter' applications, enabling secure execution of data analysis and scientific code generated by LLMs.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "sandbox",
        "code_execution",
        "data_analysis"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhangzhejian/codeinterpreter-codebox",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "code-interpreter",
        "sandbox",
        "python",
        "llm"
      ],
      "id": 934
    },
    {
      "name": "pg_vectorize",
      "one_line_profile": "PostgreSQL extension for vector search and embedding generation",
      "detailed_description": "A tool that automates the transformation of text to embeddings and enables vector similarity search directly within PostgreSQL, facilitating high-dimensional data management for scientific applications.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "data_management"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/ChuckHend/pg_vectorize",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "postgres",
        "vector-search",
        "embeddings"
      ],
      "id": 935
    },
    {
      "name": "caiss",
      "one_line_profile": "High-performance cross-platform similarity search engine",
      "detailed_description": "A lightweight, high-performance search engine for vectors, text, and audio similarity, designed for efficient retrieval in large-scale datasets.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "similarity_search",
        "vector_indexing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ChunelFeng/caiss",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "vector-search",
        "similarity-search",
        "cpp"
      ],
      "id": 936
    },
    {
      "name": "VectorETL",
      "one_line_profile": "ETL framework for vector databases",
      "detailed_description": "A data processing tool designed to streamline the extraction, transformation, and loading of data into vector databases, supporting the preparation of scientific data for embedding-based analysis.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "data_processing",
        "etl"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ContextData/VectorETL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "etl",
        "vector-database",
        "data-pipeline"
      ],
      "id": 937
    },
    {
      "name": "SRS",
      "one_line_profile": "Fast approximate nearest neighbor search algorithm",
      "detailed_description": "An implementation of a fast approximate nearest neighbor search algorithm for high-dimensional Euclidean space, utilizing a tiny index for memory efficiency.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "nearest_neighbor_search",
        "algorithm_implementation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/DBAIWangGroup/SRS",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ann",
        "high-dimensional",
        "search-algorithm"
      ],
      "id": 938
    },
    {
      "name": "go-faiss",
      "one_line_profile": "Go bindings for the Faiss similarity search library",
      "detailed_description": "Provides Go language bindings for Faiss, enabling the use of efficient similarity search and clustering of dense vectors in Go-based scientific workflows.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "similarity_search",
        "clustering"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/DataIntelligenceCrew/go-faiss",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "faiss",
        "go",
        "bindings"
      ],
      "id": 939
    },
    {
      "name": "TorchPQ",
      "one_line_profile": "GPU-accelerated Product Quantization for PyTorch",
      "detailed_description": "A library for approximate nearest neighbor search using product quantization, optimized for GPU execution within the PyTorch ecosystem.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "nearest_neighbor_search",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/DeMoriarty/TorchPQ",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "gpu",
        "ann",
        "product-quantization"
      ],
      "id": 940
    },
    {
      "name": "faiss-rs",
      "one_line_profile": "Rust bindings for the Faiss similarity search library",
      "detailed_description": "Rust language bindings for Faiss, facilitating high-performance vector similarity search and clustering in Rust applications.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "similarity_search",
        "clustering"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/Enet4/faiss-rs",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "faiss",
        "rust",
        "bindings"
      ],
      "id": 941
    },
    {
      "name": "KRAGEN",
      "one_line_profile": "Knowledge Retrieval Augmented Generation with Graph of Thoughts",
      "detailed_description": "A research tool implementing the Graph of Thoughts (GoT) methodology combined with vector databases (Weaviate) to enhance knowledge retrieval and reasoning capabilities.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/EpistasisLab/KRAGEN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "graph-of-thoughts",
        "rag",
        "weaviate"
      ],
      "id": 942
    },
    {
      "name": "Embedding Studio",
      "one_line_profile": "Framework for optimizing vector database search quality",
      "detailed_description": "A framework designed to transform vector databases into feature-rich search engines by optimizing embeddings and search configurations, improving retrieval accuracy for scientific data.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "embedding_optimization",
        "search_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/EulerSearch/embedding_studio",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "embeddings",
        "vector-search",
        "optimization"
      ],
      "id": 943
    },
    {
      "name": "LiCoMemory",
      "one_line_profile": "Lightweight and Cognitive Agentic Memory Framework",
      "detailed_description": "An implementation of a cognitive memory system for AI agents, designed to enable efficient long-term reasoning and context management in research agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_memory",
        "reasoning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EverM0re/LiCoMemory",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "memory",
        "agents",
        "reasoning"
      ],
      "id": 944
    },
    {
      "name": "FalkorDB",
      "one_line_profile": "High-performance Graph Database using GraphBLAS",
      "detailed_description": "A graph database powered by GraphBLAS sparse matrix operations, optimized for low-latency graph algorithms and Knowledge Graph RAG applications.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "graph_database",
        "knowledge_graph"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/FalkorDB/FalkorDB",
      "help_website": [
        "https://docs.falkordb.com/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "graph-database",
        "graphblas",
        "knowledge-graph"
      ],
      "id": 945
    },
    {
      "name": "RAGonite",
      "one_line_profile": "Flexible RAG pipeline for heterogeneous data",
      "detailed_description": "A RAG framework developed by Fraunhofer IIS supporting conversational QA over structured and unstructured sources, including automated database induction from knowledge graphs.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "qa_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Fraunhofer-IIS/RAGonite",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "nlp",
        "knowledge-graph"
      ],
      "id": 946
    },
    {
      "name": "GoodAI LTM",
      "one_line_profile": "Long-term memory library for language model agents",
      "detailed_description": "A Python library designed to provide long-term memory capabilities to LLM-based agents, enabling them to maintain context over extended interactions, crucial for autonomous scientific agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "agent_context"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/GoodAI/goodai-ltm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "long-term-memory",
        "llm-agents",
        "context-management"
      ],
      "id": 947
    },
    {
      "name": "GoodAI LTM Benchmark",
      "one_line_profile": "Benchmark suite for evaluating agent long-term memory",
      "detailed_description": "A library and framework for benchmarking the long-term memory and continual learning capabilities of LLM-based agents, providing metrics for agent performance evaluation.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/GoodAI/goodai-ltm-benchmark",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "benchmark",
        "memory-evaluation",
        "continual-learning"
      ],
      "id": 948
    },
    {
      "name": "SubgraphRAG",
      "one_line_profile": "Knowledge-Graph-Based Retrieval-Augmented Generation Framework",
      "detailed_description": "Implementation of SubgraphRAG, a method that leverages subgraph structures in knowledge graphs to enhance retrieval-augmented generation for LLMs, improving reasoning capabilities.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "rag_algorithm",
        "knowledge_graph_reasoning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Graph-COM/SubgraphRAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "knowledge-graph",
        "subgraph",
        "iclr-2025"
      ],
      "id": 949
    },
    {
      "name": "DiffMem",
      "one_line_profile": "Git-based memory storage for conversational AI agents",
      "detailed_description": "A memory storage solution for AI agents that utilizes Git's version control mechanisms to manage and retrieve conversational history and context.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "version_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Growth-Kinetics/DiffMem",
      "help_website": [],
      "license": null,
      "tags": [
        "memory-storage",
        "git",
        "agent-memory"
      ],
      "id": 950
    },
    {
      "name": "AutoSchemaKG",
      "one_line_profile": "Automatic knowledge graph construction framework",
      "detailed_description": "A framework for automatic knowledge graph construction that combines schema generation via conceptualization, facilitating the organization of unstructured data into structured knowledge.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "kg_construction",
        "schema_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HKUST-KnowComp/AutoSchemaKG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "schema-induction",
        "ie"
      ],
      "id": 951
    },
    {
      "name": "HelixDB",
      "one_line_profile": "Rust-based graph-vector database",
      "detailed_description": "An open-source graph-vector database built from scratch in Rust, designed for high-performance storage and retrieval of complex relationships and vector embeddings.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_database",
        "graph_database"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/HelixDB/helix-db",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "database",
        "vector-db",
        "graph-db",
        "rust"
      ],
      "id": 952
    },
    {
      "name": "GraphBit",
      "one_line_profile": "Enterprise-grade agentic AI framework",
      "detailed_description": "An Agentic AI framework built on a Rust core with a Python wrapper, designed for high-performance multi-agent workflows and secure execution.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_framework",
        "workflow_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Rust",
      "repo_url": "https://github.com/InfinitiBit/graphbit",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "agent-framework",
        "rust",
        "multi-agent"
      ],
      "id": 953
    },
    {
      "name": "RAG-FiT",
      "one_line_profile": "Framework for fine-tuning LLMs for RAG tasks",
      "detailed_description": "A framework developed by Intel Labs for enhancing Large Language Models specifically for Retrieval-Augmented Generation tasks through fine-tuning techniques.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "model_finetuning",
        "rag_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IntelLabs/RAG-FiT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "fine-tuning",
        "llm"
      ],
      "id": 954
    },
    {
      "name": "fastRAG",
      "one_line_profile": "Efficient Retrieval Augmentation and Generation Framework",
      "detailed_description": "A framework by Intel Labs optimized for efficient and scalable Retrieval-Augmented Generation, integrating various retrieval and generation components.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "rag_framework",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IntelLabs/fastRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "efficiency",
        "intel"
      ],
      "id": 955
    },
    {
      "name": "RangeFilteredANN",
      "one_line_profile": "Algorithms for range-filtered approximate nearest neighbor search",
      "detailed_description": "A library implementing algorithms for approximate nearest neighbor search with window/range filters, optimizing vector retrieval tasks.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "ann_algorithm"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/JoshEngels/RangeFilteredANN",
      "help_website": [],
      "license": null,
      "tags": [
        "ann",
        "vector-search",
        "algorithms"
      ],
      "id": 956
    },
    {
      "name": "WEAVESS",
      "one_line_profile": "Benchmark framework for graph-based ANN search",
      "detailed_description": "A comprehensive survey and experimental comparison framework for Graph-based Approximate Nearest Neighbor (ANN) search algorithms, useful for evaluating vector database performance.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "benchmarking",
        "vector_search"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/Lsyhprum/WEAVESS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ann",
        "benchmark",
        "graph-search"
      ],
      "id": 957
    },
    {
      "name": "TextMatch",
      "one_line_profile": "Toolkit for text matching, embedding, and retrieval",
      "detailed_description": "A comprehensive toolkit for text matching, classification, embedding, clustering, and retrieval, integrating various algorithms like BERT, FAISS, and BM25.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "text_analysis",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MachineLP/TextMatch",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "text-matching",
        "embedding"
      ],
      "id": 958
    },
    {
      "name": "arrowspace-rs",
      "one_line_profile": "Vector database utilizing dispersion models for graph analysis and search",
      "detailed_description": "A Rust-based vector database that implements dispersion models. It provides capabilities for graph analysis, vector search, and key-value storage, suitable for managing high-dimensional scientific data embeddings.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "graph_analysis"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/Mec-iS/arrowspace-rs",
      "help_website": [
        "https://github.com/Mec-iS/arrowspace-rs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "rust",
        "graph-analysis"
      ],
      "id": 959
    },
    {
      "name": "MemMachine",
      "one_line_profile": "Universal memory layer for AI agent state management",
      "detailed_description": "A framework providing scalable and interoperable memory storage and retrieval for AI agents. It enables long-term state management, which is crucial for autonomous scientific agents conducting extended research tasks.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "state_tracking"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/MemMachine/MemMachine",
      "help_website": [
        "https://github.com/MemMachine/MemMachine"
      ],
      "license": "Apache-2.0",
      "tags": [
        "agent-memory",
        "llm",
        "state-management"
      ],
      "id": 960
    },
    {
      "name": "MemOS",
      "one_line_profile": "Operating system-like framework for LLM long-term memory",
      "detailed_description": "MemOS serves as a memory operating system for building memory-native AI agents. It handles long-term memory storage, retrieval, and adaptive learning, facilitating the development of agents that can retain scientific context over time.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "adaptive_learning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/MemTensor/MemOS",
      "help_website": [
        "https://github.com/MemTensor/MemOS"
      ],
      "license": "Apache-2.0",
      "tags": [
        "memory-os",
        "agent-framework",
        "retrieval"
      ],
      "id": 961
    },
    {
      "name": "Memori",
      "one_line_profile": "SQL-native memory layer for multi-agent systems",
      "detailed_description": "A memory layer designed for LLMs and AI agents that utilizes SQL for structured data storage. It supports multi-agent systems, enabling complex scientific workflows where agents need to share and query structured knowledge.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "structured_storage"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MemoriLabs/Memori",
      "help_website": [
        "https://github.com/MemoriLabs/Memori"
      ],
      "license": "NOASSERTION",
      "tags": [
        "sql",
        "memory-layer",
        "multi-agent"
      ],
      "id": 962
    },
    {
      "name": "MindSQL",
      "one_line_profile": "Text-to-SQL RAG library for database interactions",
      "detailed_description": "A library that simplifies interactions with SQL databases (PostgreSQL, MySQL, etc.) using LLMs. It integrates with vector databases like ChromaDB to provide context-aware responses, aiding scientists in querying structured experimental data using natural language.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "data_querying",
        "text_to_sql"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Mindinventory/MindSQL",
      "help_website": [
        "https://github.com/Mindinventory/MindSQL"
      ],
      "license": "GPL-3.0",
      "tags": [
        "text-to-sql",
        "rag",
        "database-interface"
      ],
      "id": 963
    },
    {
      "name": "vicinity",
      "one_line_profile": "Lightweight nearest neighbors library with flexible backends",
      "detailed_description": "A Python library for performing nearest neighbor searches with support for various backends. It is useful for scientific data analysis tasks requiring similarity search and clustering without the overhead of heavy vector databases.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "similarity_search",
        "clustering"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MinishLab/vicinity",
      "help_website": [
        "https://github.com/MinishLab/vicinity"
      ],
      "license": "MIT",
      "tags": [
        "nearest-neighbors",
        "vector-search",
        "similarity"
      ],
      "id": 964
    },
    {
      "name": "SGPT",
      "one_line_profile": "GPT-based sentence embeddings for semantic search",
      "detailed_description": "A tool for generating sentence embeddings using GPT models, optimized for semantic search tasks. It is valuable for indexing and retrieving scientific literature or textual data based on semantic meaning.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "embedding_generation",
        "semantic_search"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Muennighoff/sgpt",
      "help_website": [
        "https://github.com/Muennighoff/sgpt"
      ],
      "license": "MIT",
      "tags": [
        "embeddings",
        "semantic-search",
        "gpt"
      ],
      "id": 965
    },
    {
      "name": "memU",
      "one_line_profile": "Memory infrastructure for LLMs and AI agents",
      "detailed_description": "Provides memory infrastructure for Large Language Models and AI agents, enabling the persistence of interaction history and context. This is essential for creating consistent and context-aware scientific assistants.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_infrastructure",
        "context_persistence"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/NevaMind-AI/memU",
      "help_website": [
        "https://github.com/NevaMind-AI/memU"
      ],
      "license": "NOASSERTION",
      "tags": [
        "memory",
        "llm",
        "infrastructure"
      ],
      "id": 966
    },
    {
      "name": "HippoRAG",
      "one_line_profile": "Neuroscience-inspired RAG framework using Knowledge Graphs",
      "detailed_description": "HippoRAG is a retrieval-augmented generation framework inspired by human long-term memory mechanisms (hippocampus). It utilizes Knowledge Graphs and Personalized PageRank to enable LLMs to continuously integrate and retrieve knowledge across documents, suitable for complex scientific literature synthesis.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "knowledge_integration",
        "associative_retrieval"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/OSU-NLP-Group/HippoRAG",
      "help_website": [
        "https://github.com/OSU-NLP-Group/HippoRAG"
      ],
      "license": "MIT",
      "tags": [
        "rag",
        "knowledge-graph",
        "neuroscience-inspired"
      ],
      "id": 967
    },
    {
      "name": "dkg-engine",
      "one_line_profile": "Decentralized Knowledge Graph network node engine",
      "detailed_description": "The engine for running nodes in the OriginTrail Decentralized Knowledge Graph. It facilitates the creation and querying of verifiable, distributed knowledge graphs, which can be applied to scientific data provenance and sharing.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "knowledge_graph_infrastructure",
        "data_provenance"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/OriginTrail/dkg-engine",
      "help_website": [
        "https://docs.origintrail.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dkg",
        "knowledge-graph",
        "decentralized"
      ],
      "id": 968
    },
    {
      "name": "percolate",
      "one_line_profile": "In-database agentic orchestrator",
      "detailed_description": "An agent orchestrator that resides inside a relational-vector-graph/key-value database. It enables data-centric agent workflows where logic is executed close to the data, improving efficiency for data-intensive scientific applications.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_orchestration",
        "in_database_processing"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Percolation-Labs/percolate",
      "help_website": [
        "https://github.com/Percolation-Labs/percolate"
      ],
      "license": "MIT",
      "tags": [
        "agent-orchestrator",
        "database",
        "workflow"
      ],
      "id": 969
    },
    {
      "name": "dataroom",
      "one_line_profile": "Vector database framework for managing large image datasets",
      "detailed_description": "A framework built on vector databases to store, manage, and curate large image datasets. It is particularly useful for scientific imaging tasks (e.g., microscopy, astronomy) where semantic search and organization of visual data are required.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "image_dataset_management",
        "visual_search"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Photoroom/dataroom",
      "help_website": [
        "https://github.com/Photoroom/dataroom"
      ],
      "license": "MIT",
      "tags": [
        "image-management",
        "vector-database",
        "curation"
      ],
      "id": 970
    },
    {
      "name": "Piazza-Updater",
      "one_line_profile": "Automated data synchronization tool for Weaviate databases",
      "detailed_description": "A tool that automates updates to Weaviate vector databases with real-time data. It integrates with repositories to enhance RAG capabilities, ensuring that scientific knowledge bases are kept current with the latest information.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "data_synchronization",
        "knowledge_base_maintenance"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/Piazza-tech/Piazza-Updater",
      "help_website": [
        "https://github.com/Piazza-tech/Piazza-Updater"
      ],
      "license": "MIT",
      "tags": [
        "weaviate",
        "data-sync",
        "rag"
      ],
      "id": 971
    },
    {
      "name": "Raphtory",
      "one_line_profile": "Scalable temporal graph analytics engine",
      "detailed_description": "A graph analytics database powered by a multithreaded, vectorized temporal engine. It is designed to analyze dynamic networks and temporal interactions, which is essential for modeling complex systems in biology, physics, and social sciences.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "temporal_graph_analysis",
        "network_dynamics"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/Pometry/Raphtory",
      "help_website": [
        "https://raphtory.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "graph-analytics",
        "temporal-graphs",
        "rust"
      ],
      "id": 972
    },
    {
      "name": "RediSearch",
      "one_line_profile": "Query and indexing engine for Redis with vector similarity search",
      "detailed_description": "A Redis module that provides secondary indexing, full-text search, and vector similarity search, serving as a high-performance memory/knowledge retrieval backend for AI agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "indexing",
        "data_retrieval"
      ],
      "application_level": "service",
      "primary_language": "C",
      "repo_url": "https://github.com/RediSearch/RediSearch",
      "help_website": [
        "https://redis.io/docs/stack/search/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "vector-database",
        "redis",
        "similarity-search"
      ],
      "id": 973
    },
    {
      "name": "OctaneDB",
      "one_line_profile": "High-performance lightweight vector database library",
      "detailed_description": "A Python-based vector database library designed for speed and efficiency, offering an alternative to heavier solutions for local vector storage and retrieval in AI workflows.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "embedding_storage"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/RijinRaju/octanedb",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vector-database",
        "python",
        "local-storage"
      ],
      "id": 974
    },
    {
      "name": "osgrep",
      "one_line_profile": "Open source semantic search tool for AI agents",
      "detailed_description": "A tool designed to provide semantic search capabilities specifically for AI agents, enabling them to retrieve relevant context from local files or data sources.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "semantic_search",
        "context_retrieval"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/Ryandonofrio3/osgrep",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "semantic-search",
        "agent-tool",
        "rag"
      ],
      "id": 975
    },
    {
      "name": "LangChain Integration for SAP HANA",
      "one_line_profile": "LangChain integration for SAP HANA Cloud vector and graph capabilities",
      "detailed_description": "A library that integrates SAP HANA Cloud's vector search and knowledge graph capabilities into the LangChain framework, enabling enterprise-grade data retrieval for research agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "knowledge_graph",
        "integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SAP/langchain-integration-for-sap-hana-cloud",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "langchain",
        "sap-hana",
        "vector-store"
      ],
      "id": 976
    },
    {
      "name": "esProc SPL",
      "one_line_profile": "Structured data computation engine and analysis language",
      "detailed_description": "A JVM-based data analysis engine and programming language specialized for structured data computation, suitable for complex scientific data processing and statistical analysis.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "data_analysis",
        "scientific_calculation",
        "data_processing"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/SPLWare/esProc",
      "help_website": [
        "http://www.raqsoft.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-analysis",
        "structured-data",
        "computation-engine"
      ],
      "id": 977
    },
    {
      "name": "Project Cortex",
      "one_line_profile": "Unified memory system for LLM agents",
      "detailed_description": "A production-ready memory system designed to scale automatically and work with various LLM frameworks, providing long-term context management for research agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "context_storage"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/SaintNick1214/Project-Cortex",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "memory",
        "llm-agent",
        "vector-store"
      ],
      "id": 978
    },
    {
      "name": "CAMEL (GPT-Agent)",
      "one_line_profile": "Role-playing agent framework for multi-agent collaboration",
      "detailed_description": "An implementation of the CAMEL framework (Communicative Agents for 'Mind' Exploration of Large Scale Language Model Society), enabling multi-agent collaboration for solving complex tasks.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "agent_simulation",
        "multi_agent_collaboration"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/SamurAIGPT/GPT-Agent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "multi-agent",
        "role-playing",
        "collaboration"
      ],
      "id": 979
    },
    {
      "name": "SciPhi Synthesizer",
      "one_line_profile": "LLM framework for RAG and synthetic data creation",
      "detailed_description": "A framework designed to facilitate Retrieval-Augmented Generation (RAG) and the generation of synthetic datasets, useful for training and validating scientific models.",
      "domains": [
        "AI5",
        "AI5-06"
      ],
      "subtask_category": [
        "data_synthesis",
        "rag_pipeline"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SciPhi-AI/synthesizer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "synthetic-data",
        "rag",
        "llm-framework"
      ],
      "id": 980
    },
    {
      "name": "Vectra",
      "one_line_profile": "Local file-based vector database for Node.js",
      "detailed_description": "A lightweight, local vector database library for Node.js that stores data in local files, suitable for lightweight agent memory or local semantic search applications.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "local_storage"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/Stevenic/vectra",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vector-database",
        "local",
        "nodejs"
      ],
      "id": 981
    },
    {
      "name": "TeleMem",
      "one_line_profile": "High-performance multi-character memory system",
      "detailed_description": "A memory system compatible with Mem0, featuring semantic deduplication and long-term dialogue memory, designed to support complex reasoning and multimodal interactions for agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "semantic_deduplication",
        "multimodal_memory"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TeleAI-UAGI/telemem",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "memory",
        "agent",
        "long-term-context"
      ],
      "id": 982
    },
    {
      "name": "swarms-memory",
      "one_line_profile": "Memory wrappers for Swarms agent framework",
      "detailed_description": "A collection of wrappers for various vector databases (ChromaDB, Weaviate, Pinecone) to provide unified memory management capabilities for the Swarms agent framework.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "vector_db_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/The-Swarm-Corporation/swarms-memory",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "memory",
        "swarms",
        "vector-database"
      ],
      "id": 983
    },
    {
      "name": "MemGPT-Functions",
      "one_line_profile": "Function library for MemGPT agents",
      "detailed_description": "A library of Python functions designed to extend the capabilities of MemGPT agents, enabling them to perform specific tasks and interact with external tools.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "tool_calling",
        "agent_extension"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TheOnlyWiseJEDI/MemGPT-Functions",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "memgpt",
        "functions",
        "agent-tools"
      ],
      "id": 984
    },
    {
      "name": "AthenaDB",
      "one_line_profile": "Serverless distributed vector database API",
      "detailed_description": "A serverless, distributed vector database provided as an API, designed for scalable vector storage and retrieval in AI applications.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "distributed_storage"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/TimeSurgeLabs/athenadb",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "vector-database",
        "serverless",
        "api"
      ],
      "id": 985
    },
    {
      "name": "Chat2Graph",
      "one_line_profile": "Graph-native agentic system for knowledge extraction",
      "detailed_description": "An agentic system designed to convert natural language chat interactions into knowledge graph structures, facilitating structured knowledge capture and reasoning.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "graph_rag",
        "information_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TuGraph-family/chat2graph",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "agent",
        "graph-rag"
      ],
      "id": 986
    },
    {
      "name": "kANNolo",
      "one_line_profile": "Approximate k-Nearest Neighbors Search library",
      "detailed_description": "A Rust implementation of the kANNolo algorithm for fast and smooth approximate k-nearest neighbors search, serving as a core component for high-dimensional vector retrieval.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "ann_algorithm"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/TusKANNy/kannolo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ann",
        "vector-search",
        "rust"
      ],
      "id": 987
    },
    {
      "name": "DRAG",
      "one_line_profile": "Framework for distilling RAG capabilities from LLMs to SLMs",
      "detailed_description": "A research implementation for distilling Retrieval-Augmented Generation (RAG) capabilities from Large Language Models (LLMs) to Small Language Models (SLMs) using evidence and graph-based distillation techniques. It aims to mitigate hallucination and transfer knowledge efficiently.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "model_distillation",
        "rag_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/VILA-Lab/DRAG",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "distillation",
        "slm",
        "hallucination-mitigation"
      ],
      "id": 988
    },
    {
      "name": "Extended-RaBitQ",
      "one_line_profile": "High-dimensional vector quantization library for ANN search",
      "detailed_description": "An implementation of practical and asymptotically optimal quantization for high-dimensional vectors in Euclidean space, designed to accelerate Approximate Nearest Neighbor (ANN) search in vector databases.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_quantization",
        "ann_search"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/VectorDB-NTU/Extended-RaBitQ",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-quantization",
        "ann",
        "high-dimensional-data"
      ],
      "id": 989
    },
    {
      "name": "General Agentic Memory",
      "one_line_profile": "General-purpose memory system for AI agents",
      "detailed_description": "A general memory system designed for AI agents, incorporating deep research capabilities to enable persistent context and knowledge retrieval across interactions.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_memory",
        "knowledge_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/VectorSpaceLab/general-agentic-memory",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-memory",
        "llm-agent",
        "retrieval"
      ],
      "id": 990
    },
    {
      "name": "Cyber Doctor (Cyber Huatuo)",
      "one_line_profile": "Medical agent framework based on LLM and Knowledge Graphs",
      "detailed_description": "A framework for building personal doctor agents ('Cyber Huatuo') using multimodal large language models and medical knowledge graphs. It supports disease preliminary diagnosis, medical record analysis, and professional Q&A.",
      "domains": [
        "AI5",
        "AI5-07",
        "Life Science"
      ],
      "subtask_category": [
        "medical_diagnosis",
        "knowledge_graph_qa"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/Warma10032/cyber-doctor",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "medical-ai",
        "knowledge-graph",
        "healthcare",
        "llm-agent"
      ],
      "id": 991
    },
    {
      "name": "A-MEM",
      "one_line_profile": "Agentic memory mechanism for LLM agents",
      "detailed_description": "Implementation of 'A-MEM', a memory mechanism for LLM agents that enables long-term retention and retrieval of information, enhancing the agent's ability to perform complex tasks over time.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_memory",
        "context_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/WujiangXu/A-mem",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-memory",
        "llm",
        "long-term-memory"
      ],
      "id": 992
    },
    {
      "name": "EFANNA Graph",
      "one_line_profile": "Fast approximate nearest neighbor graph construction library",
      "detailed_description": "An extremely fast algorithm framework for constructing approximate nearest neighbor (ANN) graphs, which serves as a fundamental building block for vector indexing and search systems.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "graph_construction",
        "ann_search"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/ZJULearning/efanna_graph",
      "help_website": [],
      "license": null,
      "tags": [
        "ann",
        "graph-algorithm",
        "vector-search"
      ],
      "id": 993
    },
    {
      "name": "NSG",
      "one_line_profile": "Navigating Spreading-out Graph for ANN search",
      "detailed_description": "Implementation of the Navigating Spreading-out Graph (NSG) algorithm for efficient approximate nearest neighbor search in high-dimensional spaces.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "ann_search",
        "vector_indexing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/ZJULearning/nsg",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ann",
        "vector-search",
        "nsg"
      ],
      "id": 994
    },
    {
      "name": "SAG",
      "one_line_profile": "SQL-driven RAG engine with automatic KG construction",
      "detailed_description": "A Retrieval-Augmented Generation (RAG) engine driven by SQL that automatically builds knowledge graphs during the querying process, facilitating structured data retrieval and analysis.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "rag",
        "sql_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zleap-AI/SAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "knowledge-graph",
        "sql",
        "structured-data"
      ],
      "id": 995
    },
    {
      "name": "ReMe",
      "one_line_profile": "Memory management kit for AI agents",
      "detailed_description": "A memory management toolkit for agents that provides mechanisms for remembering and refining information, supporting the development of long-term memory in research agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_memory",
        "memory_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/agentscope-ai/ReMe",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent-memory",
        "agentscope",
        "llm"
      ],
      "id": 996
    },
    {
      "name": "A-MEM (AGI Research)",
      "one_line_profile": "Agentic memory system for LLM agents",
      "detailed_description": "The official implementation of 'A-MEM: Agentic Memory for LLM Agents', providing a robust memory architecture for autonomous agents to maintain state and context over extended interactions.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_memory",
        "context_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/agiresearch/A-mem",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-memory",
        "llm",
        "research-agent"
      ],
      "id": 997
    },
    {
      "name": "Elastiknn",
      "one_line_profile": "Elasticsearch plugin for nearest neighbor search",
      "detailed_description": "A plugin for Elasticsearch that enables storage of vectors and execution of similarity searches using exact and approximate algorithms, integrating vector search into standard search infrastructure.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/alexklibisz/elastiknn",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "elasticsearch",
        "vector-search",
        "ann"
      ],
      "id": 998
    },
    {
      "name": "RAGChecker",
      "one_line_profile": "Fine-grained framework for diagnosing RAG systems",
      "detailed_description": "A framework designed to diagnose and evaluate Retrieval-Augmented Generation (RAG) systems, providing fine-grained metrics to assess retrieval accuracy and generation quality.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "rag_evaluation",
        "system_diagnosis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/amazon-science/RAGChecker",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "evaluation",
        "metrics"
      ],
      "id": 999
    },
    {
      "name": "VSAG",
      "one_line_profile": "High-performance vector indexing library for similarity search",
      "detailed_description": "A vector indexing library developed by Ant Group, designed for efficient similarity search in large-scale vector databases. It supports various indexing algorithms and is essential for building Retrieval-Augmented Generation (RAG) systems and knowledge bases in scientific AI applications.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_indexing",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/antgroup/vsag",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-search",
        "indexing",
        "rag",
        "similarity-search"
      ],
      "id": 1000
    },
    {
      "name": "Apache Zeppelin",
      "one_line_profile": "Web-based notebook for interactive data analytics",
      "detailed_description": "A web-based notebook that enables data-driven, interactive data analytics and collaborative documents with SQL, Scala, Python, and more. It serves as a workbench for scientific data analysis, visualization, and workflow orchestration.",
      "domains": [
        "AI5",
        "AI5-05"
      ],
      "subtask_category": [
        "data_analysis",
        "visualization",
        "interactive_computing"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/apache/zeppelin",
      "help_website": [
        "https://zeppelin.apache.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "notebook",
        "data-analytics",
        "visualization",
        "sql"
      ],
      "id": 1001
    },
    {
      "name": "sqlite-vec",
      "one_line_profile": "Vector search extension for SQLite",
      "detailed_description": "A vector search extension for SQLite that enables local, efficient vector storage and retrieval. It is a critical component for building lightweight, portable scientific knowledge bases and RAG systems without heavy infrastructure.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_storage",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/asg017/sqlite-vec",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sqlite",
        "vector-search",
        "embeddings",
        "database"
      ],
      "id": 1002
    },
    {
      "name": "sqlite-vss",
      "one_line_profile": "SQLite extension for efficient vector search based on Faiss",
      "detailed_description": "A SQLite extension that integrates Faiss for efficient vector search. It allows researchers to perform similarity searches directly within SQLite databases, facilitating local management of embeddings for scientific literature or molecular data.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_storage",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/asg017/sqlite-vss",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sqlite",
        "faiss",
        "vector-search",
        "embeddings"
      ],
      "id": 1003
    },
    {
      "name": "Basic Memory",
      "one_line_profile": "Long-term memory management layer for AI agents",
      "detailed_description": "A framework designed to provide persistent memory capabilities to AI agents, allowing them to retain context over long conversations or research tasks. Essential for building autonomous scientific research agents that need to maintain state across complex workflows.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "context_retention"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/basicmachines-co/basic-memory",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "agent-memory",
        "llm",
        "context-management"
      ],
      "id": 1004
    },
    {
      "name": "ANN-SoLo",
      "one_line_profile": "Spectral library searching using approximate nearest neighbor techniques",
      "detailed_description": "A specialized tool for mass spectrometry data analysis that uses approximate nearest neighbor (ANN) indexing to perform fast and accurate spectral library searching. It applies vector indexing techniques to proteomics/metabolomics data.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "spectral_search",
        "mass_spectrometry",
        "proteomics"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/bittremieuxlab/ANN-SoLo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mass-spectrometry",
        "proteomics",
        "approximate-nearest-neighbor",
        "spectral-library"
      ],
      "id": 1005
    },
    {
      "name": "chunking_evaluation",
      "one_line_profile": "Tools for evaluating text chunking strategies in RAG systems",
      "detailed_description": "A Python package for evaluating different text chunking methods, developed as part of Chroma's research. It helps researchers optimize the retrieval component of RAG systems by comparing chunking strategies for scientific literature or data.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "rag_optimization",
        "chunking",
        "evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/brandonstarxel/chunking_evaluation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "chunking",
        "evaluation",
        "chroma"
      ],
      "id": 1006
    },
    {
      "name": "Data-Copilot",
      "one_line_profile": "Natural Language Database Query System (RAG) based on LLM",
      "detailed_description": "A system that uses Large Language Models to interpret natural language queries and execute structured queries (SQL) on databases. It facilitates scientific data analysis by allowing researchers to interact with data using natural language.",
      "domains": [
        "AI5",
        "AI5-03"
      ],
      "subtask_category": [
        "data_querying",
        "text_to_sql",
        "data_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bytesc/data-copilot",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "text-to-sql",
        "rag",
        "data-analysis",
        "llm"
      ],
      "id": 1007
    },
    {
      "name": "memoripy",
      "one_line_profile": "AI memory layer with short/long-term storage and semantic clustering",
      "detailed_description": "A Python library providing a memory layer for AI agents, featuring short-term and long-term storage, semantic clustering, and context-aware memory decay to enhance agent state management.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "context_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/caspianmoon/memoripy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "memory",
        "agent",
        "semantic-clustering"
      ],
      "id": 1008
    },
    {
      "name": "Chroma",
      "one_line_profile": "Open-source embedding database for AI applications",
      "detailed_description": "A vector database designed for AI applications, providing efficient storage and retrieval of embeddings. It serves as a critical memory component for AI agents and RAG systems in scientific workflows.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_database",
        "embedding_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/chroma-core/chroma",
      "help_website": [
        "https://docs.trychroma.com"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "embeddings",
        "rag"
      ],
      "id": 1009
    },
    {
      "name": "Chromatix",
      "one_line_profile": "Differentiable wave optics simulation library using JAX",
      "detailed_description": "A library for differentiable wave optics simulation built on JAX. It allows for the modeling and optimization of optical systems, supporting tasks in computational microscopy and optical physics.",
      "domains": [
        "Physics",
        "Optics"
      ],
      "subtask_category": [
        "wave_optics_simulation",
        "optical_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chromatix-team/chromatix",
      "help_website": [
        "https://chromatix.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "optics",
        "jax",
        "differentiable-programming",
        "simulation"
      ],
      "id": 1010
    },
    {
      "name": "LLM Analysis",
      "one_line_profile": "Latency and memory analysis for Transformer models",
      "detailed_description": "A tool for analyzing the latency and memory usage of Transformer-based models during training and inference. It aids in the optimization of large models used in scientific computing and AI4S applications.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "performance_profiling",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cli99/llm-analysis",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "transformer",
        "profiling",
        "latency",
        "memory"
      ],
      "id": 1011
    },
    {
      "name": "ParlayANN",
      "one_line_profile": "Algorithms for approximate nearest neighbor search",
      "detailed_description": "A library of high-performance algorithms for approximate nearest neighbor (ANN) search in high-dimensional spaces, essential for vector indexing and similarity search in scientific data analysis.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "ann_search",
        "vector_indexing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/cmuparlay/ParlayANN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ann",
        "nearest-neighbor",
        "algorithms"
      ],
      "id": 1012
    },
    {
      "name": "Cocoindex",
      "one_line_profile": "Incremental data transformation framework for AI",
      "detailed_description": "A high-performance data transformation framework designed for AI pipelines, supporting incremental processing. It facilitates the preparation and cleaning of scientific data for AI models.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "data_transformation",
        "etl"
      ],
      "application_level": "framework",
      "primary_language": "Rust",
      "repo_url": "https://github.com/cocoindex-io/cocoindex",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-processing",
        "etl",
        "rust"
      ],
      "id": 1013
    },
    {
      "name": "Rektor DB",
      "one_line_profile": "Vector database for AI applications",
      "detailed_description": "A vector database solution designed to store and retrieve high-dimensional vectors, supporting semantic search and memory functions for AI agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_database"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/codediodeio/rektor-db",
      "help_website": [],
      "license": null,
      "tags": [
        "vector-database",
        "search"
      ],
      "id": 1014
    },
    {
      "name": "CodeFuse-muAgent",
      "one_line_profile": "Multi-agent framework driven by Knowledge Graph engine",
      "detailed_description": "An agent framework that leverages Knowledge Graphs (KG) to drive multi-agent collaboration. It integrates KG engines to enhance the reasoning and memory capabilities of agents in complex workflows.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_orchestration",
        "knowledge_graph_reasoning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/codefuse-ai/CodeFuse-muAgent",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "multi-agent",
        "knowledge-graph",
        "framework"
      ],
      "id": 1015
    },
    {
      "name": "Adaptive Classifier",
      "one_line_profile": "Adaptive system for dynamic text classification",
      "detailed_description": "A flexible classification system designed for dynamic text classification tasks. It can be applied to categorize scientific literature or textual data streams adaptively.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "text_classification",
        "nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/codelion/adaptive-classifier",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "classification",
        "nlp",
        "text-mining"
      ],
      "id": 1016
    },
    {
      "name": "HNSW (Go)",
      "one_line_profile": "In-memory HNSW vector index implementation in Go",
      "detailed_description": "A Go implementation of the Hierarchical Navigable Small World (HNSW) algorithm for efficient approximate nearest neighbor search in vector spaces.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_indexing",
        "ann_search"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/coder/hnsw",
      "help_website": [],
      "license": "CC0-1.0",
      "tags": [
        "hnsw",
        "vector-search",
        "go"
      ],
      "id": 1017
    },
    {
      "name": "Cosdata",
      "one_line_profile": "AI data platform for semantic search and vector pipelines",
      "detailed_description": "A data platform designed for next-generation search pipelines, featuring semantic search, hybrid capabilities, and ML integration. It supports immutable data management for AI projects.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "semantic_search",
        "data_management"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/cosdata/cosdata",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-search",
        "data-platform",
        "semantic-search"
      ],
      "id": 1018
    },
    {
      "name": "Coze-loop",
      "one_line_profile": "AI Agent optimization and lifecycle management platform",
      "detailed_description": "A platform for the full-lifecycle management of AI agents, including development, debugging, evaluation, and monitoring. It focuses on optimizing agent performance for complex tasks.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "agent_optimization",
        "lifecycle_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/coze-dev/coze-loop",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent-optimization",
        "llm",
        "evaluation"
      ],
      "id": 1019
    },
    {
      "name": "CozoDB",
      "one_line_profile": "Transactional relational-graph-vector database using Datalog",
      "detailed_description": "A hybrid database engine combining relational, graph, and vector capabilities, queryable via Datalog. It is designed to serve as the 'hippocampus' (memory center) for AI systems.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "graph_database",
        "vector_database",
        "knowledge_representation"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/cozodb/cozo",
      "help_website": [
        "https://docs.cozodb.org"
      ],
      "license": "MPL-2.0",
      "tags": [
        "graph-database",
        "vector-database",
        "datalog"
      ],
      "id": 1020
    },
    {
      "name": "Autofaiss",
      "one_line_profile": "Tool for automatically creating optimal Faiss k-NN indices",
      "detailed_description": "A tool that automatically selects and builds the most optimal Faiss similarity search indices based on memory and performance constraints, simplifying vector search setup.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "index_optimization",
        "vector_search"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/criteo/autofaiss",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "faiss",
        "vector-index",
        "optimization"
      ],
      "id": 1021
    },
    {
      "name": "Hnsw-sharp",
      "one_line_profile": "C# library for HNSW approximate nearest neighbor search",
      "detailed_description": "A C# implementation of the Hierarchical Navigable Small World (HNSW) graph algorithm for efficient approximate nearest neighbor search.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "ann_search",
        "vector_indexing"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/curiosity-ai/hnsw-sharp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hnsw",
        "c-sharp",
        "vector-search"
      ],
      "id": 1022
    },
    {
      "name": "Databend",
      "one_line_profile": "Cloud-native data warehouse with vector search and AI capabilities",
      "detailed_description": "A modern cloud data warehouse that integrates vector database capabilities and AI functions, allowing for unified analytics and semantic search on scientific data stored in object storage.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "data_warehousing",
        "vector_search",
        "analytics"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/databendlabs/databend",
      "help_website": [
        "https://databend.rs"
      ],
      "license": "NOASSERTION",
      "tags": [
        "data-warehouse",
        "vector-search",
        "cloud-native"
      ],
      "id": 1023
    },
    {
      "name": "JVector",
      "one_line_profile": "Embedded vector search engine for Java",
      "detailed_description": "An advanced embedded vector search engine written in Java, designed for high-performance similarity search and retrieval in AI applications.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "embedding_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/datastax/jvector",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-search",
        "java",
        "embedded"
      ],
      "id": 1024
    },
    {
      "name": "Bolt",
      "one_line_profile": "High-performance library for matrix and vector operations",
      "detailed_description": "A C++ library optimized for extremely fast matrix and vector operations, serving as a foundational tool for scientific computing and numerical analysis.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "scientific_data_analysis",
        "numerical_computing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/dblalock/bolt",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "matrix-operations",
        "vectorization",
        "performance",
        "numerical-computing"
      ],
      "id": 1025
    },
    {
      "name": "NearestNeighborDescent.jl",
      "one_line_profile": "Approximate k-nearest neighbors graph construction and search in Julia",
      "detailed_description": "A Julia library for efficient approximate nearest neighbor search, enabling high-performance similarity analysis in scientific datasets.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "scientific_data_analysis",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/dillondaudert/NearestNeighborDescent.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "knn",
        "nearest-neighbor",
        "similarity-search"
      ],
      "id": 1026
    },
    {
      "name": "DingoDB",
      "one_line_profile": "Multi-modal vector database with SQL support",
      "detailed_description": "A distributed multi-modal vector database that supports high-concurrency vector queries and upserts, suitable for managing large-scale scientific vector embeddings.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "scientific_data_management",
        "vector_storage"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/dingodb/dingo",
      "help_website": [
        "https://dingodb.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "multi-modal",
        "sql",
        "embeddings"
      ],
      "id": 1027
    },
    {
      "name": "instant-distance",
      "one_line_profile": "Fast approximate nearest neighbor searching in Rust",
      "detailed_description": "A Rust library implementing the HNSW index for fast approximate nearest neighbor search, providing efficient vector retrieval capabilities for data analysis.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "scientific_data_analysis",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/djc/instant-distance",
      "help_website": [
        "https://docs.rs/instant-distance"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rust",
        "hnsw",
        "nearest-neighbor",
        "vector-search"
      ],
      "id": 1028
    },
    {
      "name": "Sequence-Semantic-Embedding",
      "one_line_profile": "Library for training NLP models for semantic search and QA",
      "detailed_description": "A toolkit for training deep learning models for NLP tasks such as semantic search ranking, recall fetching, and question answering, applicable to scientific text mining.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "scientific_data_processing",
        "nlp_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/eBay/Sequence-Semantic-Embedding",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "semantic-search",
        "embedding",
        "deep-learning"
      ],
      "id": 1029
    },
    {
      "name": "OasysDB",
      "one_line_profile": "In-memory vector store for semantic caching and retrieval",
      "detailed_description": "An efficient in-memory vector store designed for semantic caching and retrieval systems, facilitating fast access to vector embeddings.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "scientific_data_management",
        "vector_storage"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/edwinkys/oasysdb",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-store",
        "rust",
        "semantic-search",
        "database"
      ],
      "id": 1030
    },
    {
      "name": "Lorann",
      "one_line_profile": "Approximate Nearest Neighbor search using reduced-rank regression",
      "detailed_description": "A C++ library for approximate nearest neighbor search that utilizes reduced-rank regression for fast queries and low memory usage.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "scientific_data_analysis",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/ejaasaari/lorann",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ann",
        "vector-search",
        "cpp",
        "dimensionality-reduction"
      ],
      "id": 1031
    },
    {
      "name": "Eliza",
      "one_line_profile": "Framework for building autonomous AI agents",
      "detailed_description": "A flexible framework for developing autonomous agents that can interact with various environments and tools, suitable for creating scientific research assistants.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "scientific_workflow_orchestration",
        "agent_development"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/elizaOS/eliza",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agents",
        "autonomous-systems",
        "framework",
        "ai-assistant"
      ],
      "id": 1032
    },
    {
      "name": "Epsilla VectorDB",
      "one_line_profile": "High performance Vector Database Management System",
      "detailed_description": "A high-performance vector database management system designed for scalable and efficient storage and retrieval of vector embeddings.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "scientific_data_management",
        "vector_storage"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/epsilla-cloud/vectordb",
      "help_website": [
        "https://epsilla.com/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "vector-database",
        "similarity-search",
        "embeddings",
        "cpp"
      ],
      "id": 1033
    },
    {
      "name": "ann-benchmarks",
      "one_line_profile": "Benchmarks of approximate nearest neighbor libraries",
      "detailed_description": "A comprehensive benchmarking tool for evaluating the performance of various approximate nearest neighbor (ANN) search libraries and algorithms.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "scientific_data_analysis",
        "benchmarking"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/erikbern/ann-benchmarks",
      "help_website": [
        "http://ann-benchmarks.com/"
      ],
      "license": "MIT",
      "tags": [
        "benchmarking",
        "ann",
        "nearest-neighbor",
        "performance-evaluation"
      ],
      "id": 1034
    },
    {
      "name": "distributed-faiss",
      "one_line_profile": "Library for building and serving multi-node distributed faiss indices",
      "detailed_description": "A library that extends FAISS to support distributed indexing and searching across multiple nodes, enabling large-scale vector similarity search for massive scientific datasets.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "scientific_data_analysis",
        "similarity_search",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/distributed-faiss",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "faiss",
        "distributed-systems",
        "vector-search",
        "similarity-search"
      ],
      "id": 1035
    },
    {
      "name": "FAISS",
      "one_line_profile": "Library for efficient similarity search and clustering of dense vectors",
      "detailed_description": "A library for efficient similarity search and clustering of dense vectors, widely used in scientific applications for retrieving similar molecular structures, protein sequences, and other high-dimensional data.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "scientific_data_analysis",
        "similarity_search",
        "clustering"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/facebookresearch/faiss",
      "help_website": [
        "https://github.com/facebookresearch/faiss/wiki"
      ],
      "license": "MIT",
      "tags": [
        "vector-search",
        "similarity-search",
        "clustering",
        "gpu-acceleration"
      ],
      "id": 1036
    },
    {
      "name": "PySparNN",
      "one_line_profile": "Approximate Nearest Neighbor Search for Sparse Data",
      "detailed_description": "A Python library for performing Approximate Nearest Neighbor (ANN) search specifically optimized for sparse data, useful in high-dimensional scientific data analysis.",
      "domains": [
        "AI5-07"
      ],
      "subtask_category": [
        "approximate_nearest_neighbor_search",
        "sparse_data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/pysparnn",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ann",
        "sparse-vectors",
        "similarity-search"
      ],
      "id": 1037
    },
    {
      "name": "Spreading Vectors",
      "one_line_profile": "Implementation of Spreading Vectors for Similarity Search",
      "detailed_description": "An open-source implementation of the 'Spreading Vectors' algorithm for efficient similarity search in high-dimensional spaces.",
      "domains": [
        "AI5-07"
      ],
      "subtask_category": [
        "similarity_search",
        "vector_indexing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/spreadingvectors",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "similarity-search",
        "algorithm",
        "vectors"
      ],
      "id": 1038
    },
    {
      "name": "Vector DB ID Compression",
      "one_line_profile": "Lossless Compression of Vector IDs for ANN Search",
      "detailed_description": "Implementation of lossless compression techniques for vector identifiers in Approximate Nearest Neighbor search, optimizing memory usage in vector databases.",
      "domains": [
        "AI5-07"
      ],
      "subtask_category": [
        "vector_database_optimization",
        "compression"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/facebookresearch/vector_db_id_compression",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "vector-db",
        "compression",
        "ann"
      ],
      "id": 1039
    },
    {
      "name": "FLANN",
      "one_line_profile": "Fast Library for Approximate Nearest Neighbors",
      "detailed_description": "A library for performing fast approximate nearest neighbor searches in high dimensional spaces, widely used in computer vision and scientific data clustering.",
      "domains": [
        "AI5-07"
      ],
      "subtask_category": [
        "approximate_nearest_neighbor_search",
        "clustering"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/flann-lib/flann",
      "help_website": [
        "http://www.cs.ubc.ca/research/flann/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "ann",
        "nearest-neighbor",
        "computer-vision"
      ],
      "id": 1040
    },
    {
      "name": "Semantra",
      "one_line_profile": "Multi-tool for semantic search on local documents",
      "detailed_description": "A tool for performing semantic search across local text documents, useful for literature review and qualitative data analysis in research.",
      "domains": [
        "AI5-07"
      ],
      "subtask_category": [
        "semantic_search",
        "literature_review"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/freedmand/semantra",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-search",
        "local-search",
        "embeddings"
      ],
      "id": 1041
    },
    {
      "name": "Radient",
      "one_line_profile": "Unstructured data vectorization library",
      "detailed_description": "A library that turns various data types (text, audio, image, molecular) into vectors for similarity search and RAG, facilitating scientific data processing.",
      "domains": [
        "AI5-07"
      ],
      "subtask_category": [
        "data_vectorization",
        "multimodal_embedding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fzliu/radient",
      "help_website": [
        "https://radient.readthedocs.io"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "vectorization",
        "embeddings",
        "unstructured-data"
      ],
      "id": 1042
    },
    {
      "name": "LoadThemAll",
      "one_line_profile": "QGIS plugin for recursive layer loading",
      "detailed_description": "A QGIS plugin that recursively loads vector and raster layers from a directory structure, aiding in geospatial data management and processing.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "geospatial_data_loading",
        "gis_workflow"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gacarrillor/loadthemall",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "qgis",
        "gis",
        "data-loading"
      ],
      "id": 1043
    },
    {
      "name": "Memento MCP",
      "one_line_profile": "Knowledge Graph Memory System for LLMs",
      "detailed_description": "A memory system that uses knowledge graphs to provide long-term memory for Large Language Models, supporting complex reasoning agents.",
      "domains": [
        "AI5-07"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "llm_memory"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/gannonh/memento-mcp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "knowledge-graph",
        "memory",
        "mcp"
      ],
      "id": 1044
    },
    {
      "name": "ADSampling",
      "one_line_profile": "High-Dimensional Approximate Nearest Neighbor Search",
      "detailed_description": "Implementation of an efficient algorithm for high-dimensional approximate nearest neighbor search with reliable distance comparison operations.",
      "domains": [
        "AI5-07"
      ],
      "subtask_category": [
        "approximate_nearest_neighbor_search",
        "algorithm"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/gaoj0017/ADSampling",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ann",
        "high-dimensional",
        "sampling"
      ],
      "id": 1045
    },
    {
      "name": "RaBitQ",
      "one_line_profile": "Quantization for High-Dimensional Vector Search",
      "detailed_description": "A library for quantizing high-dimensional vectors with theoretical error bounds, optimizing approximate nearest neighbor search.",
      "domains": [
        "AI5-07"
      ],
      "subtask_category": [
        "vector_quantization",
        "approximate_nearest_neighbor_search"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/gaoj0017/RaBitQ",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "ann",
        "vectors"
      ],
      "id": 1046
    },
    {
      "name": "Chroma (Protein Design)",
      "one_line_profile": "Generative model for programmable protein design",
      "detailed_description": "A generative AI model designed for programmable protein design, allowing for the generation of novel protein structures and sequences.",
      "domains": [
        "AI4S",
        "AI5"
      ],
      "subtask_category": [
        "protein_design",
        "structure_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/generatebio/chroma",
      "help_website": [
        "https://generatebiomedicines.com/chroma"
      ],
      "license": "Apache-2.0",
      "tags": [
        "protein-design",
        "generative-model",
        "biology"
      ],
      "id": 1047
    },
    {
      "name": "LibFlatArray",
      "one_line_profile": "C++ library for SoA memory layout optimization",
      "detailed_description": "A C++ library that implements Struct-of-Arrays (SoA) memory layouts for multi-dimensional arrays, optimizing vectorization for scientific computing and HPC.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "hpc_optimization",
        "memory_layout"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/gentryx/libflatarray",
      "help_website": [],
      "license": "BSL-1.0",
      "tags": [
        "hpc",
        "simd",
        "c++"
      ],
      "id": 1048
    },
    {
      "name": "Motorhead",
      "one_line_profile": "Memory and information retrieval server for LLMs",
      "detailed_description": "A server designed to handle memory and information retrieval for Large Language Models, facilitating the creation of stateful AI agents.",
      "domains": [
        "AI5-07"
      ],
      "subtask_category": [
        "llm_memory",
        "information_retrieval"
      ],
      "application_level": "service",
      "primary_language": "Rust",
      "repo_url": "https://github.com/getmetal/motorhead",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "memory",
        "llm",
        "rust"
      ],
      "id": 1049
    },
    {
      "name": "Graphiti",
      "one_line_profile": "Real-Time Knowledge Graphs for AI Agents",
      "detailed_description": "A library for building and managing real-time knowledge graphs, serving as a dynamic memory layer for AI agents.",
      "domains": [
        "AI5-07"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "agent_memory"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/getzep/graphiti",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "knowledge-graph",
        "agents",
        "memory"
      ],
      "id": 1050
    },
    {
      "name": "Zep",
      "one_line_profile": "Long-term memory service for AI Assistants",
      "detailed_description": "A platform providing long-term memory, vector search, and history management for AI assistants and agents.",
      "domains": [
        "AI5-07"
      ],
      "subtask_category": [
        "llm_memory",
        "vector_search"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/getzep/zep",
      "help_website": [
        "https://docs.getzep.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "memory",
        "vector-store",
        "nlp"
      ],
      "id": 1051
    },
    {
      "name": "Zep Python",
      "one_line_profile": "Python client for Zep memory service",
      "detailed_description": "The Python client library for interacting with the Zep memory service, enabling Python-based agents to persist and retrieve context.",
      "domains": [
        "AI5-07"
      ],
      "subtask_category": [
        "llm_memory_client",
        "context_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/getzep/zep-python",
      "help_website": [
        "https://docs.getzep.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "client",
        "memory",
        "python"
      ],
      "id": 1052
    },
    {
      "name": "GNES",
      "one_line_profile": "Generic Neural Elastic Search",
      "detailed_description": "A cloud-native semantic search system based on deep neural networks, serving as a framework for building neural search applications.",
      "domains": [
        "AI5-07"
      ],
      "subtask_category": [
        "neural_search",
        "semantic_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/gnes-ai/gnes",
      "help_website": [
        "https://gnes.ai"
      ],
      "license": "NOASSERTION",
      "tags": [
        "neural-search",
        "cloud-native",
        "semantic-search"
      ],
      "id": 1053
    },
    {
      "name": "TrustRAG",
      "one_line_profile": "Reliable RAG Framework",
      "detailed_description": "A Retrieval-Augmented Generation (RAG) framework focused on ensuring reliable input and trusted output, suitable for research-grade knowledge retrieval.",
      "domains": [
        "AI5-07"
      ],
      "subtask_category": [
        "rag_framework",
        "reliable_retrieval"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/gomate-community/TrustRAG",
      "help_website": [],
      "license": null,
      "tags": [
        "rag",
        "trustworthiness",
        "retrieval"
      ],
      "id": 1054
    },
    {
      "name": "Granne",
      "one_line_profile": "Graph-based Approximate Nearest Neighbor Search",
      "detailed_description": "A Rust library for graph-based Approximate Nearest Neighbor (ANN) search, providing efficient vector retrieval.",
      "domains": [
        "AI5-07"
      ],
      "subtask_category": [
        "approximate_nearest_neighbor_search",
        "vector_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/granne/granne",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ann",
        "rust",
        "graph-based"
      ],
      "id": 1055
    },
    {
      "name": "hann",
      "one_line_profile": "Fast approximate nearest neighbor (ANN) search library for Go",
      "detailed_description": "A library implementing approximate nearest neighbor search, suitable for vector indexing and similarity search in high-dimensional spaces.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/habedi/hann",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ann",
        "vector-search",
        "nearest-neighbor"
      ],
      "id": 1056
    },
    {
      "name": "chromap",
      "one_line_profile": "Fast alignment and preprocessing of chromatin profiles",
      "detailed_description": "A tool for ultrafast alignment and preprocessing of high-throughput chromatin profiling data (e.g., ChIP-seq, ATAC-seq), optimized for speed and accuracy.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "sequence_alignment",
        "data_preprocessing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/haowenz/chromap",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chromatin",
        "alignment",
        "bioinformatics",
        "atac-seq"
      ],
      "id": 1057
    },
    {
      "name": "hdidx",
      "one_line_profile": "Approximate Nearest Neighbor (ANN) search for high-dimensional data",
      "detailed_description": "A Python library for indexing and searching high-dimensional vectors, supporting efficient retrieval for scientific data analysis.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "indexing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/hdidx/hdidx",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ann",
        "high-dimensional",
        "indexing"
      ],
      "id": 1058
    },
    {
      "name": "hora",
      "one_line_profile": "Efficient approximate nearest neighbor search library",
      "detailed_description": "A high-performance ANN search library written in Rust, supporting multiple algorithms (HNSW, SSG, etc.) for vector indexing tasks.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/hora-search/hora",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ann",
        "rust",
        "vector-search",
        "hnsw"
      ],
      "id": 1059
    },
    {
      "name": "ChatDB",
      "one_line_profile": "Augmenting LLMs with databases as symbolic memory",
      "detailed_description": "A framework that enables LLMs to use SQL databases as symbolic memory, enhancing their capability to handle complex multi-hop reasoning and data storage.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "symbolic_reasoning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/huchenxucs/ChatDB",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "memory",
        "database",
        "symbolic-ai"
      ],
      "id": 1060
    },
    {
      "name": "Infinity",
      "one_line_profile": "AI-native database for hybrid search of dense/sparse vectors and full-text",
      "detailed_description": "A high-performance database designed for LLM applications, offering hybrid search capabilities (vector, sparse, tensor, full-text) to support RAG and knowledge retrieval.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_database",
        "hybrid_search",
        "retrieval"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/infiniflow/infinity",
      "help_website": [
        "https://infiniflow.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "rag",
        "hybrid-search",
        "llm-infrastructure"
      ],
      "id": 1061
    },
    {
      "name": "IPEX-LLM",
      "one_line_profile": "LLM inference and finetuning acceleration on Intel XPU",
      "detailed_description": "A library for accelerating local LLM inference and fine-tuning on Intel hardware (CPUs, GPUs, NPUs), integrating with major AI frameworks for scientific computing.",
      "domains": [
        "AI5",
        "AI Infrastructure"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_finetuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/intel/ipex-llm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "intel",
        "llm",
        "inference",
        "acceleration"
      ],
      "id": 1062
    },
    {
      "name": "Long-Term-Memory-API",
      "one_line_profile": "API for adding long-term memory to AI agents",
      "detailed_description": "A production-grade API/library designed to provide long-term memory capabilities to AI agents, facilitating state persistence in complex workflows.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "agent_state"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/jakops88-hub/Long-Term-Memory-API",
      "help_website": [],
      "license": null,
      "tags": [
        "memory",
        "ai-agent",
        "api"
      ],
      "id": 1063
    },
    {
      "name": "hyperDB",
      "one_line_profile": "Hyper-fast local vector database for LLM Agents",
      "detailed_description": "A lightweight, local vector database optimized for use with LLM agents, enabling efficient memory and retrieval operations.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_database",
        "local_storage"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jdagdelen/hyperDB",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vector-db",
        "llm-agent",
        "local-storage"
      ],
      "id": 1064
    },
    {
      "name": "hnswlib",
      "one_line_profile": "Java library for HNSW approximate nearest neighbors search",
      "detailed_description": "A Java implementation of the Hierarchical Navigable Small World (HNSW) algorithm for efficient approximate nearest neighbor search.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/jelmerk/hnswlib",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hnsw",
        "java",
        "ann",
        "vector-search"
      ],
      "id": 1065
    },
    {
      "name": "GaLore",
      "one_line_profile": "Memory-Efficient LLM Training by Gradient Low-Rank Projection",
      "detailed_description": "A library implementing Gradient Low-Rank Projection (GaLore) to enable memory-efficient training of Large Language Models on consumer hardware.",
      "domains": [
        "AI5",
        "AI Training"
      ],
      "subtask_category": [
        "model_training",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jiaweizzhao/GaLore",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-training",
        "optimization",
        "memory-efficient"
      ],
      "id": 1066
    },
    {
      "name": "annlite",
      "one_line_profile": "Fast embedded library for approximate nearest neighbor search",
      "detailed_description": "A lightweight, embedded library for approximate nearest neighbor search, designed for integration into neural search systems.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jina-ai/annlite",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ann",
        "vector-search",
        "embedded"
      ],
      "id": 1067
    },
    {
      "name": "Jina VectorDB",
      "one_line_profile": "Lightweight Python vector database for AI applications",
      "detailed_description": "A minimalist vector database designed for storing and retrieving vector embeddings, essential for building Retrieval-Augmented Generation (RAG) systems and knowledge bases in scientific AI agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "embedding_storage"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jina-ai/vectordb",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "rag",
        "embeddings"
      ],
      "id": 1068
    },
    {
      "name": "rcpphnsw",
      "one_line_profile": "R bindings for HNSW approximate nearest neighbors library",
      "detailed_description": "Provides R bindings for the hnswlib C++ library, enabling fast approximate nearest neighbor search. This is crucial for high-dimensional data analysis in bioinformatics (e.g., single-cell clustering) and statistical modeling within the R ecosystem.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "nearest_neighbor_search",
        "clustering"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/jlmelville/rcpphnsw",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "r",
        "hnsw",
        "nearest-neighbor"
      ],
      "id": 1069
    },
    {
      "name": "PDF Brain",
      "one_line_profile": "Local PDF knowledge base with vector search",
      "detailed_description": "A tool for creating a local knowledge base from PDF documents using PGlite and pgvector. It facilitates the management and semantic retrieval of scientific literature and technical documents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "literature_mining",
        "knowledge_management"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/joelhooks/pdf-brain",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf",
        "knowledge-base",
        "vector-search"
      ],
      "id": 1070
    },
    {
      "name": "Chat With Your Docs",
      "one_line_profile": "RAG interface for chatting with documents using local LLMs",
      "detailed_description": "An application enabling users to interact with documents (PDFs, web pages) using LLMs like Mistral and Llama2. It supports information extraction and synthesis from scientific texts.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "literature_mining",
        "information_extraction"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/jorge-armando-navarro-flores/chat_with_your_docs",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "llm",
        "document-analysis"
      ],
      "id": 1071
    },
    {
      "name": "Kagi VectorDB",
      "one_line_profile": "Minimal Python package for text chunking and vector storage",
      "detailed_description": "A lightweight library for handling text chunking, embedding generation, and vector search, suitable for building simple knowledge retrieval systems in scientific workflows.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "text_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kagisearch/vectordb",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vector-search",
        "embeddings",
        "nlp"
      ],
      "id": 1072
    },
    {
      "name": "N2",
      "one_line_profile": "Lightweight approximate Nearest Neighbor library",
      "detailed_description": "A fast and lightweight library for approximate nearest neighbor search, optimized for large datasets. Useful for clustering and similarity search in high-dimensional scientific data.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "nearest_neighbor_search",
        "clustering"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/kakao/n2",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ann",
        "nearest-neighbor",
        "high-dimensional-data"
      ],
      "id": 1073
    },
    {
      "name": "Spark Neighbors",
      "one_line_profile": "Approximate nearest neighbor search for Apache Spark",
      "detailed_description": "Implements locality-sensitive hashing (LSH) for approximate nearest neighbor search on Apache Spark, enabling scalable similarity search on massive scientific datasets.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "nearest_neighbor_search",
        "big_data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/karlhigley/spark-neighbors",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "spark",
        "lsh",
        "nearest-neighbor"
      ],
      "id": 1074
    },
    {
      "name": "Agentic Context Engine",
      "one_line_profile": "Framework for agent experience learning and context management",
      "detailed_description": "A framework designed to enable AI agents to learn from experience and manage context effectively. It supports the development of scientific agents that require persistent memory of experiments and interactions.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_memory",
        "context_management"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/kayba-ai/agentic-context-engine",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-memory",
        "context-engineering",
        "llm"
      ],
      "id": 1075
    },
    {
      "name": "Kelindar Search",
      "one_line_profile": "Go library for embedded vector search and embeddings",
      "detailed_description": "A Go library providing embedded vector search capabilities and semantic embeddings via llama.cpp. Suitable for building high-performance, compiled scientific applications requiring local inference and retrieval.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "embedding_generation"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/kelindar/search",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "go",
        "vector-search",
        "llama.cpp"
      ],
      "id": 1076
    },
    {
      "name": "Resin",
      "one_line_profile": "Language model search engine on vector database",
      "detailed_description": "A search engine infrastructure built on vector databases and key/value stores, designed to support language models in retrieving relevant context for query answering.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "information_retrieval",
        "search_engine"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/kreeben/resin",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "search",
        "vector-db",
        "dotnet"
      ],
      "id": 1077
    },
    {
      "name": "Kreuzberg",
      "one_line_profile": "Polyglot document intelligence framework",
      "detailed_description": "A framework for extracting text, metadata, and structured information from PDFs, Office documents, and images. Critical for converting scientific literature into machine-readable formats for RAG and analysis.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "document_processing",
        "text_extraction"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/kreuzberg-dev/kreuzberg",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "document-intelligence",
        "pdf-extraction",
        "ocr"
      ],
      "id": 1078
    },
    {
      "name": "Kùzu",
      "one_line_profile": "Embedded property graph database with vector search",
      "detailed_description": "A high-performance embedded graph database that supports Cypher query language and vector search. Ideal for managing complex scientific data relationships (e.g., molecular graphs, biological networks) alongside embeddings.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "graph_database",
        "knowledge_graph"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/kuzudb/kuzu",
      "help_website": [
        "https://kuzudb.com"
      ],
      "license": "MIT",
      "tags": [
        "graph-database",
        "cypher",
        "vector-search"
      ],
      "id": 1079
    },
    {
      "name": "Lantern",
      "one_line_profile": "PostgreSQL vector database extension",
      "detailed_description": "A PostgreSQL extension that adds vector database capabilities, allowing for efficient storage and retrieval of embeddings within a standard relational database environment used in scientific data management.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_storage",
        "database_extension"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/lanterndata/lantern",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "postgresql",
        "vector-db",
        "embeddings"
      ],
      "id": 1080
    },
    {
      "name": "LaVague",
      "one_line_profile": "Large Action Model framework for AI Web Agents",
      "detailed_description": "A framework for developing AI web agents capable of executing actions in browsers. This is applicable for automating scientific data collection, literature search, and interaction with web-based scientific databases.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "web_automation",
        "data_collection"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/lavague-ai/LaVague",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "web-agents",
        "automation",
        "lam"
      ],
      "id": 1081
    },
    {
      "name": "BRPC Faiss Server",
      "one_line_profile": "Vector Search Engine based on BRPC and FAISS",
      "detailed_description": "A high-performance vector search engine server implementation combining Baidu RPC (BRPC) and Facebook AI Similarity Search (FAISS), providing a robust backend for similarity search services.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "service_infrastructure"
      ],
      "application_level": "service",
      "primary_language": "C++",
      "repo_url": "https://github.com/layerism/brpc_faiss_server",
      "help_website": [],
      "license": null,
      "tags": [
        "faiss",
        "brpc",
        "vector-search"
      ],
      "id": 1082
    },
    {
      "name": "Contextual Chunking GraphRAG",
      "one_line_profile": "Advanced retrieval system with contextual chunking and knowledge graphs",
      "detailed_description": "A retrieval system combining semantic vector search, token-based search, and knowledge graphs. It employs contextual chunking to improve the precision of information retrieval from complex documents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "rag",
        "knowledge_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lesteroliver911/contextual-chunking-graphpowered-rag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "knowledge-graph",
        "chunking"
      ],
      "id": 1083
    },
    {
      "name": "Agent File",
      "one_line_profile": "File format for serializing stateful AI agents",
      "detailed_description": "Defines the '.af' file format for serializing stateful AI agents, including their persistent memory and behavior. This promotes reproducibility and sharing of configured scientific agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_serialization",
        "reproducibility"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/letta-ai/agent-file",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "serialization",
        "agents",
        "file-format"
      ],
      "id": 1084
    },
    {
      "name": "Letta Learning SDK",
      "one_line_profile": "SDK for continual learning and long-term memory in agents",
      "detailed_description": "A software development kit enabling LLM agents to possess continual learning capabilities and long-term memory, essential for adaptive scientific assistants that evolve with research progress.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_memory",
        "continual_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/letta-ai/learning-sdk",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "memory",
        "learning",
        "sdk"
      ],
      "id": 1085
    },
    {
      "name": "Letta",
      "one_line_profile": "Framework for building stateful AI agents with advanced long-term memory",
      "detailed_description": "Letta (formerly MemGPT) is a platform and framework designed to create stateful LLM agents capable of managing long-term memory and complex context. It provides an OS-like abstraction for managing context windows, enabling agents to persist information across sessions and handle tasks requiring extended reasoning or large data processing, which is essential for scientific literature review and autonomous research agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "context_management",
        "agent_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/letta-ai/letta",
      "help_website": [
        "https://docs.letta.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "agent-memory",
        "llm-os",
        "context-management",
        "stateful-agents"
      ],
      "id": 1086
    },
    {
      "name": "Selective Context",
      "one_line_profile": "Library for compressing input context for LLMs to optimize memory and processing",
      "detailed_description": "Selective Context is a Python library that compresses text prompts for Large Language Models by filtering out less informative content based on self-information (perplexity). This tool is valuable in scientific NLP workflows to fit more literature or data into limited context windows and reduce computational costs during inference.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "context_compression",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/liyucheng09/Selective_Context",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "context-compression",
        "llm-optimization",
        "nlp"
      ],
      "id": 1087
    },
    {
      "name": "PyNNDescent",
      "one_line_profile": "Approximate nearest neighbor descent algorithm implementation for Python",
      "detailed_description": "PyNNDescent is a Python library providing a fast implementation of the Nearest Neighbor Descent algorithm for approximate nearest neighbor search. It serves as a foundational component for dimensionality reduction (e.g., UMAP) and clustering in scientific data analysis, enabling efficient similarity search in high-dimensional spaces.",
      "domains": [
        "AI5-07",
        "AI4-01"
      ],
      "subtask_category": [
        "nearest_neighbor_search",
        "dimensionality_reduction",
        "clustering"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lmcinnes/pynndescent",
      "help_website": [
        "https://pynndescent.readthedocs.io/"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "ann",
        "nearest-neighbor",
        "high-dimensional-data",
        "algorithm"
      ],
      "id": 1088
    },
    {
      "name": "Chroma-PyTorch",
      "one_line_profile": "Implementation of Chroma protein generative model",
      "detailed_description": "An open-source PyTorch implementation of Chroma, a generative model for protein design using diffusion models and Graph Neural Networks. This tool allows researchers to generate and explore novel protein backbone structures and sequences, facilitating computational biology and drug design tasks.",
      "domains": [
        "AI3-02",
        "AI3-04"
      ],
      "subtask_category": [
        "protein_design",
        "structure_generation",
        "generative_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucidrains/chroma-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "protein-design",
        "diffusion-models",
        "generative-biology",
        "gnn"
      ],
      "id": 1089
    },
    {
      "name": "Memorizing Transformers PyTorch",
      "one_line_profile": "Implementation of Memorizing Transformers with kNN-augmented attention",
      "detailed_description": "A PyTorch implementation of the Memorizing Transformer architecture, which extends the attention mechanism with a k-nearest-neighbor (kNN) lookup into an external memory of past key-value pairs. This architecture is relevant for scientific tasks requiring the processing of extremely long sequences, such as genome analysis or long-context literature review.",
      "domains": [
        "AI5-07",
        "AI5-03"
      ],
      "subtask_category": [
        "memory_augmentation",
        "sequence_modeling",
        "attention_mechanism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/lucidrains/memorizing-transformers-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "transformer",
        "memory-augmented",
        "knn-attention",
        "deep-learning"
      ],
      "id": 1090
    },
    {
      "name": "Mem0",
      "one_line_profile": "Universal memory layer for AI agents and LLMs",
      "detailed_description": "Mem0 is a memory management framework for AI agents that provides a unified interface for storing and retrieving user, session, and agent state. It utilizes vector stores and graph structures to enable long-term memory, allowing scientific agents to maintain context across extended research sessions and personalize interactions based on historical data.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "agent_state_persistence",
        "context_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mem0ai/mem0",
      "help_website": [
        "https://docs.mem0.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "memory-layer",
        "agent-memory",
        "vector-store",
        "personalization"
      ],
      "id": 1091
    },
    {
      "name": "Acontext",
      "one_line_profile": "Context data platform for AI agents with memory management",
      "detailed_description": "Acontext is a context data platform designed for AI agents, providing infrastructure for managing agent memory and context. It enables the storage and retrieval of interaction history and knowledge, facilitating the development of stateful and context-aware AI systems.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "context_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/memodb-io/Acontext",
      "help_website": [
        "https://discord.acontext.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "agent-memory",
        "context-platform",
        "ai-infrastructure"
      ],
      "id": 1092
    },
    {
      "name": "DiskANN",
      "one_line_profile": "Graph-structured indices for scalable approximate nearest neighbor search",
      "detailed_description": "DiskANN is a library for approximate nearest neighbor (ANN) search that enables fast, accurate, and scalable vector search on large datasets. It uses graph-structured indices and is optimized for SSD-resident datasets, making it suitable for large-scale scientific retrieval tasks.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "approximate_nearest_neighbor"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/microsoft/DiskANN",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ann",
        "vector-search",
        "indexing"
      ],
      "id": 1093
    },
    {
      "name": "SPTAG",
      "one_line_profile": "Distributed approximate nearest neighborhood search (ANN) library",
      "detailed_description": "SPTAG (Space Partition Tree and Graph) is a library for large-scale vector approximate nearest neighbor search. It provides high-quality vector index building and distributed online serving, supporting scenarios like scientific literature retrieval and molecular similarity search.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "approximate_nearest_neighbor"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/microsoft/SPTAG",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ann",
        "vector-index",
        "distributed-search"
      ],
      "id": 1094
    },
    {
      "name": "Kernel Memory",
      "one_line_profile": "AI memory service for efficient indexing and retrieval of data",
      "detailed_description": "Kernel Memory is a multi-modal AI memory service that provides ingestion, indexing, and retrieval pipelines for RAG applications. It supports various vector databases and storage backends, enabling agents to maintain long-term memory of scientific documents and data.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "data_ingestion",
        "rag"
      ],
      "application_level": "service",
      "primary_language": "C#",
      "repo_url": "https://github.com/microsoft/kernel-memory",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "memory-service",
        "vector-search"
      ],
      "id": 1095
    },
    {
      "name": "vAttention",
      "one_line_profile": "Dynamic memory management library for serving LLMs",
      "detailed_description": "vAttention is a system library for dynamic memory management in LLM serving, optimizing KV-cache usage without PagedAttention. It enhances the efficiency of inference for large models used in scientific computing and analysis.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "inference_optimization",
        "memory_management"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/microsoft/vattention",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-serving",
        "cuda",
        "memory-optimization"
      ],
      "id": 1096
    },
    {
      "name": "Knowhere",
      "one_line_profile": "Core vector search engine library for Milvus",
      "detailed_description": "Knowhere is the core vector search engine library used by Milvus, integrating various ANN algorithms like FAISS and HNSW. It provides a unified interface for vector similarity search, essential for high-performance scientific data retrieval.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/milvus-io/knowhere",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-search",
        "ann",
        "faiss"
      ],
      "id": 1097
    },
    {
      "name": "Milvus",
      "one_line_profile": "High-performance cloud-native vector database",
      "detailed_description": "Milvus is a distributed vector database built for scalable similarity search. It is widely used in scientific applications for managing and querying massive vector datasets derived from molecules, biological sequences, and literature.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_database",
        "similarity_search"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/milvus-io/milvus",
      "help_website": [
        "https://milvus.io/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "ann",
        "cloud-native"
      ],
      "id": 1098
    },
    {
      "name": "Milvus Lite",
      "one_line_profile": "Lightweight embedded version of Milvus vector database",
      "detailed_description": "Milvus Lite is a lightweight, serverless version of Milvus that can be embedded into Python applications. It enables local vector search capabilities for scientific workflows without requiring a full distributed database deployment.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "local_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/milvus-io/milvus-lite",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-search",
        "embedded-db",
        "python"
      ],
      "id": 1099
    },
    {
      "name": "Milvus Model",
      "one_line_profile": "Library for embedding and reranking models integration",
      "detailed_description": "Milvus Model is a utility library that integrates various embedding and reranking models (e.g., OpenAI, SentenceTransformers) for use with Milvus. It simplifies the data processing pipeline for generating vectors from scientific text or data.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "embedding_generation",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/milvus-io/milvus-model",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "embeddings",
        "reranking",
        "model-integration"
      ],
      "id": 1100
    },
    {
      "name": "Decipher Research Agent",
      "one_line_profile": "AI agent for generating research notebooks from topics and files",
      "detailed_description": "Decipher Research Agent is a tool that automates the research process by turning topics, links, and files into AI-generated research notebooks. It assists in scientific literature review, summarization, and exploration.",
      "domains": [
        "AI5",
        "AI5-01"
      ],
      "subtask_category": [
        "literature_review",
        "research_automation",
        "summarization"
      ],
      "application_level": "application",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/mtwn105/decipher-research-agent",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "research-agent",
        "literature-review",
        "automation"
      ],
      "id": 1101
    },
    {
      "name": "LocalRecall",
      "one_line_profile": "Local memory layer and knowledge base for agents",
      "detailed_description": "LocalRecall is a local memory layer and knowledge base solution for AI agents. It provides a mechanism for agents to store and retrieve information locally, supporting privacy-preserving scientific assistants.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "knowledge_base"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/mudler/LocalRecall",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "local-memory",
        "agent-memory",
        "knowledge-base"
      ],
      "id": 1102
    },
    {
      "name": "MyScaleDB",
      "one_line_profile": "High-performance SQL vector database based on ClickHouse",
      "detailed_description": "MyScaleDB is a vector database built on top of ClickHouse, combining high-performance vector search with full SQL support. It is suitable for complex scientific data analysis requiring both relational and semantic queries.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_database",
        "sql_analytics",
        "hybrid_search"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/myscale/MyScaleDB",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "sql",
        "clickhouse"
      ],
      "id": 1103
    },
    {
      "name": "Vector DB Benchmark",
      "one_line_profile": "Framework for benchmarking vector databases",
      "detailed_description": "Vector DB Benchmark is a framework for evaluating the performance of various vector databases. It allows researchers and engineers to assess the scalability and latency of vector search systems used in scientific applications.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/myscale/vector-db-benchmark",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "vector-database",
        "performance"
      ],
      "id": 1104
    },
    {
      "name": "pg_embedding",
      "one_line_profile": "HNSW vector similarity search extension for PostgreSQL",
      "detailed_description": "A PostgreSQL extension implementing the Hierarchical Navigable Small World (HNSW) algorithm for efficient vector similarity search, enabling relational databases to serve as vector stores for scientific RAG applications.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_indexing",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/neondatabase/pg_embedding",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "postgresql",
        "vector-search",
        "hnsw",
        "embedding"
      ],
      "id": 1105
    },
    {
      "name": "Local-GenAI-Search",
      "one_line_profile": "Local generative search engine for personal document repositories",
      "detailed_description": "A privacy-focused RAG tool that indexes local files using Qdrant and LangChain, allowing researchers to perform question-answering over their own document collections using local LLMs.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "document_retrieval",
        "question_answering",
        "personal_knowledge_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nikolamilosevic86/local-genAI-search",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "rag",
        "local-llm",
        "qdrant",
        "document-search"
      ],
      "id": 1106
    },
    {
      "name": "VerifAI",
      "one_line_profile": "Generative QA engine with answer verification",
      "detailed_description": "An open-source initiative to build a generative question-answering engine that includes a posteriori verification step to ensure the correctness of generated answers, critical for scientific inquiry.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "question_answering",
        "fact_verification"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/nikolamilosevic86/verifAI",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "verification",
        "qa",
        "generative-ai"
      ],
      "id": 1107
    },
    {
      "name": "Nixiesearch",
      "one_line_profile": "Hybrid search engine combining text and semantic search",
      "detailed_description": "A search engine designed to combine the precision of lexical search with the understanding of semantic search, suitable for building advanced retrieval systems for scientific data and literature.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "hybrid_search",
        "information_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Scala",
      "repo_url": "https://github.com/nixiesearch/nixiesearch",
      "help_website": [
        "https://nixiesearch.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "search-engine",
        "hybrid-search",
        "vector-search"
      ],
      "id": 1108
    },
    {
      "name": "Reflexion",
      "one_line_profile": "Autonomous agent framework with dynamic memory and self-reflection",
      "detailed_description": "A framework for building autonomous agents that can verbally reflect on task feedback and maintain a dynamic memory, improving performance on complex reasoning tasks through self-correction.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_memory",
        "autonomous_reasoning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/noahshinn/reflexion-draft",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent",
        "memory",
        "reflection",
        "llm"
      ],
      "id": 1109
    },
    {
      "name": "Victor",
      "one_line_profile": "Web-optimized vector database written in Rust",
      "detailed_description": "A lightweight, high-performance vector database designed for web environments, enabling efficient storage and retrieval of vector embeddings for AI applications.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_storage",
        "similarity_search"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/not-pizza/victor",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "vector-database",
        "rust",
        "embeddings"
      ],
      "id": 1110
    },
    {
      "name": "NucliaDB",
      "one_line_profile": "AI Search database optimized for RAG",
      "detailed_description": "A database designed specifically for RAG applications, capable of indexing unstructured data (text, video, audio) and providing semantic search capabilities to power AI agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_storage",
        "semantic_search",
        "rag_pipeline"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/nuclia/nucliadb",
      "help_website": [
        "https://docs.nuclia.dev/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "rag",
        "vector-database",
        "search"
      ],
      "id": 1111
    },
    {
      "name": "ObjectBox Java",
      "one_line_profile": "High-performance on-device vector database",
      "detailed_description": "A fast, lightweight database for edge devices that supports vector search, enabling local AI and RAG applications on mobile and IoT devices without cloud dependency.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_storage",
        "edge_computing"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/objectbox/objectbox-java",
      "help_website": [
        "https://objectbox.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "edge-ai",
        "java",
        "android"
      ],
      "id": 1112
    },
    {
      "name": "SeekDB",
      "one_line_profile": "AI-Native search database unifying vector and structured data",
      "detailed_description": "A database engine designed to unify vector, text, and structured data processing, enabling hybrid search and in-database AI workflows for complex data analysis.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "hybrid_search",
        "vector_storage",
        "data_unification"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/oceanbase/seekdb",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "hybrid-search",
        "ai-native"
      ],
      "id": 1113
    },
    {
      "name": "Knowledge MCP",
      "one_line_profile": "Local knowledge base MCP server with hybrid RAG",
      "detailed_description": "A Model Context Protocol (MCP) server that provides a local knowledge base with hybrid vector and graph RAG capabilities (using LightRAG), allowing AI agents to interface with local data.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "knowledge_base",
        "rag_pipeline",
        "agent_interface"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/olafgeibig/knowledge-mcp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "rag",
        "knowledge-base",
        "lightrag"
      ],
      "id": 1114
    },
    {
      "name": "AIFS",
      "one_line_profile": "Simple local semantic search tool for file systems",
      "detailed_description": "A lightweight Python tool for performing local semantic search over file systems. It indexes files and allows for natural language queries, useful for researchers managing personal data repositories.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "local_search",
        "personal_knowledge_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/openinterpreter/aifs",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "semantic-search",
        "local-files",
        "embeddings"
      ],
      "id": 1115
    },
    {
      "name": "Open Semantic ETL",
      "one_line_profile": "ETL pipeline for document processing and semantic analysis",
      "detailed_description": "A Python-based ETL toolset for crawling, text extraction, OCR, NER, and data enrichment. It prepares unstructured data for ingestion into search indices or knowledge graphs, facilitating scientific literature mining.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "data_ingestion",
        "ocr",
        "ner",
        "etl"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/opensemanticsearch/open-semantic-etl",
      "help_website": [
        "https://opensemanticsearch.org/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "etl",
        "ocr",
        "ner",
        "semantic-search"
      ],
      "id": 1116
    },
    {
      "name": "Open Semantic Search",
      "one_line_profile": "Research tool for semantic search and document analysis",
      "detailed_description": "An integrated search platform for analyzing large document collections. It combines full-text search, faceted search, and knowledge graph exploration, designed for research and investigative tasks.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "semantic_search",
        "document_analysis",
        "knowledge_discovery"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/opensemanticsearch/open-semantic-search",
      "help_website": [
        "https://opensemanticsearch.org/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "search-engine",
        "text-mining",
        "research-tool"
      ],
      "id": 1117
    },
    {
      "name": "Eidos",
      "one_line_profile": "Self-growing AI agent with long-term memory",
      "detailed_description": "An experimental AI agent framework featuring long-term memory and environmental awareness, designed to evolve and learn over time, relevant to research in autonomous scientific agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_memory",
        "autonomous_learning"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/opisaac9001/eidos",
      "help_website": [],
      "license": null,
      "tags": [
        "agent",
        "memory",
        "autonomous-ai"
      ],
      "id": 1118
    },
    {
      "name": "Orama",
      "one_line_profile": "Browser/Edge-compatible search engine and RAG pipeline",
      "detailed_description": "A lightweight, full-text and vector search engine that runs in browsers, servers, or edge networks. It supports hybrid search and RAG pipelines, enabling portable scientific data exploration tools.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "rag_pipeline",
        "edge_inference"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/oramasearch/orama",
      "help_website": [
        "https://docs.oramasearch.com/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "search-engine",
        "vector-search",
        "edge-ai",
        "rag"
      ],
      "id": 1119
    },
    {
      "name": "Mimir",
      "one_line_profile": "Agent memory bank with semantic vector search",
      "detailed_description": "A memory management system for AI agents, providing semantic vector search for locally indexed files and shared memories across sessions. It enables agents to retain context and learn from past interactions.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_memory",
        "local_retrieval",
        "context_management"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/orneryd/Mimir",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "memory",
        "agent",
        "vector-search",
        "local-first"
      ],
      "id": 1120
    },
    {
      "name": "NornicDB",
      "one_line_profile": "Graph database designed for AI agents",
      "detailed_description": "A high-performance graph database tailored for AI agents and knowledge systems. It supports Neo4j protocols and includes features like GPU-accelerated embedding search, facilitating complex reasoning on knowledge graphs.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "graph_database",
        "knowledge_representation",
        "agent_memory"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/orneryd/NornicDB",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "graph-database",
        "agent",
        "neo4j-compatible",
        "gpu-acceleration"
      ],
      "id": 1121
    },
    {
      "name": "fegis",
      "one_line_profile": "YAML-based AI tool definition and memory retrieval framework using Qdrant",
      "detailed_description": "A framework that allows defining AI tools using YAML schemas and automatically stores tool usage in a Qdrant vector database. It enables semantic search, filtering, and memory retrieval across sessions for AI agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_memory",
        "tool_definition"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/p-funk/fegis",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-memory",
        "qdrant",
        "tool-management"
      ],
      "id": 1122
    },
    {
      "name": "RAPTOR",
      "one_line_profile": "Recursive Abstractive Processing for Tree-Organized Retrieval",
      "detailed_description": "The official implementation of RAPTOR, a retrieval method that constructs a tree structure of documents to enable recursive abstractive processing for more effective retrieval in RAG systems.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "retrieval_augmented_generation",
        "information_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/parthsarthi03/raptor",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "retrieval",
        "tree-structure"
      ],
      "id": 1123
    },
    {
      "name": "Pathway",
      "one_line_profile": "High-performance data processing framework for RAG and real-time analytics",
      "detailed_description": "A Python ETL framework designed for stream processing, real-time analytics, and LLM pipelines. It supports RAG workflows by handling data ingestion and vector indexing updates efficiently.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "data_pipeline",
        "rag_pipeline"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/pathwaycom/pathway",
      "help_website": [
        "https://pathway.com"
      ],
      "license": "NOASSERTION",
      "tags": [
        "etl",
        "stream-processing",
        "rag"
      ],
      "id": 1124
    },
    {
      "name": "EuclidesDB",
      "one_line_profile": "Multi-model machine learning feature embedding database",
      "detailed_description": "A specialized database written in C++ for storing and querying machine learning feature embeddings, supporting multi-model integration for vector search tasks.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_database",
        "embedding_storage"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/perone/euclidesdb",
      "help_website": [
        "https://euclidesdb.readthedocs.io"
      ],
      "license": "NOASSERTION",
      "tags": [
        "vector-db",
        "embeddings",
        "feature-store"
      ],
      "id": 1125
    },
    {
      "name": "VectorVFS",
      "one_line_profile": "Filesystem interface for vector database operations",
      "detailed_description": "A tool that exposes a vector database as a filesystem, allowing users to interact with vector embeddings and search operations using standard filesystem commands.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_storage",
        "data_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/perone/vectorvfs",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "filesystem",
        "vector-db",
        "interface"
      ],
      "id": 1126
    },
    {
      "name": "pgvector",
      "one_line_profile": "Open-source vector similarity search extension for PostgreSQL",
      "detailed_description": "A PostgreSQL extension that adds support for vector similarity search, enabling storage and querying of embeddings directly within a relational database. Essential for scientific data management and RAG.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_database",
        "similarity_search"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/pgvector/pgvector",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "postgresql",
        "vector-search",
        "embeddings"
      ],
      "id": 1127
    },
    {
      "name": "pgvector-python",
      "one_line_profile": "Python client for pgvector vector similarity search",
      "detailed_description": "The Python interface for the pgvector PostgreSQL extension, enabling integration of vector search capabilities into Python-based scientific workflows and data analysis pipelines.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "database_interface"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pgvector/pgvector-python",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "python",
        "postgresql",
        "vector-search"
      ],
      "id": 1128
    },
    {
      "name": "chromem-go",
      "one_line_profile": "Embeddable in-memory vector database for Go",
      "detailed_description": "An embeddable vector database written in Go, offering a Chroma-like interface with optional persistence. Suitable for lightweight vector storage and retrieval in scientific infrastructure.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_database",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/philippgille/chromem-go",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "vector-db",
        "go",
        "embedded"
      ],
      "id": 1129
    },
    {
      "name": "AutoFlow",
      "one_line_profile": "Graph RAG and conversational knowledge base tool",
      "detailed_description": "A tool that combines Graph RAG (Retrieval Augmented Generation) with conversational interfaces, built on TiDB Serverless Vector Storage, enabling complex knowledge retrieval and interaction.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "graph_rag",
        "knowledge_base"
      ],
      "application_level": "application",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/pingcap/autoflow",
      "help_website": [
        "https://tidb.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "graph-rag",
        "knowledge-graph",
        "tidb"
      ],
      "id": 1130
    },
    {
      "name": "mem0-mcp",
      "one_line_profile": "Model Context Protocol (MCP) server for mem0 memory system",
      "detailed_description": "An MCP server implementation for the mem0 memory system, enabling AI agents to access long-term memory capabilities through the Model Context Protocol standard.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_memory",
        "tool_calling"
      ],
      "application_level": "service",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/pinkpixel-dev/mem0-mcp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "memory",
        "agent-tool"
      ],
      "id": 1131
    },
    {
      "name": "pyflann",
      "one_line_profile": "Python bindings for FLANN (Fast Library for Approximate Nearest Neighbors)",
      "detailed_description": "Python bindings for the FLANN library, providing fast approximate nearest neighbor search algorithms, widely used in scientific data clustering and computer vision tasks.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "nearest_neighbor_search",
        "clustering"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/primetang/pyflann",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ann",
        "flann",
        "nearest-neighbor"
      ],
      "id": 1132
    },
    {
      "name": "zEpid",
      "one_line_profile": "Epidemiology analysis package for Python",
      "detailed_description": "A Python package designed for epidemiological analysis, providing tools for causal inference, risk estimation, and other statistical methods relevant to public health and medical research.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "epidemiology_analysis",
        "causal_inference"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pzivich/zEpid",
      "help_website": [
        "https://zepid.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "epidemiology",
        "statistics",
        "causal-inference"
      ],
      "id": 1133
    },
    {
      "name": "Qdrant",
      "one_line_profile": "High-performance vector database for neural search and AI memory",
      "detailed_description": "A vector similarity search engine and vector database that provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. It is essential for implementing Retrieval-Augmented Generation (RAG) in scientific literature search and knowledge management systems.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "scientific_knowledge_retrieval",
        "vector_similarity_search"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/qdrant/qdrant",
      "help_website": [
        "https://qdrant.tech/documentation/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "vector-database",
        "rag",
        "similarity-search",
        "knowledge-base"
      ],
      "id": 1134
    },
    {
      "name": "qKnow",
      "one_line_profile": "Enterprise knowledge graph platform for extraction and fusion",
      "detailed_description": "An open-source knowledge platform built around Knowledge Graphs, offering capabilities for knowledge extraction, knowledge fusion, graph construction, and visualization. It supports building structured, queryable, and inferable knowledge systems for scientific and organizational data.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "knowledge_extraction"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/qiantongtech/qKnow",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "knowledge-graph",
        "knowledge-fusion",
        "visualization"
      ],
      "id": 1135
    },
    {
      "name": "RagaAI-Catalyst",
      "one_line_profile": "Observability and evaluation framework for AI agents",
      "detailed_description": "A Python SDK for Agent AI Observability, Monitoring, and Evaluation. It includes features for tracing agents, LLMs, and tools, debugging multi-agentic systems, and providing advanced analytics with execution graph views, which is critical for developing reliable scientific research agents.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "agent_evaluation",
        "workflow_debugging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/raga-ai-hub/RagaAI-Catalyst",
      "help_website": [
        "https://docs.raga.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "observability",
        "agent-evaluation",
        "llm-tracing"
      ],
      "id": 1136
    },
    {
      "name": "PdfGptIndexer",
      "one_line_profile": "PDF indexing and search tool for literature review",
      "detailed_description": "A RAG-based tool for indexing and searching PDF text data using OpenAI API and FAISS. It is designed for rapid information retrieval from scientific documents (PDFs) with high search accuracy.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "literature_review",
        "pdf_indexing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/raghavan/PdfGptIndexer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pdf-search",
        "rag",
        "literature-review"
      ],
      "id": 1137
    },
    {
      "name": "cuVS",
      "one_line_profile": "GPU-accelerated library for vector search and clustering",
      "detailed_description": "A library for vector search and clustering on the GPU, part of the RAPIDS ecosystem. It provides high-performance algorithms for approximate nearest neighbor search and clustering, which are fundamental for analyzing large-scale scientific data (e.g., single-cell genomics, molecular similarity).",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "clustering",
        "vector_search",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/rapidsai/cuvs",
      "help_website": [
        "https://docs.rapids.ai/api/cuvs/stable/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "gpu",
        "vector-search",
        "clustering",
        "rapids"
      ],
      "id": 1138
    },
    {
      "name": "Context Keeper",
      "one_line_profile": "LLM-driven intelligent memory and context management system",
      "detailed_description": "A platform for AI memory management and intelligent context awareness. It supports RAG retrieval augmented generation and vector search, providing a memory layer for research agents to maintain context over long scientific workflows.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "context_awareness"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/redleaves/context-keeper",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "memory-management",
        "rag",
        "context-awareness"
      ],
      "id": 1139
    },
    {
      "name": "semtools",
      "one_line_profile": "CLI tools for semantic search and document parsing",
      "detailed_description": "A set of command-line tools for semantic search and document parsing. It facilitates the processing of text data for scientific analysis and RAG pipelines directly from the terminal.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "document_parsing",
        "semantic_search"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/run-llama/semtools",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cli",
        "semantic-search",
        "parsing"
      ],
      "id": 1140
    },
    {
      "name": "hnsw",
      "one_line_profile": "Rust implementation of HNSW for approximate nearest neighbor search",
      "detailed_description": "A Rust library implementing the Hierarchical Navigable Small World (HNSW) algorithm for efficient and robust approximate nearest neighbor search in high-dimensional spaces, suitable for vector indexing.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "similarity_search",
        "vector_indexing"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/rust-cv/hnsw",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hnsw",
        "ann",
        "vector-search",
        "rust"
      ],
      "id": 1141
    },
    {
      "name": "claude-flow",
      "one_line_profile": "Agent orchestration platform for Claude with RAG integration",
      "detailed_description": "An agent orchestration platform designed for deploying intelligent multi-agent swarms and coordinating autonomous workflows, featuring RAG integration and support for the Model Context Protocol (MCP).",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_orchestration",
        "workflow_automation"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/ruvnet/claude-flow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "agent-orchestration",
        "rag",
        "multi-agent",
        "claude"
      ],
      "id": 1142
    },
    {
      "name": "ruvector",
      "one_line_profile": "Distributed vector database with Graph Neural Network indexing",
      "detailed_description": "A distributed vector database that supports storing embeddings and querying with Cypher. It scales horizontally using Raft consensus and utilizes Graph Neural Networks for self-improving indexing.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_storage",
        "graph_indexing"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/ruvnet/ruvector",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vector-database",
        "gnn",
        "distributed-systems",
        "rust"
      ],
      "id": 1143
    },
    {
      "name": "panns",
      "one_line_profile": "Python Approximate Nearest Neighbor Search library",
      "detailed_description": "A Python library for Approximate Nearest Neighbor Search (ANNS) in very high-dimensional spaces, featuring optimized indexing for efficient similarity retrieval.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "similarity_search",
        "vector_indexing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ryanrhymes/panns",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "ann",
        "nearest-neighbor",
        "high-dimensional",
        "python"
      ],
      "id": 1144
    },
    {
      "name": "SimilaritySearch.jl",
      "one_line_profile": "Nearest neighbor search library for Julia",
      "detailed_description": "A Julia library providing exact and approximate algorithms for nearest neighbor search, enabling efficient similarity queries in scientific computing workflows.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "similarity_search",
        "data_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/sadit/SimilaritySearch.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "nearest-neighbor",
        "similarity-search",
        "ann"
      ],
      "id": 1145
    },
    {
      "name": "HypEx",
      "one_line_profile": "Framework for Causal Inference in Python",
      "detailed_description": "A fast and customizable Python framework for automatic causal inference, facilitating statistical analysis and effect estimation in scientific research.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "causal_inference",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sb-ai-lab/HypEx",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "causal-inference",
        "statistics",
        "python",
        "data-analysis"
      ],
      "id": 1146
    },
    {
      "name": "orbit",
      "one_line_profile": "Context-aware inference engine for privacy-focused AI",
      "detailed_description": "An adaptable, open-source context-aware inference engine designed to provide privacy, control, and independence from proprietary models, suitable for local research agent deployments.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "inference_engine",
        "context_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/schmitech/orbit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "privacy",
        "local-llm",
        "context-aware"
      ],
      "id": 1147
    },
    {
      "name": "scylladb-vector-store",
      "one_line_profile": "Vector indexing service for ScyllaDB",
      "detailed_description": "The indexing service component for ScyllaDB that enables vector search functionality, allowing high-performance similarity search on distributed data.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_indexing",
        "database_extension"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/scylladb/vector-store",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "scylladb",
        "vector-search",
        "indexing",
        "rust"
      ],
      "id": 1148
    },
    {
      "name": "vlite",
      "one_line_profile": "Lightweight vector database using NumPy",
      "detailed_description": "A fast and lightweight vector database implemented in Python using NumPy, designed for simple and efficient embedding storage and retrieval.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_storage",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sdan/vlite",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vector-database",
        "numpy",
        "python",
        "embeddings"
      ],
      "id": 1149
    },
    {
      "name": "mcp-memory",
      "one_line_profile": "MCP Memory Server with PostgreSQL and pgvector",
      "detailed_description": "A Model Context Protocol (MCP) server implementation that uses PostgreSQL and pgvector to provide long-term memory capabilities for AI agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "agent_infrastructure"
      ],
      "application_level": "service",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/sdimitrov/mcp-memory",
      "help_website": [],
      "license": null,
      "tags": [
        "mcp",
        "memory",
        "postgresql",
        "pgvector"
      ],
      "id": 1150
    },
    {
      "name": "similarities",
      "one_line_profile": "Toolkit for similarity calculation and semantic search",
      "detailed_description": "A Python toolkit for calculating similarities and performing semantic search across text and images, supporting large-scale data matching.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "similarity_calculation",
        "semantic_search"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shibing624/similarities",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "similarity",
        "semantic-search",
        "text-matching",
        "image-matching"
      ],
      "id": 1151
    },
    {
      "name": "memonto",
      "one_line_profile": "Long-term memory for AI agents using Knowledge Graphs",
      "detailed_description": "A library to augment AI agents with long-term memory capabilities by utilizing knowledge graphs, enabling structured information retention and retrieval.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_augmentation",
        "knowledge_graph"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shihanwan/memonto",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "memory",
        "knowledge-graph",
        "agents",
        "llm"
      ],
      "id": 1152
    },
    {
      "name": "codeinterpreter-api",
      "one_line_profile": "Open source implementation of ChatGPT Code Interpreter",
      "detailed_description": "An API that provides a code execution sandbox for LLMs, allowing agents to write and execute Python code for data analysis and visualization tasks.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "code_execution",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shroominic/codeinterpreter-api",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "code-interpreter",
        "sandbox",
        "agent-tool",
        "python"
      ],
      "id": 1153
    },
    {
      "name": "Agent-S",
      "one_line_profile": "Open agentic framework for computer interaction",
      "detailed_description": "An open agentic framework designed to enable AI agents to use computers like humans, facilitating automated workflows and task execution.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_framework",
        "workflow_automation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/simular-ai/Agent-S",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "agent-framework",
        "automation",
        "computer-use",
        "ai-agent"
      ],
      "id": 1154
    },
    {
      "name": "annoy",
      "one_line_profile": "Approximate Nearest Neighbors in C++/Python",
      "detailed_description": "A C++ library with Python bindings for Approximate Nearest Neighbors (ANN) search, optimized for memory usage and disk loading, widely used in data science and bioinformatics.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "similarity_search",
        "vector_indexing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/spotify/annoy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ann",
        "nearest-neighbor",
        "cpp",
        "python"
      ],
      "id": 1155
    },
    {
      "name": "annoy-java",
      "one_line_profile": "Approximate nearest neighbors library for Java",
      "detailed_description": "A Java implementation/port of the Annoy library for approximate nearest neighbor search, enabling vector search capabilities in Java-based scientific applications.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "similarity_search",
        "vector_indexing"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/spotify/annoy-java",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ann",
        "java",
        "nearest-neighbor",
        "vector-search"
      ],
      "id": 1156
    },
    {
      "name": "voyager",
      "one_line_profile": "Approximate nearest-neighbor search library",
      "detailed_description": "A library for approximate nearest-neighbor search in Python and Java, focusing on ease of use, simplicity, and deployability for vector retrieval tasks.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "similarity_search",
        "vector_indexing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/spotify/voyager",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ann",
        "vector-search",
        "nearest-neighbor",
        "python"
      ],
      "id": 1157
    },
    {
      "name": "sqlite-vector",
      "one_line_profile": "Vector search extension for SQLite",
      "detailed_description": "A cross-platform, ultra-efficient SQLite extension that adds vector search capabilities to the embedded database, enabling local vector storage and retrieval.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "database_extension"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/sqliteai/sqlite-vector",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "sqlite",
        "vector-search",
        "extension",
        "embedded-db"
      ],
      "id": 1158
    },
    {
      "name": "mysql_vss",
      "one_line_profile": "MySQL plugin for storing and querying vector embeddings",
      "detailed_description": "A MySQL plugin that enables vector similarity search within standard MySQL databases, facilitating the integration of vector embeddings into existing data workflows.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "database_extension"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/stephenc222/mysql_vss",
      "help_website": [],
      "license": null,
      "tags": [
        "mysql",
        "vector-search",
        "embeddings"
      ],
      "id": 1159
    },
    {
      "name": "Flexible GraphRAG",
      "one_line_profile": "Flexible framework for building GraphRAG applications with knowledge graph auto-building",
      "detailed_description": "A comprehensive framework for constructing and querying Knowledge Graphs using RAG, supporting multiple vector and graph databases, and enabling automated knowledge graph construction from documents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "knowledge_graph_construction",
        "rag",
        "information_retrieval"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/stevereiner/flexible-graphrag",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "graphrag",
        "knowledge-graph",
        "rag"
      ],
      "id": 1160
    },
    {
      "name": "SONG",
      "one_line_profile": "Graph-based Approximate Nearest Neighbor Search on GPU",
      "detailed_description": "A toolbox for approximate nearest neighbor search on GPUs using graph-based methods, accelerating vector retrieval tasks common in scientific data analysis.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "ann_search"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/sunbelbd/song",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "ann",
        "vector-search"
      ],
      "id": 1161
    },
    {
      "name": "vecs",
      "one_line_profile": "Python client for managing vector stores in PostgreSQL via pgvector",
      "detailed_description": "A Python client designed to simplify the management of vector embeddings in PostgreSQL using the pgvector extension, facilitating vector search workflows.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_management",
        "database_interface"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/supabase/vecs",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pgvector",
        "postgresql",
        "vector-database"
      ],
      "id": 1162
    },
    {
      "name": "Superduper",
      "one_line_profile": "Framework for integrating AI models and vector search directly with databases",
      "detailed_description": "An end-to-end framework that connects AI models and vector search capabilities directly to databases, enabling training and inference within the data layer for building AI agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "model_deployment",
        "vector_search"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/superduper-io/superduper",
      "help_website": [
        "https://docs.superduper.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ai-agents",
        "database-integration",
        "vector-search"
      ],
      "id": 1163
    },
    {
      "name": "RAGLite",
      "one_line_profile": "Lightweight toolkit for RAG with DuckDB or PostgreSQL",
      "detailed_description": "A Python toolkit designed to simplify Retrieval-Augmented Generation (RAG) workflows using DuckDB or PostgreSQL as the backend for vector storage and retrieval.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "rag",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/superlinear-ai/raglite",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "rag",
        "duckdb",
        "postgresql"
      ],
      "id": 1164
    },
    {
      "name": "Supermemory MCP",
      "one_line_profile": "Model Context Protocol server for universal agent memory",
      "detailed_description": "An implementation of the Model Context Protocol (MCP) that provides a universal memory layer for LLMs, allowing agents to store and retrieve context across different sessions and models.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "context_retrieval"
      ],
      "application_level": "service",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/supermemoryai/supermemory-mcp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mcp",
        "memory",
        "llm-agent"
      ],
      "id": 1165
    },
    {
      "name": "VecTextSearch",
      "one_line_profile": "Lightweight vector text search engine",
      "detailed_description": "A simple vector text search implementation in Go, providing basic capabilities for semantic search and retrieval.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "text_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/szpnygo/VecTextSearch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vector-search",
        "go",
        "semantic-search"
      ],
      "id": 1166
    },
    {
      "name": "t-rex",
      "one_line_profile": "Vector tile server for publishing geospatial data",
      "detailed_description": "A specialized server for publishing MVT vector tiles from various data sources, facilitating the visualization and distribution of geospatial scientific data.",
      "domains": [
        "Scientific Visualization",
        "Geospatial"
      ],
      "subtask_category": [
        "visualization",
        "data_publishing"
      ],
      "application_level": "service",
      "primary_language": "Rust",
      "repo_url": "https://github.com/t-rex-tileserver/t-rex",
      "help_website": [
        "https://t-rex.tileserver.ch/"
      ],
      "license": "MIT",
      "tags": [
        "gis",
        "vector-tiles",
        "mapping"
      ],
      "id": 1167
    },
    {
      "name": "Voy",
      "one_line_profile": "WASM-based vector similarity search engine",
      "detailed_description": "A vector similarity search engine written in Rust and compiled to WebAssembly, enabling efficient vector search in browser or edge environments.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "similarity_search"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/tantaraio/voy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "wasm",
        "vector-search",
        "rust"
      ],
      "id": 1168
    },
    {
      "name": "Cognitive Workspace",
      "one_line_profile": "Active memory management system for LLMs",
      "detailed_description": "A memory architecture designed to provide functional infinite context for Large Language Models through an active memory management system.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "context_extension"
      ],
      "application_level": "library",
      "primary_language": "TeX",
      "repo_url": "https://github.com/tao-hpu/cognitive-workspace",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-memory",
        "context-management"
      ],
      "id": 1169
    },
    {
      "name": "Raggo",
      "one_line_profile": "Lightweight RAG library in Go",
      "detailed_description": "A production-ready library for implementing Retrieval Augmented Generation (RAG) workflows in Go applications.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "rag",
        "information_retrieval"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/teilomillet/raggo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "go",
        "retrieval"
      ],
      "id": 1170
    },
    {
      "name": "VectorChord",
      "one_line_profile": "Scalable vector search engine for PostgreSQL",
      "detailed_description": "A high-performance vector search extension for PostgreSQL, designed for scalability and disk-friendly operations, serving as a successor to pgvecto.rs.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "database_extension"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/tensorchord/VectorChord",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "postgresql",
        "vector-search",
        "rust"
      ],
      "id": 1171
    },
    {
      "name": "pgvecto.rs",
      "one_line_profile": "Scalable vector search extension for Postgres",
      "detailed_description": "A PostgreSQL extension written in Rust that provides scalable, low-latency, and hybrid-enabled vector search capabilities.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "database_extension"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/tensorchord/pgvecto.rs",
      "help_website": [
        "https://docs.pgvecto.rs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "postgresql",
        "vector-search",
        "rust"
      ],
      "id": 1172
    },
    {
      "name": "InfLLM",
      "one_line_profile": "Training-free memory mechanism for extremely long sequences in LLMs",
      "detailed_description": "A library implementing a training-free memory mechanism that enables Large Language Models to process extremely long sequences by effectively managing context.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "context_extension"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/thunlp/InfLLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "long-context",
        "memory"
      ],
      "id": 1173
    },
    {
      "name": "PipeANN",
      "one_line_profile": "Graph-based vector store on SSD for billion-scale data",
      "detailed_description": "A low-latency, billion-scale, and updatable graph-based vector storage system optimized for SSDs, suitable for large-scale scientific retrieval tasks.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_storage",
        "ann_search"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/thustorage/PipeANN",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vector-store",
        "ssd",
        "ann"
      ],
      "id": 1174
    },
    {
      "name": "pgai",
      "one_line_profile": "Suite of tools for building RAG and AI apps with PostgreSQL",
      "detailed_description": "A collection of tools and extensions to facilitate the development of Retrieval-Augmented Generation (RAG) and semantic search applications directly within PostgreSQL.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "rag",
        "semantic_search",
        "database_extension"
      ],
      "application_level": "library",
      "primary_language": "PLpgSQL",
      "repo_url": "https://github.com/timescale/pgai",
      "help_website": [],
      "license": "PostgreSQL",
      "tags": [
        "postgresql",
        "rag",
        "ai-development"
      ],
      "id": 1175
    },
    {
      "name": "pgvectorscale",
      "one_line_profile": "High-performance vector search extension for PostgreSQL using DiskANN",
      "detailed_description": "A PostgreSQL extension that implements DiskANN for scalable and high-performance vector search, complementing pgvector for larger datasets.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "database_extension"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/timescale/pgvectorscale",
      "help_website": [],
      "license": "PostgreSQL",
      "tags": [
        "postgresql",
        "diskann",
        "vector-search"
      ],
      "id": 1176
    },
    {
      "name": "weaviate-php",
      "one_line_profile": "PHP client for Weaviate vector database",
      "detailed_description": "A PHP client library for interacting with the Weaviate vector database, enabling the integration of vector search into PHP-based scientific or data applications.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "database_interface",
        "vector_search"
      ],
      "application_level": "library",
      "primary_language": "PHP",
      "repo_url": "https://github.com/timkley/weaviate-php",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "weaviate",
        "php",
        "vector-database"
      ],
      "id": 1177
    },
    {
      "name": "LangChainGo",
      "one_line_profile": "Go implementation of the LangChain framework",
      "detailed_description": "The Go language implementation of LangChain, a framework for developing applications powered by language models, including agents and memory management.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "agent_development"
      ],
      "application_level": "framework",
      "primary_language": "Go",
      "repo_url": "https://github.com/tmc/langchaingo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "langchain",
        "go",
        "llm-agents"
      ],
      "id": 1178
    },
    {
      "name": "Attention Sinks",
      "one_line_profile": "Library for extending LLM context length with constant memory",
      "detailed_description": "A library that enables existing Large Language Models to handle infinite length sequences without retraining by modifying the attention mechanism to use constant memory.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_management",
        "context_extension"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tomaarsen/attention_sinks",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "attention",
        "llm",
        "memory-efficiency"
      ],
      "id": 1179
    },
    {
      "name": "Weaviate",
      "one_line_profile": "Cloud-native open-source vector database for AI applications",
      "detailed_description": "Weaviate is a vector database that stores both objects and vectors, allowing for combined vector search with structured filtering. It serves as a critical memory and knowledge retrieval component for AI agents and scientific RAG workflows, supporting fault tolerance and scalability.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_storage",
        "semantic_search",
        "knowledge_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/weaviate/weaviate",
      "help_website": [
        "https://weaviate.io/developers/weaviate"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "vector-database",
        "semantic-search",
        "rag",
        "memory"
      ],
      "id": 1180
    },
    {
      "name": "Rule-based Retrieval",
      "one_line_profile": "Advanced filtering and management package for RAG applications",
      "detailed_description": "A Python package designed to enhance Retrieval Augmented Generation (RAG) systems with advanced rule-based filtering capabilities. It integrates with vector databases like Pinecone or Milvus to manage knowledge retrieval, which is essential for scientific question-answering systems.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "rag",
        "knowledge_filtering",
        "retrieval_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/whyhow-ai/rule-based-retrieval",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "retrieval",
        "filtering",
        "vector-db-integration"
      ],
      "id": 1181
    },
    {
      "name": "Comet",
      "one_line_profile": "Hybrid vector store with multiple retrieval methods",
      "detailed_description": "A vector store implementation in Go that supports hybrid retrieval (BM25 + Vector), various indexing methods (HNSW, IVF, PQ), and metadata filtering. It provides a lightweight backend for vector-based memory in AI agents.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_storage",
        "hybrid_retrieval",
        "indexing"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/wizenheimer/comet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vector-store",
        "hnsw",
        "bm25",
        "hybrid-search"
      ],
      "id": 1182
    },
    {
      "name": "Tinkerbird",
      "one_line_profile": "Client-side vector database for lightweight retrieval",
      "detailed_description": "A client-side vector database designed for efficient vector storage and retrieval directly in the application environment. It enables local memory capabilities for AI agents without heavy server-side dependencies.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_storage",
        "local_retrieval"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/wizenheimer/tinkerbird",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vector-database",
        "client-side",
        "local-memory"
      ],
      "id": 1183
    },
    {
      "name": "LOPQ",
      "one_line_profile": "Locally Optimized Product Quantization for ANN search",
      "detailed_description": "A library for training Locally Optimized Product Quantization (LOPQ) models, used for approximate nearest neighbor (ANN) search in high-dimensional data. This is a foundational tool for building efficient vector indices for large-scale scientific data.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "dimensionality_reduction",
        "ann_search",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yahoo/lopq",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ann",
        "quantization",
        "vector-search",
        "high-dimensional-data"
      ],
      "id": 1184
    },
    {
      "name": "Medical-RAG",
      "one_line_profile": "Domain-specific RAG system for medical texts",
      "detailed_description": "A medical domain-specific RAG project utilizing LangChain and Milvus. It supports quick deployment and domain migration, enabling researchers to perform intelligent retrieval and QA on medical literature and data.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "rag",
        "medical_qa",
        "domain_specific_retrieval"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yolo-hyl/medical-rag",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-ai",
        "rag",
        "langchain",
        "milvus"
      ],
      "id": 1185
    },
    {
      "name": "Client-Vector-Search",
      "one_line_profile": "Browser/Node.js based vector search library",
      "detailed_description": "A library for performing vector embedding, storage, and search entirely on the client side (Browser/Node). It offers a lightweight alternative to server-side vector DBs for smaller-scale scientific data exploration and visualization tools.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "vector_search",
        "embedding",
        "client_side_processing"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/yusufhilmi/client-vector-search",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vector-search",
        "client-side",
        "embedding"
      ],
      "id": 1186
    },
    {
      "name": "VectorDBBench",
      "one_line_profile": "Benchmarking tool for performance evaluation of vector databases",
      "detailed_description": "A benchmarking tool designed to evaluate the performance of various vector databases (e.g., Milvus, Pinecone, Weaviate) under different scenarios. It helps researchers and developers select the appropriate vector storage infrastructure for scientific knowledge bases and high-dimensional data retrieval.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_evaluation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zilliztech/VectorDBBench",
      "help_website": [
        "https://vectordbbench.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "benchmark",
        "vector-database",
        "performance-testing"
      ],
      "id": 1187
    },
    {
      "name": "Deep Searcher",
      "one_line_profile": "Deep research agent for searching and reasoning over private data",
      "detailed_description": "An open-source deep research agent designed to perform complex information retrieval and reasoning tasks on private datasets. It combines vector search with LLM-based reasoning to synthesize answers from multiple documents, suitable for automated literature review and scientific knowledge discovery.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "information_retrieval",
        "automated_reasoning",
        "literature_review"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/zilliztech/deep-searcher",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deep-research",
        "rag",
        "agent"
      ],
      "id": 1188
    },
    {
      "name": "Feder",
      "one_line_profile": "Visualization tool for high-dimensional vector index structures",
      "detailed_description": "A visualization tool for understanding and debugging approximate nearest neighbor search (ANNS) indices like HNSW and FAISS. It helps researchers visualize the internal structure of vector indices and the search process, aiding in the interpretability of embedding-based retrieval systems.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "visualization",
        "index_analysis",
        "interpretability"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/zilliztech/feder",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "vector-index",
        "hnsw",
        "faiss"
      ],
      "id": 1189
    },
    {
      "name": "mcp-server-milvus",
      "one_line_profile": "Model Context Protocol (MCP) server for Milvus vector database",
      "detailed_description": "An implementation of the Model Context Protocol (MCP) for Milvus, enabling LLM agents to standardizedly access and query vector data stored in Milvus. This facilitates the integration of scientific knowledge bases into agentic workflows.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "tool_calling",
        "data_integration",
        "agent_interface"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/zilliztech/mcp-server-milvus",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mcp",
        "milvus",
        "agent-tool"
      ],
      "id": 1190
    },
    {
      "name": "Phantoscope",
      "one_line_profile": "Cloud-native search engine powered by neural networks for unstructured data",
      "detailed_description": "A high-level search engine platform that utilizes neural networks to index and search unstructured data (images, videos, text). It leverages vector databases for backend storage and is applicable to multimodal scientific data retrieval tasks.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "multimodal_search",
        "vector_retrieval"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/zilliztech/phantoscope",
      "help_website": [
        "https://phantoscope.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "search-engine",
        "neural-search",
        "multimodal"
      ],
      "id": 1191
    },
    {
      "name": "VTS",
      "one_line_profile": "Vector Transformation Service for unstructured data processing",
      "detailed_description": "A tool designed for the transformation and transportation of vectors and unstructured data. It serves as an ETL (Extract, Transform, Load) utility for vector databases, facilitating the preparation of scientific data for embedding-based search.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "data_transformation",
        "etl",
        "vector_processing"
      ],
      "application_level": "solver",
      "primary_language": "Java",
      "repo_url": "https://github.com/zilliztech/vts",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "etl",
        "vector-data",
        "data-pipeline"
      ],
      "id": 1192
    },
    {
      "name": "LightMem",
      "one_line_profile": "Lightweight memory-augmented generation framework for LLMs",
      "detailed_description": "A framework for efficient memory-augmented generation, enabling LLMs to maintain and retrieve context over long interactions. This is critical for scientific agents that need to retain knowledge across complex reasoning chains or extensive literature reviews.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "memory_augmented_generation",
        "context_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/LightMem",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-memory",
        "rag",
        "generation"
      ],
      "id": 1193
    },
    {
      "name": "Bosquet",
      "one_line_profile": "Clojure tooling for building LLM agents and memory systems",
      "detailed_description": "A functional programming toolkit for composing LLM applications, including prompt templating, agent orchestration, and memory management. It provides primitives for building complex scientific workflows involving LLMs.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "agent_orchestration",
        "prompt_composition",
        "memory_management"
      ],
      "application_level": "library",
      "primary_language": "Clojure",
      "repo_url": "https://github.com/zmedelis/bosquet",
      "help_website": [],
      "license": "EPL-1.0",
      "tags": [
        "clojure",
        "llm-agents",
        "prompt-engineering"
      ],
      "id": 1194
    },
    {
      "name": "SQLite Literature Management MCP Server",
      "one_line_profile": "Literature management system with MCP interface and Knowledge Graph integration",
      "detailed_description": "A system for managing scientific sources (papers, books, webpages) stored in SQLite, with capabilities to integrate them into knowledge graphs. It exposes an MCP (Model Context Protocol) interface, allowing AI agents to query and manipulate the literature database directly.",
      "domains": [
        "AI5",
        "AI5-07"
      ],
      "subtask_category": [
        "literature_management",
        "knowledge_graph_integration",
        "source_tracking"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/zongmin-yu/sqlite-literature-management-fastmcp-mcp-server",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "literature-management",
        "mcp",
        "knowledge-graph"
      ],
      "id": 1195
    },
    {
      "name": "jupyter_plz",
      "one_line_profile": "AI copilot extension for Jupyter notebooks to assist in scientific coding",
      "detailed_description": "A Jupyter notebook extension that integrates LLM capabilities directly into the notebook environment. It allows users to generate code, debug errors, and perform data manipulation tasks using natural language prompts via a magic command, streamlining the scientific computing workflow.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "code_generation",
        "notebook_assistance"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Akramz/jupyter_plz",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "jupyter",
        "copilot",
        "llm",
        "productivity"
      ],
      "id": 1196
    },
    {
      "name": "Chainlit",
      "one_line_profile": "Open-source Python framework for building conversational AI and agent interfaces",
      "detailed_description": "Chainlit is a Python framework designed to build scalable conversational AI applications. In the context of AI for Science, it serves as a critical infrastructure for creating human-in-the-loop interfaces for scientific agents, enabling visualization of reasoning steps (Chain of Thought), tool usage, and multi-modal data interaction (e.g., plotting, molecule rendering).",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "human_machine_interaction",
        "workflow_visualization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Chainlit/chainlit",
      "help_website": [
        "https://docs.chainlit.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ui",
        "agents",
        "visualization",
        "python"
      ],
      "id": 1197
    },
    {
      "name": "FfDL",
      "one_line_profile": "Fabric for Deep Learning - A Deep Learning Platform on Kubernetes",
      "detailed_description": "A deep learning platform offering TensorFlow, Caffe, PyTorch, and other frameworks as a service on Kubernetes, enabling scalable model training and orchestration for scientific research.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "model_training",
        "orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/IBM/FfDL",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deep-learning",
        "kubernetes",
        "platform",
        "training"
      ],
      "id": 1198
    },
    {
      "name": "JohnSnowLabs NLU",
      "one_line_profile": "Python library for state-of-the-art Natural Language Processing",
      "detailed_description": "A library providing easy access to thousands of state-of-the-art NLP models in multiple languages, facilitating text analysis, named entity recognition, and other linguistic tasks for research.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "text_analysis",
        "nlp"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/JohnSnowLabs/nlu",
      "help_website": [
        "https://nlu.johnsnowlabs.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "text-mining",
        "deep-learning",
        "spark-nlp"
      ],
      "id": 1199
    },
    {
      "name": "Multi-Modality-Arena",
      "one_line_profile": "Benchmarking platform for vision-language models",
      "detailed_description": "A benchmarking platform for evaluating vision-language models side-by-side, allowing researchers to compare model performance on multimodal inputs and scientific visual tasks.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "benchmarking",
        "model_evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/Multi-Modality-Arena",
      "help_website": [],
      "license": null,
      "tags": [
        "benchmarking",
        "vision-language-models",
        "evaluation"
      ],
      "id": 1200
    },
    {
      "name": "Calcpad",
      "one_line_profile": "Mathematical and engineering calculation software",
      "detailed_description": "Free and open source software for mathematical and engineering calculations that allows creating programmable calculation sheets with automatic report generation, suitable for scientific modeling and documentation.",
      "domains": [
        "Scientific Computing"
      ],
      "subtask_category": [
        "mathematical_modeling",
        "calculation"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/Proektsoftbg/Calcpad",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "engineering",
        "math",
        "calculation"
      ],
      "id": 1201
    },
    {
      "name": "DeepLiterature",
      "one_line_profile": "Intelligent research assistant for literature review and code execution",
      "detailed_description": "A fully open-source intelligent research assistant that integrates search, code execution, link resolution, and information expansion, with multiple tools working together to facilitate scientific research and literature review workflows.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "literature_review",
        "information_retrieval"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ScienceOne-AI/DeepLiterature",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "research-assistant",
        "literature-review",
        "agent"
      ],
      "id": 1202
    },
    {
      "name": "chat-gpt-jupyter-extension",
      "one_line_profile": "AI coding assistant extension for Jupyter Notebooks",
      "detailed_description": "A browser extension to provide various AI helper functions in Jupyter Notebooks, powered by ChatGPT. It acts as a copilot for researchers, assisting with code generation, debugging, and explanation within the scientific data analysis environment.",
      "domains": [
        "AI5-08"
      ],
      "subtask_category": [
        "code_assistance",
        "workflow_automation"
      ],
      "application_level": "workflow",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/TiesdeKok/chat-gpt-jupyter-extension",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "jupyter",
        "copilot",
        "chatgpt"
      ],
      "id": 1203
    },
    {
      "name": "AIAgents4Pharma",
      "one_line_profile": "AI Agents framework specifically designed for pharmaceutical R&D",
      "detailed_description": "A collection of AI agents and tools tailored for drug discovery and development processes. It leverages LLMs to assist in various stages of pharmaceutical research, providing a specialized workflow for this domain.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "scientific_modeling",
        "drug_discovery"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/VirtualPatientEngine/AIAgents4Pharma",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "drug-discovery",
        "pharma",
        "agents",
        "llm"
      ],
      "id": 1204
    },
    {
      "name": "thread",
      "one_line_profile": "AI-powered Jupyter Notebook environment for scientific coding",
      "detailed_description": "A standalone Jupyter Notebook interface enhanced with local AI capabilities. It allows users to generate, edit, and fix code cells using AI models, acting as a copilot specifically for data science and scientific computing workflows.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "scientific_data_analysis",
        "code_generation"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/alishobeiri/thread",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "jupyter",
        "notebook",
        "copilot",
        "data-science"
      ],
      "id": 1205
    },
    {
      "name": "MedGraph AI",
      "one_line_profile": "Healthcare RAG agent using Neo4j knowledge graphs for medical data querying",
      "detailed_description": "A healthcare-focused RAG agent that leverages Neo4j knowledge graphs to structure and query medical data. It integrates LangChain, FastAPI, and Streamlit to provide an interface for retrieving medical information and insights.",
      "domains": [
        "AI5",
        "AI5-08",
        "Medicine"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "medical_informatics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/asanmateu/medgraph-ai",
      "help_website": [],
      "license": null,
      "tags": [
        "healthcare",
        "rag",
        "knowledge-graph",
        "neo4j"
      ],
      "id": 1206
    },
    {
      "name": "Jupyter Copilot",
      "one_line_profile": "GitHub Copilot extension for JupyterLab environment",
      "detailed_description": "A browser extension that integrates GitHub Copilot into JupyterLab, assisting researchers and data scientists with code completion and generation directly within their scientific computing environment.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "code_generation",
        "interactive_coding"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/baolong281/jupyter-copilot",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "jupyterlab",
        "copilot",
        "coding-assistant"
      ],
      "id": 1207
    },
    {
      "name": "OpenInterpreterUI",
      "one_line_profile": "Graphical User Interface for Open Interpreter code execution",
      "detailed_description": "A Streamlit-based graphical interface for Open Interpreter, allowing users to execute Python and JavaScript code via natural language commands. It facilitates interactive data analysis and scripting without needing a command-line interface.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "code_execution",
        "data_analysis",
        "interactive_agent"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/blazzbyte/OpenInterpreterUI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gui",
        "open-interpreter",
        "streamlit"
      ],
      "id": 1208
    },
    {
      "name": "CAMEL Multi-Agent UI",
      "one_line_profile": "Streamlit UI for CAMEL multi-agent framework",
      "detailed_description": "A web-based user interface for the CAMEL framework, enabling users to configure and run multi-agent systems for task-driven simulations and dynamic environments. Useful for researching agent behaviors and automated problem solving.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "agent_simulation",
        "task_planning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/camel-ai/multi-agent-streamlit-ui",
      "help_website": [],
      "license": null,
      "tags": [
        "multi-agent",
        "camel",
        "streamlit"
      ],
      "id": 1209
    },
    {
      "name": "Feifei Deep Research",
      "one_line_profile": "Deep research agent adapted for Chinese developers",
      "detailed_description": "An adaptation of the open-deep-research tool, integrated with Chainlit to provide a convenient interface for conducting deep research tasks. It automates the process of gathering and synthesizing information from the web.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "literature_review",
        "information_gathering"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chenm1xuexi/feifei-deep-research",
      "help_website": [],
      "license": null,
      "tags": [
        "deep-research",
        "chainlit",
        "agent"
      ],
      "id": 1210
    },
    {
      "name": "Prettymapp",
      "one_line_profile": "Webapp to create maps from OpenStreetMap data",
      "detailed_description": "A Streamlit web application that allows users to create and customize maps using data from OpenStreetMap. It is useful for geospatial visualization and generating map figures for research.",
      "domains": [
        "AI5",
        "AI5-08",
        "Geospatial"
      ],
      "subtask_category": [
        "visualization",
        "mapping"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chrieke/prettymapp",
      "help_website": [
        "https://prettymapp.streamlit.app/"
      ],
      "license": "MIT",
      "tags": [
        "mapping",
        "openstreetmap",
        "visualization"
      ],
      "id": 1211
    },
    {
      "name": "Data Analysis LLM Agent",
      "one_line_profile": "LLM-powered agent for database querying and visualization",
      "detailed_description": "An AI agent designed to assist with data analysis tasks. It can query databases using natural language and visualize the results, streamlining the workflow from data retrieval to insight generation.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "data_analysis",
        "visualization",
        "sql_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/crazycloud/data-analysis-llm-agent",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-analysis",
        "llm-agent",
        "visualization"
      ],
      "id": 1212
    },
    {
      "name": "Natural Language to SQL",
      "one_line_profile": "Natural language interface for SQL databases",
      "detailed_description": "A tool that enables users to chat with their database by converting natural language queries into SQL. It uses LangChain and Streamlit to provide a friendly UI for interacting with BigQuery or MySQL databases, facilitating data retrieval for analysis.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "data_retrieval",
        "sql_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cremerf/natural_language_to_sql",
      "help_website": [],
      "license": null,
      "tags": [
        "nl2sql",
        "database",
        "langchain"
      ],
      "id": 1213
    },
    {
      "name": "Ragbase",
      "one_line_profile": "Local RAG tool for chatting with PDF documents",
      "detailed_description": "A completely local RAG (Retrieval-Augmented Generation) tool that allows users to chat with PDF documents. It utilizes LangChain, Streamlit, Ollama, and Qdrant to provide secure and private document analysis and information retrieval.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "knowledge_retrieval",
        "rag",
        "document_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/curiousily/ragbase",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "local-llm",
        "pdf-chat"
      ],
      "id": 1214
    },
    {
      "name": "LibreChat",
      "one_line_profile": "Advanced web interface for LLMs with support for Agents, Code Interpreter, and RAG",
      "detailed_description": "A comprehensive, open-source chat interface that serves as a platform for human-AI collaboration. It supports multiple model providers, plugins, and features a Code Interpreter and Agent capabilities, making it suitable for interactive scientific inference and data analysis workflows.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "interactive_inference",
        "code_execution",
        "agent_interface"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/danny-avila/LibreChat",
      "help_website": [
        "https://docs.librechat.ai/"
      ],
      "license": "MIT",
      "tags": [
        "chat-interface",
        "llm-ui",
        "agents",
        "code-interpreter"
      ],
      "id": 1215
    },
    {
      "name": "Jupyter AI Agents",
      "one_line_profile": "AI Agents extension for JupyterLab with MCP tool support",
      "detailed_description": "An extension for JupyterLab that integrates AI agents directly into the notebook environment. It utilizes the Model Context Protocol (MCP) to allow agents to interact with the notebook, execute code, and assist in scientific data analysis and workflow management.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "notebook_copilot",
        "code_generation",
        "interactive_analysis"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/datalayer/jupyter-ai-agents",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyterlab-extension",
        "ai-agents",
        "mcp",
        "notebooks"
      ],
      "id": 1216
    },
    {
      "name": "Jupyter MCP Server",
      "one_line_profile": "Model Context Protocol (MCP) Server implementation for Jupyter",
      "detailed_description": "A server implementation that exposes Jupyter's capabilities (kernel execution, file access) via the Model Context Protocol (MCP). This infrastructure enables external AI agents and LLMs to interface with Jupyter notebooks to perform scientific computation and data processing.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "tool_invocation",
        "interoperability",
        "remote_execution"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/datalayer/jupyter-mcp-server",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "mcp",
        "jupyter",
        "interoperability",
        "agent-tool"
      ],
      "id": 1217
    },
    {
      "name": "Deepnote",
      "one_line_profile": "AI-first collaborative data science notebook platform",
      "detailed_description": "A modern data science platform that replaces standard Jupyter notebooks with a collaborative, AI-enhanced interface. It features built-in AI agents for code generation and analysis, real-time collaboration, and native data integrations, specifically designed for scientific and data workflows.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "collaborative_analysis",
        "notebook_environment",
        "ai_assistance"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/deepnote/deepnote",
      "help_website": [
        "https://deepnote.com/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "notebook",
        "data-science",
        "collaboration",
        "ide"
      ],
      "id": 1218
    },
    {
      "name": "Deep Research",
      "one_line_profile": "AI-powered agent for iterative deep research and literature review",
      "detailed_description": "An autonomous agent designed to perform deep, iterative research on a given topic. It combines search engines, web scraping, and LLMs to refine research directions and synthesize information, automating the literature review and information gathering phase of scientific research.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "literature_review",
        "information_retrieval",
        "research_automation"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/dzhng/deep-research",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "research-agent",
        "literature-review",
        "autonomous-agent"
      ],
      "id": 1219
    },
    {
      "name": "Elyra",
      "one_line_profile": "Visual pipeline editor and workflow orchestration for JupyterLab",
      "detailed_description": "An extension for JupyterLab that provides a visual editor for building and running data science pipelines. It enables researchers to orchestrate complex workflows involving notebooks, scripts, and data processing steps without leaving the Jupyter environment.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "pipeline_orchestration",
        "workflow_design",
        "reproducibility"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/elyra-ai/elyra",
      "help_website": [
        "https://elyra.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "jupyterlab",
        "workflow",
        "pipeline",
        "visual-editor"
      ],
      "id": 1220
    },
    {
      "name": "spaCy-Streamlit",
      "one_line_profile": "Visualization building blocks for spaCy NLP models in Streamlit",
      "detailed_description": "A Python library providing Streamlit components for visualizing spaCy NLP model outputs, such as named entities, dependency parses, and text classification results. It facilitates the creation of interactive tools for linguistic analysis and NLP model inspection.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "nlp_visualization",
        "linguistic_analysis",
        "model_inspection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/explosion/spacy-streamlit",
      "help_website": [
        "https://spacy.io/usage/visualizers"
      ],
      "license": "MIT",
      "tags": [
        "nlp",
        "visualization",
        "streamlit",
        "spacy"
      ],
      "id": 1221
    },
    {
      "name": "Otto-m8",
      "one_line_profile": "Visual flowchart UI for interconnecting LLMs and deploying workflows",
      "detailed_description": "A low-code tool providing a flowchart-like user interface to connect Large Language Models (LLMs) and HuggingFace models. It allows researchers to visually design and deploy AI workflows as REST APIs, facilitating rapid prototyping of complex inference pipelines.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "visual_programming",
        "model_chaining"
      ],
      "application_level": "workflow",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/farhan0167/otto-m8",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "workflow",
        "visual-programming",
        "llm-orchestration"
      ],
      "id": 1222
    },
    {
      "name": "Open Deep Research",
      "one_line_profile": "Open-source AI agent for deep research and synthesis",
      "detailed_description": "An open-source alternative to proprietary deep research tools. It functions as an agent that performs comprehensive research on topics by querying multiple sources and synthesizing findings, aiding in the literature review process.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "literature_review",
        "research_automation",
        "synthesis"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/fdarkaou/open-deep-research",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "research-agent",
        "open-source",
        "literature-review"
      ],
      "id": 1223
    },
    {
      "name": "RAGxplorer",
      "one_line_profile": "Visualization tool for RAG (Retrieval Augmented Generation) systems",
      "detailed_description": "An open-source tool designed to visualize the retrieval process in RAG systems. It helps researchers understand document chunking, embedding spaces, and retrieval relevance, which is essential for debugging and optimizing AI-driven scientific knowledge bases.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "rag_visualization",
        "embedding_analysis",
        "model_debugging"
      ],
      "application_level": "tool",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/gabrielchua/RAGxplorer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rag",
        "visualization",
        "embeddings",
        "debug"
      ],
      "id": 1224
    },
    {
      "name": "geemap",
      "one_line_profile": "Interactive geospatial analysis and visualization with Google Earth Engine",
      "detailed_description": "A Python package for interactive mapping and geospatial analysis with Google Earth Engine (GEE). It enables scientists to visualize and analyze satellite imagery and geospatial datasets within Jupyter notebooks.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "geospatial_analysis",
        "map_visualization",
        "remote_sensing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gee-community/geemap",
      "help_website": [
        "https://geemap.org/"
      ],
      "license": "MIT",
      "tags": [
        "geospatial",
        "earth-engine",
        "mapping",
        "gis"
      ],
      "id": 1225
    },
    {
      "name": "Jupyter AI",
      "one_line_profile": "Generative AI extension for JupyterLab to assist in scientific coding and data analysis",
      "detailed_description": "A JupyterLab extension that brings generative AI to the notebook environment. It enables users to generate code, explain errors, summarize content, and interact with their data using natural language, acting as a copilot for scientific computing and data science workflows.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "code_generation",
        "notebook_summarization",
        "error_explanation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/jupyterlab/jupyter-ai",
      "help_website": [
        "https://jupyter-ai.readthedocs.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyter",
        "llm",
        "copilot",
        "generative-ai",
        "notebooks"
      ],
      "id": 1226
    },
    {
      "name": "Generative Manim",
      "one_line_profile": "GPT-based code generator for Manim mathematical animations",
      "detailed_description": "A tool that leverages GPT models to automatically generate Python code for Manim (Mathematical Animation Engine), facilitating the creation of scientific and mathematical visualizations.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "scientific_visualization",
        "code_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/marcelo-earth/generative-manim",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "manim",
        "visualization",
        "math",
        "gpt"
      ],
      "id": 1227
    },
    {
      "name": "PID-agent",
      "one_line_profile": "LLM-based platform for PID controller parameter tuning",
      "detailed_description": "An agentic platform integrating LangChain and LLMs to assist in the tuning of PID (Proportional-Integral-Derivative) controller parameters, relevant for control engineering and laboratory automation tasks.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "parameter_optimization",
        "process_control"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mcp2everything/PID-agent",
      "help_website": [],
      "license": null,
      "tags": [
        "pid-tuning",
        "control-theory",
        "agent",
        "automation"
      ],
      "id": 1228
    },
    {
      "name": "CoML",
      "one_line_profile": "Interactive coding assistant for data scientists",
      "detailed_description": "A research prototype by Microsoft designed to assist data scientists and machine learning developers with code generation and data analysis tasks through an interactive natural language interface.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "code_generation",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/CoML",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-science",
        "coding-assistant",
        "interactive-agent"
      ],
      "id": 1229
    },
    {
      "name": "Responsible AI Toolbox",
      "one_line_profile": "Suite of tools for assessing and debugging AI models and data",
      "detailed_description": "A collection of user interfaces and libraries enabling model and data exploration, error analysis, fairness assessment, and interpretability, which are critical for scientific model validation and analysis.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "model_evaluation",
        "error_analysis",
        "interpretability"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/microsoft/responsible-ai-toolbox",
      "help_website": [
        "https://responsibleaitoolbox.ai/"
      ],
      "license": "MIT",
      "tags": [
        "responsible-ai",
        "model-debugging",
        "visualization"
      ],
      "id": 1230
    },
    {
      "name": "Responsible AI Toolbox Tracker",
      "one_line_profile": "JupyterLab extension for tracking Responsible AI experiments",
      "detailed_description": "A JupyterLab extension that facilitates the tracking, management, and comparison of Responsible AI mitigations and experiments within the data science workflow.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "experiment_tracking",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/microsoft/responsible-ai-toolbox-tracker",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "jupyter-extension",
        "experiment-tracking"
      ],
      "id": 1231
    },
    {
      "name": "TensorWatch",
      "one_line_profile": "Debugging and visualization tool for Data Science and ML",
      "detailed_description": "A tool for debugging, monitoring, and visualizing machine learning models and data streams in Python, designed to support data science workflows and real-time analysis.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "scientific_visualization",
        "monitoring",
        "debugging"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/microsoft/tensorwatch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "debugging",
        "data-science"
      ],
      "id": 1232
    },
    {
      "name": "Mito",
      "one_line_profile": "Spreadsheet and AI coding assistant for Jupyter",
      "detailed_description": "A Jupyter extension that provides a spreadsheet interface and context-aware AI chat to generate Python code for data analysis, streamlining the scientific data processing workflow.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "data_processing",
        "code_generation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mito-ds/mito",
      "help_website": [
        "https://docs.trymito.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "jupyter-extension",
        "spreadsheet",
        "low-code",
        "data-science"
      ],
      "id": 1233
    },
    {
      "name": "PlotAI",
      "one_line_profile": "AI assistant for creating Matplotlib plots",
      "detailed_description": "A tool that utilizes LLMs (ChatGPT) to generate Python and Matplotlib code for data visualization directly within scripts or notebooks, assisting in scientific plotting tasks.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "scientific_visualization",
        "code_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mljar/plotai",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "matplotlib",
        "visualization",
        "llm-assistant"
      ],
      "id": 1234
    },
    {
      "name": "cad3dify",
      "one_line_profile": "2D to 3D CAD conversion tool using Vision Language Models",
      "detailed_description": "A tool that leverages Vision Language Models (VLMs) to convert 2D CAD drawings into 3D CAD models, facilitating engineering design and modeling workflows.",
      "domains": [
        "AI5",
        "Engineering"
      ],
      "subtask_category": [
        "3d_reconstruction",
        "cad_conversion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/neka-nat/cad3dify",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cad",
        "3d-reconstruction",
        "vlm",
        "engineering-design"
      ],
      "id": 1235
    },
    {
      "name": "GeoAI",
      "one_line_profile": "Artificial Intelligence toolkit for geospatial data analysis",
      "detailed_description": "A Python package designed for applying artificial intelligence and machine learning techniques to geospatial data, supporting tasks like image segmentation and object detection in satellite imagery.",
      "domains": [
        "AI5",
        "Earth Science"
      ],
      "subtask_category": [
        "geospatial_analysis",
        "remote_sensing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/opengeos/geoai",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "geospatial",
        "remote-sensing",
        "deep-learning",
        "gis"
      ],
      "id": 1236
    },
    {
      "name": "leafmap",
      "one_line_profile": "Interactive mapping and geospatial analysis library",
      "detailed_description": "A Python package for interactive mapping and geospatial analysis with minimal coding in a Jupyter environment, enabling visualization and processing of Earth science data.",
      "domains": [
        "AI5",
        "Earth Science"
      ],
      "subtask_category": [
        "geospatial_visualization",
        "mapping"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/opengeos/leafmap",
      "help_website": [
        "https://leafmap.org"
      ],
      "license": "MIT",
      "tags": [
        "mapping",
        "gis",
        "geospatial",
        "visualization"
      ],
      "id": 1237
    },
    {
      "name": "streamlit-geospatial",
      "one_line_profile": "Web application for geospatial data analysis and visualization",
      "detailed_description": "A multi-page Streamlit application that provides a user interface for various geospatial analysis tasks, making geospatial tools accessible without extensive coding.",
      "domains": [
        "AI5",
        "Earth Science"
      ],
      "subtask_category": [
        "geospatial_analysis",
        "visualization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/opengeos/streamlit-geospatial",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "streamlit",
        "geospatial",
        "web-app",
        "gis"
      ],
      "id": 1238
    },
    {
      "name": "Notebook Copilot",
      "one_line_profile": "AI-powered CLI tool for generating Jupyter Notebooks from natural language",
      "detailed_description": "A command-line interface tool that leverages Large Language Models to generate fully functional Jupyter Notebooks based on user descriptions. It streamlines the workflow for data scientists and researchers by automating the initial setup and coding of analysis notebooks.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "code_generation",
        "data_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/talperetz/notebook-copilot",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "jupyter",
        "copilot",
        "generative-ai",
        "cli"
      ],
      "id": 1239
    },
    {
      "name": "Vanna Chainlit",
      "one_line_profile": "Conversational UI for Vanna text-to-SQL framework",
      "detailed_description": "The official Chainlit-based user interface for Vanna, enabling researchers and data scientists to interact with SQL databases using natural language. It facilitates data extraction and analysis by converting questions into SQL queries within a chat interface.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "data_analysis",
        "sql_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/vanna-ai/vanna-chainlit",
      "help_website": [
        "https://vanna.ai/"
      ],
      "license": null,
      "tags": [
        "text-to-sql",
        "database",
        "chat-interface",
        "data-analysis"
      ],
      "id": 1240
    },
    {
      "name": "AutoGen UI",
      "one_line_profile": "Web user interface for AutoGen multi-agent framework",
      "detailed_description": "A graphical user interface for the AutoGen framework, allowing users to define, manage, and observe multi-agent workflows. It supports the orchestration of AI agents for complex problem-solving tasks, including research and data analysis scenarios.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "agent_management"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/victordibia/autogen-ui",
      "help_website": [
        "https://microsoft.github.io/autogen/"
      ],
      "license": "MIT",
      "tags": [
        "multi-agent",
        "workflow",
        "ui",
        "autogen"
      ],
      "id": 1241
    },
    {
      "name": "Libro",
      "one_line_profile": "Flexible and customizable notebook environment for data science",
      "detailed_description": "A notebook environment designed to offer enhanced customization and integration capabilities compared to standard Jupyter interfaces. It serves as a platform for scientific data analysis, coding, and interactive research workflows.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "data_analysis",
        "scientific_coding"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/weavefox/libro",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "notebook",
        "jupyter",
        "data-science",
        "ide"
      ],
      "id": 1242
    },
    {
      "name": "Mahilo",
      "one_line_profile": "A human-in-the-loop multi-agent orchestration framework",
      "detailed_description": "Mahilo is a framework designed for creating multi-agent systems that incorporate human interaction (HITL). It enables agents to share context and collaborate with humans to solve complex tasks, fitting the scientific agent workflow paradigm.",
      "domains": [
        "AI5",
        "AI5-08"
      ],
      "subtask_category": [
        "agent_orchestration",
        "human_agent_collaboration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wjayesh/mahilo",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "multi-agent",
        "human-in-the-loop",
        "agent-framework"
      ],
      "id": 1243
    },
    {
      "name": "MASSW",
      "one_line_profile": "Dataset for Multi-Aspect Summarization of Scientific Workflows",
      "detailed_description": "MASSW is a comprehensive text dataset specifically designed for the analysis and summarization of scientific workflows. It includes over 152,000 peer-reviewed publications from computer science conferences, serving as a resource for researching scientific process automation and documentation.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "scientific_workflow_analysis",
        "text_summarization"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/xingjian-zhang/massw",
      "help_website": [],
      "license": "CC0-1.0",
      "tags": [
        "dataset",
        "scientific-workflow",
        "nlp"
      ],
      "id": 1244
    },
    {
      "name": "Code Atlas",
      "one_line_profile": "C++ implementation of Open Interpreter for agentic code execution",
      "detailed_description": "Code Atlas is a C++ implementation of the Open Interpreter protocol. It serves as a local execution engine enabling AI agents to write and run code to perform data analysis and system tasks, a key component in agentic scientific workflows.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "code_execution",
        "agent_tooling"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ystemsrx/code-atlas",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "open-interpreter",
        "agent",
        "code-execution"
      ],
      "id": 1245
    },
    {
      "name": "LLaMA-LoRA-Tuner",
      "one_line_profile": "UI tool for fine-tuning LLaMA-based models using LoRA",
      "detailed_description": "A graphical interface and toolkit for fine-tuning Large Language Models (LLMs) using Low-Rank Adaptation (LoRA). It facilitates the adaptation of general models to specific domains (including scientific domains) through an accessible workflow.",
      "domains": [
        "AI5"
      ],
      "subtask_category": [
        "model_finetuning",
        "model_adaptation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/zetavg/LLaMA-LoRA-Tuner",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "lora",
        "fine-tuning"
      ],
      "id": 1246
    }
  ]
}