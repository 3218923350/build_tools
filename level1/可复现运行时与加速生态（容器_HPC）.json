{
  "leaf_cluster_name": "可复现运行时与加速生态（容器/HPC）",
  "domain": "Infra/HPC",
  "typical_objects": "jobs/artifacts",
  "task_chain": "环境→调度→缓存→追踪→加速",
  "tool_form": "容器/调度 + 追踪/成本",
  "total_tools": 1168,
  "tools": [
    {
      "name": "omnipkg",
      "one_line_profile": "Python package and interpreter version manager wrapper for conda-forge",
      "detailed_description": "A tool that simplifies the management of Python environments and packages using conda-forge, allowing for conflict-free installation of infinite package and interpreter versions.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "dependency_resolution"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/1minds3t/omnipkg",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "conda",
        "python",
        "package-management"
      ],
      "id": 1
    },
    {
      "name": "distrobox",
      "one_line_profile": "Container wrapper to run any Linux distribution inside the terminal",
      "detailed_description": "A tool that uses Podman or Docker to create containers using the Linux distribution of choice, enabling reproducible environments and backward/forward compatibility for scientific software on HPC or personal workstations.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "containerization"
      ],
      "application_level": "tool",
      "primary_language": "Shell",
      "repo_url": "https://github.com/89luca89/distrobox",
      "help_website": [
        "https://distrobox.it"
      ],
      "license": "GPL-3.0",
      "tags": [
        "linux",
        "container",
        "podman",
        "docker",
        "hpc"
      ],
      "id": 2
    },
    {
      "name": "lilipod",
      "one_line_profile": "Simple container manager for OCI images",
      "detailed_description": "A lightweight container manager capable of downloading, unpacking, and using OCI images, serving as a minimal runtime for containerized scientific workflows.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_management",
        "runtime"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/89luca89/lilipod",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "container",
        "oci",
        "sandbox"
      ],
      "id": 3
    },
    {
      "name": "ACCESS-OM2",
      "one_line_profile": "Global coupled ocean-sea ice model",
      "detailed_description": "The ACCESS Ocean-Sea Ice Model (ACCESS-OM2), a global coupled model used for climate research and oceanography simulations.",
      "domains": [
        "AI4S",
        "Earth Science"
      ],
      "subtask_category": [
        "simulation",
        "climate_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/ACCESS-NRI/ACCESS-OM2",
      "help_website": [
        "https://access-om2.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "oceanography",
        "climate-model",
        "simulation"
      ],
      "id": 4
    },
    {
      "name": "mSSA",
      "one_line_profile": "Multivariate Singular Spectrum Analysis for time series",
      "detailed_description": "An implementation of Multivariate Singular Spectrum Analysis (mSSA) for forecasting and imputation of multivariate time series data.",
      "domains": [
        "AI4S",
        "Data Analysis"
      ],
      "subtask_category": [
        "time_series_analysis",
        "forecasting",
        "imputation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/AbdullahO/mSSA",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "time-series",
        "forecasting",
        "statistics"
      ],
      "id": 5
    },
    {
      "name": "Covalent",
      "one_line_profile": "Workflow orchestration tool for HPC and quantum computing",
      "detailed_description": "A Pythonic tool for orchestrating machine learning, high-performance computing (HPC), and quantum computing workflows across heterogeneous compute environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "distributed_computing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/AgnostiqHQ/covalent",
      "help_website": [
        "https://covalent.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow",
        "hpc",
        "quantum-computing",
        "orchestration"
      ],
      "id": 6
    },
    {
      "name": "Batch Shipyard",
      "one_line_profile": "HPC and Batch workload management on Azure",
      "detailed_description": "A tool to simplify deploying and managing High Performance Computing (HPC) and Batch workloads on Azure, supporting Docker and Singularity containers.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "job_scheduling",
        "cloud_hpc"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Azure/batch-shipyard",
      "help_website": [
        "https://batch-shipyard.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "azure",
        "hpc",
        "batch-processing",
        "docker"
      ],
      "id": 7
    },
    {
      "name": "cyclecloud-singularity",
      "one_line_profile": "Singularity container support for Azure CycleCloud",
      "detailed_description": "A project enabling the use of Singularity containers within HPC clusters managed by Azure CycleCloud, facilitating reproducible scientific workflows in the cloud.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "cloud_hpc"
      ],
      "application_level": "tool",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/Azure/cyclecloud-singularity",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "azure",
        "singularity",
        "hpc"
      ],
      "id": 8
    },
    {
      "name": "HPK",
      "one_line_profile": "Kubernetes to Slurm/Singularity translator for HPC",
      "detailed_description": "A tool that allows running Kubernetes applications within HPC environments by translating deployments to Slurm jobs and Singularity/Apptainer containers.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "workload_management",
        "container_orchestration"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/CARV-ICS-FORTH/HPK",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "slurm",
        "hpc",
        "singularity"
      ],
      "id": 9
    },
    {
      "name": "KNoC",
      "one_line_profile": "Kubernetes Virtual Kubelet for HPC clusters",
      "detailed_description": "A Kubernetes Virtual Kubelet implementation that uses an HPC cluster as the container execution environment, bridging cloud-native and HPC workflows.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "workload_management",
        "resource_scheduling"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/CARV-ICS-FORTH/knoc",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "hpc",
        "virtual-kubelet"
      ],
      "id": 10
    },
    {
      "name": "hpc-container-wrapper",
      "one_line_profile": "Wrapper for HPC container installations",
      "detailed_description": "A tool designed to wrap software installations into containers specifically for use on HPC systems, simplifying deployment and execution.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "containerization",
        "deployment"
      ],
      "application_level": "tool",
      "primary_language": "Shell",
      "repo_url": "https://github.com/CSCfi/hpc-container-wrapper",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hpc",
        "container",
        "wrapper"
      ],
      "id": 11
    },
    {
      "name": "jupyter_environment_kernels",
      "one_line_profile": "Jupyter plugin for Conda/Virtualenv kernel detection",
      "detailed_description": "A Jupyter plugin that enables automatic detection and management of Conda and virtualenv environments as kernels, facilitating reproducible scientific computing in notebooks.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "interactive_computing"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/Cadair/jupyter_environment_kernels",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "jupyter",
        "conda",
        "virtualenv",
        "python"
      ],
      "id": 12
    },
    {
      "name": "VR-Caps",
      "one_line_profile": "Virtual environment for capsule endoscopy simulation",
      "detailed_description": "A virtual reality environment for simulating active capsule endoscopy, used for training and testing control algorithms and medical analysis.",
      "domains": [
        "AI4S",
        "Medical Physics"
      ],
      "subtask_category": [
        "simulation",
        "medical_imaging"
      ],
      "application_level": "platform",
      "primary_language": "C#",
      "repo_url": "https://github.com/CapsuleEndoscope/VirtualCapsuleEndoscopy",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "simulation",
        "medical",
        "virtual-reality",
        "endoscopy"
      ],
      "id": 13
    },
    {
      "name": "ChangeMamba",
      "one_line_profile": "Remote sensing change detection model",
      "detailed_description": "A Spatio-Temporal State Space Model (Mamba) based approach for change detection in remote sensing imagery.",
      "domains": [
        "AI4S",
        "Remote Sensing"
      ],
      "subtask_category": [
        "image_analysis",
        "change_detection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChenHongruixuan/ChangeMamba",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "remote-sensing",
        "deep-learning",
        "mamba",
        "change-detection"
      ],
      "id": 14
    },
    {
      "name": "ZigMa",
      "one_line_profile": "Mamba-based diffusion model",
      "detailed_description": "Implementation of 'ZigMa: A DiT-Style Mamba-based Diffusion Model', a generative model architecture for scientific or general image synthesis.",
      "domains": [
        "AI4S",
        "Deep Learning"
      ],
      "subtask_category": [
        "generative_modeling",
        "image_synthesis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/CompVis/zigma",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-model",
        "mamba",
        "deep-learning"
      ],
      "id": 15
    },
    {
      "name": "COVIDStrategyCalculator",
      "one_line_profile": "Epidemiological strategy assessment tool",
      "detailed_description": "A standalone software tool to assess testing and quarantine strategies for COVID-19 management, supporting contact tracing and isolation logic.",
      "domains": [
        "AI4S",
        "Epidemiology"
      ],
      "subtask_category": [
        "simulation",
        "policy_analysis"
      ],
      "application_level": "tool",
      "primary_language": "C++",
      "repo_url": "https://github.com/CovidStrategyCalculator/COVIDStrategyCalculator",
      "help_website": [
        "https://covidstrategycalculator.github.io/"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "epidemiology",
        "simulation",
        "covid-19"
      ],
      "id": 16
    },
    {
      "name": "mach-nix",
      "one_line_profile": "Tool to create highly reproducible Python environments using Nix",
      "detailed_description": "A tool that simplifies the creation of reproducible Python environments by leveraging the Nix package manager, solving complex dependency management issues in scientific computing.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "reproducibility"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DavHau/mach-nix",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "python",
        "nix",
        "reproducibility",
        "environment-manager"
      ],
      "id": 17
    },
    {
      "name": "cotainr",
      "one_line_profile": "User-space Apptainer/Singularity container builder for HPC",
      "detailed_description": "A tool designed for High Performance Computing (HPC) users to build Apptainer/Singularity containers in user space without requiring privileged access.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_build",
        "hpc_deployment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/DeiC-HPC/cotainr",
      "help_website": [],
      "license": "EUPL-1.2",
      "tags": [
        "hpc",
        "apptainer",
        "singularity",
        "container-builder"
      ],
      "id": 18
    },
    {
      "name": "e4s-alc",
      "one_line_profile": "Tool for customizing E4S container images",
      "detailed_description": "E4S à la carte (e4s-alc) is a tool that enables users to customize container images by adding system packages and Spack packages, facilitating the creation of tailored HPC environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_customization",
        "image_generation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/E4S-Project/e4s-alc",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hpc",
        "e4s",
        "container",
        "spack"
      ],
      "id": 19
    },
    {
      "name": "e4s-cl",
      "one_line_profile": "Container launcher and manager for E4S HPC applications",
      "detailed_description": "A tool designed to simplify the launch of MPI applications inside containers on HPC systems, handling library injection and inter-node communication transparently.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "job_launching",
        "mpi_runtime"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/E4S-Project/e4s-cl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hpc",
        "mpi",
        "container-runtime",
        "e4s"
      ],
      "id": 20
    },
    {
      "name": "LvArray",
      "one_line_profile": "C++ template library for portable HPC array data structures",
      "detailed_description": "A C++ library providing performance-portable array data structures and utilities designed for scientific simulations on HPC architectures (developed by GEOS-DEV).",
      "domains": [
        "AI6",
        "HPC"
      ],
      "subtask_category": [
        "data_structure",
        "scientific_computing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/GEOS-DEV/LvArray",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "c++",
        "array-manipulation",
        "scientific-simulation"
      ],
      "id": 21
    },
    {
      "name": "nd-Mamba2-torch",
      "one_line_profile": "N-dimensional Mamba2 implementation in PyTorch",
      "detailed_description": "A PyTorch library implementing the Mamba2 state space model with support for multi-dimensional data (1D/2D/3D), enabling the application of SSMs to scientific modeling tasks like vision or volumetric analysis.",
      "domains": [
        "AI-Model",
        "Scientific-Modeling"
      ],
      "subtask_category": [
        "modeling",
        "deep_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Human9000/nd-Mamba2-torch",
      "help_website": [],
      "license": null,
      "tags": [
        "pytorch",
        "mamba",
        "state-space-models",
        "scientific-ml"
      ],
      "id": 22
    },
    {
      "name": "kube-mpi",
      "one_line_profile": "MPI operator and runtime for HPC workloads on Kubernetes",
      "detailed_description": "A prototype enabling High Performance Computing (HPC) developers to deploy stateful MPI-based applications (simulation, distributed deep learning) on container orchestration platforms like Kubernetes.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "hpc_scheduling",
        "distributed_computing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/IBM/kube-mpi",
      "help_website": [],
      "license": null,
      "tags": [
        "mpi",
        "kubernetes",
        "hpc",
        "distributed-training"
      ],
      "id": 23
    },
    {
      "name": "VM-UNet",
      "one_line_profile": "Vision Mamba UNet model for medical image segmentation",
      "detailed_description": "Implementation of VM-UNet, a medical image segmentation model integrating Vision Mamba blocks into a UNet architecture to capture long-range dependencies.",
      "domains": [
        "AI4-01",
        "AI4"
      ],
      "subtask_category": [
        "medical_image_segmentation",
        "image_segmentation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JCruan519/VM-UNet",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-imaging",
        "segmentation",
        "mamba",
        "deep-learning"
      ],
      "id": 24
    },
    {
      "name": "Computer-Generated-Hologram",
      "one_line_profile": "Simulation framework for computer-generated holography",
      "detailed_description": "A framework for calculating and simulating computer-generated holograms (CGH), supporting recording and reproduction processes using MATLAB and Python.",
      "domains": [
        "AI6",
        "AI4-05"
      ],
      "subtask_category": [
        "holography_simulation",
        "optical_simulation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/JackHCC/Computer-Generated-Hologram",
      "help_website": [],
      "license": null,
      "tags": [
        "holography",
        "optics",
        "simulation",
        "matlab"
      ],
      "id": 25
    },
    {
      "name": "maru",
      "one_line_profile": "CLI for containerizing scientific applications",
      "detailed_description": "An opinionated command-line interface designed to simplify the process of containerizing scientific applications for reproducibility and deployment.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "containerization",
        "reproducibility"
      ],
      "application_level": "workflow",
      "primary_language": "Go",
      "repo_url": "https://github.com/JaneliaSciComp/maru",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "containers",
        "science",
        "reproducibility",
        "cli"
      ],
      "id": 26
    },
    {
      "name": "Swin-UMamba",
      "one_line_profile": "Mamba-based UNet model for biomedical image analysis",
      "detailed_description": "A deep learning model combining Swin Transformer and Mamba architectures for medical image segmentation tasks, with ImageNet-based pretraining.",
      "domains": [
        "AI4-01",
        "AI4"
      ],
      "subtask_category": [
        "medical_image_segmentation",
        "biomedical_imaging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/JiarunLiu/Swin-UMamba",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-imaging",
        "mamba",
        "swin-transformer",
        "segmentation"
      ],
      "id": 27
    },
    {
      "name": "IterativeSolvers.jl",
      "one_line_profile": "Iterative algorithms for solving linear systems in Julia",
      "detailed_description": "A Julia library providing iterative algorithms for solving linear systems, eigensystems, and singular value problems, essential for scientific computing.",
      "domains": [
        "AI1",
        "AI6"
      ],
      "subtask_category": [
        "linear_algebra",
        "numerical_methods"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaLinearAlgebra/IterativeSolvers.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "linear-algebra",
        "iterative-solvers",
        "math"
      ],
      "id": 28
    },
    {
      "name": "Conda.jl",
      "one_line_profile": "Conda environment manager integration for Julia",
      "detailed_description": "A Julia package that allows managing binary dependencies using Conda, facilitating the integration of Python-based scientific tools within the Julia ecosystem.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "package_management",
        "environment_management"
      ],
      "application_level": "workflow",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaPy/Conda.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "julia",
        "conda",
        "package-manager",
        "dependencies"
      ],
      "id": 29
    },
    {
      "name": "KrylovKit.jl",
      "one_line_profile": "Krylov methods for linear problems and matrix functions",
      "detailed_description": "A Julia library implementing Krylov subspace methods for solving linear problems, eigenvalues, singular values, and matrix functions in scientific computing.",
      "domains": [
        "AI1",
        "AI6"
      ],
      "subtask_category": [
        "linear_algebra",
        "numerical_methods"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/Jutho/KrylovKit.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "julia",
        "krylov-methods",
        "linear-algebra",
        "eigenvalues"
      ],
      "id": 30
    },
    {
      "name": "SCALE-MAMBA",
      "one_line_profile": "Framework for Secure Multi-Party Computation (MPC)",
      "detailed_description": "A research system for Secure Multi-Party Computation, enabling privacy-preserving computation on data, often used in secure scientific data analysis.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "secure_computation",
        "cryptography"
      ],
      "application_level": "platform",
      "primary_language": "Verilog",
      "repo_url": "https://github.com/KULeuven-COSIC/SCALE-MAMBA",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "mpc",
        "cryptography",
        "privacy",
        "secure-computation"
      ],
      "id": 31
    },
    {
      "name": "pytorch-aarch64",
      "one_line_profile": "PyTorch binaries for ARM64/AArch64 architectures",
      "detailed_description": "A repository providing PyTorch wheels and Conda packages for ARMv8/AArch64, enabling AI/ML workloads on Edge devices and ARM-based HPC systems.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "runtime_environment",
        "infrastructure"
      ],
      "application_level": "service",
      "primary_language": "HTML",
      "repo_url": "https://github.com/KumaTea/pytorch-aarch64",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "arm64",
        "aarch64",
        "wheels"
      ],
      "id": 32
    },
    {
      "name": "uberenv",
      "one_line_profile": "Automated Spack package deployment for HPC",
      "detailed_description": "A tool developed by LLNL to automate the use of Spack for building and deploying complex scientific software stacks and dependencies.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "package_management",
        "deployment"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/LLNL/uberenv",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "spack",
        "hpc",
        "deployment",
        "automation"
      ],
      "id": 33
    },
    {
      "name": "PointMamba",
      "one_line_profile": "State Space Model for 3D point cloud analysis",
      "detailed_description": "A deep learning framework applying State Space Models (Mamba) to 3D point cloud analysis, applicable in geospatial and structural scientific data processing.",
      "domains": [
        "AI4-01",
        "AI4"
      ],
      "subtask_category": [
        "point_cloud_analysis",
        "3d_vision"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/LMD0311/PointMamba",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "point-cloud",
        "mamba",
        "3d-analysis",
        "deep-learning"
      ],
      "id": 34
    },
    {
      "name": "PSCondaEnvs",
      "one_line_profile": "PowerShell scripts for Conda environment management",
      "detailed_description": "A set of scripts enabling native Conda environment activation and deactivation within PowerShell, facilitating scientific workflows on Windows.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "shell_integration"
      ],
      "application_level": "workflow",
      "primary_language": "PowerShell",
      "repo_url": "https://github.com/Liquidmantis/PSCondaEnvs",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "conda",
        "powershell",
        "windows",
        "environment-manager"
      ],
      "id": 35
    },
    {
      "name": "sumo-rl",
      "one_line_profile": "Reinforcement Learning environments for traffic simulation",
      "detailed_description": "A library providing Reinforcement Learning environments for traffic signal control using the SUMO simulator, supporting scientific research in transportation systems.",
      "domains": [
        "AI6",
        "AI4-06"
      ],
      "subtask_category": [
        "traffic_simulation",
        "reinforcement_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/LucasAlegre/sumo-rl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "simulation",
        "reinforcement-learning",
        "traffic-control",
        "sumo"
      ],
      "id": 36
    },
    {
      "name": "LUMI-EasyBuild-contrib",
      "one_line_profile": "EasyBuild configurations for LUMI supercomputer",
      "detailed_description": "A repository of EasyConfig files for building scientific software stacks on the LUMI supercomputer, enabling reproducible HPC environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "hpc_configuration",
        "build_automation"
      ],
      "application_level": "dataset",
      "primary_language": "Shell",
      "repo_url": "https://github.com/Lumi-supercomputer/LUMI-EasyBuild-contrib",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "hpc",
        "easybuild",
        "lumi",
        "configuration"
      ],
      "id": 37
    },
    {
      "name": "LUMI-SoftwareStack",
      "one_line_profile": "Software stack setup for LUMI supercomputer",
      "detailed_description": "Scripts and configurations for setting up the LMOD-based module system and EasyBuild environment on the LUMI supercomputer.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "hpc_environment",
        "module_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lumi-supercomputer/LUMI-SoftwareStack",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "hpc",
        "lmod",
        "easybuild",
        "lumi"
      ],
      "id": 38
    },
    {
      "name": "dsatools",
      "one_line_profile": "Digital signal analysis library for Python",
      "detailed_description": "A library for digital signal analysis and parameter estimation, including ARMA, SSA, EMD, and other techniques for processing scientific signal data.",
      "domains": [
        "AI1",
        "AI4"
      ],
      "subtask_category": [
        "signal_processing",
        "time_series_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/MVRonkin/dsatools",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "signal-processing",
        "spectral-analysis",
        "python",
        "decomposition"
      ],
      "id": 39
    },
    {
      "name": "VRQuestionnaireToolkit",
      "one_line_profile": "Toolkit for data collection in virtual environments",
      "detailed_description": "A toolkit enabling the collection of subjective measures and questionnaire data within virtual environments, used for research in psychology and HCI.",
      "domains": [
        "AI4-06"
      ],
      "subtask_category": [
        "data_collection",
        "behavioral_research"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/MartinFk/VRQuestionnaireToolkit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vr",
        "research-tools",
        "data-collection",
        "unity"
      ],
      "id": 40
    },
    {
      "name": "MathInspector",
      "one_line_profile": "Visual programming environment for scientific computing",
      "detailed_description": "A visual programming environment designed for scientific computing and mathematics visualization using Python.",
      "domains": [
        "AI1",
        "AI6"
      ],
      "subtask_category": [
        "scientific_visualization",
        "visual_programming"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/MathInspector/MathInspector",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "visualization",
        "scientific-computing",
        "python",
        "math"
      ],
      "id": 41
    },
    {
      "name": "ngmo-environments",
      "one_line_profile": "Environment configurations for Met Office Momentum models",
      "detailed_description": "Configuration repository for setting up Next Generation Environments for Momentum, supporting meteorological and climate modeling workflows.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_configuration",
        "climate_modeling"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/MetOffice/ngmo-environments",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "meteorology",
        "environment",
        "configuration",
        "met-office"
      ],
      "id": 42
    },
    {
      "name": "AlphaFold3-Conda-Install",
      "one_line_profile": "Installation scripts for AlphaFold 3 via Conda",
      "detailed_description": "A repository providing scripts and guides to automate the installation and environment configuration of AlphaFold 3 using Conda, facilitating structural biology research.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_setup",
        "software_deployment"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/Model3DBio/AlphaFold3-Conda-Install",
      "help_website": [],
      "license": null,
      "tags": [
        "alphafold",
        "conda",
        "installation",
        "structural-biology"
      ],
      "id": 43
    },
    {
      "name": "molssi-hub",
      "one_line_profile": "Container Hub for Computational Molecular Science",
      "detailed_description": "A central hub and registry for containers specifically designed for computational molecular science applications, maintained by MolSSI.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_registry",
        "molecular_science"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/MolSSI/molssi-hub",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "containers",
        "molecular-science",
        "hub",
        "molssi"
      ],
      "id": 44
    },
    {
      "name": "facemap",
      "one_line_profile": "Neural activity prediction from orofacial movements",
      "detailed_description": "A framework for analyzing behavioral videos to predict neural activity from mouse orofacial movements, including SVD analysis of video data.",
      "domains": [
        "AI4-01",
        "AI4"
      ],
      "subtask_category": [
        "behavioral_analysis",
        "neural_decoding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MouseLand/facemap",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "neuroscience",
        "behavior-analysis",
        "svd",
        "neural-activity"
      ],
      "id": 45
    },
    {
      "name": "LightM-UNet",
      "one_line_profile": "Lightweight Mamba-based UNet for medical segmentation",
      "detailed_description": "A PyTorch implementation of LightM-UNet, a lightweight medical image segmentation model leveraging Mamba architecture for efficiency.",
      "domains": [
        "AI4-01",
        "AI4"
      ],
      "subtask_category": [
        "medical_image_segmentation",
        "deep_learning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/MrBlankness/LightM-UNet",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-imaging",
        "mamba",
        "segmentation",
        "lightweight-model"
      ],
      "id": 46
    },
    {
      "name": "Inception",
      "one_line_profile": "Lightweight container runtime designed for HPC environments",
      "detailed_description": "Inception is a lightweight container runtime primarily targeting HPC environments. It allows unprivileged users to run containers on HPC systems, focusing on security and performance.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_runtime",
        "hpc_execution"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/NCAR/Inception",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "container-runtime",
        "linux-containers"
      ],
      "id": 47
    },
    {
      "name": "Shifter",
      "one_line_profile": "Container runtime for HPC environments enabling user-defined images",
      "detailed_description": "Shifter is a container runtime designed for High Performance Computing (HPC) environments. It allows users to run custom Docker images on supercomputers, addressing security and performance requirements specific to shared HPC resources.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_runtime",
        "image_conversion"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/NERSC/shifter",
      "help_website": [
        "https://docs.nersc.gov/development/shifter/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "docker",
        "containers",
        "nersc"
      ],
      "id": 48
    },
    {
      "name": "Remote Sensing Mamba",
      "one_line_profile": "State Space Model architecture tailored for remote sensing image analysis",
      "detailed_description": "Official implementation of Remote Sensing Mamba, a deep learning model based on the Mamba architecture, specifically optimized for processing and analyzing remote sensing imagery data.",
      "domains": [
        "AI4S-EarthScience"
      ],
      "subtask_category": [
        "image_analysis",
        "feature_extraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NJU-LHRS/Official_Remote_Sensing_Mamba",
      "help_website": [],
      "license": null,
      "tags": [
        "remote-sensing",
        "mamba",
        "deep-learning",
        "earth-observation"
      ],
      "id": 49
    },
    {
      "name": "NVFlare",
      "one_line_profile": "Federated learning runtime environment for collaborative AI model training",
      "detailed_description": "NVIDIA Federated Learning Application Runtime Environment (NVFlare) is a platform that enables federated learning, allowing multiple parties to collaborate on training AI models (often used in medical imaging and scientific collaboration) without sharing raw data.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "federated_learning",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/NVFlare",
      "help_website": [
        "https://nvflare.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "federated-learning",
        "privacy-preserving",
        "distributed-computing"
      ],
      "id": 50
    },
    {
      "name": "container-canary",
      "one_line_profile": "CLI tool for validating container images against defined requirements",
      "detailed_description": "Container Canary is a tool for testing and validating container requirements against versioned manifests. It is useful in scientific workflows to ensure container images meet specific environment specifications before deployment.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_validation",
        "quality_control"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/NVIDIA/container-canary",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "container-testing",
        "validation",
        "devops-for-science"
      ],
      "id": 51
    },
    {
      "name": "enroot",
      "one_line_profile": "Simple, powerful tool to turn container images into unprivileged sandboxes for HPC",
      "detailed_description": "Enroot is a tool designed to turn traditional container/OS images into unprivileged sandboxes. It is widely used in HPC environments (often with PyTorch/NVIDIA stacks) to provide a lightweight and performant container runtime.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_runtime",
        "sandbox_environment"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/NVIDIA/enroot",
      "help_website": [
        "https://github.com/NVIDIA/enroot/blob/master/doc/README.md"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "containers",
        "sandbox",
        "nvidia"
      ],
      "id": 52
    },
    {
      "name": "HPC Container Maker",
      "one_line_profile": "Tool to generate Dockerfiles and Singularity definition files for HPC",
      "detailed_description": "HPC Container Maker (HPCCM) is a Python tool that generates Dockerfiles and Singularity definition files. It simplifies the creation of container specifications for High Performance Computing (HPC) applications by providing high-level primitives.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "image_generation",
        "environment_definition"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/hpc-container-maker",
      "help_website": [
        "https://github.com/NVIDIA/hpc-container-maker/tree/master/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "dockerfile-generator",
        "singularity",
        "reproducibility"
      ],
      "id": 53
    },
    {
      "name": "libnvidia-container",
      "one_line_profile": "Library for NVIDIA GPU container runtime support",
      "detailed_description": "The NVIDIA container runtime library (libnvidia-container) provides a C API to configure containers with NVIDIA GPU support. It is a foundational component for running GPU-accelerated scientific applications in containers.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "gpu_acceleration",
        "container_runtime"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/NVIDIA/libnvidia-container",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu",
        "containers",
        "nvidia",
        "cuda"
      ],
      "id": 54
    },
    {
      "name": "nvidia-container-runtime",
      "one_line_profile": "Container runtime hook to enable NVIDIA GPU support in containers",
      "detailed_description": "NVIDIA Container Runtime is a modified version of runc that adds a custom pre-start hook to enable NVIDIA GPU support. It is essential for running AI and scientific simulation workloads in Docker/Kubernetes environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_runtime",
        "gpu_acceleration"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/NVIDIA/nvidia-container-runtime",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu",
        "docker",
        "runc",
        "hpc"
      ],
      "id": 55
    },
    {
      "name": "envkernel",
      "one_line_profile": "Jupyter kernel manager for Conda, Docker, Singularity, and Lmod environments",
      "detailed_description": "Envkernel allows users to run Jupyter kernels inside different environments such as Conda, Virtualenv, Docker, Singularity, and Lmod. It bridges interactive scientific computing (Jupyter) with HPC environment management systems.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "jupyter_integration"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/NordicHPC/envkernel",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyter",
        "hpc",
        "singularity",
        "conda"
      ],
      "id": 56
    },
    {
      "name": "hatch-conda",
      "one_line_profile": "Hatch plugin to manage Conda environments",
      "detailed_description": "Hatch-conda is a plugin for the Hatch project manager that enables the use of Conda environments. Since Conda is the de facto standard for scientific software packaging, this tool facilitates scientific Python development workflows.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "package_management",
        "environment_management"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/OldGrumpyViking/hatch-conda",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "conda",
        "hatch",
        "python-packaging"
      ],
      "id": 57
    },
    {
      "name": "pixi-pack",
      "one_line_profile": "Tool to pack and unpack Conda environments created with pixi",
      "detailed_description": "Pixi-pack is a utility for packing and unpacking Conda environments created with the 'pixi' package manager. It aids in the reproducibility and distribution of scientific computing environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_packaging",
        "reproducibility"
      ],
      "application_level": "tool",
      "primary_language": "Rust",
      "repo_url": "https://github.com/Quantco/pixi-pack",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "pixi",
        "environment-management"
      ],
      "id": 58
    },
    {
      "name": "neurodocker",
      "one_line_profile": "Generator for custom Docker and Singularity images for neuroimaging",
      "detailed_description": "Neurodocker is a command-line tool that generates custom Dockerfiles and Singularity definition files for neuroimaging and scientific computing. It simplifies the creation of reproducible environments containing common neuroscience software (FSL, SPM, etc.).",
      "domains": [
        "AI6",
        "AI6-01",
        "AI4S-Neuroscience"
      ],
      "subtask_category": [
        "image_generation",
        "reproducibility"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/ReproNim/neurodocker",
      "help_website": [
        "https://github.com/ReproNim/neurodocker"
      ],
      "license": "Apache-2.0",
      "tags": [
        "neuroimaging",
        "docker",
        "singularity",
        "reproducibility"
      ],
      "id": 59
    },
    {
      "name": "Spackenv",
      "one_line_profile": "Environment management wrapper for Spack in HPC clusters",
      "detailed_description": "A tool developed by SJTU HPC to manage and switch between Spack environments, facilitating software management for sysadmins, users, and developers in high-performance computing contexts.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "package_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/SJTU-HPC/spackenv",
      "help_website": [],
      "license": null,
      "tags": [
        "hpc",
        "spack",
        "environment-management"
      ],
      "id": 60
    },
    {
      "name": "Create-A-Container",
      "one_line_profile": "Builder for custom Singularity/Apptainer HPC containers",
      "detailed_description": "A repository and toolset for building custom Singularity/Apptainer containers tailored for specific HPC environments (RAP Workstation, CREATE HPC), supporting reproducible scientific workflows.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_building",
        "environment_reproducibility"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Sensible-Robots/Create-A-Container",
      "help_website": [],
      "license": null,
      "tags": [
        "singularity",
        "apptainer",
        "hpc",
        "container"
      ],
      "id": 61
    },
    {
      "name": "Singular",
      "one_line_profile": "Computer algebra system for polynomial computations",
      "detailed_description": "A computer algebra system for polynomial computations, with special emphasis on commutative and non-commutative algebra, algebraic geometry, and singularity theory.",
      "domains": [
        "Math",
        "Algebra"
      ],
      "subtask_category": [
        "algebraic_computation",
        "polynomial_solving"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/Singular/Singular",
      "help_website": [
        "https://www.singular.uni-kl.de/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "computer-algebra-system",
        "algebraic-geometry",
        "polynomials"
      ],
      "id": 62
    },
    {
      "name": "SkyText-Chinese-GPT3",
      "one_line_profile": "Chinese GPT-3 pre-trained large language model",
      "detailed_description": "A Chinese GPT-3 pre-trained large model capable of text generation, dialogue, translation, and reasoning, serving as a foundation model for NLP research.",
      "domains": [
        "AI",
        "NLP"
      ],
      "subtask_category": [
        "text_generation",
        "translation",
        "reasoning"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/SkyWorkAIGC/SkyText-Chinese-GPT3",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpt-3",
        "llm",
        "nlp",
        "chinese"
      ],
      "id": 63
    },
    {
      "name": "StaPH-B Docker Builds",
      "one_line_profile": "Container recipes for public health bioinformatics",
      "detailed_description": "A collection of Dockerfiles and documentation providing reproducible container environments for public health bioinformatics tools and workflows.",
      "domains": [
        "AI6",
        "AI6-01",
        "Bioinformatics"
      ],
      "subtask_category": [
        "environment_provisioning",
        "bioinformatics_workflow"
      ],
      "application_level": "library",
      "primary_language": "Dockerfile",
      "repo_url": "https://github.com/StaPH-B/docker-builds",
      "help_website": [
        "https://staphb.org"
      ],
      "license": "GPL-3.0",
      "tags": [
        "bioinformatics",
        "docker",
        "public-health",
        "containers"
      ],
      "id": 64
    },
    {
      "name": "BeeGFS CSI Driver",
      "one_line_profile": "Kubernetes CSI driver for BeeGFS parallel file system",
      "detailed_description": "A Container Storage Interface (CSI) driver that enables Kubernetes clusters to utilize BeeGFS, a high-performance parallel file system commonly used in HPC environments.",
      "domains": [
        "AI6",
        "HPC"
      ],
      "subtask_category": [
        "storage_management",
        "hpc_infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/ThinkParQ/beegfs-csi-driver",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "beegfs",
        "csi",
        "kubernetes",
        "hpc"
      ],
      "id": 65
    },
    {
      "name": "skrl",
      "one_line_profile": "Modular Reinforcement Learning library for robotics and physics simulations",
      "detailed_description": "A modular Reinforcement Learning library built on PyTorch, JAX, and NVIDIA Warp, designed to support scientific environments like Isaac Lab, Brax, and Gymnasium for robotics and physics control tasks.",
      "domains": [
        "AI",
        "Robotics",
        "Physics"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "robotics_control",
        "physics_simulation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Toni-SM/skrl",
      "help_website": [
        "https://skrl.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "reinforcement-learning",
        "robotics",
        "isaac-lab",
        "physics-simulation"
      ],
      "id": 66
    },
    {
      "name": "AkôFlow",
      "one_line_profile": "Middleware for container-based scientific workflows",
      "detailed_description": "An open-source middleware for orchestrating and executing container-based scientific workflows across heterogeneous environments, developed for e-Science applications.",
      "domains": [
        "AI6",
        "HPC"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "scientific_workflow"
      ],
      "application_level": "workflow",
      "primary_language": "Go",
      "repo_url": "https://github.com/UFFeScience/akoflow",
      "help_website": [],
      "license": null,
      "tags": [
        "scientific-workflow",
        "middleware",
        "containers",
        "hpc"
      ],
      "id": 67
    },
    {
      "name": "E4S Spack Environments",
      "one_line_profile": "Spack environments and container recipes for E4S",
      "detailed_description": "Configuration files and recipes for creating Spack environments and containers for the Extreme-scale Scientific Software Stack (E4S), facilitating reproducible HPC software deployment.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "environment_provisioning",
        "software_stack_management"
      ],
      "application_level": "library",
      "primary_language": "Dockerfile",
      "repo_url": "https://github.com/UO-OACISS/e4s",
      "help_website": [
        "https://e4s-project.github.io/"
      ],
      "license": null,
      "tags": [
        "e4s",
        "spack",
        "hpc",
        "containers"
      ],
      "id": 68
    },
    {
      "name": "MogaNet",
      "one_line_profile": "Efficient Multi-order Gated Aggregation Network for vision tasks",
      "detailed_description": "Implementation of MogaNet, a neural network architecture for efficient computer vision tasks, serving as a tool for image analysis and feature extraction.",
      "domains": [
        "AI",
        "Computer Vision"
      ],
      "subtask_category": [
        "image_classification",
        "feature_extraction"
      ],
      "application_level": "model",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Westlake-AI/MogaNet",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "computer-vision",
        "deep-learning",
        "moganet"
      ],
      "id": 69
    },
    {
      "name": "MedMamba",
      "one_line_profile": "Vision Mamba model for medical image classification",
      "detailed_description": "A deep learning model applying the Mamba architecture to medical image classification tasks, providing a tool for medical image analysis.",
      "domains": [
        "AI",
        "Medical Imaging"
      ],
      "subtask_category": [
        "medical_image_classification",
        "image_analysis"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/YubiaoYue/MedMamba",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-imaging",
        "mamba",
        "deep-learning"
      ],
      "id": 70
    },
    {
      "name": "NavRL",
      "one_line_profile": "Reinforcement learning framework for safe flight navigation",
      "detailed_description": "A reinforcement learning framework and library for training safe flight navigation agents in dynamic environments, integrating with ROS and NVIDIA Isaac.",
      "domains": [
        "AI",
        "Robotics"
      ],
      "subtask_category": [
        "navigation",
        "robotics_control",
        "reinforcement_learning"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/Zhefan-Xu/NavRL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "robotics",
        "navigation",
        "reinforcement-learning",
        "ros"
      ],
      "id": 71
    },
    {
      "name": "BlackMamba",
      "one_line_profile": "Implementation of the BlackMamba state-space model",
      "detailed_description": "Code repository for the BlackMamba architecture, a state-space model for sequence modeling, serving as a tool for AI research.",
      "domains": [
        "AI",
        "Deep Learning"
      ],
      "subtask_category": [
        "sequence_modeling",
        "model_architecture"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zyphra/BlackMamba",
      "help_website": [],
      "license": null,
      "tags": [
        "mamba",
        "ssm",
        "deep-learning"
      ],
      "id": 72
    },
    {
      "name": "PSSA",
      "one_line_profile": "Singular Spectrum Analysis library for time series forecasting",
      "detailed_description": "A Python implementation of Singular Spectrum Analysis (SSA) for time series decomposition and forecasting, useful in scientific data analysis.",
      "domains": [
        "Math",
        "Statistics",
        "Time Series Analysis"
      ],
      "subtask_category": [
        "forecasting",
        "time_series_analysis",
        "decomposition"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/aj-cloete/pssa",
      "help_website": [],
      "license": null,
      "tags": [
        "ssa",
        "time-series",
        "forecasting"
      ],
      "id": 73
    },
    {
      "name": "ScienceWorld",
      "one_line_profile": "Text-based virtual environment for scientific discovery agents",
      "detailed_description": "A simulation environment centered around elementary science curriculum tasks to test and evaluate AI agents' reasoning and scientific problem-solving capabilities.",
      "domains": [
        "AI Research",
        "General Science"
      ],
      "subtask_category": [
        "simulation",
        "agent_training",
        "reasoning"
      ],
      "application_level": "platform",
      "primary_language": "Scala",
      "repo_url": "https://github.com/allenai/ScienceWorld",
      "help_website": [
        "https://sciworld.apps.allenai.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rl-environment",
        "science-simulation",
        "nlp"
      ],
      "id": 74
    },
    {
      "name": "DiscoveryWorld",
      "one_line_profile": "Virtual environment for automated scientific discovery agents",
      "detailed_description": "A virtual environment designed for developing and evaluating automated agents capable of performing scientific discovery tasks.",
      "domains": [
        "AI Research",
        "Scientific Discovery"
      ],
      "subtask_category": [
        "simulation",
        "agent_training",
        "discovery"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/allenai/discoveryworld",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rl-environment",
        "scientific-discovery",
        "agent"
      ],
      "id": 75
    },
    {
      "name": "conda-merge",
      "one_line_profile": "Utility to merge Conda environment files",
      "detailed_description": "A tool to merge multiple Conda environment specification files into a single file, facilitating complex scientific environment management.",
      "domains": [
        "AI6-01",
        "Scientific Computing"
      ],
      "subtask_category": [
        "environment_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/amitbeka/conda-merge",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "conda",
        "environment-management",
        "reproducibility"
      ],
      "id": 76
    },
    {
      "name": "nb_conda",
      "one_line_profile": "Conda environment management extension for Jupyter",
      "detailed_description": "An extension that allows management of Conda environments and packages directly from within the Jupyter Notebook interface.",
      "domains": [
        "AI6-01",
        "Scientific Computing"
      ],
      "subtask_category": [
        "environment_management",
        "interactive_computing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/anaconda/nb_conda",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyter",
        "conda",
        "notebook"
      ],
      "id": 77
    },
    {
      "name": "nb_conda_kernels",
      "one_line_profile": "Jupyter extension for Conda environment kernels",
      "detailed_description": "A package that automatically creates Jupyter kernels for all environments found in the Conda installation, enabling easy switching between scientific environments.",
      "domains": [
        "AI6-01",
        "Scientific Computing"
      ],
      "subtask_category": [
        "environment_management",
        "kernel_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/anaconda/nb_conda_kernels",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyter",
        "conda",
        "kernels"
      ],
      "id": 78
    },
    {
      "name": "Apptainer",
      "one_line_profile": "Container system for High Performance Computing (HPC)",
      "detailed_description": "The open-source container system (formerly Singularity) designed for HPC environments, allowing researchers to package and run applications reproducibly.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "containerization",
        "reproducibility",
        "runtime_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/apptainer/apptainer",
      "help_website": [
        "https://apptainer.org/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "containers",
        "singularity"
      ],
      "id": 79
    },
    {
      "name": "Singularity",
      "one_line_profile": "Container platform for HPC (Legacy/Snapshot)",
      "detailed_description": "The legacy repository for Singularity (now Apptainer), a container platform optimized for High Performance Computing and scientific workflows.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "containerization",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/apptainer/singularity",
      "help_website": [
        "https://apptainer.org/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "containers",
        "legacy"
      ],
      "id": 80
    },
    {
      "name": "uv",
      "one_line_profile": "Extremely fast Python package and project manager",
      "detailed_description": "A modern, high-performance Python package manager that serves as a drop-in replacement for pip and pip-tools, increasingly used in scientific Python ecosystems for environment reproducibility.",
      "domains": [
        "AI6-01",
        "Scientific Computing"
      ],
      "subtask_category": [
        "package_management",
        "environment_management"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/astral-sh/uv",
      "help_website": [
        "https://docs.astral.sh/uv/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "python",
        "package-manager",
        "rust"
      ],
      "id": 81
    },
    {
      "name": "uvify",
      "one_line_profile": "Tool to convert Python repos to uv environments",
      "detailed_description": "A utility to automatically generate `uv` environment configurations from existing Python repositories, facilitating reproducible scientific environments.",
      "domains": [
        "AI6-01",
        "Scientific Computing"
      ],
      "subtask_category": [
        "environment_management",
        "reproducibility"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/avilum/uvify",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "uv",
        "python",
        "environment"
      ],
      "id": 82
    },
    {
      "name": "DockerMake",
      "one_line_profile": "Reproducible Docker image build system for complex stacks",
      "detailed_description": "A command-line tool to build and manage Docker images for complex software stacks, designed to support reproducible research and scientific workflows.",
      "domains": [
        "AI6-01",
        "Scientific Computing"
      ],
      "subtask_category": [
        "container_build",
        "reproducibility"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/avirshup/DockerMake",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "docker",
        "reproducibility",
        "build-tool"
      ],
      "id": 83
    },
    {
      "name": "TwinGraph",
      "one_line_profile": "Distributed container orchestration framework for simulations",
      "detailed_description": "A Python framework for orchestrating distributed containerized applications, specifically targeting high-throughput simulations, digital twins, and scientific optimization tasks on AWS/K8s.",
      "domains": [
        "AI6",
        "HPC",
        "Simulation"
      ],
      "subtask_category": [
        "orchestration",
        "simulation",
        "digital_twin"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/aws-samples/twingraph",
      "help_website": [],
      "license": "MIT-0",
      "tags": [
        "orchestration",
        "simulation",
        "kubernetes"
      ],
      "id": 84
    },
    {
      "name": "Bactopia",
      "one_line_profile": "Pipeline for complete analysis of bacterial genomes",
      "detailed_description": "A flexible and comprehensive Nextflow pipeline for the analysis of bacterial genomes, including QC, assembly, and annotation.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "genome_analysis",
        "pipeline",
        "assembly"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/bactopia/bactopia",
      "help_website": [
        "https://bactopia.github.io/"
      ],
      "license": "MIT",
      "tags": [
        "bioinformatics",
        "bacteria",
        "nextflow"
      ],
      "id": 85
    },
    {
      "name": "unidep",
      "one_line_profile": "Unified dependency management for pip and conda",
      "detailed_description": "A tool that provides a single source of truth for Python requirements, handling both pip and conda dependencies to simplify scientific environment setup.",
      "domains": [
        "AI6-01",
        "Scientific Computing"
      ],
      "subtask_category": [
        "dependency_management",
        "environment_setup"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/basnijholt/unidep",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "pip",
        "dependencies"
      ],
      "id": 86
    },
    {
      "name": "pybullet-gym",
      "one_line_profile": "Open-source OpenAI Gym MuJoCo environments using PyBullet",
      "detailed_description": "A reimplementation of OpenAI Gym MuJoCo environments using the open-source PyBullet physics engine, enabling reinforcement learning research without proprietary licenses.",
      "domains": [
        "AI Research",
        "Robotics",
        "Reinforcement Learning"
      ],
      "subtask_category": "simulation",
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/benelot/pybullet-gym",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "reinforcement-learning",
        "pybullet",
        "physics-simulation",
        "gym-environments"
      ],
      "id": 87
    },
    {
      "name": "Master of Pores",
      "one_line_profile": "Nextflow pipeline for direct RNA Nanopore sequencing analysis",
      "detailed_description": "A bioinformatics pipeline built with Nextflow for processing and analyzing direct RNA sequencing data from Oxford Nanopore technologies, handling preprocessing, alignment, and modification detection.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": "pipeline_processing",
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/biocorecrg/master_of_pores",
      "help_website": [
        "https://biocorecrg.github.io/master_of_pores/"
      ],
      "license": "MIT",
      "tags": [
        "nanopore",
        "rna-seq",
        "nextflow",
        "bioinformatics"
      ],
      "id": 88
    },
    {
      "name": "Graph-Mamba",
      "one_line_profile": "Long-range graph sequence modelling with selective state spaces",
      "detailed_description": "A deep learning model integrating Mamba's selective state space models with graph neural networks to capture long-range dependencies in graph sequences, applicable to molecular and structural analysis.",
      "domains": [
        "AI for Science",
        "Graph Learning"
      ],
      "subtask_category": "modeling",
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bowang-lab/Graph-Mamba",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "graph-neural-networks",
        "mamba",
        "deep-learning",
        "sequence-modeling"
      ],
      "id": 89
    },
    {
      "name": "U-Mamba",
      "one_line_profile": "CNN-Mamba hybrid network for biomedical image segmentation",
      "detailed_description": "A general-purpose biomedical image segmentation tool that enhances long-range dependency modeling by combining State Space Models (Mamba) with CNN-based U-Net architectures.",
      "domains": [
        "Biomedical Imaging",
        "AI for Science"
      ],
      "subtask_category": "image_segmentation",
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bowang-lab/U-Mamba",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-imaging",
        "segmentation",
        "mamba",
        "deep-learning"
      ],
      "id": 90
    },
    {
      "name": "irlba",
      "one_line_profile": "Fast truncated singular value decomposition (SVD) library",
      "detailed_description": "An R library for implicitly restarted Lanczos bidiagonalization algorithms, providing fast truncated SVD and PCA for large sparse or dense matrices common in scientific data analysis.",
      "domains": [
        "Statistics",
        "Scientific Computing"
      ],
      "subtask_category": "statistical_analysis",
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/bwlewis/irlba",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "svd",
        "pca",
        "matrix-factorization",
        "sparse-matrices"
      ],
      "id": 91
    },
    {
      "name": "calkit",
      "one_line_profile": "Project management tool for reproducible research",
      "detailed_description": "A command-line tool and Python library designed to simplify version control, environment management, and reproducible pipelines specifically for research projects.",
      "domains": [
        "AI6",
        "AI6-01",
        "Reproducible Research"
      ],
      "subtask_category": "workflow_management",
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/calkit/calkit",
      "help_website": [
        "https://calkit.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "reproducibility",
        "git",
        "pipeline",
        "research-management"
      ],
      "id": 92
    },
    {
      "name": "cmcrameri",
      "one_line_profile": "Perceptually uniform colourmaps for geosciences",
      "detailed_description": "A Python library providing Fabio Crameri's perceptually uniform colourmaps, designed to accurately represent scientific data in geosciences and prevent visual distortion.",
      "domains": [
        "Geoscience",
        "Scientific Visualization"
      ],
      "subtask_category": "visualization",
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/callumrollo/cmcrameri",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "colormaps",
        "visualization",
        "geoscience",
        "matplotlib"
      ],
      "id": 93
    },
    {
      "name": "conda-auto-env",
      "one_line_profile": "Automatic Conda environment activator",
      "detailed_description": "A shell utility that automatically activates the appropriate Conda environment when entering a directory containing an environment.yml file, streamlining scientific workflows.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": "environment_management",
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/chdoig/conda-auto-env",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "environment-management",
        "productivity",
        "shell-script"
      ],
      "id": 94
    },
    {
      "name": "vim-conda",
      "one_line_profile": "Vim plugin for Conda environment switching",
      "detailed_description": "A Vim plugin that allows users to change Conda environments directly within the editor, facilitating development in scientific Python environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": "environment_management",
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cjrh/vim-conda",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vim",
        "conda",
        "ide-plugin",
        "python"
      ],
      "id": 95
    },
    {
      "name": "CompareM2",
      "one_line_profile": "Microbial genomes-to-report pipeline",
      "detailed_description": "A comprehensive pipeline for comparative genomics of microbial isolates, automating the process from genomes to analytical reports.",
      "domains": [
        "Bioinformatics",
        "Microbiology"
      ],
      "subtask_category": "genomic_analysis",
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/cmkobel/CompareM2",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "genomics",
        "pipeline",
        "microbial-analysis",
        "bioinformatics"
      ],
      "id": 96
    },
    {
      "name": "detectron2-windows",
      "one_line_profile": "Windows build of Detectron2",
      "detailed_description": "A distribution of Facebook AI Research's Detectron2 library optimized for Windows, enabling object detection and segmentation research on Windows platforms.",
      "domains": [
        "Computer Vision",
        "AI Research"
      ],
      "subtask_category": "image_analysis",
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/conansherry/detectron2",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "detectron2",
        "object-detection",
        "segmentation",
        "windows"
      ],
      "id": 97
    },
    {
      "name": "conda-env",
      "one_line_profile": "Interface for managing Conda environments",
      "detailed_description": "A tool for managing Conda environments, allowing users to create, export, list, remove, and update environments, essential for reproducible scientific computing.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": "environment_management",
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda-archive/conda-env",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "conda",
        "environment-management",
        "reproducibility",
        "python"
      ],
      "id": 98
    },
    {
      "name": "conda-smithy",
      "one_line_profile": "Tool for managing conda-forge feedstocks",
      "detailed_description": "A tool used to manage the conda-forge scientific software distribution ecosystem, automating the linting, re-rendering, and updating of feedstock repositories.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": "package_management",
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda-forge/conda-smithy",
      "help_website": [
        "https://conda-forge.org/docs/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "conda-forge",
        "packaging",
        "automation",
        "scientific-software"
      ],
      "id": 99
    },
    {
      "name": "Miniforge",
      "one_line_profile": "Minimal installer for Conda specific to conda-forge",
      "detailed_description": "A minimal installer for Conda that is pre-configured to use the conda-forge channel, widely used in the scientific community for setting up Python/R environments, especially on architectures like Apple Silicon (M1/M2) and AArch64.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "package_installation"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/conda-forge/miniforge",
      "help_website": [
        "https://github.com/conda-forge/miniforge"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "installer",
        "python-distribution",
        "hpc"
      ],
      "id": 100
    },
    {
      "name": "conda-docker",
      "one_line_profile": "Tool to create minimal docker images from conda environments",
      "detailed_description": "A tool that allows users to generate Docker images directly from Conda environments without requiring a Docker daemon, facilitating the containerization of scientific workflows.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "containerization",
        "reproducibility"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda-incubator/conda-docker",
      "help_website": [
        "https://github.com/conda-incubator/conda-docker"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "docker",
        "conda",
        "container-image",
        "reproducibility"
      ],
      "id": 101
    },
    {
      "name": "conda-env-builder",
      "one_line_profile": "Builder for maintaining multiple custom conda environments",
      "detailed_description": "A tool to build and maintain multiple custom Conda environments from a single configuration source, useful for managing complex scientific software stacks.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "dependency_management"
      ],
      "application_level": "workflow",
      "primary_language": "Scala",
      "repo_url": "https://github.com/conda-incubator/conda-env-builder",
      "help_website": [
        "https://github.com/conda-incubator/conda-env-builder"
      ],
      "license": "MIT",
      "tags": [
        "conda",
        "environment-manager",
        "build-tool"
      ],
      "id": 102
    },
    {
      "name": "conda-project",
      "one_line_profile": "Tool for encapsulating and reproducing projects with Conda",
      "detailed_description": "A tool designed to encapsulate, run, and reproduce data science projects by managing Conda environments and project-specific commands.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "project_management",
        "reproducibility"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda-incubator/conda-project",
      "help_website": [
        "https://conda-project.readthedocs.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "reproducible-research",
        "conda",
        "project-management"
      ],
      "id": 103
    },
    {
      "name": "conda-store",
      "one_line_profile": "Server for managing and serving Conda environments",
      "detailed_description": "A tool that provides a way to build and serve Conda environments for data science teams, often integrated with JupyterHub to ensure consistent environments across users.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "collaboration"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda-incubator/conda-store",
      "help_website": [
        "https://conda-store.readthedocs.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyterhub",
        "conda",
        "data-science",
        "environment-serving"
      ],
      "id": 104
    },
    {
      "name": "conda-tree",
      "one_line_profile": "Dependency tree analyzer for Conda environments",
      "detailed_description": "A utility to inspect the dependency tree of Conda environments, helping scientists debug package conflicts and understand environment structure.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "dependency_analysis",
        "debugging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda-incubator/conda-tree",
      "help_website": [
        "https://github.com/conda-incubator/conda-tree"
      ],
      "license": "MIT",
      "tags": [
        "dependency-tree",
        "conda",
        "visualization"
      ],
      "id": 105
    },
    {
      "name": "condacolab",
      "one_line_profile": "Tool to install Conda on Google Colab",
      "detailed_description": "A Python package that enables the installation and use of Conda/Mamba on Google Colab, allowing researchers to use scientific packages not available in the default Colab runtime.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_setup",
        "cloud_computing"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/conda-incubator/condacolab",
      "help_website": [
        "https://github.com/conda-incubator/condacolab"
      ],
      "license": "MIT",
      "tags": [
        "google-colab",
        "conda",
        "python",
        "research-environment"
      ],
      "id": 106
    },
    {
      "name": "conda-execute",
      "one_line_profile": "Execute scripts in temporary Conda environments",
      "detailed_description": "A tool to execute scripts in their own temporary, reproducible Conda environments defined within the script itself, ensuring consistent execution contexts.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "reproducibility",
        "script_execution"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda-tools/conda-execute",
      "help_website": [
        "https://github.com/conda-tools/conda-execute"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "reproducibility",
        "conda",
        "scripting"
      ],
      "id": 107
    },
    {
      "name": "Conda",
      "one_line_profile": "Package, dependency and environment management for any language",
      "detailed_description": "The de facto standard package and environment manager for scientific computing (Python, R, etc.), enabling users to install, run, and update packages and their dependencies.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "package_management",
        "environment_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda/conda",
      "help_website": [
        "https://docs.conda.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "package-manager",
        "virtual-environment",
        "scientific-computing"
      ],
      "id": 108
    },
    {
      "name": "conda-build",
      "one_line_profile": "Tools for building conda packages",
      "detailed_description": "The build system for creating Conda packages, essential for packaging scientific software for distribution via channels like conda-forge.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "package_building",
        "distribution"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda/conda-build",
      "help_website": [
        "https://docs.conda.io/projects/conda-build"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "build-tool",
        "packaging",
        "conda"
      ],
      "id": 109
    },
    {
      "name": "conda-libmamba-solver",
      "one_line_profile": "Fast libmamba-based solver for Conda",
      "detailed_description": "A plugin for Conda that uses the libmamba solver to significantly speed up dependency resolution in complex scientific environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "dependency_resolution",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda/conda-libmamba-solver",
      "help_website": [
        "https://conda.github.io/conda-libmamba-solver/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "solver",
        "performance",
        "conda",
        "mamba"
      ],
      "id": 110
    },
    {
      "name": "conda-lock",
      "one_line_profile": "Lightweight lockfile generator for Conda",
      "detailed_description": "A tool to generate fully reproducible lockfiles for Conda environments across multiple platforms, ensuring identical environments for scientific collaboration.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "reproducibility",
        "dependency_locking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda/conda-lock",
      "help_website": [
        "https://conda-incubator.github.io/conda-lock/"
      ],
      "license": "MIT",
      "tags": [
        "lockfile",
        "reproducibility",
        "conda"
      ],
      "id": 111
    },
    {
      "name": "conda-pack",
      "one_line_profile": "Tool to package conda environments for redistribution",
      "detailed_description": "A tool for creating relocatable archives of Conda environments, widely used to deploy scientific environments to Spark/Hadoop clusters or HPC nodes where Conda is not installed.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "deployment",
        "environment_archiving"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda/conda-pack",
      "help_website": [
        "https://conda.github.io/conda-pack/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "deployment",
        "hpc",
        "archive",
        "conda"
      ],
      "id": 112
    },
    {
      "name": "constructor",
      "one_line_profile": "Tool for creating installers from conda packages",
      "detailed_description": "A tool that allows users to create custom installers (like Miniconda or Anaconda) from a collection of Conda packages, used for distributing scientific software stacks.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "distribution",
        "installer_generation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda/constructor",
      "help_website": [
        "https://github.com/conda/constructor"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "installer",
        "packaging",
        "distribution"
      ],
      "id": 113
    },
    {
      "name": "Grayskull",
      "one_line_profile": "Recipe generator for Conda packages",
      "detailed_description": "An automatic recipe generator for Conda that creates recipes for PyPI packages, simplifying the process of adding scientific Python libraries to conda-forge.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "package_building",
        "automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/conda/grayskull",
      "help_website": [
        "https://github.com/conda/grayskull"
      ],
      "license": "Apache-2.0",
      "tags": [
        "recipe-generator",
        "pypi",
        "conda-forge"
      ],
      "id": 114
    },
    {
      "name": "rattler",
      "one_line_profile": "Rust crates for the Conda ecosystem",
      "detailed_description": "A high-performance Rust library and toolkit for working with the Conda ecosystem, providing the foundation for next-generation Conda tools (like pixi).",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "package_management",
        "infrastructure"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/conda/rattler",
      "help_website": [
        "https://docs.rs/rattler/latest/rattler/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "rust",
        "conda",
        "performance",
        "library"
      ],
      "id": 115
    },
    {
      "name": "Buildah",
      "one_line_profile": "Tool for building OCI images, often used in HPC",
      "detailed_description": "A tool that facilitates building OCI container images. It is particularly important in scientific HPC environments for its ability to build containers without root privileges (rootless).",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_building",
        "hpc_infrastructure"
      ],
      "application_level": "workflow",
      "primary_language": "Go",
      "repo_url": "https://github.com/containers/buildah",
      "help_website": [
        "https://buildah.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "containers",
        "hpc",
        "oci",
        "rootless"
      ],
      "id": 116
    },
    {
      "name": "Podman",
      "one_line_profile": "Daemonless container engine for OCI containers",
      "detailed_description": "A daemonless container engine for developing, managing, and running OCI containers. It is the standard for running containers in HPC environments due to its rootless capabilities and compatibility with Docker CLI.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_runtime",
        "hpc_infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/containers/podman",
      "help_website": [
        "https://podman.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "containers",
        "hpc",
        "rootless",
        "docker-alternative"
      ],
      "id": 117
    },
    {
      "name": "podman-compose",
      "one_line_profile": "Run docker-compose.yml using Podman",
      "detailed_description": "A script that allows users to run docker-compose.yml files using Podman, enabling the orchestration of multi-container scientific workflows in rootless environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "orchestration",
        "workflow_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/containers/podman-compose",
      "help_website": [
        "https://github.com/containers/podman-compose"
      ],
      "license": "GPL-2.0",
      "tags": [
        "orchestration",
        "compose",
        "podman"
      ],
      "id": 118
    },
    {
      "name": "podman-py",
      "one_line_profile": "Python bindings for Podman",
      "detailed_description": "A Python library for interacting with the Podman REST API, allowing scientific applications to programmatically manage containers.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "automation",
        "container_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/containers/podman-py",
      "help_website": [
        "https://github.com/containers/podman-py"
      ],
      "license": "Apache-2.0",
      "tags": [
        "python-api",
        "podman",
        "automation"
      ],
      "id": 119
    },
    {
      "name": "podman-tui",
      "one_line_profile": "Terminal UI for Podman",
      "detailed_description": "A terminal user interface for Podman, facilitating the management of containers and pods in terminal-only environments common in HPC and remote servers.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_management",
        "visualization"
      ],
      "application_level": "workflow",
      "primary_language": "Go",
      "repo_url": "https://github.com/containers/podman-tui",
      "help_website": [
        "https://github.com/containers/podman-tui"
      ],
      "license": "Apache-2.0",
      "tags": [
        "tui",
        "podman",
        "management"
      ],
      "id": 120
    },
    {
      "name": "RamaLama",
      "one_line_profile": "Tool for local serving of AI models via containers",
      "detailed_description": "An open-source tool that simplifies the local serving and inference of AI models using containers, abstracting the complexity of hardware acceleration and container runtimes.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "model_inference",
        "ai_serving"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/containers/ramalama",
      "help_website": [
        "https://github.com/containers/ramalama"
      ],
      "license": "MIT",
      "tags": [
        "ai-inference",
        "containers",
        "llm",
        "model-serving"
      ],
      "id": 121
    },
    {
      "name": "mrs_apptainer",
      "one_line_profile": "Apptainer wrappers and resources for the MRS UAV System",
      "detailed_description": "Provides Apptainer (Singularity) wrappers, definitions, and scripts specifically designed for the MRS UAV System, facilitating reproducible robotics research environments and workflows.",
      "domains": [
        "AI6",
        "AI6-01",
        "Robotics"
      ],
      "subtask_category": [
        "environment_management",
        "robotics_simulation"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/ctu-mrs/mrs_apptainer",
      "help_website": [],
      "license": null,
      "tags": [
        "apptainer",
        "robotics",
        "uav",
        "reproducible-research"
      ],
      "id": 122
    },
    {
      "name": "ck-docker",
      "one_line_profile": "Collective Knowledge extension for Docker automation",
      "detailed_description": "Extension for the Collective Knowledge (CK) framework to automate Docker build, run, and push functions, enabling collaborative and reproducible research workflows and artifact management.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "reproducible_research",
        "artifact_management"
      ],
      "application_level": "workflow",
      "primary_language": "Dockerfile",
      "repo_url": "https://github.com/ctuning/ck-docker",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "collective-knowledge",
        "reproducible-research",
        "docker",
        "artifact-evaluation"
      ],
      "id": 123
    },
    {
      "name": "Omnia Artifactory",
      "one_line_profile": "HPC cluster container management and automation tools",
      "detailed_description": "Part of the Omnia framework, providing tools to build, manage, and deploy containerized services for HPC clusters, including Ansible-based provisioning and automated image creation.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "hpc_provisioning",
        "cluster_management"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/dell/omnia-artifactory",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "ansible",
        "container-deployment",
        "dell-omnia"
      ],
      "id": 124
    },
    {
      "name": "Phobos",
      "one_line_profile": "Blender add-on for robot model creation (URDF/SDF)",
      "detailed_description": "An add-on for Blender that enables the creation and editing of URDF, SDF, and SMURF robot models in a WYSIWYG environment for robotics simulation and research.",
      "domains": [
        "Robotics",
        "Modeling"
      ],
      "subtask_category": [
        "robot_modeling",
        "simulation_setup"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dfki-ric/phobos",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "blender",
        "urdf",
        "robotics",
        "simulation"
      ],
      "id": 125
    },
    {
      "name": "wfl",
      "one_line_profile": "Simple job workflow library for Go supporting HPC/Containers",
      "detailed_description": "A Go library for creating job workflows that can run in processes, containers, pods, or HPC jobs (supporting DRMAA), facilitating scientific workflow management.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "workflow_management",
        "job_scheduling"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/dgruber/wfl",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "workflow",
        "hpc",
        "drmaa",
        "go"
      ],
      "id": 126
    },
    {
      "name": "neuron_poker",
      "one_line_profile": "Texas Hold'em RL environment",
      "detailed_description": "A reinforcement learning environment for Texas Hold'em poker, based on keras-rl, used for AI research in game theory and decision making.",
      "domains": [
        "AI_Research",
        "Reinforcement_Learning"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "game_simulation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dickreuter/neuron_poker",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "reinforcement-learning",
        "poker",
        "openai-gym",
        "ai-research"
      ],
      "id": 127
    },
    {
      "name": "poetry2conda",
      "one_line_profile": "Tool to convert Poetry projects to Conda environments",
      "detailed_description": "A utility that converts Python pyproject.toml configuration files into Conda environment.yaml files, bridging standard Python packaging with the scientific Conda ecosystem.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "dependency_management",
        "environment_conversion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dojeda/poetry2conda",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "poetry",
        "conda",
        "python",
        "dependency-management"
      ],
      "id": 128
    },
    {
      "name": "earth-analytics-python-env",
      "one_line_profile": "Conda environment and Docker container for Earth and environmental science",
      "detailed_description": "A pre-configured Conda environment and Docker container designed to support Python-based workflows in earth and environmental data science. It ensures reproducibility by providing a consistent set of libraries for geospatial analysis and data processing.",
      "domains": [
        "AI6",
        "AI6-01",
        "Earth Science"
      ],
      "subtask_category": [
        "environment_management",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/earthlab/earth-analytics-python-env",
      "help_website": [
        "https://www.earthdatascience.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "docker",
        "earth-science",
        "reproducibility"
      ],
      "id": 129
    },
    {
      "name": "JSC EasyBuild Repository",
      "one_line_profile": "Jülich Supercomputing Centre's EasyBuild configuration repository",
      "detailed_description": "The public repository of EasyBuild configuration files (easyconfigs) and custom blocks used by the Jülich Supercomputing Centre (JSC). It enables the reproduction of the scientific software stack deployed on JSC's HPC systems.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "package_management",
        "environment_deployment"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/easybuilders/JSC",
      "help_website": [
        "https://easybuild.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "hpc",
        "easybuild",
        "configuration",
        "jsc"
      ],
      "id": 130
    },
    {
      "name": "EasyBuild",
      "one_line_profile": "Software build and installation framework for HPC systems",
      "detailed_description": "A software installation framework written in Python that allows for the structured, robust, and reproducible building of scientific software stacks on High Performance Computing (HPC) systems. It automates the compilation and management of dependencies.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "package_management",
        "compilation",
        "environment_management"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/easybuilders/easybuild",
      "help_website": [
        "https://easybuild.io/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "hpc",
        "build-automation",
        "scientific-software",
        "python"
      ],
      "id": 131
    },
    {
      "name": "easybuild-easyblocks",
      "one_line_profile": "Collection of Python modules for EasyBuild software installation logic",
      "detailed_description": "A collection of 'easyblocks' that implement the specific build and installation logic for various scientific software packages within the EasyBuild framework. These blocks define how to configure, build, and install complex scientific applications.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "package_management",
        "build_automation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/easybuilders/easybuild-easyblocks",
      "help_website": [
        "https://docs.easybuild.io/en/latest/Writing_easyblocks.html"
      ],
      "license": "GPL-2.0",
      "tags": [
        "easybuild",
        "hpc",
        "build-recipes"
      ],
      "id": 132
    },
    {
      "name": "easybuild-easyconfigs",
      "one_line_profile": "Collection of build configuration files for EasyBuild",
      "detailed_description": "A comprehensive collection of 'easyconfig' files that describe which scientific software versions to build, using which toolchains and dependencies. It serves as the central database of recipes for the EasyBuild ecosystem.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "package_management",
        "reproducibility"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/easybuilders/easybuild-easyconfigs",
      "help_website": [
        "https://easybuild.io/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "easybuild",
        "configuration",
        "hpc",
        "recipes"
      ],
      "id": 133
    },
    {
      "name": "easybuild-framework",
      "one_line_profile": "Core framework for the EasyBuild software installation system",
      "detailed_description": "The core Python framework of EasyBuild that provides the functionality to parse easyconfigs, load easyblocks, and execute the build and installation process for scientific software on HPC infrastructure.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "package_management",
        "framework"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/easybuilders/easybuild-framework",
      "help_website": [
        "https://easybuild.io/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "hpc",
        "python",
        "installation-framework"
      ],
      "id": 134
    },
    {
      "name": "eb-singularity",
      "one_line_profile": "Integration tools for EasyBuild and Singularity containers",
      "detailed_description": "A set of tools and scripts to integrate EasyBuild with Singularity (Apptainer), enabling the generation of scientific containers directly from EasyBuild recipes for reproducible HPC workflows.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "containerization",
        "image_generation"
      ],
      "application_level": "workflow",
      "primary_language": "Roff",
      "repo_url": "https://github.com/easybuilders/eb-singularity",
      "help_website": [
        "https://easybuild.io/"
      ],
      "license": null,
      "tags": [
        "singularity",
        "easybuild",
        "containers",
        "hpc"
      ],
      "id": 135
    },
    {
      "name": "OpenArm",
      "one_line_profile": "Open-source humanoid arm for physical AI research",
      "detailed_description": "A low-cost, open-source robotic arm platform designed for research in physical AI, teleoperation, and contact-rich manipulation. It provides the hardware design and software interfaces necessary for training and testing embodied AI agents.",
      "domains": [
        "Robotics",
        "Embodied AI"
      ],
      "subtask_category": [
        "scientific_modeling",
        "data_generation"
      ],
      "application_level": "platform",
      "primary_language": "MDX",
      "repo_url": "https://github.com/enactic/openarm",
      "help_website": [
        "https://open-arm.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "robotics",
        "physical-ai",
        "hardware",
        "research-platform"
      ],
      "id": 136
    },
    {
      "name": "EPFL-SCITAS Spack Config",
      "one_line_profile": "Spack configuration for EPFL SCITAS HPC deployment",
      "detailed_description": "A repository containing site-specific configurations, package lists, and helper scripts for deploying the Spack package manager at the EPFL SCITAS supercomputing facility. It facilitates the reproducible deployment of scientific software in that specific HPC environment.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "environment_management",
        "package_deployment"
      ],
      "application_level": "dataset",
      "primary_language": "Jinja",
      "repo_url": "https://github.com/epfl-scitas/spack-packagelist",
      "help_website": [
        "https://spack.io"
      ],
      "license": null,
      "tags": [
        "spack",
        "hpc",
        "epfl",
        "configuration"
      ],
      "id": 137
    },
    {
      "name": "svd3",
      "one_line_profile": "Fast 3x3 singular value decomposition library",
      "detailed_description": "A specialized library for performing fast singular value decomposition (SVD), diagonalization, and QR decomposition of 3x3 matrices. This is a critical low-level kernel for many physics simulations, computer graphics, and mechanics problems.",
      "domains": [
        "Scientific Computing",
        "Physics"
      ],
      "subtask_category": [
        "scientific_data_analysis",
        "linear_algebra"
      ],
      "application_level": "library",
      "primary_language": "Mathematica",
      "repo_url": "https://github.com/ericjang/svd3",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "svd",
        "linear-algebra",
        "mathematica",
        "physics-simulation"
      ],
      "id": 138
    },
    {
      "name": "CSCS Production Scripts",
      "one_line_profile": "User scripts and tools for CSCS HPC environment",
      "detailed_description": "A collection of utility scripts and tools for users of the Swiss National Supercomputing Centre (CSCS). It includes helpers for job submission, environment setup, and data management specific to CSCS scientific infrastructure.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "job_management",
        "environment_setup"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/eth-cscs/production",
      "help_website": [
        "https://www.cscs.ch/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "hpc",
        "cscs",
        "scripts",
        "utility"
      ],
      "id": 139
    },
    {
      "name": "py2spack",
      "one_line_profile": "Converter from Python packages to Spack recipes",
      "detailed_description": "A tool that automates the conversion of standard Python packages (from PyPI) into Spack package recipes. It simplifies the process of adding new Python scientific libraries to the Spack ecosystem.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "package_management",
        "automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/eth-cscs/py2spack",
      "help_website": [
        "https://spack.io"
      ],
      "license": null,
      "tags": [
        "spack",
        "python",
        "pypi",
        "packaging"
      ],
      "id": 140
    },
    {
      "name": "Sarus",
      "one_line_profile": "OCI-compatible container engine for HPC environments",
      "detailed_description": "A container engine designed specifically for High Performance Computing (HPC) environments. It provides OCI compliance while addressing the unique security and performance requirements of HPC, such as support for MPI, GPU, and high-speed interconnects.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "containerization",
        "runtime"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/eth-cscs/sarus",
      "help_website": [
        "https://sarus.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "containers",
        "oci",
        "mpi"
      ],
      "id": 141
    },
    {
      "name": "spack-batteries-included",
      "one_line_profile": "Standalone Spack installer",
      "detailed_description": "A project aimed at installing the Spack package manager without relying on system dependencies, ensuring a self-contained and portable package management setup for scientific computing environments.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "package_management",
        "deployment"
      ],
      "application_level": "workflow",
      "primary_language": "C",
      "repo_url": "https://github.com/eth-cscs/spack-batteries-included",
      "help_website": [
        "https://spack.io"
      ],
      "license": "GPL-3.0",
      "tags": [
        "spack",
        "installation",
        "portability"
      ],
      "id": 142
    },
    {
      "name": "Habitat-Lab",
      "one_line_profile": "Modular library for training embodied AI agents",
      "detailed_description": "A modular high-level library designed to train embodied AI agents across a variety of tasks (like navigation and instruction following) and 3D environments. It serves as a standard platform for simulation-based AI research.",
      "domains": [
        "AI6",
        "Embodied AI"
      ],
      "subtask_category": [
        "scientific_modeling",
        "simulation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/habitat-lab",
      "help_website": [
        "https://aihabitat.org/"
      ],
      "license": "MIT",
      "tags": [
        "embodied-ai",
        "simulation",
        "reinforcement-learning",
        "robotics"
      ],
      "id": 143
    },
    {
      "name": "fastai-docker-containers",
      "one_line_profile": "Docker images for the fastai deep learning library",
      "detailed_description": "Official Docker containers for the fastai library, providing a reproducible and pre-configured environment for deep learning research and development. It simplifies the setup of GPU-accelerated AI workflows.",
      "domains": [
        "AI6",
        "AI6-01",
        "Deep Learning"
      ],
      "subtask_category": [
        "environment_management",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/fastai/docker-containers",
      "help_website": [
        "https://github.com/fastai/docker-containers"
      ],
      "license": "Apache-2.0",
      "tags": [
        "fastai",
        "docker",
        "deep-learning",
        "gpu"
      ],
      "id": 144
    },
    {
      "name": "easybuild.experimental",
      "one_line_profile": "Experimental contributions for EasyBuild",
      "detailed_description": "A repository for experimental or community-contributed EasyBuild configurations and blocks that are not yet part of the main stable release. It serves as a staging ground for new scientific software recipes.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "package_management",
        "experimentation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/fgeorgatos/easybuild.experimental",
      "help_website": [
        "https://easybuild.io/"
      ],
      "license": null,
      "tags": [
        "easybuild",
        "experimental",
        "hpc",
        "recipes"
      ],
      "id": 145
    },
    {
      "name": "easy_update",
      "one_line_profile": "Tool to update EasyBuild configuration files",
      "detailed_description": "A utility script to automate the updating of EasyBuild easyconfig files, specifically for R and Python bundles. It helps maintainers keep scientific software stacks up to date with minimal manual effort.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "package_management",
        "maintenance"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/fizwit/easy_update",
      "help_website": [],
      "license": null,
      "tags": [
        "easybuild",
        "automation",
        "maintenance",
        "python",
        "r"
      ],
      "id": 146
    },
    {
      "name": "nixpack",
      "one_line_profile": "Integration of Nix and Spack package managers",
      "detailed_description": "An experimental tool from the Flatiron Institute that aims to combine the strengths of the Nix package manager (reproducibility) and Spack (HPC optimization) for scientific software deployment.",
      "domains": [
        "AI6",
        "AI6-01",
        "HPC"
      ],
      "subtask_category": [
        "package_management",
        "reproducibility"
      ],
      "application_level": "workflow",
      "primary_language": "Nix",
      "repo_url": "https://github.com/flatironinstitute/nixpack",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nix",
        "spack",
        "hpc",
        "package-management"
      ],
      "id": 147
    },
    {
      "name": "copip",
      "one_line_profile": "Environment development overlays for Conda to facilitate reproducible scientific workflows",
      "detailed_description": "A tool designed to manage development overlays for Conda environments, allowing users to install packages in 'development mode' (editable installs) on top of existing Conda environments. This is particularly useful in scientific computing workflows where researchers need to modify libraries without breaking the base reproducible environment.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "reproducibility"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/fperez/copip",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "environment-management",
        "reproducibility",
        "python"
      ],
      "id": 148
    },
    {
      "name": "SegMamba",
      "one_line_profile": "Long-range sequential modeling Mamba for 3D medical image segmentation",
      "detailed_description": "A deep learning model based on the Mamba architecture designed for 3D medical image segmentation. It addresses the challenge of modeling long-range dependencies in volumetric medical data, providing a tool for scientific analysis of medical imaging datasets.",
      "domains": [
        "AI4S",
        "Medical Imaging"
      ],
      "subtask_category": [
        "image_segmentation",
        "medical_analysis"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/ge-xing/SegMamba",
      "help_website": [],
      "license": null,
      "tags": [
        "medical-imaging",
        "segmentation",
        "mamba",
        "deep-learning"
      ],
      "id": 149
    },
    {
      "name": "Popper",
      "one_line_profile": "Container-native task automation engine for scientific reproducibility",
      "detailed_description": "A tool for defining and executing container-native workflows, specifically designed to implement the 'Popper Convention' for scientific reproducibility. It allows researchers to automate experiments and validate results in a portable way using containers (Docker, Singularity).",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "workflow_automation",
        "reproducibility"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/getpopper/popper",
      "help_website": [
        "https://popper.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "reproducibility",
        "workflow",
        "containers",
        "scientific-computing"
      ],
      "id": 150
    },
    {
      "name": "GitLab HPC CI/CB",
      "one_line_profile": "GitLab runner scripts for HPC systems using Enroot and Slurm",
      "detailed_description": "A set of tools and scripts to enable Continuous Integration (CI) and Continuous Benchmarking (CB) on High Performance Computing (HPC) systems. It leverages Slurm for job scheduling and Enroot for containerization, facilitating automated testing of scientific software in HPC environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "hpc_workflow",
        "ci_cd"
      ],
      "application_level": "tool",
      "primary_language": "Shell",
      "repo_url": "https://github.com/ginkgo-project/gitlab-hpc-ci-cb",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "slurm",
        "enroot",
        "ci-cd",
        "gitlab"
      ],
      "id": 151
    },
    {
      "name": "docker-centos7-slurm",
      "one_line_profile": "Slurm Docker container for simulating HPC clusters",
      "detailed_description": "A Docker container setup that runs Slurm on CentOS 7, providing a simulated HPC environment. This tool is used by researchers and developers to develop and test HPC workflows and job submission scripts locally before deploying to actual supercomputers.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "hpc_simulation",
        "environment_simulation"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/giovtorres/docker-centos7-slurm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "hpc",
        "docker",
        "simulation"
      ],
      "id": 152
    },
    {
      "name": "HOOMD-blue",
      "one_line_profile": "Molecular dynamics and Monte Carlo soft matter simulation on GPUs",
      "detailed_description": "A general-purpose particle simulation toolkit optimized for GPUs. It performs molecular dynamics (MD) and Monte Carlo (MC) simulations of soft matter systems, widely used in physics, chemistry, and materials science research.",
      "domains": [
        "AI4S",
        "Physics",
        "Chemistry"
      ],
      "subtask_category": [
        "molecular_dynamics",
        "monte_carlo_simulation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/glotzerlab/hoomd-blue",
      "help_website": [
        "https://hoomd-blue.readthedocs.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "molecular-dynamics",
        "gpu-acceleration",
        "simulation",
        "soft-matter"
      ],
      "id": 153
    },
    {
      "name": "PyBOMBS",
      "one_line_profile": "Package management system for GNU Radio and scientific signal processing",
      "detailed_description": "The GNU Radio install management system (Python Build Overlay Managed Bundle System). It resolves dependencies and installs out-of-tree projects for GNU Radio, a key framework in scientific signal processing and radio astronomy.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "package_management",
        "environment_management"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/gnuradio/pybombs",
      "help_website": [
        "https://github.com/gnuradio/pybombs"
      ],
      "license": "GPL-3.0",
      "tags": [
        "gnu-radio",
        "package-manager",
        "signal-processing",
        "sdr"
      ],
      "id": 154
    },
    {
      "name": "OpenSpiel",
      "one_line_profile": "Framework for reinforcement learning and search in games",
      "detailed_description": "A collection of environments and algorithms for research in general reinforcement learning and search/planning in games. It serves as a platform for scientific research in AI, game theory, and multi-agent systems.",
      "domains": [
        "AI4S",
        "AI Research"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "game_theory",
        "simulation"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/google-deepmind/open_spiel",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reinforcement-learning",
        "game-theory",
        "ai-research",
        "deepmind"
      ],
      "id": 155
    },
    {
      "name": "containerize-conda",
      "one_line_profile": "Tool to convert Conda environments into Singularity containers",
      "detailed_description": "A utility that packages an existing Conda environment into a Singularity container (or a squashfs image). This bridges the gap between scientific package management (Conda) and HPC container runtimes (Singularity), ensuring reproducibility on supercomputers.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "containerization",
        "environment_management"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/grst/containerize-conda",
      "help_website": [],
      "license": null,
      "tags": [
        "conda",
        "singularity",
        "hpc",
        "reproducibility"
      ],
      "id": 156
    },
    {
      "name": "rstudio-server-conda",
      "one_line_profile": "Deployment tool for RStudio Server within Conda environments",
      "detailed_description": "A wrapper script and configuration to run RStudio Server inside a Conda environment. This allows data scientists to manage R versions and dependencies via Conda while using the standard RStudio IDE interface, facilitating reproducible data analysis environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "data_analysis_environment"
      ],
      "application_level": "tool",
      "primary_language": "Shell",
      "repo_url": "https://github.com/grst/rstudio-server-conda",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rstudio",
        "conda",
        "data-science",
        "reproducibility"
      ],
      "id": 157
    },
    {
      "name": "MCC",
      "one_line_profile": "Automated container cluster creation tool for scientific computing",
      "detailed_description": "My Container Cluster (MCC) is a tool developed by the GRyCAP research group to automate the creation of container-based computing clusters (using LXD). It is designed to support scientific computing workloads on cloud infrastructures.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "cluster_management",
        "cloud_computing"
      ],
      "application_level": "tool",
      "primary_language": "Shell",
      "repo_url": "https://github.com/grycap/mcc",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lxd",
        "cluster-management",
        "cloud-computing",
        "hpc"
      ],
      "id": 158
    },
    {
      "name": "Cobra",
      "one_line_profile": "Multi-modal Large Language Model extending Mamba for efficient inference",
      "detailed_description": "A Multi-modal Large Language Model (MLLM) that extends the Mamba architecture. It is designed for efficient inference in multi-modal tasks, serving as a scientific AI model for processing and analyzing multi-modal data.",
      "domains": [
        "AI4S",
        "AI Models"
      ],
      "subtask_category": [
        "inference",
        "multi_modal_analysis"
      ],
      "application_level": "model",
      "primary_language": "Python",
      "repo_url": "https://github.com/h-zhao1997/cobra",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mamba",
        "mllm",
        "multi-modal",
        "efficient-inference"
      ],
      "id": 159
    },
    {
      "name": "PDC (Proactive Data Containers)",
      "one_line_profile": "Object-centric data management system for HPC environments",
      "detailed_description": "Proactive Data Containers (PDC) is a runtime system and API designed for high-performance computing (HPC) environments. It provides object-centric data management services, allowing efficient data placement in memory/storage hierarchies, asynchronous data movement, and scalable metadata operations for scientific applications.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "data_management",
        "hpc_io"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/hpc-io/pdc",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "data-management",
        "object-storage",
        "parallel-io"
      ],
      "id": 160
    },
    {
      "name": "Project AirSim",
      "one_line_profile": "High-fidelity simulation platform for autonomous systems",
      "detailed_description": "Project AirSim is an advanced simulation platform designed for building, training, and testing autonomous systems (such as drones and robots) in realistic virtual environments. It supports physics-based simulation for generating synthetic scientific data for robotics and AI research.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "simulation",
        "synthetic_data_generation"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/iamaisim/ProjectAirSim",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "simulation",
        "robotics",
        "autonomous-systems",
        "synthetic-data"
      ],
      "id": 161
    },
    {
      "name": "udocker",
      "one_line_profile": "User-space container execution tool for HPC systems",
      "detailed_description": "udocker is a basic user tool to execute simple Docker containers in batch or interactive systems without root privileges. It is specifically designed for High Performance Computing (HPC) environments where users lack administrative rights, enabling the use of containerized scientific applications.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_runtime",
        "environment_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/indigo-dc/udocker",
      "help_website": [
        "https://indigo-dc.github.io/udocker/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "docker",
        "containers",
        "user-space"
      ],
      "id": 162
    },
    {
      "name": "NVIDIA Isaac Sim",
      "one_line_profile": "Robotics simulation and synthetic data generation platform",
      "detailed_description": "NVIDIA Isaac Sim is a simulation platform built on NVIDIA Omniverse for developing, testing, and managing AI-based robots. It provides photorealistic, physically accurate virtual environments for scientific simulation and synthetic data generation in robotics research.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "simulation",
        "robotics_modeling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/isaac-sim/IsaacSim",
      "help_website": [
        "https://developer.nvidia.com/isaac-sim"
      ],
      "license": "NOASSERTION",
      "tags": [
        "simulation",
        "robotics",
        "omniverse",
        "synthetic-data"
      ],
      "id": 163
    },
    {
      "name": "conda-minify",
      "one_line_profile": "Tool for minifying Conda environment specifications",
      "detailed_description": "A library and tool to create minified or relaxed versions of Conda environment specifications. It facilitates the sharing and reproduction of scientific computing environments across different platforms by reducing strict dependency pinning issues.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "reproducibility"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jamespreed/conda-minify",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "conda",
        "reproducibility",
        "environment-management"
      ],
      "id": 164
    },
    {
      "name": "Berryconda",
      "one_line_profile": "Conda distribution for Raspberry Pi (ARM)",
      "detailed_description": "Berryconda is a Conda-based Python distribution specifically for the Raspberry Pi. It enables the management of scientific Python stacks (NumPy, SciPy, Pandas, etc.) on ARM-based edge devices, facilitating scientific computing and data collection in IoT/edge scenarios.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "edge_computing"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/jjhelmus/berryconda",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "raspberry-pi",
        "arm",
        "scientific-computing"
      ],
      "id": 165
    },
    {
      "name": "apptainer-in-docker",
      "one_line_profile": "Utility to run Apptainer (Singularity) within Docker containers for CI/CD workflows",
      "detailed_description": "A specialized container image and utility that enables running Apptainer (formerly Singularity), the standard container runtime for High Performance Computing (HPC), inside Docker environments. This is crucial for building and testing scientific containers in standard CI/CD pipelines.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_management",
        "reproducibility"
      ],
      "application_level": "service",
      "primary_language": "Dockerfile",
      "repo_url": "https://github.com/kaczmarj/apptainer-in-docker",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "apptainer",
        "singularity",
        "hpc",
        "ci-cd",
        "docker"
      ],
      "id": 166
    },
    {
      "name": "pymssa",
      "one_line_profile": "Python implementation of Multivariate Singular Spectrum Analysis (MSSA)",
      "detailed_description": "A Python library implementing Multivariate Singular Spectrum Analysis (MSSA), a statistical technique used for time series analysis, decomposition, and forecasting in scientific domains such as geophysics and climate science.",
      "domains": [
        "Scientific Analysis"
      ],
      "subtask_category": [
        "time_series_analysis",
        "statistics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kieferk/pymssa",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mssa",
        "time-series",
        "statistics",
        "analysis"
      ],
      "id": 167
    },
    {
      "name": "Mycodo",
      "one_line_profile": "Environmental monitoring and regulation system for research and automation",
      "detailed_description": "An open-source software system for environmental monitoring and regulation, designed to run on the Raspberry Pi. It is widely used in scientific research for lab automation, hydroponics, and biological experiments requiring precise control of environmental conditions.",
      "domains": [
        "Lab Automation",
        "Scientific Data Generation"
      ],
      "subtask_category": [
        "environmental_monitoring",
        "lab_automation",
        "data_acquisition"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/kizniche/Mycodo",
      "help_website": [
        "https://kizniche.github.io/Mycodo/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "environmental-monitoring",
        "raspberry-pi",
        "lab-automation",
        "hydroponics",
        "sensors"
      ],
      "id": 168
    },
    {
      "name": "MultiModalMamba",
      "one_line_profile": "Implementation of Multi-Modal Mamba model for AI research",
      "detailed_description": "A PyTorch implementation of a Multi-Modal Model fusing Vision Transformer (ViT) with Mamba (State Space Model). It serves as a research tool for exploring efficient multi-modal representation learning.",
      "domains": [
        "AI4S",
        "Deep Learning"
      ],
      "subtask_category": [
        "multimodal_modeling",
        "deep_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kyegomez/MultiModalMamba",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mamba",
        "transformer",
        "multimodal",
        "deep-learning"
      ],
      "id": 169
    },
    {
      "name": "VisionMamba",
      "one_line_profile": "Implementation of Vision Mamba for efficient visual representation learning",
      "detailed_description": "A PyTorch implementation of the Vision Mamba architecture, offering a more efficient alternative to Transformers for visual representation learning tasks in AI research.",
      "domains": [
        "AI4S",
        "Computer Vision"
      ],
      "subtask_category": [
        "computer_vision",
        "deep_learning",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kyegomez/VisionMamba",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vision-mamba",
        "computer-vision",
        "deep-learning",
        "ssm"
      ],
      "id": 170
    },
    {
      "name": "Backend.AI",
      "one_line_profile": "Container-based computing cluster platform for AI and HPC",
      "detailed_description": "A streamlined, container-based computing cluster platform designed to host machine learning frameworks and support heterogeneous accelerators (CUDA, ROCm, TPU, IPU). It manages resources and environments for scientific computing and AI training/inference.",
      "domains": [
        "AI6",
        "HPC"
      ],
      "subtask_category": [
        "cluster_management",
        "compute_orchestration",
        "environment_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/lablup/backend.ai",
      "help_website": [
        "https://docs.backend.ai/"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "hpc",
        "gpu-cluster",
        "container-orchestration",
        "machine-learning-platform"
      ],
      "id": 171
    },
    {
      "name": "libigl-python-bindings",
      "one_line_profile": "Python bindings for the libigl geometry processing library",
      "detailed_description": "Provides Python access to libigl, a simple C++ geometry processing library. It is widely used in computer graphics and scientific modeling for tasks such as meshing, parameterization, and geometric analysis.",
      "domains": [
        "Scientific Computing",
        "Geometry Processing"
      ],
      "subtask_category": [
        "geometry_processing",
        "modeling",
        "mesh_analysis"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/libigl/libigl-python-bindings",
      "help_website": [
        "https://libigl.github.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "geometry-processing",
        "mesh",
        "graphics",
        "python-bindings"
      ],
      "id": 172
    },
    {
      "name": "venvstacks",
      "one_line_profile": "Tool for creating portable Python virtual environment stacks",
      "detailed_description": "A utility to create layered, portable Python virtual environments. This is particularly useful for scientific workflows requiring reproducible environments that can be distributed across different machines or containers without full containerization overhead.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "reproducibility"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/lmstudio-ai/venvstacks",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "python",
        "virtualenv",
        "reproducibility",
        "packaging"
      ],
      "id": 173
    },
    {
      "name": "Crocoddyl",
      "one_line_profile": "Optimal control library for robot control and physics simulation",
      "detailed_description": "Crocoddyl (Contact RObot COntrol by Differential DYnamic Library) is an optimal control library for robot control under contact sequence. It uses efficient Differential Dynamic Programming (DDP) algorithms for multi-body dynamics and physics simulations.",
      "domains": [
        "Robotics",
        "Physics Simulation"
      ],
      "subtask_category": [
        "optimal_control",
        "simulation",
        "trajectory_optimization"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/loco-3d/crocoddyl",
      "help_website": [
        "https://gepettoweb.laas.fr/cms/crocoddyl/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "optimal-control",
        "robotics",
        "ddp",
        "physics-simulation"
      ],
      "id": 174
    },
    {
      "name": "Agent Studio",
      "one_line_profile": "Environment and benchmark platform for general virtual agents",
      "detailed_description": "A comprehensive platform providing environments, tools, and benchmarks for evaluating general virtual agents. It supports multimodal interactions and is used for AI research in agent behavior and task completion.",
      "domains": [
        "AI Research",
        "Agent Evaluation"
      ],
      "subtask_category": [
        "agent_evaluation",
        "benchmark",
        "simulation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ltzheng/agent-studio",
      "help_website": [
        "https://skyworkai.github.io/agent-studio/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "ai-agents",
        "benchmark",
        "multimodal",
        "virtual-environment"
      ],
      "id": 175
    },
    {
      "name": "boa",
      "one_line_profile": "Fast Conda package builder using Mamba",
      "detailed_description": "A package builder for the Conda ecosystem that utilizes Mamba for dependency resolution. It significantly speeds up the creation of scientific packages compared to traditional Conda build tools.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "package_management",
        "build_system"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/mamba-org/boa",
      "help_website": [
        "https://github.com/mamba-org/boa"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "mamba",
        "package-build",
        "scientific-computing"
      ],
      "id": 176
    },
    {
      "name": "gator",
      "one_line_profile": "Conda environment management extension for Jupyter",
      "detailed_description": "A JupyterLab extension that provides a graphical interface for managing Conda/Mamba environments and packages directly within the scientific notebook interface.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "ide_integration"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/mamba-org/gator",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "jupyter",
        "conda",
        "mamba",
        "environment-manager"
      ],
      "id": 177
    },
    {
      "name": "Mamba",
      "one_line_profile": "Fast, cross-platform package manager for scientific computing",
      "detailed_description": "A reimplementation of the Conda package manager in C++. It offers parallel downloading of repository data and package files, and much faster dependency solving, serving as a critical infrastructure tool for scientific Python environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "package_management",
        "environment_management"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/mamba-org/mamba",
      "help_website": [
        "https://mamba.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "package-manager",
        "conda",
        "scientific-computing",
        "dependency-solver"
      ],
      "id": 178
    },
    {
      "name": "micromamba-docker",
      "one_line_profile": "Docker utilities for Micromamba-based scientific containers",
      "detailed_description": "Provides base images and utilities for building lightweight Docker containers using Micromamba. It is essential for creating reproducible and efficient containerized scientific environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "containerization",
        "environment_management"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/mamba-org/micromamba-docker",
      "help_website": [
        "https://github.com/mamba-org/micromamba-docker"
      ],
      "license": "Apache-2.0",
      "tags": [
        "docker",
        "micromamba",
        "containers",
        "reproducibility"
      ],
      "id": 179
    },
    {
      "name": "Quetz",
      "one_line_profile": "Open-source server for Conda package repositories",
      "detailed_description": "A server implementation for hosting Conda packages. It allows scientific organizations to manage their own package channels and artifacts, supporting the distribution of scientific software.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "package_distribution",
        "repository_management"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/mamba-org/quetz",
      "help_website": [
        "https://quetz.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "conda-server",
        "package-repository",
        "scientific-software"
      ],
      "id": 180
    },
    {
      "name": "vscode-micromamba",
      "one_line_profile": "VS Code extension for Micromamba environments",
      "detailed_description": "Integrates Micromamba into Visual Studio Code, allowing researchers and developers to easily create, activate, and manage scientific Python environments directly from their editor.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "ide_integration"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/mamba-org/vscode-micromamba",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "vscode",
        "micromamba",
        "environment-manager"
      ],
      "id": 181
    },
    {
      "name": "Sublime Text Conda",
      "one_line_profile": "Conda environment management for Sublime Text",
      "detailed_description": "A plugin for Sublime Text 3 that enables users to work with Conda environments, including activation, deactivation, and package management, facilitating scientific development workflows.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "ide_integration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/mandeep/sublime-text-conda",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "sublime-text",
        "conda",
        "environment-manager"
      ],
      "id": 182
    },
    {
      "name": "condax",
      "one_line_profile": "Isolated execution of Conda-packaged applications",
      "detailed_description": "A tool similar to pipx but for Conda. It allows users to install and run scientific applications packaged with Conda in isolated environments, preventing dependency conflicts.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "application_isolation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/mariusvniekerk/condax",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "conda",
        "cli-tools",
        "isolation",
        "package-management"
      ],
      "id": 183
    },
    {
      "name": "conda-move",
      "one_line_profile": "Utility to relocate Conda environments",
      "detailed_description": "A shell script utility to move Conda environments from one directory to another, handling the necessary path updates. Useful for reorganizing scientific computing environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "system_administration"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/matthuska/conda-move",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "conda",
        "environment-migration",
        "shell-script"
      ],
      "id": 184
    },
    {
      "name": "Syndeo",
      "one_line_profile": "Tool for running massively parallel Ray jobs on SLURM with Apptainer",
      "detailed_description": "Syndeo bridges modern AI frameworks (Ray) with traditional scientific HPC schedulers (SLURM) using secure containerization (Apptainer), enabling scalable AI4S workflows.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "job_scheduling",
        "distributed_computing",
        "hpc_integration"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/mit-ll/Syndeo",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "ray",
        "slurm",
        "apptainer",
        "hpc"
      ],
      "id": 185
    },
    {
      "name": "MLRun",
      "one_line_profile": "Open source MLOps platform for managing continuous ML applications",
      "detailed_description": "MLRun provides an open MLOps orchestration framework to manage the lifecycle of machine learning applications, including data preparation, training, and deployment, facilitating reproducibility in data science.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "pipeline_orchestration",
        "experiment_tracking",
        "model_lifecycle"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/mlrun/mlrun",
      "help_website": [
        "https://docs.mlrun.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "orchestration",
        "reproducibility"
      ],
      "id": 186
    },
    {
      "name": "repo2apptainer",
      "one_line_profile": "Wrapper to convert repo2docker environments into Apptainer images for HPC",
      "detailed_description": "A tool developed by NCAR to facilitate reproducible science by converting Jupyter-ready repositories (repo2docker format) into Apptainer/Singularity images compatible with High Performance Computing environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "reproducibility",
        "environment_management",
        "image_build"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ncar-xdev/repo2apptainer",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "apptainer",
        "jupyter",
        "reproducibility"
      ],
      "id": 187
    },
    {
      "name": "Nextflow",
      "one_line_profile": "Workflow orchestration engine for data-driven computational pipelines",
      "detailed_description": "A domain-specific language and runtime environment for creating scalable, portable, and reproducible scientific workflows, widely adopted in bioinformatics and data-intensive science.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "pipeline_orchestration",
        "workflow_management"
      ],
      "application_level": "workflow",
      "primary_language": "Groovy",
      "repo_url": "https://github.com/nextflow-io/nextflow",
      "help_website": [
        "https://www.nextflow.io/docs/latest/index.html"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow",
        "bioinformatics",
        "pipeline",
        "reproducibility"
      ],
      "id": 188
    },
    {
      "name": "Nextstrain CLI",
      "one_line_profile": "CLI tool for running and visualizing pathogen evolution analysis",
      "detailed_description": "The command-line interface for Nextstrain, enabling consistent execution of pathogen build pipelines and visualization (Augur/Auspice) across different computing environments (Docker, Conda, AWS Batch).",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "epidemiology",
        "phylogenetics",
        "visualization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/nextstrain/cli",
      "help_website": [
        "https://docs.nextstrain.org/en/latest/guides/install/cli.html"
      ],
      "license": "MIT",
      "tags": [
        "epidemiology",
        "pathogen",
        "visualization",
        "cli"
      ],
      "id": 189
    },
    {
      "name": "Sarek",
      "one_line_profile": "Analysis pipeline for germline and somatic variant calling",
      "detailed_description": "A comprehensive Nextflow pipeline for detecting germline or somatic variants from Whole Genome Sequencing (WGS) or targeted sequencing data, handling pre-processing, variant calling, and annotation.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "variant_calling",
        "genomics",
        "bioinformatics"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/nf-core/sarek",
      "help_website": [
        "https://nf-co.re/sarek"
      ],
      "license": "MIT",
      "tags": [
        "genomics",
        "wgs",
        "variant-calling",
        "nf-core"
      ],
      "id": 190
    },
    {
      "name": "PyGame Learning Environment (PLE)",
      "one_line_profile": "Reinforcement learning environment based on PyGame",
      "detailed_description": "A framework that provides a learning environment for Reinforcement Learning agents using PyGame, allowing the simulation of games for AI training and evaluation.",
      "domains": [
        "AI4",
        "AI4-01"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "simulation_environment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ntasfi/PyGame-Learning-Environment",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "reinforcement-learning",
        "pygame",
        "simulation",
        "ai-training"
      ],
      "id": 191
    },
    {
      "name": "conda-depgraph",
      "one_line_profile": "Visualization tool for Conda environment dependencies",
      "detailed_description": "A command-line utility designed to generate and plot the dependency graph of a Conda environment, aiding in the management and debugging of complex scientific software environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "dependency_visualization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/omegacen/conda-depgraph",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "conda",
        "dependency-graph",
        "visualization",
        "environment-management"
      ],
      "id": 192
    },
    {
      "name": "Open-CE",
      "one_line_profile": "Build recipes and environment definitions for AI/HPC packages",
      "detailed_description": "A community-driven project providing recipes and tools to build and distribute Python and binary packages for the Open Cognitive Environment, focusing on AI, Machine Learning, and Deep Learning frameworks on HPC architectures.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "package_management",
        "build_system"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/open-ce/open-ce",
      "help_website": [
        "https://open-ce.github.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "conda",
        "ai-infrastructure",
        "build-system"
      ],
      "id": 193
    },
    {
      "name": "leafmap",
      "one_line_profile": "Interactive geospatial analysis and mapping library",
      "detailed_description": "A Python package for interactive mapping and geospatial analysis with minimal coding in a Jupyter environment, supporting various mapping backends and data formats for scientific geospatial research.",
      "domains": [
        "AI4",
        "AI4-03"
      ],
      "subtask_category": [
        "geospatial_analysis",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/opengeos/leafmap",
      "help_website": [
        "https://leafmap.org"
      ],
      "license": "MIT",
      "tags": [
        "geospatial",
        "mapping",
        "gis",
        "jupyter"
      ],
      "id": 194
    },
    {
      "name": "poetry-kernel",
      "one_line_profile": "Jupyter kernel for Poetry-managed environments",
      "detailed_description": "A tool that creates a Jupyter kernel for Python projects managed by Poetry, facilitating reproducible scientific computing workflows within Jupyter notebooks.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "reproducibility"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/pathbird/poetry-kernel",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "jupyter",
        "poetry",
        "reproducibility",
        "python-environment"
      ],
      "id": 195
    },
    {
      "name": "PLIP",
      "one_line_profile": "Protein-Ligand Interaction Profiler",
      "detailed_description": "A tool to analyze and visualize non-covalent protein-ligand interactions in PDB files, widely used in structural biology and drug discovery.",
      "domains": [
        "AI4",
        "AI4-04"
      ],
      "subtask_category": [
        "interaction_analysis",
        "structure_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/pharmai/plip",
      "help_website": [
        "https://plip-tool.biotec.tu-dresden.de/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "protein-ligand",
        "structural-biology",
        "bioinformatics",
        "interaction-profiling"
      ],
      "id": 196
    },
    {
      "name": "Archiconda3",
      "one_line_profile": "Conda distribution for ARM64 devices",
      "detailed_description": "A lightweight Anaconda environment distribution specifically designed for ARM64 devices (like Raspberry Pi, Jetson), enabling scientific computing stacks on edge hardware.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "distribution"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/piyoki/archiconda3",
      "help_website": [],
      "license": null,
      "tags": [
        "conda",
        "arm64",
        "scientific-computing",
        "environment-distribution"
      ],
      "id": 197
    },
    {
      "name": "pixi",
      "one_line_profile": "Package management tool for reproducible scientific environments based on the Conda ecosystem",
      "detailed_description": "Pixi is a package manager built on top of the Conda ecosystem that focuses on project-local environments and reproducibility. It allows developers and scientists to manage dependencies and environments declaratively, ensuring consistent execution across different machines, which is critical for scientific reproducibility.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/prefix-dev/pixi",
      "help_website": [
        "https://pixi.sh/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "package-manager",
        "reproducibility",
        "environment-management"
      ],
      "id": 198
    },
    {
      "name": "rattler-build",
      "one_line_profile": "High-performance builder for Conda packages",
      "detailed_description": "rattler-build is a universal and fast tool for building Conda packages. It serves as a modern replacement for conda-build, enabling the creation of binary artifacts for scientific software across multiple platforms, which is essential for the distribution of AI4S tools.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "package_building",
        "distribution"
      ],
      "application_level": "tool",
      "primary_language": "Rust",
      "repo_url": "https://github.com/prefix-dev/rattler-build",
      "help_website": [
        "https://prefix.dev/docs/rattler-build"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "conda",
        "build-tool",
        "packaging"
      ],
      "id": 199
    },
    {
      "name": "PRIMME",
      "one_line_profile": "High-performance library for solving large sparse eigenvalue and singular value problems",
      "detailed_description": "PRIMME (PReconditioned Iterative MultiMethod Eigensolver) is a high-performance library for computing a few eigenvalues/eigenvectors and singular values/vectors of large, sparse matrices. It is widely used in scientific computing applications such as quantum physics, chemistry, and structural mechanics.",
      "domains": [
        "Math",
        "Physics"
      ],
      "subtask_category": [
        "numerical_solver",
        "eigenvalue_problem"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/primme/primme",
      "help_website": [
        "https://www.cs.wm.edu/~andreas/software/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "eigenvalues",
        "sparse-matrices",
        "numerical-linear-algebra",
        "hpc"
      ],
      "id": 200
    },
    {
      "name": "Bender",
      "one_line_profile": "Dependency management tool for hardware design and verification projects",
      "detailed_description": "Bender is a dependency management tool specifically designed for hardware description languages (SystemVerilog, VHDL). It manages IP cores and verification components, facilitating reproducible hardware design workflows in research and engineering (e.g., RISC-V research).",
      "domains": [
        "Electronic Engineering",
        "AI6"
      ],
      "subtask_category": [
        "dependency_management",
        "hardware_design"
      ],
      "application_level": "tool",
      "primary_language": "Rust",
      "repo_url": "https://github.com/pulp-platform/bender",
      "help_website": [
        "https://github.com/pulp-platform/bender"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hardware-design",
        "dependency-manager",
        "eda",
        "risc-v"
      ],
      "id": 201
    },
    {
      "name": "PyAMG",
      "one_line_profile": "Algebraic Multigrid (AMG) solvers for large sparse linear systems",
      "detailed_description": "PyAMG is a library of Algebraic Multigrid (AMG) solvers for solving large sparse linear systems of equations. It provides implementations of Ruge-Stuben (RS) and Smoothed Aggregation (SA) AMG, commonly used in scientific simulations involving partial differential equations.",
      "domains": [
        "Math",
        "Physics"
      ],
      "subtask_category": [
        "numerical_solver",
        "linear_algebra"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pyamg/pyamg",
      "help_website": [
        "https://pyamg.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "multigrid",
        "solver",
        "sparse-matrices",
        "pde"
      ],
      "id": 202
    },
    {
      "name": "PyMTL3",
      "one_line_profile": "Python-based framework for hardware generation, simulation, and verification",
      "detailed_description": "PyMTL3 is a framework for multi-level hardware modeling. It allows researchers to design, simulate, and verify hardware components using Python, bridging the gap between high-level modeling and low-level RTL implementation.",
      "domains": [
        "Electronic Engineering",
        "Computer Science"
      ],
      "subtask_category": [
        "hardware_simulation",
        "modeling"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/pymtl/pymtl3",
      "help_website": [
        "https://pymtl3.readthedocs.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "hardware-simulation",
        "verilog",
        "modeling",
        "eda"
      ],
      "id": 203
    },
    {
      "name": "Prosodic",
      "one_line_profile": "Metrical-phonological parser for linguistic analysis",
      "detailed_description": "Prosodic is a scientific tool for the analysis of language prosody. It parses text to determine its metrical structure, useful in linguistics and digital humanities research for analyzing poetry, speech rhythm, and phonology.",
      "domains": [
        "Linguistics",
        "Digital Humanities"
      ],
      "subtask_category": [
        "text_analysis",
        "phonological_parsing"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/quadrismegistus/prosodic",
      "help_website": [
        "https://github.com/quadrismegistus/prosodic"
      ],
      "license": "GPL-3.0",
      "tags": [
        "linguistics",
        "nlp",
        "phonology",
        "meter"
      ],
      "id": 204
    },
    {
      "name": "FireHPC",
      "one_line_profile": "Container-based HPC cluster emulator for workflow testing",
      "detailed_description": "FireHPC is a tool designed to instantly emulate an HPC cluster using containers. It allows researchers and system administrators to test HPC workflows, schedulers, and configurations in a reproducible local environment without needing access to a physical supercomputer.",
      "domains": [
        "AI6",
        "HPC"
      ],
      "subtask_category": [
        "simulation",
        "infrastructure_testing"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/rackslab/FireHPC",
      "help_website": [
        "https://github.com/rackslab/FireHPC"
      ],
      "license": "GPL-3.0",
      "tags": [
        "hpc",
        "emulation",
        "containers",
        "cluster"
      ],
      "id": 205
    },
    {
      "name": "radioconda-installer",
      "one_line_profile": "Software radio distribution and environment manager based on Conda",
      "detailed_description": "Radioconda is a distribution of software-defined radio (SDR) tools packaged with Conda. This installer sets up a reproducible environment containing essential tools for radio science and signal processing research, such as GNU Radio and various hardware drivers.",
      "domains": [
        "Signal Processing",
        "Physics"
      ],
      "subtask_category": [
        "environment_management",
        "signal_processing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/radioconda/radioconda-installer",
      "help_website": [
        "https://github.com/radioconda/radioconda-installer"
      ],
      "license": "NOASSERTION",
      "tags": [
        "sdr",
        "conda",
        "radio-astronomy",
        "signal-processing"
      ],
      "id": 206
    },
    {
      "name": "OpenRAVE",
      "one_line_profile": "Environment for testing and developing robotics motion planning algorithms",
      "detailed_description": "OpenRAVE (Open Robotics Automation Virtual Environment) is a platform for robotics research. It provides an environment for testing, developing, and deploying motion planning algorithms, focusing on simulation and analysis of kinematic and geometric constraints.",
      "domains": [
        "Robotics"
      ],
      "subtask_category": [
        "simulation",
        "motion_planning"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/rdiankov/openrave",
      "help_website": [
        "http://openrave.org/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "robotics",
        "simulation",
        "motion-planning",
        "kinematics"
      ],
      "id": 207
    },
    {
      "name": "poetry-conda",
      "one_line_profile": "Poetry plugin for managing Conda environments",
      "detailed_description": "This tool is a plugin for Poetry that enables the creation and management of Conda environments directly from Poetry workflows. It bridges the gap between the standard Python packaging ecosystem (Poetry) and the scientific computing ecosystem (Conda), facilitating reproducible research environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "interoperability"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/renan-r-santos/poetry-conda",
      "help_website": [
        "https://github.com/renan-r-santos/poetry-conda"
      ],
      "license": "MIT",
      "tags": [
        "poetry",
        "conda",
        "environment-management",
        "python"
      ],
      "id": 208
    },
    {
      "name": "What the Phage",
      "one_line_profile": "Reproducible pipeline for phage identification and annotation",
      "detailed_description": "What the Phage (WtP) is a bioinformatics pipeline for the identification and annotation of bacteriophages. It leverages Nextflow and containers (Docker/Singularity) to ensure reproducibility and scalability across different computing environments.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "sequence_analysis",
        "identification"
      ],
      "application_level": "workflow",
      "primary_language": "Nextflow",
      "repo_url": "https://github.com/replikation/What_the_Phage",
      "help_website": [
        "https://replikation.github.io/What_the_Phage/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "phage",
        "nextflow",
        "bioinformatics",
        "pipeline"
      ],
      "id": 209
    },
    {
      "name": "allgebra",
      "one_line_profile": "Base container environment for C++ and Fortran HPC application development",
      "detailed_description": "A specialized Docker container image designed to provide a reproducible build and runtime environment for High Performance Computing (HPC) applications written in C++ and Fortran. It serves as a foundational layer for scientific software development, ensuring consistency across different computing clusters.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "containerization"
      ],
      "application_level": "platform",
      "primary_language": "Dockerfile",
      "repo_url": "https://github.com/ricosjp/allgebra",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "docker",
        "c++",
        "fortran",
        "reproducibility"
      ],
      "id": 210
    },
    {
      "name": "law",
      "one_line_profile": "Large-scale task workflow management system for High Energy Physics",
      "detailed_description": "A workflow management system based on Luigi, designed for large-scale physics analysis (specifically High Energy Physics). It extends Luigi with features for remote job submission (HTCondor, Slurm, etc.), remote file targets, and environment sandboxing using Docker and Singularity, enabling reproducible scientific pipelines.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "workflow_management",
        "job_submission"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/riga/law",
      "help_website": [
        "https://law.readthedocs.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "workflow",
        "hpc",
        "physics",
        "luigi",
        "singularity"
      ],
      "id": 211
    },
    {
      "name": "packrat",
      "one_line_profile": "Dependency management system for reproducible R scientific analysis",
      "detailed_description": "A dependency management tool for the R programming language, widely used in statistical computing and bioinformatics. It ensures that R projects are self-contained, portable, and reproducible by isolating package dependencies, which is critical for scientific research workflows.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "dependency_management"
      ],
      "application_level": "platform",
      "primary_language": "R",
      "repo_url": "https://github.com/rstudio/packrat",
      "help_website": [
        "https://rstudio.github.io/packrat/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "r",
        "reproducibility",
        "package-manager",
        "science"
      ],
      "id": 212
    },
    {
      "name": "spack-manager",
      "one_line_profile": "Management tool for Spack deployments in HPC environments",
      "detailed_description": "A tool developed by Sandia National Laboratories to manage the deployment of software stacks using Spack (a package manager for supercomputers). It facilitates the creation and maintenance of reproducible software environments on High Performance Computing (HPC) systems.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "package_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/sandialabs/spack-manager",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "spack",
        "package-management",
        "sandia"
      ],
      "id": 213
    },
    {
      "name": "docker-selkies-egl-desktop",
      "one_line_profile": "Containerized KDE desktop with EGL support for HPC visualization",
      "detailed_description": "A specialized Docker container providing a KDE Plasma desktop environment optimized for Kubernetes and HPC clusters. It supports OpenGL EGL for NVIDIA GPUs, enabling low-latency remote visualization of scientific applications and simulations via WebRTC.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "visualization",
        "remote_desktop"
      ],
      "application_level": "platform",
      "primary_language": "Dockerfile",
      "repo_url": "https://github.com/selkies-project/docker-selkies-egl-desktop",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "hpc",
        "visualization",
        "egl",
        "kubernetes",
        "remote-desktop"
      ],
      "id": 214
    },
    {
      "name": "docker-selkies-glx-desktop",
      "one_line_profile": "Containerized KDE desktop with GLX support for HPC visualization",
      "detailed_description": "A specialized Docker container providing a KDE Plasma desktop environment optimized for Kubernetes and HPC clusters. It supports OpenGL GLX for NVIDIA GPUs, enabling low-latency remote visualization of scientific applications and simulations via WebRTC.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "visualization",
        "remote_desktop"
      ],
      "application_level": "platform",
      "primary_language": "Dockerfile",
      "repo_url": "https://github.com/selkies-project/docker-selkies-glx-desktop",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "hpc",
        "visualization",
        "glx",
        "kubernetes",
        "remote-desktop"
      ],
      "id": 215
    },
    {
      "name": "selkies",
      "one_line_profile": "WebRTC-based remote desktop streaming platform for HPC and Cloud",
      "detailed_description": "An open-source platform for low-latency, accelerated remote desktop streaming using WebRTC and HTML5. It is designed for self-hosting on Kubernetes or HPC clusters to provide remote access to graphical scientific applications and visualization workloads.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "visualization",
        "remote_access"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/selkies-project/selkies",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "webrtc",
        "hpc",
        "visualization",
        "streaming",
        "kubernetes"
      ],
      "id": 216
    },
    {
      "name": "wave-cli",
      "one_line_profile": "CLI for Wave container provisioning service in scientific workflows",
      "detailed_description": "The command-line interface for the Wave container provisioning service, developed by Seqera Labs (creators of Nextflow). It enables on-the-fly container creation and augmentation for scientific workflows, facilitating reproducible bioinformatics and data science pipelines.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "containerization",
        "workflow_management"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/seqeralabs/wave-cli",
      "help_website": [
        "https://wave.seqera.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nextflow",
        "containers",
        "bioinformatics",
        "workflow",
        "cli"
      ],
      "id": 217
    },
    {
      "name": "docker2singularity",
      "one_line_profile": "Converter for Docker images to Singularity format for HPC",
      "detailed_description": "A utility tool that converts Docker container images into Singularity images. This is essential for HPC workflows where Docker is used for development but Singularity (Apptainer) is required for runtime execution on shared clusters.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "containerization",
        "image_conversion"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/singularityhub/docker2singularity",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hpc",
        "singularity",
        "docker",
        "conversion",
        "container"
      ],
      "id": 218
    },
    {
      "name": "singularity-deploy",
      "one_line_profile": "Deployment tool for Singularity containers to GitHub Releases",
      "detailed_description": "A CI/CD utility designed to build and deploy Singularity container images directly to GitHub releases. It streamlines the distribution of scientific software containers, making them easily accessible for HPC users.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "containerization",
        "deployment"
      ],
      "application_level": "platform",
      "primary_language": "Singularity",
      "repo_url": "https://github.com/singularityhub/singularity-deploy",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "hpc",
        "singularity",
        "ci-cd",
        "deployment"
      ],
      "id": 219
    },
    {
      "name": "singularity-hpc",
      "one_line_profile": "Local container registry manager for HPC environments",
      "detailed_description": "A tool for managing a local filesystem registry of Singularity containers, specifically designed for HPC environments. It integrates with Lmod or Environment Modules to allow users and admins to easily manage and load containerized scientific applications.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "container_registry"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/singularityhub/singularity-hpc",
      "help_website": [
        "https://singularity-hpc.readthedocs.io"
      ],
      "license": "MPL-2.0",
      "tags": [
        "hpc",
        "singularity",
        "lmod",
        "modules",
        "registry"
      ],
      "id": 220
    },
    {
      "name": "singularity-python",
      "one_line_profile": "Python API and CLI for Singularity container management",
      "detailed_description": "A Python library and command-line interface for interacting with Singularity containers and Singularity Hub. It allows researchers to automate the management, inspection, and execution of Singularity containers within Python-based scientific workflows.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "containerization",
        "automation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/singularityhub/singularity-python",
      "help_website": [
        "https://singularityhub.github.io/singularity-python"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "python",
        "singularity",
        "hpc",
        "api"
      ],
      "id": 221
    },
    {
      "name": "sregistry",
      "one_line_profile": "Singularity Registry Server for scientific container storage",
      "detailed_description": "An open-source registry server specifically designed for storing and managing Singularity images. It allows institutions and research groups to host their own private or public container registries, facilitating the sharing and reproducibility of scientific environments.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_registry",
        "data_management"
      ],
      "application_level": "service",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/singularityhub/sregistry",
      "help_website": [
        "https://singularityhub.github.io/sregistry"
      ],
      "license": "MPL-2.0",
      "tags": [
        "registry",
        "singularity",
        "hpc",
        "container-storage"
      ],
      "id": 222
    },
    {
      "name": "Spack",
      "one_line_profile": "A flexible package manager for HPC supporting multiple versions, configurations, platforms, and compilers",
      "detailed_description": "Spack is a package manager designed for high-performance computing (HPC) environments. It enables reproducible scientific software stacks by handling complex dependency graphs, supporting multiple compiler versions, and allowing coexistence of different library configurations, which is critical for scientific simulations and data analysis.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "package_management",
        "environment_reproducibility",
        "hpc_deployment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/spack/spack",
      "help_website": [
        "https://spack.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "package-manager",
        "reproducibility",
        "supercomputing"
      ],
      "id": 223
    },
    {
      "name": "Spyder",
      "one_line_profile": "The Scientific Python Development Environment",
      "detailed_description": "Spyder is a powerful scientific environment written in Python, for Python, and designed by and for scientists, engineers and data analysts. It features a unique combination of the advanced editing, analysis, debugging, and profiling functionality of a comprehensive development tool with the data exploration, interactive execution, deep inspection, and beautiful visualization capabilities of a scientific package.",
      "domains": [
        "Scientific_Computing",
        "Data_Analysis"
      ],
      "subtask_category": [
        "scientific_programming",
        "data_analysis",
        "visualization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/spyder-ide/spyder",
      "help_website": [
        "https://www.spyder-ide.org/"
      ],
      "license": "MIT",
      "tags": [
        "ide",
        "python",
        "scientific-computing",
        "data-science"
      ],
      "id": 224
    },
    {
      "name": "SSRS",
      "one_line_profile": "Semantic Segmentation for Remote Sensing imagery",
      "detailed_description": "A deep learning toolkit specifically designed for semantic segmentation tasks in remote sensing. It provides implementations of various segmentation models tailored for earth observation data analysis.",
      "domains": [
        "AI4S_Earth",
        "Remote_Sensing"
      ],
      "subtask_category": [
        "semantic_segmentation",
        "image_analysis",
        "earth_observation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/sstary/SSRS",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "remote-sensing",
        "deep-learning",
        "segmentation",
        "earth-science"
      ],
      "id": 225
    },
    {
      "name": "Pinocchio",
      "one_line_profile": "Rigid Body Dynamics algorithms and their analytical derivatives",
      "detailed_description": "A fast and flexible C++ library for rigid body dynamics computations. It is widely used in robotics, biomechanics, and physics simulations to calculate kinematics and dynamics efficiently.",
      "domains": [
        "Physics",
        "Robotics"
      ],
      "subtask_category": [
        "dynamics_simulation",
        "kinematics_solver",
        "physics_modeling"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/stack-of-tasks/pinocchio",
      "help_website": [
        "https://stack-of-tasks.github.io/pinocchio"
      ],
      "license": "BSD-2-Clause",
      "tags": [
        "rigid-body-dynamics",
        "physics-simulation",
        "robotics",
        "biomechanics"
      ],
      "id": 226
    },
    {
      "name": "MedAgentBench",
      "one_line_profile": "A Realistic Virtual EHR Environment to Benchmark Medical LLM Agents",
      "detailed_description": "A benchmark suite that provides a realistic virtual Electronic Health Record (EHR) environment to evaluate the performance and capabilities of Medical Large Language Model (LLM) agents in clinical scenarios.",
      "domains": [
        "AI4S_Medicine",
        "AI_Evaluation"
      ],
      "subtask_category": [
        "benchmarking",
        "model_evaluation",
        "clinical_simulation"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanfordmlgroup/MedAgentBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-ai",
        "benchmark",
        "ehr",
        "clinical-nlp"
      ],
      "id": 227
    },
    {
      "name": "SingularityCE",
      "one_line_profile": "Container platform optimized for HPC and scientific computing",
      "detailed_description": "Singularity (now SingularityCE/Apptainer) is a container platform designed specifically for High Performance Computing (HPC). It allows researchers to package their scientific workflows, software, and data into a single image that can be run reproducibly on various HPC clusters without requiring root privileges.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_runtime",
        "reproducibility",
        "hpc_execution"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/sylabs/singularity",
      "help_website": [
        "https://sylabs.io/singularity/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "containers",
        "singularity",
        "reproducibility"
      ],
      "id": 228
    },
    {
      "name": "Konda",
      "one_line_profile": "Lightweight utility for managing Conda environments within Google Colab sessions",
      "detailed_description": "Konda is a Python utility designed to bridge the gap between Google Colab's default runtime and the Conda package management system. It allows researchers to easily install and persist Conda environments in Colab, enabling the use of scientific libraries and tools that are not available via standard pip installations or require complex dependency resolution.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "package_installation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tamnguyenvan/konda",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "conda",
        "google-colab",
        "environment-setup",
        "data-science"
      ],
      "id": 229
    },
    {
      "name": "Recipe Wizard",
      "one_line_profile": "Dockerfile generator for hardware-accelerated scientific simulation environments",
      "detailed_description": "Recipe Wizard is a tool that automates the creation of Dockerfiles for complex scientific simulation setups. It specifically targets headless server environments requiring OpenGL (GLX), nvidia-docker2 (CUDA), ROS (Robot Operating System), and Gazebo, streamlining the deployment of robotics and physics simulations.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_generation",
        "simulation_environment_setup"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/trn84/recipe-wizard",
      "help_website": [],
      "license": null,
      "tags": [
        "docker",
        "ros",
        "gazebo",
        "cuda",
        "opengl",
        "simulation"
      ],
      "id": 230
    },
    {
      "name": "Banpei",
      "one_line_profile": "Anomaly detection library based on Singular Spectrum Transformation",
      "detailed_description": "Banpei is a Python library dedicated to anomaly detection in time-series data using the Singular Spectrum Transformation (SST) method. It provides a simple interface for change-point detection, applicable to scientific monitoring and signal processing tasks.",
      "domains": [
        "AI3",
        "AI3-03"
      ],
      "subtask_category": [
        "anomaly_detection",
        "time_series_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tsurubee/banpei",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "anomaly-detection",
        "singular-spectrum-transformation",
        "time-series",
        "statistics"
      ],
      "id": 231
    },
    {
      "name": "Videoflow",
      "one_line_profile": "Python framework for building multiprocessing video analysis pipelines",
      "detailed_description": "Videoflow is a Python framework designed to facilitate the rapid development of complex video analysis applications. It handles multiprocessing and flow execution, allowing researchers to focus on implementing computer vision algorithms and processing logic for scientific video data.",
      "domains": [
        "AI3",
        "AI3-01"
      ],
      "subtask_category": [
        "video_processing",
        "pipeline_orchestration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/videoflow/videoflow",
      "help_website": [
        "https://videoflow.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "computer-vision",
        "video-processing",
        "multiprocessing",
        "pipeline"
      ],
      "id": 232
    },
    {
      "name": "ipyvizzu",
      "one_line_profile": "Animated data visualization library for Jupyter notebooks",
      "detailed_description": "ipyvizzu is a tool that enables the creation of animated, interactive charts within Jupyter notebooks and other Python environments. It allows scientists to build data stories and visualize complex dataset transitions, enhancing the interpretability and presentation of research findings.",
      "domains": [
        "AI3",
        "AI3-04"
      ],
      "subtask_category": [
        "data_visualization",
        "interactive_plotting"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/vizzuhq/ipyvizzu",
      "help_website": [
        "https://ipyvizzu.vizzuhq.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "visualization",
        "jupyter",
        "animation",
        "data-storytelling"
      ],
      "id": 233
    },
    {
      "name": "Warewulf",
      "one_line_profile": "Stateless and diskless container operating system provisioning system for HPC clusters",
      "detailed_description": "Warewulf is a scalable systems management and provisioning suite specifically designed for High Performance Computing (HPC) clusters. It facilitates the deployment of stateless and diskless container-based operating systems to bare metal hardware, essential for scientific computing infrastructure.",
      "domains": [
        "Infra/HPC",
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_provisioning",
        "system_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/warewulf/warewulf",
      "help_website": [
        "https://warewulf.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "provisioning",
        "cluster-management",
        "bare-metal"
      ],
      "id": 234
    },
    {
      "name": "UltraLight VM-UNet",
      "one_line_profile": "Parallel Vision Mamba network for skin lesion segmentation",
      "detailed_description": "A lightweight medical image segmentation model that integrates Vision Mamba into a U-Net architecture. It is specifically designed for skin lesion segmentation tasks, offering reduced parameter count while maintaining performance.",
      "domains": [
        "Computer Vision",
        "Medical Imaging"
      ],
      "subtask_category": [
        "image_segmentation",
        "medical_diagnosis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wurenkai/UltraLight-VM-UNet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-imaging",
        "segmentation",
        "mamba",
        "deep-learning"
      ],
      "id": 235
    },
    {
      "name": "S-D-Mamba",
      "one_line_profile": "Mamba-based model for time series forecasting",
      "detailed_description": "An implementation evaluating and utilizing the Mamba architecture for time series forecasting tasks. It serves as a solver for scientific data analysis involving temporal sequences.",
      "domains": [
        "Machine Learning",
        "Time Series Analysis"
      ],
      "subtask_category": [
        "time_series_forecasting",
        "data_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wzhwzhwzh0921/S-D-Mamba",
      "help_website": [],
      "license": "Unknown",
      "tags": [
        "time-series",
        "forecasting",
        "mamba",
        "deep-learning"
      ],
      "id": 236
    },
    {
      "name": "conda-envs (InSAR)",
      "one_line_profile": "Conda environment configurations for InSAR data processing",
      "detailed_description": "A collection of Conda environment setup scripts and configurations specifically tailored for Interferometric Synthetic Aperture Radar (InSAR) data processing workflows on Linux and macOS.",
      "domains": [
        "Earth Science",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_setup",
        "reproducibility"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/yunjunz/conda-envs",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "insar",
        "conda",
        "environment-management",
        "earth-science"
      ],
      "id": 237
    },
    {
      "name": "MambaOut",
      "one_line_profile": "Efficient vision backbone architecture analyzing Mamba's necessity",
      "detailed_description": "An implementation of the MambaOut architecture, which empirically analyzes the necessity of Mamba blocks in vision tasks. It serves as a computer vision backbone for scientific image analysis.",
      "domains": [
        "Computer Vision",
        "AI4S"
      ],
      "subtask_category": [
        "image_classification",
        "feature_extraction"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yuweihao/MambaOut",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "computer-vision",
        "model-architecture",
        "deep-learning"
      ],
      "id": 238
    },
    {
      "name": "Sigma",
      "one_line_profile": "Siamese Mamba Network for Multi-Modal Semantic Segmentation",
      "detailed_description": "A deep learning model implementing a Siamese Mamba Network for multi-modal semantic segmentation (e.g., RGB-Thermal, RGB-Depth). Useful for scientific sensing and robotics perception tasks.",
      "domains": [
        "Computer Vision",
        "Robotics"
      ],
      "subtask_category": [
        "semantic_segmentation",
        "multi_modal_fusion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/zifuwan/Sigma",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "segmentation",
        "mamba",
        "multi-modal",
        "rgb-t"
      ],
      "id": 239
    },
    {
      "name": "Mamba-UNet",
      "one_line_profile": "Zoo of Mamba-UNet models for medical image segmentation",
      "detailed_description": "A collection (Zoo) of Mamba-integrated U-Net architectures designed for medical image segmentation tasks. It provides reusable model implementations for biomedical image analysis.",
      "domains": [
        "Medical Imaging",
        "Computer Vision"
      ],
      "subtask_category": [
        "medical_segmentation",
        "image_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ziyangwang007/Mamba-UNet",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "medical-imaging",
        "unet",
        "mamba",
        "segmentation"
      ],
      "id": 240
    },
    {
      "name": "DAGEE",
      "one_line_profile": "Directed Acyclic Graph Execution Engine for concurrent task scheduling on CPUs/GPUs",
      "detailed_description": "A C++ library developed by AMD Research that enables programmers to express computation and data movement as task graphs, scheduled concurrently and asynchronously on heterogeneous architectures (CPUs and GPUs).",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "task_execution",
        "runtime_optimization"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/AMDResearch/DAGEE",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hpc",
        "task-graph",
        "gpu-scheduling",
        "amd"
      ],
      "id": 241
    },
    {
      "name": "lidar_IMU_calib",
      "one_line_profile": "Targetless Calibration of LiDAR-IMU System Based on Continuous-time Batch Estimation",
      "detailed_description": "A tool for calibrating LiDAR and IMU systems using continuous-time batch estimation, essential for sensor fusion in robotics and autonomous data collection systems.",
      "domains": [
        "AI6",
        "Robotics"
      ],
      "subtask_category": [
        "calibration",
        "sensor_fusion"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/APRIL-ZJU/lidar_IMU_calib",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "calibration",
        "lidar",
        "imu",
        "sensor-fusion"
      ],
      "id": 242
    },
    {
      "name": "gpushare-scheduler-extender",
      "one_line_profile": "GPU Sharing Scheduler for Kubernetes Cluster",
      "detailed_description": "A Kubernetes scheduler extender that enables fine-grained GPU sharing among pods, allowing multiple tasks to share a single GPU resource, optimizing utilization for AI/HPC workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "resource_scheduling",
        "gpu_sharing"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/AliyunContainerService/gpushare-scheduler-extender",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "gpu-scheduling",
        "hpc",
        "resource-management"
      ],
      "id": 243
    },
    {
      "name": "aicsimageio",
      "one_line_profile": "Image Reading, Metadata Conversion, and Image Writing for Microscopy Images",
      "detailed_description": "A Python library developed by the Allen Institute for Cell Science for reading, writing, and converting microscopy image data and metadata, supporting various scientific file formats.",
      "domains": [
        "AI6",
        "Bioinformatics"
      ],
      "subtask_category": [
        "image_io",
        "data_conversion"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AllenCellModeling/aicsimageio",
      "help_website": [
        "https://allencellmodeling.github.io/aicsimageio/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "microscopy",
        "bioimage",
        "image-io",
        "metadata"
      ],
      "id": 244
    },
    {
      "name": "daskqueue",
      "one_line_profile": "Distributed persistent Task Queue running on Dask",
      "detailed_description": "A distributed task queue built on top of Dask, providing a persistent queue mechanism for scheduling and executing tasks in scientific computing workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "task_scheduling",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AmineDiro/daskqueue",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dask",
        "task-queue",
        "distributed-computing",
        "python"
      ],
      "id": 245
    },
    {
      "name": "batch-shipyard",
      "one_line_profile": "Simplify HPC and Batch workloads on Azure",
      "detailed_description": "A tool to provision and execute batch-style and HPC workloads on Azure Batch using Docker containers, simplifying the deployment of scientific applications in the cloud.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "batch_processing",
        "cloud_hpc"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Azure/batch-shipyard",
      "help_website": [
        "https://batch-shipyard.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "azure",
        "hpc",
        "batch-processing",
        "docker"
      ],
      "id": 246
    },
    {
      "name": "cyclecloud-lsf",
      "one_line_profile": "Enable Spectrum LSF job scheduler in Azure CycleCloud HPC clusters",
      "detailed_description": "An official Azure project providing the necessary configuration and scripts to integrate the IBM Spectrum LSF job scheduler with Azure CycleCloud, enabling hybrid or cloud-native HPC scheduling.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "scheduler_integration",
        "cluster_management"
      ],
      "application_level": "platform",
      "primary_language": "HTML",
      "repo_url": "https://github.com/Azure/cyclecloud-lsf",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "lsf",
        "hpc",
        "azure",
        "scheduler"
      ],
      "id": 247
    },
    {
      "name": "ggVolcano",
      "one_line_profile": "R package for creating volcano plots from differential expression data",
      "detailed_description": "An R package designed to generate customizable volcano plots for visualizing differential gene expression analysis results, including gradient colors and GO term annotation.",
      "domains": [
        "Bioinformatics"
      ],
      "subtask_category": [
        "visualization",
        "differential_expression"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/BioSenior/ggVolcano",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "bioinformatics",
        "visualization",
        "r",
        "volcano-plot"
      ],
      "id": 248
    },
    {
      "name": "cobamp",
      "one_line_profile": "Constraint-based modeling framework for pathway analysis concepts",
      "detailed_description": "A Python framework for constraint-based modeling of metabolic networks, specifically focused on the enumeration of pathway analysis concepts in systems biology.",
      "domains": [
        "Bioinformatics",
        "Systems Biology"
      ],
      "subtask_category": [
        "metabolic_modeling",
        "pathway_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/BioSystemsUM/cobamp",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "systems-biology",
        "metabolic-networks",
        "constraint-based-modeling"
      ],
      "id": 249
    },
    {
      "name": "pyvolcans",
      "one_line_profile": "Python tool to identify analogue volcanoes",
      "detailed_description": "A Python tool developed by the British Geological Survey to identify analogue volcanoes based on various geological and physical parameters, aiding in volcanology research.",
      "domains": [
        "Geology"
      ],
      "subtask_category": [
        "data_analysis",
        "classification"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/BritishGeologicalSurvey/pyvolcans",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "volcanology",
        "geology",
        "analogue-identification"
      ],
      "id": 250
    },
    {
      "name": "scrapi",
      "one_line_profile": "Data processing pipeline for research metadata harvesting",
      "detailed_description": "A data processing pipeline developed by the Center for Open Science that schedules and runs content harvesters to normalize research metadata from various sources into a unified dataset.",
      "domains": [
        "AI6",
        "Open Science"
      ],
      "subtask_category": [
        "data_harvesting",
        "metadata_normalization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/CenterForOpenScience/scrapi",
      "help_website": [
        "https://osf.io/share/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "open-science",
        "metadata",
        "harvesting",
        "pipeline"
      ],
      "id": 251
    },
    {
      "name": "go-socker",
      "one_line_profile": "Wrapper for secure running of Docker containers on Slurm",
      "detailed_description": "A Go-based wrapper tool that enables the secure execution of Docker containers within a Slurm HPC environment, bridging the gap between containerized workflows and traditional batch schedulers.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "container_runtime",
        "job_submission"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/China-HPC/go-socker",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "docker",
        "hpc",
        "container"
      ],
      "id": 252
    },
    {
      "name": "Toil",
      "one_line_profile": "Scalable, efficient, cross-platform workflow engine for scientific pipelines",
      "detailed_description": "Toil is a workflow engine written in pure Python that supports widely used scientific workflow languages like WDL and CWL. It is designed to run scalable scientific pipelines on various platforms, including commercial clouds (AWS, Google, Azure) and high-performance computing (HPC) environments.",
      "domains": [
        "AI6",
        "AI6-02",
        "Bioinformatics"
      ],
      "subtask_category": [
        "workflow_management",
        "pipeline_orchestration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/DataBiosphere/toil",
      "help_website": [
        "https://toil.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow-engine",
        "wdl",
        "cwl",
        "hpc",
        "cloud-computing"
      ],
      "id": 253
    },
    {
      "name": "HyperGBM",
      "one_line_profile": "Full pipeline AutoML tool for tabular data",
      "detailed_description": "HyperGBM is an AutoML tool designed for tabular data that integrates data cleaning, preprocessing, feature generation, and model selection into a unified pipeline. It leverages gradient boosting models and hyperparameter optimization to automate the construction of machine learning models for scientific and industrial data analysis.",
      "domains": [
        "AI4S",
        "Machine Learning"
      ],
      "subtask_category": [
        "automl",
        "model_training",
        "tabular_data_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DataCanvasIO/HyperGBM",
      "help_website": [
        "https://hypergbm.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "automl",
        "tabular-data",
        "gradient-boosting",
        "hyperparameter-optimization"
      ],
      "id": 254
    },
    {
      "name": "Bolt",
      "one_line_profile": "Batch job submission script generator for HPC environments",
      "detailed_description": "Bolt is a tool developed by EPCC to automate the production of batch job submission scripts. It simplifies the process of configuring and submitting jobs to high-performance computing clusters by generating the necessary scheduler directives.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "hpc_utility"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/EPCCed/bolt",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "hpc",
        "batch-jobs",
        "script-generation",
        "epcc"
      ],
      "id": 255
    },
    {
      "name": "cubo",
      "one_line_profile": "On-Demand Earth System Data Cubes generation tool",
      "detailed_description": "cubo is a Python library for creating Earth System Data Cubes (ESDCs) on demand. It facilitates the access and processing of geospatial data from various sources (like Sentinel imagery) into structured data cubes suitable for scientific analysis and machine learning applications.",
      "domains": [
        "Earth Science",
        "Geospatial"
      ],
      "subtask_category": [
        "data_access",
        "data_cube_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ESDS-Leipzig/cubo",
      "help_website": [
        "https://cubo.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "earth-observation",
        "data-cubes",
        "geospatial",
        "sentinel"
      ],
      "id": 256
    },
    {
      "name": "VSM",
      "one_line_profile": "Volcano and Seismic source Modeling tool",
      "detailed_description": "VSM (Volcano and Seismic source Modeling) is a Python tool for modeling volcanic and seismic sources. It allows researchers to invert deformation data to estimate source parameters, supporting various source geometries used in geophysics.",
      "domains": [
        "Geophysics",
        "Seismology"
      ],
      "subtask_category": [
        "modeling",
        "inversion",
        "source_characterization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/EliTras/VSM",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "volcanology",
        "seismology",
        "geophysics",
        "modeling"
      ],
      "id": 257
    },
    {
      "name": "EngineCL",
      "one_line_profile": "Heterogeneous computing scheduling and usability framework",
      "detailed_description": "EngineCL is a framework designed to improve usability and performance in heterogeneous computing environments. It acts as a scheduler and wrapper for OpenCL, managing device selection and kernel execution across different hardware accelerators.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "task_scheduling",
        "heterogeneous_computing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/EngineCL/EngineCL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "opencl",
        "hpc",
        "scheduling",
        "heterogeneous-computing"
      ],
      "id": 258
    },
    {
      "name": "Daft",
      "one_line_profile": "High-performance distributed data engine for multimodal AI workloads",
      "detailed_description": "Daft is a distributed query engine written in Rust, designed for ETL, analytics, and data processing for multimodal AI datasets. It provides a Python DataFrame API and is optimized for handling large-scale scientific and AI data workloads.",
      "domains": [
        "AI Infra",
        "Data Science"
      ],
      "subtask_category": [
        "data_processing",
        "etl",
        "distributed_computing"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/Eventual-Inc/Daft",
      "help_website": [
        "https://www.getdaft.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dataframe",
        "distributed-computing",
        "etl",
        "multimodal-ai"
      ],
      "id": 259
    },
    {
      "name": "simple_gpu_scheduler",
      "one_line_profile": "Lightweight scheduler for managing GPU jobs",
      "detailed_description": "A simple Python-based scheduler designed to manage and queue jobs on machines with multiple GPUs. It allows users to submit commands that require GPU resources and executes them as devices become available.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ExpectationMax/simple_gpu_scheduler",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "gpu",
        "scheduling",
        "queue",
        "python"
      ],
      "id": 260
    },
    {
      "name": "FedML",
      "one_line_profile": "Unified library for distributed training and federated learning",
      "detailed_description": "FedML is a comprehensive library for federated learning and distributed training. It includes a cross-cloud scheduler (FedML Launch) that enables running AI jobs across diverse GPU clouds and on-premise clusters, facilitating large-scale scientific ML experiments.",
      "domains": [
        "AI6",
        "AI6-02",
        "Machine Learning"
      ],
      "subtask_category": [
        "distributed_training",
        "federated_learning",
        "job_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/FedML-AI/FedML",
      "help_website": [
        "https://doc.fedml.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "federated-learning",
        "distributed-systems",
        "scheduler",
        "edge-computing"
      ],
      "id": 261
    },
    {
      "name": "GENIE Generator",
      "one_line_profile": "Universal neutrino event generator and simulation tool",
      "detailed_description": "The GENIE Generator is a large-scale physics simulation tool used by neutrino experiments. It simulates neutrino interactions across a wide energy range (MeV–PeV) and handles flux generation, detector geometry, and event reweighting.",
      "domains": [
        "Physics",
        "High Energy Physics"
      ],
      "subtask_category": [
        "simulation",
        "event_generation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/GENIE-MC/Generator",
      "help_website": [
        "http://www.genie-mc.org/"
      ],
      "license": null,
      "tags": [
        "neutrino",
        "physics-simulation",
        "monte-carlo",
        "particle-physics"
      ],
      "id": 262
    },
    {
      "name": "gpu-topo-aware",
      "one_line_profile": "GPU topology-aware job scheduler",
      "detailed_description": "A scheduler designed to optimize job placement based on GPU topology. It aims to improve performance for distributed training or HPC tasks by considering the interconnect architecture of GPU resources.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HiEST/gpu-topo-aware",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu",
        "topology",
        "scheduling",
        "hpc"
      ],
      "id": 263
    },
    {
      "name": "lsf-slurm-wrappers",
      "one_line_profile": "Wrappers to execute LSF commands using Slurm syntax",
      "detailed_description": "A set of wrapper scripts developed by IBM Spectrum Computing to assist users in migrating from Slurm to LSF. It allows users to run common Slurm commands which are then translated to execute LSF commands in the background.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "migration_utility"
      ],
      "application_level": "solver",
      "primary_language": "Perl",
      "repo_url": "https://github.com/IBMSpectrumComputing/lsf-slurm-wrappers",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "slurm",
        "lsf",
        "scheduler-migration"
      ],
      "id": 264
    },
    {
      "name": "PaRSEC",
      "one_line_profile": "Generic framework for architecture-aware micro-task scheduling",
      "detailed_description": "PaRSEC is a runtime system for distributed, GPU-accelerated, heterogeneous architectures. It manages micro-tasks with a dynamic, fully-distributed scheduler that optimizes for data locality, communication overlap, and architectural features like NUMA nodes.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "task_scheduling",
        "runtime_system"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/ICLDisco/parsec",
      "help_website": [
        "http://icl.utk.edu/parsec/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "distributed-computing",
        "task-scheduling",
        "heterogeneous-computing"
      ],
      "id": 265
    },
    {
      "name": "Maui-Simulation",
      "one_line_profile": "Simulation environment for HPC job scheduling",
      "detailed_description": "A simulation tool for modeling and analyzing the behavior of the Maui/PBS job scheduler in large-scale HPC clusters. It allows researchers and administrators to simulate job scheduling scenarios based on real cluster data.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "simulation",
        "scheduler_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/It4innovations/Maui-Simulation",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "hpc",
        "scheduling-simulation",
        "maui",
        "pbs"
      ],
      "id": 266
    },
    {
      "name": "Kartothek",
      "one_line_profile": "Consistent table management library for datasets",
      "detailed_description": "Kartothek is a Python library for managing consistent tabular datasets backed by cloud object stores. It builds on Apache Arrow and Parquet to provide reliable data storage and retrieval for data-intensive scientific and analytical workflows.",
      "domains": [
        "Data Science",
        "AI Infra"
      ],
      "subtask_category": [
        "data_management",
        "storage"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/JDASoftwareGroup/kartothek",
      "help_website": [
        "https://kartothek.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "parquet",
        "arrow",
        "dataset-management",
        "python"
      ],
      "id": 267
    },
    {
      "name": "xESMF",
      "one_line_profile": "Universal Regridder for Geospatial Data",
      "detailed_description": "xESMF is a Python package for regridding geospatial data (e.g., climate model outputs). It wraps the ESMF (Earth System Modeling Framework) regridding algorithms and integrates with Xarray to handle complex grid transformations in Earth Science.",
      "domains": [
        "Earth Science",
        "Climate Science"
      ],
      "subtask_category": [
        "data_processing",
        "regridding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/JiaweiZhuang/xESMF",
      "help_website": [
        "https://xesmf.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "geospatial",
        "regridding",
        "climate-data",
        "xarray"
      ],
      "id": 268
    },
    {
      "name": "VolcaNoseR",
      "one_line_profile": "Web app for generating and annotating Volcano plots",
      "detailed_description": "VolcaNoseR is an R Shiny application designed for the interactive creation and annotation of volcano plots, which are widely used in bioinformatics to visualize differential expression data.",
      "domains": [
        "Bioinformatics"
      ],
      "subtask_category": [
        "visualization",
        "data_plotting"
      ],
      "application_level": "solver",
      "primary_language": "R",
      "repo_url": "https://github.com/JoachimGoedhart/VolcaNoseR",
      "help_website": [
        "https://huygens.science.uva.nl/VolcaNoseR/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "volcano-plot",
        "bioinformatics",
        "shiny",
        "visualization"
      ],
      "id": 269
    },
    {
      "name": "ClusterManagers.jl",
      "one_line_profile": "Julia interface for HPC job schedulers",
      "detailed_description": "ClusterManagers.jl provides an interface for the Julia programming language to submit and manage jobs on various HPC schedulers, including Slurm, PBS, LSF, and SGE, enabling distributed scientific computing in Julia.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaParallel/ClusterManagers.jl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "julia",
        "hpc",
        "slurm",
        "pbs",
        "distributed-computing"
      ],
      "id": 270
    },
    {
      "name": "mass",
      "one_line_profile": "Batch job management system for complex pipelines",
      "detailed_description": "mass is a computer farm management system based on AWS SWF, designed to handle complex pipelines of batch jobs. It serves as a lightweight scheduler for managing computational workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "pipeline_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/KKBOX/mass",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "batch-jobs",
        "workflow",
        "aws-swf",
        "scheduler"
      ],
      "id": 271
    },
    {
      "name": "volcano3D",
      "one_line_profile": "3D visualization tool for differential expression analysis",
      "detailed_description": "volcano3D is an R package that enables the plotting of interactive three-way differential expression analysis results. It extends standard 2D volcano plots to 3D to visualize gene expression changes across three groups simultaneously.",
      "domains": [
        "Bioinformatics"
      ],
      "subtask_category": [
        "visualization",
        "differential_expression"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/KatrionaGoldmann/volcano3D",
      "help_website": [
        "https://katrionagoldmann.github.io/volcano3D/"
      ],
      "license": null,
      "tags": [
        "bioinformatics",
        "visualization",
        "3d-plot",
        "r-package"
      ],
      "id": 272
    },
    {
      "name": "Magpie",
      "one_line_profile": "Scripts for running Big Data software in HPC environments",
      "detailed_description": "Magpie provides a set of scripts to deploy and run Big Data frameworks like Hadoop and Spark within traditional HPC environments (using schedulers like Slurm, Moab, LSF). It bridges the gap between HPC schedulers and big data analytics stacks.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "framework_integration"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/LLNL/magpie",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "hpc",
        "hadoop",
        "spark",
        "slurm",
        "lustre"
      ],
      "id": 273
    },
    {
      "name": "Yoda-Scheduler",
      "one_line_profile": "GPU-metric based scheduler for Kubernetes clusters",
      "detailed_description": "Yoda is a Kubernetes scheduler extension that optimizes pod placement based on GPU metrics, designed to improve resource utilization for AI and scientific workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/Mr-Linus/Yoda-Scheduler",
      "help_website": [],
      "license": null,
      "tags": [
        "kubernetes",
        "scheduler",
        "gpu",
        "hpc"
      ],
      "id": 274
    },
    {
      "name": "qhist",
      "one_line_profile": "Historical job query utility for PBS Pro",
      "detailed_description": "A command-line utility developed by NCAR to query and analyze historical job data from the PBS Pro workload manager, facilitating HPC usage analysis.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "hpc_analytics"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NCAR/qhist",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pbs-pro",
        "hpc",
        "job-history",
        "ncar"
      ],
      "id": 275
    },
    {
      "name": "KAI-Scheduler",
      "one_line_profile": "Kubernetes native scheduler for large-scale AI workloads",
      "detailed_description": "An open-source Kubernetes scheduler optimized for large-scale AI and HPC workloads, providing advanced scheduling capabilities for GPU resources.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/NVIDIA/KAI-Scheduler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "scheduler",
        "ai-infrastructure",
        "gpu"
      ],
      "id": 276
    },
    {
      "name": "pyxis",
      "one_line_profile": "Slurm container execution plugin",
      "detailed_description": "A SPANK plugin for Slurm that enables unprivileged users to execute containerized workloads (via Enroot) seamlessly within HPC environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "container_runtime",
        "job_execution"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/NVIDIA/pyxis",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "slurm",
        "container",
        "hpc",
        "enroot"
      ],
      "id": 277
    },
    {
      "name": "mlforecast",
      "one_line_profile": "Scalable machine learning framework for time series forecasting",
      "detailed_description": "A framework for performing scalable time series forecasting using machine learning models, applicable to scientific domains such as weather, climate, and energy load forecasting.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "time_series_forecasting",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Nixtla/mlforecast",
      "help_website": [
        "https://nixtla.github.io/mlforecast/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "time-series",
        "forecasting",
        "machine-learning"
      ],
      "id": 278
    },
    {
      "name": "Slurm_tools",
      "one_line_profile": "Collection of administration and user tools for Slurm",
      "detailed_description": "A set of scripts and utilities for managing and interacting with the Slurm HPC workload manager, aiding in job submission, monitoring, and accounting.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "cluster_administration"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/OleHolmNielsen/Slurm_tools",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "slurm",
        "hpc",
        "administration"
      ],
      "id": 279
    },
    {
      "name": "CSGHub",
      "one_line_profile": "Open-source platform for managing LLMs and datasets",
      "detailed_description": "A platform for managing the lifecycle of Large Language Models (LLMs), datasets, and agents, providing infrastructure for AI model hosting and deployment relevant to AI4S workflows.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "model_management",
        "dataset_management"
      ],
      "application_level": "platform",
      "primary_language": "Vue",
      "repo_url": "https://github.com/OpenCSGs/csghub",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "model-registry",
        "ai-infrastructure"
      ],
      "id": 280
    },
    {
      "name": "PipelineDP",
      "one_line_profile": "Differential privacy framework for large dataset processing",
      "detailed_description": "A Python framework for applying differentially private aggregations to large datasets using batch processing systems like Spark and Beam, enabling secure scientific data analysis.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_processing",
        "privacy_preservation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenMined/PipelineDP",
      "help_website": [
        "https://pipelinedp.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "differential-privacy",
        "data-processing",
        "spark",
        "beam"
      ],
      "id": 281
    },
    {
      "name": "OpenRLHF",
      "one_line_profile": "High-performance RLHF framework based on Ray",
      "detailed_description": "A scalable framework for Reinforcement Learning from Human Feedback (RLHF) built on Ray, facilitating the training and alignment of large models used in various AI applications including scientific domains.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "model_training",
        "reinforcement_learning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenRLHF/OpenRLHF",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "ray",
        "llm-training",
        "distributed-training"
      ],
      "id": 282
    },
    {
      "name": "xclim",
      "one_line_profile": "Library for calculating climate indicators",
      "detailed_description": "A Python library based on xarray for calculating climate indices and indicators from climate model output and observational data.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "climate_analysis",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Ouranosinc/xclim",
      "help_website": [
        "https://xclim.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "climate-science",
        "xarray",
        "meteorology"
      ],
      "id": 283
    },
    {
      "name": "HybriMoE",
      "one_line_profile": "Hybrid CPU-GPU scheduling for MoE inference",
      "detailed_description": "A system for efficient Mixture-of-Experts (MoE) inference that utilizes hybrid CPU-GPU scheduling and cache management to optimize resource usage.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "inference_scheduling",
        "resource_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PKU-SEC-Lab/HybriMoE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "moe",
        "scheduling",
        "inference",
        "gpu"
      ],
      "id": 284
    },
    {
      "name": "condor",
      "one_line_profile": "R interface for HTCondor",
      "detailed_description": "An R package that enables interaction with the HTCondor high-throughput computing system via SSH, allowing users to submit and manage jobs from R.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/PacificCommunity/condor",
      "help_website": [],
      "license": null,
      "tags": [
        "htcondor",
        "r",
        "hpc",
        "ssh"
      ],
      "id": 285
    },
    {
      "name": "paddle-operator",
      "one_line_profile": "Kubernetes operator for PaddlePaddle training jobs",
      "detailed_description": "A Kubernetes operator that facilitates elastic deep learning training for PaddlePaddle by leveraging Volcano for scheduling and resource management.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/PaddleFlow/paddle-operator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "paddlepaddle",
        "operator",
        "volcano"
      ],
      "id": 286
    },
    {
      "name": "Liquid",
      "one_line_profile": "Resource estimation and scheduling for DL jobs",
      "detailed_description": "A system for intelligent resource requirement estimation and scheduling of deep learning jobs on distributed GPU clusters, developed by PasaLab.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_estimation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/PasaLab/Liquid",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "scheduling",
        "deep-learning",
        "gpu-cluster",
        "hpc"
      ],
      "id": 287
    },
    {
      "name": "volcano-vgpu-device-plugin",
      "one_line_profile": "Volcano vGPU device plugin for Kubernetes",
      "detailed_description": "A Kubernetes device plugin designed for the Volcano scheduler to support hard resource isolation and scheduling of virtual GPUs (vGPUs).",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "resource_management",
        "scheduling"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/Project-HAMi/volcano-vgpu-device-plugin",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "volcano",
        "gpu",
        "virtualization"
      ],
      "id": 288
    },
    {
      "name": "pyslurm",
      "one_line_profile": "Python interface to Slurm C API",
      "detailed_description": "A Python extension that provides an interface to the Slurm Workload Manager's C API, allowing programmatic interaction with Slurm for job control and querying.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "api_binding"
      ],
      "application_level": "library",
      "primary_language": "Cython",
      "repo_url": "https://github.com/PySlurm/pyslurm",
      "help_website": [
        "https://pyslurm.github.io/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "slurm",
        "python",
        "hpc",
        "api"
      ],
      "id": 289
    },
    {
      "name": "Embree",
      "one_line_profile": "High-performance ray tracing kernels",
      "detailed_description": "A collection of high-performance ray tracing kernels developed by Intel, widely used in scientific visualization and rendering engines to accelerate geometric calculations.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "scientific_visualization",
        "rendering"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/RenderKit/embree",
      "help_website": [
        "https://www.embree.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ray-tracing",
        "visualization",
        "rendering",
        "hpc"
      ],
      "id": 290
    },
    {
      "name": "REEF",
      "one_line_profile": "GPU-accelerated DNN inference serving system",
      "detailed_description": "A high-performance DNN inference serving system that supports instant kernel preemption and biased concurrent execution for optimized GPU scheduling.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "inference_serving",
        "gpu_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/SJTU-IPADS/reef",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "gpu",
        "scheduling",
        "preemption"
      ],
      "id": 291
    },
    {
      "name": "Slurm",
      "one_line_profile": "A highly scalable workload manager for HPC clusters",
      "detailed_description": "Slurm is an open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters. It is the de facto standard for HPC job scheduling in scientific research.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/SchedMD/slurm",
      "help_website": [
        "https://slurm.schedmd.com/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "scheduler",
        "workload-manager"
      ],
      "id": 292
    },
    {
      "name": "Slurm on GCP",
      "one_line_profile": "Deployment tools for running Slurm clusters on Google Cloud Platform",
      "detailed_description": "A set of tools and scripts to deploy and manage Slurm clusters on Google Cloud Platform (GCP), enabling scalable HPC workloads in the cloud.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cloud_deployment",
        "cluster_management"
      ],
      "application_level": "platform",
      "primary_language": "HCL",
      "repo_url": "https://github.com/SchedMD/slurm-gcp",
      "help_website": [
        "https://github.com/SchedMD/slurm-gcp"
      ],
      "license": "Apache-2.0",
      "tags": [
        "gcp",
        "slurm",
        "cloud-hpc"
      ],
      "id": 293
    },
    {
      "name": "Slurm in Docker",
      "one_line_profile": "Dockerized Slurm environment for testing and development",
      "detailed_description": "Provides Docker images and configurations to run Slurm clusters in containers, facilitating the development, testing, and reproducibility of HPC workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "environment_setup",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/SciDAS/slurm-in-docker",
      "help_website": [
        "https://github.com/SciDAS/slurm-in-docker"
      ],
      "license": "MIT",
      "tags": [
        "docker",
        "slurm",
        "containerization"
      ],
      "id": 294
    },
    {
      "name": "TRTIS Kubernetes Scheduler",
      "one_line_profile": "Custom Kubernetes scheduler for deploying ML models to TensorRT Inference Server",
      "detailed_description": "A custom scheduler designed to optimize the deployment of machine learning models to NVIDIA's TensorRT Inference Server (TRTIS) on Kubernetes, specifically handling GPU sharing.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "inference_scheduling",
        "gpu_sharing"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/SeldonIO/trtis-k8s-scheduler",
      "help_website": [
        "https://github.com/SeldonIO/trtis-k8s-scheduler"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "inference",
        "gpu"
      ],
      "id": 295
    },
    {
      "name": "Slurm Operator",
      "one_line_profile": "Kubernetes Operator for managing Slurm clusters",
      "detailed_description": "An operator to deploy and manage Slurm clusters on Kubernetes, bridging traditional HPC scheduling with cloud-native infrastructure.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_management",
        "cloud_native_hpc"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/SlinkyProject/slurm-operator",
      "help_website": [
        "https://github.com/SlinkyProject/slurm-operator"
      ],
      "license": null,
      "tags": [
        "kubernetes",
        "slurm",
        "operator"
      ],
      "id": 296
    },
    {
      "name": "spark.condor",
      "one_line_profile": "Utilities to run Apache Spark on HTCondor clusters",
      "detailed_description": "Scripts and tools to submit and manage Apache Spark jobs in standalone mode on HTCondor clusters, enabling big data processing in scientific HPC environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "big_data_processing"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/SmartDataInnovationLab/spark.condor",
      "help_website": [
        "https://github.com/SmartDataInnovationLab/spark.condor"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "spark",
        "htcondor",
        "hpc"
      ],
      "id": 297
    },
    {
      "name": "Snakemake HTCondor Profile",
      "one_line_profile": "Snakemake profile for executing workflows on HTCondor",
      "detailed_description": "A configuration profile for Snakemake that allows scientific workflows to be executed on HTCondor clusters, managing job submission and resource allocation.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_execution",
        "job_submission"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Snakemake-Profiles/htcondor",
      "help_website": [
        "https://github.com/Snakemake-Profiles/htcondor"
      ],
      "license": "MIT",
      "tags": [
        "snakemake",
        "htcondor",
        "workflow"
      ],
      "id": 298
    },
    {
      "name": "watchmen",
      "one_line_profile": "Toolkit for GPU scheduling and monitoring",
      "detailed_description": "A simple toolkit designed to assist with GPU scheduling and monitoring, useful for managing resources in deep learning and scientific computing experiments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "gpu_scheduling",
        "resource_monitoring"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Spico197/watchmen",
      "help_website": [
        "https://github.com/Spico197/watchmen"
      ],
      "license": "MIT",
      "tags": [
        "gpu",
        "scheduling",
        "monitoring"
      ],
      "id": 299
    },
    {
      "name": "SEML",
      "one_line_profile": "Slurm Experiment Management Library for machine learning",
      "detailed_description": "SEML allows researchers to manage and track machine learning experiments on Slurm clusters, handling job submission, configuration management, and results collection.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "experiment_management",
        "job_scheduling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/TUM-DAML/seml",
      "help_website": [
        "https://github.com/TUM-DAML/seml"
      ],
      "license": "NOASSERTION",
      "tags": [
        "slurm",
        "experiment-tracking",
        "machine-learning"
      ],
      "id": 300
    },
    {
      "name": "Caelus",
      "one_line_profile": "Kubernetes solution for reusing idle node resources for batch jobs",
      "detailed_description": "Caelus is a set of Kubernetes solutions designed to improve resource utilization by running extra batch jobs (often scientific or AI workloads) on idle node resources.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "resource_optimization",
        "batch_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/Tencent/caelus",
      "help_website": [
        "https://github.com/Tencent/caelus"
      ],
      "license": "NOASSERTION",
      "tags": [
        "kubernetes",
        "batch-jobs",
        "resource-management"
      ],
      "id": 301
    },
    {
      "name": "TimeEval",
      "one_line_profile": "Evaluation tool for time series anomaly detection algorithms",
      "detailed_description": "TimeEval is a tool for evaluating and benchmarking anomaly detection algorithms on time series data, automating the execution and scoring of algorithms.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "benchmarking",
        "algorithm_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/TimeEval/TimeEval",
      "help_website": [
        "https://timeeval.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "time-series",
        "anomaly-detection",
        "benchmarking"
      ],
      "id": 302
    },
    {
      "name": "Orca",
      "one_line_profile": "Task orchestration library for UrbanSim and data science",
      "detailed_description": "Orca is a Python library for task orchestration, primarily used within the UrbanSim ecosystem for urban data science and modeling simulations.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "task_orchestration",
        "simulation_pipeline"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/UDST/orca",
      "help_website": [
        "https://udst.github.io/orca/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "orchestration",
        "urban-science",
        "pipeline"
      ],
      "id": 303
    },
    {
      "name": "slurmR",
      "one_line_profile": "Lightweight R wrapper for Slurm",
      "detailed_description": "slurmR provides a lightweight wrapper for Slurm, allowing R users to submit and manage jobs on Slurm clusters directly from their R environment.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "parallel_computing"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/USCbiostats/slurmR",
      "help_website": [
        "https://github.com/USCbiostats/slurmR"
      ],
      "license": "NOASSERTION",
      "tags": [
        "r",
        "slurm",
        "hpc"
      ],
      "id": 304
    },
    {
      "name": "pbsweb",
      "one_line_profile": "Web interface for monitoring PBS Pro HPC clusters",
      "detailed_description": "A web interface designed to display the status of nodes, queues, and jobs on High Performance Compute (HPC) clusters using the PBS Pro scheduler.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_monitoring",
        "job_visualization"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/UTS-eResearch/pbsweb",
      "help_website": [
        "https://github.com/UTS-eResearch/pbsweb"
      ],
      "license": "GPL-3.0",
      "tags": [
        "pbs-pro",
        "hpc",
        "monitoring"
      ],
      "id": 305
    },
    {
      "name": "vector-inference",
      "one_line_profile": "Efficient LLM inference on Slurm clusters",
      "detailed_description": "A tool for running efficient Large Language Model (LLM) inference on Slurm-managed clusters using vLLM, facilitating AI research on HPC infrastructure.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "inference_scheduling",
        "llm_deployment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/VectorInstitute/vector-inference",
      "help_website": [
        "https://github.com/VectorInstitute/vector-inference"
      ],
      "license": "MIT",
      "tags": [
        "slurm",
        "llm",
        "inference"
      ],
      "id": 306
    },
    {
      "name": "pyglidein",
      "one_line_profile": "Scripts to launch HTCondor glideins",
      "detailed_description": "Python scripts to launch HTCondor glideins, used for distributed computing in particle astrophysics research (e.g., IceCube).",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_computing",
        "job_submission"
      ],
      "application_level": "utility",
      "primary_language": "Python",
      "repo_url": "https://github.com/WIPACrepo/pyglidein",
      "help_website": [
        "https://github.com/WIPACrepo/pyglidein"
      ],
      "license": "MIT",
      "tags": [
        "htcondor",
        "distributed-computing",
        "physics"
      ],
      "id": 307
    },
    {
      "name": "xsched",
      "one_line_profile": "Scheduling framework for diverse XPUs (GPUs, NPUs, FPGAs)",
      "detailed_description": "A scheduling framework designed for multitasking over heterogeneous computing units (XPUs) such as GPUs, NPUs, ASICs, and FPGAs, optimizing resource usage in accelerated computing.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "heterogeneous_scheduling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/XpuOS/xsched",
      "help_website": [
        "https://github.com/XpuOS/xsched"
      ],
      "license": "Apache-2.0",
      "tags": [
        "scheduling",
        "xpu",
        "accelerators"
      ],
      "id": 308
    },
    {
      "name": "Grove",
      "one_line_profile": "Kubernetes scheduler extensions for gang scheduling and topology awareness",
      "detailed_description": "Grove provides Kubernetes enhancements for Network Topology Aware Gang Scheduling and Autoscaling, which are critical for distributed AI training and HPC workloads to ensure efficient resource utilization and job coordination.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "scheduling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/ai-dynamo/grove",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "gang-scheduling",
        "hpc",
        "autoscaling"
      ],
      "id": 309
    },
    {
      "name": "slurm_gpustat",
      "one_line_profile": "Command line tool for monitoring GPU usage on Slurm clusters",
      "detailed_description": "A simple command line utility designed to display GPU usage statistics specifically for jobs running on a SLURM cluster, aiding in resource monitoring and optimization for HPC workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "monitoring",
        "resource_management"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/albanie/slurm_gpustat",
      "help_website": [],
      "license": null,
      "tags": [
        "slurm",
        "gpu",
        "monitoring",
        "hpc"
      ],
      "id": 310
    },
    {
      "name": "GPU-scheduler-for-deep-learning",
      "one_line_profile": "GPU scheduler designed for deep learning workloads",
      "detailed_description": "A specialized scheduler for managing GPU resources in deep learning environments, optimizing the allocation and execution of training jobs.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "scheduling",
        "resource_management"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/alibaba/GPU-scheduler-for-deep-learning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "scheduling",
        "deep-learning"
      ],
      "id": 311
    },
    {
      "name": "simple_slurm",
      "one_line_profile": "Python wrapper for Slurm Workload Manager",
      "detailed_description": "A Python library that provides a simple wrapper around the Slurm Workload Manager, allowing users to submit and manage HPC jobs programmatically.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/amq92/simple_slurm",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "slurm",
        "python",
        "hpc",
        "job-management"
      ],
      "id": 312
    },
    {
      "name": "Whippletree",
      "one_line_profile": "Dynamic scheduling framework for irregular GPU workloads",
      "detailed_description": "A novel approach and framework for scheduling dynamic, irregular workloads directly on the GPU, bypassing some of the limitations of traditional kernel launch overheads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "scheduling",
        "gpu_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/apc-llc/whippletree",
      "help_website": [],
      "license": null,
      "tags": [
        "cuda",
        "gpu",
        "scheduling",
        "hpc"
      ],
      "id": 313
    },
    {
      "name": "Spark on Kubernetes Batch Processing Gateway",
      "one_line_profile": "Gateway for managing Spark batch jobs on Kubernetes",
      "detailed_description": "A gateway component designed to simplify the submission and management of Spark batch processing jobs on Kubernetes clusters, facilitating large-scale data processing workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "batch_processing"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/apple/batch-processing-gateway",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "spark",
        "kubernetes",
        "batch-processing"
      ],
      "id": 314
    },
    {
      "name": "Armada",
      "one_line_profile": "Multi-cluster batch queuing system for Kubernetes",
      "detailed_description": "A high-throughput batch queuing system for Kubernetes that spans multiple clusters, designed to handle massive scale scientific and AI workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "scheduling",
        "queue_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/armadaproject/armada",
      "help_website": [
        "https://armadaproject.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "batch-processing",
        "hpc",
        "multi-cluster"
      ],
      "id": 315
    },
    {
      "name": "Escalator",
      "one_line_profile": "Batch-optimized horizontal autoscaler for Kubernetes",
      "detailed_description": "A horizontal autoscaler for Kubernetes optimized for batch jobs and large-scale compute workloads, ensuring efficient resource scaling based on job demand.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "autoscaling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/atlassian/escalator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "autoscaling",
        "batch-jobs"
      ],
      "id": 316
    },
    {
      "name": "Kolibri",
      "one_line_profile": "Framework for concurrent batch processing and ranking evaluation",
      "detailed_description": "A Scala-based framework for concurrent multi-node batch processing and evaluation of search systems, providing out-of-the-box functionality for IR metrics (NDCG, Precision, Recall).",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "batch_processing",
        "evaluation"
      ],
      "application_level": "framework",
      "primary_language": "Scala",
      "repo_url": "https://github.com/awagen/kolibri",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "batch-processing",
        "evaluation",
        "scala",
        "distributed-computing"
      ],
      "id": 317
    },
    {
      "name": "AWS SDK for pandas",
      "one_line_profile": "Pandas integration for AWS data services",
      "detailed_description": "An open-source Python library that extends pandas to easily integrate with AWS data services like Athena, Glue, Redshift, and S3, facilitating scientific data processing pipelines on AWS.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_processing",
        "data_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aws/aws-sdk-pandas",
      "help_website": [
        "https://aws-sdk-pandas.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "pandas",
        "aws",
        "data-processing",
        "etl"
      ],
      "id": 318
    },
    {
      "name": "Floto",
      "one_line_profile": "Task orchestration tool based on AWS SWF",
      "detailed_description": "A task orchestration tool built on top of AWS Simple Workflow Service (SWF) and boto3, allowing for the definition and execution of distributed data processing workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "orchestration",
        "workflow_management"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/babbel/floto",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "orchestration",
        "aws-swf",
        "workflow"
      ],
      "id": 319
    },
    {
      "name": "Bodywork",
      "one_line_profile": "ML pipeline orchestration and model deployment on Kubernetes",
      "detailed_description": "A tool for orchestrating machine learning pipelines and deploying models on Kubernetes, supporting continuous training and batch scoring workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "orchestration",
        "mlops"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/bodywork-ml/bodywork-core",
      "help_website": [
        "https://bodywork.readthedocs.io/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "kubernetes",
        "mlops",
        "orchestration",
        "pipeline"
      ],
      "id": 320
    },
    {
      "name": "slurmpy",
      "one_line_profile": "Python wrapper for submitting jobs to the Slurm workload manager",
      "detailed_description": "A lightweight Python library that simplifies the submission of jobs to the Slurm scheduler, allowing users to define job properties and scripts programmatically within Python code.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/brentp/slurmpy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "hpc",
        "python",
        "job-scheduling"
      ],
      "id": 321
    },
    {
      "name": "Uchuva",
      "one_line_profile": "Scientific web portal for submitting workflows to HPC schedulers",
      "detailed_description": "A web-based portal designed to facilitate the creation and submission of scientific workflows to various HPC schedulers including HTCondor, Slurm, OpenLava, and Torque.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "workflow_management"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/carlochess/uchuva",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "hpc",
        "web-portal",
        "htcondor",
        "slurm",
        "workflow"
      ],
      "id": 322
    },
    {
      "name": "JobSchedulers.jl",
      "one_line_profile": "Julia-based job scheduler and workload manager",
      "detailed_description": "A pure Julia implementation of a job scheduler and workload manager, inspired by Slurm and PBS, designed to manage scientific computations and tasks within the Julia ecosystem.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "workload_management"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/cihga39871/JobSchedulers.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "scheduler",
        "hpc",
        "parallel-computing"
      ],
      "id": 323
    },
    {
      "name": "ClearML Agent",
      "one_line_profile": "MLOps orchestration agent for experiment scheduling",
      "detailed_description": "The agent component of the ClearML platform, responsible for pulling experiment execution tasks from the queue and running them on local or remote resources, facilitating reproducible AI research workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "experiment_orchestration",
        "mlops"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/clearml/clearml-agent",
      "help_website": [
        "https://clear.ml/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "orchestration",
        "reproducibility",
        "scheduler"
      ],
      "id": 324
    },
    {
      "name": "GPUTasker",
      "one_line_profile": "Lightweight GPU task scheduler for single-node clusters",
      "detailed_description": "A lightweight and easy-to-use GPU task scheduling tool designed to manage and queue tasks on GPU servers, optimizing resource utilization for small-scale AI research environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "gpu_scheduling",
        "resource_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/cnstark/gputasker",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "scheduler",
        "python",
        "deep-learning"
      ],
      "id": 325
    },
    {
      "name": "vGPU Manager",
      "one_line_profile": "Kubernetes device plugin for vGPU scheduling and allocation",
      "detailed_description": "A Kubernetes device plugin that enables the scheduling and allocation of virtualized GPU resources, allowing for fine-grained sharing of GPUs in containerized scientific workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "resource_allocation",
        "container_orchestration"
      ],
      "application_level": "service",
      "primary_language": "C",
      "repo_url": "https://github.com/coldzerofear/vgpu-manager",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "gpu",
        "virtualization",
        "scheduler"
      ],
      "id": 326
    },
    {
      "name": "MetaVolcanoR",
      "one_line_profile": "Gene expression meta-analysis visualization tool",
      "detailed_description": "An R package designed for the visualization of gene expression meta-analysis results, specifically creating volcano plots to identify differentially expressed genes across multiple studies.",
      "domains": [
        "Bioinformatics",
        "Visualization"
      ],
      "subtask_category": [
        "visualization",
        "differential_expression_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/csbl-usp/MetaVolcanoR",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "genomics",
        "visualization",
        "r",
        "meta-analysis"
      ],
      "id": 327
    },
    {
      "name": "DanteGPU Core",
      "one_line_profile": "Core microservices for decentralized GPU computing network",
      "detailed_description": "The core infrastructure for the DanteGPU network, enabling decentralized orchestration of AI job scheduling and management of distributed GPU providers.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_computing",
        "resource_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/dante-gpu/dantegpu-core",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "decentralized-computing",
        "scheduler",
        "go"
      ],
      "id": 328
    },
    {
      "name": "FluxPrune.jl",
      "one_line_profile": "Pruning framework for Flux machine learning models",
      "detailed_description": "A Julia library providing methods and a framework for pruning neural networks built with Flux.jl, facilitating model compression and efficiency in scientific machine learning.",
      "domains": [
        "Scientific Machine Learning"
      ],
      "subtask_category": [
        "model_optimization",
        "pruning"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/darsnack/FluxPrune.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "flux",
        "machine-learning",
        "model-compression"
      ],
      "id": 329
    },
    {
      "name": "Dask SQL",
      "one_line_profile": "Distributed SQL Engine for Dask DataFrames",
      "detailed_description": "A distributed SQL engine that allows users to query Dask DataFrames using SQL, enabling scalable data analysis and processing on large scientific datasets using familiar SQL syntax.",
      "domains": [
        "AI6",
        "Data Science"
      ],
      "subtask_category": [
        "data_querying",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask-contrib/dask-sql",
      "help_website": [
        "https://dask-sql.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "sql",
        "dask",
        "distributed-computing",
        "python"
      ],
      "id": 330
    },
    {
      "name": "Dask",
      "one_line_profile": "Flexible library for parallel computing in Python",
      "detailed_description": "A core library for parallel computing in Python that integrates with the scientific Python stack (NumPy, Pandas, Scikit-Learn) to enable scalable data analysis and task scheduling.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "parallel_computing",
        "task_scheduling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask",
      "help_website": [
        "https://dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "parallel-computing",
        "python",
        "scheduler",
        "big-data"
      ],
      "id": 331
    },
    {
      "name": "Dask Cloudprovider",
      "one_line_profile": "Cloud provider cluster managers for Dask",
      "detailed_description": "A library for deploying and managing Dask clusters on various cloud providers (AWS, Azure, GCP), facilitating the scaling of scientific workloads in cloud environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_management",
        "cloud_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask-cloudprovider",
      "help_website": [
        "https://cloudprovider.dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "dask",
        "cloud",
        "cluster-management",
        "python"
      ],
      "id": 332
    },
    {
      "name": "Dask Gateway",
      "one_line_profile": "Multi-tenant server for securely deploying and managing Dask clusters",
      "detailed_description": "A secure, multi-tenant server for managing Dask clusters, allowing users to launch and use Dask clusters in a shared environment with authentication and resource limits.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_management",
        "job_scheduling"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask-gateway",
      "help_website": [
        "https://gateway.dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "dask",
        "cluster-management",
        "distributed-computing"
      ],
      "id": 333
    },
    {
      "name": "dask-image",
      "one_line_profile": "Distributed image processing library using Dask",
      "detailed_description": "A library for distributed image processing that integrates with Dask arrays, allowing for scalable analysis of large scientific image datasets.",
      "domains": [
        "AI6",
        "AI4"
      ],
      "subtask_category": [
        "image_processing",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask-image",
      "help_website": [
        "https://image.dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "image-processing",
        "dask",
        "distributed"
      ],
      "id": 334
    },
    {
      "name": "dask-jobqueue",
      "one_line_profile": "Integration of Dask with HPC job schedulers (PBS, Slurm, SGE)",
      "detailed_description": "A library that deploys Dask workers on common HPC job schedulers like PBS, Slurm, SGE, and LSF, enabling scalable scientific computing on existing cluster infrastructure.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "hpc_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask-jobqueue",
      "help_website": [
        "https://jobqueue.dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "slurm",
        "pbs",
        "dask"
      ],
      "id": 335
    },
    {
      "name": "dask-kubernetes",
      "one_line_profile": "Native Kubernetes integration for deploying Dask clusters",
      "detailed_description": "Provides utilities for deploying and managing Dask clusters on Kubernetes, including a native operator and a classic cluster manager.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_management",
        "container_orchestration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask-kubernetes",
      "help_website": [
        "https://kubernetes.dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "kubernetes",
        "dask",
        "cloud-native"
      ],
      "id": 336
    },
    {
      "name": "dask-labextension",
      "one_line_profile": "JupyterLab extension for managing and monitoring Dask clusters",
      "detailed_description": "A JupyterLab extension that provides a dashboard for managing Dask clusters and visualizing task progress directly within the scientific research environment.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_management",
        "monitoring"
      ],
      "application_level": "plugin",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/dask/dask-labextension",
      "help_website": [
        "https://github.com/dask/dask-labextension"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyterlab",
        "dask",
        "visualization"
      ],
      "id": 337
    },
    {
      "name": "dask-ml",
      "one_line_profile": "Scalable machine learning library compatible with Scikit-Learn",
      "detailed_description": "A library for scalable machine learning in Python, providing parallel implementations of common ML algorithms and integration with Dask for handling large datasets.",
      "domains": [
        "AI3",
        "AI6"
      ],
      "subtask_category": [
        "machine_learning",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/dask-ml",
      "help_website": [
        "https://ml.dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "machine-learning",
        "distributed",
        "scikit-learn"
      ],
      "id": 338
    },
    {
      "name": "Dask Distributed",
      "one_line_profile": "Distributed task scheduler for the Dask ecosystem",
      "detailed_description": "The core distributed scheduling engine for Dask, managing task execution across clusters of machines with low latency and high throughput.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dask/distributed",
      "help_website": [
        "https://distributed.dask.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "scheduler",
        "distributed",
        "python"
      ],
      "id": 339
    },
    {
      "name": "Cube Studio",
      "one_line_profile": "Cloud-native one-stop MLOps and LLM platform",
      "detailed_description": "An open-source AI platform supporting the full lifecycle of machine learning and large model development, including distributed training, inference, and resource management on Kubernetes.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "mlops",
        "platform_orchestration",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/data-infra/cube-studio",
      "help_website": [
        "https://github.com/data-infra/cube-studio"
      ],
      "license": "NOASSERTION",
      "tags": [
        "mlops",
        "kubernetes",
        "llm",
        "distributed-training"
      ],
      "id": 340
    },
    {
      "name": "ec2cluster",
      "one_line_profile": "Tool for launching and managing MPI clusters on Amazon EC2",
      "detailed_description": "A Rails-based web service and dashboard for provisioning MPI-ready clusters on AWS EC2 and managing user-submitted HPC jobs.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_provisioning",
        "job_submission"
      ],
      "application_level": "tool",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/datawrangling/ec2cluster",
      "help_website": [],
      "license": null,
      "tags": [
        "aws",
        "mpi",
        "hpc",
        "cluster-management"
      ],
      "id": 341
    },
    {
      "name": "cwm-simulator",
      "one_line_profile": "Simulator for Slurm-like cluster workload managers",
      "detailed_description": "A simulation tool for modeling and analyzing the behavior of cluster workload managers (like Slurm), useful for research on scheduling algorithms.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "scheduling_simulation",
        "performance_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dchasap/cwm-simulator",
      "help_website": [],
      "license": null,
      "tags": [
        "slurm",
        "simulator",
        "scheduling"
      ],
      "id": 342
    },
    {
      "name": "dpdispatcher",
      "one_line_profile": "Job submission and management tool for DeepModeling ecosystem",
      "detailed_description": "A Python tool to generate HPC scheduler scripts, submit jobs, and monitor their status, specifically designed for the DeepModeling scientific workflow.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "workflow_automation"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepmodeling/dpdispatcher",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "hpc",
        "deepmodeling",
        "scheduler"
      ],
      "id": 343
    },
    {
      "name": "DeepSquare Grid",
      "one_line_profile": "Decentralized HPC platform with Slurm-like interface",
      "detailed_description": "A decentralized high-performance computing grid based on blockchain technology, offering an abstracted Slurm interface for job scheduling and meta-scheduling strategies.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_computing",
        "resource_allocation"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/deepsquare-io/grid",
      "help_website": [
        "https://docs.deepsquare.io/"
      ],
      "license": null,
      "tags": [
        "hpc",
        "decentralized",
        "blockchain",
        "slurm"
      ],
      "id": 344
    },
    {
      "name": "Omnia",
      "one_line_profile": "Toolkit for deploying and managing HPC and AI clusters",
      "detailed_description": "An open-source toolkit using Ansible and Kubernetes to deploy and manage high-performance clusters for HPC, AI, and data analytics workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_provisioning",
        "infrastructure_management"
      ],
      "application_level": "tool",
      "primary_language": "YAML",
      "repo_url": "https://github.com/dell/omnia",
      "help_website": [
        "https://omnia-doc.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "ansible",
        "kubernetes",
        "cluster-deployment"
      ],
      "id": 345
    },
    {
      "name": "High-Performance-Integer-Factorization-Suite",
      "one_line_profile": "High-performance suite for integer factorization algorithms",
      "detailed_description": "A suite implementing GNFS, MPQS, and QS algorithms with optimizations like GPU acceleration and NUMA-aware scheduling for computational number theory research.",
      "domains": [
        "AI4",
        "AI6"
      ],
      "subtask_category": [
        "integer_factorization",
        "cryptanalysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/devatnull/High-Performance-Integer-Factorization-Suite-GNFS-MPQS-QS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "number-theory",
        "factorization",
        "gpu",
        "hpc"
      ],
      "id": 346
    },
    {
      "name": "opt_einsum",
      "one_line_profile": "Optimizer for tensor contraction orders in scientific computing",
      "detailed_description": "A library that optimizes the contraction order of einsum functions in NumPy, TensorFlow, and Dask, significantly speeding up tensor operations in quantum chemistry and physics.",
      "domains": [
        "AI4",
        "AI6"
      ],
      "subtask_category": [
        "numerical_optimization",
        "tensor_contraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dgasmith/opt_einsum",
      "help_website": [
        "https://optimized-einsum.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "tensor",
        "optimization",
        "numpy",
        "quantum-chemistry"
      ],
      "id": 347
    },
    {
      "name": "qsub",
      "one_line_profile": "Command line utility for submitting batch jobs to Kubernetes",
      "detailed_description": "A Go-based utility that emulates the traditional 'qsub' command to submit batch jobs to Kubernetes clusters, bridging the gap between HPC and Cloud Native workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "hpc_emulation"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/dgruber/qsub",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "kubernetes",
        "hpc",
        "batch-jobs"
      ],
      "id": 348
    },
    {
      "name": "XGBoost",
      "one_line_profile": "Scalable and distributed gradient boosting library",
      "detailed_description": "An optimized distributed gradient boosting library designed to be highly efficient, flexible and portable, widely used in scientific data analysis and machine learning competitions.",
      "domains": [
        "AI3",
        "AI6"
      ],
      "subtask_category": [
        "machine_learning",
        "gradient_boosting"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/dmlc/xgboost",
      "help_website": [
        "https://xgboost.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "gbdt",
        "machine-learning",
        "distributed"
      ],
      "id": 349
    },
    {
      "name": "cms-htcondor-es",
      "one_line_profile": "ElasticSearch integration for CMS HTCondor pool monitoring",
      "detailed_description": "A tool for integrating the CMS experiment's HTCondor pool with ElasticSearch, enabling monitoring and analysis of high-throughput computing jobs in high-energy physics.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "monitoring",
        "hpc_infrastructure"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/dmwm/cms-htcondor-es",
      "help_website": [],
      "license": null,
      "tags": [
        "cms",
        "cern",
        "htcondor",
        "monitoring"
      ],
      "id": 350
    },
    {
      "name": "dstack",
      "one_line_profile": "Control plane for running AI jobs on GPUs across clouds",
      "detailed_description": "An open-source control plane that simplifies running development, training, and inference jobs on GPUs across various cloud providers and on-premise clusters.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "mlops",
        "resource_orchestration",
        "job_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/dstackai/dstack",
      "help_website": [
        "https://dstack.ai/"
      ],
      "license": "MPL-2.0",
      "tags": [
        "mlops",
        "gpu",
        "cloud-computing"
      ],
      "id": 351
    },
    {
      "name": "Metview Python",
      "one_line_profile": "Python interface to Metview meteorological workstation",
      "detailed_description": "A Python interface to Metview, enabling meteorological data processing, analysis, and visualization, as well as interaction with batch systems for weather forecasting workflows.",
      "domains": [
        "AI6",
        "AI4"
      ],
      "subtask_category": [
        "meteorology",
        "data_visualization",
        "workflow_automation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ecmwf/metview-python",
      "help_website": [
        "https://metview.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "meteorology",
        "ecmwf",
        "visualization"
      ],
      "id": 352
    },
    {
      "name": "elastic-gpu-scheduler",
      "one_line_profile": "Kubernetes scheduler extender for GPU resources",
      "detailed_description": "A Kubernetes scheduler extender designed to optimize GPU resource scheduling, supporting elastic scaling for AI and HPC workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "resource_scheduling",
        "gpu_management"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/elastic-ai/elastic-gpu-scheduler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "gpu",
        "scheduler"
      ],
      "id": 353
    },
    {
      "name": "ElastiCluster",
      "one_line_profile": "Tool to create and configure compute clusters on cloud providers",
      "detailed_description": "A command-line tool to create, manage, and setup computing clusters (with Slurm, GridEngine, etc.) on various cloud providers using Ansible.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_provisioning",
        "cloud_hpc"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/elasticluster/elasticluster",
      "help_website": [
        "https://elasticluster.readthedocs.io/"
      ],
      "license": "GPL-3.0",
      "tags": [
        "cloud",
        "hpc",
        "ansible",
        "cluster-management"
      ],
      "id": 354
    },
    {
      "name": "TESK API",
      "one_line_profile": "GA4GH Task Execution Service implementation for Kubernetes",
      "detailed_description": "An implementation of the GA4GH Task Execution Service (TES) API that translates scientific task descriptions into Kubernetes Batch API calls, facilitating interoperable genomics workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_execution",
        "genomics_infrastructure"
      ],
      "application_level": "service",
      "primary_language": "Java",
      "repo_url": "https://github.com/elixir-cloud-aai/tesk-api",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ga4gh",
        "genomics",
        "kubernetes",
        "workflow"
      ],
      "id": 355
    },
    {
      "name": "Paella",
      "one_line_profile": "Low-latency model serving system with virtualized GPU scheduling",
      "detailed_description": "A research system for low-latency machine learning model serving that utilizes virtualized GPU scheduling to optimize resource usage and response times.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "model_serving",
        "gpu_scheduling"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/eniac/paella",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "model-serving",
        "gpu",
        "scheduling"
      ],
      "id": 356
    },
    {
      "name": "Proteus",
      "one_line_profile": "Heterogeneous database engine with adaptive scheduling",
      "detailed_description": "A research database engine designed for heterogeneous environments, featuring GPU acceleration and adaptive scheduling to handle variable scientific and analytical workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "data_management",
        "adaptive_scheduling"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/epfl-dias/proteus",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "database",
        "gpu",
        "heterogeneous-computing"
      ],
      "id": 357
    },
    {
      "name": "Orion",
      "one_line_profile": "Interference-aware scheduler for fine-grained GPU sharing",
      "detailed_description": "A scheduler designed to manage fine-grained GPU sharing by being aware of interference between tasks, optimizing throughput for deep learning workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "gpu_scheduling",
        "resource_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/eth-easl/orion",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "scheduling",
        "deep-learning"
      ],
      "id": 358
    },
    {
      "name": "submitit",
      "one_line_profile": "Python toolbox for submitting jobs to Slurm",
      "detailed_description": "A lightweight Python library for submitting and managing jobs on Slurm clusters, enabling easy switching between local execution and cluster execution for research experiments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "experiment_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookincubator/submitit",
      "help_website": [
        "https://github.com/facebookincubator/submitit"
      ],
      "license": "MIT",
      "tags": [
        "slurm",
        "python",
        "hpc"
      ],
      "id": 359
    },
    {
      "name": "GPUTaskScheduler",
      "one_line_profile": "Lightweight Python library for scheduling tasks on available GPUs",
      "detailed_description": "A simple Python-based scheduler designed to manage and distribute tasks across available GPU resources, useful for local scientific experiment management.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fjxmlzn/GPUTaskScheduler",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "scheduling",
        "python"
      ],
      "id": 360
    },
    {
      "name": "Flux Core",
      "one_line_profile": "Next-generation resource manager and scheduler for HPC centers",
      "detailed_description": "The core framework of the Flux project, providing a hierarchical resource management system and job scheduler designed for modern High Performance Computing (HPC) environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/flux-framework/flux-core",
      "help_website": [
        "http://flux-framework.org"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "hpc",
        "scheduler",
        "resource-manager",
        "flux"
      ],
      "id": 361
    },
    {
      "name": "Flux K8s",
      "one_line_profile": "Integration components for running Flux resource manager on Kubernetes",
      "detailed_description": "A project to manage Flux tasks and standardize Kubernetes HPC scheduling interfaces, enabling the use of the Flux scheduler within Cloud Native environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "orchestration"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/flux-framework/flux-k8s",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "hpc",
        "flux",
        "scheduling"
      ],
      "id": 362
    },
    {
      "name": "Fugue",
      "one_line_profile": "Unified interface for distributed computing on Spark, Dask, and Ray",
      "detailed_description": "An abstraction layer that allows users to write code in native Python or SQL and execute it on distributed computing engines like Spark, Dask, and Ray, facilitating scalable scientific data processing.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_computing",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fugue-project/fugue",
      "help_website": [
        "https://fugue-tutorials.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-computing",
        "spark",
        "dask",
        "ray",
        "abstraction"
      ],
      "id": 363
    },
    {
      "name": "Furiko",
      "one_line_profile": "Kubernetes-native batch job platform for complex workflows",
      "detailed_description": "A high-performance cron and batch job platform for Kubernetes, suitable for managing scientific batch workloads with advanced scheduling features.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "batch_processing"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/furiko-io/furiko",
      "help_website": [
        "https://furiko.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "batch-jobs",
        "cron",
        "scheduling"
      ],
      "id": 364
    },
    {
      "name": "Ansible Role for Slurm",
      "one_line_profile": "Ansible role for deploying Slurm Workload Manager",
      "detailed_description": "An Ansible role maintained by the Galaxy Project for installing and managing the Slurm Workload Manager, essential for setting up scientific HPC clusters.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_management",
        "deployment"
      ],
      "application_level": "service",
      "primary_language": "Jinja",
      "repo_url": "https://github.com/galaxyproject/ansible-slurm",
      "help_website": [],
      "license": null,
      "tags": [
        "slurm",
        "ansible",
        "hpc",
        "deployment"
      ],
      "id": 365
    },
    {
      "name": "Hypertunity",
      "one_line_profile": "Toolset for black-box hyperparameter optimisation",
      "detailed_description": "A lightweight and modular Python library for black-box hyperparameter optimization, supporting various schedulers and optimization algorithms for scientific ML models.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "hyperparameter_optimization",
        "model_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gdikov/hypertunity",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hpo",
        "optimization",
        "machine-learning"
      ],
      "id": 366
    },
    {
      "name": "GeodMod",
      "one_line_profile": "Geodetic Modeling Software in Matlab",
      "detailed_description": "A MATLAB-based software suite for geodetic modeling, used for analyzing deformation data and geophysical parameters.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "scientific_modeling",
        "geodesy"
      ],
      "application_level": "solver",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/geodesymiami/GeodMod",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "geodesy",
        "matlab",
        "modeling",
        "earth-science"
      ],
      "id": 367
    },
    {
      "name": "Dask-GeoPandas",
      "one_line_profile": "Parallel GeoPandas with Dask",
      "detailed_description": "A library that enables parallel processing of geospatial data by integrating GeoPandas with Dask, facilitating large-scale spatial analysis.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_processing",
        "spatial_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/geopandas/dask-geopandas",
      "help_website": [
        "https://dask-geopandas.readthedocs.io"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "geospatial",
        "dask",
        "parallel-computing",
        "gis"
      ],
      "id": 368
    },
    {
      "name": "foamlib",
      "one_line_profile": "Modern Python package for interacting with OpenFOAM",
      "detailed_description": "A Python interface for OpenFOAM, allowing users to automate CFD simulations, manipulate cases, and interact with OpenFOAM utilities programmatically.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "simulation_interface",
        "cfd"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gerlero/foamlib",
      "help_website": [
        "https://foamlib.readthedocs.io"
      ],
      "license": "GPL-3.0",
      "tags": [
        "openfoam",
        "cfd",
        "python",
        "simulation"
      ],
      "id": 369
    },
    {
      "name": "Docker CentOS7 Slurm",
      "one_line_profile": "Slurm Docker Container on CentOS 7",
      "detailed_description": "A Docker image providing a pre-configured Slurm Workload Manager environment on CentOS 7, useful for testing and developing HPC workflows locally.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "environment_simulation",
        "hpc_testing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/giovtorres/docker-centos7-slurm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "docker",
        "hpc",
        "centos"
      ],
      "id": 370
    },
    {
      "name": "Slurm Docker Cluster",
      "one_line_profile": "A Slurm cluster using docker-compose",
      "detailed_description": "A tool to deploy a multi-node Slurm cluster using Docker Compose, enabling reproducible local simulation of HPC environments for job scheduling development.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_simulation",
        "job_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/giovtorres/slurm-docker-cluster",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "docker-compose",
        "hpc",
        "cluster"
      ],
      "id": 371
    },
    {
      "name": "stackstac",
      "one_line_profile": "Turn a STAC catalog into a dask-based xarray",
      "detailed_description": "A library for converting SpatioTemporal Asset Catalogs (STAC) into Dask-backed Xarray objects, streamlining the analysis of large-scale satellite and earth science data.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_loading",
        "earth_observation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/gjoseph92/stackstac",
      "help_website": [
        "https://stackstac.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "stac",
        "xarray",
        "dask",
        "remote-sensing"
      ],
      "id": 372
    },
    {
      "name": "SDSC ibrun",
      "one_line_profile": "SDSC's implementation of the ibrun MPI launcher",
      "detailed_description": "A wrapper script used at the San Diego Supercomputer Center (SDSC) to simplify MPI job launching across different batch schedulers and MPI implementations.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_launching",
        "mpi_execution"
      ],
      "application_level": "solver",
      "primary_language": "Perl",
      "repo_url": "https://github.com/glennklockwood/sdsc-ibrun",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "mpi",
        "hpc",
        "job-launcher",
        "sdsc"
      ],
      "id": 373
    },
    {
      "name": "PathwaysJob API",
      "one_line_profile": "Kubernetes-native API to deploy ML training and batch inference using Pathways",
      "detailed_description": "An API and controller for deploying Machine Learning training and batch inference workloads on Google Kubernetes Engine (GKE) using the Pathways runtime.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "ml_orchestration",
        "batch_inference"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/google/pathways-job",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "machine-learning",
        "pathways",
        "gke"
      ],
      "id": 374
    },
    {
      "name": "Xarray-Beam",
      "one_line_profile": "Distributed Xarray with Apache Beam",
      "detailed_description": "A library that adapts Xarray data structures for use with Apache Beam, enabling distributed processing of massive multi-dimensional scientific datasets.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "distributed_processing",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google/xarray-beam",
      "help_website": [
        "https://xarray-beam.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "xarray",
        "apache-beam",
        "distributed-computing",
        "big-data"
      ],
      "id": 375
    },
    {
      "name": "grid-control",
      "one_line_profile": "Versatile job submission and management tool for grid computing",
      "detailed_description": "A job submission tool designed for High Energy Physics and other scientific domains, supporting parameterized jobs and automatic resubmission on Grid and local batch systems.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "grid_computing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/grid-control/grid-control",
      "help_website": [
        "https://grid-control.github.io"
      ],
      "license": null,
      "tags": [
        "grid-computing",
        "batch-jobs",
        "hep",
        "job-management"
      ],
      "id": 376
    },
    {
      "name": "VodaScheduler",
      "one_line_profile": "GPU scheduler for elastic and distributed deep learning workloads on Kubernetes",
      "detailed_description": "VodaScheduler is a GPU scheduler designed for Kubernetes clusters to optimize elastic and distributed deep learning workloads. It improves resource utilization and training efficiency by managing GPU allocation dynamically.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_allocation"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/heyfey/vodascheduler",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "gpu-scheduling",
        "deep-learning",
        "distributed-training"
      ],
      "id": 377
    },
    {
      "name": "Kubernetes Scheduler Simulator",
      "one_line_profile": "Simulator for evaluating Kubernetes schedulers",
      "detailed_description": "A tool designed to simulate the behavior of Kubernetes schedulers, allowing researchers and developers to evaluate scheduling algorithms and cluster behavior without deploying a real cluster. Useful for optimizing HPC/AI workload placement.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "simulation",
        "scheduling_research"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/hkust-adsl/kubernetes-scheduler-simulator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "simulator",
        "scheduling",
        "hpc"
      ],
      "id": 378
    },
    {
      "name": "hvPlot",
      "one_line_profile": "High-level plotting API for scientific data visualization",
      "detailed_description": "A high-level plotting API built on HoloViews that provides a general and consistent interface for visualizing data from Pandas, Dask, XArray, and NetworkX. Widely used in geoscience and physics for interactive data exploration.",
      "domains": [
        "AI6",
        "Scientific Visualization"
      ],
      "subtask_category": [
        "visualization",
        "data_exploration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/holoviz/hvplot",
      "help_website": [
        "https://hvplot.holoviz.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "visualization",
        "pandas",
        "xarray",
        "dask",
        "interactive-plots"
      ],
      "id": 379
    },
    {
      "name": "Horovod",
      "one_line_profile": "Distributed deep learning training framework",
      "detailed_description": "A distributed deep learning training framework for TensorFlow, Keras, PyTorch, and Apache MXNet. It makes distributed training easy and efficient, often used in HPC environments (via MPI) for large-scale scientific AI models.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_training",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/horovod/horovod",
      "help_website": [
        "https://horovod.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "deep-learning",
        "distributed-training",
        "mpi",
        "hpc"
      ],
      "id": 380
    },
    {
      "name": "HTCondor",
      "one_line_profile": "High-Throughput Computing (HTC) workload management system",
      "detailed_description": "A specialized workload management system for compute-intensive jobs. It provides a job queueing mechanism, scheduling policy, priority scheme, resource monitoring, and resource management, widely used in physics (e.g., CERN) and genomics.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "workload_management"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/htcondor/htcondor",
      "help_website": [
        "https://htcondor.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "htc",
        "batch-system",
        "scheduling",
        "grid-computing"
      ],
      "id": 381
    },
    {
      "name": "HTCondor-CE",
      "one_line_profile": "Grid gatekeeper for HTCondor compute elements",
      "detailed_description": "A site grid gatekeeper technology based on HTCondor components, used to authorize and route incoming grid jobs to the local batch system. Essential for federated scientific computing grids.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "grid_computing",
        "job_routing"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/htcondor/htcondor-ce",
      "help_website": [
        "https://htcondor-ce.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "grid",
        "gatekeeper",
        "htcondor",
        "compute-element"
      ],
      "id": 382
    },
    {
      "name": "HTCondor-RESTD",
      "one_line_profile": "REST API interface for HTCondor",
      "detailed_description": "Provides a RESTful interface to the HTCondor High-Throughput Computing system, enabling remote job submission, query, and management via HTTP, facilitating integration with modern scientific web portals.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "api_interface"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/htcondor/htcondor-restd",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rest-api",
        "htcondor",
        "job-management"
      ],
      "id": 383
    },
    {
      "name": "HTMap",
      "one_line_profile": "Pythonic high-throughput computing library powered by HTCondor",
      "detailed_description": "A library that wraps HTCondor to provide a map-reduce style interface for Python, allowing researchers to easily scale out function calls across a cluster without managing job files directly.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "high_throughput_computing",
        "parallel_execution"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/htcondor/htmap",
      "help_website": [
        "https://htmap.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "python",
        "htcondor",
        "map-reduce",
        "parallel-computing"
      ],
      "id": 384
    },
    {
      "name": "llm-swarm",
      "one_line_profile": "Scalable LLM inference on Slurm clusters",
      "detailed_description": "A tool to manage and scale open LLM inference endpoints within Slurm-managed HPC clusters. It facilitates the deployment of large language models for scientific research using existing HPC infrastructure.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "inference_serving",
        "resource_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/llm-swarm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "llm",
        "inference",
        "hpc"
      ],
      "id": 385
    },
    {
      "name": "Opara",
      "one_line_profile": "DNN Operator parallel scheduling framework",
      "detailed_description": "A lightweight and resource-aware DNN Operator parallel scheduling framework designed to accelerate the execution of DNN inference on GPUs by optimizing operator execution order.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "inference_optimization",
        "operator_scheduling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/icloud-ecnu/Opara",
      "help_website": [],
      "license": null,
      "tags": [
        "dnn",
        "scheduling",
        "gpu",
        "inference"
      ],
      "id": 386
    },
    {
      "name": "Prophet",
      "one_line_profile": "Communication scheduling strategy for distributed training",
      "detailed_description": "A predictable communication scheduling strategy to schedule gradient transfers in an adequate order, aiming to maximize GPU and network resource utilization during distributed DNN training.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_training",
        "communication_scheduling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/icloud-ecnu/Prophet",
      "help_website": [],
      "license": null,
      "tags": [
        "distributed-training",
        "gradient-scheduling",
        "network-optimization"
      ],
      "id": 387
    },
    {
      "name": "Argo Volcano Executor Plugin",
      "one_line_profile": "Argo Workflows plugin for executing Volcano Jobs",
      "detailed_description": "A plugin that allows Argo Workflows to trigger and manage Volcano jobs. Volcano is a batch scheduling system for Kubernetes, widely used for AI and Big Data workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "job_submission"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/iflytek/argo-volcano-executor-plugin",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "argo",
        "volcano",
        "kubernetes",
        "workflow"
      ],
      "id": 388
    },
    {
      "name": "MintPy",
      "one_line_profile": "Miami InSAR time-series software",
      "detailed_description": "An open-source software package for Interferometric Synthetic Aperture Radar (InSAR) time-series analysis. It reads stack of interferograms and estimates the ground displacement time-series.",
      "domains": [
        "Geoscience",
        "Remote Sensing"
      ],
      "subtask_category": [
        "time_series_analysis",
        "image_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/insarlab/MintPy",
      "help_website": [
        "https://mintpy.readthedocs.io/"
      ],
      "license": null,
      "tags": [
        "insar",
        "geodesy",
        "remote-sensing",
        "deformation"
      ],
      "id": 389
    },
    {
      "name": "BigDL",
      "one_line_profile": "Distributed deep learning on Big Data platforms",
      "detailed_description": "A distributed deep learning framework for Apache Spark and Ray. It allows users to write deep learning applications as standard Spark/Ray programs, facilitating the integration of AI models into big data pipelines.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_training",
        "big_data_analytics"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/intel/BigDL",
      "help_website": [
        "https://bigdl.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "spark",
        "ray",
        "deep-learning",
        "distributed-computing"
      ],
      "id": 390
    },
    {
      "name": "CRI Resource Manager",
      "one_line_profile": "Hardware resource aware workload placement for Kubernetes",
      "detailed_description": "A Kubernetes Container Runtime Interface (CRI) proxy service that applies hardware resource-aware policies (e.g., NUMA topology, cache allocation) to optimize workload placement, essential for high-performance AI/HPC jobs.",
      "domains": [
        "AI6",
        "HPC"
      ],
      "subtask_category": [
        "resource_management",
        "workload_placement"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/intel/cri-resource-manager",
      "help_website": [
        "https://intel.github.io/cri-resource-manager/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "numa",
        "resource-management",
        "hpc"
      ],
      "id": 391
    },
    {
      "name": "cellxgene_VIP",
      "one_line_profile": "Visualization in Plugin for cellxgene",
      "detailed_description": "A plugin for cellxgene that provides advanced visualization capabilities (violin plots, heatmaps, volcano plots) and differential gene expression analysis for single-cell transcriptomics data.",
      "domains": [
        "Bioinformatics",
        "Genomics"
      ],
      "subtask_category": [
        "visualization",
        "differential_expression_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/interactivereport/cellxgene_VIP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "single-cell",
        "visualization",
        "genomics",
        "cellxgene"
      ],
      "id": 392
    },
    {
      "name": "Slurm Bank",
      "one_line_profile": "Resource accounting wrapper for Slurm",
      "detailed_description": "A collection of wrapper scripts for Slurm to provide banking/accounting capabilities (similar to GOLD), allowing HPC centers to manage compute allocations and project budgets.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "resource_accounting",
        "allocation_management"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/jcftang/slurm-bank",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "slurm",
        "accounting",
        "hpc",
        "resource-management"
      ],
      "id": 393
    },
    {
      "name": "autoray",
      "one_line_profile": "Abstract array operations for backend-agnostic scientific computing",
      "detailed_description": "A lightweight library that abstracts array operations, allowing scientific code to run transparently on NumPy, PyTorch, JAX, TensorFlow, Dask, and CuPy. Heavily used in quantum physics simulations (e.g., tensor networks).",
      "domains": [
        "AI6",
        "Scientific Computing"
      ],
      "subtask_category": [
        "array_computing",
        "backend_abstraction"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jcmgray/autoray",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "numpy",
        "pytorch",
        "jax",
        "tensor-networks"
      ],
      "id": 394
    },
    {
      "name": "smk-simple-slurm",
      "one_line_profile": "Simple Slurm profile for Snakemake",
      "detailed_description": "A configuration profile for Snakemake that simplifies the execution of scientific workflows on Slurm clusters, handling job submission and resource specification without complex cluster configuration files.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_execution",
        "job_submission"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/jdblischak/smk-simple-slurm",
      "help_website": [],
      "license": "CC0-1.0",
      "tags": [
        "snakemake",
        "slurm",
        "workflow",
        "hpc"
      ],
      "id": 395
    },
    {
      "name": "GeoWombat",
      "one_line_profile": "Utilities for geospatial data processing",
      "detailed_description": "A Python package for processing geospatial data at scale. It simplifies tasks like reading/writing rasters, tiling, and applying functions over large satellite imagery datasets, often used in earth science research.",
      "domains": [
        "Geoscience",
        "Remote Sensing"
      ],
      "subtask_category": [
        "geospatial_analysis",
        "image_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jgrss/geowombat",
      "help_website": [
        "https://geowombat.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "geospatial",
        "remote-sensing",
        "raster",
        "satellite-imagery"
      ],
      "id": 396
    },
    {
      "name": "Swifter",
      "one_line_profile": "Efficiently applies any function to a pandas dataframe or series in the fastest available manner",
      "detailed_description": "A library that accelerates pandas DataFrame operations by automatically vectorizing or parallelizing computations using Dask or multiprocessing, essential for processing large scientific datasets.",
      "domains": [
        "AI6",
        "Data Science"
      ],
      "subtask_category": [
        "data_processing",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jmcarpenter2/swifter",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pandas",
        "acceleration",
        "parallel-computing",
        "data-processing"
      ],
      "id": 397
    },
    {
      "name": "BatchSpawner",
      "one_line_profile": "Custom Spawner for Jupyterhub to start servers in batch scheduled systems",
      "detailed_description": "A JupyterHub spawner that enables launching Jupyter notebook servers as batch jobs on HPC schedulers like Slurm, HTCondor, and Torque, bridging interactive computing with HPC infrastructure.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "interactive_computing"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/jupyterhub/batchspawner",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "jupyterhub",
        "hpc",
        "slurm",
        "batch-scheduling"
      ],
      "id": 398
    },
    {
      "name": "Task Spooler",
      "one_line_profile": "A UNIX batch system where tasks submitted from a shell are run one after another",
      "detailed_description": "A lightweight job scheduling tool for single machines that allows users to queue commands (tasks) for sequential execution, useful for managing scientific simulations or data processing jobs on workstations.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "task_queue"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/justanhduc/task-spooler",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "scheduler",
        "batch-system",
        "cli",
        "queue"
      ],
      "id": 399
    },
    {
      "name": "Turm",
      "one_line_profile": "TUI for the Slurm Workload Manager",
      "detailed_description": "A terminal user interface (TUI) for monitoring and managing jobs on the Slurm Workload Manager, providing a visual way to interact with HPC clusters.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "monitoring"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/kabouzeid/turm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "hpc",
        "tui",
        "monitoring"
      ],
      "id": 400
    },
    {
      "name": "EnhancedVolcano",
      "one_line_profile": "Publication-ready volcano plots with enhanced colouring and labeling",
      "detailed_description": "An R package for generating highly customizable volcano plots to visualize differential expression results in bioinformatics and genomics research.",
      "domains": [
        "Bioinformatics"
      ],
      "subtask_category": [
        "visualization",
        "differential_expression"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/kevinblighe/EnhancedVolcano",
      "help_website": [
        "https://bioconductor.org/packages/release/bioc/html/EnhancedVolcano.html"
      ],
      "license": "GPL-3.0",
      "tags": [
        "volcano-plot",
        "genomics",
        "visualization",
        "r-package"
      ],
      "id": 401
    },
    {
      "name": "kube-batch",
      "one_line_profile": "A batch scheduler of kubernetes for high performance workload",
      "detailed_description": "A batch scheduler for Kubernetes designed for high-performance workloads such as AI/ML, Big Data, and HPC, supporting advanced scheduling policies like gang scheduling.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "workload_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubernetes-retired/kube-batch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "batch-scheduling",
        "hpc",
        "gang-scheduling"
      ],
      "id": 402
    },
    {
      "name": "JobSet",
      "one_line_profile": "A Kubernetes-native API for distributed ML training and HPC workloads",
      "detailed_description": "A Kubernetes controller that manages groups of related jobs (JobSets) as a single unit, specifically designed to handle distributed machine learning training and HPC workloads with failure recovery policies.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workload_management",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubernetes-sigs/jobset",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "hpc",
        "machine-learning",
        "distributed-training"
      ],
      "id": 403
    },
    {
      "name": "Kueue",
      "one_line_profile": "Kubernetes-native Job Queueing",
      "detailed_description": "A job queueing controller for Kubernetes that manages quotas and job admission, enabling batch scheduling capabilities similar to traditional HPC schedulers within a cloud-native environment.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_queueing",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubernetes-sigs/kueue",
      "help_website": [
        "https://kueue.sigs.k8s.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "batch-queueing",
        "job-management",
        "hpc"
      ],
      "id": 404
    },
    {
      "name": "ggvolc",
      "one_line_profile": "Translates differential expression datasets into informative volcano plots",
      "detailed_description": "An R package designed to simplify the creation of volcano plots for RNA-seq and differential expression data, allowing for easy visualization of genes of interest.",
      "domains": [
        "Bioinformatics"
      ],
      "subtask_category": [
        "visualization",
        "differential_expression"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/loukesio/ggvolc",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "volcano-plot",
        "visualization",
        "rnaseq",
        "r"
      ],
      "id": 405
    },
    {
      "name": "Mars",
      "one_line_profile": "Tensor-based unified framework for scaling numpy, pandas, and scikit-learn",
      "detailed_description": "Mars is a tensor-based unified framework for large-scale data computation which scales Python scientific libraries like numpy, pandas, and scikit-learn. It allows researchers to run data-intensive scientific computing tasks on distributed clusters with minimal code changes.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_computing",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mars-project/mars",
      "help_website": [
        "https://mars-project.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-computing",
        "tensor",
        "numpy-compatible",
        "parallel-computing"
      ],
      "id": 406
    },
    {
      "name": "LiCSAlert",
      "one_line_profile": "Volcano monitoring system using Sentinel-1 InSAR data",
      "detailed_description": "LiCSAlert is a tool for automatic volcano monitoring that processes Sentinel-1 InSAR data to detect ground deformation. It is designed to assist in the surveillance of volcanic activity through satellite remote sensing data analysis.",
      "domains": [
        "Earth Science",
        "Geophysics"
      ],
      "subtask_category": [
        "remote_sensing_analysis",
        "anomaly_detection"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/matthew-gaddes/LiCSAlert",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "volcanology",
        "insar",
        "remote-sensing",
        "monitoring"
      ],
      "id": 407
    },
    {
      "name": "ssubmit",
      "one_line_profile": "CLI tool to submit Slurm jobs without writing sbatch scripts",
      "detailed_description": "ssubmit is a command-line utility that simplifies the submission of jobs to the Slurm workload manager. It allows users to submit jobs directly without the need to create and manage temporary sbatch scripts, streamlining the HPC workflow.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "workflow_management"
      ],
      "application_level": "tool",
      "primary_language": "Rust",
      "repo_url": "https://github.com/mbhall88/ssubmit",
      "help_website": [],
      "license": "Unlicense",
      "tags": [
        "slurm",
        "hpc",
        "cli",
        "productivity"
      ],
      "id": 408
    },
    {
      "name": "TorchX",
      "one_line_profile": "Universal job launcher for PyTorch applications on HPC and Cloud",
      "detailed_description": "TorchX is a universal job launcher and workflow engine for PyTorch applications. It supports submitting distributed training and batch inference jobs to various schedulers including Slurm, Kubernetes, AWS Batch, and Ray, facilitating reproducible AI research.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/meta-pytorch/torchx",
      "help_website": [
        "https://pytorch.org/torchx/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "pytorch",
        "job-launcher",
        "slurm",
        "kubernetes",
        "mlops"
      ],
      "id": 409
    },
    {
      "name": "CRA",
      "one_line_profile": "Common Runtime for Applications for distributed dataflow",
      "detailed_description": "Common Runtime for Applications (CRA) is a library designed to simplify the creation and deployment of distributed dataflow-style applications. It abstracts resource management on clusters like Kubernetes and YARN, useful for building custom scientific distributed computing systems.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "distributed_computing",
        "resource_management"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/microsoft/CRA",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "distributed-systems",
        "dataflow",
        "runtime",
        "microsoft-research"
      ],
      "id": 410
    },
    {
      "name": "OpenPAI",
      "one_line_profile": "Resource scheduling and cluster management platform for AI",
      "detailed_description": "OpenPAI is an open-source platform that provides complete AI model training and resource management capabilities. It supports job scheduling, cluster monitoring, and efficient resource utilization for large-scale AI for Science workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_management",
        "job_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/microsoft/pai",
      "help_website": [
        "https://openpai.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "ai-platform",
        "cluster-management",
        "kubernetes",
        "gpu-scheduling"
      ],
      "id": 411
    },
    {
      "name": "stui",
      "one_line_profile": "Terminal-based dashboard for monitoring Slurm jobs",
      "detailed_description": "stui is a terminal user interface (TUI) for the Slurm workload manager. It allows researchers and administrators to monitor job status, node utilization, and cluster health directly from the command line in an interactive dashboard.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "monitoring",
        "job_management"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/mil-ad/stui",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "tui",
        "monitoring",
        "hpc"
      ],
      "id": 412
    },
    {
      "name": "batchtools",
      "one_line_profile": "R package for high-performance computing on batch systems",
      "detailed_description": "batchtools is an R package that provides a unified interface for parallel computing on batch systems like Slurm, LSF, SGE, and Torque. It handles job submission, status monitoring, and result collection, enabling scalable scientific data analysis in R.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "parallel_computing"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/mlr-org/batchtools",
      "help_website": [
        "https://mllg.github.io/batchtools/"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "r",
        "hpc",
        "slurm",
        "parallel-computing"
      ],
      "id": 413
    },
    {
      "name": "pbrt-v4",
      "one_line_profile": "Physically based rendering system for light transport simulation",
      "detailed_description": "pbrt-v4 is the source code for the fourth edition of 'Physically Based Rendering'. It is a comprehensive rendering system that simulates the physical behavior of light, widely used in computer graphics research and optical simulation.",
      "domains": [
        "Physics",
        "Computer Graphics"
      ],
      "subtask_category": [
        "simulation",
        "rendering"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/mmp/pbrt-v4",
      "help_website": [
        "https://pbrt.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "rendering",
        "ray-tracing",
        "physics-simulation",
        "optics"
      ],
      "id": 414
    },
    {
      "name": "clustermq",
      "one_line_profile": "Efficient parallelization of R function calls on HPC clusters",
      "detailed_description": "clustermq is an R package that sends function calls as jobs to HPC schedulers (Slurm, LSF, SGE, etc.) or via SSH. It reduces the overhead of job submission and management compared to traditional batch scripts, optimizing high-throughput scientific computing in R.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "parallel_computing"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/mschubert/clustermq",
      "help_website": [
        "https://mschubert.github.io/clustermq/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "r",
        "hpc",
        "slurm",
        "parallelization"
      ],
      "id": 415
    },
    {
      "name": "Lexcube",
      "one_line_profile": "Interactive 3D visualization for Earth system data cubes",
      "detailed_description": "Lexcube is a tool for the interactive 3D visualization of large Earth system data cubes within Jupyter Notebooks. It enables scientists to explore and analyze massive spatiotemporal datasets (e.g., climate data) efficiently.",
      "domains": [
        "Earth Science",
        "Climate Science"
      ],
      "subtask_category": [
        "visualization",
        "data_exploration"
      ],
      "application_level": "tool",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/msoechting/lexcube",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "visualization",
        "earth-science",
        "data-cube",
        "jupyter"
      ],
      "id": 416
    },
    {
      "name": "Narwhals",
      "one_line_profile": "Compatibility layer for scientific dataframe libraries",
      "detailed_description": "Narwhals is a lightweight compatibility layer that allows library developers to write dataframe-agnostic code. It supports pandas, Polars, and other dataframe libraries, facilitating the development of interoperable scientific data analysis tools.",
      "domains": [
        "AI6",
        "Data Science"
      ],
      "subtask_category": [
        "data_processing",
        "interoperability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/narwhals-dev/narwhals",
      "help_website": [
        "https://narwhals-dev.github.io/narwhals/"
      ],
      "license": "MIT",
      "tags": [
        "dataframe",
        "pandas",
        "polars",
        "compatibility"
      ],
      "id": 417
    },
    {
      "name": "scores",
      "one_line_profile": "Metrics for verification and evaluation of weather and climate forecasts",
      "detailed_description": "scores is a Python package containing mathematical functions for the verification, evaluation, and optimization of forecasts, predictions, or models, specifically tailored for meteorology and climate science applications.",
      "domains": [
        "Earth Science",
        "Meteorology"
      ],
      "subtask_category": [
        "model_evaluation",
        "verification"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/nci/scores",
      "help_website": [
        "https://scores.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "meteorology",
        "verification",
        "metrics",
        "climate-science"
      ],
      "id": 418
    },
    {
      "name": "NCSA Scheduler",
      "one_line_profile": "Aggregate job launcher for HPC environments",
      "detailed_description": "The NCSA Scheduler is a tool designed to aggregate and launch single-core or single-node applications on HPC sites. It helps optimize job scheduling and resource usage on supercomputing clusters.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "workload_management"
      ],
      "application_level": "tool",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/ncsa/Scheduler",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "scheduler",
        "ncsa",
        "job-launcher"
      ],
      "id": 419
    },
    {
      "name": "Nebari",
      "one_line_profile": "Open source data science platform for scalable collaboration",
      "detailed_description": "Nebari is an opinionated, open-source data science platform that integrates JupyterHub, Dask, and Conda. It provides a reproducible and scalable environment for scientific collaboration and data analysis on cloud or on-premise infrastructure.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "environment_management",
        "collaborative_science"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/nebari-dev/nebari",
      "help_website": [
        "https://www.nebari.dev/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "data-science",
        "jupyterhub",
        "dask",
        "platform"
      ],
      "id": 420
    },
    {
      "name": "soperator",
      "one_line_profile": "Kubernetes operator for running Slurm clusters",
      "detailed_description": "soperator is a Kubernetes operator that manages the deployment and lifecycle of Slurm clusters on Kubernetes. It enables the convergence of HPC and cloud-native workflows by running Slurm workloads within a Kubernetes environment.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_management",
        "orchestration"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/nebius/soperator",
      "help_website": [
        "https://nebius.ai/slurm-operator"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "slurm",
        "operator",
        "hpc-on-k8s"
      ],
      "id": 421
    },
    {
      "name": "Slurm-Mail",
      "one_line_profile": "Enhanced email notification system for Slurm jobs",
      "detailed_description": "A drop-in replacement for standard Slurm email notifications that provides users with comprehensive job information, including resource usage and status details, improving observability for HPC workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_monitoring",
        "hpc_utility"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/neilmunday/slurm-mail",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "slurm",
        "hpc",
        "monitoring",
        "email-notifications"
      ],
      "id": 422
    },
    {
      "name": "OAR",
      "one_line_profile": "Versatile resource and task manager for HPC clusters",
      "detailed_description": "A batch scheduler and resource manager for high-performance computing clusters. It provides a flexible architecture for managing jobs, resources, and scheduling policies, widely used in research infrastructures like Grid'5000.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Perl",
      "repo_url": "https://github.com/oar-team/oar",
      "help_website": [
        "http://oar.imag.fr/"
      ],
      "license": "GPL-2.0",
      "tags": [
        "hpc",
        "scheduler",
        "batch-system",
        "cluster-management"
      ],
      "id": 423
    },
    {
      "name": "OAR3",
      "one_line_profile": "Next-generation Python-based OAR scheduler",
      "detailed_description": "The third generation of the OAR resource and job manager, rewritten in Python to provide a more modern, maintainable, and extensible architecture for cluster scheduling.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/oar-team/oar3",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "scheduler",
        "python",
        "cluster"
      ],
      "id": 424
    },
    {
      "name": "Funnel",
      "one_line_profile": "Distributed task execution toolkit implementing GA4GH TES",
      "detailed_description": "A toolkit for distributed task execution that implements the GA4GH Task Execution Schema (TES), enabling standardized job submission and execution across various compute backends (HPC, Cloud) for genomics and bioinformatics workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "task_execution",
        "genomics_workflow"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/ohsu-comp-bio/funnel",
      "help_website": [
        "https://ohsu-comp-bio.github.io/funnel/"
      ],
      "license": "MIT",
      "tags": [
        "ga4gh",
        "tes",
        "bioinformatics",
        "distributed-computing",
        "task-runner"
      ],
      "id": 425
    },
    {
      "name": "CCQHub",
      "one_line_profile": "Meta-scheduler for linking disparate HPC environments",
      "detailed_description": "A meta-scheduler designed to connect different HPC environments, allowing jobs to be treated as payloads that can be routed and executed across disparate computing resources.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "meta_scheduling",
        "hpc_interoperability"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/omnibond/CCQHub",
      "help_website": [],
      "license": "LGPL-3.0",
      "tags": [
        "hpc",
        "meta-scheduler",
        "cloud-bursting",
        "job-management"
      ],
      "id": 426
    },
    {
      "name": "CoexecutorRuntime",
      "one_line_profile": "Runtime for heterogeneous computing scheduling in oneAPI",
      "detailed_description": "A runtime environment associated with Intel's oneAPI ecosystem, designed to facilitate straightforward heterogeneous computing and scheduling across different accelerator architectures.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "heterogeneous_scheduling",
        "runtime_acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/oneAPI-scheduling/CoexecutorRuntime",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "oneapi",
        "hpc",
        "heterogeneous-computing",
        "scheduling"
      ],
      "id": 427
    },
    {
      "name": "Kubernetes EC2 Autoscaler",
      "one_line_profile": "Batch-optimized scaling manager for Kubernetes on AWS",
      "detailed_description": "A Kubernetes autoscaler optimized for batch workloads (like AI training and scientific simulations), managing EC2 ASGs to efficiently scale compute resources based on pending job requirements.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "resource_scaling",
        "cloud_hpc"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/openai/kubernetes-ec2-autoscaler",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kubernetes",
        "autoscaling",
        "batch-processing",
        "aws",
        "ai-infra"
      ],
      "id": 428
    },
    {
      "name": "Gridscale",
      "one_line_profile": "Scala library for accessing grid and batch schedulers",
      "detailed_description": "A library used by the OpenMOLE workflow engine to abstract interactions with various computing backends, including local execution, SSH, Slurm, PBS, and grid middlewares, facilitating distributed scientific computing.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "grid_computing"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/openmole/gridscale",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "scala",
        "hpc",
        "grid-computing",
        "middleware",
        "job-submission"
      ],
      "id": 429
    },
    {
      "name": "OpenPBS",
      "one_line_profile": "HPC workload manager and job scheduler",
      "detailed_description": "An open-source version of the Portable Batch System (PBS), a widely used workload manager for HPC clusters, clouds, and supercomputers, responsible for scheduling and managing computational jobs.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_scheduling",
        "workload_management"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/openpbs/openpbs",
      "help_website": [
        "https://www.openpbs.org"
      ],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "scheduler",
        "workload-manager",
        "cluster"
      ],
      "id": 430
    },
    {
      "name": "Kueue Operator",
      "one_line_profile": "Operator for managing Kueue job queuing system on Kubernetes",
      "detailed_description": "A Kubernetes operator to deploy and manage Kueue, a cloud-native job queueing system that manages batch jobs and resource quotas, essential for running AI/ML and scientific batch workloads on Kubernetes.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "batch_scheduling",
        "k8s_operator"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/openshift/kueue-operator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "batch-jobs",
        "operator",
        "kueue",
        "ai-infra"
      ],
      "id": 431
    },
    {
      "name": "django-remote-submission",
      "one_line_profile": "Django app for remote job submission to HPC clusters",
      "detailed_description": "A Django application developed at ORNL that facilitates asynchronous task submission and monitoring on remote HPC resources (via Celery and Redis), typically used to build science gateways and web portals for research.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "science_gateway"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ornl-ndav/django-remote-submission",
      "help_website": [],
      "license": "ISC",
      "tags": [
        "hpc",
        "django",
        "celery",
        "job-submission",
        "science-gateway"
      ],
      "id": 432
    },
    {
      "name": "ATOS",
      "one_line_profile": "Multi-GPU dynamic scheduler with PGAS communication",
      "detailed_description": "A research scheduler for multi-GPU environments that utilizes PGAS-style cross-GPU communication to optimize dynamic task scheduling and execution efficiency in high-performance computing contexts.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "gpu_scheduling",
        "parallel_computing"
      ],
      "application_level": "solver",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/owensgroup/ATOS",
      "help_website": [],
      "license": null,
      "tags": [
        "gpu",
        "cuda",
        "scheduling",
        "hpc",
        "pgas"
      ],
      "id": 433
    },
    {
      "name": "mgpuscheduler",
      "one_line_profile": "Multi-GPU CUDA-based scheduler",
      "detailed_description": "A scheduler designed for managing and executing tasks across multiple GPUs using CUDA, developed for research into efficient GPU utilization and parallel task management.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "gpu_scheduling",
        "parallel_computing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/owensgroup/mgpuscheduler",
      "help_website": [],
      "license": null,
      "tags": [
        "gpu",
        "cuda",
        "scheduler",
        "hpc"
      ],
      "id": 434
    },
    {
      "name": "Climpred",
      "one_line_profile": "Verification tool for weather and climate forecasts",
      "detailed_description": "A python package for the verification and analysis of weather and climate forecasts. It provides statistical tools to assess the skill of prediction models against observations.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "forecast_verification",
        "climate_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pangeo-data/climpred",
      "help_website": [
        "https://climpred.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "climate-science",
        "weather-forecasting",
        "verification",
        "geoscience",
        "pangeo"
      ],
      "id": 435
    },
    {
      "name": "mpify",
      "one_line_profile": "MPI-like multiprocessing for Python in Jupyter",
      "detailed_description": "A simple API to launch Python functions on multiple ranked processes, enabling interactive distributed data parallel experiments (e.g., for AI training) directly from Jupyter/IPython environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_computing",
        "interactive_hpc"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/philtrade/mpify",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multiprocessing",
        "jupyter",
        "distributed-training",
        "mpi",
        "python"
      ],
      "id": 436
    },
    {
      "name": "Pipefunc",
      "one_line_profile": "Lightweight pipeline creation for scientific HPC workflows",
      "detailed_description": "A Python library for creating lightweight, fast function pipelines (DAGs) specifically designed for scientific and HPC workflows, facilitating modular code structure and execution.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_creation",
        "pipeline_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pipefunc/pipefunc",
      "help_website": [
        "https://pipefunc.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "pipeline",
        "dag",
        "hpc",
        "scientific-computing",
        "workflow"
      ],
      "id": 437
    },
    {
      "name": "slurm-rs",
      "one_line_profile": "Rust bindings for Slurm workload manager",
      "detailed_description": "Rust language bindings for interacting with the Slurm workload manager API, enabling the development of high-performance tools and utilities for HPC job management in Rust.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "hpc_development",
        "job_management_api"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/pkgw/slurm-rs",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rust",
        "slurm",
        "hpc",
        "bindings"
      ],
      "id": 438
    },
    {
      "name": "Soopervisor",
      "one_line_profile": "Exporter for Ploomber pipelines to HPC and Cloud platforms",
      "detailed_description": "A tool that exports Ploomber data science pipelines to various execution environments including Kubernetes (Argo), Airflow, AWS Batch, and SLURM, bridging local development and production/HPC execution.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "pipeline_deployment",
        "workflow_export"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/ploomber/soopervisor",
      "help_website": [
        "https://soopervisor.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ploomber",
        "pipeline",
        "slurm",
        "kubernetes",
        "mlops"
      ],
      "id": 439
    },
    {
      "name": "ScanTools",
      "one_line_profile": "Genomic selection analysis tools and Slurm wrapper",
      "detailed_description": "A collection of tools for analyzing selection in genomic data, including a wrapper for simplifying job submission to Slurm clusters, tailored for bioinformatics research.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "genomics_analysis",
        "job_submission"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/pmonnahan/ScanTools",
      "help_website": [],
      "license": null,
      "tags": [
        "genomics",
        "bioinformatics",
        "slurm",
        "selection-analysis"
      ],
      "id": 440
    },
    {
      "name": "TraceML",
      "one_line_profile": "ML/Data tracking and visualization engine for Polyaxon",
      "detailed_description": "The tracking and visualization engine for the Polyaxon platform, providing capabilities for logging experiments, visualizing metrics, and detecting drift in machine learning workflows used in research and production.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "experiment_tracking",
        "mlops"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/polyaxon/traceml",
      "help_website": [
        "https://polyaxon.com/docs/experimentation/tracking/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "tracking",
        "visualization",
        "polyaxon",
        "experiment-management"
      ],
      "id": 441
    },
    {
      "name": "AppWrapper",
      "one_line_profile": "Kueue controller for managing AI/HPC applications on Kubernetes",
      "detailed_description": "Part of the Project CodeFlare, AppWrapper is a Kubernetes controller that integrates with Kueue to provide advanced queuing, resource management, and lifecycle handling for complex AI and HPC applications.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "application_management",
        "batch_scheduling"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/project-codeflare/appwrapper",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "hpc",
        "ai",
        "controller",
        "codeflare"
      ],
      "id": 442
    },
    {
      "name": "MLBatch",
      "one_line_profile": "Queuing and quota management for AI/ML batch jobs",
      "detailed_description": "A system for managing queuing and resource quotas specifically for AI/ML batch jobs on Kubernetes, ensuring efficient utilization of cluster resources for training and inference workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "batch_management",
        "resource_quota"
      ],
      "application_level": "service",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/project-codeflare/mlbatch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "ml",
        "batch-jobs",
        "quota-management"
      ],
      "id": 443
    },
    {
      "name": "PyCondor",
      "one_line_profile": "Python utility for HTCondor workflow submission",
      "detailed_description": "A Python package that simplifies the process of building and submitting workflows to the HTCondor high-throughput computing system, allowing users to define jobs and DAGs using Python objects.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "workflow_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pycondor/pycondor",
      "help_website": [
        "https://pycondor.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "htcondor",
        "hpc",
        "workflow",
        "python",
        "high-throughput-computing"
      ],
      "id": 444
    },
    {
      "name": "xarray",
      "one_line_profile": "N-D labeled arrays and datasets in Python",
      "detailed_description": "Xarray introduces labels in the form of dimensions, coordinates and attributes on top of raw NumPy-like arrays, which allows for a more intuitive, more concise, and less error-prone developer experience. It is widely used in physics, climate science, and oceanography for handling multi-dimensional scientific data.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "data_processing",
        "multidimensional_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pydata/xarray",
      "help_website": [
        "https://docs.xarray.dev"
      ],
      "license": "Apache-2.0",
      "tags": [
        "scientific-computing",
        "multi-dimensional-arrays",
        "netcdf"
      ],
      "id": 445
    },
    {
      "name": "pyresample",
      "one_line_profile": "Geospatial image resampling in Python",
      "detailed_description": "A Python package for resampling geospatial image data. It is primarily designed for resampling earth observation satellite data and handling various map projections.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_processing",
        "resampling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pytroll/pyresample",
      "help_website": [
        "https://pyresample.readthedocs.io"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "geospatial",
        "remote-sensing",
        "resampling"
      ],
      "id": 446
    },
    {
      "name": "satpy",
      "one_line_profile": "Python package for earth-observing satellite data processing",
      "detailed_description": "Satpy is a python library for reading, manipulating, and writing meteorological remote sensing data. It supports various satellite instrument formats and provides functionality for compositing and resampling.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_processing",
        "satellite_imaging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pytroll/satpy",
      "help_website": [
        "https://satpy.readthedocs.io"
      ],
      "license": "GPL-3.0",
      "tags": [
        "remote-sensing",
        "meteorology",
        "satellite-data"
      ],
      "id": 447
    },
    {
      "name": "Slurm-web",
      "one_line_profile": "Open source web interface for Slurm HPC & AI clusters",
      "detailed_description": "A web interface for the Slurm workload manager, providing a dashboard for monitoring cluster status and jobs, tailored for HPC and AI research environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "cluster_monitoring"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/rackslab/Slurm-web",
      "help_website": [
        "https://rackslab.github.io/Slurm-web"
      ],
      "license": "MIT",
      "tags": [
        "hpc",
        "slurm",
        "web-interface"
      ],
      "id": 448
    },
    {
      "name": "Crater",
      "one_line_profile": "Cloud-native AI training & inference platform",
      "detailed_description": "A platform designed to streamline AI training and inference workloads on cloud-native infrastructure, facilitating the execution of scientific machine learning models.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "model_training",
        "inference_serving"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/raids-lab/crater",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ai-platform",
        "training",
        "inference"
      ],
      "id": 449
    },
    {
      "name": "cuDF",
      "one_line_profile": "GPU DataFrame Library",
      "detailed_description": "A GPU DataFrame library for loading, joining, aggregating, filtering, and manipulating data, built on the Apache Arrow columnar memory format. It accelerates scientific data processing pipelines.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_processing",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/rapidsai/cudf",
      "help_website": [
        "https://docs.rapids.ai/api/cudf/stable/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "gpu",
        "dataframe",
        "rapids"
      ],
      "id": 450
    },
    {
      "name": "dask-cuda",
      "one_line_profile": "Utilities for Dask and CUDA interactions",
      "detailed_description": "Utilities for using Dask with CUDA-enabled GPUs, including cluster management and worker configuration, enabling distributed parallel computing for scientific workloads.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_computing",
        "gpu_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rapidsai/dask-cuda",
      "help_website": [
        "https://docs.rapids.ai/api/dask-cuda/stable/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dask",
        "cuda",
        "distributed-computing"
      ],
      "id": 451
    },
    {
      "name": "dask-cudf",
      "one_line_profile": "Dask support for distributed GDF object",
      "detailed_description": "A library that connects Dask and cuDF to provide distributed GPU DataFrames, allowing for scaling of scientific data processing across multiple GPUs.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_processing",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/rapidsai/dask-cudf",
      "help_website": [
        "https://docs.rapids.ai/api/dask-cudf/stable/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dask",
        "cudf",
        "gpu"
      ],
      "id": 452
    },
    {
      "name": "KubeRay",
      "one_line_profile": "A toolkit to run Ray applications on Kubernetes",
      "detailed_description": "KubeRay is a Kubernetes operator for managing Ray clusters, simplifying the deployment and management of distributed AI and scientific computing applications on K8s.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_management",
        "distributed_computing"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/ray-project/kuberay",
      "help_website": [
        "https://ray-project.github.io/kuberay/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ray",
        "kubernetes",
        "operator"
      ],
      "id": 453
    },
    {
      "name": "Ray",
      "one_line_profile": "Unified framework for scaling AI and Python applications",
      "detailed_description": "Ray provides a simple, universal API for building distributed applications. It is widely used for scaling scientific AI workloads like reinforcement learning, hyperparameter tuning, and model training.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "distributed_computing",
        "model_training"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ray-project/ray",
      "help_website": [
        "https://docs.ray.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-computing",
        "machine-learning",
        "scaling"
      ],
      "id": 454
    },
    {
      "name": "XGBoost on Ray",
      "one_line_profile": "Distributed XGBoost on Ray",
      "detailed_description": "A library for training XGBoost models at scale using Ray clusters, enabling efficient processing of large-scale scientific datasets.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "model_training",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ray-project/xgboost_ray",
      "help_website": [
        "https://docs.ray.io/en/latest/ray-air/examples/xgboost_example.html"
      ],
      "license": "Apache-2.0",
      "tags": [
        "xgboost",
        "ray",
        "distributed-ml"
      ],
      "id": 455
    },
    {
      "name": "ezpz",
      "one_line_profile": "Distributed training utility for PyTorch",
      "detailed_description": "A lightweight wrapper to simplify distributed training across multiple devices and nodes, facilitating scientific machine learning experiments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "model_training",
        "distributed_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/saforem2/ezpz",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "distributed-training",
        "ddp"
      ],
      "id": 456
    },
    {
      "name": "Kuscia",
      "one_line_profile": "Kubernetes-based privacy-preserving computing task orchestration framework",
      "detailed_description": "A lightweight, privacy-preserving computing task orchestration framework based on Kubernetes, designed for secure collaborative analysis of sensitive scientific or medical data.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "task_orchestration",
        "privacy_preserving_computing"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/secretflow/kuscia",
      "help_website": [
        "https://www.secretflow.org.cn/docs/kuscia/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "privacy-computing",
        "kubernetes",
        "orchestration"
      ],
      "id": 457
    },
    {
      "name": "spark-gateway",
      "one_line_profile": "REST API for interacting with batch Spark Applications on Kubernetes",
      "detailed_description": "A gateway service that provides a REST API to submit and manage Spark batch applications on Kubernetes clusters, facilitating big data processing for scientific research.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "batch_processing"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/slackhq/spark-gateway",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "spark",
        "kubernetes",
        "batch-processing"
      ],
      "id": 458
    },
    {
      "name": "snakemake-executor-plugin-kueue",
      "one_line_profile": "Snakemake executor plugin for Kueue on Kubernetes",
      "detailed_description": "A plugin for Snakemake that allows scientific workflow jobs to be executed via the Kueue job queueing system on Kubernetes, enabling scalable workflow execution.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_execution",
        "job_scheduling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/snakemake/snakemake-executor-plugin-kueue",
      "help_website": [
        "https://snakemake.github.io/snakemake-plugin-catalog/plugins/executor/kueue.html"
      ],
      "license": "MIT",
      "tags": [
        "snakemake",
        "kueue",
        "kubernetes"
      ],
      "id": 459
    },
    {
      "name": "STUMPY",
      "one_line_profile": "Scalable Python library for modern time series analysis using Matrix Profiles",
      "detailed_description": "STUMPY is a powerful and scalable Python library that efficiently computes the matrix profile for time series data. It is used for pattern discovery, anomaly detection, and semantic segmentation in scientific and industrial time series analysis.",
      "domains": [
        "AI1",
        "AI1-01"
      ],
      "subtask_category": [
        "time_series_analysis",
        "motif_discovery",
        "anomaly_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/stumpy-dev/stumpy",
      "help_website": [
        "https://stumpy.readthedocs.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "time-series",
        "matrix-profile",
        "data-analysis"
      ],
      "id": 460
    },
    {
      "name": "wlm-operator",
      "one_line_profile": "Kubernetes operator for interacting with Slurm workloads via Singularity",
      "detailed_description": "A Kubernetes operator that serves as a bridge between Kubernetes and Slurm Workload Manager. It allows for the submission and management of Slurm jobs directly from a Kubernetes environment, utilizing Singularity containers for HPC compatibility.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "workload_management",
        "hpc_integration"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/sylabs/wlm-operator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "slurm",
        "kubernetes",
        "singularity",
        "hpc"
      ],
      "id": 461
    },
    {
      "name": "pbstools",
      "one_line_profile": "Administration and management utilities for PBS/TORQUE HPC schedulers",
      "detailed_description": "A collection of utilities designed to assist in the administration, use, and management of PBS (Portable Batch System) variants, including OpenPBS, PBS Pro, and TORQUE, facilitating HPC cluster operations.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_administration",
        "job_management"
      ],
      "application_level": "library",
      "primary_language": "PHP",
      "repo_url": "https://github.com/tabaer/pbstools",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "pbs",
        "torque",
        "hpc",
        "scheduler"
      ],
      "id": 462
    },
    {
      "name": "Slurm4Azure",
      "one_line_profile": "Deployment scripts for Slurm Workload Manager on Microsoft Azure",
      "detailed_description": "A set of tools and scripts to deploy and configure the Slurm Workload Manager on Ubuntu instances within the Microsoft Azure cloud environment, enabling cloud-based HPC clusters.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_deployment",
        "cloud_hpc"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/tamhinsf/Slurm4Azure",
      "help_website": [],
      "license": null,
      "tags": [
        "slurm",
        "azure",
        "hpc",
        "cloud-computing"
      ],
      "id": 463
    },
    {
      "name": "GooseSLURM",
      "one_line_profile": "Command line wrappers and utilities for Slurm job submission",
      "detailed_description": "A collection of Python-based command line tools and scripts that simplify the interaction with the Slurm Workload Manager, providing convenient wrappers for job submission and management tasks.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "cli_utility"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tdegeus/GooseSLURM",
      "help_website": [
        "https://gooseslurm.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "slurm",
        "cli",
        "hpc",
        "job-management"
      ],
      "id": 464
    },
    {
      "name": "condorpy",
      "one_line_profile": "Python interface for HTCondor high-throughput computing system",
      "detailed_description": "A Python module that provides an interface to interact with HTCondor, allowing users to create, submit, and manage high-throughput computing jobs programmatically from Python scripts.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_submission",
        "htc_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tethysplatform/condorpy",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "htcondor",
        "htc",
        "job-scheduling",
        "python-wrapper"
      ],
      "id": 465
    },
    {
      "name": "Paperboy",
      "one_line_profile": "Web frontend for scheduling and executing Jupyter notebook reports",
      "detailed_description": "A web-based application for scheduling and running Jupyter notebooks as reports. It allows users to parameterize notebooks and schedule their execution, facilitating reproducible scientific reporting and automated analysis workflows.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "notebook_scheduling",
        "workflow_automation",
        "reporting"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/tkp-archive/paperboy",
      "help_website": [
        "https://paperboy.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "jupyter",
        "scheduling",
        "reporting",
        "reproducibility"
      ],
      "id": 466
    },
    {
      "name": "Tuplex",
      "one_line_profile": "Parallel big data processing framework for optimizing Python data science pipelines",
      "detailed_description": "Tuplex is a parallel big data processing framework that compiles Python data science pipelines into optimized LLVM bytecode. It is designed to run Python code at the speed of compiled languages like C++, specifically targeting data cleaning and transformation tasks in scientific data analysis.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "data_processing",
        "pipeline_optimization",
        "parallel_computing"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/tuplex/tuplex",
      "help_website": [
        "https://tuplex.cs.brown.edu/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-science",
        "llvm",
        "parallel-processing",
        "python-optimization"
      ],
      "id": 467
    },
    {
      "name": "Cook",
      "one_line_profile": "Fair job scheduler for batch workloads and Spark on Kubernetes/Mesos",
      "detailed_description": "Cook is a fair job scheduler designed for batch workloads and Spark jobs, running on Kubernetes and Mesos. It provides advanced scheduling features like preemption, fair sharing, and resource pooling, suitable for high-performance computing and quantitative research environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "batch_scheduling",
        "resource_management",
        "spark_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Clojure",
      "repo_url": "https://github.com/twosigma/Cook",
      "help_website": [
        "https://github.com/twosigma/Cook/wiki"
      ],
      "license": "Apache-2.0",
      "tags": [
        "scheduler",
        "kubernetes",
        "batch-processing",
        "spark"
      ],
      "id": 468
    },
    {
      "name": "socker",
      "one_line_profile": "Wrapper for securely running Docker containers on Slurm clusters",
      "detailed_description": "A tool that wraps Docker execution to allow secure running of containers within a Slurm HPC environment. It addresses security concerns associated with running Docker in multi-user clusters by managing permissions and execution contexts.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "container_runtime",
        "hpc_security"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/unioslo/socker",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "docker",
        "slurm",
        "hpc",
        "container"
      ],
      "id": 469
    },
    {
      "name": "HTGS",
      "one_line_profile": "Hybrid Task Graph Scheduler API for high-performance computing",
      "detailed_description": "The Hybrid Task Graph Scheduler (HTGS) is an abstract execution model and API designed to facilitate the implementation of workflow systems for high-performance computing. It helps manage data dependencies and task scheduling across hybrid architectures.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "task_scheduling",
        "workflow_execution"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/usnistgov/HTGS",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "task-graph",
        "scheduler",
        "cpp"
      ],
      "id": 470
    },
    {
      "name": "Tensor Fusion",
      "one_line_profile": "GPU virtualization and pooling solution for optimizing AI cluster utilization",
      "detailed_description": "Tensor Fusion is a GPU virtualization and pooling solution designed to maximize GPU cluster utilization. It supports dynamic resource allocation and sharing for AI inference and training workloads, integrating with tools like Karpenter and PyTorch.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "gpu_virtualization",
        "resource_optimization",
        "ai_infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/veneratedcoin/tensor-fusion",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu-virtualization",
        "ai-infrastructure",
        "resource-pooling",
        "cuda"
      ],
      "id": 471
    },
    {
      "name": "Volcano",
      "one_line_profile": "Cloud Native Batch Scheduling System for Kubernetes",
      "detailed_description": "Volcano is a batch system built on Kubernetes, designed for high-performance computing (HPC) and big data workloads. It provides powerful scheduling capabilities such as gang scheduling, fair share, and queue management, making it a critical component for running AI and scientific workloads in cloud-native environments.",
      "domains": [
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "batch_scheduling",
        "workload_management",
        "resource_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/volcano-sh/volcano",
      "help_website": [
        "https://volcano.sh/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "batch-processing",
        "scheduler",
        "hpc",
        "cncf"
      ],
      "id": 472
    },
    {
      "name": "Volcano Global",
      "one_line_profile": "Federation scheduler for multi-cluster management in Volcano ecosystem",
      "detailed_description": "A federation scheduler component for the Volcano batch system, enabling cross-cluster job scheduling and resource management for cloud-native AI and HPC workloads.",
      "domains": [
        "Infra/HPC",
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "scheduling",
        "cluster_federation"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/volcano-sh/volcano-global",
      "help_website": [
        "https://volcano.sh"
      ],
      "license": "Apache-2.0",
      "tags": [
        "scheduler",
        "kubernetes",
        "hpc",
        "federation",
        "volcano"
      ],
      "id": 473
    },
    {
      "name": "veTurboIO",
      "one_line_profile": "High-performance I/O library for PyTorch model files",
      "detailed_description": "A library developed by Volcano Engine to accelerate reading and writing of PyTorch model files, optimizing I/O performance for large-scale AI model training and inference.",
      "domains": [
        "Infra/HPC",
        "AI6"
      ],
      "subtask_category": [
        "io_optimization",
        "model_loading"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/volcengine/veTurboIO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pytorch",
        "io-optimization",
        "hpc",
        "ai-infrastructure"
      ],
      "id": 474
    },
    {
      "name": "verl",
      "one_line_profile": "Volcano Engine Reinforcement Learning library for LLMs",
      "detailed_description": "A high-performance Reinforcement Learning (RL) library designed for Large Language Models (LLMs), supporting flexible and scalable RLHF (Reinforcement Learning from Human Feedback) training workflows.",
      "domains": [
        "Infra/HPC",
        "AI6"
      ],
      "subtask_category": [
        "model_training",
        "reinforcement_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/volcengine/verl",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "rlhf",
        "reinforcement-learning",
        "training-framework"
      ],
      "id": 475
    },
    {
      "name": "prometheus-slurm-exporter",
      "one_line_profile": "Prometheus exporter for Slurm metrics",
      "detailed_description": "A tool that collects performance and status metrics from the Slurm workload manager and exports them for monitoring via Prometheus, essential for HPC cluster observability.",
      "domains": [
        "Infra/HPC",
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "monitoring",
        "cluster_management"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/vpenso/prometheus-slurm-exporter",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "slurm",
        "prometheus",
        "monitoring",
        "hpc",
        "exporter"
      ],
      "id": 476
    },
    {
      "name": "Slurmer",
      "one_line_profile": "TUI application for Slurm job management",
      "detailed_description": "A Terminal User Interface (TUI) tool for monitoring and managing jobs on Slurm-based HPC clusters, providing a user-friendly way to interact with the scheduler.",
      "domains": [
        "Infra/HPC",
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "job_management",
        "monitoring"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/wjwei-handsome/Slurmer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "tui",
        "hpc",
        "job-management",
        "rust"
      ],
      "id": 477
    },
    {
      "name": "tmux-mpi",
      "one_line_profile": "Tool for launching MPI processes in tmux",
      "detailed_description": "A utility for launching and managing MPI (Message Passing Interface) processes within tmux windows, facilitating debugging and interactive monitoring of parallel HPC applications.",
      "domains": [
        "Infra/HPC",
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "process_launching",
        "debugging"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wrs20/tmux-mpi",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mpi",
        "tmux",
        "hpc",
        "parallel-computing",
        "debugging"
      ],
      "id": 478
    },
    {
      "name": "xcube",
      "one_line_profile": "Python package for Earth observation data cubes",
      "detailed_description": "A Python package for generating, manipulating, and analyzing Earth observation data cubes, leveraging xarray, dask, and zarr for scalable scientific data processing.",
      "domains": [
        "Earth Science",
        "Scientific Data Analysis"
      ],
      "subtask_category": [
        "data_cube_generation",
        "geospatial_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/xcube-dev/xcube",
      "help_website": [
        "https://xcube.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "earth-observation",
        "data-cubes",
        "xarray",
        "dask",
        "geospatial"
      ],
      "id": 479
    },
    {
      "name": "slurm-for-ml",
      "one_line_profile": "Machine Learning workflow scripts for Slurm",
      "detailed_description": "A collection of scripts and configurations designed to streamline running Machine Learning workflows on Slurm-managed HPC clusters, handling job submission and environment setup.",
      "domains": [
        "Infra/HPC",
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "workflow_management",
        "job_submission"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/y0ast/slurm-for-ml",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "machine-learning",
        "hpc",
        "workflow"
      ],
      "id": 480
    },
    {
      "name": "cuda_scheduling_examiner",
      "one_line_profile": "Tool for examining GPU scheduling behavior",
      "detailed_description": "A utility for analyzing and understanding CUDA GPU scheduling behavior, useful for performance optimization and debugging of GPU-accelerated scientific applications.",
      "domains": [
        "Infra/HPC",
        "AI6"
      ],
      "subtask_category": [
        "performance_analysis",
        "scheduling_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/yalue/cuda_scheduling_examiner_mirror",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "cuda",
        "gpu",
        "scheduling",
        "performance-analysis",
        "hpc"
      ],
      "id": 481
    },
    {
      "name": "HPC-NOW",
      "one_line_profile": "Cross-platform multi-cloud HPC platform manager",
      "detailed_description": "A command-line tool to quickly deploy and manage High-Performance Computing (HPC) clusters across multiple cloud providers or local environments, simplifying scientific computing infrastructure setup.",
      "domains": [
        "Infra/HPC",
        "AI6",
        "AI6-02"
      ],
      "subtask_category": [
        "cluster_deployment",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/zhenrong-wang/hpc-now",
      "help_website": [
        "https://hpc-now.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "hpc",
        "cloud-computing",
        "cluster-management",
        "infrastructure"
      ],
      "id": 482
    },
    {
      "name": "Spline",
      "one_line_profile": "Data lineage tracking and visualization solution for data processing engines like Spark",
      "detailed_description": "Spline is a data lineage tracking and visualization tool that captures and stores lineage information from data processing pipelines (e.g., Apache Spark), enabling reproducibility and auditing in data-intensive scientific workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_lineage",
        "provenance_tracking"
      ],
      "application_level": "service",
      "primary_language": "Scala",
      "repo_url": "https://github.com/AbsaOSS/spline",
      "help_website": [
        "https://absaoss.github.io/spline/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-lineage",
        "spark",
        "provenance",
        "visualization"
      ],
      "id": 483
    },
    {
      "name": "Alluxio",
      "one_line_profile": "Data orchestration platform for analytics and machine learning in hybrid cloud environments",
      "detailed_description": "Alluxio is a data orchestration layer that brings data closer to compute for analytics and machine learning workloads. It provides a unified file system namespace and caching to accelerate data access across heterogeneous storage systems in HPC and AI pipelines.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_orchestration",
        "caching",
        "storage_abstraction"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/Alluxio/alluxio",
      "help_website": [
        "https://www.alluxio.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-orchestration",
        "distributed-cache",
        "hpc",
        "machine-learning"
      ],
      "id": 484
    },
    {
      "name": "Alluxio Python Client",
      "one_line_profile": "Python client library for interacting with the Alluxio data orchestration system",
      "detailed_description": "The Alluxio Python client enables Python-based data science and machine learning applications to interact with the Alluxio file system, facilitating efficient data access and management within Python workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_access",
        "client_library"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Alluxio/alluxio-py",
      "help_website": [
        "https://docs.alluxio.io/os/user/stable/en/api/Python-API.html"
      ],
      "license": "Apache-2.0",
      "tags": [
        "python",
        "alluxio",
        "client",
        "data-access"
      ],
      "id": 485
    },
    {
      "name": "FedHeteroBench",
      "one_line_profile": "Benchmark framework for handling data heterogeneity in federated learning",
      "detailed_description": "FedHeteroBench is a repository and framework designed to evaluate and handle data heterogeneity in federated learning (Non-IID settings). It provides unified implementations and reproducible experiments for researching federated learning algorithms.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "federated_learning",
        "benchmarking",
        "reproducibility"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AntonioZC666/FedHeteroBench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "federated-learning",
        "benchmark",
        "non-iid",
        "heterogeneity"
      ],
      "id": 486
    },
    {
      "name": "Deep AutoViML",
      "one_line_profile": "AutoML library for building TensorFlow Keras model pipelines with MLflow tracking",
      "detailed_description": "Deep AutoViML is an automated machine learning library that simplifies the process of building deep learning models using TensorFlow and Keras. It includes built-in integration with MLflow for experiment tracking and reproducibility.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "automl",
        "model_training",
        "experiment_tracking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AutoViML/deep_autoviml",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "automl",
        "tensorflow",
        "keras",
        "mlflow",
        "deep-learning"
      ],
      "id": 487
    },
    {
      "name": "RD-CDM",
      "one_line_profile": "Ontology-based common data model for rare diseases",
      "detailed_description": "RD-CDM (Rare Disease Common Data Model) is an ontology-based framework for harmonizing international registries, FHIR, and Phenopackets, facilitating data interoperability and standardization in rare disease research.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_modeling",
        "ontology_alignment",
        "data_harmonization"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/BIH-CEI/rd-cdm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rare-disease",
        "common-data-model",
        "ontology",
        "fhir"
      ],
      "id": 488
    },
    {
      "name": "Lite Tracer",
      "one_line_profile": "Lightweight experiment reproducibility toolset for ML",
      "detailed_description": "Lite Tracer is a lightweight toolset designed to facilitate experiment reproducibility in machine learning by tracking and managing experiment configurations and artifacts.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "experiment_tracking",
        "reproducibility"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BorealisAI/lite_tracer",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "reproducibility",
        "experiment-tracking",
        "ml-ops"
      ],
      "id": 489
    },
    {
      "name": "HPC DME APIs",
      "one_line_profile": "APIs for NCI High Performance Computing Data Management Services",
      "detailed_description": "This repository contains the Common APIs for the National Cancer Institute (NCI) High Performance Computing (HPC) Data Management Services (DME), enabling researchers to programmatically interact with scientific data archives.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_management",
        "archive_access",
        "hpc_api"
      ],
      "application_level": "library",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/CBIIT/HPC_DME_APIs",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "nci",
        "hpc",
        "data-management",
        "api"
      ],
      "id": 490
    },
    {
      "name": "Scratch Manager",
      "one_line_profile": "Daemon for automating dataset caching in HPC environments",
      "detailed_description": "Scratch Manager is a daemon designed to automate the caching of read-only datasets between slow (archive) and fast (scratch) storage locations, optimizing data access for HPC workloads.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "caching",
        "storage_management",
        "hpc_io"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/CEA-LIST/scratch_manager",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "caching",
        "storage-tiering",
        "dataset-management"
      ],
      "id": 491
    },
    {
      "name": "Stochastic Caching",
      "one_line_profile": "Library for stochastic dataset caching in PyTorch",
      "detailed_description": "A lightweight library for implementing stochastic caching strategies for datasets in PyTorch, helping to optimize data loading performance in machine learning training pipelines.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "caching",
        "data_loading",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Charl-AI/stochastic-caching",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "caching",
        "data-loading",
        "optimization"
      ],
      "id": 492
    },
    {
      "name": "Oceananigans.jl",
      "one_line_profile": "Fast and flexible fluid dynamics software for ocean modeling on CPUs and GPUs",
      "detailed_description": "Oceananigans.jl is a Julia software package for fluid dynamics simulations, specifically tailored for oceanography and atmospheric science. It supports fast execution on CPUs and GPUs and provides a user-friendly interface for setting up complex simulations.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "fluid_dynamics",
        "ocean_modeling",
        "simulation"
      ],
      "application_level": "solver",
      "primary_language": "Julia",
      "repo_url": "https://github.com/CliMA/Oceananigans.jl",
      "help_website": [
        "https://clima.github.io/Oceananigans.jl/stable/"
      ],
      "license": "MIT",
      "tags": [
        "fluid-dynamics",
        "oceanography",
        "julia",
        "gpu-acceleration"
      ],
      "id": 493
    },
    {
      "name": "DagsHub Client",
      "one_line_profile": "Client library for DagsHub data versioning and collaboration platform",
      "detailed_description": "The DagsHub client library allows users to interact with the DagsHub platform, facilitating data versioning, experiment tracking, and collaboration for machine learning projects using Git and DVC.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_versioning",
        "collaboration",
        "experiment_tracking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DagsHub/client",
      "help_website": [
        "https://dagshub.com/docs/"
      ],
      "license": "MIT",
      "tags": [
        "data-versioning",
        "mlops",
        "dagshub",
        "client"
      ],
      "id": 494
    },
    {
      "name": "Fast Data Science (fds)",
      "one_line_profile": "CLI tool wrapping Git and DVC for simplified data and code version control",
      "detailed_description": "Fast Data Science (fds) is a command-line interface that simplifies the usage of Git and DVC (Data Version Control) for data scientists, streamlining the process of versioning both code and large datasets.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_versioning",
        "version_control",
        "cli"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/DagsHub/fds",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dvc",
        "git",
        "data-versioning",
        "cli"
      ],
      "id": 495
    },
    {
      "name": "GeoMet Data Registry",
      "one_line_profile": "Registry system for managing access to meteorological open data via OGC standards",
      "detailed_description": "A system to manage access to the Environment and Climate Change Canada's Meteorological Service of Canada (MSC) open data, including raw numerical weather prediction (NWP) model data layers and weather radar mosaics, via Open Geospatial Consortium (OGC) standards.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_management",
        "data_access",
        "meteorology"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/ECCC-MSC/geomet-data-registry",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "meteorology",
        "ogc",
        "data-registry",
        "weather-data"
      ],
      "id": 496
    },
    {
      "name": "FastTrackML",
      "one_line_profile": "High-performance experiment tracking server compatible with MLflow",
      "detailed_description": "An experiment tracking server focused on speed and scalability, designed to be a drop-in replacement for the MLflow tracking server, facilitating reproducible machine learning experiments.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "experiment_tracking",
        "reproducibility",
        "artifact_management"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/G-Research/fasttrackml",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mlflow",
        "experiment-tracking",
        "reproducibility",
        "mlops"
      ],
      "id": 497
    },
    {
      "name": "kedro-mlflow",
      "one_line_profile": "Kedro plugin for MLflow integration enabling experiment tracking and model versioning",
      "detailed_description": "A plugin for the Kedro framework that integrates MLflow capabilities, specifically focusing on machine learning model versioning, packaging, and experiment tracking within data pipelines.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "experiment_tracking",
        "model_versioning",
        "pipeline_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Galileo-Galilei/kedro-mlflow",
      "help_website": [
        "https://kedro-mlflow.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kedro",
        "mlflow",
        "pipeline",
        "versioning"
      ],
      "id": 498
    },
    {
      "name": "GiraffeTools",
      "one_line_profile": "Graphical interface for reproducible analysis of workflow experiments",
      "detailed_description": "A graphical interface designed to facilitate the reproducible analysis of workflow experiments, likely in a bioinformatics or scientific computing context, enabling users to manage and visualize analysis processes.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "workflow_management",
        "reproducibility",
        "analysis_visualization"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/GiraffeTools/GiraffeTools",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "workflow",
        "reproducibility",
        "gui",
        "scientific-analysis"
      ],
      "id": 499
    },
    {
      "name": "jzfs",
      "one_line_profile": "Git-based version control file system for code, data, and models",
      "detailed_description": "A Git-based Version Control File System designed for the joint management of code, data, and models, facilitating reproducibility and artifact management in AI and scientific workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_versioning",
        "artifact_management",
        "reproducibility"
      ],
      "application_level": "system",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/GitDataAI/jzfs",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-versioning",
        "filesystem",
        "git",
        "model-management"
      ],
      "id": 500
    },
    {
      "name": "CMF",
      "one_line_profile": "Common Metadata Framework for tracking ML pipeline lineage and artifacts",
      "detailed_description": "A library to collect and store information associated with ML pipelines, tracking lineages for artifacts and executions of distributed AI pipelines to ensure reproducibility and metadata management.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "metadata_tracking",
        "lineage_tracking",
        "artifact_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HewlettPackard/cmf",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "metadata",
        "lineage",
        "ml-pipeline",
        "reproducibility"
      ],
      "id": 501
    },
    {
      "name": "Sacred",
      "one_line_profile": "Tool to configure, organize, log, and reproduce computational experiments",
      "detailed_description": "A tool to help researchers configure, organize, log, and reproduce experiments, managing configuration injection and database logging of experiment runs.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "experiment_tracking",
        "reproducibility",
        "configuration_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IDSIA/sacred",
      "help_website": [
        "https://sacred.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "experiment-tracking",
        "reproducibility",
        "machine-learning",
        "logging"
      ],
      "id": 502
    },
    {
      "name": "pycellin",
      "one_line_profile": "Graph-based framework for analyzing cell lineages from tracking data",
      "detailed_description": "A graph-based framework to manipulate and analyze cell lineages derived from cell tracking data, facilitating the study of cellular dynamics and genealogy.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "cell_lineage_analysis",
        "graph_analysis",
        "biological_image_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Image-Analysis-Hub/pycellin",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "cell-lineage",
        "bioinformatics",
        "graph-theory",
        "tracking"
      ],
      "id": 503
    },
    {
      "name": "ArtiVC",
      "one_line_profile": "Version control system for large files in data science projects",
      "detailed_description": "A version control system designed to manage large files, similar to DVC, enabling data versioning and artifact management within scientific and AI workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_versioning",
        "artifact_management",
        "large_file_storage"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/InfuseAI/ArtiVC",
      "help_website": [
        "https://artivc.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-versioning",
        "version-control",
        "large-files",
        "reproducibility"
      ],
      "id": 504
    },
    {
      "name": "PositionBasedDynamics",
      "one_line_profile": "Library for physically-based simulation of rigid bodies, deformable solids, and fluids",
      "detailed_description": "A library implementing Position Based Dynamics (PBD) for the physically-based simulation of rigid bodies, deformable solids, and fluids, widely used in computer graphics and scientific simulation.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "physics_simulation",
        "fluid_dynamics",
        "solid_mechanics"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/InteractiveComputerGraphics/PositionBasedDynamics",
      "help_website": [
        "https://interactivecomputergraphics.github.io/PositionBasedDynamics/"
      ],
      "license": "MIT",
      "tags": [
        "physics-simulation",
        "pbd",
        "fluid-dynamics",
        "deformable-solids"
      ],
      "id": 505
    },
    {
      "name": "SPlisHSPlasH",
      "one_line_profile": "Open-source library for physically-based simulation of fluids",
      "detailed_description": "An open-source library focused on the physically-based simulation of fluids, implementing various SPH (Smoothed Particle Hydrodynamics) methods for scientific modeling.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "fluid_dynamics",
        "sph_simulation",
        "physics_modeling"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/InteractiveComputerGraphics/SPlisHSPlasH",
      "help_website": [
        "https://interactivecomputergraphics.github.io/SPlisHSPlasH/"
      ],
      "license": "MIT",
      "tags": [
        "fluid-simulation",
        "sph",
        "physics",
        "cfd"
      ],
      "id": 506
    },
    {
      "name": "MLJModels.jl",
      "one_line_profile": "Model registry and loader for the MLJ machine learning framework",
      "detailed_description": "The model registry and tools for model queries and code loading for MLJ, a machine learning framework in Julia, facilitating model management and reproducibility.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "model_registry",
        "model_management",
        "machine_learning"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaAI/MLJModels.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "machine-learning",
        "model-registry",
        "mlj"
      ],
      "id": 507
    },
    {
      "name": "trixi",
      "one_line_profile": "Modular experiment infrastructure optimized for PyTorch reproducibility",
      "detailed_description": "A tool to manage machine learning experiments, ensuring reproducibility and modularity. It provides an experiment infrastructure optimized for PyTorch but flexible enough for other frameworks, facilitating artifact management and logging.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "experiment_tracking",
        "reproducibility",
        "artifact_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MIC-DKFZ/trixi",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "experiment-management",
        "reproducibility"
      ],
      "id": 508
    },
    {
      "name": "ML4ITS-synthetic-data",
      "one_line_profile": "GAN-based synthetic time-series generation system",
      "detailed_description": "A functional end-to-end system for generating synthetic time-series data using generative adversarial networks (GANs). It includes modules for dataset generation, model registry, and an interface for evaluation, specifically targeted at Intelligent Transportation Systems (ITS) research.",
      "domains": [
        "AI4",
        "AI6-03"
      ],
      "subtask_category": [
        "data_generation",
        "model_registry"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ML4ITS/synthetic-data",
      "help_website": [],
      "license": null,
      "tags": [
        "gan",
        "synthetic-data",
        "time-series"
      ],
      "id": 509
    },
    {
      "name": "smilelogging",
      "one_line_profile": "Python logging package for reproducible research experiments",
      "detailed_description": "A Python logging package designed to facilitate easy and reproducible experimenting in research. It helps in tracking experiment logs and configurations to ensure scientific reproducibility.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "experiment_logging",
        "reproducibility"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/MingSun-Tse/smilelogging",
      "help_website": [],
      "license": null,
      "tags": [
        "logging",
        "reproducibility",
        "research-tools"
      ],
      "id": 510
    },
    {
      "name": "PipelineX",
      "one_line_profile": "ML pipeline builder for experimentation with Kedro and MLflow",
      "detailed_description": "A Python package to build machine learning pipelines for experimentation, integrating with Kedro and MLflow. It focuses on simplifying the ML lifecycle management and experiment tracking.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "pipeline_orchestration",
        "experiment_tracking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Minyus/pipelinex",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ml-pipeline",
        "kedro",
        "mlflow",
        "experimentation"
      ],
      "id": 511
    },
    {
      "name": "CoolGraph",
      "one_line_profile": "Graph Neural Network (GNN) library",
      "detailed_description": "A library designed to make Graph Neural Networks (GNNs) easy to start with. GNNs are widely used in scientific modeling (e.g., molecular structures, physics simulations).",
      "domains": [
        "AI3",
        "AI6"
      ],
      "subtask_category": [
        "graph_learning",
        "modeling"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/MobileTeleSystems/CoolGraph",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gnn",
        "graph-neural-networks",
        "deep-learning"
      ],
      "id": 512
    },
    {
      "name": "Oxen",
      "one_line_profile": "High-performance data version control system for ML datasets",
      "detailed_description": "A lightning-fast data version control system designed for structured and unstructured machine learning datasets. It aims to make versioning datasets as easy as versioning code, serving as a faster alternative to DVC for large scientific artifacts.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_versioning",
        "artifact_management"
      ],
      "application_level": "platform",
      "primary_language": "Rust",
      "repo_url": "https://github.com/Oxen-AI/Oxen",
      "help_website": [
        "https://oxen.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-version-control",
        "machine-learning",
        "dvc-alternative",
        "rust"
      ],
      "id": 513
    },
    {
      "name": "Pachyderm Acoustic (Grasshopper)",
      "one_line_profile": "Acoustical simulation extension for Grasshopper",
      "detailed_description": "The Grasshopper extension for Pachyderm Acoustic, enabling acoustical simulation and analysis within the Grasshopper parametric modeling environment. Used for scientific modeling of sound propagation.",
      "domains": [
        "AI6",
        "Physics"
      ],
      "subtask_category": [
        "acoustic_simulation",
        "modeling"
      ],
      "application_level": "solver",
      "primary_language": "C#",
      "repo_url": "https://github.com/PachydermAcoustic/PachydermAcoustic_Grasshopper",
      "help_website": [],
      "license": null,
      "tags": [
        "acoustics",
        "simulation",
        "grasshopper",
        "parametric-modeling"
      ],
      "id": 514
    },
    {
      "name": "Pachyderm Acoustic (Rhino)",
      "one_line_profile": "Acoustical simulation plugin for Rhinoceros",
      "detailed_description": "A popular acoustical simulation plugin for Rhinoceros 3D. It performs scientific simulation of room acoustics and sound analysis.",
      "domains": [
        "AI6",
        "Physics"
      ],
      "subtask_category": [
        "acoustic_simulation",
        "modeling"
      ],
      "application_level": "solver",
      "primary_language": "C#",
      "repo_url": "https://github.com/PachydermAcoustic/PachydermAcoustic_Rhinoceros",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "acoustics",
        "simulation",
        "rhinoceros"
      ],
      "id": 515
    },
    {
      "name": "WebGL-Fluid-Simulation",
      "one_line_profile": "Real-time fluid dynamics simulation solver in browser",
      "detailed_description": "A WebGL-based implementation of fluid dynamics simulation (Navier-Stokes equations). While often used for visualization, it is a functional physics solver for fluid behavior.",
      "domains": [
        "AI6",
        "Physics"
      ],
      "subtask_category": [
        "fluid_simulation",
        "visualization"
      ],
      "application_level": "solver",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/PavelDoGreat/WebGL-Fluid-Simulation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cfd",
        "fluid-dynamics",
        "webgl",
        "simulation"
      ],
      "id": 516
    },
    {
      "name": "RL Reach",
      "one_line_profile": "Platform for reproducible reinforcement learning experiments",
      "detailed_description": "A platform designed for running reproducible reinforcement learning (RL) experiments, specifically focusing on reaching tasks in robotics/simulation environments.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/PierreExeter/rl_reach",
      "help_website": [],
      "license": null,
      "tags": [
        "reinforcement-learning",
        "reproducibility",
        "robotics"
      ],
      "id": 517
    },
    {
      "name": "FluidX3D",
      "one_line_profile": "High-performance lattice Boltzmann CFD software",
      "detailed_description": "A highly optimized Computational Fluid Dynamics (CFD) software based on the Lattice Boltzmann Method (LBM). It runs on GPUs and CPUs via OpenCL, designed for high-performance scientific simulation.",
      "domains": [
        "AI6",
        "Physics"
      ],
      "subtask_category": [
        "cfd_simulation",
        "fluid_dynamics"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ProjectPhysX/FluidX3D",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "cfd",
        "lattice-boltzmann",
        "opencl",
        "hpc"
      ],
      "id": 518
    },
    {
      "name": "ReproZip",
      "one_line_profile": "Tool for packing and reproducing experiments by tracing system calls",
      "detailed_description": "ReproZip is a tool aimed at simplifying the process of creating reproducible experiments from command-line executions. It tracks operating system calls to identify and package all necessary files and dependencies, allowing the experiment to be replayed on different environments.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "reproducibility",
        "experiment_packing",
        "provenance_tracking"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/VIDA-NYU/reprozip",
      "help_website": [
        "https://www.reprozip.org/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "reproducibility",
        "provenance",
        "experiment-management"
      ],
      "id": 519
    },
    {
      "name": "SoptSC",
      "one_line_profile": "Single-cell RNA-seq data analysis tool for clustering and lineage inference",
      "detailed_description": "SoptSC is a MATLAB-based tool for single-cell data analysis. It performs unsupervised inference of clustering, cell lineage, pseudotime, and cell-cell communication networks from scRNA-seq data using similarity matrix optimization.",
      "domains": [
        "AI4",
        "AI4-06"
      ],
      "subtask_category": [
        "clustering",
        "lineage_inference",
        "scrna_seq_analysis"
      ],
      "application_level": "solver",
      "primary_language": "MATLAB",
      "repo_url": "https://github.com/WangShuxiong/SoptSC",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "single-cell",
        "rna-seq",
        "clustering",
        "lineage-inference"
      ],
      "id": 520
    },
    {
      "name": "WaterLily.jl",
      "one_line_profile": "Fast and simple fluid simulator for solving Navier-Stokes equations",
      "detailed_description": "WaterLily.jl is a Julia library for solving the incompressible Navier-Stokes equations on Cartesian grids. It is designed to be fast, simple, and backend-agnostic, suitable for fluid dynamics simulations.",
      "domains": [
        "AI6",
        "AI4"
      ],
      "subtask_category": [
        "fluid_simulation",
        "cfd",
        "navier_stokes"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/WaterLily-jl/WaterLily.jl",
      "help_website": [
        "https://waterlily-jl.github.io/WaterLily.jl/dev/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "fluid-dynamics",
        "cfd",
        "julia",
        "simulation"
      ],
      "id": 521
    },
    {
      "name": "Geochemistrypi",
      "one_line_profile": "Automated machine learning framework for geochemistry data analysis",
      "detailed_description": "Geochemistryπ is an open-sourced, highly automated machine learning Python framework designed specifically for data-driven geochemistry discovery. It simplifies the application of ML techniques to geochemical datasets.",
      "domains": [
        "AI4",
        "AI4-01"
      ],
      "subtask_category": [
        "geochemistry_analysis",
        "data_mining",
        "automated_ml"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ZJUEarthData/Geochemistrypi",
      "help_website": [
        "https://geochemistrypi.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "geochemistry",
        "machine-learning",
        "earth-science",
        "automl"
      ],
      "id": 522
    },
    {
      "name": "Aim",
      "one_line_profile": "An easy-to-use & supercharged open-source experiment tracker",
      "detailed_description": "Aim is an open-source experiment tracking tool that logs AI metadata (hyperparameters, metrics, images, etc.) and provides a UI for comparison and visualization, facilitating reproducible research.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "experiment_tracking",
        "visualization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/aimhubio/aim",
      "help_website": [
        "https://aimstack.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "experiment-tracking",
        "mlops",
        "visualization"
      ],
      "id": 523
    },
    {
      "name": "AimLflow",
      "one_line_profile": "Aim-MLflow integration for syncing experiments",
      "detailed_description": "A tool that synchronizes MLflow runs with Aim, allowing users to leverage Aim's visualization and tracking capabilities on top of existing MLflow setups.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "experiment_tracking",
        "artifact_sync"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aimhubio/aimlflow",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mlflow",
        "integration",
        "experiment-tracking"
      ],
      "id": 524
    },
    {
      "name": "FeatHub",
      "one_line_profile": "Stream-batch unified feature store for real-time machine learning",
      "detailed_description": "FeatHub is a feature store that simplifies feature engineering and management for machine learning, supporting both streaming and batch data processing with point-in-time correctness.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "feature_store",
        "data_versioning"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/alibaba/feathub",
      "help_website": [
        "https://github.com/alibaba/feathub"
      ],
      "license": "Apache-2.0",
      "tags": [
        "feature-store",
        "flink",
        "machine-learning"
      ],
      "id": 525
    },
    {
      "name": "MLflow Export-Import",
      "one_line_profile": "Tools to export and import MLflow experiments, runs, or models",
      "detailed_description": "A set of utilities to migrate MLflow objects (experiments, runs, registered models) between different MLflow tracking servers or for backup purposes.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_management",
        "migration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/amesar/mlflow-export-import",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mlflow",
        "migration",
        "backup"
      ],
      "id": 526
    },
    {
      "name": "Hamilton",
      "one_line_profile": "Modular dataflow definition with lineage and metadata tracking",
      "detailed_description": "Apache Hamilton is a framework for defining dataflows in Python that automatically tracks lineage and metadata, facilitating reproducible feature engineering and data processing pipelines.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "pipeline_orchestration",
        "lineage_tracking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/apache/hamilton",
      "help_website": [
        "https://hamilton.dagworks.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dataflow",
        "lineage",
        "feature-engineering"
      ],
      "id": 527
    },
    {
      "name": "AIOps Modules",
      "one_line_profile": "Reusable IaC modules for ML and GenAI infrastructure on AWS",
      "detailed_description": "A collection of Infrastructure as Code (IaC) modules designed to accelerate the deployment and operation of Machine Learning and Generative AI workloads on AWS.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "infrastructure_provisioning",
        "mlops_deployment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/awslabs/aiops-modules",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "iac",
        "aws",
        "mlops"
      ],
      "id": 528
    },
    {
      "name": "Data on EKS",
      "one_line_profile": "Tool to build, deploy and scale Data Platforms on Amazon EKS",
      "detailed_description": "Data on EKS (DoEKS) provides blueprints and tools to deploy scalable data and machine learning platforms (like Spark, Ray, Kubeflow) on Amazon EKS, optimizing for performance and cost.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "platform_engineering",
        "cluster_management"
      ],
      "application_level": "platform",
      "primary_language": "HCL",
      "repo_url": "https://github.com/awslabs/data-on-eks",
      "help_website": [
        "https://awslabs.github.io/data-on-eks/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "eks",
        "data-platform"
      ],
      "id": 529
    },
    {
      "name": "Cloud Detection Model for Sentinel-2",
      "one_line_profile": "Deep learning model for cloud detection in Sentinel-2 satellite imagery",
      "detailed_description": "A semantic segmentation model based on U-Net/ResNet architectures specifically trained to detect clouds in Sentinel-2 satellite imagery, facilitating preprocessing for remote sensing and earth science analysis.",
      "domains": [
        "AI4-Earth",
        "AI6"
      ],
      "subtask_category": [
        "cloud_detection",
        "image_segmentation",
        "preprocessing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/azavea/cloud-model",
      "help_website": [
        "https://github.com/azavea/cloud-model"
      ],
      "license": "MIT",
      "tags": [
        "remote-sensing",
        "sentinel-2",
        "cloud-masking",
        "earth-science"
      ],
      "id": 530
    },
    {
      "name": "InfiniStore",
      "one_line_profile": "High-performance KV cache store for distributed LLM inference",
      "detailed_description": "A scalable key-value storage system designed specifically for managing KV caches in distributed Large Language Model (LLM) inference, optimizing memory usage and access latency for AI workloads.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "kv_caching",
        "inference_acceleration",
        "memory_management"
      ],
      "application_level": "service",
      "primary_language": "C++",
      "repo_url": "https://github.com/bytedance/InfiniStore",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "kv-cache",
        "distributed-systems",
        "inference"
      ],
      "id": 531
    },
    {
      "name": "Calkit",
      "one_line_profile": "Lightweight research project management and reproducibility tool",
      "detailed_description": "A command-line tool designed for researchers to manage project environments, version control data and code, and execute reproducible pipelines, simplifying the complexity of Git and DVC for scientific workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "reproducibility",
        "data_versioning",
        "environment_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/calkit/calkit",
      "help_website": [
        "https://calkit.readthedocs.io"
      ],
      "license": "MIT",
      "tags": [
        "reproducibility",
        "git",
        "research-management",
        "pipeline"
      ],
      "id": 532
    },
    {
      "name": "PARSEC Benchmark",
      "one_line_profile": "Benchmark suite for shared-memory parallel systems",
      "detailed_description": "A ported and maintained version of the PARSEC Benchmark suite, widely used in High Performance Computing (HPC) research to evaluate the performance of shared-memory parallel systems using diverse workloads.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_evaluation",
        "hpc_analysis"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/cirosantilli/parsec-benchmark",
      "help_website": [
        "http://parsec.cs.princeton.edu"
      ],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "benchmark",
        "parallel-computing"
      ],
      "id": 533
    },
    {
      "name": "ClearML",
      "one_line_profile": "Integrated MLOps platform for experiment tracking and orchestration",
      "detailed_description": "A comprehensive open-source MLOps platform that provides tools for experiment management, data versioning, and pipeline orchestration, widely used in AI research to ensure reproducibility and manage scientific machine learning workflows.",
      "domains": [
        "AI6",
        "AI6-03",
        "AI6-01"
      ],
      "subtask_category": [
        "experiment_tracking",
        "artifact_management",
        "pipeline_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/clearml/clearml",
      "help_website": [
        "https://clear.ml/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "experiment-tracking",
        "reproducibility",
        "data-management"
      ],
      "id": 534
    },
    {
      "name": "ClearML Server",
      "one_line_profile": "Backend server for the ClearML MLOps platform",
      "detailed_description": "The backend infrastructure for ClearML, handling data persistence, API requests, and coordination for experiment tracking and orchestration services.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "experiment_tracking_backend",
        "service_orchestration"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/clearml/clearml-server",
      "help_website": [
        "https://clear.ml/docs"
      ],
      "license": "NOASSERTION",
      "tags": [
        "mlops",
        "backend",
        "server"
      ],
      "id": 535
    },
    {
      "name": "OMLMD",
      "one_line_profile": "OCI Artifact specification and tool for ML models",
      "detailed_description": "A tool and specification for packaging Machine Learning models and their metadata as OCI (Open Container Initiative) artifacts, facilitating the distribution and management of ML assets in container registries.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "model_packaging",
        "artifact_management",
        "metadata_handling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/containers/omlmd",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "oci",
        "ml-models",
        "containers",
        "artifact-management"
      ],
      "id": 536
    },
    {
      "name": "git-rdm",
      "one_line_profile": "Research data management plugin for Git to track data provenance and publication",
      "detailed_description": "A plugin for the Git version control system designed to facilitate research data management (RDM). It allows researchers to curate, version control, and share their research data alongside their code, bridging the gap between version control and data repositories.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_versioning",
        "artifact_management",
        "reproducibility"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ctjacobs/git-rdm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "git",
        "research-data-management",
        "reproducibility",
        "provenance"
      ],
      "id": 537
    },
    {
      "name": "DataTracer",
      "one_line_profile": "Data lineage tracing library for data science workflows",
      "detailed_description": "A library designed to trace data lineage and provenance in data science and machine learning workflows. It helps in understanding the origin and transformation of data, which is critical for reproducibility in scientific data processing.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_provenance",
        "lineage_tracing",
        "reproducibility"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/data-dev/DataTracer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-lineage",
        "provenance",
        "data-science",
        "reproducibility"
      ],
      "id": 538
    },
    {
      "name": "RaceID3_StemID2_package",
      "one_line_profile": "Algorithm for cell type and lineage inference from single-cell RNA-seq data",
      "detailed_description": "An R package implementing the RaceID3 and StemID2 algorithms. It is used for the identification of rare cell types and the inference of lineage trees and differentiation trajectories from single-cell RNA-sequencing data.",
      "domains": [
        "Life Sciences",
        "Bioinformatics"
      ],
      "subtask_category": [
        "cell_type_inference",
        "lineage_inference",
        "single_cell_analysis"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/dgrun/RaceID3_StemID2_package",
      "help_website": [],
      "license": null,
      "tags": [
        "scrna-seq",
        "lineage-inference",
        "cell-type-identification",
        "bioinformatics"
      ],
      "id": 539
    },
    {
      "name": "StemID",
      "one_line_profile": "Algorithm for lineage tree inference from single-cell data",
      "detailed_description": "An algorithm for the inference of cell types and lineage trees from single-cell RNA-seq data. It focuses on identifying differentiation trajectories and stem cell populations.",
      "domains": [
        "Life Sciences",
        "Bioinformatics"
      ],
      "subtask_category": [
        "lineage_inference",
        "trajectory_analysis"
      ],
      "application_level": "solver",
      "primary_language": "R",
      "repo_url": "https://github.com/dgrun/StemID",
      "help_website": [],
      "license": null,
      "tags": [
        "scrna-seq",
        "lineage-tree",
        "differentiation",
        "bioinformatics"
      ],
      "id": 540
    },
    {
      "name": "Fluid Engine Dev",
      "one_line_profile": "Fluid simulation engine for computer graphics and physics applications",
      "detailed_description": "A C++ library for simulating fluid dynamics, often used in computer graphics but applicable to physics-based modeling. It provides solvers for grid-based and particle-based fluid simulations.",
      "domains": [
        "Physics",
        "Computer_Graphics",
        "Simulation"
      ],
      "subtask_category": [
        "fluid_dynamics_simulation",
        "physics_modeling"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/doyubkim/fluid-engine-dev",
      "help_website": [
        "http://doyubkim.github.io/fluid-engine-dev/"
      ],
      "license": "MIT",
      "tags": [
        "fluid-simulation",
        "physics-engine",
        "cfd"
      ],
      "id": 541
    },
    {
      "name": "DuckDB Delta",
      "one_line_profile": "DuckDB extension for reading and writing Delta Lake tables",
      "detailed_description": "An extension for DuckDB that enables direct interaction with Delta Lake tables, facilitating data versioning and management in scientific data lakes and analytical workflows.",
      "domains": [
        "AI6-03",
        "Data_Engineering"
      ],
      "subtask_category": [
        "data_access",
        "data_versioning"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/duckdb/duckdb-delta",
      "help_website": [
        "https://duckdb.org/docs/extensions/delta"
      ],
      "license": "MIT",
      "tags": [
        "duckdb",
        "delta-lake",
        "data-lake",
        "versioning"
      ],
      "id": 542
    },
    {
      "name": "paleotree",
      "one_line_profile": "R library for analyzing and simulating phylogenies of extinct lineages",
      "detailed_description": "A package for analyzing, time-scaling, and simulating phylogenies of extinct/fossil lineages, including plotting diversity curves for stratigraphic range data.",
      "domains": [
        "Biology",
        "Paleontology"
      ],
      "subtask_category": [
        "phylogenetic_analysis",
        "evolutionary_modeling"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/dwbapst/paleotree",
      "help_website": [
        "https://cran.r-project.org/web/packages/paleotree/index.html"
      ],
      "license": "CC0-1.0",
      "tags": [
        "phylogeny",
        "fossils",
        "evolution",
        "time-scaling"
      ],
      "id": 543
    },
    {
      "name": "Elementary",
      "one_line_profile": "dbt-native data observability and quality monitoring solution",
      "detailed_description": "An open-source data observability solution for data engineers using dbt. It provides monitoring for data pipelines, anomaly detection, and data quality reporting, ensuring the reliability of data artifacts.",
      "domains": [
        "AI6-03",
        "Data_Engineering"
      ],
      "subtask_category": [
        "data_quality_control",
        "pipeline_monitoring"
      ],
      "application_level": "platform",
      "primary_language": "HTML",
      "repo_url": "https://github.com/elementary-data/elementary",
      "help_website": [
        "https://docs.elementary-data.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-observability",
        "dbt",
        "data-quality",
        "monitoring"
      ],
      "id": 544
    },
    {
      "name": "SCICHEM",
      "one_line_profile": "Puff model with chemistry for simulating atmospheric plume transport",
      "detailed_description": "A version of the SCIPUFF puff model incorporating chemical transformations. It simulates the transport and chemical evolution of power plant plumes in the atmosphere.",
      "domains": [
        "Environmental_Science",
        "Atmospheric_Physics"
      ],
      "subtask_category": [
        "atmospheric_dispersion_modeling",
        "chemical_transport_simulation"
      ],
      "application_level": "solver",
      "primary_language": "Fortran",
      "repo_url": "https://github.com/epri-dev/SCICHEM_archived",
      "help_website": [],
      "license": "Unknown",
      "tags": [
        "atmospheric-model",
        "plume-simulation",
        "chemistry"
      ],
      "id": 545
    },
    {
      "name": "papermill-mlflow",
      "one_line_profile": "Integration for tracking Papermill notebook executions in MLflow",
      "detailed_description": "A utility that connects Papermill (parameterized notebooks) with MLflow, enabling automatic tracking of parameters, metrics, and artifacts from notebook-based experiments.",
      "domains": [
        "AI6-03",
        "Data_Science"
      ],
      "subtask_category": [
        "experiment_tracking",
        "reproducibility"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/eugeneyan/papermill-mlflow",
      "help_website": [],
      "license": "Unknown",
      "tags": [
        "mlflow",
        "papermill",
        "experiment-tracking",
        "jupyter"
      ],
      "id": 546
    },
    {
      "name": "IEEE-118 Power Flow Data Pipeline",
      "one_line_profile": "Data pipeline for generating IEEE-118 power system flow cases",
      "detailed_description": "A data processing pipeline designed to build and structure power flow cases for the IEEE-118 bus power system, facilitating simulation and analysis in power engineering.",
      "domains": [
        "Power_Systems",
        "Engineering"
      ],
      "subtask_category": [
        "data_generation",
        "power_flow_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/evgenytsydenov/ieee118_power_flow_data",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "power-systems",
        "ieee-118",
        "data-pipeline"
      ],
      "id": 547
    },
    {
      "name": "Expfactory",
      "one_line_profile": "Framework for generating reproducible experiment containers",
      "detailed_description": "Software to generate reproducible containers (Docker/Singularity) containing a battery of behavioral experiments, ensuring consistent runtime environments for scientific studies.",
      "domains": [
        "AI6",
        "Psychology",
        "Neuroscience"
      ],
      "subtask_category": [
        "experiment_deployment",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/expfactory/expfactory",
      "help_website": [
        "https://expfactory.github.io/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "reproducibility",
        "containers",
        "behavioral-experiments"
      ],
      "id": 548
    },
    {
      "name": "Data Lineage Doris",
      "one_line_profile": "Data lineage tracking tool for Apache Doris",
      "detailed_description": "A tool for parsing and tracking table and field-level lineage within Apache Doris, aiding in data provenance and impact analysis for data warehouses.",
      "domains": [
        "AI6-03",
        "Data_Engineering"
      ],
      "subtask_category": [
        "data_lineage",
        "provenance_tracking"
      ],
      "application_level": "tool",
      "primary_language": "Java",
      "repo_url": "https://github.com/eyesmoons/data-lineage-doris",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "data-lineage",
        "apache-doris",
        "provenance"
      ],
      "id": 549
    },
    {
      "name": "dbt Feature Store",
      "one_line_profile": "Feature store implementation using dbt macros",
      "detailed_description": "A lightweight feature store implementation that allows defining and managing machine learning features directly within dbt repositories using macros.",
      "domains": [
        "AI6-03",
        "Machine_Learning"
      ],
      "subtask_category": [
        "feature_management",
        "feature_store"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fal-ai/dbt_feature_store",
      "help_website": [],
      "license": "Unknown",
      "tags": [
        "dbt",
        "feature-store",
        "mlops"
      ],
      "id": 550
    },
    {
      "name": "Feast",
      "one_line_profile": "Open source feature store for machine learning",
      "detailed_description": "A leading open-source feature store that manages the serving of features for training and inference, ensuring consistency between offline and online environments.",
      "domains": [
        "AI6-03",
        "Machine_Learning"
      ],
      "subtask_category": [
        "feature_serving",
        "feature_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/feast-dev/feast",
      "help_website": [
        "https://feast.dev/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "feature-store",
        "mlops",
        "feature-serving"
      ],
      "id": 551
    },
    {
      "name": "Featureform",
      "one_line_profile": "Virtual feature store for existing data infrastructure",
      "detailed_description": "A virtual feature store that turns existing data infrastructure (like Spark, Redis, Snowflake) into a feature store, managing feature definitions, lineage, and serving.",
      "domains": [
        "AI6-03",
        "Machine_Learning"
      ],
      "subtask_category": [
        "feature_management",
        "feature_store"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/featureform/featureform",
      "help_website": [
        "https://www.featureform.com/"
      ],
      "license": "MPL-2.0",
      "tags": [
        "feature-store",
        "mlops",
        "virtual-feature-store"
      ],
      "id": 552
    },
    {
      "name": "Featury",
      "one_line_profile": "Machine learning feature store library",
      "detailed_description": "A feature store library designed to simplify feature engineering and serving for machine learning applications.",
      "domains": [
        "AI6-03",
        "Machine_Learning"
      ],
      "subtask_category": [
        "feature_store",
        "feature_engineering"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/findify/featury",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "feature-store",
        "scala",
        "ml"
      ],
      "id": 553
    },
    {
      "name": "Fluid",
      "one_line_profile": "Elastic data abstraction and acceleration for AI/BigData on Kubernetes",
      "detailed_description": "A cloud-native data orchestration and acceleration system that abstracts data access for AI and Big Data applications, providing caching and data locality in Kubernetes environments.",
      "domains": [
        "AI6-03",
        "Cloud_Native"
      ],
      "subtask_category": [
        "data_orchestration",
        "data_acceleration",
        "caching"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/fluid-cloudnative/fluid",
      "help_website": [
        "https://fluid-cloudnative.github.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "data-acceleration",
        "caching",
        "cncf"
      ],
      "id": 554
    },
    {
      "name": "Flyte Data Catalog",
      "one_line_profile": "Service for indexing and managing parameterized data artifacts in Flyte workflows",
      "detailed_description": "Data Catalog is a core service within the Flyte ecosystem designed to index and manage strongly-typed data artifacts across revisions. It enables efficient caching (memoization) of task outputs and ensures reproducibility by tracking data lineage in scientific and ML workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_management",
        "data_lineage",
        "caching"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/flyteorg/datacatalog",
      "help_website": [
        "https://flyte.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "flyte",
        "artifact-management",
        "caching",
        "mlops"
      ],
      "id": 555
    },
    {
      "name": "alluxiofs",
      "one_line_profile": "Fsspec implementation for Alluxio distributed caching",
      "detailed_description": "Alluxiofs provides a Python filesystem interface (fsspec) for Alluxio, enabling scientific data processing tools (like Pandas, Dask, and Ray) to leverage Alluxio's distributed caching capabilities for accelerated data access.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_access",
        "caching"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fsspec/alluxiofs",
      "help_website": [
        "https://github.com/fsspec/alluxiofs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "fsspec",
        "alluxio",
        "distributed-caching",
        "python"
      ],
      "id": 556
    },
    {
      "name": "FuseML",
      "one_line_profile": "Orchestration framework for MLOps and scientific workflows",
      "detailed_description": "FuseML is an MLOps framework designed to dynamically integrate various AI/ML tools. It provides a flexible orchestration layer for managing the lifecycle of machine learning models and scientific data processing pipelines.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "workflow_orchestration",
        "mlops"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/fuseml/fuseml",
      "help_website": [
        "https://fuseml.github.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "orchestration",
        "workflow",
        "integration"
      ],
      "id": 557
    },
    {
      "name": "git-lfs-fuse",
      "one_line_profile": "FUSE filesystem for mounting Git LFS repositories",
      "detailed_description": "Git LFS FUSE allows users to mount remote Git LFS repositories as a local filesystem. This enables instant access to large scientific models and datasets without downloading the entire repository, facilitating efficient data exploration and lazy loading.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_access",
        "dataset_management"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/git-lfs-fuse/git-lfs-fuse",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "git-lfs",
        "fuse",
        "data-access",
        "mounting"
      ],
      "id": 558
    },
    {
      "name": "Git LFS",
      "one_line_profile": "Git extension for versioning large files",
      "detailed_description": "Git Large File Storage (LFS) replaces large files such as audio samples, videos, datasets, and graphics with text pointers inside Git, while storing the file contents on a remote server. It is the industry standard for versioning large scientific datasets and ML models.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_versioning",
        "artifact_management"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/git-lfs/git-lfs",
      "help_website": [
        "https://git-lfs.github.com/"
      ],
      "license": "MIT",
      "tags": [
        "version-control",
        "large-file-storage",
        "data-versioning"
      ],
      "id": 559
    },
    {
      "name": "lfs-test-server",
      "one_line_profile": "Standalone Git LFS server implementation",
      "detailed_description": "A simple, standalone implementation of the Git LFS server API. While originally designed for testing, it serves as a lightweight artifact store for hosting scientific datasets and models in self-managed environments.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_store",
        "data_hosting"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/git-lfs/lfs-test-server",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "git-lfs",
        "server",
        "artifact-store"
      ],
      "id": 560
    },
    {
      "name": "FluidNet",
      "one_line_profile": "Accelerating Eulerian Fluid Simulation With Convolutional Networks",
      "detailed_description": "FluidNet is a deep learning framework for accelerating Eulerian fluid simulations. It uses Convolutional Neural Networks (ConvNets) to predict fluid dynamics, offering a data-driven approach to scientific simulation.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "fluid_simulation",
        "physics_informed_ml"
      ],
      "application_level": "solver",
      "primary_language": "Lua",
      "repo_url": "https://github.com/google/FluidNet",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "cfd",
        "deep-learning",
        "fluid-simulation",
        "physics"
      ],
      "id": 561
    },
    {
      "name": "JAX-CFD",
      "one_line_profile": "Computational Fluid Dynamics in JAX",
      "detailed_description": "JAX-CFD is a library for computational fluid dynamics (CFD) written in JAX. It enables differentiable physics simulations, allowing for gradient-based optimization and integration with machine learning models for scientific research.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "fluid_simulation",
        "cfd",
        "differentiable_physics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google/jax-cfd",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jax",
        "cfd",
        "fluid-dynamics",
        "simulation"
      ],
      "id": 562
    },
    {
      "name": "Space",
      "one_line_profile": "Unified storage framework for the machine learning lifecycle",
      "detailed_description": "Space is a unified storage framework designed to manage data across the entire machine learning lifecycle. It provides abstractions for dataset management, versioning, and access, facilitating reproducible ML research.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_storage",
        "dataset_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/google/space",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "storage",
        "ml-lifecycle",
        "dataset-management"
      ],
      "id": 563
    },
    {
      "name": "Ground",
      "one_line_profile": "Open-source data context service for lineage and versioning",
      "detailed_description": "Ground is a vendor-neutral data context service that manages the lineage, metadata, and versioning of data artifacts. It serves as a critical infrastructure component for ensuring reproducibility and traceability in scientific data workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_lineage",
        "metadata_management",
        "data_versioning"
      ],
      "application_level": "service",
      "primary_language": "Java",
      "repo_url": "https://github.com/ground-context/ground",
      "help_website": [
        "http://www.ground-context.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-lineage",
        "metadata",
        "versioning",
        "reproducibility"
      ],
      "id": 564
    },
    {
      "name": "carla_apollo_bridge",
      "one_line_profile": "Bridge between Carla simulator and Apollo control stack",
      "detailed_description": "This tool provides a data and control bridge enabling communication between the Carla autonomous driving simulator and the Apollo open autonomous driving platform. It facilitates scientific research in robotics and autonomous systems by linking simulation with control logic.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "simulation_bridge",
        "robotics_simulation"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/guardstrikelab/carla_apollo_bridge",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "carla",
        "apollo",
        "autonomous-driving",
        "simulation"
      ],
      "id": 565
    },
    {
      "name": "Spark Atlas Connector",
      "one_line_profile": "Connector to track Spark data lineage in Apache Atlas for data governance",
      "detailed_description": "A connector that enables tracking of data lineage and metadata from Apache Spark jobs into Apache Atlas. This is essential for scientific data governance, reproducibility, and provenance tracking in large-scale data processing pipelines.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_lineage",
        "provenance_tracking"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/hortonworks-spark/spark-atlas-connector",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "data-lineage",
        "spark",
        "atlas",
        "provenance"
      ],
      "id": 566
    },
    {
      "name": "Superglue",
      "one_line_profile": "Data lineage tracking and visualization tool for complex pipelines",
      "detailed_description": "A lineage-tracking tool designed to visualize the propagation of data through complex pipelines composed of tables, jobs, and reports. It helps in understanding data dependencies and provenance, which is critical for reproducible scientific workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_lineage",
        "visualization"
      ],
      "application_level": "platform",
      "primary_language": "Scala",
      "repo_url": "https://github.com/intuit/superglue",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lineage",
        "data-visualization",
        "pipeline-tracking"
      ],
      "id": 567
    },
    {
      "name": "GPU-Jupyter",
      "one_line_profile": "GPU-accelerated JupyterLab environment for reproducible deep learning",
      "detailed_description": "A specialized JupyterLab environment stack pre-configured with GPU support (CUDA/cuDNN) and data science libraries (TensorFlow, PyTorch). It serves as a reproducible runtime platform for conducting deep learning experiments in scientific research.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "reproducible_environment",
        "interactive_computing"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/iot-salzburg/gpu-jupyter",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jupyter",
        "gpu",
        "reproducibility",
        "deep-learning"
      ],
      "id": 568
    },
    {
      "name": "GTO",
      "one_line_profile": "Git Tag Ops for artifact and model registry management",
      "detailed_description": "A tool that turns a Git repository into an Artifact Registry or Model Registry using Git tags. It allows scientific teams to version, register, and manage the lifecycle of machine learning models and data artifacts directly within their version control system.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_management",
        "model_registry"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/iterative/gto",
      "help_website": [
        "https://iterative.github.io/gto/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "gitops",
        "model-registry",
        "artifact-management",
        "mlops"
      ],
      "id": 569
    },
    {
      "name": "pachypy",
      "one_line_profile": "Python client library for Pachyderm data lineage and versioning",
      "detailed_description": "A Python client library for Pachyderm, a data versioning and lineage platform for machine learning and scientific data processing. It simplifies the interaction with Pachyderm pipelines and data repositories.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_versioning",
        "pipeline_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/itssimon/pachypy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pachyderm",
        "data-lineage",
        "versioning",
        "python-client"
      ],
      "id": 570
    },
    {
      "name": "Rudolfs",
      "one_line_profile": "High-performance caching Git LFS server",
      "detailed_description": "A high-performance, caching Git LFS (Large File Storage) server with support for AWS S3 and local storage backends. It facilitates the management and efficient retrieval of large scientific artifacts (datasets, models) in version-controlled workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_storage",
        "caching"
      ],
      "application_level": "service",
      "primary_language": "Rust",
      "repo_url": "https://github.com/jasonwhite/rudolfs",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "git-lfs",
        "caching",
        "artifact-storage",
        "rust"
      ],
      "id": 571
    },
    {
      "name": "sci-pype",
      "one_line_profile": "Machine Learning API and pipeline framework with caching",
      "detailed_description": "A Machine Learning API framework featuring native Redis caching and S3 export/import capabilities. It is designed to build, train, test, and analyze entire datasets, providing a structured pipeline for scientific data analysis and reproducibility.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "pipeline_management",
        "caching",
        "data_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/jay-johnson/sci-pype",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pipeline",
        "caching",
        "machine-learning",
        "reproducibility"
      ],
      "id": 572
    },
    {
      "name": "DeltaLakeReader",
      "one_line_profile": "Lightweight reader for Delta Lake tables without Spark",
      "detailed_description": "A Python library to read Delta Lake tables directly without requiring a Spark engine. This enables lightweight access to versioned scientific datasets stored in Delta format, facilitating data analysis in non-Spark environments.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_access",
        "data_versioning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jeppe742/DeltaLakeReader",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "delta-lake",
        "data-access",
        "python"
      ],
      "id": 573
    },
    {
      "name": "SharedDataset",
      "one_line_profile": "Shared memory caching wrapper for PyTorch Datasets",
      "detailed_description": "A PyTorch Dataset extension that caches samples in shared memory, making them accessible globally to all processes to reduce memory redundancy and accelerate data loading in machine learning pipelines.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "caching",
        "data_loading"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jotaf98/shareddataset",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "pytorch",
        "caching",
        "shared-memory",
        "data-loading"
      ],
      "id": 574
    },
    {
      "name": "JuiceFS",
      "one_line_profile": "Distributed POSIX file system for cloud-native AI and big data",
      "detailed_description": "A distributed POSIX file system built on top of object storage (e.g., S3) and a metadata engine (e.g., Redis), widely used in AI/Science for high-performance data caching, artifact storage, and sharing across containerized environments.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_storage",
        "caching",
        "distributed_storage"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/juicedata/juicefs",
      "help_website": [
        "https://juicefs.com/docs/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-filesystem",
        "posix",
        "caching",
        "cloud-native",
        "storage"
      ],
      "id": 575
    },
    {
      "name": "K3ai",
      "one_line_profile": "Lightweight AI infrastructure stack deployer",
      "detailed_description": "A tool designed to rapidly deploy and configure AI infrastructure stacks (including Kubernetes and AI tools) for experimentation and development, facilitating reproducible runtime environments for scientific AI workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "infrastructure_deployment",
        "environment_setup"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/k3ai/k3ai",
      "help_website": [
        "https://docs.k3ai.in"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "mlops",
        "kubernetes",
        "infrastructure",
        "deployment"
      ],
      "id": 576
    },
    {
      "name": "Karamel",
      "one_line_profile": "Orchestration tool for reproducible distributed experiments",
      "detailed_description": "A tool for defining, provisioning, and deploying distributed systems and experiments on cloud infrastructure, ensuring reproducibility of runtime environments for data-intensive research.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "experiment_orchestration",
        "reproducibility"
      ],
      "application_level": "tool",
      "primary_language": "Java",
      "repo_url": "https://github.com/karamelchef/karamel",
      "help_website": [
        "http://www.karamel.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-systems",
        "reproducibility",
        "orchestration",
        "cloud"
      ],
      "id": 577
    },
    {
      "name": "Klever Model Registry",
      "one_line_profile": "Cloud-native machine learning model registry",
      "detailed_description": "A cloud-native registry for managing machine learning models, providing versioning, storage, and metadata management for ML artifacts in scientific workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "model_management",
        "artifact_versioning"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/kleveross/klever-model-registry",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "model-registry",
        "mlops",
        "artifact-management",
        "cloud-native"
      ],
      "id": 578
    },
    {
      "name": "ORMB",
      "one_line_profile": "OCI-based artifact manager for ML/DL models",
      "detailed_description": "A tool that manages machine learning and deep learning models as OCI (Open Container Initiative) artifacts, enabling versioning, distribution, and deployment of models similar to Docker images.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_management",
        "model_distribution",
        "versioning"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/kleveross/ormb",
      "help_website": [
        "https://ormb.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "oci-artifacts",
        "model-management",
        "mlops",
        "docker"
      ],
      "id": 579
    },
    {
      "name": "Kart",
      "one_line_profile": "Distributed version control for geospatial and tabular data",
      "detailed_description": "A distributed version control system specifically designed for geospatial and tabular datasets, enabling collaboration, history tracking, and branching for scientific data similar to Git for code.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_versioning",
        "geospatial_data_management"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/koordinates/kart",
      "help_website": [
        "https://kartproject.org"
      ],
      "license": "NOASSERTION",
      "tags": [
        "data-versioning",
        "geospatial",
        "gis",
        "version-control"
      ],
      "id": 580
    },
    {
      "name": "Kubeflow Model Registry",
      "one_line_profile": "Centralized management for ML models and artifacts",
      "detailed_description": "A core component of the Kubeflow ecosystem that provides a centralized registry for indexing, versioning, and managing metadata of machine learning models and artifacts, facilitating collaboration in MLOps lifecycles.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "model_registry",
        "artifact_management",
        "metadata_tracking"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubeflow/model-registry",
      "help_website": [
        "https://github.com/kubeflow/model-registry"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubeflow",
        "model-registry",
        "mlops",
        "artifact-management"
      ],
      "id": 581
    },
    {
      "name": "Mooncake",
      "one_line_profile": "LLM serving platform with optimized KV caching",
      "detailed_description": "A serving platform designed for Large Language Models (LLMs), featuring optimized KV cache management and scheduling to accelerate inference and improve throughput for AI science applications.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "inference_acceleration",
        "kv_caching",
        "llm_serving"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/kvcache-ai/Mooncake",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "serving",
        "kv-cache",
        "inference"
      ],
      "id": 582
    },
    {
      "name": "LaminDB",
      "one_line_profile": "Data framework for biology with lineage and artifact tracking",
      "detailed_description": "A data framework specifically designed for biology, providing capabilities for data querying, lineage tracking, reproducibility, and artifact management (lakehouse, feature store) to ensure FAIR data principles.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_management",
        "lineage_tracking",
        "reproducibility",
        "biology_data"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/laminlabs/lamindb",
      "help_website": [
        "https://lamin.ai/docs/lamindb/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "biology",
        "data-lineage",
        "reproducibility",
        "feature-store"
      ],
      "id": 583
    },
    {
      "name": "llm-d-kv-cache",
      "one_line_profile": "Distributed KV cache coordinator for LLMs",
      "detailed_description": "A distributed coordinator for managing Key-Value (KV) caches in Large Language Model (LLM) inference, enabling efficient cache sharing and management across distributed runtime environments.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "kv_caching",
        "inference_optimization",
        "distributed_coordination"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/llm-d/llm-d-kv-cache",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "kv-cache",
        "distributed-systems",
        "inference"
      ],
      "id": 584
    },
    {
      "name": "Hopsworks",
      "one_line_profile": "Data-intensive AI platform with a Feature Store for managing ML artifacts",
      "detailed_description": "Hopsworks is an open-source platform for developing and operating machine learning models at scale. It includes a Feature Store for managing features, a Model Registry for model versioning, and support for distributed training, directly addressing artifact management in scientific ML workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_management",
        "feature_store",
        "mlops"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/logicalclocks/hopsworks",
      "help_website": [
        "https://www.hopsworks.ai/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "feature-store",
        "mlops",
        "model-registry"
      ],
      "id": 585
    },
    {
      "name": "git-lfs-s3-server",
      "one_line_profile": "Git LFS server implementation using S3, developed for astronomical data management",
      "detailed_description": "A deployable Git LFS server that uses AWS S3 as the storage backend. Developed by the LSST (Legacy Survey of Space and Time) Data Management team, it is designed to handle large scientific artifacts and data files within a version-controlled environment.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_management",
        "data_versioning"
      ],
      "application_level": "service",
      "primary_language": "Ruby",
      "repo_url": "https://github.com/lsst-sqre/git-lfs-s3-server",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "git-lfs",
        "s3",
        "astronomy",
        "artifact-storage"
      ],
      "id": 586
    },
    {
      "name": "marimo",
      "one_line_profile": "Reactive Python notebook for reproducible scientific experiments",
      "detailed_description": "A reactive notebook for Python that stores notebooks as pure Python scripts, enabling better version control and reproducibility for scientific experiments. It supports executing as a script, deploying as an app, and integrates with data analysis workflows.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "reproducible_runtime",
        "scientific_visualization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/marimo-team/marimo",
      "help_website": [
        "https://marimo.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "notebook",
        "reproducibility",
        "python",
        "data-science"
      ],
      "id": 587
    },
    {
      "name": "spark-sql-flow-plugin",
      "one_line_profile": "Spark SQL plugin for visualizing column-level data lineage",
      "detailed_description": "A plugin for Apache Spark that extracts and visualizes column-level data lineage from Spark SQL queries. This is essential for tracking data provenance and transformations in large-scale scientific data processing pipelines.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_lineage",
        "provenance_tracking"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/maropu/spark-sql-flow-plugin",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "spark",
        "data-lineage",
        "visualization",
        "provenance"
      ],
      "id": 588
    },
    {
      "name": "SingleCellLineage",
      "one_line_profile": "Pipelines for processing GESTALT single-cell lineage tracing data",
      "detailed_description": "Scripts and pipelines for processing GESTALT (Genome Editing of Synthetic Target Arrays for Lineage Tracing) data at single-cell resolution. It facilitates the reconstruction of cell lineage trees in developmental biology research.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "lineage_inference",
        "bioinformatics",
        "single_cell_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Scala",
      "repo_url": "https://github.com/mckennalab/SingleCellLineage",
      "help_website": [],
      "license": null,
      "tags": [
        "single-cell",
        "lineage-tracing",
        "gestalt",
        "bioinformatics"
      ],
      "id": 589
    },
    {
      "name": "OpenTTDLab",
      "one_line_profile": "Framework for running reproducible experiments using OpenTTD simulation",
      "detailed_description": "A Python framework designed to run reproducible experiments using the OpenTTD game engine. It allows researchers (likely in RL or complex systems) to automate simulations, manage seeds, and collect data in a consistent manner.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "simulation",
        "reproducible_experiments",
        "reinforcement_learning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/michalc/OpenTTDLab",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "simulation",
        "reproducibility",
        "openttd",
        "experimentation"
      ],
      "id": 590
    },
    {
      "name": "DataLineage",
      "one_line_profile": "Tool for extracting and visualizing data lineage from Spark and PowerBI",
      "detailed_description": "A tool developed to extract data lineage information from Spark components and PowerBI/AAS and visualize it (e.g., in Azure Purview). It supports the management of data provenance in analytical workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_lineage",
        "provenance_tracking"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/DataLineage",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-lineage",
        "spark",
        "azure",
        "provenance"
      ],
      "id": 591
    },
    {
      "name": "lst-bench",
      "one_line_profile": "Benchmark framework for Log-Structured Tables (Delta Lake, Hudi, Iceberg)",
      "detailed_description": "A framework for benchmarking Log-Structured Tables (LSTs) such as Delta Lake, Apache Hudi, and Apache Iceberg. It helps data engineers and scientists evaluate the performance of artifact stores used in data lakehouse architectures.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "benchmarking",
        "artifact_management",
        "data_storage"
      ],
      "application_level": "tool",
      "primary_language": "Java",
      "repo_url": "https://github.com/microsoft/lst-bench",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "delta-lake",
        "hudi",
        "iceberg",
        "data-lake"
      ],
      "id": 592
    },
    {
      "name": "RSoptSC",
      "one_line_profile": "Cell-cell communication and lineage inference for scRNA-seq data",
      "detailed_description": "An R package for inferring cell-cell communication networks and reconstructing cell lineage trajectories from single-cell RNA sequencing (scRNA-seq) data. It uses optimization techniques to model cellular interactions and developmental paths.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "lineage_inference",
        "bioinformatics",
        "scRNA-seq"
      ],
      "application_level": "solver",
      "primary_language": "R",
      "repo_url": "https://github.com/mkarikom/RSoptSC",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "bioinformatics",
        "single-cell",
        "lineage",
        "inference"
      ],
      "id": 593
    },
    {
      "name": "MLflow",
      "one_line_profile": "Open source platform for the machine learning lifecycle",
      "detailed_description": "A platform to streamline machine learning development, including tracking experiments, packaging code into reproducible runs, and sharing and deploying models. It provides a central registry for model management.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_management",
        "model_registry",
        "experiment_tracking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/mlflow/mlflow",
      "help_website": [
        "https://mlflow.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "experiment-tracking",
        "model-registry"
      ],
      "id": 594
    },
    {
      "name": "MCP Registry",
      "one_line_profile": "Registry service for Model Context Protocol (MCP) servers",
      "detailed_description": "A community-driven registry service designed to manage and discover Model Context Protocol (MCP) servers, facilitating the connection between AI models and data contexts.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_management",
        "service_registry"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/modelcontextprotocol/registry",
      "license": "MIT",
      "tags": [
        "mcp",
        "registry",
        "llm-infrastructure"
      ],
      "id": 595
    },
    {
      "name": "CellTagR",
      "one_line_profile": "R package for clone calling and lineage reconstruction",
      "detailed_description": "A computational tool for analyzing CellTag data to support clone calling and lineage reconstruction in single-cell biology experiments.",
      "domains": [
        "Bioinformatics"
      ],
      "subtask_category": [
        "lineage_reconstruction",
        "clone_calling"
      ],
      "application_level": "library",
      "primary_language": "R",
      "repo_url": "https://github.com/morris-lab/CellTagR",
      "license": null,
      "tags": [
        "single-cell",
        "lineage-tracing",
        "r-package"
      ],
      "id": 596
    },
    {
      "name": "Jodie",
      "one_line_profile": "Delta Lake and filesystem helper methods for Scala",
      "detailed_description": "A utility library providing helper methods for managing Delta Lake tables and filesystem operations, facilitating data versioning and management in data science workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_management",
        "data_versioning"
      ],
      "application_level": "library",
      "primary_language": "Scala",
      "repo_url": "https://github.com/mrpowers-io/jodie",
      "license": "MIT",
      "tags": [
        "delta-lake",
        "scala",
        "data-engineering"
      ],
      "id": 597
    },
    {
      "name": "Levi",
      "one_line_profile": "Delta Lake helper methods for Python",
      "detailed_description": "A Python library offering utility functions for interacting with Delta Lake, enabling efficient data management and versioning without a direct Spark dependency.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_management",
        "data_versioning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mrpowers-io/levi",
      "license": "MIT",
      "tags": [
        "delta-lake",
        "python",
        "data-management"
      ],
      "id": 598
    },
    {
      "name": "Horcrux",
      "one_line_profile": "Version controlled access to data for Docker containers",
      "detailed_description": "A tool that provides on-demand, version-controlled access to data volumes for Docker containers, facilitating reproducible data environments for containerized applications.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_versioning",
        "container_storage"
      ],
      "application_level": "infrastructure",
      "primary_language": "Go",
      "repo_url": "https://github.com/muthu-r/horcrux",
      "license": "BSD-3-Clause",
      "tags": [
        "docker",
        "data-versioning",
        "storage"
      ],
      "id": 599
    },
    {
      "name": "Fast-LangGraph",
      "one_line_profile": "High-performance Rust accelerators for LangGraph applications",
      "detailed_description": "A library providing Rust-based accelerators for LangGraph, optimizing checkpoint operations and state management for LLM agent workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "state_management",
        "artifact_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/neul-labs/fast-langgraph",
      "license": "MIT",
      "tags": [
        "langgraph",
        "rust",
        "optimization"
      ],
      "id": 600
    },
    {
      "name": "Reskit",
      "one_line_profile": "Library for reproducible pipelines in scientific machine learning",
      "detailed_description": "A Python library designed to assist in creating and curating reproducible machine learning pipelines, specifically targeting scientific and industrial applications.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "pipeline_management",
        "reproducibility"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/neuro-ml/reskit",
      "license": "BSD-3-Clause",
      "tags": [
        "scientific-ml",
        "reproducibility",
        "pipelines"
      ],
      "id": 601
    },
    {
      "name": "ONNX Registry",
      "one_line_profile": "Web service for managing ONNX models",
      "detailed_description": "An intelligent component registry web service for storing, managing, and retrieving SNN, DNN, and ML models in the ONNX format.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "model_registry",
        "artifact_management"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/neurom-iot/onnx-registry",
      "license": "MIT",
      "tags": [
        "onnx",
        "model-registry",
        "mlops"
      ],
      "id": 602
    },
    {
      "name": "Kapsule",
      "one_line_profile": "Tool for packaging LLM models into OCI images",
      "detailed_description": "A utility for packaging Large Language Models (LLMs) into encrypted OCI (Open Container Initiative) images, enabling secure distribution via standard container registries.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_packaging",
        "model_distribution"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/nicholasjackson/kapsule",
      "license": null,
      "tags": [
        "llm",
        "oci",
        "packaging"
      ],
      "id": 603
    },
    {
      "name": "Shelf",
      "one_line_profile": "Type-aware, fsspec-based artifact store client",
      "detailed_description": "A Python client for general artifact storage that leverages fsspec to provide a type-aware interface for managing data and model artifacts across various storage backends.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_management",
        "storage_client"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nicholasjng/shelf",
      "license": "Apache-2.0",
      "tags": [
        "fsspec",
        "artifact-store",
        "python"
      ],
      "id": 604
    },
    {
      "name": "lfs-s3",
      "one_line_profile": "Git LFS custom transfer agent for S3",
      "detailed_description": "A custom transfer agent for Git LFS (Large File Storage) that enables using Amazon S3 (or compatible providers) as the storage backend for versioning large scientific datasets and models.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_versioning",
        "storage_backend"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/nicolas-graves/lfs-s3",
      "license": "MIT",
      "tags": [
        "git-lfs",
        "s3",
        "data-versioning"
      ],
      "id": 605
    },
    {
      "name": "Trustix",
      "one_line_profile": "Distributed trust and reproducibility tracking for binary caches",
      "detailed_description": "A tool for tracking reproducibility and establishing distributed trust for binary caches, particularly within the Nix ecosystem, ensuring artifact integrity in scientific computing workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "reproducibility",
        "artifact_verification"
      ],
      "application_level": "infrastructure",
      "primary_language": "Go",
      "repo_url": "https://github.com/nix-community/trustix",
      "license": null,
      "tags": [
        "nix",
        "reproducibility",
        "binary-cache"
      ],
      "id": 606
    },
    {
      "name": "OpenHPC Scale-up Automation",
      "one_line_profile": "Automation scripts for scaling OpenHPC clusters",
      "detailed_description": "A set of tools and scripts to automate the process of scaling up OpenHPC clusters by leveraging IPMI and Redfish for hardware management and node discovery.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "cluster_management",
        "hpc_automation"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/nsfcac/Automating-the-scale-up-process-in-OpenHPC",
      "license": null,
      "tags": [
        "openhpc",
        "hpc",
        "automation"
      ],
      "id": 607
    },
    {
      "name": "StorageLayer",
      "one_line_profile": "Content-addressable storage for files across S3 and local systems",
      "detailed_description": "A library providing a content-addressable storage abstraction layer, allowing unified file management across local filesystems and S3, useful for data-intensive analysis.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "storage_abstraction",
        "artifact_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/occrp-attic/storagelayer",
      "license": "MIT",
      "tags": [
        "storage",
        "content-addressable",
        "s3"
      ],
      "id": 608
    },
    {
      "name": "Ollama GGUF Downloader",
      "one_line_profile": "CLI tool to download GGUF model files from Ollama registry",
      "detailed_description": "A command-line tool designed to download GGUF model files directly from the Ollama registry, facilitating the acquisition and management of local AI models.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_management",
        "model_download"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/olamide226/ollama-gguf-downloader",
      "license": "MIT",
      "tags": [
        "ollama",
        "gguf",
        "model-management"
      ],
      "id": 609
    },
    {
      "name": "Onllama ModelScope2Registry",
      "one_line_profile": "Ollama Model Registry Mirror/Accelerator for ModelScope",
      "detailed_description": "A tool acting as a registry mirror and accelerator, enabling faster downloading of Ollama models from the ModelScope repository.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_management",
        "registry_mirror"
      ],
      "application_level": "tool",
      "primary_language": "C#",
      "repo_url": "https://github.com/onllama/Onllama.ModelScope2Registry",
      "license": "MIT",
      "tags": [
        "ollama",
        "modelscope",
        "registry"
      ],
      "id": 610
    },
    {
      "name": "GAM",
      "one_line_profile": "Globally Addressable Memory management via RDMA",
      "detailed_description": "A system for efficient distributed memory management using RDMA and caching, designed to support high-performance computing applications requiring shared memory abstractions.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "memory_management",
        "caching",
        "hpc_acceleration"
      ],
      "application_level": "infrastructure",
      "primary_language": "C++",
      "repo_url": "https://github.com/ooibc88/gam",
      "license": null,
      "tags": [
        "rdma",
        "distributed-memory",
        "hpc"
      ],
      "id": 611
    },
    {
      "name": "OomStore",
      "one_line_profile": "Lightweight and fast Feature Store",
      "detailed_description": "A feature store powered by Go and Rust, designed to manage and serve machine learning features consistently across training and inference environments.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "feature_store",
        "data_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/oom-ai/oomstore",
      "license": "Apache-2.0",
      "tags": [
        "feature-store",
        "mlops",
        "go"
      ],
      "id": 612
    },
    {
      "name": "OpenMetadata",
      "one_line_profile": "Unified metadata platform for data discovery and observability",
      "detailed_description": "A platform for metadata management, data discovery, and lineage tracking, essential for governing scientific data assets and ensuring data quality and traceability.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "metadata_management",
        "lineage_tracking",
        "data_discovery"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/open-metadata/OpenMetadata",
      "help_website": [
        "https://open-metadata.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "metadata",
        "data-governance",
        "lineage"
      ],
      "id": 613
    },
    {
      "name": "ODD Platform",
      "one_line_profile": "Open-source data discovery and observability platform",
      "detailed_description": "A platform focused on data discovery and observability, helping data practitioners manage data lineage and quality in complex data ecosystems.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_discovery",
        "observability"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/opendatadiscovery/odd-platform",
      "license": "Apache-2.0",
      "tags": [
        "observability",
        "data-discovery",
        "lineage"
      ],
      "id": 614
    },
    {
      "name": "hcfsfuse",
      "one_line_profile": "Hadoop compatible FUSE client",
      "detailed_description": "A FUSE (Filesystem in Userspace) implementation that allows mounting Hadoop-compatible filesystems locally, facilitating access to distributed storage in HPC/Big Data environments.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "storage_access",
        "hpc_integration"
      ],
      "application_level": "tool",
      "primary_language": "Java",
      "repo_url": "https://github.com/opendataio/hcfsfuse",
      "license": "Apache-2.0",
      "tags": [
        "hadoop",
        "fuse",
        "hpc"
      ],
      "id": 615
    },
    {
      "name": "ModelStore",
      "one_line_profile": "Library to version, export, and save ML models",
      "detailed_description": "A Python library that simplifies the process of versioning, exporting, and saving machine learning models to various storage providers, supporting reproducible ML workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "model_versioning",
        "artifact_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/operatorai/modelstore",
      "license": "Apache-2.0",
      "tags": [
        "model-versioning",
        "mlops",
        "python"
      ],
      "id": 616
    },
    {
      "name": "Pachyderm",
      "one_line_profile": "Data-centric pipeline and data versioning platform for reproducible data science",
      "detailed_description": "Pachyderm is a data versioning and data lineage platform that allows users to create reproducible data science pipelines. It provides a Git-like file system for data (PFS) and a pipeline system (PPS) that automatically triggers processing when data changes, ensuring full reproducibility and provenance tracking for scientific workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_versioning",
        "lineage_tracking",
        "pipeline_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/pachyderm/pachyderm",
      "help_website": [
        "https://www.pachyderm.com/docs"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-versioning",
        "mlops",
        "reproducibility",
        "pipeline"
      ],
      "id": 617
    },
    {
      "name": "python-pachyderm",
      "one_line_profile": "Python client library for Pachyderm data versioning platform",
      "detailed_description": "The official Python client for Pachyderm, enabling scientists and developers to interact with Pachyderm's data versioning and pipeline features programmatically. It facilitates the integration of data lineage and version control into Python-based scientific workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_versioning",
        "api_client"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pachyderm/python-pachyderm",
      "help_website": [
        "https://pachyderm-python.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "python",
        "client",
        "pachyderm",
        "data-science"
      ],
      "id": 618
    },
    {
      "name": "duckdb-diskcache",
      "one_line_profile": "Disk caching extension for DuckDB to accelerate access to remote data lakes",
      "detailed_description": "A C++ extension for DuckDB that provides a disk cache for accessing remote data lakes (such as Iceberg or Delta Lake). Developed by researchers at CWI, it optimizes data access patterns for analytical workloads common in scientific data processing.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "caching",
        "data_access_acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/peterboncz/duckdb-diskcache",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "duckdb",
        "caching",
        "data-lake",
        "performance"
      ],
      "id": 619
    },
    {
      "name": "STREAM",
      "one_line_profile": "Single-cell Trajectories Reconstruction, Exploration And Mapping tool",
      "detailed_description": "STREAM is an interactive pipeline for reconstructing complex cellular differentiation trajectories from single-cell RNA-sequencing data. It can accurately disentangle complex trajectories and provides visualization tools for exploring developmental branches.",
      "domains": [
        "AI3",
        "Bioinformatics"
      ],
      "subtask_category": [
        "trajectory_inference",
        "single_cell_analysis",
        "visualization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/pinellolab/STREAM",
      "help_website": [
        "https://stream.pinellolab.partners.org/"
      ],
      "license": "AGPL-3.0",
      "tags": [
        "single-cell",
        "trajectory-inference",
        "rna-seq",
        "bioinformatics"
      ],
      "id": 620
    },
    {
      "name": "PLynx",
      "one_line_profile": "Domain-agnostic platform for managing reproducible experiments and data-oriented workflows",
      "detailed_description": "PLynx is a modular platform designed to manage reproducible experiments and data-oriented workflows. It provides a graphical interface for building pipelines, tracking experiment history, and managing artifacts, suitable for machine learning and scientific computing tasks.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "workflow_management",
        "reproducibility",
        "experiment_tracking"
      ],
      "application_level": "platform",
      "primary_language": "JavaScript",
      "repo_url": "https://github.com/plynx-team/plynx",
      "help_website": [
        "https://plynx.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "workflow",
        "reproducibility",
        "experiment-tracking",
        "pipeline"
      ],
      "id": 621
    },
    {
      "name": "GENDIS",
      "one_line_profile": "Genetic Discovery of Shapelets algorithm for time series classification",
      "detailed_description": "GENDIS (GEnetic DIscovery of Shapelets) is a Python implementation of a genetic algorithm-based shapelet discovery method for time series classification. It provides a scikit-learn compatible API for analyzing time-series data, which is common in scientific experiments.",
      "domains": [
        "AI1",
        "DataScience"
      ],
      "subtask_category": [
        "time_series_analysis",
        "shapelet_discovery",
        "classification"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/predict-idlab/GENDIS",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "time-series",
        "genetic-algorithm",
        "shapelets",
        "sklearn"
      ],
      "id": 622
    },
    {
      "name": "GridFluidSim3D",
      "one_line_profile": "PIC/FLIP fluid simulation solver based on physical methods",
      "detailed_description": "A C++ implementation of a fluid simulation solver using Particle-In-Cell (PIC) and Fluid-Implicit-Particle (FLIP) methods, capable of generating fluid dynamics data.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "simulation",
        "fluid_dynamics"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/rlguy/GridFluidSim3D",
      "help_website": [],
      "license": "Zlib",
      "tags": [
        "fluid-simulation",
        "physics",
        "solver",
        "cpp"
      ],
      "id": 623
    },
    {
      "name": "BPref",
      "one_line_profile": "Benchmark suite for preference-based reinforcement learning",
      "detailed_description": "A benchmarking framework for preference-based reinforcement learning (PbRL), providing environments and baselines to evaluate RL algorithms.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "benchmarking",
        "reinforcement_learning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/rll-research/BPref",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "reinforcement-learning",
        "benchmark",
        "preference-learning"
      ],
      "id": 624
    },
    {
      "name": "gittargets",
      "one_line_profile": "Data version control for R analysis pipelines",
      "detailed_description": "A tool that integrates data version control with the 'targets' workflow package in R, enabling reproducible analysis pipelines by tracking data snapshots.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_versioning",
        "workflow_management"
      ],
      "application_level": "tool",
      "primary_language": "R",
      "repo_url": "https://github.com/ropensci/gittargets",
      "help_website": [
        "https://docs.ropensci.org/gittargets/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "r",
        "data-version-control",
        "reproducibility",
        "pipeline"
      ],
      "id": 625
    },
    {
      "name": "s3git",
      "one_line_profile": "Distributed version control for data on cloud storage",
      "detailed_description": "A CLI tool that brings git-like versioning to data stored in S3 and other cloud storage, enabling distributed version control for large datasets.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_versioning",
        "artifact_management"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/s3git/s3git",
      "help_website": [
        "http://s3git.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-versioning",
        "s3",
        "cloud-storage",
        "git-like"
      ],
      "id": 626
    },
    {
      "name": "git-lfs-ipfs",
      "one_line_profile": "IPFS storage backend for Git LFS",
      "detailed_description": "A custom transfer agent for Git LFS that allows using IPFS (InterPlanetary File System) as the storage backend for large scientific artifacts.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_management",
        "data_storage"
      ],
      "application_level": "tool",
      "primary_language": "Rust",
      "repo_url": "https://github.com/sameer/git-lfs-ipfs",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "git-lfs",
        "ipfs",
        "decentralized-storage",
        "artifact-management"
      ],
      "id": 627
    },
    {
      "name": "lambo",
      "one_line_profile": "Bayesian optimization solver for protein design",
      "detailed_description": "Implementation of 'Latent MBO', a method for accelerating Bayesian Optimization for protein design using denoising autoencoders.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "protein_design",
        "optimization"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/samuelstanton/lambo",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "protein-design",
        "bayesian-optimization",
        "machine-learning",
        "bioinformatics"
      ],
      "id": 628
    },
    {
      "name": "lfscache",
      "one_line_profile": "Caching proxy for Git LFS",
      "detailed_description": "A caching proxy server for Git LFS, designed to accelerate the retrieval of large artifacts in distributed workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "caching",
        "artifact_management"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/saracen/lfscache",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "git-lfs",
        "caching",
        "proxy",
        "performance"
      ],
      "id": 629
    },
    {
      "name": "llm-data-annotation",
      "one_line_profile": "Data annotation framework using LLMs",
      "detailed_description": "A framework that leverages Large Language Models (LLMs) and active learning to automate and enhance data annotation processes for machine learning datasets.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_annotation",
        "data_processing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/saran9991/llm-data-annotation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-annotation",
        "llm",
        "active-learning",
        "cleanlab"
      ],
      "id": 630
    },
    {
      "name": "DVCP-TE",
      "one_line_profile": "Simulation model of the Tennessee Eastman chemical process",
      "detailed_description": "A simulation environment for the Tennessee Eastman chemical process, used as a benchmark for process control and security research (Damn Vulnerable Chemical Process).",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "simulation",
        "process_control"
      ],
      "application_level": "dataset",
      "primary_language": "HTML",
      "repo_url": "https://github.com/satejnik/DVCP-TE",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "chemical-process",
        "simulation",
        "benchmark",
        "security"
      ],
      "id": 631
    },
    {
      "name": "lfs-folderstore",
      "one_line_profile": "Local folder storage adapter for Git LFS",
      "detailed_description": "A custom transfer adapter for Git LFS that allows using a local folder (or shared network drive) as the remote storage backend, facilitating artifact management in restricted environments.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "artifact_management",
        "data_storage"
      ],
      "application_level": "tool",
      "primary_language": "Go",
      "repo_url": "https://github.com/sinbad/lfs-folderstore",
      "help_website": [],
      "license": null,
      "tags": [
        "git-lfs",
        "storage-adapter",
        "artifact-management"
      ],
      "id": 632
    },
    {
      "name": "Spine Toolbox",
      "one_line_profile": "Workflow and data management for modelling and simulation",
      "detailed_description": "An open-source platform to manage data, scenarios, and workflows for complex modelling and simulation tasks, supporting version control and team collaboration.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "workflow_management",
        "simulation_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/spine-tools/Spine-Toolbox",
      "help_website": [
        "https://spine-toolbox.readthedocs.io/"
      ],
      "license": "LGPL-3.0",
      "tags": [
        "workflow",
        "simulation",
        "data-management",
        "modelling"
      ],
      "id": 633
    },
    {
      "name": "stac-geoparquet",
      "one_line_profile": "Conversion library between STAC items and GeoParquet format",
      "detailed_description": "A Python library to convert SpatioTemporal Asset Catalog (STAC) items between JSON, GeoParquet, pgstac, and Delta Lake formats, facilitating efficient storage and querying of geospatial data.",
      "domains": [
        "Earth Science",
        "Geospatial",
        "AI6-03"
      ],
      "subtask_category": [
        "data_conversion",
        "data_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/stac-utils/stac-geoparquet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "stac",
        "geoparquet",
        "geospatial",
        "gis",
        "data-conversion"
      ],
      "id": 634
    },
    {
      "name": "SU2",
      "one_line_profile": "Open-Source Suite for Multiphysics Simulation and Design",
      "detailed_description": "SU2 is an open-source suite of software tools written in C++ for the numerical solution of partial differential equations (PDE) and performing PDE-constrained optimization, primarily for CFD and aerodynamics.",
      "domains": [
        "Physics",
        "CFD",
        "HPC",
        "AI6"
      ],
      "subtask_category": [
        "simulation",
        "modeling",
        "optimization"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/su2code/SU2",
      "help_website": [
        "https://su2code.github.io/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "cfd",
        "multiphysics",
        "simulation",
        "aerodynamics",
        "optimization"
      ],
      "id": 635
    },
    {
      "name": "torchdatasets",
      "one_line_profile": "Extended PyTorch Dataset with caching and mapping capabilities",
      "detailed_description": "A library that extends PyTorch Dataset with features like caching, mapping, and other functional transformations, similar to tensorflow.data, to optimize data loading pipelines in scientific machine learning.",
      "domains": [
        "AI6-03",
        "Machine Learning"
      ],
      "subtask_category": [
        "data_loading",
        "caching",
        "data_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/szymonmaszke/torchdatasets",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "dataset",
        "caching",
        "data-loading"
      ],
      "id": 636
    },
    {
      "name": "Hangar",
      "one_line_profile": "Version control system for tensor data",
      "detailed_description": "Hangar is a version control system specifically designed for tensor data. It allows users to commit, branch, merge, revert, and collaborate on numerical data, ensuring reproducibility in machine learning and scientific research.",
      "domains": [
        "AI6-03",
        "Machine Learning"
      ],
      "subtask_category": [
        "data_versioning",
        "artifact_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/tensorwerk/hangar-py",
      "help_website": [
        "https://hangar-py.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-versioning",
        "tensors",
        "reproducibility",
        "git-for-data"
      ],
      "id": 637
    },
    {
      "name": "LineageExplorer",
      "one_line_profile": "Tool for estimating SARS-CoV-2 variant growth advantages",
      "detailed_description": "An R package/tool to estimate the growth rate advantage of SARS-CoV-2 variants of concern based on international genomic surveillance data and multinomial spline fits.",
      "domains": [
        "Biology",
        "Epidemiology",
        "Genomics"
      ],
      "subtask_category": [
        "inference",
        "statistical_analysis",
        "modeling"
      ],
      "application_level": "solver",
      "primary_language": "R",
      "repo_url": "https://github.com/tomwenseleers/LineageExplorer",
      "help_website": [],
      "license": null,
      "tags": [
        "covid-19",
        "epidemiology",
        "genomics",
        "statistical-modeling"
      ],
      "id": 638
    },
    {
      "name": "DVC",
      "one_line_profile": "Data Version Control for Machine Learning Projects",
      "detailed_description": "DVC is a data version control system built for machine learning projects. It handles large files, datasets, and machine learning models, making them shareable and reproducible. It integrates with Git to version control data and pipelines.",
      "domains": [
        "AI6-03",
        "Machine Learning",
        "Data Science"
      ],
      "subtask_category": [
        "data_versioning",
        "reproducibility",
        "pipeline_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/treeverse/dvc",
      "help_website": [
        "https://dvc.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-version-control",
        "mlops",
        "reproducibility",
        "git-for-data"
      ],
      "id": 639
    },
    {
      "name": "DVCLive",
      "one_line_profile": "Library for logging and tracking ML metrics",
      "detailed_description": "DVCLive is a Python library for logging machine learning metrics, parameters, and model artifacts. It integrates with DVC to track experiments and visualize results, facilitating scientific experiment management.",
      "domains": [
        "AI6-03",
        "Machine Learning"
      ],
      "subtask_category": [
        "experiment_tracking",
        "metrics_logging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/treeverse/dvclive",
      "help_website": [
        "https://dvc.org/doc/dvclive"
      ],
      "license": "Apache-2.0",
      "tags": [
        "experiment-tracking",
        "mlops",
        "metrics",
        "logging"
      ],
      "id": 640
    },
    {
      "name": "lakeFS",
      "one_line_profile": "Git-like version control for data lakes",
      "detailed_description": "lakeFS provides a Git-like version control interface for object storage (S3, Azure Blob, GCS). It allows managing data lakes with commits, branches, and merges, enabling reproducible data science and data engineering workflows.",
      "domains": [
        "AI6-03",
        "Data Science",
        "Big Data"
      ],
      "subtask_category": [
        "data_versioning",
        "artifact_management",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/treeverse/lakeFS",
      "help_website": [
        "https://lakefs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "data-lake",
        "version-control",
        "object-storage",
        "reproducibility"
      ],
      "id": 641
    },
    {
      "name": "ATOM",
      "one_line_profile": "Python package for fast exploration and optimization of machine learning pipelines",
      "detailed_description": "ATOM is an AutoML tool designed to accelerate the data science pipeline. It provides features for data cleaning, feature engineering, and model selection/optimization, specifically catering to scientific modeling and analysis tasks.",
      "domains": [
        "AI4",
        "AI6"
      ],
      "subtask_category": [
        "automl",
        "model_optimization",
        "pipeline_automation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tvdboom/ATOM",
      "help_website": [
        "https://atom-ml.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "automl",
        "machine-learning",
        "data-science"
      ],
      "id": 642
    },
    {
      "name": "tvault",
      "one_line_profile": "Lightweight local model registry for PyTorch",
      "detailed_description": "tvault is a tool for managing machine learning model artifacts. It allows researchers to track, compare, and register PyTorch models locally, facilitating reproducibility and experiment management in scientific workflows.",
      "domains": [
        "AI6-03"
      ],
      "subtask_category": [
        "model_registry",
        "artifact_management",
        "experiment_tracking"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/vessl-ai/tvault",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "model-registry",
        "pytorch",
        "mlops"
      ],
      "id": 643
    },
    {
      "name": "OpenCorr",
      "one_line_profile": "Digital Image Correlation (DIC) and Digital Volume Correlation (DVC) library",
      "detailed_description": "OpenCorr is an open-source C++ library for Digital Image Correlation (DIC) and Digital Volume Correlation (DVC), widely used in experimental mechanics and materials science for strain and deformation analysis.",
      "domains": [
        "Physics",
        "Materials Science"
      ],
      "subtask_category": [
        "digital_image_correlation",
        "strain_analysis",
        "deformation_measurement"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/vincentjzy/OpenCorr",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "dic",
        "dvc",
        "experimental-mechanics"
      ],
      "id": 644
    },
    {
      "name": "vLLM",
      "one_line_profile": "High-throughput and memory-efficient inference engine for LLMs",
      "detailed_description": "vLLM is a high-performance library for LLM inference and serving. It utilizes PagedAttention to manage attention key and value memory efficiently, making it a critical tool for deploying large-scale scientific language models.",
      "domains": [
        "AI6",
        "AI6-01"
      ],
      "subtask_category": [
        "llm_inference",
        "model_serving",
        "memory_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/vllm-project/vllm",
      "help_website": [
        "https://docs.vllm.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "inference-engine",
        "llm",
        "hpc"
      ],
      "id": 645
    },
    {
      "name": "GPTCache",
      "one_line_profile": "Semantic caching library for Large Language Models to reduce latency and costs",
      "detailed_description": "A semantic cache for LLMs that stores and retrieves responses based on semantic similarity. It integrates with LangChain and llama_index to optimize inference efficiency, reducing API costs and latency in AI-driven scientific workflows.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "caching",
        "inference_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zilliztech/GPTCache",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "caching",
        "semantic-search",
        "optimization"
      ],
      "id": 646
    },
    {
      "name": "ZnTrack",
      "one_line_profile": "Python interface for DVC to manage scientific workflows and data versioning",
      "detailed_description": "A lightweight Python package that acts as a wrapper for DVC (Data Version Control). It enables researchers to define, run, visualize, and benchmark DVC pipelines directly within Python scripts or Jupyter notebooks, facilitating reproducible scientific experiments.",
      "domains": [
        "AI6",
        "AI6-03"
      ],
      "subtask_category": [
        "data_versioning",
        "workflow_management"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/zincware/ZnTrack",
      "help_website": [
        "https://zntrack.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "dvc",
        "reproducibility",
        "pipeline",
        "jupyter"
      ],
      "id": 647
    },
    {
      "name": "tensorscript",
      "one_line_profile": "Shape-checking neural network DSL compiling to PyTorch",
      "detailed_description": "A domain-specific language (DSL) for defining neural networks with a Hindley-Milner type system for shape checking, compiling to PyTorch for execution.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "model_definition"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/0b01/tensorscript",
      "help_website": [],
      "license": null,
      "tags": [
        "dsl",
        "compiler",
        "pytorch",
        "shape-checking"
      ],
      "id": 648
    },
    {
      "name": "YOLO_RKNN_Acceleration_Program",
      "one_line_profile": "Multi-threaded hardware-accelerated inference framework for YOLO on RKNN",
      "detailed_description": "A framework for accelerating YOLO object detection models using Rockchip NPU (RKNN), featuring multi-threading support for efficient inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "edge_computing"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/1125962926/YOLO_RKNN_Acceleration_Program",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "yolo",
        "rknn",
        "npu",
        "inference"
      ],
      "id": 649
    },
    {
      "name": "PTQ4DM",
      "one_line_profile": "Post-training quantization framework for diffusion models",
      "detailed_description": "Implementation of post-training quantization (PTQ) techniques specifically optimized for diffusion models to reduce model size and accelerate inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/42Shawn/PTQ4DM",
      "help_website": [],
      "license": null,
      "tags": [
        "diffusion-models",
        "ptq",
        "quantization"
      ],
      "id": 650
    },
    {
      "name": "OpenEmbedding",
      "one_line_profile": "Distributed training acceleration framework for TensorFlow embedding layers",
      "detailed_description": "An open-source framework designed to accelerate distributed training of large-scale embedding layers in TensorFlow models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "training_acceleration",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/4paradigm/OpenEmbedding",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tensorflow",
        "embedding",
        "distributed-training"
      ],
      "id": 651
    },
    {
      "name": "micronet",
      "one_line_profile": "Comprehensive model compression and deployment library",
      "detailed_description": "A library for neural network compression and deployment, supporting quantization (QAT, PTQ), pruning, and TensorRT deployment integration.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "quantization",
        "pruning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/666DZY666/micronet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "model-compression",
        "quantization",
        "pruning",
        "tensorrt"
      ],
      "id": 652
    },
    {
      "name": "JetStream",
      "one_line_profile": "High-throughput LLM inference engine for XLA devices",
      "detailed_description": "A throughput and memory optimized inference engine for Large Language Models (LLMs) designed for XLA devices like TPUs.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "llm_serving"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/AI-Hypercomputer/JetStream",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "inference",
        "tpu",
        "xla"
      ],
      "id": 653
    },
    {
      "name": "jetstream-pytorch",
      "one_line_profile": "PyTorch/XLA integration for JetStream inference engine",
      "detailed_description": "Provides PyTorch/XLA integration with the JetStream engine to enable high-performance LLM inference using PyTorch models on XLA devices.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "framework_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AI-Hypercomputer/jetstream-pytorch",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pytorch",
        "xla",
        "jetstream",
        "inference"
      ],
      "id": 654
    },
    {
      "name": "BiLLM",
      "one_line_profile": "Ultra-low bit post-training quantization for LLMs",
      "detailed_description": "Implementation of BiLLM, a method for pushing the limits of post-training quantization for Large Language Models to extremely low bit-widths.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Aaronhuang-778/BiLLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "quantization",
        "ptq"
      ],
      "id": 655
    },
    {
      "name": "Hash3D",
      "one_line_profile": "Training-free acceleration tool for 3D generation",
      "detailed_description": "A tool providing training-free acceleration techniques for 3D generative models, optimizing the generation process.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "3d_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Adamdad/hash3D",
      "help_website": [],
      "license": null,
      "tags": [
        "3d-generation",
        "acceleration",
        "training-free"
      ],
      "id": 656
    },
    {
      "name": "Adlik",
      "one_line_profile": "End-to-end deep learning inference acceleration toolkit",
      "detailed_description": "A toolkit for accelerating deep learning inference, providing model optimization and deployment capabilities across various hardware platforms.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_optimization"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/Adlik/Adlik",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "acceleration",
        "deep-learning"
      ],
      "id": 657
    },
    {
      "name": "LLM-distributed-finetune",
      "one_line_profile": "Distributed fine-tuning workflow for LLMs using DeepSpeed and Ray",
      "detailed_description": "A workflow tool for efficiently fine-tuning Large Language Models (LLMs) using distributed training techniques with DeepSpeed and Ray orchestration.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "fine_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/AdrianBZG/LLM-distributed-finetune",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "distributed-training",
        "deepspeed",
        "ray"
      ],
      "id": 658
    },
    {
      "name": "optimum-transformers",
      "one_line_profile": "Accelerated NLP pipelines using ONNX Runtime",
      "detailed_description": "A library providing accelerated NLP pipelines for fast inference on CPU and GPU, integrating Transformers with Optimum and ONNX Runtime.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "nlp_pipeline"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AlekseyKorshuk/optimum-transformers",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "nlp",
        "onnx",
        "inference",
        "acceleration"
      ],
      "id": 659
    },
    {
      "name": "torchacc",
      "one_line_profile": "PyTorch distributed training acceleration framework",
      "detailed_description": "A framework designed to accelerate distributed training workloads in PyTorch, optimizing performance for large-scale models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "training_acceleration",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AlibabaPAI/torchacc",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pytorch",
        "distributed-training",
        "acceleration"
      ],
      "id": 660
    },
    {
      "name": "Compass_Apache_TVM",
      "one_line_profile": "Enhanced Apache TVM compiler for heterogeneous execution",
      "detailed_description": "An enhanced version of the Apache TVM compiler stack, optimized for wide neural network support and heterogeneous execution on specific hardware.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "inference_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Arm-China/Compass_Apache_TVM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tvm",
        "compiler",
        "heterogeneous-computing"
      ],
      "id": 661
    },
    {
      "name": "AutoGPTQ",
      "one_line_profile": "Easy-to-use LLM quantization package based on GPTQ",
      "detailed_description": "A user-friendly library for quantizing Large Language Models (LLMs) using the GPTQ algorithm, facilitating efficient inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/AutoGPTQ/AutoGPTQ",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gptq",
        "quantization",
        "llm"
      ],
      "id": 662
    },
    {
      "name": "distribuuuu",
      "one_line_profile": "Lightweight PyTorch distributed training framework",
      "detailed_description": "A minimalist and clear framework for PyTorch distributed training, designed to simplify the setup and execution of distributed experiments.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "training_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BIGBALLON/distribuuuu",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "distributed-training"
      ],
      "id": 663
    },
    {
      "name": "BitNet-Transformers",
      "one_line_profile": "1-bit Transformer implementation for LLMs",
      "detailed_description": "A PyTorch implementation of BitNet (Scaling 1-bit Transformers for Large Language Models) integrated with Huggingface Transformers.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_architecture"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Beomi/BitNet-Transformers",
      "help_website": [],
      "license": null,
      "tags": [
        "bitnet",
        "1-bit",
        "quantization",
        "llm"
      ],
      "id": 664
    },
    {
      "name": "bluefog",
      "one_line_profile": "Decentralized distributed training framework for PyTorch",
      "detailed_description": "A distributed and decentralized training framework for PyTorch that operates over graphs, optimizing communication for large-scale training.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "decentralized_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Bluefog-Lib/bluefog",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "decentralized",
        "pytorch"
      ],
      "id": 665
    },
    {
      "name": "attorch",
      "one_line_profile": "PyTorch modules accelerated with OpenAI Triton",
      "detailed_description": "A collection of PyTorch neural network modules re-implemented using OpenAI's Triton language for high-performance GPU acceleration.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "acceleration",
        "kernel_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/BobMcDear/attorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "triton",
        "pytorch",
        "acceleration"
      ],
      "id": 666
    },
    {
      "name": "metalQwen3",
      "one_line_profile": "Metal GPU accelerated inference for Qwen3 on macOS",
      "detailed_description": "A C++ implementation of the Qwen3 transformer model optimized for Apple Silicon using Metal compute shaders for acceleration.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "edge_computing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/BoltzmannEntropy/metalQwen3",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "metal",
        "apple-silicon",
        "qwen",
        "inference"
      ],
      "id": 667
    },
    {
      "name": "Triton-distributed",
      "one_line_profile": "Distributed compiler based on Triton",
      "detailed_description": "A distributed compiler infrastructure built on top of Triton, designed to optimize parallel execution across distributed systems.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "distributed_computing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ByteDance-Seed/Triton-distributed",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "triton",
        "compiler",
        "distributed-systems"
      ],
      "id": 668
    },
    {
      "name": "Super-Fast-Adversarial-Training",
      "one_line_profile": "High-performance adversarial training framework",
      "detailed_description": "A PyTorch implementation for super fast adversarial training, incorporating distributed data parallel, mixed precision, and efficient data loading techniques.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "training_acceleration",
        "adversarial_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ByungKwanLee/Super-Fast-Adversarial-Training",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "adversarial-training",
        "acceleration",
        "pytorch"
      ],
      "id": 669
    },
    {
      "name": "XB-Sim",
      "one_line_profile": "Simulation framework for ReRAM-based CNN acceleration",
      "detailed_description": "A unified framework for training, mapping, and simulating Convolutional Neural Networks (CNNs) on ReRAM-based hardware accelerators.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "hardware_simulation",
        "neuromorphic_computing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/CRAFT-THU/XB-Sim",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "reram",
        "simulation",
        "hardware-acceleration"
      ],
      "id": 670
    },
    {
      "name": "ChatGLM_mutli_gpu_tuning",
      "one_line_profile": "Multi-GPU fine-tuning tool for ChatGLM",
      "detailed_description": "A streamlined implementation for multi-GPU fine-tuning of ChatGLM models using DeepSpeed and HuggingFace Trainer.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "fine_tuning",
        "distributed_training"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/CSHaitao/ChatGLM_mutli_gpu_tuning",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chatglm",
        "fine-tuning",
        "deepspeed"
      ],
      "id": 671
    },
    {
      "name": "triton-linalg",
      "one_line_profile": "Triton to Linalg dialect conversion tool",
      "detailed_description": "A development repository for converting Triton IR to MLIR Linalg dialect, facilitating compiler interoperability and optimization.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "ir_conversion"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/Cambricon/triton-linalg",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "triton",
        "mlir",
        "linalg",
        "compiler"
      ],
      "id": 672
    },
    {
      "name": "APQ-DM",
      "one_line_profile": "Accurate post-training quantization for diffusion models",
      "detailed_description": "Implementation of APQ-DM, a method for accurate post-training quantization of diffusion models, preserving generation quality.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChangyuanWang17/APQ-DM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-models",
        "quantization",
        "ptq"
      ],
      "id": 673
    },
    {
      "name": "vllm-cli",
      "one_line_profile": "CLI tool for serving LLMs with vLLM",
      "detailed_description": "A command-line interface wrapper for vLLM, simplifying the deployment and serving of Large Language Models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_serving",
        "deployment"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/Chen-zexi/vllm-cli",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vllm",
        "cli",
        "serving",
        "llm"
      ],
      "id": 674
    },
    {
      "name": "ncnnqat",
      "one_line_profile": "Quantization-aware training package for NCNN on PyTorch",
      "detailed_description": "A Python package designed to facilitate quantization-aware training (QAT) for models intended to be deployed with the NCNN inference framework, helping to maintain accuracy while optimizing for edge devices.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ChenShisen/ncnnqat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ncnn",
        "quantization-aware-training",
        "pytorch"
      ],
      "id": 675
    },
    {
      "name": "llm-rk3588",
      "one_line_profile": "GPU-accelerated LLM inference on Rockchip RK3588",
      "detailed_description": "A deployment tool enabling the execution of Large Language Models on Rockchip RK3588 hardware with GPU acceleration, optimizing inference for edge computing scenarios.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "edge_computing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/Chrisz236/llm-rk3588",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rk3588",
        "llm",
        "edge-inference"
      ],
      "id": 676
    },
    {
      "name": "BiSeNet",
      "one_line_profile": "Implementation of BiSeNet V1 and V2 for real-time semantic segmentation",
      "detailed_description": "A PyTorch implementation of the BiSeNet (Bilateral Segmentation Network) architecture, designed for efficient real-time semantic segmentation tasks in computer vision.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "image_segmentation",
        "model_implementation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CoinCheung/BiSeNet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "semantic-segmentation",
        "bisenet",
        "computer-vision"
      ],
      "id": 677
    },
    {
      "name": "gdGPT",
      "one_line_profile": "Accelerated LLM training using DeepSpeed pipeline mode",
      "detailed_description": "A training framework for Large Language Models (Bloom, Llama, Baichuan, ChatGLM) utilizing DeepSpeed's pipeline parallelism to achieve faster training speeds compared to standard Zero/FSDP methods.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "training_acceleration",
        "distributed_training"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/CoinCheung/gdGPT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-training",
        "deepspeed",
        "pipeline-parallelism"
      ],
      "id": 678
    },
    {
      "name": "MPP-LLaVA",
      "one_line_profile": "Multimodal Pipeline Parallel training for LLaVA-like models",
      "detailed_description": "A project enabling the training of large multimodal models (like Qwen-VL) on consumer-grade hardware (e.g., RTX3090/4090) using pipeline parallelism techniques.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "training_acceleration",
        "multimodal_learning"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Coobiw/MPP-LLaVA",
      "help_website": [],
      "license": null,
      "tags": [
        "mllm",
        "pipeline-parallelism",
        "consumer-gpu"
      ],
      "id": 679
    },
    {
      "name": "QuIP",
      "one_line_profile": "2-Bit Quantization of Large Language Models with guarantees",
      "detailed_description": "Implementation of the QuIP algorithm for extreme quantization (2-bit) of Large Language Models, providing theoretical guarantees and practical code for model compression.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Cornell-RelaxML/QuIP",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-quantization",
        "2-bit",
        "model-compression"
      ],
      "id": 680
    },
    {
      "name": "dfq-toolkit",
      "one_line_profile": "Task-Specific Zero-shot Quantization-Aware Training toolkit",
      "detailed_description": "A toolkit for performing zero-shot quantization-aware training specifically optimized for object detection tasks, as presented at ICCV 2025.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "object_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DFQ-Dojo/dfq-toolkit",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "quantization-aware-training",
        "zero-shot",
        "object-detection"
      ],
      "id": 681
    },
    {
      "name": "BerryNet",
      "one_line_profile": "Deep learning gateway for Raspberry Pi and edge devices",
      "detailed_description": "An open-source deep learning gateway designed to turn edge devices like Raspberry Pi into intelligent AI nodes, managing inference tasks and data flow.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "edge_inference",
        "iot_gateway"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/DT42/BerryNet",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "edge-ai",
        "raspberry-pi",
        "inference-gateway"
      ],
      "id": 682
    },
    {
      "name": "Audio-Denoiser-ONNX",
      "one_line_profile": "Audio denoising using ONNX Runtime",
      "detailed_description": "A tool leveraging ONNX Runtime to perform efficient audio denoising, suitable for cleaning up audio data in scientific or media processing pipelines.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "audio_processing",
        "denoising"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DakeQQ/Audio-Denoiser-ONNX",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "audio-denoising",
        "onnx",
        "signal-processing"
      ],
      "id": 683
    },
    {
      "name": "F5-TTS-ONNX",
      "one_line_profile": "F5-TTS implementation using ONNX Runtime",
      "detailed_description": "A runtime implementation for the F5 Text-to-Speech model using ONNX, enabling efficient speech synthesis inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "speech_synthesis",
        "inference_acceleration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DakeQQ/F5-TTS-ONNX",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tts",
        "onnx",
        "inference"
      ],
      "id": 684
    },
    {
      "name": "HiPrune",
      "one_line_profile": "Training-free visual token pruning for VLM acceleration",
      "detailed_description": "Implementation of a method for pruning visual tokens in Vision-Language Models (VLMs) without retraining, aiming to accelerate inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_pruning",
        "vlm_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Danielement321/HiPrune",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pruning",
        "vlm",
        "acceleration"
      ],
      "id": 685
    },
    {
      "name": "CVFusion",
      "one_line_profile": "Deep learning compiler to fuse OpenCV operators",
      "detailed_description": "An open-source deep learning compiler designed to optimize computer vision pipelines by fusing OpenCV operators, improving execution efficiency.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "operator_fusion"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/DeepLink-org/CVFusion",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compiler",
        "opencv",
        "optimization"
      ],
      "id": 686
    },
    {
      "name": "jaxDecomp",
      "one_line_profile": "JAX bindings for NVIDIA cuDecomp library",
      "detailed_description": "Provides JAX bindings for the NVIDIA cuDecomp library, enabling efficient domain decomposition for high-performance scientific computing and simulations on GPUs.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "hpc",
        "domain_decomposition"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/DifferentiableUniverseInitiative/jaxDecomp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "jax",
        "hpc",
        "cudecomp"
      ],
      "id": 687
    },
    {
      "name": "keras_compressor",
      "one_line_profile": "Model Compression CLI Tool for Keras",
      "detailed_description": "A command-line interface tool for compressing Keras models, facilitating optimization for deployment.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/DwangoMediaVillage/keras_compressor",
      "help_website": [],
      "license": null,
      "tags": [
        "keras",
        "compression",
        "cli"
      ],
      "id": 688
    },
    {
      "name": "EduChat",
      "one_line_profile": "Open-source educational chat model",
      "detailed_description": "A large language model specifically tuned for educational contexts, including tools for data cleaning and GPU deployment.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "llm",
        "education_domain"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ECNU-ICALK/EduChat",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "education",
        "deployment"
      ],
      "id": 689
    },
    {
      "name": "kernl",
      "one_line_profile": "Accelerated PyTorch transformer inference on GPU",
      "detailed_description": "A library that optimizes PyTorch transformer models for faster GPU inference using custom kernels, designed to be easily integrated and modified.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "kernel_optimization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ELS-RD/kernl",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pytorch",
        "transformer",
        "gpu-acceleration"
      ],
      "id": 690
    },
    {
      "name": "evogp",
      "one_line_profile": "GPU-accelerated library for Tree-based Genetic Programming",
      "detailed_description": "A library leveraging PyTorch and CUDA for high-performance evolutionary computation, specifically tree-based genetic programming for symbolic regression and classification.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "genetic_programming",
        "symbolic_regression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/EMI-Group/evogp",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "genetic-programming",
        "gpu",
        "symbolic-regression"
      ],
      "id": 691
    },
    {
      "name": "Stable-Diffusion-NCNN",
      "one_line_profile": "Stable Diffusion implementation in NCNN with C++",
      "detailed_description": "A C++ implementation of Stable Diffusion using the NCNN framework, enabling image generation on edge devices and mobile platforms.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "generative_ai",
        "edge_inference"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/EdVince/Stable-Diffusion-NCNN",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "stable-diffusion",
        "ncnn",
        "edge-ai"
      ],
      "id": 692
    },
    {
      "name": "mera",
      "one_line_profile": "Heterogeneous Platform Deep Learning Compiler Framework",
      "detailed_description": "A compiler framework from EdgeCortix designed to optimize deep learning models for heterogeneous computing platforms.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "heterogeneous_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Edgecortix-Inc/mera",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compiler",
        "edge-ai",
        "optimization"
      ],
      "id": 693
    },
    {
      "name": "Einsums",
      "one_line_profile": "Compile-time tensor contraction analysis and optimization",
      "detailed_description": "A C++ library that performs compile-time analysis of tensor contraction patterns to determine and execute optimal tensor operations.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "tensor_computation",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/Einsums/Einsums",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tensor",
        "c++",
        "optimization"
      ],
      "id": 694
    },
    {
      "name": "gpt-neox",
      "one_line_profile": "Model parallel autoregressive transformer implementation on GPUs",
      "detailed_description": "A library for training large-scale language models on GPUs using model parallelism, built on top of Megatron-LM and DeepSpeed.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "llm_training",
        "distributed_computing"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/EleutherAI/gpt-neox",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "distributed-training",
        "gpu"
      ],
      "id": 695
    },
    {
      "name": "Reactant.jl",
      "one_line_profile": "Optimize Julia functions with MLIR and XLA",
      "detailed_description": "A tool to optimize Julia code execution on high-performance hardware (CPU, GPU, TPU) by leveraging MLIR and XLA compilation stacks.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "hpc"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/EnzymeAD/Reactant.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "xla",
        "mlir"
      ],
      "id": 696
    },
    {
      "name": "candle-vllm",
      "one_line_profile": "Efficient inference and serving platform for local LLMs",
      "detailed_description": "A Rust-based platform for efficient inference and serving of Large Language Models, compatible with OpenAI API standards.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_serving",
        "llm"
      ],
      "application_level": "service",
      "primary_language": "Rust",
      "repo_url": "https://github.com/EricLBuehler/candle-vllm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm-serving",
        "rust",
        "inference"
      ],
      "id": 697
    },
    {
      "name": "FaceONNX",
      "one_line_profile": "Face recognition library based on ONNX Runtime",
      "detailed_description": "A C# library for face recognition and analytics utilizing deep neural networks and the ONNX Runtime for inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "face_recognition",
        "biometrics"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/FaceONNX/FaceONNX",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "face-recognition",
        "onnx",
        "c#"
      ],
      "id": 698
    },
    {
      "name": "fasterai",
      "one_line_profile": "Model pruning and distillation library for FastAI/PyTorch",
      "detailed_description": "A library designed to facilitate neural network compression techniques such as pruning and knowledge distillation within the FastAI and PyTorch ecosystems.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "pruning"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/FasterAI-Labs/fasterai",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pruning",
        "distillation",
        "fastai"
      ],
      "id": 699
    },
    {
      "name": "TensorRT-Alpha",
      "one_line_profile": "TensorRT implementations for YOLO series and other models",
      "detailed_description": "A comprehensive collection of TensorRT implementations for accelerating various YOLO models (v5-v8) and other architectures on NVIDIA GPUs.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "tensorrt"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/FeiYull/TensorRT-Alpha",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "tensorrt",
        "yolo",
        "inference"
      ],
      "id": 700
    },
    {
      "name": "QDLM",
      "one_line_profile": "Post-training quantization for Diffusion LLMs",
      "detailed_description": "A tool for applying post-training quantization techniques specifically to Diffusion Large Language Models (dLLMs) to improve efficiency.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "diffusion_models"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/FelixMessi/QDLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "quantization",
        "diffusion-llm",
        "ptq"
      ],
      "id": 701
    },
    {
      "name": "CMUNeXt",
      "one_line_profile": "Efficient Medical Image Segmentation Network",
      "detailed_description": "An efficient deep learning network architecture designed for medical image segmentation, featuring large kernels and skip fusion mechanisms.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "medical_image_segmentation",
        "model_architecture"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FengheTan9/CMUNeXt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "medical-imaging",
        "segmentation",
        "efficient-network"
      ],
      "id": 702
    },
    {
      "name": "RoboBrain",
      "one_line_profile": "Unified Brain Model for Robotic Manipulation",
      "detailed_description": "A unified foundation model for robotic manipulation tasks, bridging abstract reasoning with concrete control actions.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "robotics",
        "foundation_model"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/FlagOpen/RoboBrain",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "robotics",
        "manipulation",
        "foundation-model"
      ],
      "id": 703
    },
    {
      "name": "XLA.jl",
      "one_line_profile": "XLA compiler bindings for Julia",
      "detailed_description": "A package providing bindings to the XLA (Accelerated Linear Algebra) compiler for the Julia language, enabling hardware acceleration for machine learning workloads.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/FluxML/XLA.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "xla",
        "compiler"
      ],
      "id": 704
    },
    {
      "name": "compressonator",
      "one_line_profile": "Texture and 3D Model Compression Tool Suite",
      "detailed_description": "A suite of tools for compressing, optimizing, and analyzing textures and 3D models, supporting various hardware accelerations (CPU, GPU, APU).",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "data_compression",
        "3d_visualization"
      ],
      "application_level": "workflow",
      "primary_language": "C++",
      "repo_url": "https://github.com/GPUOpen-Tools/compressonator",
      "help_website": [],
      "license": null,
      "tags": [
        "compression",
        "texture",
        "3d-model"
      ],
      "id": 705
    },
    {
      "name": "nano-vllm",
      "one_line_profile": "Lightweight implementation of vLLM",
      "detailed_description": "A simplified and lightweight version of the vLLM library, designed for efficient LLM inference with lower overhead.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "llm"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/GeeeekExplorer/nano-vllm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vllm",
        "inference",
        "lightweight"
      ],
      "id": 706
    },
    {
      "name": "FastMOT",
      "one_line_profile": "High-performance multiple object tracking",
      "detailed_description": "A high-performance multiple object tracking library integrating YOLO, Deep SORT, and KLT optical flow for efficient video analysis.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "object_tracking",
        "video_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/GeekAlexis/FastMOT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tracking",
        "yolo",
        "computer-vision"
      ],
      "id": 707
    },
    {
      "name": "Depths-CPP",
      "one_line_profile": "High-performance C++ depth estimation using ONNX Runtime",
      "detailed_description": "A C++ application and header library for real-time metric depth estimation using Depth-Anything-V2 models, optimized with ONNX Runtime and OpenCV.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "depth_estimation",
        "computer_vision"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/Geekgineer/Depths-CPP",
      "help_website": [],
      "license": null,
      "tags": [
        "depth-estimation",
        "onnx",
        "c++"
      ],
      "id": 708
    },
    {
      "name": "YOLOs-CPP",
      "one_line_profile": "High-performance C++ YOLO inference library",
      "detailed_description": "A C++ library for real-time object detection and segmentation using various YOLO models (v5-v12), leveraging ONNX Runtime for optimized CPU/GPU inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "object_detection",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/Geekgineer/YOLOs-CPP",
      "help_website": [],
      "license": null,
      "tags": [
        "yolo",
        "onnx",
        "c++"
      ],
      "id": 709
    },
    {
      "name": "PiSSA",
      "one_line_profile": "Parameter-efficient fine-tuning method for Large Language Models",
      "detailed_description": "A library implementing Principal Singular Values and Singular Vectors Adaptation (PiSSA) for efficient fine-tuning of LLMs, optimizing parameter adaptation compared to LoRA.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "model_adaptation",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/GraphPKU/PiSSA",
      "help_website": [],
      "license": null,
      "tags": [
        "peft",
        "llm-finetuning",
        "parameter-efficiency"
      ],
      "id": 710
    },
    {
      "name": "YOLOv5-Multibackbone-Compression",
      "one_line_profile": "Comprehensive compression toolbox for YOLOv5 models",
      "detailed_description": "A toolbox integrating multi-backbone support, pruning (EagleEye, Network Slimming), quantization (MQBench), and deployment (TensorRT, ncnn) for YOLOv5 series models.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "model_compression",
        "quantization",
        "pruning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/Gumpest/YOLOv5-Multibackbone-Compression",
      "help_website": [],
      "license": null,
      "tags": [
        "yolov5",
        "model-compression",
        "pruning",
        "quantization"
      ],
      "id": 711
    },
    {
      "name": "EasyCache",
      "one_line_profile": "Training-free acceleration for video diffusion models",
      "detailed_description": "A library for accelerating video diffusion models using runtime-adaptive caching mechanisms, enabling faster inference without retraining.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "inference_acceleration",
        "caching"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/H-EmbodVis/EasyCache",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-models",
        "video-generation",
        "acceleration"
      ],
      "id": 712
    },
    {
      "name": "TTC",
      "one_line_profile": "High-performance compiler for tensor transpositions",
      "detailed_description": "A specialized compiler designed to generate high-performance code for tensor transpositions, optimizing data layout transformations in scientific computing and deep learning.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "compilation",
        "tensor_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/HPAC/TTC",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "compiler",
        "tensor-transposition",
        "hpc"
      ],
      "id": 713
    },
    {
      "name": "tpc_llvm",
      "one_line_profile": "LLVM-based compiler for HabanaLabs TPC accelerators",
      "detailed_description": "The TPC-CLANG compiler based on LLVM, designed to compile TPC C programming language for HabanaLabs Deep-Learning Accelerators.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "compilation",
        "hardware_acceleration"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/HabanaAI/tpc_llvm",
      "help_website": [],
      "license": null,
      "tags": [
        "llvm",
        "compiler",
        "habana",
        "accelerator"
      ],
      "id": 714
    },
    {
      "name": "YOLO-Multi-Backbones-Attention",
      "one_line_profile": "Model compression toolkit for YOLOv3",
      "detailed_description": "A model compression toolkit for YOLOv3 incorporating lightweight backbones (ShuffleNet, GhostNet), attention mechanisms, pruning, and quantization.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "model_compression",
        "pruning",
        "quantization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/HaloTrouvaille/YOLO-Multi-Backbones-Attention",
      "help_website": [],
      "license": null,
      "tags": [
        "yolo",
        "model-compression",
        "pruning"
      ],
      "id": 715
    },
    {
      "name": "revlib",
      "one_line_profile": "Memory-efficient Reversible Network library for PyTorch",
      "detailed_description": "A library implementing Reversible Networks (RevNet) for PyTorch, supporting XLA and DeepSpeed to significantly reduce memory usage during training.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "training_optimization",
        "memory_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HomebrewML/revlib",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "memory-optimization",
        "reversible-networks",
        "pytorch"
      ],
      "id": 716
    },
    {
      "name": "transpeeder",
      "one_line_profile": "Tool for training Llama on single A100 using Pipeline Parallelism",
      "detailed_description": "A utility enabling the training of large language models (like Llama) on limited hardware (single A100 node) by leveraging DeepSpeed Pipeline Parallelism.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "distributed_training",
        "pipeline_parallelism"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/HuangLK/transpeeder",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-training",
        "deepspeed",
        "pipeline-parallelism"
      ],
      "id": 717
    },
    {
      "name": "tfbert",
      "one_line_profile": "TensorFlow 1.x based BERT pre-training framework",
      "detailed_description": "A pre-training framework for BERT models based on TensorFlow 1.x, supporting multi-GPU training, gradient accumulation, XLA acceleration, and mixed precision.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "model_training",
        "pretraining"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/HuiResearch/tfbert",
      "help_website": [],
      "license": null,
      "tags": [
        "bert",
        "pretraining",
        "tensorflow",
        "xla"
      ],
      "id": 718
    },
    {
      "name": "zDLC",
      "one_line_profile": "Deep Learning Compiler for IBM Z systems",
      "detailed_description": "A deep learning compiler specifically optimized for IBM Z mainframes, enabling efficient execution of neural networks on this architecture.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "compilation",
        "hardware_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/IBM/zDLC",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compiler",
        "ibm-z",
        "deep-learning"
      ],
      "id": 719
    },
    {
      "name": "OBC",
      "one_line_profile": "Optimal Brain Compression framework for quantization and pruning",
      "detailed_description": "A framework for accurate post-training quantization and pruning of neural networks, implementing the Optimal Brain Compression method.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "model_compression",
        "quantization",
        "pruning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IST-DASLab/OBC",
      "help_website": [],
      "license": null,
      "tags": [
        "quantization",
        "pruning",
        "model-compression"
      ],
      "id": 720
    },
    {
      "name": "GPTQ",
      "one_line_profile": "Accurate post-training quantization for GPT models",
      "detailed_description": "A widely used library for post-training quantization of generative pretrained transformers (GPT), enabling efficient inference on consumer hardware.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IST-DASLab/gptq",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "llm",
        "gpt",
        "inference-acceleration"
      ],
      "id": 721
    },
    {
      "name": "QMoE",
      "one_line_profile": "Sub-1-bit compression tool for Mixture-of-Experts models",
      "detailed_description": "A library for compressing trillion-parameter Mixture-of-Experts (MoE) models to sub-1-bit precision while maintaining accuracy.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IST-DASLab/qmoe",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "moe",
        "quantization",
        "model-compression"
      ],
      "id": 722
    },
    {
      "name": "InferenceMAX",
      "one_line_profile": "Continuous inference benchmarking tool for LLM hardware",
      "detailed_description": "A benchmarking tool for evaluating large language model inference performance across various hardware accelerators (NVIDIA, AMD, TPU).",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_analysis"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/InferenceMAX/InferenceMAX",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmarking",
        "llm-inference",
        "hardware-evaluation"
      ],
      "id": 723
    },
    {
      "name": "TriForce",
      "one_line_profile": "Lossless acceleration for long sequence generation",
      "detailed_description": "A system for accelerating long sequence generation in LLMs using Hierarchical Speculative Decoding, maintaining lossless quality.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "inference_acceleration",
        "speculative_decoding"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Infini-AI-Lab/TriForce",
      "help_website": [],
      "license": null,
      "tags": [
        "llm-acceleration",
        "speculative-decoding",
        "long-sequence"
      ],
      "id": 724
    },
    {
      "name": "NLP Architect",
      "one_line_profile": "Intel's library for NLP model optimization and exploration",
      "detailed_description": "A library by Intel Labs for exploring state-of-the-art deep learning topologies and optimization techniques specifically for Natural Language Processing.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "model_optimization",
        "nlp_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/IntelLabs/nlp-architect",
      "help_website": [
        "http://nlp_architect.nervanasys.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "optimization",
        "intel",
        "deep-learning"
      ],
      "id": 725
    },
    {
      "name": "LMDeploy",
      "one_line_profile": "Toolkit for compressing, deploying, and serving LLMs",
      "detailed_description": "A comprehensive toolkit for the efficient compression, deployment, and serving of Large Language Models, supporting high-throughput inference.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "model_deployment",
        "inference_serving",
        "compression"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/InternLM/lmdeploy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-serving",
        "deployment",
        "compression",
        "inference"
      ],
      "id": 726
    },
    {
      "name": "Neural-Net-LabView-DLL",
      "one_line_profile": "Deep Learning library for LabView integration",
      "detailed_description": "A C++-based library enabling the execution of feed-forward neural networks within the LabView environment, facilitating deep learning integration in experimental setups.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "inference_integration",
        "data_acquisition"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/JamesGlare/Neural-Net-LabView-DLL",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "labview",
        "neural-network",
        "integration",
        "experimental-physics"
      ],
      "id": 727
    },
    {
      "name": "Jittor",
      "one_line_profile": "High-performance JIT-based deep learning framework",
      "detailed_description": "A deep learning framework based on JIT compiling and meta-operators, designed for high performance and easy optimization.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "deep_learning_framework",
        "jit_compilation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/Jittor/jittor",
      "help_website": [
        "https://jittor.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "deep-learning-framework",
        "jit",
        "compiler"
      ],
      "id": 728
    },
    {
      "name": "Kernel Tuner",
      "one_line_profile": "Auto-tuning tool for GPU kernels",
      "detailed_description": "A tool for automatically tuning and optimizing CUDA, OpenCL, and C code kernels for GPUs, essential for high-performance scientific computing.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "kernel_tuning",
        "performance_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/KernelTuner/kernel_tuner",
      "help_website": [
        "http://kerneltuner.github.io/kernel_tuner/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "auto-tuning",
        "gpu",
        "cuda",
        "opencl"
      ],
      "id": 729
    },
    {
      "name": "fastT5",
      "one_line_profile": "Inference acceleration library for T5 models",
      "detailed_description": "A library to boost the inference speed of T5 models by converting them to ONNX Runtime and quantizing them, reducing model size and latency.",
      "domains": [
        "AI6-04",
        "AI6"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Ki6an/fastT5",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "t5",
        "onnx",
        "quantization",
        "inference"
      ],
      "id": 730
    },
    {
      "name": "LMCache",
      "one_line_profile": "High-performance KV cache storage backend for LLM inference acceleration",
      "detailed_description": "LMCache is a specialized cache layer designed to accelerate Large Language Model (LLM) inference by optimizing Key-Value (KV) cache management. It supports sharing KV caches across different inference engines and instances, significantly reducing latency and improving throughput for distributed LLM serving.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "memory_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/LMCache/LMCache",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "kv-cache",
        "inference-optimization"
      ],
      "id": 731
    },
    {
      "name": "ocaml-xla",
      "one_line_profile": "OCaml bindings for the XLA (Accelerated Linear Algebra) compiler",
      "detailed_description": "This library provides OCaml bindings for Google's XLA (Accelerated Linear Algebra) compiler, enabling OCaml developers to leverage high-performance machine learning compilation and hardware acceleration (GPU/TPU).",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler_binding",
        "model_compilation"
      ],
      "application_level": "library",
      "primary_language": "OCaml",
      "repo_url": "https://github.com/LaurentMazare/ocaml-xla",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "xla",
        "ocaml",
        "compiler",
        "acceleration"
      ],
      "id": 732
    },
    {
      "name": "ug",
      "one_line_profile": "Experimental deep learning compiler written in Rust",
      "detailed_description": "ug is an experimental compiler for deep learning models, written in Rust. It aims to provide a testbed for exploring compilation techniques and optimizations for neural network inference and training.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compilation"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/LaurentMazare/ug",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compiler",
        "rust",
        "deep-learning"
      ],
      "id": 733
    },
    {
      "name": "xla-rs",
      "one_line_profile": "Rust bindings for the XLA compiler",
      "detailed_description": "xla-rs provides Rust bindings for the XLA compiler, allowing Rust programs to construct and execute XLA computations for accelerated linear algebra and machine learning tasks.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler_binding",
        "model_compilation"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/LaurentMazare/xla-rs",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rust",
        "xla",
        "compiler"
      ],
      "id": 734
    },
    {
      "name": "AutoGPTQ.tvm",
      "one_line_profile": "TVM kernel implementation for GPTQ quantization inference",
      "detailed_description": "This project provides a TVM (Tensor Virtual Machine) kernel implementation for GPTQ (Generative Pre-trained Transformer Quantization), enabling efficient inference of quantized LLMs using the TVM compiler stack.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization_inference",
        "kernel_optimization"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/LeiWang1999/AutoGPTQ.tvm",
      "help_website": [],
      "license": null,
      "tags": [
        "tvm",
        "gptq",
        "quantization",
        "cuda"
      ],
      "id": 735
    },
    {
      "name": "FusedKernelLibrary",
      "one_line_profile": "Library for user-defined GPU kernel fusion",
      "detailed_description": "FusedKernelLibrary implements a methodology allowing users to define and execute fused GPU kernels without writing raw CUDA code, optimizing memory bandwidth and execution speed for custom operations.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "kernel_optimization",
        "gpu_acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/Libraries-Openly-Fused/FusedKernelLibrary",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kernel-fusion",
        "gpu",
        "cuda",
        "optimization"
      ],
      "id": 736
    },
    {
      "name": "lit-llama",
      "one_line_profile": "Optimized implementation of LLaMA for training and fine-tuning",
      "detailed_description": "lit-llama is a clean, optimized implementation of the LLaMA language model based on nanoGPT. It supports advanced features like Flash Attention, Int8/GPTQ quantization, LoRA, and LLaMA-Adapter for efficient pre-training and fine-tuning.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_training",
        "model_finetuning",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Lightning-AI/lit-llama",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llama",
        "finetuning",
        "quantization",
        "lora"
      ],
      "id": 737
    },
    {
      "name": "TensorRT-For-YOLO-Series",
      "one_line_profile": "TensorRT deployment toolkit for YOLO object detection models",
      "detailed_description": "A comprehensive toolkit for deploying various versions of YOLO (v5-v11, X) using NVIDIA TensorRT. It includes C++ and Python implementations for efficient inference acceleration and NMS plugin support.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "object_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Linaom1214/TensorRT-For-YOLO-Series",
      "help_website": [],
      "license": null,
      "tags": [
        "tensorrt",
        "yolo",
        "inference",
        "object-detection"
      ],
      "id": 738
    },
    {
      "name": "Lux.jl",
      "one_line_profile": "Explicit parameter deep learning framework for Julia",
      "detailed_description": "Lux.jl is a Julia deep learning framework that emphasizes explicit parameter handling and functional design, making it highly suitable for scientific machine learning (SciML) and integration with differential equation solvers.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "deep_learning_framework",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/LuxDL/Lux.jl",
      "help_website": [
        "https://lux.csail.mit.edu/"
      ],
      "license": "MIT",
      "tags": [
        "julia",
        "deep-learning",
        "sciml"
      ],
      "id": 739
    },
    {
      "name": "mpeg-pcc-tmc13",
      "one_line_profile": "Reference software for Geometry-based Point Cloud Compression (G-PCC)",
      "detailed_description": "The official reference software implementation for the MPEG Geometry-based Point Cloud Compression (G-PCC) standard, providing encoder and decoder tools for scientific and industrial point cloud data.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "data_compression",
        "point_cloud_processing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/MPEGGroup/mpeg-pcc-tmc13",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "point-cloud",
        "compression",
        "mpeg",
        "g-pcc"
      ],
      "id": 740
    },
    {
      "name": "mpeg-pcc-tmc2",
      "one_line_profile": "Reference software for Video-based Point Cloud Compression (V-PCC)",
      "detailed_description": "The official reference software implementation for the MPEG Video-based Point Cloud Compression (V-PCC) standard, enabling compression of dynamic point clouds by projecting them onto 2D video frames.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "data_compression",
        "point_cloud_processing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/MPEGGroup/mpeg-pcc-tmc2",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "point-cloud",
        "compression",
        "mpeg",
        "v-pcc"
      ],
      "id": 741
    },
    {
      "name": "NNPACK",
      "one_line_profile": "High-performance neural network inference acceleration package for multi-core CPUs",
      "detailed_description": "NNPACK is an acceleration package for neural network computations, optimized for multi-core CPUs. It provides high-performance implementations of convolution, pooling, and matrix multiplication operations.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "cpu_optimization"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/Maratyszcza/NNPACK",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "acceleration",
        "cpu",
        "neural-network",
        "optimization"
      ],
      "id": 742
    },
    {
      "name": "volksdep",
      "one_line_profile": "Toolbox for deploying and accelerating models with TensorRT",
      "detailed_description": "volksdep is an open-source toolbox designed to simplify the deployment and acceleration of PyTorch, ONNX, and TensorFlow models using TensorRT, providing a unified interface for inference optimization.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_deployment",
        "model_conversion"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Media-Smart/volksdep",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tensorrt",
        "deployment",
        "inference",
        "acceleration"
      ],
      "id": 743
    },
    {
      "name": "YOLOX",
      "one_line_profile": "High-performance anchor-free YOLO object detection library",
      "detailed_description": "YOLOX is a high-performance, anchor-free object detection model family. It supports multiple deployment backends including ONNX, TensorRT, ncnn, and OpenVINO, making it suitable for scientific image analysis and real-time detection tasks.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "object_detection",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Megvii-BaseDetection/YOLOX",
      "help_website": [
        "https://yolox.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "object-detection",
        "yolo",
        "computer-vision"
      ],
      "id": 744
    },
    {
      "name": "TensorFrost",
      "one_line_profile": "Static optimizing tensor compiler with Python frontend",
      "detailed_description": "TensorFrost is a static optimizing tensor compiler that provides a Python frontend and autodifferentiation capabilities. It aims to offer a shader-like syntax for high-performance tensor computations.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "tensor_compiler",
        "autodifferentiation"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/MichaelMoroz/TensorFrost",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "compiler",
        "tensor",
        "optimization"
      ],
      "id": 745
    },
    {
      "name": "modalities",
      "one_line_profile": "PyTorch-native framework for distributed foundation model training",
      "detailed_description": "Modalities is a framework designed for the distributed and reproducible training of foundation models. It leverages PyTorch native components to provide a modular and scalable training infrastructure.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "model_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Modalities/modalities",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "distributed-training",
        "pytorch",
        "foundation-models"
      ],
      "id": 746
    },
    {
      "name": "GPTQModel",
      "one_line_profile": "LLM quantization toolkit with multi-backend hardware acceleration",
      "detailed_description": "GPTQModel is a toolkit for quantizing Large Language Models (LLMs) using GPTQ. It supports hardware acceleration for NVIDIA CUDA, AMD ROCm, Intel XPU, and CPUs, integrating with HF, vLLM, and SGLang.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_quantization",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ModelCloud/GPTQModel",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "quantization",
        "gptq",
        "llm",
        "acceleration"
      ],
      "id": 747
    },
    {
      "name": "EasyLLM",
      "one_line_profile": "Usability-focused LLM training framework based on Megatron-Deepspeed",
      "detailed_description": "EasyLLM is a training framework built upon Megatron-Deepspeed and HuggingFace Trainer. It simplifies the complexity of distributed training for Large Language Models while maintaining high efficiency.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_training",
        "distributed_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/ModelTC/EasyLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "training",
        "megatron-deepspeed"
      ],
      "id": 748
    },
    {
      "name": "LightCompress",
      "one_line_profile": "Toolkit for compressing large language and vision models",
      "detailed_description": "LightCompress is a toolkit dedicated to the compression of large models, including LLMs, VLMs, and video generation models. It implements techniques to reduce model size and improve inference efficiency.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ModelTC/LightCompress",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compression",
        "llm",
        "vlm"
      ],
      "id": 749
    },
    {
      "name": "MQBench",
      "one_line_profile": "Benchmark framework for model quantization algorithms",
      "detailed_description": "MQBench is a comprehensive benchmark framework for evaluating model quantization techniques. It allows researchers to assess the performance and accuracy of different quantization algorithms on various models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization_benchmark",
        "model_evaluation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/ModelTC/MQBench",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "benchmark",
        "deep-learning"
      ],
      "id": 750
    },
    {
      "name": "LARS-ImageNet-PyTorch",
      "one_line_profile": "LARS optimizer implementation for large batch training",
      "detailed_description": "This repository provides a PyTorch implementation of the LARS (Layer-wise Adaptive Rate Scaling) optimizer, designed for large batch training of deep learning models (e.g., ResNet on ImageNet) in distributed environments.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "optimization_algorithm",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NUS-HPC-AI-Lab/LARS-ImageNet-PyTorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "optimizer",
        "lars",
        "distributed-training"
      ],
      "id": 751
    },
    {
      "name": "torch2trt",
      "one_line_profile": "Easy-to-use PyTorch to TensorRT converter",
      "detailed_description": "torch2trt is a Python library that simplifies the conversion of PyTorch models to NVIDIA TensorRT engines, enabling easy acceleration of inference on NVIDIA GPUs.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_conversion",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA-AI-IOT/torch2trt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "tensorrt",
        "converter"
      ],
      "id": 752
    },
    {
      "name": "trt_pose",
      "one_line_profile": "Real-time pose estimation accelerated with TensorRT",
      "detailed_description": "trt_pose provides tools for training and deploying real-time human pose estimation models accelerated by NVIDIA TensorRT, suitable for computer vision and behavioral analysis tasks.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "pose_estimation",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA-AI-IOT/trt_pose",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pose-estimation",
        "tensorrt",
        "computer-vision"
      ],
      "id": 753
    },
    {
      "name": "isaac_ros_object_detection",
      "one_line_profile": "NVIDIA-accelerated object detection package for ROS",
      "detailed_description": "This package provides NVIDIA-accelerated deep learning model support for object detection within the ROS (Robot Operating System) ecosystem, enabling high-performance vision for robotics applications.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "object_detection",
        "robotics_inference"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_object_detection",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ros",
        "object-detection",
        "isaac",
        "robotics"
      ],
      "id": 754
    },
    {
      "name": "Model-Optimizer",
      "one_line_profile": "Unified library for SOTA model optimization techniques",
      "detailed_description": "NVIDIA Model-Optimizer is a library containing state-of-the-art techniques for model optimization, including quantization, pruning, distillation, and speculative decoding, to compress models for efficient deployment.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_optimization",
        "quantization",
        "pruning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/Model-Optimizer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "optimization",
        "quantization",
        "pruning",
        "distillation"
      ],
      "id": 755
    },
    {
      "name": "Stable-Diffusion-WebUI-TensorRT",
      "one_line_profile": "TensorRT acceleration extension for Stable Diffusion Web UI",
      "detailed_description": "This extension integrates NVIDIA TensorRT into the Stable Diffusion Web UI, providing significant inference speedups for generative AI image synthesis tasks.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "image_synthesis"
      ],
      "application_level": "plugin",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/Stable-Diffusion-WebUI-TensorRT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "stable-diffusion",
        "tensorrt",
        "acceleration",
        "generative-ai"
      ],
      "id": 756
    },
    {
      "name": "TensorRT",
      "one_line_profile": "SDK for high-performance deep learning inference on NVIDIA GPUs",
      "detailed_description": "NVIDIA TensorRT is a high-performance deep learning inference SDK. It includes a deep learning inference optimizer and runtime that delivers low latency and high throughput for deep learning inference applications.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_optimization"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/NVIDIA/TensorRT",
      "help_website": [
        "https://developer.nvidia.com/tensorrt"
      ],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "gpu",
        "optimization",
        "sdk"
      ],
      "id": 757
    },
    {
      "name": "TensorRT-LLM",
      "one_line_profile": "Library for optimizing and executing Large Language Models on NVIDIA GPUs",
      "detailed_description": "TensorRT-LLM provides a comprehensive Python API and C++ runtime for defining, optimizing, and executing Large Language Models (LLMs) on NVIDIA GPUs, incorporating state-of-the-art techniques for efficient inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "llm_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/TensorRT-LLM",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "tensorrt",
        "inference",
        "gpu"
      ],
      "id": 758
    },
    {
      "name": "apex",
      "one_line_profile": "PyTorch extension for mixed precision and distributed training",
      "detailed_description": "A PyTorch extension that provides tools for easy mixed precision and distributed training, enabling faster training times and lower memory usage for deep learning models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "training_acceleration",
        "mixed_precision"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/apex",
      "help_website": [
        "https://nvidia.github.io/apex/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "pytorch",
        "mixed-precision",
        "distributed-training"
      ],
      "id": 759
    },
    {
      "name": "nvvl",
      "one_line_profile": "Hardware-accelerated video loading library for ML training",
      "detailed_description": "A library that leverages hardware acceleration to load sequences of video frames, facilitating efficient machine learning training by offloading video decoding to the GPU.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "data_loading",
        "video_processing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/NVIDIA/nvvl",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "video-loading",
        "gpu-acceleration",
        "machine-learning"
      ],
      "id": 760
    },
    {
      "name": "Fast-dLLM",
      "one_line_profile": "Training-free acceleration framework for Diffusion LLMs",
      "detailed_description": "An acceleration framework for Diffusion Language Models that enables KV Cache and Parallel Decoding without the need for retraining, improving inference speed.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "diffusion_models"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVlabs/Fast-dLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-llm",
        "acceleration",
        "kv-cache"
      ],
      "id": 761
    },
    {
      "name": "he-transformer",
      "one_line_profile": "Homomorphic Encryption backend for Intel nGraph",
      "detailed_description": "A tool enabling deep learning with Homomorphic Encryption (HE) through the Intel nGraph compiler, allowing computation on encrypted data.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "privacy_preserving_computation",
        "compiler_backend"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/NervanaSystems/he-transformer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "homomorphic-encryption",
        "ngraph",
        "privacy"
      ],
      "id": 762
    },
    {
      "name": "Tengine",
      "one_line_profile": "Lite, high-performance modular inference engine for embedded devices",
      "detailed_description": "A modular and high-performance inference engine designed for embedded devices, supporting various AI models and hardware backends.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_engine",
        "embedded_ai"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/OAID/Tengine",
      "help_website": [
        "http://tengine.openailab.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "inference-engine",
        "embedded",
        "edge-ai"
      ],
      "id": 763
    },
    {
      "name": "GRAT",
      "one_line_profile": "Training-free acceleration for Diffusion Transformers",
      "detailed_description": "A tool implementing 'Grouping First, Attending Smartly' to accelerate Diffusion Transformers without retraining, optimizing the attention mechanism.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "diffusion_transformers"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OliverRensu/GRAT",
      "help_website": [],
      "license": null,
      "tags": [
        "acceleration",
        "diffusion-models",
        "transformer"
      ],
      "id": 764
    },
    {
      "name": "BMCook",
      "one_line_profile": "Model compression toolkit for large language models",
      "detailed_description": "A toolkit designed for compressing big models through techniques like quantization, pruning, and distillation to reduce resource consumption.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenBMB/BMCook",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "model-compression",
        "llm",
        "quantization"
      ],
      "id": 765
    },
    {
      "name": "UltraRAG",
      "one_line_profile": "Low-code framework for building RAG pipelines",
      "detailed_description": "A framework for constructing complex Retrieval-Augmented Generation (RAG) pipelines, facilitating the integration of external knowledge into LLMs.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "rag_pipeline",
        "knowledge_retrieval"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenBMB/UltraRAG",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rag",
        "llm",
        "pipeline"
      ],
      "id": 766
    },
    {
      "name": "llm-inference",
      "one_line_profile": "Platform for managing and deploying LLM inference",
      "detailed_description": "A platform providing out-of-the-box features for LLM model deployment, auto-scaling, and computing resource management.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_serving",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenCSGs/llm-inference",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-serving",
        "inference",
        "deployment"
      ],
      "id": 767
    },
    {
      "name": "EfficientQAT",
      "one_line_profile": "Efficient Quantization-Aware Training for LLMs",
      "detailed_description": "A tool for performing efficient Quantization-Aware Training (QAT) on Large Language Models, enabling high-performance low-bit inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/EfficientQAT",
      "help_website": [],
      "license": null,
      "tags": [
        "qat",
        "quantization",
        "llm"
      ],
      "id": 768
    },
    {
      "name": "VideoChat-Flash",
      "one_line_profile": "Hierarchical compression tool for long-context video modeling",
      "detailed_description": "A tool implementing hierarchical compression techniques to enable efficient modeling of long-context videos.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "video_modeling",
        "data_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenGVLab/VideoChat-Flash",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "video-understanding",
        "compression",
        "long-context"
      ],
      "id": 769
    },
    {
      "name": "CoLLiE",
      "one_line_profile": "Framework for collaborative training of Large Language Models",
      "detailed_description": "A library designed to facilitate efficient and collaborative training of Large Language Models, optimizing resource usage and training speed.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "llm_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/OpenMOSS/CoLLiE",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "distributed-training",
        "optimization"
      ],
      "id": 770
    },
    {
      "name": "CTranslate2",
      "one_line_profile": "Fast inference engine for Transformer models",
      "detailed_description": "A C++ and Python library for efficient inference with Transformer models, supporting weights quantization and hardware acceleration.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_engine",
        "transformer_acceleration"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/OpenNMT/CTranslate2",
      "help_website": [
        "https://opennmt.net/CTranslate2/"
      ],
      "license": "MIT",
      "tags": [
        "inference",
        "transformer",
        "quantization"
      ],
      "id": 771
    },
    {
      "name": "simple-onnx-processing-tools",
      "one_line_profile": "Tools for ONNX model manipulation and optimization",
      "detailed_description": "A collection of utilities for splitting, merging, compressing, and modifying ONNX models to facilitate deployment and inference optimization.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_optimization",
        "onnx_manipulation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PINTO0309/simple-onnx-processing-tools",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "onnx",
        "model-optimization",
        "tools"
      ],
      "id": 772
    },
    {
      "name": "tflite2tensorflow",
      "one_line_profile": "Model converter for TFLite to various formats",
      "detailed_description": "A tool to generate saved_model, ONNX, OpenVINO, and other formats from .tflite files, supporting quantization and inverse quantization.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_conversion",
        "interoperability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PINTO0309/tflite2tensorflow",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "model-conversion",
        "tflite",
        "onnx"
      ],
      "id": 773
    },
    {
      "name": "safe-rlhf",
      "one_line_profile": "Framework for constrained value alignment via Safe RLHF",
      "detailed_description": "A framework implementing Safe Reinforcement Learning from Human Feedback to ensure AI model alignment with safety constraints.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "safety_alignment",
        "rlhf"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/PKU-Alignment/safe-rlhf",
      "help_website": [
        "https://safe-rlhf.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "safety",
        "alignment",
        "rlhf"
      ],
      "id": 774
    },
    {
      "name": "LLM-boost-recognition",
      "one_line_profile": "OCR and Voice Recognition module with LLM correction",
      "detailed_description": "A module for converting documents and audio into text using OCR and voice recognition, enhanced by LLM-based correction and GPU acceleration.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "data_ingestion",
        "ocr",
        "speech_recognition"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PStarH/LLM-boost-recognition",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "ocr",
        "voice-recognition",
        "data-processing"
      ],
      "id": 775
    },
    {
      "name": "FastDeploy",
      "one_line_profile": "High-performance inference and deployment toolkit",
      "detailed_description": "A toolkit for the inference and deployment of Large Language Models (LLMs) and Vision-Language Models (VLMs), supporting multiple backends and hardware.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_deployment",
        "model_serving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PaddlePaddle/FastDeploy",
      "help_website": [
        "https://github.com/PaddlePaddle/FastDeploy"
      ],
      "license": "Apache-2.0",
      "tags": [
        "deployment",
        "inference",
        "paddlepaddle"
      ],
      "id": 776
    },
    {
      "name": "PARL",
      "one_line_profile": "High-performance distributed reinforcement learning framework",
      "detailed_description": "A flexible and high-performance framework for distributed Reinforcement Learning, built on PaddlePaddle.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "distributed_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/PaddlePaddle/PARL",
      "help_website": [
        "https://parl.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "reinforcement-learning",
        "distributed-system",
        "paddlepaddle"
      ],
      "id": 777
    },
    {
      "name": "PaddleNLP",
      "one_line_profile": "NLP library for LLMs and SLMs",
      "detailed_description": "A comprehensive Natural Language Processing library providing easy-to-use interfaces for Large Language Models and Small Language Models.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "nlp_modeling",
        "text_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PaddlePaddle/PaddleNLP",
      "help_website": [
        "https://paddlenlp.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "llm",
        "paddlepaddle"
      ],
      "id": 778
    },
    {
      "name": "PaddleSlim",
      "one_line_profile": "Deep model compression and architecture search library",
      "detailed_description": "A library for deep learning model compression, including quantization, pruning, distillation, and neural architecture search.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "nas"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/PaddlePaddle/PaddleSlim",
      "help_website": [
        "https://paddleslim.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "compression",
        "quantization",
        "pruning"
      ],
      "id": 779
    },
    {
      "name": "PERSIA",
      "one_line_profile": "Distributed framework for training recommendation models",
      "detailed_description": "A high-performance distributed training framework specifically optimized for deep learning recommendation models, based on PyTorch.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "recommendation_systems",
        "distributed_training"
      ],
      "application_level": "framework",
      "primary_language": "Rust",
      "repo_url": "https://github.com/PersiaML/PERSIA",
      "help_website": [
        "https://persiaml-tutorials.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "recommendation",
        "distributed-training",
        "pytorch"
      ],
      "id": 780
    },
    {
      "name": "NeuralSolvers",
      "one_line_profile": "Neural network based solvers for PDEs",
      "detailed_description": "A library implementing physics-informed neural networks (PINNs) and other neural solvers for partial differential equations and inverse problems.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "pde_solver",
        "scientific_modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Photon-AI-Research/NeuralSolvers",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pinn",
        "pde",
        "scientific-computing"
      ],
      "id": 781
    },
    {
      "name": "OpenDiloco",
      "one_line_profile": "Framework for globally distributed low-communication training",
      "detailed_description": "An open-source framework enabling efficient, globally distributed training of AI models with low communication overhead.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "communication_optimization"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/PrimeIntellect-ai/OpenDiloco",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "decentralized-ai",
        "optimization"
      ],
      "id": 782
    },
    {
      "name": "prime-diloco",
      "one_line_profile": "Framework for globally distributed AI model training",
      "detailed_description": "A framework designed for efficient training of AI models across globally distributed compute resources over the internet.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "decentralized_computing"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/PrimeIntellect-ai/prime-diloco",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "infrastructure",
        "ai"
      ],
      "id": 783
    },
    {
      "name": "tensornet",
      "one_line_profile": "Distributed training framework for sparse data",
      "detailed_description": "A TensorFlow-based distributed training framework optimized for large-scale sparse data, often used in recommendation and search ranking.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "distributed_training",
        "sparse_data_processing"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/Qihoo360/tensornet",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "tensorflow",
        "sparse-data"
      ],
      "id": 784
    },
    {
      "name": "QizNLP",
      "one_line_profile": "Tensorflow-based NLP task framework",
      "detailed_description": "A framework for quickly running various NLP tasks such as classification, sequence labeling, and matching, with support for distributed training.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "nlp_workflow",
        "model_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Qznan/QizNLP",
      "help_website": [],
      "license": "MPL-2.0",
      "tags": [
        "nlp",
        "tensorflow",
        "distributed-training"
      ],
      "id": 785
    },
    {
      "name": "TritonForge",
      "one_line_profile": "LLM-powered GPU kernel synthesis tool",
      "detailed_description": "A tool that uses LLMs to synthesize optimized Triton kernels from PyTorch operations, facilitating custom operator acceleration.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "kernel_synthesis",
        "code_generation"
      ],
      "application_level": "tool",
      "primary_language": "Python",
      "repo_url": "https://github.com/RLsys-Foundation/TritonForge",
      "help_website": [],
      "license": null,
      "tags": [
        "triton",
        "gpu-kernel",
        "compiler"
      ],
      "id": 786
    },
    {
      "name": "rwkv.cpp",
      "one_line_profile": "CPU inference engine for RWKV models",
      "detailed_description": "A high-performance CPU inference implementation for RWKV language models, supporting various quantization formats (INT4/INT5/INT8).",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_engine",
        "cpu_acceleration"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/RWKV/rwkv.cpp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "inference",
        "rwkv",
        "quantization"
      ],
      "id": 787
    },
    {
      "name": "Model Compression Toolkit (MCT)",
      "one_line_profile": "Advanced quantization and compression tools for neural network optimization on constrained hardware",
      "detailed_description": "An open-source project by Sony Semiconductor Solutions providing researchers and developers with tools for neural network model optimization, specifically focusing on quantization and compression to enable efficient deployment on hardware with constraints.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/SonySemiconductorSolutions/mct-model-optimization",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "model-compression",
        "neural-network",
        "optimization"
      ],
      "id": 788
    },
    {
      "name": "YOLO-ModelCompression",
      "one_line_profile": "Framework for YOLO model compression, multi-dataset training, and multi-backbone support",
      "detailed_description": "A comprehensive framework designed for compressing YOLO series models (v3/v4), supporting advanced features like multi-dataset training, pruning, and quantization to optimize models for deployment.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "training_optimization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/SpursLipu/YOLOv3v4-ModelCompression-MultidatasetTraining-Multibackbone",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "yolo",
        "model-compression",
        "pruning",
        "quantization"
      ],
      "id": 789
    },
    {
      "name": "Mobile-YOLOv5-Pruning-Distillation",
      "one_line_profile": "Toolkit for pruning and distilling YOLOv5 models for efficient mobile deployment",
      "detailed_description": "A specialized toolkit for optimizing YOLOv5 models through pruning and knowledge distillation, specifically targeting mobile deployment with support for NCNN and TensorRT export.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "pruning",
        "distillation"
      ],
      "application_level": "workflow",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Syencil/mobile-yolov5-pruning-distillation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "yolov5",
        "pruning",
        "knowledge-distillation",
        "ncnn",
        "tensorrt"
      ],
      "id": 790
    },
    {
      "name": "Oobleck",
      "one_line_profile": "Resilient distributed training framework for large models",
      "detailed_description": "A distributed training framework designed to be resilient to faults, enabling robust and efficient training of large language models by handling node failures and topology changes dynamically.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "distributed_training",
        "fault_tolerance"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/SymbioticLab/Oobleck",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "fault-tolerance",
        "llm",
        "hpc"
      ],
      "id": 791
    },
    {
      "name": "Torch-Model-Compression",
      "one_line_profile": "Automated toolset for analyzing and compressing PyTorch models",
      "detailed_description": "A toolset developed by THU-MIG for automated model structure analysis and modification, providing a library of compression algorithms to optimize PyTorch models for efficiency.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "model_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/THU-MIG/torch-model-compression",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "model-compression",
        "automation",
        "optimization"
      ],
      "id": 792
    },
    {
      "name": "lyraDiff",
      "one_line_profile": "Inference acceleration engine for Diffusion and DiT models",
      "detailed_description": "An out-of-the-box inference acceleration engine specifically optimized for Diffusion and Diffusion Transformer (DiT) models, aiming to speed up generative AI tasks.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "generative_ai"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/TMElyralab/lyraDiff",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-models",
        "inference-acceleration",
        "dit",
        "generative-ai"
      ],
      "id": 793
    },
    {
      "name": "AngelSlim",
      "one_line_profile": "Comprehensive model compression toolkit for enhanced usability and efficiency",
      "detailed_description": "A model compression toolkit from Tencent designed to improve the usability and efficiency of deploying AI models, offering a range of compression techniques.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "deployment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Tencent/AngelSlim",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "model-compression",
        "tencent",
        "optimization",
        "deployment"
      ],
      "id": 794
    },
    {
      "name": "PocketFlow",
      "one_line_profile": "Automatic Model Compression (AutoMC) framework",
      "detailed_description": "An open-source framework for Automatic Model Compression (AutoMC) developed by Tencent, enabling developers to create smaller and faster AI applications with minimal human effort.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "automl"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/Tencent/PocketFlow",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "automc",
        "model-compression",
        "automl",
        "optimization"
      ],
      "id": 795
    },
    {
      "name": "TNN",
      "one_line_profile": "High-performance deep learning inference framework for mobile and edge",
      "detailed_description": "A uniform deep learning inference framework developed by Tencent Youtu Lab, optimized for mobile, desktop, and server platforms, featuring high performance, cross-platform support, and model compression capabilities.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_engine",
        "edge_computing"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/Tencent/TNN",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "inference-framework",
        "mobile-ai",
        "edge-computing",
        "ncnn"
      ],
      "id": 796
    },
    {
      "name": "OnnxStack",
      "one_line_profile": ".NET library for running Stable Diffusion and AI models via ONNX Runtime",
      "detailed_description": "A library that enables the execution of Stable Diffusion and other deep learning models within the .NET ecosystem using ONNX Runtime, facilitating inference integration in Windows applications.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_runtime",
        "generative_ai"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/TensorStack-AI/OnnxStack",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "onnx",
        "stable-diffusion",
        "dotnet",
        "inference"
      ],
      "id": 797
    },
    {
      "name": "PyTorch-YOLOv4",
      "one_line_profile": "PyTorch implementation of YOLOv4 with ONNX and TensorRT support",
      "detailed_description": "A widely used PyTorch implementation of the YOLOv4 object detection model, including tools for training, inference, and conversion to ONNX and TensorRT for accelerated deployment.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "object_detection",
        "model_implementation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Tianxiaomo/pytorch-YOLOv4",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "yolov4",
        "pytorch",
        "tensorrt",
        "onnx",
        "object-detection"
      ],
      "id": 798
    },
    {
      "name": "Frame_Extractor",
      "one_line_profile": "Automated video scene detection and frame extraction tool for datasets",
      "detailed_description": "A utility tool that automatically detects scenes in videos and extracts the sharpest frames, optimized for preparing high-quality image datasets for training AI models (e.g., LoRA fine-tuning).",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "data_preparation",
        "dataset_creation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Tranchillo/Frame_Extractor",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "dataset-preparation",
        "video-processing",
        "frame-extraction",
        "lora"
      ],
      "id": 799
    },
    {
      "name": "AQLM",
      "one_line_profile": "Extreme compression of Large Language Models via Additive Quantization",
      "detailed_description": "AQLM (Additive Quantization for Language Models) is a library and method for extreme compression of LLMs, enabling efficient inference on consumer hardware while maintaining high accuracy.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Vahe1994/AQLM",
      "help_website": [
        "https://arxiv.org/pdf/2401.06118.pdf"
      ],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "llm",
        "compression",
        "inference-acceleration"
      ],
      "id": 800
    },
    {
      "name": "FasterCache",
      "one_line_profile": "Training-free acceleration for video diffusion models",
      "detailed_description": "FasterCache is a training-free acceleration tool for video diffusion models that utilizes caching mechanisms to speed up inference while maintaining high generation quality.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "generative_model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Vchitect/FasterCache",
      "help_website": [],
      "license": null,
      "tags": [
        "diffusion-models",
        "video-generation",
        "acceleration",
        "caching"
      ],
      "id": 801
    },
    {
      "name": "voltaML",
      "one_line_profile": "Lightweight library for accelerating ML/DL models on high-performance runtimes",
      "detailed_description": "VoltaML is a library designed to convert and run machine learning and deep learning models on high-performance inference runtimes such as TensorRT, TorchScript, ONNX, and TVM, optimizing them for speed.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_conversion"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/VoltaML/voltaML",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tensorrt",
        "onnx",
        "inference",
        "acceleration"
      ],
      "id": 802
    },
    {
      "name": "Fast3Dcache",
      "one_line_profile": "Training-free acceleration for 3D geometry synthesis",
      "detailed_description": "Fast3Dcache provides a training-free method to accelerate 3D geometry synthesis, optimizing the inference process for 3D generative models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "3d_synthesis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Westlake-AGI-Lab/Fast3Dcache",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "3d-generation",
        "acceleration",
        "geometry-synthesis"
      ],
      "id": 803
    },
    {
      "name": "Q-Diffusion",
      "one_line_profile": "Quantization framework for diffusion models",
      "detailed_description": "Q-Diffusion is a tool for quantizing diffusion models to reduce their memory footprint and accelerate inference without significant loss in generation quality.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Xiuyu-Li/q-diffusion",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "diffusion-models",
        "quantization",
        "compression"
      ],
      "id": 804
    },
    {
      "name": "native-sparse-attention-triton",
      "one_line_profile": "Efficient Triton implementation of Native Sparse Attention",
      "detailed_description": "This repository provides an optimized implementation of Native Sparse Attention using OpenAI Triton, serving as a kernel-level acceleration tool for transformer models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "kernel_optimization",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/XunhaoLai/native-sparse-attention-triton",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "triton",
        "sparse-attention",
        "cuda",
        "optimization"
      ],
      "id": 805
    },
    {
      "name": "DashGaussian",
      "one_line_profile": "Acceleration method for 3D Gaussian Splatting training",
      "detailed_description": "DashGaussian implements a powerful acceleration method for training 3D Gaussian Splatting (3DGS) models, significantly reducing training time for 3D scene reconstruction.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "training_acceleration",
        "3d_reconstruction"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/YouyuChen0207/DashGaussian",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "3d-gaussian-splatting",
        "acceleration",
        "rendering"
      ],
      "id": 806
    },
    {
      "name": "KVCache-Factory",
      "one_line_profile": "Unified KV Cache compression methods for auto-regressive models",
      "detailed_description": "KVCache-Factory is a unified framework providing various KV cache compression methods to accelerate inference and reduce memory usage for large language models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "memory_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zefan-Cai/KVCache-Factory",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kv-cache",
        "llm",
        "compression",
        "inference"
      ],
      "id": 807
    },
    {
      "name": "R-KV",
      "one_line_profile": "Redundancy-aware KV Cache compression for reasoning models",
      "detailed_description": "R-KV implements a redundancy-aware KV cache compression technique specifically designed for reasoning models, optimizing memory efficiency during long-context inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "memory_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/Zefan-Cai/R-KV",
      "help_website": [],
      "license": null,
      "tags": [
        "kv-cache",
        "llm",
        "reasoning",
        "compression"
      ],
      "id": 808
    },
    {
      "name": "deepC",
      "one_line_profile": "Vendor-independent TinyML deep learning compiler and inference framework",
      "detailed_description": "deepC is a deep learning compiler and inference framework designed for microcomputers and microcontrollers, enabling vendor-independent TinyML model deployment.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "inference_deployment"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/ai-techsystems/deepC",
      "help_website": [
        "https://deepc.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "tinyml",
        "compiler",
        "embedded-ai",
        "inference"
      ],
      "id": 809
    },
    {
      "name": "AidLearning-FrameWork",
      "one_line_profile": "AIoT development platform for Linux on Android",
      "detailed_description": "AidLearning is a mobile AI development platform that provides a Linux environment on Android with support for GUI, deep learning inference acceleration (CPU/GPU/NPU), and visual IDEs.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_platform",
        "edge_computing"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/aidlearning/AidLearning-FrameWork",
      "help_website": [
        "http://www.aidlearning.net"
      ],
      "license": "NOASSERTION",
      "tags": [
        "android",
        "linux",
        "aiot",
        "inference"
      ],
      "id": 810
    },
    {
      "name": "EasyParallelLibrary",
      "one_line_profile": "General and efficient deep learning framework for distributed model training",
      "detailed_description": "Easy Parallel Library (EPL) is a framework designed to simplify and accelerate distributed model training for deep learning, providing efficient parallelization strategies.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "parallel_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/alibaba/EasyParallelLibrary",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "parallelism",
        "deep-learning"
      ],
      "id": 811
    },
    {
      "name": "TePDist",
      "one_line_profile": "HLO-level automatic distributed system for DL models",
      "detailed_description": "TePDist (TEnsor Program DISTributed) is an automatic distributed system that operates at the HLO (High Level Optimizer) level to optimize deep learning models for distributed execution.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "compiler_optimization"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/alibaba/TePDist",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-systems",
        "compiler",
        "hlo",
        "deep-learning"
      ],
      "id": 812
    },
    {
      "name": "TinyNeuralNetwork",
      "one_line_profile": "Efficient deep learning model compression framework",
      "detailed_description": "TinyNeuralNetwork is a framework focused on deep learning model compression, offering tools for quantization, pruning, and optimization to enable efficient deployment on resource-constrained devices.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/alibaba/TinyNeuralNetwork",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "model-compression",
        "quantization",
        "tinyml",
        "optimization"
      ],
      "id": 813
    },
    {
      "name": "PainlessInferenceAcceleration",
      "one_line_profile": "Tool for simplified inference acceleration",
      "detailed_description": "PainlessInferenceAcceleration provides a streamlined workflow and tools to accelerate deep learning model inference with minimal user effort, supporting various backends.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/alipay/PainlessInferenceAcceleration",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "inference",
        "acceleration",
        "optimization"
      ],
      "id": 814
    },
    {
      "name": "cONNXr",
      "one_line_profile": "Pure C ONNX runtime for embedded devices",
      "detailed_description": "cONNXr is a lightweight, zero-dependency ONNX runtime written in pure C, specifically designed for running inference on embedded devices.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_runtime",
        "embedded_ai"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/alrevuelta/cONNXr",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "onnx",
        "embedded",
        "inference",
        "c"
      ],
      "id": 815
    },
    {
      "name": "GLake",
      "one_line_profile": "GPU memory management and IO transmission optimization",
      "detailed_description": "GLake is a system tool for optimizing GPU memory management and I/O transmission efficiency, aiming to improve the performance of large-scale model training and inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "memory_optimization",
        "io_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/antgroup/glake",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu-memory",
        "optimization",
        "io-acceleration"
      ],
      "id": 816
    },
    {
      "name": "nnieqat-pytorch",
      "one_line_profile": "Quantization aware training tool for NNIE on PyTorch",
      "detailed_description": "nnieqat-pytorch is a quantization-aware training (QAT) tool designed for the HiSilicon NNIE (Neural Network Inference Engine), enabling users to train models compatible with NNIE quantization requirements.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aovoc/nnieqat-pytorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "quantization",
        "nnie",
        "pytorch",
        "qat"
      ],
      "id": 817
    },
    {
      "name": "TVM",
      "one_line_profile": "Open deep learning compiler stack for cpu, gpu and specialized accelerators",
      "detailed_description": "Apache TVM is an open source machine learning compiler framework for CPUs, GPUs, and machine learning accelerators. It aims to enable machine learning engineers to optimize and run computations efficiently on any hardware backend.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "optimization",
        "inference_acceleration"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/apache/tvm",
      "help_website": [
        "https://tvm.apache.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "compiler",
        "deep-learning",
        "optimization",
        "inference"
      ],
      "id": 818
    },
    {
      "name": "flux-fp8-api",
      "one_line_profile": "Flux diffusion model implementation with quantized FP8 acceleration",
      "detailed_description": "A specialized implementation of the Flux diffusion model utilizing quantized FP8 matrix multiplication and half-precision accumulation to achieve acceleration on consumer devices.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "inference_acceleration",
        "image_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aredden/flux-fp8-api",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "fp8",
        "diffusion-model",
        "acceleration"
      ],
      "id": 819
    },
    {
      "name": "torch-bnb-fp4",
      "one_line_profile": "Accelerated 4-bit FP4 linear operations for PyTorch",
      "detailed_description": "A library providing faster PyTorch bitsandbytes 4-bit FP4 nn.Linear operations, enabling efficient low-bit quantization for neural networks.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aredden/torch-bnb-fp4",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "quantization",
        "fp4",
        "pytorch",
        "acceleration"
      ],
      "id": 820
    },
    {
      "name": "LLM-Inference-Bench",
      "one_line_profile": "Benchmark suite for Large Language Model inference performance",
      "detailed_description": "A benchmarking tool developed by Argonne National Laboratory to evaluate and analyze the inference performance of Large Language Models on various hardware configurations.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_analysis"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/argonne-lcf/LLM-Inference-Bench",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "benchmarking",
        "llm",
        "inference",
        "hpc"
      ],
      "id": 821
    },
    {
      "name": "DeepX",
      "one_line_profile": "Unified framework for large-scale auto-distributed training and inference",
      "detailed_description": "A large-scale auto-distributed training and inference unified framework featuring a memory-compute-control decoupled architecture and support for heterogeneous hardware.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "inference",
        "hpc"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/array2d/deepx",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "inference",
        "framework",
        "hpc"
      ],
      "id": 822
    },
    {
      "name": "Fine-Tune Codebase",
      "one_line_profile": "Tool for fine-tuning LLMs on codebases with LoRA and quantization support",
      "detailed_description": "A scalable and efficient tool designed for fine-tuning large language models on codebases, supporting LoRA, mixed precision training, and quantization.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_finetuning",
        "training"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/ayminovitch/fine-tune-codebase",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "finetuning",
        "llm",
        "lora",
        "quantization"
      ],
      "id": 823
    },
    {
      "name": "TokenSwift",
      "one_line_profile": "Lossless acceleration method for ultra-long sequence generation",
      "detailed_description": "Implementation of TokenSwift, a method for accelerating ultra-long sequence generation in large language models without loss of quality.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "sequence_generation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bigai-nlco/TokenSwift",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "acceleration",
        "llm",
        "inference",
        "long-sequence"
      ],
      "id": 824
    },
    {
      "name": "Megatron-DeepSpeed",
      "one_line_profile": "Large-scale distributed training framework for transformer models",
      "detailed_description": "A deep learning library that combines Megatron-LM and DeepSpeed to enable efficient large-scale distributed training of transformer language models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "hpc",
        "model_training"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/bigscience-workshop/Megatron-DeepSpeed",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "distributed-training",
        "transformer",
        "hpc",
        "deepspeed"
      ],
      "id": 825
    },
    {
      "name": "bitsandbytes",
      "one_line_profile": "Lightweight wrapper around CUDA custom functions, in particular 8-bit optimizers and quantization",
      "detailed_description": "A library that provides accessible large language models via k-bit quantization for PyTorch, including 8-bit optimizers and matrix multiplication routines.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "optimization",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bitsandbytes-foundation/bitsandbytes",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "quantization",
        "cuda",
        "optimization",
        "pytorch"
      ],
      "id": 826
    },
    {
      "name": "X-LLM",
      "one_line_profile": "Library for cutting-edge and easy LLM fine-tuning",
      "detailed_description": "A library designed to simplify and accelerate the fine-tuning process of Large Language Models (LLMs), providing cutting-edge techniques.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_finetuning",
        "training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/bobazooba/xllm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "finetuning",
        "llm",
        "training"
      ],
      "id": 827
    },
    {
      "name": "QuantVSR",
      "one_line_profile": "Low-bit post-training quantization for video super-resolution",
      "detailed_description": "PyTorch implementation of QuantVSR, a method for low-bit post-training quantization specifically designed for real-world video super-resolution tasks.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "super_resolution",
        "image_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/bowenchai/QuantVSR",
      "help_website": [],
      "license": null,
      "tags": [
        "quantization",
        "super-resolution",
        "video-processing"
      ],
      "id": 828
    },
    {
      "name": "fastai_xla_extensions",
      "one_line_profile": "Extensions to run fastai on TPUs using PyTorch-XLA",
      "detailed_description": "A Python package that enables the fastai library to utilize TPUs for accelerated training and inference via PyTorch-XLA.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "hardware_acceleration",
        "training",
        "tpu_support"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/butchland/fastai_xla_extensions",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "fastai",
        "tpu",
        "xla",
        "acceleration"
      ],
      "id": 829
    },
    {
      "name": "ABQ-LLM",
      "one_line_profile": "Acceleration library for arbitrary bit-width combinatorial quantization",
      "detailed_description": "An acceleration library that supports arbitrary bit-width combinatorial quantization operations for Large Language Models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/bytedance/ABQ-LLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "acceleration",
        "llm"
      ],
      "id": 830
    },
    {
      "name": "BytePS",
      "one_line_profile": "High performance and generic framework for distributed DNN training",
      "detailed_description": "A high-performance, generic framework for distributed Deep Neural Network (DNN) training, designed to run on heterogeneous hardware clusters.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "hpc"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/bytedance/byteps",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "distributed-training",
        "hpc",
        "deep-learning"
      ],
      "id": 831
    },
    {
      "name": "exprgrad",
      "one_line_profile": "Differentiable array programming language and DL framework for Nim",
      "detailed_description": "An experimental deep learning framework for the Nim programming language, based on a differentiable array programming approach.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "modeling",
        "training"
      ],
      "application_level": "framework",
      "primary_language": "Nim",
      "repo_url": "https://github.com/can-lehmann/exprgrad",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deep-learning",
        "nim",
        "differentiable-programming"
      ],
      "id": 832
    },
    {
      "name": "JEDI",
      "one_line_profile": "Jetson embedded platform deep learning inference acceleration framework",
      "detailed_description": "A deep learning inference acceleration framework specifically targeted for Jetson embedded platforms using TensorRT.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "embedded_ai"
      ],
      "application_level": "framework",
      "primary_language": "C++",
      "repo_url": "https://github.com/cap-lab/jedi",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "jetson",
        "tensorrt",
        "inference",
        "embedded"
      ],
      "id": 833
    },
    {
      "name": "NeuPIMs",
      "one_line_profile": "NPU-PIM heterogeneous acceleration simulator for batched LLM inferencing",
      "detailed_description": "A framework/simulator for NPU-PIM (Processing-in-Memory) heterogeneous acceleration, specifically optimized for batched Large Language Model inferencing.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "hardware_simulation"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/casys-kaist/NeuPIMs",
      "help_website": [],
      "license": null,
      "tags": [
        "pim",
        "acceleration",
        "llm",
        "simulation"
      ],
      "id": 834
    },
    {
      "name": "petit-kernel",
      "one_line_profile": "Optimized FP16/BF16 x FP4 GPU kernels for AMD GPUs",
      "detailed_description": "A library of optimized GPU kernels for AMD GPUs, supporting FP16/BF16 and FP4 precisions, useful for accelerating low-precision inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "kernel_optimization",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/causalflow-ai/petit-kernel",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "amd-gpu",
        "kernels",
        "quantization",
        "acceleration"
      ],
      "id": 835
    },
    {
      "name": "flex-nano-vllm",
      "one_line_profile": "Minimal FlexAttention-based inference engine for Gemma 2",
      "detailed_description": "A minimal, vLLM-style inference engine optimized for fast Gemma 2 inference using FlexAttention.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_engine",
        "acceleration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/changjonathanc/flex-nano-vllm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "inference",
        "vllm",
        "gemma",
        "acceleration"
      ],
      "id": 836
    },
    {
      "name": "llama-dfdx",
      "one_line_profile": "Rust implementation of LLaMa 7b with CUDA acceleration",
      "detailed_description": "A Rust implementation of the LLaMa 7b model featuring CUDA acceleration and optimized for minimal GPU memory usage.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference",
        "model_implementation"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/chelsea0x3b/llama-dfdx",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "rust",
        "llama",
        "cuda",
        "inference"
      ],
      "id": 837
    },
    {
      "name": "model_compression",
      "one_line_profile": "Model compression implementation using knowledge distillation",
      "detailed_description": "A repository implementing model compression techniques, specifically focusing on knowledge distillation methods.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "knowledge_distillation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/chengshengchan/model_compression",
      "help_website": [],
      "license": null,
      "tags": [
        "model-compression",
        "knowledge-distillation"
      ],
      "id": 838
    },
    {
      "name": "PTQ4SAM",
      "one_line_profile": "Post-Training Quantization for Segment Anything Model",
      "detailed_description": "Implementation of Post-Training Quantization (PTQ) specifically tailored for the Segment Anything Model (SAM), enabling efficient inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "inference_acceleration",
        "computer_vision"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/chengtao-lv/PTQ4SAM",
      "help_website": [],
      "license": null,
      "tags": [
        "quantization",
        "sam",
        "segmentation"
      ],
      "id": 839
    },
    {
      "name": "DDRNet.pytorch",
      "one_line_profile": "Deep Dual-resolution Networks for real-time semantic segmentation",
      "detailed_description": "Implementation of Deep Dual-resolution Networks (DDRNet) for real-time and accurate semantic segmentation of road scenes.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "image_segmentation",
        "model_implementation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chenjun2hao/DDRNet.pytorch",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "semantic-segmentation",
        "real-time",
        "computer-vision"
      ],
      "id": 840
    },
    {
      "name": "topicGPT",
      "one_line_profile": "Prompt-based framework for topic modeling",
      "detailed_description": "A framework utilizing Large Language Models (LLMs) and prompting techniques to perform topic modeling on text data.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "topic_modeling",
        "text_analysis"
      ],
      "application_level": "framework",
      "primary_language": "Python",
      "repo_url": "https://github.com/chtmp223/topicGPT",
      "help_website": [],
      "license": null,
      "tags": [
        "topic-modeling",
        "llm",
        "nlp"
      ],
      "id": 841
    },
    {
      "name": "EasyQuant",
      "one_line_profile": "Efficient post-training quantization method optimizing weights and activations",
      "detailed_description": "An efficient and simple post-training quantization (PTQ) tool that optimizes the scales of weights and activations to reduce quantization error. It is designed to facilitate the deployment of deep learning models on low-precision hardware.",
      "domains": [
        "AI6-04",
        "Computer Vision"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepglint/EasyQuant",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "quantization",
        "post-training-quantization",
        "cnn",
        "optimization"
      ],
      "id": 842
    },
    {
      "name": "DeepSpeed",
      "one_line_profile": "Deep learning optimization library for distributed training and inference",
      "detailed_description": "A deep learning optimization library that enables massive-scale distributed training and inference. It provides system innovations like ZeRO (Zero Redundancy Optimizer), 3D parallelism, and sparse attention to improve speed, memory efficiency, and scalability of large models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "inference_acceleration",
        "memory_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepspeedai/DeepSpeed",
      "help_website": [
        "https://www.deepspeed.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "optimization",
        "zero-redundancy-optimizer",
        "hpc"
      ],
      "id": 843
    },
    {
      "name": "DeepSpeed-MII",
      "one_line_profile": "High-throughput and low-latency inference library powered by DeepSpeed",
      "detailed_description": "DeepSpeed Model Implementations for Inference (MII) is a library designed to accelerate low-latency and high-throughput inference of large models. It leverages DeepSpeed's inference engine to provide optimized serving solutions.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_serving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/deepspeedai/DeepSpeed-MII",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "latency-optimization",
        "throughput",
        "serving"
      ],
      "id": 844
    },
    {
      "name": "tensorRTIntegrate",
      "one_line_profile": "C++ integration tool for TensorRT inference and ONNX plugin management",
      "detailed_description": "A C++ repository providing tools and examples for integrating TensorRT inference, managing ONNX plugins, and compiling models. It facilitates the deployment of deep learning models using NVIDIA's TensorRT engine.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "inference_deployment",
        "model_conversion"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/dlunion/tensorRTIntegrate",
      "help_website": [],
      "license": null,
      "tags": [
        "tensorrt",
        "onnx",
        "inference",
        "cpp"
      ],
      "id": 845
    },
    {
      "name": "nnvm-fusion",
      "one_line_profile": "Kernel fusion and runtime compilation module based on NNVM",
      "detailed_description": "A library implementing kernel fusion and runtime compilation techniques based on the NNVM (Neural Network Virtual Machine) intermediate representation. It aims to optimize deep learning graph execution.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "compiler_optimization",
        "kernel_fusion"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/dmlc/nnvm-fusion",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nnvm",
        "compiler",
        "optimization",
        "kernel-fusion"
      ],
      "id": 846
    },
    {
      "name": "Paracel",
      "one_line_profile": "Distributed training framework implementing the parameter server architecture",
      "detailed_description": "A distributed training framework designed to solve large-scale machine learning problems using the parameter server architecture. It supports various ML algorithms and provides a mechanism for efficient data and parameter synchronization.",
      "domains": [
        "AI6",
        "HPC"
      ],
      "subtask_category": [
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/douban/paracel",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "parameter-server",
        "distributed-systems",
        "machine-learning"
      ],
      "id": 847
    },
    {
      "name": "VisDrone-dataset-python-toolkit",
      "one_line_profile": "Toolkit for processing and using the VisDrone aerial object detection dataset",
      "detailed_description": "A Python toolkit designed to facilitate the use of the VisDrone dataset for aerial object detection. It includes pipelines for training, inference, and format conversion, supporting models like Faster R-CNN and RetinaNet.",
      "domains": [
        "Computer Vision",
        "Data Processing"
      ],
      "subtask_category": [
        "data_processing",
        "object_detection"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dronefreak/VisDrone-dataset-python-toolkit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "visdrone",
        "aerial-imagery",
        "dataset-tools",
        "pytorch"
      ],
      "id": 848
    },
    {
      "name": "gemlite",
      "one_line_profile": "Library for fast low-bit matrix multiplication kernels using Triton",
      "detailed_description": "A library providing optimized low-bit matrix multiplication (matmul) kernels implemented in Triton. It focuses on accelerating quantized neural network operations on GPUs.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "kernel_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dropbox/gemlite",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "triton",
        "matmul",
        "quantization",
        "gpu-acceleration"
      ],
      "id": 849
    },
    {
      "name": "XLand-MiniGrid",
      "one_line_profile": "JAX-accelerated meta-reinforcement learning environments",
      "detailed_description": "A library of JAX-accelerated reinforcement learning environments inspired by XLand and MiniGrid. It is designed for meta-reinforcement learning research, enabling fast and scalable simulation on hardware accelerators.",
      "domains": [
        "Reinforcement Learning",
        "AI6"
      ],
      "subtask_category": [
        "reinforcement_learning",
        "simulation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dunnolab/xland-minigrid",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jax",
        "reinforcement-learning",
        "environment",
        "simulation"
      ],
      "id": 850
    },
    {
      "name": "XLand-MiniGrid Datasets",
      "one_line_profile": "Large-scale multi-task dataset for in-context reinforcement learning",
      "detailed_description": "A large-scale dataset (XLand-100B) designed for multi-task and in-context reinforcement learning research, generated using the XLand-MiniGrid environments.",
      "domains": [
        "Reinforcement Learning"
      ],
      "subtask_category": [
        "reinforcement_learning"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/dunnolab/xland-minigrid-datasets",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "dataset",
        "reinforcement-learning",
        "jax"
      ],
      "id": 851
    },
    {
      "name": "NanoLLM",
      "one_line_profile": "Optimized local inference library for LLMs and multimodal models on NVIDIA Jetson/Edge",
      "detailed_description": "A lightweight and efficient library for running Large Language Models (LLMs), Vision-Language Models (VLMs), and multimodal agents locally on NVIDIA Jetson and edge devices. It supports quantization (AWQ, GPTQ), multimodal pipelines, and integrates with vector databases for RAG applications.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "quantization",
        "edge_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/dusty-nv/NanoLLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "edge-ai",
        "quantization",
        "nvidia-jetson"
      ],
      "id": 852
    },
    {
      "name": "jetson-inference",
      "one_line_profile": "High-performance deep learning inference library for NVIDIA Jetson devices",
      "detailed_description": "A C++ library and collection of utilities for deploying deep learning inference networks (image classification, detection, segmentation, pose estimation) on NVIDIA Jetson devices using TensorRT. It provides optimized primitives for vision tasks and streamlined deployment workflows.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "computer_vision",
        "edge_computing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/dusty-nv/jetson-inference",
      "help_website": [
        "https://github.com/dusty-nv/jetson-inference/blob/master/docs/html/index.md"
      ],
      "license": "MIT",
      "tags": [
        "tensorrt",
        "edge-ai",
        "inference",
        "computer-vision"
      ],
      "id": 853
    },
    {
      "name": "ros_deep_learning",
      "one_line_profile": "Deep learning inference nodes for ROS/ROS2 integration",
      "detailed_description": "Provides ROS and ROS2 nodes that wrap deep learning inference capabilities (using TensorRT and NVIDIA Jetson), enabling robotic systems to perform real-time object detection, classification, and segmentation within the ROS ecosystem.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "robotics_integration",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/dusty-nv/ros_deep_learning",
      "help_website": [],
      "license": null,
      "tags": [
        "ros",
        "ros2",
        "robotics",
        "tensorrt"
      ],
      "id": 854
    },
    {
      "name": "Q-LLM",
      "one_line_profile": "Query-aware inference acceleration library for Large Language Models",
      "detailed_description": "Implementation of the QuickLLaMA method, focusing on query-aware inference acceleration for LLMs. It provides techniques to optimize the inference process by leveraging query information to reduce computational redundancy.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dvlab-research/Q-LLM",
      "help_website": [],
      "license": null,
      "tags": [
        "llm",
        "inference",
        "acceleration"
      ],
      "id": 855
    },
    {
      "name": "mixtral-offloading",
      "one_line_profile": "Efficient offloading inference engine for Mixtral-8x7B models",
      "detailed_description": "A specialized inference tool enabling the execution of large Mixture-of-Experts (MoE) models like Mixtral-8x7B on consumer-grade hardware or limited memory environments (e.g., Colab) through efficient CPU/GPU offloading strategies.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "memory_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/dvmazur/mixtral-offloading",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "moe",
        "offloading",
        "inference",
        "mixtral"
      ],
      "id": 856
    },
    {
      "name": "Nx",
      "one_line_profile": "Numerical computing and tensor library for Elixir",
      "detailed_description": "A foundational library for numerical computing in Elixir, providing multi-dimensional arrays (tensors) and automatic differentiation. It serves as the core infrastructure for machine learning and scientific computing within the Elixir ecosystem.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "numerical_computing",
        "tensor_operations"
      ],
      "application_level": "library",
      "primary_language": "Elixir",
      "repo_url": "https://github.com/elixir-nx/nx",
      "help_website": [
        "https://hexdocs.pm/nx/Nx.html"
      ],
      "license": null,
      "tags": [
        "elixir",
        "tensors",
        "numerical-computing"
      ],
      "id": 857
    },
    {
      "name": "Ortex",
      "one_line_profile": "ONNX Runtime bindings for Elixir",
      "detailed_description": "Provides Elixir bindings for ONNX Runtime, enabling the execution of machine learning models trained in other frameworks (PyTorch, TensorFlow) within Elixir applications for high-performance inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_runtime",
        "interoperability"
      ],
      "application_level": "library",
      "primary_language": "Elixir",
      "repo_url": "https://github.com/elixir-nx/ortex",
      "help_website": [
        "https://hexdocs.pm/ortex"
      ],
      "license": "MIT",
      "tags": [
        "onnx",
        "elixir",
        "inference"
      ],
      "id": 858
    },
    {
      "name": "XLA (Elixir)",
      "one_line_profile": "XLA (Accelerated Linear Algebra) compiler extension for Elixir Nx",
      "detailed_description": "Integrates Google's XLA compiler with Elixir Nx, allowing tensor operations to be just-in-time compiled to optimized machine code for CPUs, GPUs, and TPUs, significantly accelerating numerical computations.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compilation",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "Elixir",
      "repo_url": "https://github.com/elixir-nx/xla",
      "help_website": [
        "https://hexdocs.pm/xla"
      ],
      "license": "Apache-2.0",
      "tags": [
        "xla",
        "compiler",
        "acceleration",
        "elixir"
      ],
      "id": 859
    },
    {
      "name": "tensorflow-serving-arm",
      "one_line_profile": "Cross-compilation toolkit for TensorFlow Serving on ARM architecture",
      "detailed_description": "A utility project providing scripts and configurations to cross-compile TensorFlow Serving for ARM-based devices (e.g., Raspberry Pi, edge devices), facilitating the deployment of ML models on edge infrastructure.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "deployment",
        "cross_compilation"
      ],
      "application_level": "utility",
      "primary_language": "C++",
      "repo_url": "https://github.com/emacski/tensorflow-serving-arm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tensorflow-serving",
        "arm",
        "cross-compile"
      ],
      "id": 860
    },
    {
      "name": "yolo-tensorrt",
      "one_line_profile": "TensorRT implementation and conversion tool for YOLO object detection models",
      "detailed_description": "A C++ library and toolset for converting and running YOLO series models (v3, v4, v5) using NVIDIA TensorRT. It optimizes inference speed for real-time object detection applications.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_conversion"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/enazoe/yolo-tensorrt",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tensorrt",
        "yolo",
        "inference",
        "acceleration"
      ],
      "id": 861
    },
    {
      "name": "imgcomp-cvpr",
      "one_line_profile": "Deep image compression model implementation based on Conditional Probability Models",
      "detailed_description": "A TensorFlow implementation of deep image compression techniques using conditional probability models. While a paper implementation, it serves as a baseline solver for image compression research and data processing.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "image_compression",
        "data_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/fab-jul/imgcomp-cvpr",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "image-compression",
        "deep-learning",
        "tensorflow"
      ],
      "id": 862
    },
    {
      "name": "FBTT-Embedding",
      "one_line_profile": "Tensor Train compression library for sparse embedding tables",
      "detailed_description": "A library for compressing sparse embedding tables in large-scale recommendation and NLP models using Tensor Train decomposition. It significantly reduces memory footprint and enables efficient runtime decompression.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "memory_optimization"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/facebookresearch/FBTT-Embedding",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "embedding-compression",
        "tensor-train",
        "dlrm"
      ],
      "id": 863
    },
    {
      "name": "LLM-QAT",
      "one_line_profile": "Data-Free Quantization Aware Training framework for LLMs",
      "detailed_description": "A research tool enabling Quantization Aware Training (QAT) for Large Language Models without requiring original training data (data-free). It facilitates the production of quantized models with preserved accuracy.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/LLM-QAT",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "qat",
        "quantization",
        "llm"
      ],
      "id": 864
    },
    {
      "name": "diffq",
      "one_line_profile": "Differentiable quantization library for model compression",
      "detailed_description": "A library for differentiable quantization using pseudo quantization noise. It allows automatic tuning of bit-width per weight or group to achieve optimal trade-offs between model size and accuracy.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/diffq",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "quantization",
        "differentiable-programming",
        "compression"
      ],
      "id": 865
    },
    {
      "name": "flashy",
      "one_line_profile": "Lightweight framework for deep learning training loops",
      "detailed_description": "A flexible framework for constructing deep learning training loops, handling checkpointing, logging, and distributed training (Dora compatibility), designed to streamline research experimentation.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "training_framework",
        "experiment_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/flashy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "training-loop",
        "distributed-training",
        "pytorch"
      ],
      "id": 866
    },
    {
      "name": "Felafax",
      "one_line_profile": "Infrastructure platform for AI workloads on non-NVIDIA GPUs",
      "detailed_description": "A platform and toolkit designed to facilitate the running and fine-tuning of AI models on diverse hardware backends, specifically targeting non-NVIDIA GPUs (e.g., AMD, TPUs) to democratize AI compute access.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "hardware_abstraction",
        "distributed_training"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/felafax/felafax",
      "help_website": [
        "https://felafax.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "amd-gpu",
        "tpu",
        "infrastructure",
        "fine-tuning"
      ],
      "id": 867
    },
    {
      "name": "fhelipe",
      "one_line_profile": "Tensor compiler for Fully Homomorphic Encryption (FHE)",
      "detailed_description": "A compiler designed to transform high-level tensor operations into Fully Homomorphic Encryption (FHE) compatible circuits, enabling privacy-preserving computation on encrypted data.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "compilation",
        "privacy_preserving_computing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/fhelipe-compiler/fhelipe",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "fhe",
        "compiler",
        "privacy",
        "tensor"
      ],
      "id": 868
    },
    {
      "name": "Finch.jl",
      "one_line_profile": "Sparse and structured tensor compiler for Julia",
      "detailed_description": "A compiler for sparse and structured tensor operations in Julia. It optimizes tensor loops to generate high-performance code for complex sparse array computations, essential for scientific computing and graph analysis.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "compilation",
        "sparse_computing"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/finch-tensor/Finch.jl",
      "help_website": [
        "https://willow-ahrens.io/Finch.jl/stable/"
      ],
      "license": "MIT",
      "tags": [
        "julia",
        "sparse-tensors",
        "compiler",
        "hpc"
      ],
      "id": 869
    },
    {
      "name": "native-sparse-attention",
      "one_line_profile": "Hardware-aligned sparse attention kernels in Triton",
      "detailed_description": "A library of efficient Triton implementations for native sparse attention mechanisms. It provides optimized kernels that align with hardware characteristics to accelerate training and inference of sparse transformers.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "kernel_optimization",
        "sparse_attention"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/fla-org/native-sparse-attention",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "triton",
        "sparse-attention",
        "acceleration"
      ],
      "id": 870
    },
    {
      "name": "FlagAttention",
      "one_line_profile": "Memory-efficient attention operators library",
      "detailed_description": "A collection of high-performance, memory-efficient attention operators implemented in Triton. It aims to optimize the core attention mechanism in Large Language Models for better throughput and lower memory usage.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "kernel_optimization",
        "attention_mechanism"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/flagos-ai/FlagAttention",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "triton",
        "attention",
        "optimization"
      ],
      "id": 871
    },
    {
      "name": "FlagGems",
      "one_line_profile": "Triton-based operator library for Large Language Models",
      "detailed_description": "A library of general-purpose and specialized operators for deep learning, implemented in Triton. It serves as a high-performance backend for LLM inference and training, offering alternatives to standard CUDA kernels.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "kernel_optimization",
        "operator_library"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/flagos-ai/FlagGems",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "triton",
        "operators",
        "llm"
      ],
      "id": 872
    },
    {
      "name": "FlagTree",
      "one_line_profile": "Unified compiler for custom DL operations on multiple AI chips",
      "detailed_description": "A fork of the Triton compiler designed to support multiple AI chip backends. It provides a unified compilation framework for custom deep learning operations, facilitating portability across different hardware architectures.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "compilation",
        "hardware_abstraction"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/flagos-ai/flagtree",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "compiler",
        "triton",
        "multi-backend"
      ],
      "id": 873
    },
    {
      "name": "SAX",
      "one_line_profile": "S-parameter based frequency domain circuit simulation with JAX",
      "detailed_description": "A circuit simulation and optimization tool based on S-parameters, built on top of JAX. It leverages JAX's autograd and XLA capabilities for efficient frequency domain analysis and optimization of photonic and electrical circuits.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "scientific_modeling",
        "simulation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/flaport/sax",
      "help_website": [
        "https://flaport.github.io/sax/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "jax",
        "circuit-simulation",
        "photonics",
        "autograd"
      ],
      "id": 874
    },
    {
      "name": "Deep Learning on Flink",
      "one_line_profile": "Distributed deep learning framework on Apache Flink",
      "detailed_description": "Integrates deep learning frameworks (TensorFlow, PyTorch) with Apache Flink, enabling distributed training and inference workflows on Flink clusters for large-scale data processing pipelines.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "distributed_computing",
        "workflow_orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/flink-extended/dl-on-flink",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "flink",
        "distributed-training",
        "tensorflow",
        "pytorch"
      ],
      "id": 875
    },
    {
      "name": "fms-acceleration",
      "one_line_profile": "Acceleration libraries for foundation model fine-tuning",
      "detailed_description": "A collection of libraries and plugins designed to accelerate the fine-tuning and training of foundation models within the Foundation Model Stack ecosystem. It provides optimizations for training loops and hardware utilization.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "training_acceleration",
        "fine_tuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/foundation-model-stack/fms-acceleration",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "foundation-models",
        "acceleration",
        "fine-tuning"
      ],
      "id": 876
    },
    {
      "name": "GPTQ-triton",
      "one_line_profile": "Triton kernel implementation for GPTQ inference",
      "detailed_description": "A specialized implementation of the GPTQ (Generative Pre-trained Transformer Quantization) inference kernel using OpenAI's Triton language. It enables high-performance inference of quantized models on GPUs.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/fpgaminer/GPTQ-triton",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gptq",
        "triton",
        "quantization",
        "inference"
      ],
      "id": 877
    },
    {
      "name": "Galois",
      "one_line_profile": "Tensor computing compiler based on tile programming for GPU/CPU/TPU",
      "detailed_description": "A tensor computing compiler that utilizes tile programming to optimize execution on various hardware backends including GPUs, CPUs, and TPUs.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "tensor_computing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/galois-stack/galois",
      "help_website": [],
      "license": null,
      "tags": [
        "compiler",
        "tensor",
        "gpu",
        "tpu"
      ],
      "id": 878
    },
    {
      "name": "CLAMP-ViT",
      "one_line_profile": "Contrastive data-free learning for adaptive post-training quantization of ViTs",
      "detailed_description": "A tool implementing contrastive data-free learning techniques for adaptive post-training quantization specifically designed for Vision Transformers (ViTs).",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/georgia-tech-synergy-lab/CLAMP-ViT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "quantization",
        "vit",
        "post-training-quantization"
      ],
      "id": 879
    },
    {
      "name": "SparQ",
      "one_line_profile": "Post-training sparsity-aware quantization framework",
      "detailed_description": "A framework for post-training quantization that takes sparsity into account to optimize model performance and size.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gilshm/sparq",
      "help_website": [],
      "license": null,
      "tags": [
        "quantization",
        "sparsity",
        "post-training"
      ],
      "id": 880
    },
    {
      "name": "GoMLX",
      "one_line_profile": "Accelerated Machine Learning Framework for Go",
      "detailed_description": "A machine learning framework for the Go programming language that provides acceleration capabilities, likely via XLA or similar backends.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "ml_framework",
        "training",
        "inference"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/gomlx/gomlx",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "go",
        "machine-learning",
        "framework"
      ],
      "id": 881
    },
    {
      "name": "AI Edge Quantizer",
      "one_line_profile": "Flexible post-training quantization for LiteRT models",
      "detailed_description": "A tool provided by Google AI Edge for performing flexible post-training quantization on LiteRT (formerly TensorFlow Lite) models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "edge_computing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/google-ai-edge/ai-edge-quantizer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "litert",
        "tensorflow-lite"
      ],
      "id": 882
    },
    {
      "name": "GPUStack",
      "one_line_profile": "GPU cluster manager for optimized AI model deployment",
      "detailed_description": "A cluster management tool designed to orchestrate and optimize the deployment of AI models across GPU clusters.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "cluster_management",
        "deployment",
        "orchestration"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/gpustack/gpustack",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu",
        "cluster-manager",
        "deployment"
      ],
      "id": 883
    },
    {
      "name": "Horovod Ansible",
      "one_line_profile": "Ansible roles for deploying Horovod clusters",
      "detailed_description": "Infrastructure-as-Code tool using Ansible to automate the deployment and configuration of Horovod distributed training clusters.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "deployment",
        "infrastructure_provisioning"
      ],
      "application_level": "workflow",
      "primary_language": "HCL",
      "repo_url": "https://github.com/graykode/horovod-ansible",
      "help_website": [],
      "license": null,
      "tags": [
        "ansible",
        "horovod",
        "distributed-training"
      ],
      "id": 884
    },
    {
      "name": "Inference (C#)",
      "one_line_profile": "C# deployment wrapper for OpenVINO, TensorRT, and ONNX Runtime",
      "detailed_description": "A library providing C# interfaces for deploying models using various high-performance inference engines like OpenVINO, TensorRT, and ONNX Runtime.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_wrapper",
        "deployment"
      ],
      "application_level": "library",
      "primary_language": "C#",
      "repo_url": "https://github.com/guojin-yan/Inference",
      "help_website": [],
      "license": null,
      "tags": [
        "csharp",
        "openvino",
        "tensorrt",
        "onnx"
      ],
      "id": 885
    },
    {
      "name": "BERT-pre-training",
      "one_line_profile": "Multi-GPU pre-training implementation for BERT without Horovod",
      "detailed_description": "A specialized implementation for pre-training BERT models using multi-GPU data parallelism on a single machine without requiring Horovod.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_training",
        "parallelism"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/guotong1988/BERT-pre-training",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "bert",
        "pre-training",
        "multi-gpu"
      ],
      "id": 886
    },
    {
      "name": "APPy",
      "one_line_profile": "Annotated Parallelism for Python to GPU compiler",
      "detailed_description": "A compiler tool that allows users to annotate Python loops and tensor expressions for automatic compilation into efficient GPU kernels.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "parallelization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/habanero-lab/APPy",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "compiler",
        "gpu",
        "python",
        "parallelism"
      ],
      "id": 887
    },
    {
      "name": "docker-tensorflow-builder",
      "one_line_profile": "Docker environment for compiling TensorFlow from source",
      "detailed_description": "A set of Docker configurations and scripts to facilitate the compilation of TensorFlow from source, enabling custom builds.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "build_tool",
        "compilation"
      ],
      "application_level": "workflow",
      "primary_language": "Shell",
      "repo_url": "https://github.com/hadim/docker-tensorflow-builder",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "docker",
        "tensorflow",
        "compilation"
      ],
      "id": 888
    },
    {
      "name": "PTQ4ViT",
      "one_line_profile": "Post-Training Quantization for Vision Transformers",
      "detailed_description": "A tool implementing post-training quantization techniques specifically optimized for Vision Transformer (ViT) architectures.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hahnyuan/PTQ4ViT",
      "help_website": [],
      "license": null,
      "tags": [
        "quantization",
        "vit",
        "vision-transformer"
      ],
      "id": 889
    },
    {
      "name": "RPTQ4LLM",
      "one_line_profile": "Reorder-based post-training quantization for LLMs",
      "detailed_description": "A quantization tool for Large Language Models that uses a reorder-based approach to maintain accuracy after post-training quantization.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "llm_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hahnyuan/RPTQ4LLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "quantization",
        "llm",
        "post-training"
      ],
      "id": 890
    },
    {
      "name": "Hailo Model Zoo",
      "one_line_profile": "Pre-trained models and build environment for Hailo hardware",
      "detailed_description": "A collection of pre-trained models along with a build and evaluation environment optimized for deployment on Hailo AI processors.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_deployment",
        "benchmarking"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/hailo-ai/hailo_model_zoo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "model-zoo",
        "hailo",
        "deployment"
      ],
      "id": 891
    },
    {
      "name": "Catgrad",
      "one_line_profile": "Categorical deep learning compiler",
      "detailed_description": "A deep learning compiler built using principles from category theory, written in Rust.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "deep_learning"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/hellas-ai/catgrad",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "compiler",
        "rust",
        "category-theory"
      ],
      "id": 892
    },
    {
      "name": "SWIFT",
      "one_line_profile": "On-the-Fly Self-Speculative Decoding for LLM Inference Acceleration",
      "detailed_description": "A tool implementing self-speculative decoding to accelerate the inference of Large Language Models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "decoding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hemingkx/SWIFT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "acceleration",
        "llm",
        "speculative-decoding"
      ],
      "id": 893
    },
    {
      "name": "Quantization.MXNet",
      "one_line_profile": "Quantization simulation for MXNet-Gluon models",
      "detailed_description": "A tool to simulate quantization and perform quantization-aware training for models built with MXNet-Gluon.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "simulation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hey-yahei/Quantization.MXNet",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "mxnet",
        "quantization",
        "gluon"
      ],
      "id": 894
    },
    {
      "name": "tensorflow-cpp",
      "one_line_profile": "TensorFlow C++ library compilation for CMake projects",
      "detailed_description": "A utility to compile TensorFlow into a C++ library suitable for integration into CMake-based projects.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "build_tool",
        "integration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/hhzrz/tensorflow-cpp",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tensorflow",
        "cpp",
        "cmake"
      ],
      "id": 895
    },
    {
      "name": "Hidet",
      "one_line_profile": "Efficient deep learning framework and compiler",
      "detailed_description": "An open-source deep learning framework and compiler written in Python, designed for high efficiency.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "dl_framework"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/hidet-org/hidet",
      "help_website": [
        "https://hidet.org"
      ],
      "license": "Apache-2.0",
      "tags": [
        "compiler",
        "deep-learning",
        "python"
      ],
      "id": 896
    },
    {
      "name": "Higgsfield",
      "one_line_profile": "Fault-tolerant GPU orchestration and training framework",
      "detailed_description": "A scalable GPU orchestration platform and machine learning framework designed for training large-scale models with fault tolerance.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "orchestration",
        "training_framework"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/higgsfield-ai/higgsfield",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "orchestration",
        "gpu",
        "training"
      ],
      "id": 897
    },
    {
      "name": "Caten",
      "one_line_profile": "Polyhedral-based Deep Learning Compiler",
      "detailed_description": "A deep learning compiler leveraging polyhedral compilation techniques, lightweight IRs, and pattern matching for optimization.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "optimization"
      ],
      "application_level": "solver",
      "primary_language": "Common Lisp",
      "repo_url": "https://github.com/hikettei/Caten",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "compiler",
        "polyhedral",
        "lisp"
      ],
      "id": 898
    },
    {
      "name": "Parallel Prompt Decoding",
      "one_line_profile": "Efficient LLM Inference Acceleration using Prompting",
      "detailed_description": "A tool implementing parallel prompt decoding techniques to accelerate the inference process of Large Language Models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "decoding"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hmarkc/parallel-prompt-decoding",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "acceleration",
        "llm"
      ],
      "id": 899
    },
    {
      "name": "LLM-Pruner",
      "one_line_profile": "Structural Pruning tool for Large Language Models",
      "detailed_description": "A tool for structural pruning of Large Language Models (LLMs) such as Llama, BLOOM, and Vicuna to reduce model size and improve efficiency.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "pruning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/horseee/LLM-Pruner",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "pruning",
        "llm",
        "compression"
      ],
      "id": 900
    },
    {
      "name": "SINQ",
      "one_line_profile": "Fast and high-quality quantization method for LLMs",
      "detailed_description": "A quantization tool designed to compress Large Language Models while preserving accuracy, implementing the SINQ method.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/huawei-csl/SINQ",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "llm",
        "compression"
      ],
      "id": 901
    },
    {
      "name": "Huawei Noah PLM",
      "one_line_profile": "Pretrained language models and optimization techniques",
      "detailed_description": "A repository containing pretrained language models and implementations of optimization techniques (like PanGu-Alpha) developed by Huawei Noah's Ark Lab.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_optimization",
        "pretraining"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huawei-noah/Pretrained-Language-Model",
      "help_website": [],
      "license": null,
      "tags": [
        "pretrained-models",
        "optimization",
        "huawei"
      ],
      "id": 902
    },
    {
      "name": "Accelerate",
      "one_line_profile": "Library for easy distributed training and mixed precision in PyTorch",
      "detailed_description": "A library by Hugging Face that abstracts the boilerplate code for distributed training and mixed precision, making it easy to run PyTorch scripts on various hardware configurations.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/accelerate",
      "help_website": [
        "https://huggingface.co/docs/accelerate"
      ],
      "license": "Apache-2.0",
      "tags": [
        "pytorch",
        "distributed-training",
        "mixed-precision"
      ],
      "id": 903
    },
    {
      "name": "Optimum ONNX",
      "one_line_profile": "Export and inference tool for ONNX Runtime via Hugging Face",
      "detailed_description": "A tool to export Hugging Face models to ONNX format and run inference using ONNX Runtime, optimizing performance.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_optimization",
        "model_export"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/optimum-onnx",
      "help_website": [
        "https://huggingface.co/docs/optimum"
      ],
      "license": "Apache-2.0",
      "tags": [
        "onnx",
        "inference",
        "optimization"
      ],
      "id": 904
    },
    {
      "name": "Picotron",
      "one_line_profile": "Minimalistic 4D-parallelism distributed training framework",
      "detailed_description": "A distributed training framework implementing 4D-parallelism, designed for educational purposes but functional as a reference implementation for advanced parallelism techniques.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "parallelism"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/huggingface/picotron",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "distributed-training",
        "parallelism",
        "educational"
      ],
      "id": 905
    },
    {
      "name": "tensorflow-yolov4-tflite",
      "one_line_profile": "YOLOv4 implementation with conversion tools for TFLite and TensorRT",
      "detailed_description": "A comprehensive repository providing implementations of YOLOv4, YOLOv4-tiny, YOLOv3, and YOLOv3-tiny in TensorFlow 2.0, along with utilities to convert these models to TensorFlow Lite (.tflite) and TensorRT formats for accelerated inference on edge devices.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_conversion",
        "inference_acceleration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hunglc007/tensorflow-yolov4-tflite",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "yolov4",
        "tflite",
        "tensorrt",
        "conversion"
      ],
      "id": 906
    },
    {
      "name": "PD-Quant",
      "one_line_profile": "Post-training quantization method based on prediction difference metric",
      "detailed_description": "Implementation of the PD-Quant method (CVPR 2023), a post-training quantization technique that uses a prediction difference metric to optimize quantization parameters without requiring retraining.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/hustvl/PD-Quant",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "post-training-quantization",
        "cvpr-2023",
        "model-compression"
      ],
      "id": 907
    },
    {
      "name": "yzma",
      "one_line_profile": "Go bindings for llama.cpp enabling local LLM inference",
      "detailed_description": "A Go library that integrates with llama.cpp to provide hardware-accelerated local inference for Large Language Models (LLMs) within Go applications.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "llm_inference"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/hybridgroup/yzma",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llama.cpp",
        "go",
        "llm",
        "inference"
      ],
      "id": 908
    },
    {
      "name": "AutoRound",
      "one_line_profile": "Advanced quantization toolkit for LLMs and VLMs",
      "detailed_description": "An advanced quantization toolkit designed for Large Language Models (LLMs) and Vision-Language Models (VLMs), supporting various schemes like WOQ, MXFP4, and NVFP4. It integrates with major frameworks like Transformers and vLLM to facilitate low-bit model deployment.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/intel/auto-round",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "llm",
        "vlm",
        "intel"
      ],
      "id": 909
    },
    {
      "name": "Intel Extension for DeepSpeed",
      "one_line_profile": "DeepSpeed extension for Intel XPU acceleration",
      "detailed_description": "An extension for the DeepSpeed optimization library that enables support for Intel GPU (XPU) devices using SYCL kernels, facilitating accelerated distributed training on Intel hardware.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "training_acceleration",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/intel/intel-extension-for-deepspeed",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "deepspeed",
        "intel-xpu",
        "sycl",
        "distributed-training"
      ],
      "id": 910
    },
    {
      "name": "Intel XPU Backend for Triton",
      "one_line_profile": "OpenAI Triton compiler backend for Intel GPUs",
      "detailed_description": "A backend implementation for the OpenAI Triton compiler, enabling Triton kernels to run efficiently on Intel GPUs (XPU), supporting high-performance deep learning primitives.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler_backend",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "MLIR",
      "repo_url": "https://github.com/intel/intel-xpu-backend-for-triton",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "triton",
        "intel-gpu",
        "compiler",
        "acceleration"
      ],
      "id": 911
    },
    {
      "name": "IPEX-LLM",
      "one_line_profile": "LLM inference and finetuning acceleration library for Intel XPU",
      "detailed_description": "A library for accelerating local inference and fine-tuning of Large Language Models (LLMs) on Intel hardware (CPUs, iGPUs, discrete GPUs). It integrates with popular frameworks like HuggingFace, LangChain, and vLLM.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "finetuning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/intel/ipex-llm",
      "help_website": [
        "https://ipex-llm.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "intel",
        "inference",
        "finetuning"
      ],
      "id": 912
    },
    {
      "name": "Intel Neural Compressor",
      "one_line_profile": "Model compression tool for quantization and sparsity",
      "detailed_description": "A model compression tool that provides state-of-the-art quantization (INT8, FP8, INT4, etc.) and sparsity techniques for PyTorch, TensorFlow, and ONNX Runtime, aiming to accelerate inference with minimal accuracy loss.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression",
        "sparsity"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/intel/neural-compressor",
      "help_website": [
        "https://intel.github.io/neural-compressor/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "compression",
        "intel",
        "optimization"
      ],
      "id": 913
    },
    {
      "name": "NeuroVectorizer",
      "one_line_profile": "RL-based framework for optimal compiler vectorization",
      "detailed_description": "A framework that utilizes deep reinforcement learning to predict optimal vectorization compiler pragmas for loops in C and C++ code, automating the tuning of compiler optimizations.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler_optimization",
        "vectorization"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/intel/neuro-vectorizer",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "compiler",
        "reinforcement-learning",
        "vectorization",
        "optimization"
      ],
      "id": 914
    },
    {
      "name": "PKD-for-BERT",
      "one_line_profile": "Patient Knowledge Distillation for BERT model compression",
      "detailed_description": "PyTorch implementation of Patient Knowledge Distillation (PKD), a method for compressing BERT models by distilling knowledge from intermediate layers, enabling efficient inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "knowledge_distillation",
        "model_compression"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/intersun/PKD-for-BERT-Model-Compression",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "bert",
        "knowledge-distillation",
        "compression"
      ],
      "id": 915
    },
    {
      "name": "IREE",
      "one_line_profile": "Retargetable MLIR-based machine learning compiler and runtime",
      "detailed_description": "A compiler and runtime toolkit based on MLIR that lowers machine learning models to a unified intermediate representation, enabling execution on diverse hardware targets including mobile, edge, and datacenter devices.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "runtime",
        "inference_acceleration"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/iree-org/iree",
      "help_website": [
        "https://iree.dev/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlir",
        "compiler",
        "runtime",
        "cross-platform"
      ],
      "id": 916
    },
    {
      "name": "yolov4-triton-tensorrt",
      "one_line_profile": "Deployment workflow for YOLOv4 on Triton Inference Server via TensorRT",
      "detailed_description": "A repository providing the necessary configurations and scripts to deploy YOLOv4 models as optimized TensorRT engines within the Triton Inference Server environment.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_deployment",
        "inference_serving"
      ],
      "application_level": "workflow",
      "primary_language": "C++",
      "repo_url": "https://github.com/isarsoft/yolov4-triton-tensorrt",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "yolov4",
        "triton-inference-server",
        "tensorrt",
        "deployment"
      ],
      "id": 917
    },
    {
      "name": "Tzer",
      "one_line_profile": "Coverage-guided tensor compiler fuzzer for TVM",
      "detailed_description": "A fuzzing tool designed for tensor compilers (specifically TVM) that uses coverage guidance and joint IR-pass mutation to detect bugs and correctness issues in the compilation process.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler_testing",
        "fuzzing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ise-uiuc/tzer",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tvm",
        "fuzzing",
        "compiler-testing"
      ],
      "id": 918
    },
    {
      "name": "CalibTIP",
      "one_line_profile": "Layer-wise calibration for post-training neural quantization",
      "detailed_description": "Implementation of a post-training quantization method that utilizes layer-wise calibration and integer programming to improve the accuracy of quantized neural networks.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "calibration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/itayhubara/CalibTIP",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "quantization",
        "calibration",
        "optimization"
      ],
      "id": 919
    },
    {
      "name": "dl-benchmark",
      "one_line_profile": "Multi-framework deep learning inference benchmark tool",
      "detailed_description": "A benchmarking tool for evaluating deep learning inference performance across multiple frameworks including OpenVINO, TensorFlow, ONNX Runtime, PyTorch, and TVM.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_analysis"
      ],
      "application_level": "solver",
      "primary_language": "HTML",
      "repo_url": "https://github.com/itlab-vision/dl-benchmark",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "benchmark",
        "inference",
        "deep-learning"
      ],
      "id": 920
    },
    {
      "name": "yolov5-onnxruntime",
      "one_line_profile": "C++ inference implementation for YOLOv5 using ONNX Runtime",
      "detailed_description": "A C++ implementation for running inference on YOLOv5 models using the ONNX Runtime, providing a lightweight solution for deploying object detection models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_deployment"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/itsnine/yolov5-onnxruntime",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "yolov5",
        "onnx-runtime",
        "cpp",
        "inference"
      ],
      "id": 921
    },
    {
      "name": "InferenceHelper",
      "one_line_profile": "C++ helper library for multiple deep learning inference frameworks",
      "detailed_description": "A C++ wrapper library that provides a unified interface for various deep learning inference frameworks such as TensorFlow Lite, TensorRT, OpenVINO, ONNX Runtime, and ncnn, simplifying application development.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_abstraction",
        "deployment"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/iwatake2222/InferenceHelper",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "inference",
        "wrapper",
        "cpp",
        "multi-framework"
      ],
      "id": 922
    },
    {
      "name": "Alpaca-LoRA-RLHF-PyTorch",
      "one_line_profile": "Pipeline for finetuning Alpaca LLM with LoRA and RLHF",
      "detailed_description": "A complete pipeline for fine-tuning the Alpaca Large Language Model using Low-Rank Adaptation (LoRA) and Reinforcement Learning with Human Feedback (RLHF) on consumer hardware.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "finetuning",
        "rlhf",
        "training_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/jackaduma/Alpaca-LoRA-RLHF-PyTorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "alpaca",
        "lora",
        "rlhf",
        "finetuning"
      ],
      "id": 923
    },
    {
      "name": "ChatGLM-LoRA-RLHF-PyTorch",
      "one_line_profile": "Pipeline for finetuning ChatGLM with LoRA and RLHF",
      "detailed_description": "A pipeline designed to fine-tune the ChatGLM model using LoRA and RLHF techniques, enabling efficient customization of the model on consumer-grade hardware.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "finetuning",
        "rlhf",
        "training_pipeline"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/jackaduma/ChatGLM-LoRA-RLHF-PyTorch",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "chatglm",
        "lora",
        "rlhf",
        "finetuning"
      ],
      "id": 924
    },
    {
      "name": "YOLOv8-qat",
      "one_line_profile": "Quantization Aware Training implementation for YOLOv8",
      "detailed_description": "A tool implementing Quantization Aware Training (QAT) specifically for YOLOv8 models, allowing for the creation of quantized models that retain high accuracy.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization_aware_training",
        "model_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/jahongir7174/YOLOv8-qat",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "yolov8",
        "qat",
        "quantization"
      ],
      "id": 925
    },
    {
      "name": "jax-triton",
      "one_line_profile": "Integration library between JAX and OpenAI Triton",
      "detailed_description": "A library that provides integrations between JAX and OpenAI Triton, allowing users to write custom Triton kernels and use them within JAX computations for accelerated machine learning.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler_integration",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jax-ml/jax-triton",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "jax",
        "triton",
        "kernel",
        "acceleration"
      ],
      "id": 926
    },
    {
      "name": "xllm",
      "one_line_profile": "High-performance inference engine for LLMs on diverse accelerators",
      "detailed_description": "A high-performance inference engine designed for Large Language Models (LLMs), optimized to run efficiently on various AI accelerators and hardware platforms.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_engine",
        "llm_acceleration"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/jd-opensource/xllm",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "llm",
        "inference-engine",
        "acceleration"
      ],
      "id": 927
    },
    {
      "name": "QSNNs",
      "one_line_profile": "Quantization-aware training for spiking neural networks",
      "detailed_description": "A library/tool for performing quantization-aware training specifically tailored for Spiking Neural Networks (SNNs), enabling the deployment of efficient neuromorphic models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "neuromorphic_computing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jeshraghian/QSNNs",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "snn",
        "quantization",
        "spiking-neural-networks"
      ],
      "id": 928
    },
    {
      "name": "tensorrt_demos",
      "one_line_profile": "Collection of TensorRT implementation examples and utilities",
      "detailed_description": "A widely used collection of examples and utility scripts for deploying various deep learning models (YOLO, SSD, etc.) using TensorRT on NVIDIA Jetson and x86 platforms.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_deployment",
        "tensorrt_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jkjung-avt/tensorrt_demos",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tensorrt",
        "jetson",
        "inference",
        "demo"
      ],
      "id": 929
    },
    {
      "name": "DeepDetect",
      "one_line_profile": "Open source deep learning API and server",
      "detailed_description": "A deep learning API and server written in C++14 that supports multiple backends (PyTorch, TensorRT, NCNN, etc.), providing a unified platform for training and inference integration.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_server",
        "model_serving"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/jolibrain/deepdetect",
      "help_website": [
        "https://www.deepdetect.com/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "inference-server",
        "api",
        "deep-learning"
      ],
      "id": 930
    },
    {
      "name": "pykaldi2",
      "one_line_profile": "Speech recognition toolkit based on Kaldi and PyTorch",
      "detailed_description": "A Python wrapper and toolkit for the Kaldi speech recognition system, integrating it with PyTorch for flexible model training and inference.",
      "domains": [
        "AI6",
        "AI4"
      ],
      "subtask_category": [
        "speech_recognition",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/jzlianglu/pykaldi2",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kaldi",
        "speech-recognition",
        "pytorch-wrapper"
      ],
      "id": 931
    },
    {
      "name": "trident",
      "one_line_profile": "Performance library for machine learning applications",
      "detailed_description": "A library designed to accelerate machine learning applications, providing optimized kernels and utilities for performance enhancement.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "training_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/kakaobrain/trident",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "acceleration",
        "performance",
        "machine-learning"
      ],
      "id": 932
    },
    {
      "name": "ps-dnn",
      "one_line_profile": "Distributed deep learning training and prediction framework",
      "detailed_description": "A lightweight distributed deep learning framework based on Parameter Server (PS-Lite), supporting feature extraction and distributed training.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "inference"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/kangshantong/ps-dnn",
      "help_website": [],
      "license": null,
      "tags": [
        "parameter-server",
        "distributed-training",
        "c++"
      ],
      "id": 933
    },
    {
      "name": "sparrow",
      "one_line_profile": "Structured data extraction tool using ML and LLMs",
      "detailed_description": "A tool for extracting structured data from documents and images using machine learning and Large Language Models, useful for scientific data processing.",
      "domains": [
        "AI1",
        "AI6"
      ],
      "subtask_category": [
        "data_extraction",
        "document_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/katanaml/sparrow",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "data-extraction",
        "llm",
        "ocr"
      ],
      "id": 934
    },
    {
      "name": "nncase",
      "one_line_profile": "Deep learning compiler stack for AI accelerators",
      "detailed_description": "An open compiler stack designed to optimize and deploy deep learning models onto Kendryte AI accelerators.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compilation",
        "inference_acceleration"
      ],
      "application_level": "solver",
      "primary_language": "C#",
      "repo_url": "https://github.com/kendryte/nncase",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compiler",
        "ai-accelerator",
        "kendryte"
      ],
      "id": 935
    },
    {
      "name": "onnxruntime-server",
      "one_line_profile": "Server for ONNX inference via REST APIs",
      "detailed_description": "A server application that provides TCP and HTTP/HTTPS REST APIs for performing inference using ONNX Runtime.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_serving",
        "inference"
      ],
      "application_level": "service",
      "primary_language": "C++",
      "repo_url": "https://github.com/kibae/onnxruntime-server",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "onnx",
        "serving",
        "rest-api"
      ],
      "id": 936
    },
    {
      "name": "kserve",
      "one_line_profile": "Standardized distributed AI inference platform on Kubernetes",
      "detailed_description": "A platform for serving machine learning models on Kubernetes, supporting serverless inference, canary rollouts, and multi-framework deployment.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_serving",
        "inference_management"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/kserve/kserve",
      "help_website": [
        "https://kserve.github.io/website/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes",
        "inference-serving",
        "mlops"
      ],
      "id": 937
    },
    {
      "name": "kubeai",
      "one_line_profile": "AI Inference Operator for Kubernetes",
      "detailed_description": "A Kubernetes operator designed to simplify the deployment and serving of AI models, including LLMs and VLMs, in production environments.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_serving",
        "deployment_automation"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubeai-project/kubeai",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kubernetes-operator",
        "inference",
        "llm-serving"
      ],
      "id": 938
    },
    {
      "name": "mpi-operator",
      "one_line_profile": "Kubernetes Operator for MPI-based applications",
      "detailed_description": "A Kubernetes operator that manages the lifecycle of MPI jobs, facilitating distributed training and HPC workloads on Kubernetes clusters.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "hpc_job_management"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/kubeflow/mpi-operator",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mpi",
        "kubernetes",
        "hpc"
      ],
      "id": 939
    },
    {
      "name": "pytorch2c",
      "one_line_profile": "Compiler for converting PyTorch graphs to C",
      "detailed_description": "A tool that compiles PyTorch computational graphs into C code, enabling standalone execution of models without the Python runtime.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compilation",
        "inference_acceleration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lantiga/pytorch2c",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pytorch",
        "compiler",
        "c-generation"
      ],
      "id": 940
    },
    {
      "name": "TensorRT-YOLO",
      "one_line_profile": "Deployment toolkit for YOLO models using TensorRT",
      "detailed_description": "A toolkit designed to facilitate the deployment of YOLO object detection models on NVIDIA GPUs using TensorRT for acceleration.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_deployment"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/laugh12321/TensorRT-YOLO",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "tensorrt",
        "yolo",
        "deployment"
      ],
      "id": 941
    },
    {
      "name": "Liger-Kernel",
      "one_line_profile": "Efficient Triton kernels for LLM training",
      "detailed_description": "A library of highly optimized Triton kernels designed to accelerate the training of Large Language Models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "training_acceleration",
        "kernel_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/linkedin/Liger-Kernel",
      "help_website": [],
      "license": "BSD-2-Clause",
      "tags": [
        "triton",
        "kernels",
        "llm-training"
      ],
      "id": 942
    },
    {
      "name": "Tempo",
      "one_line_profile": "Declarative compiled dynamic deep learning system",
      "detailed_description": "A system for end-to-end compiled dynamic deep learning, offering declarative interfaces and efficient execution.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compilation",
        "deep_learning_system"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/lsds/Tempo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "compiler",
        "deep-learning",
        "system"
      ],
      "id": 943
    },
    {
      "name": "pytorch-quantity",
      "one_line_profile": "Automated 8-bit quantization conversion tool for PyTorch",
      "detailed_description": "A tool for performing post-training quantization on PyTorch models, specifically using KL divergence for calibration.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/lswzjuer/pytorch-quantity",
      "help_website": [],
      "license": null,
      "tags": [
        "quantization",
        "pytorch",
        "post-training-quantization"
      ],
      "id": 944
    },
    {
      "name": "SOBER",
      "one_line_profile": "Fast Bayesian optimization with GPU acceleration",
      "detailed_description": "A tool for performing fast Bayesian optimization, quadrature, and inference over arbitrary domains, leveraging GPU acceleration.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "optimization",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ma921/SOBER",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "bayesian-optimization",
        "gpu-acceleration",
        "inference"
      ],
      "id": 945
    },
    {
      "name": "altius",
      "one_line_profile": "Small ONNX inference runtime written in Rust",
      "detailed_description": "A lightweight inference runtime for ONNX models, implemented in Rust, focusing on portability and performance.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_runtime",
        "model_execution"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/maekawatoshiki/altius",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "onnx",
        "runtime",
        "rust"
      ],
      "id": 946
    },
    {
      "name": "DeepStream-Yolo",
      "one_line_profile": "NVIDIA DeepStream implementation for YOLO models",
      "detailed_description": "A widely used integration tool that enables running YOLO object detection models within the NVIDIA DeepStream SDK pipeline.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "pipeline_integration"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/marcoslucianops/DeepStream-Yolo",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "deepstream",
        "yolo",
        "nvidia"
      ],
      "id": 947
    },
    {
      "name": "ONN-QAT-SQL",
      "one_line_profile": "Simulation scripts for Optical Neural Networks under photon shot noise",
      "detailed_description": "A set of scripts for training neural networks resistant to photon shot noise using quantization-aware training, including simulation of neural network performance under shot noise conditions.",
      "domains": [
        "AI6-04",
        "Physics"
      ],
      "subtask_category": [
        "simulation",
        "quantization_aware_training"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mcmahon-lab/ONN-QAT-SQL",
      "help_website": [],
      "license": "CC-BY-4.0",
      "tags": [
        "optical-neural-networks",
        "simulation",
        "quantization"
      ],
      "id": 948
    },
    {
      "name": "FQ-ViT",
      "one_line_profile": "Post-Training Quantization for Fully Quantized Vision Transformers",
      "detailed_description": "Implementation of FQ-ViT, a method for post-training quantization specifically designed for Vision Transformers to achieve full quantization.",
      "domains": [
        "AI6-04",
        "CV"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/megvii-research/FQ-ViT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vision-transformer",
        "post-training-quantization",
        "ptq"
      ],
      "id": 949
    },
    {
      "name": "Sparsebit",
      "one_line_profile": "Model compression and acceleration toolbox for PyTorch",
      "detailed_description": "A comprehensive toolbox for model compression and acceleration based on PyTorch, facilitating quantization and pruning tasks.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/megvii-research/Sparsebit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compression",
        "acceleration",
        "pytorch"
      ],
      "id": 950
    },
    {
      "name": "MSLK",
      "one_line_profile": "Meta Superintelligence Labs Kernels for GenAI optimization",
      "detailed_description": "A collection of PyTorch GPU operator libraries designed and optimized for GenAI training and inference, including FP8 row-wise quantization and collective communications.",
      "domains": [
        "AI6-04",
        "HPC"
      ],
      "subtask_category": [
        "kernel_optimization",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/meta-pytorch/MSLK",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "gpu-kernels",
        "fp8",
        "genai"
      ],
      "id": 951
    },
    {
      "name": "Tritonbench",
      "one_line_profile": "Benchmarking framework for PyTorch operators and Triton kernels",
      "detailed_description": "A collection of PyTorch custom operators with example inputs designed to measure their performance, serving as a benchmarking tool for Triton kernels.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "benchmarking",
        "performance_profiling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/meta-pytorch/tritonbench",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "triton",
        "benchmarking",
        "pytorch"
      ],
      "id": 952
    },
    {
      "name": "TritonParse",
      "one_line_profile": "Compiler Tracer and Visualizer for Triton Kernels",
      "detailed_description": "A tool for tracing, visualizing, and reproducing Triton compiler behavior, aiding in the debugging and optimization of Triton kernels.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "compiler_debugging",
        "visualization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/meta-pytorch/tritonparse",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "triton",
        "compiler",
        "visualization"
      ],
      "id": 953
    },
    {
      "name": "Olive",
      "one_line_profile": "Model optimization toolchain for hardware acceleration",
      "detailed_description": "A tool to simplify ML model finetuning, conversion, quantization, and optimization for deployment on CPUs, GPUs, and NPUs.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "model_optimization",
        "quantization"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/Olive",
      "help_website": [
        "https://microsoft.github.io/Olive/"
      ],
      "license": "MIT",
      "tags": [
        "onnx",
        "optimization",
        "quantization"
      ],
      "id": 954
    },
    {
      "name": "SwitchML",
      "one_line_profile": "Switch-based training acceleration for machine learning",
      "detailed_description": "A project implementing switch-based training acceleration for machine learning workloads, optimizing communication in distributed training.",
      "domains": [
        "AI6",
        "HPC"
      ],
      "subtask_category": [
        "distributed_training",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/SwitchML",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "distributed-training",
        "networking",
        "acceleration"
      ],
      "id": 955
    },
    {
      "name": "TileFusion",
      "one_line_profile": "C++ macro kernel template library for CUDA tile processing",
      "detailed_description": "An experimental C++ macro kernel template library that elevates the abstraction level in CUDA C for efficient tile processing.",
      "domains": [
        "AI6-04",
        "HPC"
      ],
      "subtask_category": [
        "kernel_optimization",
        "cuda_programming"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/microsoft/TileFusion",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "cuda",
        "kernel-templates",
        "optimization"
      ],
      "id": 956
    },
    {
      "name": "Antares",
      "one_line_profile": "Automatic engine for multi-platform kernel generation",
      "detailed_description": "An automatic engine for multi-platform kernel generation and optimization, supporting various backends like CPU, CUDA, ROCm, and OpenCL.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "kernel_generation",
        "compiler"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/microsoft/antares",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "kernel-generation",
        "compiler",
        "multi-platform"
      ],
      "id": 957
    },
    {
      "name": "Hummingbird",
      "one_line_profile": "Compiles traditional ML models into tensor computation",
      "detailed_description": "A library that compiles trained traditional ML models (like decision trees) into tensor computation for faster inference on deep learning frameworks.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "model_compilation",
        "inference_acceleration"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/hummingbird",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ml-compilation",
        "tensor-computation",
        "inference"
      ],
      "id": 958
    },
    {
      "name": "NNI",
      "one_line_profile": "AutoML toolkit for model compression and NAS",
      "detailed_description": "An open source AutoML toolkit for automating machine learning lifecycle, including feature engineering, neural architecture search (NAS), model compression, and hyper-parameter tuning.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "automl",
        "model_compression",
        "nas"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/nni",
      "help_website": [
        "https://nni.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "automl",
        "nas",
        "hyperparameter-tuning"
      ],
      "id": 959
    },
    {
      "name": "ONNX Runtime",
      "one_line_profile": "High performance ML inferencing and training accelerator",
      "detailed_description": "A cross-platform, high performance machine learning inferencing and training accelerator that supports models from PyTorch, TensorFlow/Keras, TFLite, scikit-learn, and other frameworks.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "runtime"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/microsoft/onnxruntime",
      "help_website": [
        "https://onnxruntime.ai/"
      ],
      "license": "MIT",
      "tags": [
        "inference",
        "onnx",
        "acceleration"
      ],
      "id": 960
    },
    {
      "name": "onnxruntime-extensions",
      "one_line_profile": "Pre- and post-processing library for ONNX Runtime",
      "detailed_description": "A specialized library providing custom operators for pre- and post-processing to support ONNX Runtime, enabling end-to-end model execution.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "data_processing",
        "custom_operators"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/microsoft/onnxruntime-extensions",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "onnx",
        "preprocessing",
        "extensions"
      ],
      "id": 961
    },
    {
      "name": "triton-shared",
      "one_line_profile": "Shared Middle-Layer for Triton Compilation",
      "detailed_description": "A shared middle-layer infrastructure for Triton compilation, facilitating the development of Triton backends and compiler optimizations.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "compiler_infrastructure"
      ],
      "application_level": "library",
      "primary_language": "MLIR",
      "repo_url": "https://github.com/microsoft/triton-shared",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "triton",
        "compiler",
        "mlir"
      ],
      "id": 962
    },
    {
      "name": "Vidur",
      "one_line_profile": "Large-scale simulation framework for LLM inference",
      "detailed_description": "A large-scale simulation framework designed to model and analyze the performance of Large Language Model (LLM) inference systems.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "performance_simulation",
        "profiling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/microsoft/vidur",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "simulation",
        "inference"
      ],
      "id": 963
    },
    {
      "name": "BoxMOT",
      "one_line_profile": "Pluggable multi-object tracking modules",
      "detailed_description": "A collection of state-of-the-art multi-object tracking modules pluggable into segmentation, object detection, and pose estimation models.",
      "domains": [
        "AI6",
        "CV"
      ],
      "subtask_category": [
        "object_tracking",
        "image_analysis"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mikel-brostrom/boxmot",
      "help_website": [],
      "license": "AGPL-3.0",
      "tags": [
        "tracking",
        "computer-vision",
        "mot"
      ],
      "id": 964
    },
    {
      "name": "MindNLP",
      "one_line_profile": "NLP library for MindSpore with Huggingface compatibility",
      "detailed_description": "An NLP library that enables running Transformers/Diffusers models on MindSpore with seamless compatibility and acceleration.",
      "domains": [
        "AI6-04",
        "NLP"
      ],
      "subtask_category": [
        "natural_language_processing",
        "model_training"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/mindspore-lab/mindnlp",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "mindspore",
        "nlp",
        "transformers"
      ],
      "id": 965
    },
    {
      "name": "AMC",
      "one_line_profile": "AutoML for Model Compression on Mobile Devices",
      "detailed_description": "A tool implementing AutoML for Model Compression (AMC), leveraging reinforcement learning to automate the compression of deep neural networks for mobile devices.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "automl"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mit-han-lab/amc",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "compression",
        "automl",
        "mobile-ai"
      ],
      "id": 966
    },
    {
      "name": "DistriFusion",
      "one_line_profile": "Distributed Parallel Inference for Diffusion Models",
      "detailed_description": "A framework for distributed parallel inference enabling high-resolution diffusion model generation by splitting computation across devices.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_inference",
        "image_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mit-han-lab/distrifuser",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "diffusion-models",
        "distributed-inference",
        "parallel-computing"
      ],
      "id": 967
    },
    {
      "name": "AWQ",
      "one_line_profile": "Activation-aware Weight Quantization for LLMs",
      "detailed_description": "A tool for Activation-aware Weight Quantization (AWQ), enabling efficient compression and acceleration of Large Language Models.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mit-han-lab/llm-awq",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "quantization",
        "awq"
      ],
      "id": 968
    },
    {
      "name": "SmoothQuant",
      "one_line_profile": "Post-Training Quantization for Large Language Models",
      "detailed_description": "A framework for accurate and efficient post-training quantization of Large Language Models, enabling 8-bit weight and activation quantization.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/mit-han-lab/smoothquant",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "quantization",
        "post-training"
      ],
      "id": 969
    },
    {
      "name": "TorchSparse",
      "one_line_profile": "Efficient Sparse Convolution Framework on GPUs",
      "detailed_description": "A high-performance computing framework for efficient training and inference of sparse convolutions on GPUs.",
      "domains": [
        "AI6-04",
        "HPC"
      ],
      "subtask_category": [
        "sparse_computation",
        "acceleration"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/mit-han-lab/torchsparse",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "sparse-convolution",
        "gpu",
        "acceleration"
      ],
      "id": 970
    },
    {
      "name": "WebLLM",
      "one_line_profile": "High-performance in-browser LLM inference engine",
      "detailed_description": "A high-performance in-browser inference engine for Large Language Models, bringing hardware-accelerated AI to web browsers.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "inference_engine",
        "web_ai"
      ],
      "application_level": "solver",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/mlc-ai/web-llm",
      "help_website": [
        "https://webllm.mlc.ai/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "webgpu",
        "inference"
      ],
      "id": 971
    },
    {
      "name": "mpi4jax",
      "one_line_profile": "Zero-copy MPI communication for JAX",
      "detailed_description": "A library enabling zero-copy MPI communication of JAX arrays, facilitating the development of turbo-charged HPC applications in Python.",
      "domains": [
        "AI6",
        "HPC"
      ],
      "subtask_category": [
        "distributed_computing",
        "hpc"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mpi4jax/mpi4jax",
      "help_website": [
        "https://mpi4jax.readthedocs.io/"
      ],
      "license": "MIT",
      "tags": [
        "jax",
        "mpi",
        "hpc"
      ],
      "id": 972
    },
    {
      "name": "FastVGGT",
      "one_line_profile": "Training-free acceleration library for Visual Geometry Transformers",
      "detailed_description": "A library implementing training-free acceleration techniques for Visual Geometry Transformers (VGGT), optimizing inference speed without retraining.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mystorm16/FastVGGT",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "transformer",
        "acceleration",
        "vision"
      ],
      "id": 973
    },
    {
      "name": "onnxruntime-rs",
      "one_line_profile": "Rust bindings for ONNX Runtime inference engine",
      "detailed_description": "A Rust wrapper for Microsoft's ONNX Runtime, enabling high-performance machine learning inference within Rust applications.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_runtime",
        "model_deployment"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/nbigaouette/onnxruntime-rs",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rust",
        "onnx",
        "inference"
      ],
      "id": 974
    },
    {
      "name": "DeepSparse",
      "one_line_profile": "Sparsity-aware deep learning inference runtime for CPUs",
      "detailed_description": "An inference runtime engine optimized for sparse neural networks, delivering GPU-class performance on commodity CPUs by leveraging sparsity.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "inference_runtime"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/neuralmagic/deepsparse",
      "help_website": [
        "https://docs.neuralmagic.com/deepsparse/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "sparsity",
        "inference",
        "cpu-optimization"
      ],
      "id": 975
    },
    {
      "name": "SparseZoo",
      "one_line_profile": "Repository of sparse models and recipes for inference optimization",
      "detailed_description": "A repository and library providing pre-sparsified models and optimization recipes to facilitate the deployment of high-performance sparse neural networks.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_optimization",
        "model_repository"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/neuralmagic/sparsezoo",
      "help_website": [
        "https://docs.neuralmagic.com/sparsezoo/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "sparse-models",
        "optimization-recipes",
        "neural-networks"
      ],
      "id": 976
    },
    {
      "name": "Sparsify",
      "one_line_profile": "Tool for model sparsification and pruning to accelerate inference",
      "detailed_description": "A tool enabling users to apply sparsification technologies (pruning and quantization) to neural networks to accelerate inference performance.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "quantization",
        "pruning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/neuralmagic/sparsify",
      "help_website": [
        "https://docs.neuralmagic.com/sparsify/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "pruning",
        "quantization",
        "optimization"
      ],
      "id": 977
    },
    {
      "name": "vLLM-gfx906",
      "one_line_profile": "Port of vLLM inference engine for AMD gfx906 GPUs",
      "detailed_description": "A specialized fork of the vLLM library optimized for AMD gfx906 GPUs (e.g., Radeon VII, MI50, MI60), enabling high-throughput LLM inference on this hardware.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_runtime",
        "llm_serving"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/nlzy/vllm-gfx906",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "amd",
        "rocm",
        "vllm",
        "llm"
      ],
      "id": 978
    },
    {
      "name": "nndeploy",
      "one_line_profile": "Cross-platform high-performance AI model deployment framework",
      "detailed_description": "A comprehensive framework for AI model deployment that supports multiple inference backends (TensorRT, ONNX Runtime, OpenVINO, etc.) and provides a unified C++ interface.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_deployment",
        "inference_runtime"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/nndeploy/nndeploy",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "deployment",
        "inference",
        "cross-platform"
      ],
      "id": 979
    },
    {
      "name": "NNTile",
      "one_line_profile": "Task-based parallel neural network training framework for HPC",
      "detailed_description": "A neural network training framework built on a task-based parallel programming paradigm, designed for high-performance computing environments.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "hpc_acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/nntile/nntile",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "hpc",
        "parallel-computing",
        "training"
      ],
      "id": 980
    },
    {
      "name": "tf-to-xla-to-wasm",
      "one_line_profile": "Toolchain to compile TensorFlow graphs to WebAssembly via XLA",
      "detailed_description": "A utility that compiles TensorFlow graphs into WebAssembly modules using XLA, enabling model execution in web environments.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compilation",
        "webassembly_export"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/nuchi/tf-to-xla-to-wasm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tensorflow",
        "xla",
        "webassembly",
        "compiler"
      ],
      "id": 981
    },
    {
      "name": "DeepCompressor",
      "one_line_profile": "Compression toolbox for LLMs and diffusion models",
      "detailed_description": "A model compression toolbox specifically designed for Large Language Models and Diffusion Models, offering quantization and optimization techniques.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nunchaku-tech/deepcompressor",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "diffusion",
        "compression"
      ],
      "id": 982
    },
    {
      "name": "Nunchaku",
      "one_line_profile": "Inference engine and quantization library for 4-bit diffusion models",
      "detailed_description": "A library implementing SVDQuant for 4-bit quantization of diffusion models, enabling efficient inference by absorbing outliers into low-rank components.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/nunchaku-tech/nunchaku",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-models",
        "quantization",
        "svdquant"
      ],
      "id": 983
    },
    {
      "name": "ComfyUI-FSampler",
      "one_line_profile": "Acceleration layer for diffusion sampling in ComfyUI",
      "detailed_description": "A training-free, sampler-agnostic acceleration layer integrated into ComfyUI to speed up diffusion model sampling.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "image_generation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/obisin/ComfyUI-FSampler",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "comfyui",
        "diffusion",
        "acceleration"
      ],
      "id": 984
    },
    {
      "name": "ONNX-TensorRT",
      "one_line_profile": "TensorRT backend for parsing and executing ONNX models",
      "detailed_description": "A library that parses ONNX models and executes them using the NVIDIA TensorRT inference engine, serving as a critical bridge for deploying ONNX models on NVIDIA GPUs.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compilation",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/onnx/onnx-tensorrt",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "onnx",
        "tensorrt",
        "nvidia"
      ],
      "id": 985
    },
    {
      "name": "OpenVINO Training Extensions",
      "one_line_profile": "Framework for training, optimizing, and deploying CV models with OpenVINO",
      "detailed_description": "A framework that provides workflows for training, evaluating, optimizing, and deploying computer vision models, specifically tailored for the OpenVINO toolkit.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_optimization",
        "deployment_workflow"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/open-edge-platform/training_extensions",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "openvino",
        "computer-vision",
        "optimization"
      ],
      "id": 986
    },
    {
      "name": "MMDeploy",
      "one_line_profile": "Model deployment framework supporting export to multiple inference backends",
      "detailed_description": "A comprehensive model deployment toolbox that provides a unified pipeline to export OpenMMLab models to various inference backends like ONNX Runtime, TensorRT, and ncnn.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_deployment",
        "model_conversion"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/open-mmlab/mmdeploy",
      "help_website": [
        "https://mmdeploy.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "deployment",
        "openmmlab",
        "conversion"
      ],
      "id": 987
    },
    {
      "name": "MMRazor",
      "one_line_profile": "Model compression toolbox for pruning, quantization, and distillation",
      "detailed_description": "A model compression toolbox that includes algorithms for neural network pruning, quantization, knowledge distillation, and architecture search.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "quantization",
        "pruning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/open-mmlab/mmrazor",
      "help_website": [
        "https://mmrazor.readthedocs.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "compression",
        "distillation",
        "nas"
      ],
      "id": 988
    },
    {
      "name": "DI-hpc",
      "one_line_profile": "High-performance operator library for Reinforcement Learning",
      "detailed_description": "A library of optimized CUDA and Triton kernels specifically designed to accelerate Reinforcement Learning operations.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "kernel_optimization",
        "hpc_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/opendilab/DI-hpc",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "reinforcement-learning",
        "cuda",
        "triton"
      ],
      "id": 989
    },
    {
      "name": "ReaLHF",
      "one_line_profile": "Efficient RLHF training system for LLMs",
      "detailed_description": "A system for efficient Reinforcement Learning from Human Feedback (RLHF) training of Large Language Models, utilizing parameter reallocation techniques.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "distributed_training",
        "llm_optimization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/openpsi-project/ReaLHF",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rlhf",
        "llm",
        "training-system"
      ],
      "id": 990
    },
    {
      "name": "XLA",
      "one_line_profile": "Domain-specific compiler for linear algebra and machine learning models",
      "detailed_description": "A machine learning compiler that optimizes linear algebra computations for execution on GPUs, CPUs, and ML accelerators.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compilation",
        "hardware_acceleration"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/openxla/xla",
      "help_website": [
        "https://openxla.org/xla"
      ],
      "license": "Apache-2.0",
      "tags": [
        "compiler",
        "linear-algebra",
        "optimization"
      ],
      "id": 991
    },
    {
      "name": "sd4j",
      "one_line_profile": "Java implementation of Stable Diffusion pipeline using ONNX Runtime",
      "detailed_description": "A library that provides a Stable Diffusion inference pipeline in Java, leveraging ONNX Runtime for execution.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_runtime",
        "image_generation"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/oracle/sd4j",
      "help_website": [],
      "license": "UPL-1.0",
      "tags": [
        "java",
        "stable-diffusion",
        "onnx"
      ],
      "id": 992
    },
    {
      "name": "kvcached",
      "one_line_profile": "Virtualized elastic KV cache system for dynamic GPU sharing",
      "detailed_description": "A system that provides a virtualized, elastic Key-Value (KV) cache to enable efficient dynamic GPU sharing for Large Language Model inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_optimization",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/ovg-project/kvcached",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kv-cache",
        "llm",
        "gpu-sharing"
      ],
      "id": 993
    },
    {
      "name": "onnx_transformers",
      "one_line_profile": "Library for accelerated NLP inference using ONNX Runtime",
      "detailed_description": "A library that provides accelerated NLP pipelines by integrating Hugging Face Transformers with ONNX Runtime for faster CPU inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "nlp_pipeline"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/patil-suraj/onnx_transformers",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nlp",
        "onnx",
        "transformers"
      ],
      "id": 994
    },
    {
      "name": "BambooAI",
      "one_line_profile": "Library for conversational data analysis using LLMs",
      "detailed_description": "A Python library that leverages Large Language Models to perform conversational data discovery, analysis, and visualization.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "data_analysis",
        "scientific_visualization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pgalko/BambooAI",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "data-analysis",
        "llm",
        "visualization"
      ],
      "id": 995
    },
    {
      "name": "neural-imaging",
      "one_line_profile": "Toolbox for modeling and optimizing photo acquisition pipelines",
      "detailed_description": "A Python toolbox for modeling, simulating, and optimizing various stages of photo acquisition and distribution pipelines, including ISP and compression.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "image_processing",
        "pipeline_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pkorus/neural-imaging",
      "help_website": [],
      "license": null,
      "tags": [
        "imaging",
        "isp",
        "optimization"
      ],
      "id": 996
    },
    {
      "name": "FastV",
      "one_line_profile": "Inference acceleration library for Large Vision-Language Models",
      "detailed_description": "A plug-and-play inference acceleration library for Large Vision-Language Models (LVLMs) that reduces computational cost via token pruning.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "token_pruning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pkunlp-icler/FastV",
      "help_website": [],
      "license": null,
      "tags": [
        "lvlm",
        "acceleration",
        "pruning"
      ],
      "id": 997
    },
    {
      "name": "PlaidML",
      "one_line_profile": "Tensor compiler and runtime for deep learning on diverse hardware",
      "detailed_description": "A tensor compiler and runtime framework that enables deep learning on a wide range of hardware devices by using OpenCL and other backends.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compilation",
        "inference_runtime"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/plaidml/plaidml",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compiler",
        "opencl",
        "deep-learning"
      ],
      "id": 998
    },
    {
      "name": "YOLOv5-Lite",
      "one_line_profile": "Lightweight YOLOv5 implementation optimized for edge devices with NPU/GPU support",
      "detailed_description": "A lightweight version of YOLOv5 designed for edge computing devices like Raspberry Pi. It features model pruning and quantization (int8/fp16) to achieve high inference speeds (e.g., 15 FPS on RPi 4B) while maintaining reasonable accuracy, suitable for real-time object detection in resource-constrained scientific or field environments.",
      "domains": [
        "AI6-04",
        "Computer Vision"
      ],
      "subtask_category": [
        "inference_optimization",
        "quantization",
        "edge_computing"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/ppogg/YOLOv5-Lite",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "yolo",
        "quantization",
        "edge-ai",
        "ncnn",
        "mnn"
      ],
      "id": 999
    },
    {
      "name": "DinkyTrain",
      "one_line_profile": "Lightweight pre-training library with DeepSpeed integration",
      "detailed_description": "A pre-training library from Princeton NLP based on fairseq, integrated with DeepSpeed kernels. It is designed to facilitate efficient training of language models, providing a streamlined interface for research into model pre-training and optimization.",
      "domains": [
        "AI6-04",
        "NLP"
      ],
      "subtask_category": [
        "training_acceleration",
        "model_pretraining"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/princeton-nlp/DinkyTrain",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "deepspeed",
        "training",
        "nlp",
        "fairseq"
      ],
      "id": 1000
    },
    {
      "name": "Prometheus-Eval",
      "one_line_profile": "LLM evaluation toolkit using Prometheus and GPT-4",
      "detailed_description": "A toolkit for evaluating Large Language Models (LLMs) by leveraging Prometheus (an open-source evaluator LLM) and GPT-4. It provides a framework for assessing model responses, enabling researchers to perform quality control and comparative analysis of generative models.",
      "domains": [
        "AI11",
        "NLP"
      ],
      "subtask_category": [
        "model_evaluation",
        "quality_control"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/prometheus-eval/prometheus-eval",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm-evaluation",
        "benchmark",
        "prometheus"
      ],
      "id": 1001
    },
    {
      "name": "Torch-TensorRT",
      "one_line_profile": "PyTorch compiler for NVIDIA GPUs using TensorRT",
      "detailed_description": "A compiler for PyTorch/TorchScript/FX that targets NVIDIA GPUs using NVIDIA's TensorRT deep learning optimizer and runtime. It accelerates inference for PyTorch models by leveraging TensorRT's optimizations while maintaining the ease of use of the PyTorch ecosystem.",
      "domains": [
        "AI6-04",
        "AI Infra"
      ],
      "subtask_category": [
        "compiler",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pytorch/TensorRT",
      "help_website": [
        "https://pytorch.org/TensorRT/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "pytorch",
        "tensorrt",
        "inference",
        "compiler",
        "gpu"
      ],
      "id": 1002
    },
    {
      "name": "PyTorch-ORT",
      "one_line_profile": "PyTorch acceleration via ONNX Runtime",
      "detailed_description": "A library that accelerates PyTorch model training and inference by integrating with ONNX Runtime. It allows users to run PyTorch models with the performance benefits of ONNX Runtime's optimizations without leaving the PyTorch environment.",
      "domains": [
        "AI6-04",
        "AI Infra"
      ],
      "subtask_category": [
        "inference_acceleration",
        "training_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/pytorch/ort",
      "help_website": [
        "https://onnxruntime.ai/"
      ],
      "license": "MIT",
      "tags": [
        "onnx-runtime",
        "pytorch",
        "acceleration"
      ],
      "id": 1003
    },
    {
      "name": "PyTorch XLA",
      "one_line_profile": "PyTorch support for XLA devices (TPU/GPU)",
      "detailed_description": "A Python package that connects PyTorch to the XLA (Accelerated Linear Algebra) compiler, enabling PyTorch models to run on high-performance XLA devices such as Google TPUs and GPUs. It provides the necessary runtime and compiler integration for scaling PyTorch workloads.",
      "domains": [
        "AI6-04",
        "AI Infra"
      ],
      "subtask_category": [
        "compiler",
        "training_acceleration",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/pytorch/xla",
      "help_website": [
        "https://github.com/pytorch/xla"
      ],
      "license": "NOASSERTION",
      "tags": [
        "xla",
        "tpu",
        "pytorch",
        "compiler"
      ],
      "id": 1004
    },
    {
      "name": "async_cosyvoice",
      "one_line_profile": "Accelerated inference for CosyVoice2 using vLLM",
      "detailed_description": "A tool designed to accelerate the inference of the CosyVoice2 text-to-speech model by leveraging vLLM (a high-throughput and memory-efficient LLM serving engine). It optimizes the runtime performance for audio generation tasks.",
      "domains": [
        "AI6-04",
        "Audio"
      ],
      "subtask_category": [
        "inference_acceleration",
        "audio_generation"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/qi-hua/async_cosyvoice",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vllm",
        "cosyvoice",
        "inference",
        "tts"
      ],
      "id": 1005
    },
    {
      "name": "AIMET",
      "one_line_profile": "AI Model Efficiency Toolkit for quantization and compression",
      "detailed_description": "A library that provides advanced model quantization and compression techniques for trained neural networks. It helps in reducing model size and improving inference latency on edge devices while maintaining accuracy, supporting both post-training quantization and quantization-aware training.",
      "domains": [
        "AI6-04",
        "AI Infra"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/quic/aimet",
      "help_website": [
        "https://quic.github.io/aimet-pages/index.html"
      ],
      "license": "NOASSERTION",
      "tags": [
        "quantization",
        "compression",
        "neural-networks"
      ],
      "id": 1006
    },
    {
      "name": "Chatterbox-vLLM",
      "one_line_profile": "vLLM port of the Chatterbox TTS model",
      "detailed_description": "A port of the Chatterbox Text-to-Speech model to the vLLM inference engine. This tool enables high-performance serving of the Chatterbox model, leveraging vLLM's memory management and batching capabilities for efficient audio synthesis.",
      "domains": [
        "AI6-04",
        "Audio"
      ],
      "subtask_category": [
        "inference_acceleration",
        "inference_serving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/randombk/chatterbox-vllm",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vllm",
        "tts",
        "inference"
      ],
      "id": 1007
    },
    {
      "name": "ComfyUI_Step1X-Edit",
      "one_line_profile": "TeaCache acceleration plugin for ComfyUI",
      "detailed_description": "A plugin for ComfyUI that implements TeaCache acceleration, enabling up to 2x faster inference for generative models with minimal quality loss. It serves as an optimization tool for image generation workflows.",
      "domains": [
        "AI6-04",
        "Generative AI"
      ],
      "subtask_category": [
        "inference_acceleration",
        "caching"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/raykindle/ComfyUI_Step1X-Edit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "comfyui",
        "acceleration",
        "teacache"
      ],
      "id": 1008
    },
    {
      "name": "RZV DRP-AI TVM",
      "one_line_profile": "Apache TVM extension for Renesas DRP-AI accelerators",
      "detailed_description": "An extension package for the Apache TVM machine learning compiler, specifically designed to support Renesas DRP-AI accelerators. It enables the compilation and optimization of deep learning models for deployment on Renesas hardware.",
      "domains": [
        "AI6-04",
        "Embedded AI"
      ],
      "subtask_category": [
        "compiler",
        "hardware_acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/renesas-rz/rzv_drp-ai_tvm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "tvm",
        "compiler",
        "drp-ai",
        "renesas"
      ],
      "id": 1009
    },
    {
      "name": "FreeTensor",
      "one_line_profile": "Language and compiler for irregular tensor programs",
      "detailed_description": "A domain-specific language and compiler designed for optimizing irregular tensor programs. It targets high-performance computing scenarios where standard tensor compilers may struggle with irregular data structures or access patterns.",
      "domains": [
        "AI6-04",
        "HPC"
      ],
      "subtask_category": [
        "compiler",
        "tensor_computation"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/roastduck/FreeTensor",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compiler",
        "tensor",
        "hpc",
        "irregular-computation"
      ],
      "id": 1010
    },
    {
      "name": "Roboflow Inference",
      "one_line_profile": "High-performance inference server for computer vision",
      "detailed_description": "A comprehensive inference server and library for running computer vision models on various devices (edge to cloud). It provides a unified interface for deploying models, managing inference pipelines, and optimizing runtime performance.",
      "domains": [
        "AI6-04",
        "Computer Vision"
      ],
      "subtask_category": [
        "inference_serving",
        "deployment"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/roboflow/inference",
      "help_website": [
        "https://inference.roboflow.com/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "inference-server",
        "computer-vision",
        "deployment"
      ],
      "id": 1011
    },
    {
      "name": "l2hmc-qcd",
      "one_line_profile": "L2HMC algorithm implementation for Lattice QCD simulations",
      "detailed_description": "An implementation of the L2HMC (Learning to Hamiltonian Monte Carlo) algorithm specifically applied to simulations in Lattice Quantum Chromodynamics (QCD). It serves as a computational tool for physics research, enabling more efficient sampling in high-dimensional spaces.",
      "domains": [
        "AI4S",
        "Physics"
      ],
      "subtask_category": [
        "simulation",
        "lattice_qcd",
        "sampling"
      ],
      "application_level": "solver",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/saforem2/l2hmc-qcd",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "l2hmc",
        "lattice-qcd",
        "physics-simulation",
        "mcmc"
      ],
      "id": 1012
    },
    {
      "name": "HLOEnv",
      "one_line_profile": "RL environment for XLA compiler optimization research",
      "detailed_description": "A research environment based on XLA (Accelerated Linear Algebra) designed for deep learning compiler optimization. It allows researchers to apply reinforcement learning techniques to optimize HLO (High Level Optimizer) passes and graph transformations.",
      "domains": [
        "AI6-04",
        "Compiler Research"
      ],
      "subtask_category": [
        "compiler_optimization",
        "reinforcement_learning"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/sail-sg/hloenv",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "xla",
        "compiler",
        "reinforcement-learning",
        "optimization"
      ],
      "id": 1013
    },
    {
      "name": "Sbnb Linux",
      "one_line_profile": "Linux distribution optimized for AI workloads",
      "detailed_description": "A specialized Linux distribution designed for AI computers, automating the setup and execution of AI workloads like vLLM, SGLang, and RAG pipelines. It serves as an infrastructure platform to facilitate reproducible AI research and deployment.",
      "domains": [
        "AI6",
        "AI Infra"
      ],
      "subtask_category": [
        "environment_management",
        "infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "Shell",
      "repo_url": "https://github.com/sbnb-io/sbnb",
      "help_website": [
        "https://sbnb.io"
      ],
      "license": "MIT",
      "tags": [
        "linux-distro",
        "ai-infrastructure",
        "vllm"
      ],
      "id": 1014
    },
    {
      "name": "Red Candle",
      "one_line_profile": "Ruby interface for local LLM inference via Candle",
      "detailed_description": "A Ruby gem that provides an interface to run state-of-the-art language models locally, powered by the Rust-based Candle framework. It supports Metal/CUDA acceleration, enabling Ruby-based scientific workflows to leverage efficient local LLM inference.",
      "domains": [
        "AI6-04",
        "NLP"
      ],
      "subtask_category": [
        "inference_acceleration",
        "inference_serving"
      ],
      "application_level": "library",
      "primary_language": "Rust",
      "repo_url": "https://github.com/scientist-labs/red-candle",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ruby",
        "candle",
        "llm",
        "inference"
      ],
      "id": 1015
    },
    {
      "name": "ScatterMoE",
      "one_line_profile": "Triton-based Sparse Mixture of Experts implementation",
      "detailed_description": "A high-performance implementation of Sparse Mixture of Experts (MoE) using OpenAI's Triton language. It provides efficient kernels for training and inference of MoE models, serving as a building block for large-scale model acceleration.",
      "domains": [
        "AI6-04",
        "AI Infra"
      ],
      "subtask_category": [
        "training_acceleration",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/shawntan/scattermoe",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "triton",
        "moe",
        "mixture-of-experts",
        "acceleration"
      ],
      "id": 1016
    },
    {
      "name": "TensorRT_Pro",
      "one_line_profile": "C++ library for easy TensorRT integration",
      "detailed_description": "A C++ library that simplifies the integration and usage of NVIDIA TensorRT. It provides a high-level API for loading models, managing memory, and executing inference, aiming to streamline the deployment of accelerated deep learning models.",
      "domains": [
        "AI6-04",
        "AI Infra"
      ],
      "subtask_category": [
        "inference_acceleration",
        "deployment"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/shouxieai/tensorRT_Pro",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tensorrt",
        "c++",
        "inference",
        "wrapper"
      ],
      "id": 1017
    },
    {
      "name": "chatGLM-6B-QLoRA",
      "one_line_profile": "Efficient fine-tuning and quantization implementation for ChatGLM models",
      "detailed_description": "A specific implementation for 4-bit QLoRA fine-tuning of ChatGLM-6B/ChatGLM2-6B models, including LoRA model merging and 4-bit quantization capabilities.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "model_quantization",
        "fine_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/shuxueslpi/chatGLM-6B-QLoRA",
      "help_website": [],
      "license": null,
      "tags": [
        "qlora",
        "quantization",
        "llm",
        "chatglm"
      ],
      "id": 1018
    },
    {
      "name": "Tacker",
      "one_line_profile": "Tensor-CUDA Core Kernel Fusion for Improving GPU Utilization",
      "detailed_description": "A kernel fusion tool that leverages Tensor Cores and CUDA Cores to improve GPU utilization while ensuring QoS, specifically designed for optimizing deep learning workloads.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "kernel_optimization",
        "gpu_acceleration"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/sjtu-epcc/Tacker",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "kernel-fusion",
        "cuda",
        "gpu-optimization"
      ],
      "id": 1019
    },
    {
      "name": "ArcticInference",
      "one_line_profile": "vLLM plugin for high-throughput, low-latency inference",
      "detailed_description": "A plugin for vLLM designed to enable high-throughput and low-latency inference, specifically optimized for Snowflake's Arctic models and enterprise-grade workloads.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_serving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/snowflakedb/ArcticInference",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "vllm",
        "inference",
        "llm"
      ],
      "id": 1020
    },
    {
      "name": "llms_tool",
      "one_line_profile": "Toolkit for LLM training, testing, quantization and deployment",
      "detailed_description": "A comprehensive tool based on HuggingFace for Large Language Model training (Pre-training, SFT, RM, PPO, DPO), testing, quantization, and model fusion.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "model_training",
        "model_quantization",
        "fine_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/stanleylsx/llms_tool",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "quantization",
        "fine-tuning",
        "rlhf"
      ],
      "id": 1021
    },
    {
      "name": "catgrad",
      "one_line_profile": "A categorical deep learning compiler",
      "detailed_description": "A compiler for deep learning that leverages categorical concepts, providing a framework for compiling and optimizing neural network models.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "model_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/statusfailed/catgrad",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "compiler",
        "deep-learning",
        "category-theory"
      ],
      "id": 1022
    },
    {
      "name": "llm_finetuning",
      "one_line_profile": "Wrapper for LLM fine-tuning and inference with quantization",
      "detailed_description": "A convenient wrapper tool for fine-tuning and running inference on Large Language Models, supporting quantization techniques like GPTQ and bitsandbytes.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "fine_tuning",
        "model_quantization",
        "inference"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/taprosoft/llm_finetuning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "gptq",
        "bitsandbytes",
        "fine-tuning"
      ],
      "id": 1023
    },
    {
      "name": "Tensara",
      "one_line_profile": "Competitive GPU kernel optimization platform",
      "detailed_description": "A platform designed for optimizing GPU kernels, likely providing tools or frameworks to benchmark and improve kernel performance for deep learning or scientific computing.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "kernel_optimization",
        "gpu_acceleration"
      ],
      "application_level": "platform",
      "primary_language": "TypeScript",
      "repo_url": "https://github.com/tensara/tensara",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "gpu",
        "optimization",
        "kernel"
      ],
      "id": 1024
    },
    {
      "name": "taco",
      "one_line_profile": "The Tensor Algebra Compiler",
      "detailed_description": "A compiler that computes sparse tensor expressions on CPUs and GPUs, automatically generating efficient code for complex tensor algebra operations used in scientific computing and machine learning.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "tensor_algebra",
        "sparse_computation"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/tensor-compiler/taco",
      "help_website": [
        "http://tensor-compiler.org"
      ],
      "license": "NOASSERTION",
      "tags": [
        "compiler",
        "tensor-algebra",
        "sparse-tensors"
      ],
      "id": 1025
    },
    {
      "name": "TensorFlow Model Optimization Toolkit",
      "one_line_profile": "Toolkit to optimize ML models for deployment",
      "detailed_description": "A suite of tools for optimizing machine learning models for deployment and execution, including techniques like quantization and pruning to reduce model size and improve latency.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "model_quantization",
        "model_pruning",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tensorflow/model-optimization",
      "help_website": [
        "https://www.tensorflow.org/model_optimization"
      ],
      "license": "Apache-2.0",
      "tags": [
        "tensorflow",
        "quantization",
        "pruning",
        "optimization"
      ],
      "id": 1026
    },
    {
      "name": "HyperPose",
      "one_line_profile": "Library for Fast and Flexible Human Pose Estimation",
      "detailed_description": "A library built on TensorLayer for high-performance human pose estimation, focusing on acceleration and flexibility for real-time applications and research.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "pose_estimation",
        "inference_acceleration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tensorlayer/HyperPose",
      "help_website": [],
      "license": null,
      "tags": [
        "pose-estimation",
        "tensorlayer",
        "acceleration"
      ],
      "id": 1027
    },
    {
      "name": "tt-forge-fe",
      "one_line_profile": "Graph compiler for Tenstorrent hardware",
      "detailed_description": "A graph compiler frontend designed to optimize and transform computational graphs for deep learning models, specifically targeting Tenstorrent's AI hardware accelerators.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "graph_optimization"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tenstorrent/tt-forge-fe",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compiler",
        "tenstorrent",
        "graph-optimization"
      ],
      "id": 1028
    },
    {
      "name": "tt-xla",
      "one_line_profile": "PJRT device implementation for Tenstorrent AI Compiler",
      "detailed_description": "Implementation of a PJRT (Pretty Just-In-Time Runtime) device for Tenstorrent's AI compiler stack, enabling XLA (Accelerated Linear Algebra) compatibility.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "backend_integration"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/tenstorrent/tt-xla",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "xla",
        "compiler",
        "tenstorrent"
      ],
      "id": 1029
    },
    {
      "name": "SageAttention",
      "one_line_profile": "Quantized Attention acceleration library",
      "detailed_description": "A library implementing Quantized Attention that achieves significant speedups compared to FlashAttention without losing accuracy, applicable to language, image, and video models.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "attention_acceleration",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/thu-ml/SageAttention",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "attention",
        "quantization",
        "acceleration",
        "cuda"
      ],
      "id": 1030
    },
    {
      "name": "SpargeAttn",
      "one_line_profile": "Training-free sparse attention for inference acceleration",
      "detailed_description": "A library implementing SpargeAttention, a training-free sparse attention mechanism designed to accelerate model inference across various architectures.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "attention_acceleration",
        "sparse_computation"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/thu-ml/SpargeAttn",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "sparse-attention",
        "inference-acceleration",
        "cuda"
      ],
      "id": 1031
    },
    {
      "name": "DAMO-YOLO",
      "one_line_profile": "Fast and accurate object detection method with NAS and distillation",
      "detailed_description": "A high-performance object detection framework incorporating Neural Architecture Search (NAS) backbones, efficient RepGFPN, and distillation enhancement for accelerated inference.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "object_detection",
        "model_distillation",
        "nas"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tinyvision/DAMO-YOLO",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "object-detection",
        "yolo",
        "nas",
        "distillation"
      ],
      "id": 1032
    },
    {
      "name": "TonY",
      "one_line_profile": "Framework to natively run deep learning on Apache Hadoop",
      "detailed_description": "TonY (TensorFlow on YARN) is a framework for running distributed deep learning jobs (TensorFlow, PyTorch, etc.) on Apache Hadoop clusters, enabling scalable scientific computing.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "distributed_training",
        "job_scheduling"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/tony-framework/TonY",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hadoop",
        "distributed-training",
        "yarn"
      ],
      "id": 1033
    },
    {
      "name": "llama.onnx",
      "one_line_profile": "ONNX export and quantization tools for LLaMa/RWKV",
      "detailed_description": "A set of tools and scripts for converting LLaMa and RWKV models to ONNX format and performing quantization to enable efficient inference.",
      "domains": [
        "AI6-04"
      ],
      "subtask_category": [
        "model_quantization",
        "model_conversion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/tpoisonooo/llama.onnx",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "onnx",
        "quantization",
        "llama",
        "rwkv"
      ],
      "id": 1034
    },
    {
      "name": "GDS3D",
      "one_line_profile": "3D hardware accelerated viewer for GDSII IC layouts",
      "detailed_description": "An application that interprets IC layouts (GDSII files) and renders them in 3D, allowing real-time control over camera position and angle for inspecting chip designs.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "scientific_visualization",
        "chip_design"
      ],
      "application_level": "application",
      "primary_language": "C++",
      "repo_url": "https://github.com/trilomix/GDS3D",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "gdsii",
        "3d-rendering",
        "ic-layout",
        "visualization"
      ],
      "id": 1035
    },
    {
      "name": "YOLOv8-TensorRT",
      "one_line_profile": "TensorRT implementation for YOLOv8 acceleration",
      "detailed_description": "A C++ and Python implementation for accelerating YOLOv8 object detection models using NVIDIA TensorRT, optimized for high-performance inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "computer_vision"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/triple-Mu/YOLOv8-TensorRT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tensorrt",
        "yolov8",
        "inference",
        "acceleration"
      ],
      "id": 1036
    },
    {
      "name": "Triton Backend",
      "one_line_profile": "Utilities for creating custom Triton Inference Server backends",
      "detailed_description": "Common source code, scripts, and utilities designed to facilitate the creation and maintenance of backends for the Triton Inference Server.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_serving",
        "backend_development"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/triton-inference-server/backend",
      "help_website": [
        "https://github.com/triton-inference-server/server"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "triton",
        "inference-server",
        "backend"
      ],
      "id": 1037
    },
    {
      "name": "Triton Client",
      "one_line_profile": "Client libraries for Triton Inference Server",
      "detailed_description": "Provides Python, C++, and Java client libraries, along with GRPC-generated examples, to interact with the Triton Inference Server for sending inference requests.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_serving",
        "client_interface"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/triton-inference-server/client",
      "help_website": [
        "https://github.com/triton-inference-server/server"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "triton",
        "client",
        "grpc",
        "http"
      ],
      "id": 1038
    },
    {
      "name": "Triton Model Analyzer",
      "one_line_profile": "Profiling tool for Triton model compute and memory requirements",
      "detailed_description": "A CLI tool that helps users understand the compute and memory requirements of models served by Triton Inference Server, enabling configuration optimization.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "profiling",
        "optimization"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/triton-inference-server/model_analyzer",
      "help_website": [
        "https://github.com/triton-inference-server/server"
      ],
      "license": "Apache-2.0",
      "tags": [
        "profiling",
        "optimization",
        "triton",
        "inference"
      ],
      "id": 1039
    },
    {
      "name": "Triton Model Navigator",
      "one_line_profile": "Toolkit for optimizing and deploying DL models on NVIDIA GPUs",
      "detailed_description": "An inference toolkit designed to automate the process of moving deep learning models from training to deployment, focusing on optimization for NVIDIA GPUs within the Triton ecosystem.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_optimization",
        "deployment"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/triton-inference-server/model_navigator",
      "help_website": [
        "https://github.com/triton-inference-server/server"
      ],
      "license": "Apache-2.0",
      "tags": [
        "deployment",
        "optimization",
        "nvidia",
        "triton"
      ],
      "id": 1040
    },
    {
      "name": "Triton ONNX Runtime Backend",
      "one_line_profile": "ONNX Runtime integration for Triton Inference Server",
      "detailed_description": "The backend implementation that allows Triton Inference Server to execute models using the ONNX Runtime engine.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_serving",
        "runtime_integration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/triton-inference-server/onnxruntime_backend",
      "help_website": [
        "https://github.com/triton-inference-server/server"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "onnx",
        "triton",
        "backend"
      ],
      "id": 1041
    },
    {
      "name": "Triton Python Backend",
      "one_line_profile": "Python execution backend for Triton Inference Server",
      "detailed_description": "Enables pre-processing, post-processing, and other custom logic to be implemented in Python and executed within the Triton Inference Server pipeline.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_serving",
        "custom_logic"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/triton-inference-server/python_backend",
      "help_website": [
        "https://github.com/triton-inference-server/server"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "python",
        "triton",
        "backend"
      ],
      "id": 1042
    },
    {
      "name": "PyTriton",
      "one_line_profile": "Python interface for deploying models with Triton",
      "detailed_description": "A Flask/FastAPI-like interface that simplifies the deployment of Python models and functions using Triton Inference Server, allowing developers to bind Python functions to Triton endpoints.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_serving",
        "deployment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/triton-inference-server/pytriton",
      "help_website": [
        "https://triton-inference-server.github.io/pytriton"
      ],
      "license": "Apache-2.0",
      "tags": [
        "python",
        "serving",
        "triton",
        "deployment"
      ],
      "id": 1043
    },
    {
      "name": "Triton Inference Server",
      "one_line_profile": "High-performance inference serving platform",
      "detailed_description": "An open-source inference serving software that streamlines AI inference by enabling teams to deploy, run, and scale trained AI models from any framework on any GPU- or CPU-based infrastructure.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_serving",
        "platform"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/triton-inference-server/server",
      "help_website": [
        "https://developer.nvidia.com/nvidia-triton-inference-server"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "inference",
        "server",
        "gpu",
        "cloud",
        "edge"
      ],
      "id": 1044
    },
    {
      "name": "Triton TensorRT-LLM Backend",
      "one_line_profile": "TensorRT-LLM integration for Triton Inference Server",
      "detailed_description": "A backend for Triton Inference Server that enables the execution of Large Language Models (LLMs) optimized with NVIDIA TensorRT-LLM.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_serving",
        "llm_acceleration"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/triton-inference-server/tensorrtllm_backend",
      "help_website": [
        "https://github.com/triton-inference-server/server"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "tensorrt",
        "triton",
        "backend"
      ],
      "id": 1045
    },
    {
      "name": "Triton",
      "one_line_profile": "Language and compiler for custom Deep Learning primitives",
      "detailed_description": "A language and compiler for writing highly efficient custom Deep Learning primitives. It aims to provide an open-source environment to write fast code at higher productivity than CUDA.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "kernel_optimization"
      ],
      "application_level": "library",
      "primary_language": "MLIR",
      "repo_url": "https://github.com/triton-lang/triton",
      "help_website": [
        "https://triton-lang.org/"
      ],
      "license": "MIT",
      "tags": [
        "compiler",
        "gpu",
        "cuda",
        "optimization",
        "deep-learning"
      ],
      "id": 1046
    },
    {
      "name": "TrustGraph",
      "one_line_profile": "Graph-based tool to reduce AI hallucinations",
      "detailed_description": "A tool designed to eliminate hallucinations from AI agents by leveraging knowledge graphs and trusted data sources to ground the generation process.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "knowledge_graph",
        "ai_reliability"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/trustgraph-ai/trustgraph",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hallucination",
        "knowledge-graph",
        "ai-agent",
        "reliability"
      ],
      "id": 1047
    },
    {
      "name": "Petastorm",
      "one_line_profile": "Data access library for deep learning from Parquet",
      "detailed_description": "A library that enables single machine or distributed training and evaluation of deep learning models directly from datasets in Apache Parquet format, supporting TensorFlow, PyTorch, and PySpark.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "data_loading",
        "distributed_training"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/uber/petastorm",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "parquet",
        "data-loading",
        "deep-learning",
        "distributed-training"
      ],
      "id": 1048
    },
    {
      "name": "Telamon",
      "one_line_profile": "Optimization framework for GPU computational kernels",
      "detailed_description": "A framework designed to explore and find optimal combinations of optimizations for computational kernels running on GPUs, acting as an auto-tuning tool.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "kernel_optimization",
        "auto_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/ulysseB/telamon",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu",
        "optimization",
        "kernel",
        "auto-tuning"
      ],
      "id": 1049
    },
    {
      "name": "SparseTIR",
      "one_line_profile": "Sparse tensor compiler for deep learning",
      "detailed_description": "A compiler infrastructure for sparse tensor algebra in deep learning, enabling efficient execution of sparse operations on hardware accelerators.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "sparse_computation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/uwsampl/SparseTIR",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compiler",
        "sparse-tensor",
        "deep-learning",
        "optimization"
      ],
      "id": 1050
    },
    {
      "name": "Cache-DiT",
      "one_line_profile": "Inference engine with cache acceleration for Diffusion Transformers",
      "detailed_description": "A PyTorch-native inference engine that utilizes hybrid cache acceleration and parallelism to speed up Diffusion Transformer (DiT) models like Z-Image and FLUX2.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "diffusion_models"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/vipshop/cache-dit",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "diffusion-transformer",
        "inference",
        "cache",
        "acceleration"
      ],
      "id": 1051
    },
    {
      "name": "LLM Compressor",
      "one_line_profile": "Library for compressing LLMs for vLLM deployment",
      "detailed_description": "A library compatible with Transformers for applying various compression algorithms (quantization, sparsification) to Large Language Models to optimize them for deployment with vLLM.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_compression",
        "quantization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vllm-project/llm-compressor",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "compression",
        "quantization",
        "vllm"
      ],
      "id": 1052
    },
    {
      "name": "Semantic Router",
      "one_line_profile": "Routing layer for Mixture-of-Models and LLM agents",
      "detailed_description": "An intelligent routing tool for AI systems that directs queries to the most appropriate model or agent based on semantic meaning, optimizing resource usage and response quality.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_routing",
        "model_orchestration"
      ],
      "application_level": "library",
      "primary_language": "Go",
      "repo_url": "https://github.com/vllm-project/semantic-router",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "routing",
        "llm",
        "mixture-of-models",
        "agent"
      ],
      "id": 1053
    },
    {
      "name": "vLLM Ascend",
      "one_line_profile": "Ascend NPU hardware plugin for vLLM",
      "detailed_description": "A community-maintained plugin that enables vLLM to run on Huawei Ascend hardware, providing hardware-specific optimizations for LLM inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "hardware_acceleration",
        "inference_serving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vllm-project/vllm-ascend",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ascend",
        "npu",
        "vllm",
        "hardware-support"
      ],
      "id": 1054
    },
    {
      "name": "vLLM Omni",
      "one_line_profile": "Inference framework for omni-modality models",
      "detailed_description": "An extension of the vLLM framework designed to support efficient inference for omni-modality models (processing text, image, audio, etc. simultaneously).",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "multimodal_inference",
        "serving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/vllm-project/vllm-omni",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "multimodal",
        "inference",
        "vllm",
        "omni-modality"
      ],
      "id": 1055
    },
    {
      "name": "PytorchAutoDrive",
      "one_line_profile": "Toolkit for segmentation and lane detection in autonomous driving",
      "detailed_description": "A PyTorch-based toolkit providing implementations of various segmentation and lane detection models (ERFNet, SCNN, etc.) along with tools for training, visualization, benchmarking, and deployment.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "computer_vision",
        "autonomous_driving"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/voldemortX/pytorch-auto-drive",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "autonomous-driving",
        "segmentation",
        "lane-detection",
        "pytorch"
      ],
      "id": 1056
    },
    {
      "name": "TensorRTx",
      "one_line_profile": "TensorRT implementations of popular deep learning networks",
      "detailed_description": "A comprehensive collection of TensorRT network definition API implementations for popular deep learning models, serving as a reference and library for accelerating these models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_implementation"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/wang-xinyu/tensorrtx",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tensorrt",
        "deep-learning",
        "acceleration",
        "inference"
      ],
      "id": 1057
    },
    {
      "name": "3d-model-convert-to-gltf",
      "one_line_profile": "Converter for 3D models to glTF format",
      "detailed_description": "A utility tool to convert various 3D model formats (STL, IGES, STEP, OBJ, FBX) into the glTF format, often used for efficient transmission and loading of 3D scenes.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "data_conversion",
        "scientific_visualization"
      ],
      "application_level": "application",
      "primary_language": "Python",
      "repo_url": "https://github.com/wangerzi/3d-model-convert-to-gltf",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "3d-model",
        "converter",
        "gltf",
        "visualization"
      ],
      "id": 1058
    },
    {
      "name": "QLLM",
      "one_line_profile": "Quantization toolbox for Large Language Models",
      "detailed_description": "A general quantization toolbox supporting 2-8 bit quantization methods like GPTQ, AWQ, HQQ, and VPTQ, with capabilities to export models to ONNX/ONNX Runtime.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wejoncy/QLLM",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "llm",
        "onnx",
        "compression"
      ],
      "id": 1059
    },
    {
      "name": "QDrop",
      "one_line_profile": "Post-training quantization method implementation",
      "detailed_description": "The official implementation of the QDrop method for randomly dropping quantization during post-training quantization to achieve better performance with low-bit models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wimh966/QDrop",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "quantization",
        "ptq",
        "deep-learning",
        "optimization"
      ],
      "id": 1060
    },
    {
      "name": "QwT",
      "one_line_profile": "Post-training quantization library with lightweight linear compensation",
      "detailed_description": "A PyTorch implementation of 'Quantization without Tears' (QwT) that provides fast and accurate post-training network quantization using lightweight linear compensation layers to minimize accuracy loss.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/wujx2001/QwT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "pytorch",
        "post-training-quantization"
      ],
      "id": 1061
    },
    {
      "name": "rknn-3588-npu-yolo-accelerate",
      "one_line_profile": "YOLOv5 inference acceleration on RK3588 NPU",
      "detailed_description": "A C++ implementation for deploying and accelerating YOLOv5 object detection models on Rockchip RK3588 NPUs, utilizing thread pools for efficient inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "edge_computing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/wzxzhuxi/rknn-3588-npu-yolo-accelerate",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "rknn",
        "npu",
        "yolov5",
        "inference"
      ],
      "id": 1062
    },
    {
      "name": "libonnx",
      "one_line_profile": "Lightweight pure C99 ONNX inference engine",
      "detailed_description": "A portable and lightweight ONNX inference engine written in pure C99, designed for embedded devices with support for hardware acceleration.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_engine",
        "embedded_ai"
      ],
      "application_level": "library",
      "primary_language": "C",
      "repo_url": "https://github.com/xboot/libonnx",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "onnx",
        "inference",
        "embedded",
        "c99"
      ],
      "id": 1063
    },
    {
      "name": "xlang",
      "one_line_profile": "High-performance dynamic language for AI and IoT",
      "detailed_description": "A next-generation dynamic programming language designed for AI and IoT applications, featuring built-in distributed computing capabilities and high performance.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "programming_language"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/xlang-foundation/xlang",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "language",
        "compiler",
        "distributed-computing"
      ],
      "id": 1064
    },
    {
      "name": "lite.ai.toolkit",
      "one_line_profile": "C++ AI toolkit wrapping MNN, ONNXRuntime, and TensorRT",
      "detailed_description": "A lightweight C++ toolkit that integrates multiple inference backends (MNN, ONNXRuntime, TensorRT) to support over 100 models for tasks like detection, segmentation, and generation.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_deployment"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/xlite-dev/lite.ai.toolkit",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "inference",
        "mnn",
        "tensorrt",
        "onnxruntime"
      ],
      "id": 1065
    },
    {
      "name": "onnx_runtime_cpp",
      "one_line_profile": "Simplified C++ wrapper for ONNX Runtime",
      "detailed_description": "A small C++ library designed to facilitate the quick deployment of machine learning models using ONNX Runtime, providing a simplified interface for inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_deployment",
        "model_serving"
      ],
      "application_level": "library",
      "primary_language": "C++",
      "repo_url": "https://github.com/xmba15/onnx_runtime_cpp",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "onnx-runtime",
        "cpp",
        "inference"
      ],
      "id": 1066
    },
    {
      "name": "Xinference",
      "one_line_profile": "Unified inference platform for LLMs and multimodal models",
      "detailed_description": "A production-ready inference platform that allows running open-source LLMs, speech, and multimodal models on cloud or on-premise infrastructure with a unified API compatible with GPT.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_serving",
        "llm_inference"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/xorbitsai/inference",
      "help_website": [
        "https://inference.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "inference-server",
        "distributed-inference"
      ],
      "id": 1067
    },
    {
      "name": "local-dream",
      "one_line_profile": "Stable Diffusion inference on Android with NPU acceleration",
      "detailed_description": "An application and toolkit for running Stable Diffusion models on Android devices, leveraging Snapdragon NPU acceleration as well as CPU/GPU support.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "mobile_inference",
        "generative_ai"
      ],
      "application_level": "solver",
      "primary_language": "Kotlin",
      "repo_url": "https://github.com/xororz/local-dream",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "android",
        "stable-diffusion",
        "npu",
        "inference"
      ],
      "id": 1068
    },
    {
      "name": "GlobalCom2",
      "one_line_profile": "Plug-and-play inference acceleration for LVLMs",
      "detailed_description": "A tool implementing 'Global Compression Commander' for accelerating high-resolution Large Vision-Language Models (LVLMs) inference through token compression.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "model_compression"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/xuyang-liu16/GlobalCom2",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "lvlm",
        "compression",
        "acceleration"
      ],
      "id": 1069
    },
    {
      "name": "VidCom2",
      "one_line_profile": "Inference acceleration for Video LLMs",
      "detailed_description": "A plug-and-play tool for accelerating Video Large Language Models inference via video compression techniques, as presented at EMNLP 2025.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "video_processing"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/xuyang-liu16/VidCom2",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "video-llm",
        "compression",
        "inference"
      ],
      "id": 1070
    },
    {
      "name": "LOPQ",
      "one_line_profile": "Locally Optimized Product Quantization for ANN search",
      "detailed_description": "A library for training Locally Optimized Product Quantization (LOPQ) models to enable efficient approximate nearest neighbor search for high-dimensional data.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "ann_search"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/yahoo/lopq",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "ann",
        "search",
        "spark"
      ],
      "id": 1071
    },
    {
      "name": "face-parsing",
      "one_line_profile": "Real-time face parsing inference with ONNX Runtime",
      "detailed_description": "A tool for real-time face parsing using BiSeNet, providing a pipeline from PyTorch training to ONNX Runtime inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "image_segmentation",
        "inference_deployment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yakhyo/face-parsing",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "face-parsing",
        "onnx",
        "segmentation"
      ],
      "id": 1072
    },
    {
      "name": "face-reidentification",
      "one_line_profile": "Face re-identification pipeline with FAISS and ONNX",
      "detailed_description": "A complete pipeline for face re-identification integrating SCRFD for detection, ArcFace for recognition, and FAISS for vector search, optimized for ONNX Runtime inference.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "face_recognition",
        "inference_pipeline"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yakhyo/face-reidentification",
      "help_website": [],
      "license": null,
      "tags": [
        "face-reid",
        "faiss",
        "onnx"
      ],
      "id": 1073
    },
    {
      "name": "gaze-estimation",
      "one_line_profile": "Real-time gaze estimation inference models",
      "detailed_description": "A collection of real-time gaze estimation models (ResNet, MobileNet, etc.) optimized for inference using ONNX Runtime.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "gaze_estimation",
        "inference_deployment"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yakhyo/gaze-estimation",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gaze-estimation",
        "onnx",
        "real-time"
      ],
      "id": 1074
    },
    {
      "name": "Monocular_Depth_Estimation_TRT",
      "one_line_profile": "TensorRT optimization for monocular depth estimation",
      "detailed_description": "A toolkit for optimizing monocular depth estimation models using TensorRT, including model conversion and inference acceleration for 3D reconstruction tasks.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "depth_estimation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/yester31/Monocular_Depth_Estimation_TRT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "tensorrt",
        "depth-estimation",
        "acceleration"
      ],
      "id": 1075
    },
    {
      "name": "LLM-SFT",
      "one_line_profile": "Framework for Chinese LLM supervised fine-tuning",
      "detailed_description": "A comprehensive framework for Supervised Fine-Tuning (SFT) of Large Language Models (LLMs), supporting multiple base models (ChatGLM, LLaMA, etc.) and acceleration techniques like LoRA, QLoRA, and DeepSpeed.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "model_training",
        "fine_tuning"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/yongzhuo/LLM-SFT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "sft",
        "fine-tuning",
        "deepspeed"
      ],
      "id": 1076
    },
    {
      "name": "SimVQ",
      "one_line_profile": "Vector quantization method to address representation collapse",
      "detailed_description": "An implementation of SimVQ, a method to improve vector quantized models by addressing representation collapse using a linear layer approach, as presented at ICCV 2025.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "representation_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/youngsheen/SimVQ",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "vector-quantization",
        "iccv",
        "computer-vision"
      ],
      "id": 1077
    },
    {
      "name": "rknn-cpp-yolo",
      "one_line_profile": "Optimized YOLOv11 inference on RK3588",
      "detailed_description": "A C++ project for efficient real-time inference of YOLOv11 on RK3588 platforms using RKNN and RGA hardware acceleration.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_acceleration",
        "edge_computing"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/yuunnn-w/rknn-cpp-yolo",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "rknn",
        "yolo",
        "rk3588",
        "inference"
      ],
      "id": 1078
    },
    {
      "name": "Optimizing-SGEMM-on-NVIDIA-Turing-GPUs",
      "one_line_profile": "High-performance SGEMM kernels for NVIDIA GPUs",
      "detailed_description": "A collection of highly optimized SGEMM (Single-Precision General Matrix Multiply) kernel functions for NVIDIA Turing GPUs, achieving performance close to cuBLAS.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "hpc_kernels",
        "matrix_multiplication"
      ],
      "application_level": "library",
      "primary_language": "Cuda",
      "repo_url": "https://github.com/yzhaiustc/Optimizing-SGEMM-on-NVIDIA-Turing-GPUs",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "cuda",
        "sgemm",
        "optimization",
        "hpc"
      ],
      "id": 1079
    },
    {
      "name": "AI-research-SKILLs",
      "one_line_profile": "Library of AI research skills for agents",
      "detailed_description": "A comprehensive library of AI research and engineering skills designed to be packaged into AI agents (like Claude or Gemini) to enhance their capabilities in conducting AI research.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "agent_tools",
        "research_automation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zechenzhangAGI/AI-research-SKILLs",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ai-agent",
        "research-tools",
        "skills-library"
      ],
      "id": 1080
    },
    {
      "name": "ZhiLight",
      "one_line_profile": "High-performance LLM inference engine",
      "detailed_description": "A highly optimized inference acceleration engine specifically designed for Llama and its variants, providing efficient serving capabilities.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_engine",
        "llm_serving"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/zhihu/ZhiLight",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "inference",
        "acceleration",
        "llama"
      ],
      "id": 1081
    },
    {
      "name": "yolort",
      "one_line_profile": "Runtime stack for YOLOv5 on accelerators",
      "detailed_description": "A runtime stack that simplifies the deployment of YOLOv5 models on specialized accelerators such as TensorRT, LibTorch, ONNX Runtime, TVM, and NCNN.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "inference_runtime",
        "model_deployment"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zhiqwang/yolort",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "yolov5",
        "tensorrt",
        "tvm",
        "inference"
      ],
      "id": 1082
    },
    {
      "name": "PTQD",
      "one_line_profile": "Post-training quantization for diffusion models",
      "detailed_description": "The official implementation of PTQD, a method for accurate post-training quantization specifically tailored for diffusion models.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "diffusion_models"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/ziplab/PTQD",
      "help_website": [],
      "license": null,
      "tags": [
        "quantization",
        "diffusion",
        "post-training"
      ],
      "id": 1083
    },
    {
      "name": "KnowLM",
      "one_line_profile": "Knowledgeable Large Language Model Framework",
      "detailed_description": "An open-source framework for building and training Knowledgeable Large Language Models, focusing on integrating knowledge graphs and structured data.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "llm_framework",
        "knowledge_integration"
      ],
      "application_level": "workflow",
      "primary_language": "Python",
      "repo_url": "https://github.com/zjunlp/KnowLM",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "llm",
        "knowledge-graph",
        "framework"
      ],
      "id": 1084
    },
    {
      "name": "RepQ-ViT",
      "one_line_profile": "Post-training quantization for Vision Transformers",
      "detailed_description": "A tool implementing RepQ-ViT, a scale reparameterization method for post-training quantization of Vision Transformers (ViTs).",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "quantization",
        "vision_transformer"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/zkkli/RepQ-ViT",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "quantization",
        "vit",
        "post-training"
      ],
      "id": 1085
    },
    {
      "name": "zml",
      "one_line_profile": "High-performance AI compiler and runtime stack",
      "detailed_description": "A machine learning compiler and runtime stack built with Zig, OpenXLA, and MLIR, designed to run any model on any hardware with zero compromise.",
      "domains": [
        "AI6",
        "AI6-04"
      ],
      "subtask_category": [
        "compiler",
        "runtime"
      ],
      "application_level": "platform",
      "primary_language": "Zig",
      "repo_url": "https://github.com/zml/zml",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "compiler",
        "zig",
        "mlir",
        "openxla"
      ],
      "id": 1086
    },
    {
      "name": "ssh-dashboard",
      "one_line_profile": "Lightweight CLI dashboard for monitoring GPU/CPU usage across SSH servers",
      "detailed_description": "A terminal-based dashboard that aggregates and visualizes real-time resource usage (CPU, RAM, Disk, and specifically NVIDIA/AMD GPUs) from multiple remote servers via SSH. It is particularly useful for researchers managing small-scale AI/HPC clusters or GPU workstations.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "monitoring",
        "resource_visualization"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/AlpinDale/ssh-dashboard",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu-monitoring",
        "ssh",
        "cli",
        "hpc-monitoring"
      ],
      "id": 1087
    },
    {
      "name": "TensorDash",
      "one_line_profile": "Remote monitoring application for deep learning model training",
      "detailed_description": "A tool that allows researchers to remotely monitor their deep learning model's training metrics (loss, accuracy, etc.) in real-time via a mobile app or dashboard. It supports major frameworks like TensorFlow, PyTorch, and Keras, enabling tracking of long-running scientific experiments.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "experiment_tracking",
        "monitoring"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/CleanPegasus/TensorDash",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "deep-learning",
        "monitoring",
        "mobile-app",
        "experiment-tracking"
      ],
      "id": 1088
    },
    {
      "name": "coffeeshop",
      "one_line_profile": "Slack notification tool for deep learning training metrics",
      "detailed_description": "A Python library that integrates with deep learning training loops to send real-time metrics and status updates (epoch completion, crash alerts) to a Slack channel. It facilitates remote monitoring of scientific machine learning experiments.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "alerting",
        "experiment_tracking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/CleanPegasus/coffeeshop",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slack",
        "notification",
        "deep-learning",
        "monitoring"
      ],
      "id": 1089
    },
    {
      "name": "Graphical Prototyping Toolbox for ML Experimentation",
      "one_line_profile": "Web-based toolbox for ML experiment setup, data preparation, and tracking",
      "detailed_description": "A composition of web applications for machine learning experimentation, including components for data preparation, experiment setup, and algorithm tracking (MLflow integration), developed by Fraunhofer MEVIS.",
      "domains": [
        "AI6",
        "AI6-05",
        "Medical Imaging"
      ],
      "subtask_category": [
        "experiment_tracking",
        "workflow_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/FraunhoferMEVIS/Graphical_prototyping_Toolbox_for_ML_Experimentation",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "ml-experimentation",
        "workflow",
        "fraunhofer"
      ],
      "id": 1090
    },
    {
      "name": "prometheus-cluster-exporter",
      "one_line_profile": "Prometheus exporter for Lustre and Slurm metrics on HPC clusters",
      "detailed_description": "A monitoring tool that exports Lustre metadata operations and IO throughput metrics associated with SLURM accounts and user processes, designed for HPC cluster observability.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "hpc_monitoring",
        "resource_observability"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/GSI-HPC/prometheus-cluster-exporter",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "hpc",
        "lustre",
        "slurm",
        "prometheus",
        "monitoring"
      ],
      "id": 1091
    },
    {
      "name": "Tattle",
      "one_line_profile": "Self-service dashboard application for Graphite and Ganglia monitoring",
      "detailed_description": "A lightweight web application providing dashboards for Graphite and Ganglia, which are legacy but widely used monitoring systems in HPC environments.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "hpc_monitoring",
        "visualization"
      ],
      "application_level": "platform",
      "primary_language": "PHP",
      "repo_url": "https://github.com/Graphite-Tattle/Tattle",
      "help_website": [],
      "license": null,
      "tags": [
        "ganglia",
        "graphite",
        "dashboard",
        "hpc"
      ],
      "id": 1092
    },
    {
      "name": "CompressAI-Trainer",
      "one_line_profile": "Training platform for end-to-end deep learning compression models",
      "detailed_description": "A platform for training, evaluating, and benchmarking end-to-end compression models using the CompressAI library, supporting scientific signal processing research.",
      "domains": [
        "Computer Science",
        "Signal Processing"
      ],
      "subtask_category": [
        "model_training",
        "compression"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/InterDigitalInc/CompressAI-Trainer",
      "help_website": [],
      "license": "BSD-3-Clause-Clear",
      "tags": [
        "compression",
        "deep-learning",
        "compressai"
      ],
      "id": 1093
    },
    {
      "name": "NVTX.jl",
      "one_line_profile": "Julia bindings for NVIDIA Tools Extension (NVTX) profiling",
      "detailed_description": "Provides Julia bindings for NVTX, allowing researchers to instrument Julia scientific code for profiling with NVIDIA Nsight Systems.",
      "domains": [
        "AI6",
        "AI6-05",
        "Scientific Computing"
      ],
      "subtask_category": [
        "profiling",
        "performance_analysis"
      ],
      "application_level": "library",
      "primary_language": "Julia",
      "repo_url": "https://github.com/JuliaGPU/NVTX.jl",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "julia",
        "gpu",
        "profiling",
        "nvtx",
        "hpc"
      ],
      "id": 1094
    },
    {
      "name": "KohakuBoard",
      "one_line_profile": "Lightweight local ML experiment tracking system",
      "detailed_description": "A high-efficiency, self-hosted machine learning experiment tracking dashboard, serving as a lightweight alternative to tools like TensorBoard or MLflow for researchers.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "experiment_tracking",
        "visualization"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/KohakuBlueleaf/KohakuBoard",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "mlops",
        "experiment-tracking",
        "visualization"
      ],
      "id": 1095
    },
    {
      "name": "BlendingToolKit",
      "one_line_profile": "Simulation and analysis toolkit for galaxy blending in astronomy",
      "detailed_description": "Tools to create blend catalogs, produce training samples, and implement blending metrics for astronomical surveys, specifically for the LSST Dark Energy Science Collaboration.",
      "domains": [
        "Astronomy",
        "Astrophysics"
      ],
      "subtask_category": [
        "simulation",
        "data_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/LSSTDESC/BlendingToolKit",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "astronomy",
        "lsst",
        "galaxy-blending",
        "simulation"
      ],
      "id": 1096
    },
    {
      "name": "extra_keras_metrics",
      "one_line_profile": "Library of additional metrics for Keras models",
      "detailed_description": "Integrates a comprehensive set of additional training and evaluation metrics into the Keras neural network library, facilitating detailed model performance analysis.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/LucaCappelletti94/extra_keras_metrics",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "keras",
        "metrics",
        "deep-learning",
        "evaluation"
      ],
      "id": 1097
    },
    {
      "name": "Vernier",
      "one_line_profile": "Caliper-based profiler for scientific code on HPC platforms",
      "detailed_description": "A profiling tool developed by the Met Office designed for scientific applications on High Performance Computing (HPC) platforms, using a caliper-based approach.",
      "domains": [
        "AI6",
        "AI6-05",
        "HPC"
      ],
      "subtask_category": [
        "profiling",
        "performance_analysis"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/MetOffice/Vernier",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "profiling",
        "met-office",
        "performance"
      ],
      "id": 1098
    },
    {
      "name": "dynolog",
      "one_line_profile": "Telemetry daemon for AI/HPC performance monitoring and tracing",
      "detailed_description": "A telemetry daemon that exports metrics from Linux kernel, CPU, GPU, and integrates with PyTorch to trigger traces for distributed training applications, developed by Moore Threads.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "profiling",
        "telemetry",
        "distributed_training"
      ],
      "application_level": "service",
      "primary_language": "C++",
      "repo_url": "https://github.com/MooreThreads/dynolog",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "telemetry",
        "pytorch",
        "gpu",
        "profiling",
        "hpc"
      ],
      "id": 1099
    },
    {
      "name": "dcgm-exporter",
      "one_line_profile": "NVIDIA GPU metrics exporter for Prometheus",
      "detailed_description": "A tool that leverages the NVIDIA Data Center GPU Manager (DCGM) to export GPU metrics to Prometheus, essential for monitoring AI and HPC clusters.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "gpu_monitoring",
        "infrastructure_observability"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/NVIDIA/dcgm-exporter",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nvidia",
        "gpu",
        "prometheus",
        "monitoring",
        "dcgm"
      ],
      "id": 1100
    },
    {
      "name": "gpu-monitoring-tools",
      "one_line_profile": "Legacy tools for monitoring NVIDIA GPUs on Linux",
      "detailed_description": "A collection of tools for monitoring NVIDIA GPUs, including wrappers and exporters, widely used in HPC and AI infrastructure before the consolidation into dcgm-exporter.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "gpu_monitoring",
        "resource_management"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/NVIDIA/gpu-monitoring-tools",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "nvidia",
        "gpu",
        "monitoring",
        "linux"
      ],
      "id": 1101
    },
    {
      "name": "nsight-python",
      "one_line_profile": "Python bindings for NVIDIA Nsight profiling tools",
      "detailed_description": "Provides a Python interface to NVIDIA Nsight tools, enabling researchers to profile and optimize Python-based scientific and AI applications on GPUs.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "profiling",
        "optimization"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/NVIDIA/nsight-python",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "profiling",
        "nvidia",
        "python",
        "cuda",
        "nsight"
      ],
      "id": 1102
    },
    {
      "name": "slurm2sql",
      "one_line_profile": "Tool to convert Slurm accounting logs to SQLite for analysis",
      "detailed_description": "A utility that dumps the Slurm workload manager's accounting database into a SQLite3 database, facilitating easy analysis of HPC usage and costs.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "cost_analysis",
        "usage_reporting"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/NordicHPC/slurm2sql",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "slurm",
        "hpc",
        "accounting",
        "sqlite"
      ],
      "id": 1103
    },
    {
      "name": "sonar",
      "one_line_profile": "HPC resource usage profiling tool",
      "detailed_description": "A tool designed to profile the usage of HPC resources by regularly probing processes, helping to identify performance bottlenecks and resource efficiency.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "profiling",
        "resource_monitoring"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/NordicHPC/sonar",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "profiling",
        "rust",
        "monitoring"
      ],
      "id": 1104
    },
    {
      "name": "Jobstats",
      "one_line_profile": "Job monitoring platform for CPU and GPU clusters in HPC environments",
      "detailed_description": "A job monitoring platform designed for CPU and GPU clusters, providing insights into job performance and resource utilization, specifically tailored for academic or research high-performance computing environments.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "monitoring",
        "resource_profiling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/PrincetonUniversity/jobstats",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "hpc",
        "cluster-monitoring",
        "slurm",
        "gpu-monitoring"
      ],
      "id": 1105
    },
    {
      "name": "ROCmValidationSuite",
      "one_line_profile": "System validation and diagnostics tool for AMD GPUs in HPC",
      "detailed_description": "A system validation and diagnostics tool designed for monitoring, stress testing, detecting, and troubleshooting issues impacting AMD GPUs specifically in high-performance computing environments.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "hardware_validation",
        "diagnostics"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/ROCm/ROCmValidationSuite",
      "help_website": [
        "https://rocm.docs.amd.com/projects/RVS/en/latest/"
      ],
      "license": "MIT",
      "tags": [
        "rocm",
        "amd-gpu",
        "hpc",
        "diagnostics",
        "stress-testing"
      ],
      "id": 1106
    },
    {
      "name": "gpu-utils",
      "one_line_profile": "Utilities for monitoring and customizing GPU performance",
      "detailed_description": "A set of utilities for monitoring and customizing GPU performance, useful for optimizing scientific computing workloads on GPU infrastructure.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "monitoring",
        "performance_tuning"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Ricks-Lab/gpu-utils",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "gpu",
        "monitoring",
        "performance",
        "nvidia"
      ],
      "id": 1107
    },
    {
      "name": "easy_metric_learning",
      "one_line_profile": "Library for training metric learning models",
      "detailed_description": "A Python library designed to simplify the training of metric learning models, facilitating scientific data analysis and machine learning research tasks.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "model_training",
        "metric_learning"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/RocketFlash/easy_metric_learning",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "metric-learning",
        "machine-learning",
        "deep-learning"
      ],
      "id": 1108
    },
    {
      "name": "StoneNeedle",
      "one_line_profile": "I/O workload profiling tool for HPC and Cloud computing",
      "detailed_description": "A tool running in the Linux kernel environment to statistic I/O workload profiling data, aimed at enabling I/O optimizations for HPC and Cloud computing in the exascale era.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "io_profiling",
        "performance_analysis"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/Samsung/StoneNeedle",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "hpc",
        "io-profiling",
        "linux-kernel",
        "performance"
      ],
      "id": 1109
    },
    {
      "name": "slurm_exporter",
      "one_line_profile": "Prometheus exporter for Slurm-managed clusters metrics",
      "detailed_description": "A Prometheus exporter designed to scrape and expose performance and scheduling metrics from Slurm-managed clusters, supporting CPU and GPU resource accounting for HPC environments.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "monitoring",
        "resource_accounting"
      ],
      "application_level": "service",
      "primary_language": "Go",
      "repo_url": "https://github.com/SckyzO/slurm_exporter",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "slurm",
        "prometheus-exporter",
        "hpc",
        "monitoring"
      ],
      "id": 1110
    },
    {
      "name": "gpu_mon",
      "one_line_profile": "Lightweight Python script for monitoring GPU access",
      "detailed_description": "A Python script designed to monitor GPU access and usage, providing a simple way to track GPU resources in scientific computing setups.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "monitoring"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/Shmuma/gpu_mon",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "gpu",
        "monitoring",
        "python"
      ],
      "id": 1111
    },
    {
      "name": "nvtop",
      "one_line_profile": "Interactive GPU process monitor for NVIDIA, AMD, and others",
      "detailed_description": "A task monitor for GPUs and accelerators (AMD, Apple, Huawei, Intel, NVIDIA, Qualcomm), essential for monitoring scientific training and inference jobs.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "monitoring",
        "process_management"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/Syllo/nvtop",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "gpu",
        "monitoring",
        "hpc",
        "nvidia",
        "amd"
      ],
      "id": 1112
    },
    {
      "name": "HPCPerfStats",
      "one_line_profile": "Automated resource-usage monitoring and analysis for HPC Clusters",
      "detailed_description": "An automated resource-usage monitoring and analysis package specifically designed for HPC Clusters, developed by TACC (Texas Advanced Computing Center).",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "monitoring",
        "performance_analysis"
      ],
      "application_level": "platform",
      "primary_language": "C",
      "repo_url": "https://github.com/TACC/HPCPerfStats",
      "help_website": [],
      "license": "LGPL-2.1",
      "tags": [
        "hpc",
        "monitoring",
        "performance",
        "tacc"
      ],
      "id": 1113
    },
    {
      "name": "GFPGAN",
      "one_line_profile": "Practical algorithms for real-world face restoration",
      "detailed_description": "A deep learning tool for blind face restoration, utilizing Generative Facial Prior (GFP) for scientific image processing and computer vision research.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "image_restoration",
        "inference"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/TencentARC/GFPGAN",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "gan",
        "face-restoration",
        "computer-vision",
        "deep-learning"
      ],
      "id": 1114
    },
    {
      "name": "uetai",
      "one_line_profile": "Custom ML tracking experiment and debugging tools",
      "detailed_description": "A toolset for tracking machine learning experiments and debugging, facilitating the scientific process of model development and evaluation.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "experiment_tracking",
        "debugging"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/UETAILab/uetai",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ml-tracking",
        "experiment-management",
        "debugging"
      ],
      "id": 1115
    },
    {
      "name": "TEGNAS",
      "one_line_profile": "Neural Architecture Search with Training-Free Metrics",
      "detailed_description": "Implementation of 'Understanding and Accelerating Neural Architecture Search with Training-Free and Theory-Grounded Metrics', a tool for scientific modeling and AI research.",
      "domains": [
        "AI4"
      ],
      "subtask_category": [
        "neural_architecture_search",
        "modeling"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/VITA-Group/TEGNAS",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "nas",
        "deep-learning",
        "neural-architecture-search"
      ],
      "id": 1116
    },
    {
      "name": "VevestaX",
      "one_line_profile": "Lightweight ML experiment tracking and EDA tool",
      "detailed_description": "A library to track machine learning experiments, perform exploratory data analysis (EDA), and manage versioning, supporting scientific data analysis workflows.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "experiment_tracking",
        "eda"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/Vevesta/VevestaX",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ml-tracking",
        "eda",
        "data-science"
      ],
      "id": 1117
    },
    {
      "name": "nvitop",
      "one_line_profile": "Interactive NVIDIA-GPU process viewer and management tool",
      "detailed_description": "An interactive process viewer for NVIDIA GPUs, providing a one-stop solution for GPU process management and monitoring, critical for AI and HPC workloads.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "monitoring",
        "process_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/XuehaiPan/nvitop",
      "help_website": [
        "https://nvitop.readthedocs.io"
      ],
      "license": "Apache-2.0",
      "tags": [
        "gpu",
        "nvidia",
        "monitoring",
        "hpc"
      ],
      "id": 1118
    },
    {
      "name": "Prometheus (Drone)",
      "one_line_profile": "Open source software platform for autonomous drone research",
      "detailed_description": "Prometheus is an open-source software project for autonomous drones, providing a complete set of solutions for mapping, localization, planning, and control, facilitating robotics research.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "robotics_control",
        "simulation"
      ],
      "application_level": "platform",
      "primary_language": "C++",
      "repo_url": "https://github.com/amov-lab/Prometheus",
      "help_website": [
        "https://github.com/amov-lab/Prometheus/wiki"
      ],
      "license": "Apache-2.0",
      "tags": [
        "robotics",
        "drones",
        "autonomous-control"
      ],
      "id": 1119
    },
    {
      "name": "MOCHA",
      "one_line_profile": "Dataset and metrics for evaluating reading comprehension models",
      "detailed_description": "MOCHA is a dataset and evaluation suite for training and evaluating reading comprehension metrics, supporting scientific analysis of NLP models.",
      "domains": [
        "AI6"
      ],
      "subtask_category": [
        "model_evaluation",
        "dataset"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/anthonywchen/MOCHA",
      "help_website": [],
      "license": null,
      "tags": [
        "nlp",
        "evaluation-metric",
        "dataset"
      ],
      "id": 1120
    },
    {
      "name": "Apache Ambari",
      "one_line_profile": "Platform for provisioning and managing Hadoop clusters",
      "detailed_description": "Apache Ambari is a tool for provisioning, managing, and monitoring Apache Hadoop clusters, which are essential infrastructure for big data scientific computing.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "cluster_management",
        "monitoring"
      ],
      "application_level": "platform",
      "primary_language": "Java",
      "repo_url": "https://github.com/apache/ambari",
      "help_website": [
        "https://ambari.apache.org/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "hadoop",
        "cluster-management",
        "big-data"
      ],
      "id": 1121
    },
    {
      "name": "k8s-gpu-hpa",
      "one_line_profile": "Horizontal Pod Autoscaling for Kubernetes using Nvidia GPU Metrics",
      "detailed_description": "A tool to enable Horizontal Pod Autoscaling (HPA) in Kubernetes based on custom Nvidia GPU metrics, essential for optimizing AI/HPC workloads.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "resource_optimization",
        "autoscaling"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/ashrafgt/k8s-gpu-hpa",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "kubernetes",
        "gpu",
        "autoscaling"
      ],
      "id": 1122
    },
    {
      "name": "SageMaker Experiments",
      "one_line_profile": "Experiment tracking library for Amazon SageMaker",
      "detailed_description": "A library for tracking, organizing, and comparing machine learning experiments on Amazon SageMaker, facilitating scientific reproducibility.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "experiment_tracking",
        "model_management"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/aws/sagemaker-experiments",
      "help_website": [
        "https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html"
      ],
      "license": "Apache-2.0",
      "tags": [
        "sagemaker",
        "experiment-tracking",
        "ml"
      ],
      "id": 1123
    },
    {
      "name": "selFIe",
      "one_line_profile": "Lightweight profiling engine for Linux commands and HPC codes",
      "detailed_description": "A very light profiling tool designed for Linux commands and HPC codes, developed by CEA-HPC. It provides self-profiling capabilities to analyze runtime performance.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "profiling",
        "performance_analysis"
      ],
      "application_level": "solver",
      "primary_language": "C",
      "repo_url": "https://github.com/cea-hpc/selFIe",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "hpc",
        "profiling",
        "linux",
        "performance"
      ],
      "id": 1124
    },
    {
      "name": "ceph-scripts",
      "one_line_profile": "Helper scripts for monitoring and managing Ceph clusters",
      "detailed_description": "A collection of helper scripts developed by CERN for monitoring and managing Ceph storage clusters, facilitating infrastructure operations in scientific computing environments.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "storage_management",
        "monitoring"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/cernceph/ceph-scripts",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "ceph",
        "storage",
        "cern",
        "monitoring"
      ],
      "id": 1125
    },
    {
      "name": "chaiNNer",
      "one_line_profile": "Node-based image processing GUI for AI upscaling and manipulation",
      "detailed_description": "A node-based image processing GUI aimed at making chaining image processing tasks easy and customizable. It supports AI upscaling and programmatic image processing workflows.",
      "domains": [
        "AI-Workflow",
        "Image-Processing"
      ],
      "subtask_category": [
        "image_processing",
        "upscaling",
        "workflow_automation"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/chaiNNer-org/chaiNNer",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "image-processing",
        "gui",
        "ai-upscaling",
        "workflow"
      ],
      "id": 1126
    },
    {
      "name": "nsys2json",
      "one_line_profile": "Converter for NVIDIA Nsight Systems output to JSON format",
      "detailed_description": "A Python script to convert the output of NVIDIA Nsight Systems (SQLite format) to JSON in Google Chrome Trace Event Format, facilitating performance analysis of GPU workloads.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "profiling",
        "visualization",
        "format_conversion"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/chenyu-jiang/nsys2json",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "nvidia",
        "nsight",
        "profiling",
        "gpu"
      ],
      "id": 1127
    },
    {
      "name": "gputasker",
      "one_line_profile": "Lightweight GPU task scheduler for cluster management",
      "detailed_description": "A lightweight and effective GPU cluster task scheduling tool designed to manage and orchestrate GPU tasks.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/cnstark/gputasker",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "scheduler",
        "cluster-management"
      ],
      "id": 1128
    },
    {
      "name": "mactop",
      "one_line_profile": "Real-time monitoring tool for Apple Silicon chips",
      "detailed_description": "A terminal-based monitoring tool specifically for Apple Silicon (M1/M2/M3) chips, displaying real-time metrics for CPU, GPU, and Neural Engine usage, useful for local AI development monitoring.",
      "domains": [
        "AI6-05"
      ],
      "subtask_category": [
        "hardware_monitoring",
        "resource_profiling"
      ],
      "application_level": "solver",
      "primary_language": "Go",
      "repo_url": "https://github.com/context-labs/mactop",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "apple-silicon",
        "monitoring",
        "gpu",
        "cli"
      ],
      "id": 1129
    },
    {
      "name": "netdata_nv_plugin",
      "one_line_profile": "NetData plugin for NVIDIA GPU statistics",
      "detailed_description": "A plugin for NetData to poll and display statistics from NVIDIA GPUs, enabling infrastructure monitoring for AI/HPC nodes.",
      "domains": [
        "AI6-05"
      ],
      "subtask_category": [
        "hardware_monitoring",
        "gpu_metrics"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/coraxx/netdata_nv_plugin",
      "help_website": [],
      "license": null,
      "tags": [
        "netdata",
        "nvidia",
        "gpu",
        "monitoring"
      ],
      "id": 1130
    },
    {
      "name": "torch-log-wmse",
      "one_line_profile": "Audio quality metric and loss function for source separation",
      "detailed_description": "Implementation of logWMSE, an audio quality metric and loss function with support for digital silence targets, useful for training and evaluating audio source separation systems.",
      "domains": [
        "AI-Model",
        "Audio"
      ],
      "subtask_category": [
        "model_training",
        "evaluation_metric"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/crlandsc/torch-log-wmse",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "audio",
        "loss-function",
        "pytorch",
        "source-separation"
      ],
      "id": 1131
    },
    {
      "name": "dantegpu-core",
      "one_line_profile": "Core microservices for DanteGPU distributed GPU network",
      "detailed_description": "Core microservices powering the DanteGPU distributed GPU network. It manages providers, orchestrates AI job scheduling, and handles authentication and monitoring for distributed AI computing.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "job_scheduling",
        "distributed_computing"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/dante-gpu/dantegpu-core",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "distributed-systems",
        "scheduler",
        "ai-infra"
      ],
      "id": 1132
    },
    {
      "name": "socpowerbud",
      "one_line_profile": "Real-time power and frequency monitor for Apple Silicon",
      "detailed_description": "A sudoless alternative to powermetrics for Apple Silicon, providing real-time monitoring of CPU & GPU frequency, voltage, and usage, useful for local scientific computing profiling.",
      "domains": [
        "AI6-05"
      ],
      "subtask_category": [
        "hardware_monitoring",
        "power_profiling"
      ],
      "application_level": "solver",
      "primary_language": "Objective-C",
      "repo_url": "https://github.com/dehydratedpotato/socpowerbud",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "apple-silicon",
        "power-monitoring",
        "profiling"
      ],
      "id": 1133
    },
    {
      "name": "kronos",
      "one_line_profile": "HPC workload analysis and modeling tool",
      "detailed_description": "Tools for analysing profiling information, modeling, and generating portable HPC workloads, developed by ECMWF (European Centre for Medium-Range Weather Forecasts).",
      "domains": [
        "AI6",
        "HPC"
      ],
      "subtask_category": [
        "workload_modeling",
        "profiling",
        "simulation"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ecmwf/kronos",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "hpc",
        "workload-generation",
        "ecmwf",
        "profiling"
      ],
      "id": 1134
    },
    {
      "name": "mltraq",
      "one_line_profile": "Experiment tracking tool for ML and AI",
      "detailed_description": "A tool to track and collaborate on Machine Learning and AI experiments, supporting metadata logging and experiment management.",
      "domains": [
        "AI6-05",
        "MLOps"
      ],
      "subtask_category": [
        "experiment_tracking",
        "metadata_management"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/elehcimd/mltraq",
      "help_website": [],
      "license": "BSD-3-Clause",
      "tags": [
        "mlops",
        "experiment-tracking",
        "reproducibility"
      ],
      "id": 1135
    },
    {
      "name": "evidently",
      "one_line_profile": "Open-source ML and LLM observability framework",
      "detailed_description": "An open-source framework to evaluate, test, and monitor ML models and LLMs in production, covering data drift, model performance, and data quality metrics.",
      "domains": [
        "AI6-05",
        "MLOps"
      ],
      "subtask_category": [
        "model_monitoring",
        "data_drift_detection",
        "evaluation"
      ],
      "application_level": "platform",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/evidentlyai/evidently",
      "help_website": [
        "https://docs.evidentlyai.com/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "mlops",
        "observability",
        "data-drift",
        "llm-monitoring"
      ],
      "id": 1136
    },
    {
      "name": "Dynolog",
      "one_line_profile": "Telemetry daemon for performance monitoring and tracing of AI/HPC workloads",
      "detailed_description": "Dynolog is a telemetry daemon designed for performance monitoring and tracing in distributed training applications. It integrates with PyTorch to export metrics from system components (CPU, GPU, Linux kernel) and correlates them with training events, enabling performance analysis of AI models.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "performance_monitoring",
        "distributed_training_tracing"
      ],
      "application_level": "service",
      "primary_language": "C++",
      "repo_url": "https://github.com/facebookincubator/dynolog",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "telemetry",
        "pytorch",
        "hpc",
        "gpu-monitoring"
      ],
      "id": 1137
    },
    {
      "name": "OmniSealBench",
      "one_line_profile": "Benchmark and toolkit for evaluating neural watermarking techniques",
      "detailed_description": "A comprehensive benchmark suite for evaluating the performance and robustness of neural watermarking techniques. It includes datasets, evaluation metrics, and tools for training and testing neural networks specifically for watermarking research.",
      "domains": [
        "AI4",
        "AI4-11"
      ],
      "subtask_category": [
        "model_evaluation",
        "watermarking_benchmarking"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/facebookresearch/omnisealbench",
      "help_website": [],
      "license": "NOASSERTION",
      "tags": [
        "neural-watermarking",
        "benchmark",
        "model-security"
      ],
      "id": 1138
    },
    {
      "name": "gpuview",
      "one_line_profile": "Lightweight web dashboard for monitoring GPU usage in AI labs",
      "detailed_description": "A lightweight web-based dashboard for monitoring GPU status (usage, temperature, memory) across multiple machines. It is designed to help researchers and AI engineers track resource utilization in GPU clusters or local labs.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "resource_monitoring",
        "gpu_management"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/fgaim/gpuview",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "monitoring",
        "dashboard",
        "nvidia"
      ],
      "id": 1139
    },
    {
      "name": "Ganglia Web",
      "one_line_profile": "Web frontend for the Ganglia distributed monitoring system",
      "detailed_description": "The web interface for Ganglia, a scalable distributed monitoring system for high-performance computing systems such as clusters and grids. It visualizes metrics collected by the Ganglia monitor core.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "hpc_monitoring",
        "cluster_visualization"
      ],
      "application_level": "service",
      "primary_language": "PHP",
      "repo_url": "https://github.com/ganglia/ganglia-web",
      "help_website": [
        "http://ganglia.sourceforge.net/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "monitoring",
        "cluster",
        "visualization"
      ],
      "id": 1140
    },
    {
      "name": "Ganglia Contrib",
      "one_line_profile": "Collection of user-contributed tools for Ganglia monitoring system",
      "detailed_description": "A repository containing various add-ons, scripts, and extensions for the Ganglia monitoring system, enhancing its capability to monitor specific scientific and HPC workloads.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "hpc_monitoring",
        "metrics_collection"
      ],
      "application_level": "library",
      "primary_language": "HTML",
      "repo_url": "https://github.com/ganglia/ganglia_contrib",
      "help_website": [],
      "license": null,
      "tags": [
        "hpc",
        "monitoring",
        "extensions"
      ],
      "id": 1141
    },
    {
      "name": "JMXetric",
      "one_line_profile": "Java JVM instrumentation for Ganglia monitoring",
      "detailed_description": "A tool that provides a bridge between JMX (Java Management Extensions) and Ganglia, allowing monitoring of Java-based scientific applications and HPC middleware.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "application_monitoring",
        "jvm_metrics"
      ],
      "application_level": "library",
      "primary_language": "Java",
      "repo_url": "https://github.com/ganglia/jmxetric",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "java",
        "jmx",
        "ganglia",
        "monitoring"
      ],
      "id": 1142
    },
    {
      "name": "Ganglia Monitor Core",
      "one_line_profile": "Scalable distributed monitoring system for HPC clusters",
      "detailed_description": "The core component of Ganglia, a scalable distributed monitoring system for high-performance computing systems such as clusters and grids. It handles metric collection and distribution.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "hpc_monitoring",
        "resource_tracking"
      ],
      "application_level": "service",
      "primary_language": "C",
      "repo_url": "https://github.com/ganglia/monitor-core",
      "help_website": [
        "http://ganglia.info/"
      ],
      "license": "BSD-3-Clause",
      "tags": [
        "hpc",
        "cluster",
        "monitoring",
        "distributed-systems"
      ],
      "id": 1143
    },
    {
      "name": "Ganglia API",
      "one_line_profile": "RESTful API layer for Ganglia distributed monitoring system",
      "detailed_description": "A Python-based API that exposes Ganglia monitoring data in a RESTful JSON format, enabling programmatic access to HPC cluster metrics for scientific infrastructure observability.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "monitoring",
        "observability"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/guardian/ganglia-api",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "ganglia",
        "hpc",
        "monitoring",
        "api"
      ],
      "id": 1144
    },
    {
      "name": "Slurm Job Exporter",
      "one_line_profile": "Prometheus exporter for Slurm job statistics and GPU usage",
      "detailed_description": "A Prometheus exporter that collects statistics from Slurm cgroup accounting, including NVIDIA GPU usage per job, specifically designed for monitoring scientific HPC workloads.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "monitoring",
        "resource_tracking"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/guilbaults/slurm-job-exporter",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "slurm",
        "prometheus",
        "gpu-monitoring",
        "hpc"
      ],
      "id": 1145
    },
    {
      "name": "Guild AI",
      "one_line_profile": "Experiment tracking and ML developer tool",
      "detailed_description": "An open-source experiment tracking tool for machine learning that manages runs, hyperparameters, and results, facilitating reproducible scientific research and model development.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "experiment_tracking",
        "reproducibility"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/guildai/guildai",
      "help_website": [
        "https://guild.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "experiment-tracking",
        "mlops",
        "reproducibility"
      ],
      "id": 1146
    },
    {
      "name": "gvtop",
      "one_line_profile": "Interactive TUI for monitoring NVIDIA GPUs",
      "detailed_description": "A terminal-based user interface (TUI) for monitoring NVIDIA GPU status, utilization, and processes, providing real-time observability for scientific computing resources.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "monitoring",
        "gpu_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/gvlassis/gvtop",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "monitoring",
        "nvidia",
        "tui"
      ],
      "id": 1147
    },
    {
      "name": "OptScale",
      "one_line_profile": "FinOps and cloud cost optimization platform for ML/AI workloads",
      "detailed_description": "A comprehensive FinOps and cloud cost optimization platform that supports Kubernetes and AI/ML workloads, helping scientific organizations manage and optimize computing costs across various cloud providers.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "cost_optimization",
        "resource_management"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/hystax/optscale",
      "help_website": [
        "https://my.optscale.com"
      ],
      "license": "Apache-2.0",
      "tags": [
        "finops",
        "cost-optimization",
        "kubernetes",
        "ml-cost"
      ],
      "id": 1148
    },
    {
      "name": "LLaMA-Omni",
      "one_line_profile": "Low-latency end-to-end speech interaction model",
      "detailed_description": "A speech interaction model built upon Llama-3.1-8B-Instruct, designed for low-latency and high-quality end-to-end speech processing, serving as a solver for scientific speech tasks.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "inference",
        "speech_processing"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ictnlp/LLaMA-Omni",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "llm",
        "speech-interaction",
        "model",
        "inference"
      ],
      "id": 1149
    },
    {
      "name": "LACT",
      "one_line_profile": "Linux GPU configuration and monitoring tool",
      "detailed_description": "A robust tool for configuring and monitoring AMD and NVIDIA GPUs on Linux, providing essential hardware control and observability for scientific computing workstations and nodes.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "monitoring",
        "hardware_control"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/ilya-zlobintsev/LACT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "linux",
        "monitoring",
        "overclocking"
      ],
      "id": 1150
    },
    {
      "name": "all-smi",
      "one_line_profile": "Unified command-line utility for monitoring GPU hardware",
      "detailed_description": "A command-line tool that aggregates monitoring data from both NVIDIA (nvidia-smi) and AMD (rocm-smi) GPUs, facilitating unified observability in heterogeneous scientific computing environments.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "monitoring",
        "observability"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/inureyes/all-smi",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu",
        "monitoring",
        "nvidia",
        "amd"
      ],
      "id": 1151
    },
    {
      "name": "gpu-sentry",
      "one_line_profile": "Flask-based package for monitoring NVIDIA GPU utilization",
      "detailed_description": "A lightweight monitoring package that exposes NVIDIA GPU utilization metrics via a web interface, useful for tracking resource usage in scientific deep learning servers.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "monitoring",
        "observability"
      ],
      "application_level": "service",
      "primary_language": "Python",
      "repo_url": "https://github.com/jacenkow/gpu-sentry",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "monitoring",
        "flask",
        "nvidia"
      ],
      "id": 1152
    },
    {
      "name": "Jina Serve",
      "one_line_profile": "Cloud-native framework for building multimodal AI applications",
      "detailed_description": "A framework for building and serving multimodal AI applications, providing the runtime infrastructure for deploying scientific AI models (e.g., neural search, generative AI) as services.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "serving",
        "inference_infrastructure"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/jina-ai/serve",
      "help_website": [
        "https://jina.ai"
      ],
      "license": "Apache-2.0",
      "tags": [
        "ai-serving",
        "multimodal",
        "cloud-native",
        "inference"
      ],
      "id": 1153
    },
    {
      "name": "gpud",
      "one_line_profile": "Automated monitoring and diagnostics tool for GPU infrastructure in AI/HPC",
      "detailed_description": "GPUd is a lightweight daemon and library designed to automate the monitoring, diagnostics, and issue identification of NVIDIA GPUs in AI and HPC clusters. It provides real-time visibility into GPU health, ECC errors, NVLink topology, and thermal states, enabling researchers and cluster administrators to maintain the reliability of scientific computing infrastructure.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "infrastructure_monitoring",
        "hardware_diagnostics"
      ],
      "application_level": "platform",
      "primary_language": "Go",
      "repo_url": "https://github.com/leptonai/gpud",
      "help_website": [],
      "license": "Apache-2.0",
      "tags": [
        "gpu-monitoring",
        "hpc",
        "ai-infrastructure",
        "nvidia",
        "diagnostics"
      ],
      "id": 1154
    },
    {
      "name": "torcheval",
      "one_line_profile": "Performant model evaluation metrics library for PyTorch",
      "detailed_description": "Torcheval is a library that provides a rich collection of performant metrics for evaluating PyTorch models. It supports distributed training scenarios and offers a simple interface to create custom metrics, facilitating the scientific analysis of model performance in AI research.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "metrics_computation"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/meta-pytorch/torcheval",
      "help_website": [
        "https://pytorch.org/torcheval"
      ],
      "license": "NOASSERTION",
      "tags": [
        "pytorch",
        "metrics",
        "model-evaluation",
        "distributed-training"
      ],
      "id": 1155
    },
    {
      "name": "gmonitor",
      "one_line_profile": "NVIDIA GPU monitoring tool for terminal",
      "detailed_description": "A command-line tool for monitoring NVIDIA GPU metrics such as usage, memory, and temperature, essential for tracking resource utilization in AI/HPC compute clusters.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "resource_monitoring",
        "gpu_observability"
      ],
      "application_level": "solver",
      "primary_language": "C++",
      "repo_url": "https://github.com/mountassir/gmonitor",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "gpu-monitoring",
        "nvidia",
        "hpc",
        "observability"
      ],
      "id": 1156
    },
    {
      "name": "SparseCT",
      "one_line_profile": "Framework for sparse-view CT reconstruction research",
      "detailed_description": "A framework designed for developing, training, and benchmarking sparse-view Computed Tomography (CT) reconstruction algorithms, providing datasets, metrics, and baselines for medical imaging research.",
      "domains": [
        "Medical Imaging",
        "Physics"
      ],
      "subtask_category": [
        "image_reconstruction",
        "scientific_modeling"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/mozanunal/SparseCT",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "ct-reconstruction",
        "medical-imaging",
        "sparse-view",
        "deep-learning"
      ],
      "id": 1157
    },
    {
      "name": "gpu_monitor",
      "one_line_profile": "Multi-node GPU monitoring utility",
      "detailed_description": "A Python-based tool to monitor GPU status across single machines or clusters, facilitating resource tracking for distributed AI training and scientific computing workloads.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "resource_monitoring",
        "cluster_observability"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/msalvaris/gpu_monitor",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "monitoring",
        "cluster",
        "distributed-computing"
      ],
      "id": 1158
    },
    {
      "name": "nviwatch",
      "one_line_profile": "TUI for NVIDIA GPU process management and monitoring",
      "detailed_description": "A terminal user interface (TUI) built in Rust for real-time monitoring and management of NVIDIA GPU processes, aiding in the optimization and debugging of AI/HPC jobs.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "resource_monitoring",
        "process_management"
      ],
      "application_level": "solver",
      "primary_language": "Rust",
      "repo_url": "https://github.com/msminhas93/nviwatch",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "gpu",
        "nvidia",
        "tui",
        "monitoring",
        "rust"
      ],
      "id": 1159
    },
    {
      "name": "datadog_nvml",
      "one_line_profile": "NVIDIA GPU monitoring integration for Datadog",
      "detailed_description": "A utility that collects NVIDIA GPU metrics via NVML and sends them to Datadog, enabling centralized monitoring of GPU resources in scientific computing environments.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "resource_monitoring",
        "observability"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/ngi644/datadog_nvml",
      "help_website": [],
      "license": "GPL-2.0",
      "tags": [
        "gpu",
        "datadog",
        "nvml",
        "monitoring"
      ],
      "id": 1160
    },
    {
      "name": "OpenLIT",
      "one_line_profile": "OpenTelemetry-native observability and evaluation platform for LLMs and GenAI",
      "detailed_description": "OpenLIT is an observability and evaluation platform designed for AI engineering. It provides automatic instrumentation for LLMs, vector databases, and GPU accelerators, enabling developers to trace model execution, monitor costs, and perform evaluations (e.g., hallucination detection) on AI model outputs.",
      "domains": [
        "AI6",
        "AI6-05"
      ],
      "subtask_category": [
        "model_evaluation",
        "observability",
        "performance_profiling"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/openlit/openlit",
      "help_website": [
        "https://docs.openlit.io/"
      ],
      "license": "Apache-2.0",
      "tags": [
        "llm-ops",
        "observability",
        "evaluation",
        "gpu-monitoring",
        "opentelemetry"
      ],
      "id": 1161
    },
    {
      "name": "EconML",
      "one_line_profile": "A Python package for estimating heterogeneous treatment effects and causal inference",
      "detailed_description": "ALICE (Automated Learning and Intelligence for Causation and Economics) is a Microsoft Research project. EconML is a toolkit that combines state-of-the-art machine learning techniques with econometrics to solve complex causal inference problems. It implements orthogonal machine learning algorithms such as double machine learning, enabling the measurement of causal effects of treatment variables on outcomes while controlling for high-dimensional features.",
      "domains": [
        "AI3-02",
        "Social Science"
      ],
      "subtask_category": [
        "causal_inference",
        "estimation",
        "statistical_analysis"
      ],
      "application_level": "library",
      "primary_language": "Jupyter Notebook",
      "repo_url": "https://github.com/py-why/EconML",
      "help_website": [
        "https://econml.azurewebsites.net/"
      ],
      "license": "NOASSERTION",
      "tags": [
        "causal-inference",
        "econometrics",
        "machine-learning",
        "treatment-effect"
      ],
      "id": 1162
    },
    {
      "name": "ApeBench",
      "one_line_profile": "Benchmark suite for autoregressive neural emulation of PDEs",
      "detailed_description": "A benchmark suite designed for evaluating autoregressive neural networks in the context of emulating Partial Differential Equations (PDEs), supporting 1D, 2D, and 3D physics simulations.",
      "domains": [
        "AI4S",
        "Physics"
      ],
      "subtask_category": [
        "benchmarking",
        "scientific_modeling",
        "pde_solver"
      ],
      "application_level": "dataset",
      "primary_language": "Python",
      "repo_url": "https://github.com/tum-pbs/apebench",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "pde",
        "physics-ml",
        "benchmark",
        "neural-emulation"
      ],
      "id": 1163
    },
    {
      "name": "stubl",
      "one_line_profile": "SLURM Tools and UBiLities for HPC job management",
      "detailed_description": "A collection of shell scripts and utilities to facilitate the management and monitoring of jobs on Slurm-based HPC clusters, simplifying common tasks for researchers.",
      "domains": [
        "AI6",
        "HPC"
      ],
      "subtask_category": [
        "job_scheduling",
        "cluster_management"
      ],
      "application_level": "solver",
      "primary_language": "Shell",
      "repo_url": "https://github.com/ubccr/stubl",
      "help_website": [],
      "license": "GPL-3.0",
      "tags": [
        "slurm",
        "hpc",
        "job-management",
        "cluster-tools"
      ],
      "id": 1164
    },
    {
      "name": "HiddenLayer",
      "one_line_profile": "Neural network graph visualization and training metrics library",
      "detailed_description": "A lightweight library for visualizing neural network architectures (graphs) and tracking training metrics for PyTorch, TensorFlow, and Keras, aiding in model debugging and analysis.",
      "domains": [
        "AI6-05",
        "AI3"
      ],
      "subtask_category": [
        "model_visualization",
        "training_monitoring"
      ],
      "application_level": "library",
      "primary_language": "Python",
      "repo_url": "https://github.com/waleedka/hiddenlayer",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "visualization",
        "deep-learning",
        "pytorch",
        "tensorflow"
      ],
      "id": 1165
    },
    {
      "name": "GPUSitter",
      "one_line_profile": "Lightweight GPU job scheduler for idle resource utilization",
      "detailed_description": "A tool to monitor GPU usage and automatically launch jobs when resources are idle, designed for maximizing utilization in shared research server environments.",
      "domains": [
        "AI6",
        "HPC"
      ],
      "subtask_category": [
        "job_scheduling",
        "resource_management"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wilmerwang/GPUSitter",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "scheduling",
        "automation",
        "hpc"
      ],
      "id": 1166
    },
    {
      "name": "gpustat",
      "one_line_profile": "Command-line utility for monitoring GPU status",
      "detailed_description": "A standard command-line tool for querying and monitoring NVIDIA GPU status (usage, memory, temperature, processes) on Linux, widely used in AI/HPC research environments.",
      "domains": [
        "AI6-05",
        "HPC"
      ],
      "subtask_category": [
        "resource_monitoring",
        "observability"
      ],
      "application_level": "solver",
      "primary_language": "Python",
      "repo_url": "https://github.com/wookayin/gpustat",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "monitoring",
        "nvidia",
        "cli"
      ],
      "id": 1167
    },
    {
      "name": "gpustat-web",
      "one_line_profile": "Web interface for gpustat monitoring",
      "detailed_description": "A web-based interface for the gpustat utility, allowing remote monitoring of GPU cluster status through a browser.",
      "domains": [
        "AI6-05",
        "HPC"
      ],
      "subtask_category": [
        "resource_monitoring",
        "observability"
      ],
      "application_level": "platform",
      "primary_language": "Python",
      "repo_url": "https://github.com/wookayin/gpustat-web",
      "help_website": [],
      "license": "MIT",
      "tags": [
        "gpu",
        "monitoring",
        "web-ui",
        "cluster"
      ],
      "id": 1168
    }
  ]
}